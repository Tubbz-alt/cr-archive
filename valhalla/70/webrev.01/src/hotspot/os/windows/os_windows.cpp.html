<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/os/windows/os_windows.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // Must be at least Windows Vista or Server 2008 to use InitOnceExecuteOnce
  26 #define _WIN32_WINNT 0x0600
  27 
  28 // no precompiled headers
  29 #include &quot;jvm.h&quot;
  30 #include &quot;classfile/classLoader.hpp&quot;
  31 #include &quot;classfile/systemDictionary.hpp&quot;
  32 #include &quot;classfile/vmSymbols.hpp&quot;
  33 #include &quot;code/icBuffer.hpp&quot;
  34 #include &quot;code/vtableStubs.hpp&quot;
  35 #include &quot;compiler/compileBroker.hpp&quot;
  36 #include &quot;compiler/disassembler.hpp&quot;
  37 #include &quot;interpreter/interpreter.hpp&quot;
  38 #include &quot;logging/log.hpp&quot;
  39 #include &quot;logging/logStream.hpp&quot;
  40 #include &quot;memory/allocation.inline.hpp&quot;
  41 #include &quot;memory/filemap.hpp&quot;
  42 #include &quot;oops/oop.inline.hpp&quot;
  43 #include &quot;os_share_windows.hpp&quot;
  44 #include &quot;os_windows.inline.hpp&quot;
  45 #include &quot;prims/jniFastGetField.hpp&quot;
  46 #include &quot;prims/jvm_misc.hpp&quot;
  47 #include &quot;runtime/arguments.hpp&quot;
  48 #include &quot;runtime/atomic.hpp&quot;
  49 #include &quot;runtime/extendedPC.hpp&quot;
  50 #include &quot;runtime/globals.hpp&quot;
  51 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  52 #include &quot;runtime/java.hpp&quot;
  53 #include &quot;runtime/javaCalls.hpp&quot;
  54 #include &quot;runtime/mutexLocker.hpp&quot;
  55 #include &quot;runtime/objectMonitor.hpp&quot;
  56 #include &quot;runtime/orderAccess.hpp&quot;
  57 #include &quot;runtime/osThread.hpp&quot;
  58 #include &quot;runtime/perfMemory.hpp&quot;
  59 #include &quot;runtime/safepointMechanism.hpp&quot;
  60 #include &quot;runtime/sharedRuntime.hpp&quot;
  61 #include &quot;runtime/statSampler.hpp&quot;
  62 #include &quot;runtime/stubRoutines.hpp&quot;
  63 #include &quot;runtime/thread.inline.hpp&quot;
  64 #include &quot;runtime/threadCritical.hpp&quot;
  65 #include &quot;runtime/timer.hpp&quot;
  66 #include &quot;runtime/vm_version.hpp&quot;
  67 #include &quot;services/attachListener.hpp&quot;
  68 #include &quot;services/memTracker.hpp&quot;
  69 #include &quot;services/runtimeService.hpp&quot;
  70 #include &quot;utilities/align.hpp&quot;
  71 #include &quot;utilities/decoder.hpp&quot;
  72 #include &quot;utilities/defaultStream.hpp&quot;
  73 #include &quot;utilities/events.hpp&quot;
  74 #include &quot;utilities/growableArray.hpp&quot;
  75 #include &quot;utilities/macros.hpp&quot;
  76 #include &quot;utilities/vmError.hpp&quot;
  77 #include &quot;symbolengine.hpp&quot;
  78 #include &quot;windbghelp.hpp&quot;
  79 
  80 
  81 #ifdef _DEBUG
  82 #include &lt;crtdbg.h&gt;
  83 #endif
  84 
  85 
  86 #include &lt;windows.h&gt;
  87 #include &lt;sys/types.h&gt;
  88 #include &lt;sys/stat.h&gt;
  89 #include &lt;sys/timeb.h&gt;
  90 #include &lt;objidl.h&gt;
  91 #include &lt;shlobj.h&gt;
  92 
  93 #include &lt;malloc.h&gt;
  94 #include &lt;signal.h&gt;
  95 #include &lt;direct.h&gt;
  96 #include &lt;errno.h&gt;
  97 #include &lt;fcntl.h&gt;
  98 #include &lt;io.h&gt;
  99 #include &lt;process.h&gt;              // For _beginthreadex(), _endthreadex()
 100 #include &lt;imagehlp.h&gt;             // For os::dll_address_to_function_name
 101 // for enumerating dll libraries
 102 #include &lt;vdmdbg.h&gt;
 103 #include &lt;psapi.h&gt;
 104 #include &lt;mmsystem.h&gt;
 105 #include &lt;winsock2.h&gt;
 106 
 107 // for timer info max values which include all bits
 108 #define ALL_64_BITS CONST64(-1)
 109 
 110 // For DLL loading/load error detection
 111 // Values of PE COFF
 112 #define IMAGE_FILE_PTR_TO_SIGNATURE 0x3c
 113 #define IMAGE_FILE_SIGNATURE_LENGTH 4
 114 
 115 static HANDLE main_process;
 116 static HANDLE main_thread;
 117 static int    main_thread_id;
 118 
 119 static FILETIME process_creation_time;
 120 static FILETIME process_exit_time;
 121 static FILETIME process_user_time;
 122 static FILETIME process_kernel_time;
 123 
 124 #ifdef _M_AMD64
 125   #define __CPU__ amd64
 126 #else
 127   #define __CPU__ i486
 128 #endif
 129 
 130 #if INCLUDE_AOT
 131 PVOID  topLevelVectoredExceptionHandler = NULL;
 132 LONG WINAPI topLevelVectoredExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo);
 133 #endif
 134 
 135 // save DLL module handle, used by GetModuleFileName
 136 
 137 HINSTANCE vm_lib_handle;
 138 
 139 BOOL WINAPI DllMain(HINSTANCE hinst, DWORD reason, LPVOID reserved) {
 140   switch (reason) {
 141   case DLL_PROCESS_ATTACH:
 142     vm_lib_handle = hinst;
 143     if (ForceTimeHighResolution) {
 144       timeBeginPeriod(1L);
 145     }
 146     WindowsDbgHelp::pre_initialize();
 147     SymbolEngine::pre_initialize();
 148     break;
 149   case DLL_PROCESS_DETACH:
 150     if (ForceTimeHighResolution) {
 151       timeEndPeriod(1L);
 152     }
 153 #if INCLUDE_AOT
 154     if (topLevelVectoredExceptionHandler != NULL) {
 155       RemoveVectoredExceptionHandler(topLevelVectoredExceptionHandler);
 156       topLevelVectoredExceptionHandler = NULL;
 157     }
 158 #endif
 159     break;
 160   default:
 161     break;
 162   }
 163   return true;
 164 }
 165 
 166 static inline double fileTimeAsDouble(FILETIME* time) {
 167   const double high  = (double) ((unsigned int) ~0);
 168   const double split = 10000000.0;
 169   double result = (time-&gt;dwLowDateTime / split) +
 170                    time-&gt;dwHighDateTime * (high/split);
 171   return result;
 172 }
 173 
 174 // Implementation of os
 175 
 176 bool os::unsetenv(const char* name) {
 177   assert(name != NULL, &quot;Null pointer&quot;);
 178   return (SetEnvironmentVariable(name, NULL) == TRUE);
 179 }
 180 
 181 // No setuid programs under Windows.
 182 bool os::have_special_privileges() {
 183   return false;
 184 }
 185 
 186 
 187 // This method is  a periodic task to check for misbehaving JNI applications
 188 // under CheckJNI, we can add any periodic checks here.
 189 // For Windows at the moment does nothing
 190 void os::run_periodic_checks() {
 191   return;
 192 }
 193 
 194 // previous UnhandledExceptionFilter, if there is one
 195 static LPTOP_LEVEL_EXCEPTION_FILTER prev_uef_handler = NULL;
 196 
 197 LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo);
 198 
 199 void os::init_system_properties_values() {
 200   // sysclasspath, java_home, dll_dir
 201   {
 202     char *home_path;
 203     char *dll_path;
 204     char *pslash;
 205     const char *bin = &quot;\\bin&quot;;
 206     char home_dir[MAX_PATH + 1];
 207     char *alt_home_dir = ::getenv(&quot;_ALT_JAVA_HOME_DIR&quot;);
 208 
 209     if (alt_home_dir != NULL)  {
 210       strncpy(home_dir, alt_home_dir, MAX_PATH + 1);
 211       home_dir[MAX_PATH] = &#39;\0&#39;;
 212     } else {
 213       os::jvm_path(home_dir, sizeof(home_dir));
 214       // Found the full path to jvm.dll.
 215       // Now cut the path to &lt;java_home&gt;/jre if we can.
 216       *(strrchr(home_dir, &#39;\\&#39;)) = &#39;\0&#39;;  // get rid of \jvm.dll
 217       pslash = strrchr(home_dir, &#39;\\&#39;);
 218       if (pslash != NULL) {
 219         *pslash = &#39;\0&#39;;                   // get rid of \{client|server}
 220         pslash = strrchr(home_dir, &#39;\\&#39;);
 221         if (pslash != NULL) {
 222           *pslash = &#39;\0&#39;;                 // get rid of \bin
 223         }
 224       }
 225     }
 226 
 227     home_path = NEW_C_HEAP_ARRAY(char, strlen(home_dir) + 1, mtInternal);
 228     strcpy(home_path, home_dir);
 229     Arguments::set_java_home(home_path);
 230     FREE_C_HEAP_ARRAY(char, home_path);
 231 
 232     dll_path = NEW_C_HEAP_ARRAY(char, strlen(home_dir) + strlen(bin) + 1,
 233                                 mtInternal);
 234     strcpy(dll_path, home_dir);
 235     strcat(dll_path, bin);
 236     Arguments::set_dll_dir(dll_path);
 237     FREE_C_HEAP_ARRAY(char, dll_path);
 238 
 239     if (!set_boot_path(&#39;\\&#39;, &#39;;&#39;)) {
 240       vm_exit_during_initialization(&quot;Failed setting boot class path.&quot;, NULL);
 241     }
 242   }
 243 
 244 // library_path
 245 #define EXT_DIR &quot;\\lib\\ext&quot;
 246 #define BIN_DIR &quot;\\bin&quot;
 247 #define PACKAGE_DIR &quot;\\Sun\\Java&quot;
 248   {
 249     // Win32 library search order (See the documentation for LoadLibrary):
 250     //
 251     // 1. The directory from which application is loaded.
 252     // 2. The system wide Java Extensions directory (Java only)
 253     // 3. System directory (GetSystemDirectory)
 254     // 4. Windows directory (GetWindowsDirectory)
 255     // 5. The PATH environment variable
 256     // 6. The current directory
 257 
 258     char *library_path;
 259     char tmp[MAX_PATH];
 260     char *path_str = ::getenv(&quot;PATH&quot;);
 261 
 262     library_path = NEW_C_HEAP_ARRAY(char, MAX_PATH * 5 + sizeof(PACKAGE_DIR) +
 263                                     sizeof(BIN_DIR) + (path_str ? strlen(path_str) : 0) + 10, mtInternal);
 264 
 265     library_path[0] = &#39;\0&#39;;
 266 
 267     GetModuleFileName(NULL, tmp, sizeof(tmp));
 268     *(strrchr(tmp, &#39;\\&#39;)) = &#39;\0&#39;;
 269     strcat(library_path, tmp);
 270 
 271     GetWindowsDirectory(tmp, sizeof(tmp));
 272     strcat(library_path, &quot;;&quot;);
 273     strcat(library_path, tmp);
 274     strcat(library_path, PACKAGE_DIR BIN_DIR);
 275 
 276     GetSystemDirectory(tmp, sizeof(tmp));
 277     strcat(library_path, &quot;;&quot;);
 278     strcat(library_path, tmp);
 279 
 280     GetWindowsDirectory(tmp, sizeof(tmp));
 281     strcat(library_path, &quot;;&quot;);
 282     strcat(library_path, tmp);
 283 
 284     if (path_str) {
 285       strcat(library_path, &quot;;&quot;);
 286       strcat(library_path, path_str);
 287     }
 288 
 289     strcat(library_path, &quot;;.&quot;);
 290 
 291     Arguments::set_library_path(library_path);
 292     FREE_C_HEAP_ARRAY(char, library_path);
 293   }
 294 
 295   // Default extensions directory
 296   {
 297     char path[MAX_PATH];
 298     char buf[2 * MAX_PATH + 2 * sizeof(EXT_DIR) + sizeof(PACKAGE_DIR) + 1];
 299     GetWindowsDirectory(path, MAX_PATH);
 300     sprintf(buf, &quot;%s%s;%s%s%s&quot;, Arguments::get_java_home(), EXT_DIR,
 301             path, PACKAGE_DIR, EXT_DIR);
 302     Arguments::set_ext_dirs(buf);
 303   }
 304   #undef EXT_DIR
 305   #undef BIN_DIR
 306   #undef PACKAGE_DIR
 307 
 308 #ifndef _WIN64
 309   // set our UnhandledExceptionFilter and save any previous one
 310   prev_uef_handler = SetUnhandledExceptionFilter(Handle_FLT_Exception);
 311 #endif
 312 
 313   // Done
 314   return;
 315 }
 316 
 317 void os::breakpoint() {
 318   DebugBreak();
 319 }
 320 
 321 // Invoked from the BREAKPOINT Macro
 322 extern &quot;C&quot; void breakpoint() {
 323   os::breakpoint();
 324 }
 325 
 326 // RtlCaptureStackBackTrace Windows API may not exist prior to Windows XP.
 327 // So far, this method is only used by Native Memory Tracking, which is
 328 // only supported on Windows XP or later.
 329 //
 330 int os::get_native_stack(address* stack, int frames, int toSkip) {
 331   int captured = RtlCaptureStackBackTrace(toSkip + 1, frames, (PVOID*)stack, NULL);
 332   for (int index = captured; index &lt; frames; index ++) {
 333     stack[index] = NULL;
 334   }
 335   return captured;
 336 }
 337 
 338 
 339 // os::current_stack_base()
 340 //
 341 //   Returns the base of the stack, which is the stack&#39;s
 342 //   starting address.  This function must be called
 343 //   while running on the stack of the thread being queried.
 344 
 345 address os::current_stack_base() {
 346   MEMORY_BASIC_INFORMATION minfo;
 347   address stack_bottom;
 348   size_t stack_size;
 349 
 350   VirtualQuery(&amp;minfo, &amp;minfo, sizeof(minfo));
 351   stack_bottom =  (address)minfo.AllocationBase;
 352   stack_size = minfo.RegionSize;
 353 
 354   // Add up the sizes of all the regions with the same
 355   // AllocationBase.
 356   while (1) {
 357     VirtualQuery(stack_bottom+stack_size, &amp;minfo, sizeof(minfo));
 358     if (stack_bottom == (address)minfo.AllocationBase) {
 359       stack_size += minfo.RegionSize;
 360     } else {
 361       break;
 362     }
 363   }
 364   return stack_bottom + stack_size;
 365 }
 366 
 367 size_t os::current_stack_size() {
 368   size_t sz;
 369   MEMORY_BASIC_INFORMATION minfo;
 370   VirtualQuery(&amp;minfo, &amp;minfo, sizeof(minfo));
 371   sz = (size_t)os::current_stack_base() - (size_t)minfo.AllocationBase;
 372   return sz;
 373 }
 374 
 375 bool os::committed_in_range(address start, size_t size, address&amp; committed_start, size_t&amp; committed_size) {
 376   MEMORY_BASIC_INFORMATION minfo;
 377   committed_start = NULL;
 378   committed_size = 0;
 379   address top = start + size;
 380   const address start_addr = start;
 381   while (start &lt; top) {
 382     VirtualQuery(start, &amp;minfo, sizeof(minfo));
 383     if ((minfo.State &amp; MEM_COMMIT) == 0) {  // not committed
 384       if (committed_start != NULL) {
 385         break;
 386       }
 387     } else {  // committed
 388       if (committed_start == NULL) {
 389         committed_start = start;
 390       }
 391       size_t offset = start - (address)minfo.BaseAddress;
 392       committed_size += minfo.RegionSize - offset;
 393     }
 394     start = (address)minfo.BaseAddress + minfo.RegionSize;
 395   }
 396 
 397   if (committed_start == NULL) {
 398     assert(committed_size == 0, &quot;Sanity&quot;);
 399     return false;
 400   } else {
 401     assert(committed_start &gt;= start_addr &amp;&amp; committed_start &lt; top, &quot;Out of range&quot;);
 402     // current region may go beyond the limit, trim to the limit
 403     committed_size = MIN2(committed_size, size_t(top - committed_start));
 404     return true;
 405   }
 406 }
 407 
 408 struct tm* os::localtime_pd(const time_t* clock, struct tm* res) {
 409   const struct tm* time_struct_ptr = localtime(clock);
 410   if (time_struct_ptr != NULL) {
 411     *res = *time_struct_ptr;
 412     return res;
 413   }
 414   return NULL;
 415 }
 416 
 417 struct tm* os::gmtime_pd(const time_t* clock, struct tm* res) {
 418   const struct tm* time_struct_ptr = gmtime(clock);
 419   if (time_struct_ptr != NULL) {
 420     *res = *time_struct_ptr;
 421     return res;
 422   }
 423   return NULL;
 424 }
 425 
 426 LONG WINAPI topLevelExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo);
 427 
 428 // Thread start routine for all newly created threads
 429 static unsigned __stdcall thread_native_entry(Thread* thread) {
 430 
 431   thread-&gt;record_stack_base_and_size();
 432 
 433   // Try to randomize the cache line index of hot stack frames.
 434   // This helps when threads of the same stack traces evict each other&#39;s
 435   // cache lines. The threads can be either from the same JVM instance, or
 436   // from different JVM instances. The benefit is especially true for
 437   // processors with hyperthreading technology.
 438   static int counter = 0;
 439   int pid = os::current_process_id();
 440   _alloca(((pid ^ counter++) &amp; 7) * 128);
 441 
 442   thread-&gt;initialize_thread_current();
 443 
 444   OSThread* osthr = thread-&gt;osthread();
 445   assert(osthr-&gt;get_state() == RUNNABLE, &quot;invalid os thread state&quot;);
 446 
 447   if (UseNUMA) {
 448     int lgrp_id = os::numa_get_group_id();
 449     if (lgrp_id != -1) {
 450       thread-&gt;set_lgrp_id(lgrp_id);
 451     }
 452   }
 453 
 454   // Diagnostic code to investigate JDK-6573254
 455   int res = 30115;  // non-java thread
 456   if (thread-&gt;is_Java_thread()) {
 457     res = 20115;    // java thread
 458   }
 459 
 460   log_info(os, thread)(&quot;Thread is alive (tid: &quot; UINTX_FORMAT &quot;).&quot;, os::current_thread_id());
 461 
 462   // Install a win32 structured exception handler around every thread created
 463   // by VM, so VM can generate error dump when an exception occurred in non-
 464   // Java thread (e.g. VM thread).
 465   __try {
 466     thread-&gt;call_run();
 467   } __except(topLevelExceptionFilter(
 468                                      (_EXCEPTION_POINTERS*)_exception_info())) {
 469     // Nothing to do.
 470   }
 471 
 472   // Note: at this point the thread object may already have deleted itself.
 473   // Do not dereference it from here on out.
 474 
 475   log_info(os, thread)(&quot;Thread finished (tid: &quot; UINTX_FORMAT &quot;).&quot;, os::current_thread_id());
 476 
 477   // One less thread is executing
 478   // When the VMThread gets here, the main thread may have already exited
 479   // which frees the CodeHeap containing the Atomic::add code
 480   if (thread != VMThread::vm_thread() &amp;&amp; VMThread::vm_thread() != NULL) {
 481     Atomic::dec(&amp;os::win32::_os_thread_count);
 482   }
 483 
 484   // Thread must not return from exit_process_or_thread(), but if it does,
 485   // let it proceed to exit normally
 486   return (unsigned)os::win32::exit_process_or_thread(os::win32::EPT_THREAD, res);
 487 }
 488 
 489 static OSThread* create_os_thread(Thread* thread, HANDLE thread_handle,
 490                                   int thread_id) {
 491   // Allocate the OSThread object
 492   OSThread* osthread = new OSThread(NULL, NULL);
 493   if (osthread == NULL) return NULL;
 494 
 495   // Initialize the JDK library&#39;s interrupt event.
 496   // This should really be done when OSThread is constructed,
 497   // but there is no way for a constructor to report failure to
 498   // allocate the event.
 499   HANDLE interrupt_event = CreateEvent(NULL, true, false, NULL);
 500   if (interrupt_event == NULL) {
 501     delete osthread;
 502     return NULL;
 503   }
 504   osthread-&gt;set_interrupt_event(interrupt_event);
 505 
 506   // Store info on the Win32 thread into the OSThread
 507   osthread-&gt;set_thread_handle(thread_handle);
 508   osthread-&gt;set_thread_id(thread_id);
 509 
 510   if (UseNUMA) {
 511     int lgrp_id = os::numa_get_group_id();
 512     if (lgrp_id != -1) {
 513       thread-&gt;set_lgrp_id(lgrp_id);
 514     }
 515   }
 516 
 517   // Initial thread state is INITIALIZED, not SUSPENDED
 518   osthread-&gt;set_state(INITIALIZED);
 519 
 520   return osthread;
 521 }
 522 
 523 
 524 bool os::create_attached_thread(JavaThread* thread) {
 525 #ifdef ASSERT
 526   thread-&gt;verify_not_published();
 527 #endif
 528   HANDLE thread_h;
 529   if (!DuplicateHandle(main_process, GetCurrentThread(), GetCurrentProcess(),
 530                        &amp;thread_h, THREAD_ALL_ACCESS, false, 0)) {
 531     fatal(&quot;DuplicateHandle failed\n&quot;);
 532   }
 533   OSThread* osthread = create_os_thread(thread, thread_h,
 534                                         (int)current_thread_id());
 535   if (osthread == NULL) {
 536     return false;
 537   }
 538 
 539   // Initial thread state is RUNNABLE
 540   osthread-&gt;set_state(RUNNABLE);
 541 
 542   thread-&gt;set_osthread(osthread);
 543 
 544   log_info(os, thread)(&quot;Thread attached (tid: &quot; UINTX_FORMAT &quot;).&quot;,
 545     os::current_thread_id());
 546 
 547   return true;
 548 }
 549 
 550 bool os::create_main_thread(JavaThread* thread) {
 551 #ifdef ASSERT
 552   thread-&gt;verify_not_published();
 553 #endif
 554   if (_starting_thread == NULL) {
 555     _starting_thread = create_os_thread(thread, main_thread, main_thread_id);
 556     if (_starting_thread == NULL) {
 557       return false;
 558     }
 559   }
 560 
 561   // The primordial thread is runnable from the start)
 562   _starting_thread-&gt;set_state(RUNNABLE);
 563 
 564   thread-&gt;set_osthread(_starting_thread);
 565   return true;
 566 }
 567 
 568 // Helper function to trace _beginthreadex attributes,
 569 //  similar to os::Posix::describe_pthread_attr()
 570 static char* describe_beginthreadex_attributes(char* buf, size_t buflen,
 571                                                size_t stacksize, unsigned initflag) {
 572   stringStream ss(buf, buflen);
 573   if (stacksize == 0) {
 574     ss.print(&quot;stacksize: default, &quot;);
 575   } else {
 576     ss.print(&quot;stacksize: &quot; SIZE_FORMAT &quot;k, &quot;, stacksize / 1024);
 577   }
 578   ss.print(&quot;flags: &quot;);
 579   #define PRINT_FLAG(f) if (initflag &amp; f) ss.print( #f &quot; &quot;);
 580   #define ALL(X) \
 581     X(CREATE_SUSPENDED) \
 582     X(STACK_SIZE_PARAM_IS_A_RESERVATION)
 583   ALL(PRINT_FLAG)
 584   #undef ALL
 585   #undef PRINT_FLAG
 586   return buf;
 587 }
 588 
 589 // Allocate and initialize a new OSThread
 590 bool os::create_thread(Thread* thread, ThreadType thr_type,
 591                        size_t stack_size) {
 592   unsigned thread_id;
 593 
 594   // Allocate the OSThread object
 595   OSThread* osthread = new OSThread(NULL, NULL);
 596   if (osthread == NULL) {
 597     return false;
 598   }
 599 
 600   // Initialize the JDK library&#39;s interrupt event.
 601   // This should really be done when OSThread is constructed,
 602   // but there is no way for a constructor to report failure to
 603   // allocate the event.
 604   HANDLE interrupt_event = CreateEvent(NULL, true, false, NULL);
 605   if (interrupt_event == NULL) {
 606     delete osthread;
 607     return false;
 608   }
 609   osthread-&gt;set_interrupt_event(interrupt_event);
 610   // We don&#39;t call set_interrupted(false) as it will trip the assert in there
 611   // as we are not operating on the current thread. We don&#39;t need to call it
 612   // because the initial state is already correct.
 613 
 614   thread-&gt;set_osthread(osthread);
 615 
 616   if (stack_size == 0) {
 617     switch (thr_type) {
 618     case os::java_thread:
 619       // Java threads use ThreadStackSize which default value can be changed with the flag -Xss
 620       if (JavaThread::stack_size_at_create() &gt; 0) {
 621         stack_size = JavaThread::stack_size_at_create();
 622       }
 623       break;
 624     case os::compiler_thread:
 625       if (CompilerThreadStackSize &gt; 0) {
 626         stack_size = (size_t)(CompilerThreadStackSize * K);
 627         break;
 628       } // else fall through:
 629         // use VMThreadStackSize if CompilerThreadStackSize is not defined
 630     case os::vm_thread:
 631     case os::pgc_thread:
 632     case os::cgc_thread:
 633     case os::watcher_thread:
 634       if (VMThreadStackSize &gt; 0) stack_size = (size_t)(VMThreadStackSize * K);
 635       break;
 636     }
 637   }
 638 
 639   // Create the Win32 thread
 640   //
 641   // Contrary to what MSDN document says, &quot;stack_size&quot; in _beginthreadex()
 642   // does not specify stack size. Instead, it specifies the size of
 643   // initially committed space. The stack size is determined by
 644   // PE header in the executable. If the committed &quot;stack_size&quot; is larger
 645   // than default value in the PE header, the stack is rounded up to the
 646   // nearest multiple of 1MB. For example if the launcher has default
 647   // stack size of 320k, specifying any size less than 320k does not
 648   // affect the actual stack size at all, it only affects the initial
 649   // commitment. On the other hand, specifying &#39;stack_size&#39; larger than
 650   // default value may cause significant increase in memory usage, because
 651   // not only the stack space will be rounded up to MB, but also the
 652   // entire space is committed upfront.
 653   //
 654   // Finally Windows XP added a new flag &#39;STACK_SIZE_PARAM_IS_A_RESERVATION&#39;
 655   // for CreateThread() that can treat &#39;stack_size&#39; as stack size. However we
 656   // are not supposed to call CreateThread() directly according to MSDN
 657   // document because JVM uses C runtime library. The good news is that the
 658   // flag appears to work with _beginthredex() as well.
 659 
 660   const unsigned initflag = CREATE_SUSPENDED | STACK_SIZE_PARAM_IS_A_RESERVATION;
 661   HANDLE thread_handle =
 662     (HANDLE)_beginthreadex(NULL,
 663                            (unsigned)stack_size,
 664                            (unsigned (__stdcall *)(void*)) thread_native_entry,
 665                            thread,
 666                            initflag,
 667                            &amp;thread_id);
 668 
 669   char buf[64];
 670   if (thread_handle != NULL) {
 671     log_info(os, thread)(&quot;Thread started (tid: %u, attributes: %s)&quot;,
 672       thread_id, describe_beginthreadex_attributes(buf, sizeof(buf), stack_size, initflag));
 673   } else {
 674     log_warning(os, thread)(&quot;Failed to start thread - _beginthreadex failed (%s) for attributes: %s.&quot;,
 675       os::errno_name(errno), describe_beginthreadex_attributes(buf, sizeof(buf), stack_size, initflag));
 676     // Log some OS information which might explain why creating the thread failed.
 677     log_info(os, thread)(&quot;Number of threads approx. running in the VM: %d&quot;, Threads::number_of_threads());
 678     LogStream st(Log(os, thread)::info());
 679     os::print_memory_info(&amp;st);
 680   }
 681 
 682   if (thread_handle == NULL) {
 683     // Need to clean up stuff we&#39;ve allocated so far
 684     thread-&gt;set_osthread(NULL);
 685     delete osthread;
 686     return false;
 687   }
 688 
 689   Atomic::inc(&amp;os::win32::_os_thread_count);
 690 
 691   // Store info on the Win32 thread into the OSThread
 692   osthread-&gt;set_thread_handle(thread_handle);
 693   osthread-&gt;set_thread_id(thread_id);
 694 
 695   // Initial thread state is INITIALIZED, not SUSPENDED
 696   osthread-&gt;set_state(INITIALIZED);
 697 
 698   // The thread is returned suspended (in state INITIALIZED), and is started higher up in the call chain
 699   return true;
 700 }
 701 
 702 
 703 // Free Win32 resources related to the OSThread
 704 void os::free_thread(OSThread* osthread) {
 705   assert(osthread != NULL, &quot;osthread not set&quot;);
 706 
 707   // We are told to free resources of the argument thread,
 708   // but we can only really operate on the current thread.
 709   assert(Thread::current()-&gt;osthread() == osthread,
 710          &quot;os::free_thread but not current thread&quot;);
 711 
 712   CloseHandle(osthread-&gt;thread_handle());
 713   delete osthread;
 714 }
 715 
 716 static jlong first_filetime;
 717 static jlong initial_performance_count;
 718 static jlong performance_frequency;
 719 
 720 
 721 jlong as_long(LARGE_INTEGER x) {
 722   jlong result = 0; // initialization to avoid warning
 723   set_high(&amp;result, x.HighPart);
 724   set_low(&amp;result, x.LowPart);
 725   return result;
 726 }
 727 
 728 
 729 jlong os::elapsed_counter() {
 730   LARGE_INTEGER count;
 731   QueryPerformanceCounter(&amp;count);
 732   return as_long(count) - initial_performance_count;
 733 }
 734 
 735 
 736 jlong os::elapsed_frequency() {
 737   return performance_frequency;
 738 }
 739 
 740 
 741 julong os::available_memory() {
 742   return win32::available_memory();
 743 }
 744 
 745 julong os::win32::available_memory() {
 746   // Use GlobalMemoryStatusEx() because GlobalMemoryStatus() may return incorrect
 747   // value if total memory is larger than 4GB
 748   MEMORYSTATUSEX ms;
 749   ms.dwLength = sizeof(ms);
 750   GlobalMemoryStatusEx(&amp;ms);
 751 
 752   return (julong)ms.ullAvailPhys;
 753 }
 754 
 755 julong os::physical_memory() {
 756   return win32::physical_memory();
 757 }
 758 
 759 bool os::has_allocatable_memory_limit(julong* limit) {
 760   MEMORYSTATUSEX ms;
 761   ms.dwLength = sizeof(ms);
 762   GlobalMemoryStatusEx(&amp;ms);
 763 #ifdef _LP64
 764   *limit = (julong)ms.ullAvailVirtual;
 765   return true;
 766 #else
 767   // Limit to 1400m because of the 2gb address space wall
 768   *limit = MIN2((julong)1400*M, (julong)ms.ullAvailVirtual);
 769   return true;
 770 #endif
 771 }
 772 
 773 int os::active_processor_count() {
 774   // User has overridden the number of active processors
 775   if (ActiveProcessorCount &gt; 0) {
 776     log_trace(os)(&quot;active_processor_count: &quot;
 777                   &quot;active processor count set by user : %d&quot;,
 778                   ActiveProcessorCount);
 779     return ActiveProcessorCount;
 780   }
 781 
 782   DWORD_PTR lpProcessAffinityMask = 0;
 783   DWORD_PTR lpSystemAffinityMask = 0;
 784   int proc_count = processor_count();
 785   if (proc_count &lt;= sizeof(UINT_PTR) * BitsPerByte &amp;&amp;
 786       GetProcessAffinityMask(GetCurrentProcess(), &amp;lpProcessAffinityMask, &amp;lpSystemAffinityMask)) {
 787     // Nof active processors is number of bits in process affinity mask
 788     int bitcount = 0;
 789     while (lpProcessAffinityMask != 0) {
 790       lpProcessAffinityMask = lpProcessAffinityMask &amp; (lpProcessAffinityMask-1);
 791       bitcount++;
 792     }
 793     return bitcount;
 794   } else {
 795     return proc_count;
 796   }
 797 }
 798 
 799 uint os::processor_id() {
 800   return (uint)GetCurrentProcessorNumber();
 801 }
 802 
 803 void os::set_native_thread_name(const char *name) {
 804 
 805   // See: http://msdn.microsoft.com/en-us/library/xcb2z8hs.aspx
 806   //
 807   // Note that unfortunately this only works if the process
 808   // is already attached to a debugger; debugger must observe
 809   // the exception below to show the correct name.
 810 
 811   // If there is no debugger attached skip raising the exception
 812   if (!IsDebuggerPresent()) {
 813     return;
 814   }
 815 
 816   const DWORD MS_VC_EXCEPTION = 0x406D1388;
 817   struct {
 818     DWORD dwType;     // must be 0x1000
 819     LPCSTR szName;    // pointer to name (in user addr space)
 820     DWORD dwThreadID; // thread ID (-1=caller thread)
 821     DWORD dwFlags;    // reserved for future use, must be zero
 822   } info;
 823 
 824   info.dwType = 0x1000;
 825   info.szName = name;
 826   info.dwThreadID = -1;
 827   info.dwFlags = 0;
 828 
 829   __try {
 830     RaiseException (MS_VC_EXCEPTION, 0, sizeof(info)/sizeof(DWORD), (const ULONG_PTR*)&amp;info );
 831   } __except(EXCEPTION_EXECUTE_HANDLER) {}
 832 }
 833 
 834 bool os::bind_to_processor(uint processor_id) {
 835   // Not yet implemented.
 836   return false;
 837 }
 838 
 839 void os::win32::initialize_performance_counter() {
 840   LARGE_INTEGER count;
 841   QueryPerformanceFrequency(&amp;count);
 842   performance_frequency = as_long(count);
 843   QueryPerformanceCounter(&amp;count);
 844   initial_performance_count = as_long(count);
 845 }
 846 
 847 
 848 double os::elapsedTime() {
 849   return (double) elapsed_counter() / (double) elapsed_frequency();
 850 }
 851 
 852 
 853 // Windows format:
 854 //   The FILETIME structure is a 64-bit value representing the number of 100-nanosecond intervals since January 1, 1601.
 855 // Java format:
 856 //   Java standards require the number of milliseconds since 1/1/1970
 857 
 858 // Constant offset - calculated using offset()
 859 static jlong  _offset   = 116444736000000000;
 860 // Fake time counter for reproducible results when debugging
 861 static jlong  fake_time = 0;
 862 
 863 #ifdef ASSERT
 864 // Just to be safe, recalculate the offset in debug mode
 865 static jlong _calculated_offset = 0;
 866 static int   _has_calculated_offset = 0;
 867 
 868 jlong offset() {
 869   if (_has_calculated_offset) return _calculated_offset;
 870   SYSTEMTIME java_origin;
 871   java_origin.wYear          = 1970;
 872   java_origin.wMonth         = 1;
 873   java_origin.wDayOfWeek     = 0; // ignored
 874   java_origin.wDay           = 1;
 875   java_origin.wHour          = 0;
 876   java_origin.wMinute        = 0;
 877   java_origin.wSecond        = 0;
 878   java_origin.wMilliseconds  = 0;
 879   FILETIME jot;
 880   if (!SystemTimeToFileTime(&amp;java_origin, &amp;jot)) {
 881     fatal(&quot;Error = %d\nWindows error&quot;, GetLastError());
 882   }
 883   _calculated_offset = jlong_from(jot.dwHighDateTime, jot.dwLowDateTime);
 884   _has_calculated_offset = 1;
 885   assert(_calculated_offset == _offset, &quot;Calculated and constant time offsets must be equal&quot;);
 886   return _calculated_offset;
 887 }
 888 #else
 889 jlong offset() {
 890   return _offset;
 891 }
 892 #endif
 893 
 894 jlong windows_to_java_time(FILETIME wt) {
 895   jlong a = jlong_from(wt.dwHighDateTime, wt.dwLowDateTime);
 896   return (a - offset()) / 10000;
 897 }
 898 
 899 // Returns time ticks in (10th of micro seconds)
 900 jlong windows_to_time_ticks(FILETIME wt) {
 901   jlong a = jlong_from(wt.dwHighDateTime, wt.dwLowDateTime);
 902   return (a - offset());
 903 }
 904 
 905 FILETIME java_to_windows_time(jlong l) {
 906   jlong a = (l * 10000) + offset();
 907   FILETIME result;
 908   result.dwHighDateTime = high(a);
 909   result.dwLowDateTime  = low(a);
 910   return result;
 911 }
 912 
 913 bool os::supports_vtime() { return true; }
 914 
 915 double os::elapsedVTime() {
 916   FILETIME created;
 917   FILETIME exited;
 918   FILETIME kernel;
 919   FILETIME user;
 920   if (GetThreadTimes(GetCurrentThread(), &amp;created, &amp;exited, &amp;kernel, &amp;user) != 0) {
 921     // the resolution of windows_to_java_time() should be sufficient (ms)
 922     return (double) (windows_to_java_time(kernel) + windows_to_java_time(user)) / MILLIUNITS;
 923   } else {
 924     return elapsedTime();
 925   }
 926 }
 927 
 928 jlong os::javaTimeMillis() {
 929   FILETIME wt;
 930   GetSystemTimeAsFileTime(&amp;wt);
 931   return windows_to_java_time(wt);
 932 }
 933 
 934 void os::javaTimeSystemUTC(jlong &amp;seconds, jlong &amp;nanos) {
 935   FILETIME wt;
 936   GetSystemTimeAsFileTime(&amp;wt);
 937   jlong ticks = windows_to_time_ticks(wt); // 10th of micros
 938   jlong secs = jlong(ticks / 10000000); // 10000 * 1000
 939   seconds = secs;
 940   nanos = jlong(ticks - (secs*10000000)) * 100;
 941 }
 942 
 943 jlong os::javaTimeNanos() {
 944     LARGE_INTEGER current_count;
 945     QueryPerformanceCounter(&amp;current_count);
 946     double current = as_long(current_count);
 947     double freq = performance_frequency;
 948     jlong time = (jlong)((current/freq) * NANOSECS_PER_SEC);
 949     return time;
 950 }
 951 
 952 void os::javaTimeNanos_info(jvmtiTimerInfo *info_ptr) {
 953   jlong freq = performance_frequency;
 954   if (freq &lt; NANOSECS_PER_SEC) {
 955     // the performance counter is 64 bits and we will
 956     // be multiplying it -- so no wrap in 64 bits
 957     info_ptr-&gt;max_value = ALL_64_BITS;
 958   } else if (freq &gt; NANOSECS_PER_SEC) {
 959     // use the max value the counter can reach to
 960     // determine the max value which could be returned
 961     julong max_counter = (julong)ALL_64_BITS;
 962     info_ptr-&gt;max_value = (jlong)(max_counter / (freq / NANOSECS_PER_SEC));
 963   } else {
 964     // the performance counter is 64 bits and we will
 965     // be using it directly -- so no wrap in 64 bits
 966     info_ptr-&gt;max_value = ALL_64_BITS;
 967   }
 968 
 969   // using a counter, so no skipping
 970   info_ptr-&gt;may_skip_backward = false;
 971   info_ptr-&gt;may_skip_forward = false;
 972 
 973   info_ptr-&gt;kind = JVMTI_TIMER_ELAPSED;                // elapsed not CPU time
 974 }
 975 
 976 char* os::local_time_string(char *buf, size_t buflen) {
 977   SYSTEMTIME st;
 978   GetLocalTime(&amp;st);
 979   jio_snprintf(buf, buflen, &quot;%d-%02d-%02d %02d:%02d:%02d&quot;,
 980                st.wYear, st.wMonth, st.wDay, st.wHour, st.wMinute, st.wSecond);
 981   return buf;
 982 }
 983 
 984 bool os::getTimesSecs(double* process_real_time,
 985                       double* process_user_time,
 986                       double* process_system_time) {
 987   HANDLE h_process = GetCurrentProcess();
 988   FILETIME create_time, exit_time, kernel_time, user_time;
 989   BOOL result = GetProcessTimes(h_process,
 990                                 &amp;create_time,
 991                                 &amp;exit_time,
 992                                 &amp;kernel_time,
 993                                 &amp;user_time);
 994   if (result != 0) {
 995     FILETIME wt;
 996     GetSystemTimeAsFileTime(&amp;wt);
 997     jlong rtc_millis = windows_to_java_time(wt);
 998     *process_real_time = ((double) rtc_millis) / ((double) MILLIUNITS);
 999     *process_user_time =
1000       (double) jlong_from(user_time.dwHighDateTime, user_time.dwLowDateTime) / (10 * MICROUNITS);
1001     *process_system_time =
1002       (double) jlong_from(kernel_time.dwHighDateTime, kernel_time.dwLowDateTime) / (10 * MICROUNITS);
1003     return true;
1004   } else {
1005     return false;
1006   }
1007 }
1008 
1009 void os::shutdown() {
1010   // allow PerfMemory to attempt cleanup of any persistent resources
1011   perfMemory_exit();
1012 
1013   // flush buffered output, finish log files
1014   ostream_abort();
1015 
1016   // Check for abort hook
1017   abort_hook_t abort_hook = Arguments::abort_hook();
1018   if (abort_hook != NULL) {
1019     abort_hook();
1020   }
1021 }
1022 
1023 
1024 static HANDLE dumpFile = NULL;
1025 
1026 // Check if dump file can be created.
1027 void os::check_dump_limit(char* buffer, size_t buffsz) {
1028   bool status = true;
1029   if (!FLAG_IS_DEFAULT(CreateCoredumpOnCrash) &amp;&amp; !CreateCoredumpOnCrash) {
1030     jio_snprintf(buffer, buffsz, &quot;CreateCoredumpOnCrash is disabled from command line&quot;);
1031     status = false;
1032   }
1033 
1034 #ifndef ASSERT
1035   if (!os::win32::is_windows_server() &amp;&amp; FLAG_IS_DEFAULT(CreateCoredumpOnCrash)) {
1036     jio_snprintf(buffer, buffsz, &quot;Minidumps are not enabled by default on client versions of Windows&quot;);
1037     status = false;
1038   }
1039 #endif
1040 
1041   if (status) {
1042     const char* cwd = get_current_directory(NULL, 0);
1043     int pid = current_process_id();
1044     if (cwd != NULL) {
1045       jio_snprintf(buffer, buffsz, &quot;%s\\hs_err_pid%u.mdmp&quot;, cwd, pid);
1046     } else {
1047       jio_snprintf(buffer, buffsz, &quot;.\\hs_err_pid%u.mdmp&quot;, pid);
1048     }
1049 
1050     if (dumpFile == NULL &amp;&amp;
1051        (dumpFile = CreateFile(buffer, GENERIC_WRITE, 0, NULL, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL))
1052                  == INVALID_HANDLE_VALUE) {
1053       jio_snprintf(buffer, buffsz, &quot;Failed to create minidump file (0x%x).&quot;, GetLastError());
1054       status = false;
1055     }
1056   }
1057   VMError::record_coredump_status(buffer, status);
1058 }
1059 
1060 void os::abort(bool dump_core, void* siginfo, const void* context) {
1061   EXCEPTION_POINTERS ep;
1062   MINIDUMP_EXCEPTION_INFORMATION mei;
1063   MINIDUMP_EXCEPTION_INFORMATION* pmei;
1064 
1065   HANDLE hProcess = GetCurrentProcess();
1066   DWORD processId = GetCurrentProcessId();
1067   MINIDUMP_TYPE dumpType;
1068 
1069   shutdown();
1070   if (!dump_core || dumpFile == NULL) {
1071     if (dumpFile != NULL) {
1072       CloseHandle(dumpFile);
1073     }
1074     win32::exit_process_or_thread(win32::EPT_PROCESS, 1);
1075   }
1076 
1077   dumpType = (MINIDUMP_TYPE)(MiniDumpWithFullMemory | MiniDumpWithHandleData |
1078     MiniDumpWithFullMemoryInfo | MiniDumpWithThreadInfo | MiniDumpWithUnloadedModules);
1079 
1080   if (siginfo != NULL &amp;&amp; context != NULL) {
1081     ep.ContextRecord = (PCONTEXT) context;
1082     ep.ExceptionRecord = (PEXCEPTION_RECORD) siginfo;
1083 
1084     mei.ThreadId = GetCurrentThreadId();
1085     mei.ExceptionPointers = &amp;ep;
1086     pmei = &amp;mei;
1087   } else {
1088     pmei = NULL;
1089   }
1090 
1091   // Older versions of dbghelp.dll (the one shipped with Win2003 for example) may not support all
1092   // the dump types we really want. If first call fails, lets fall back to just use MiniDumpWithFullMemory then.
1093   if (!WindowsDbgHelp::miniDumpWriteDump(hProcess, processId, dumpFile, dumpType, pmei, NULL, NULL) &amp;&amp;
1094       !WindowsDbgHelp::miniDumpWriteDump(hProcess, processId, dumpFile, (MINIDUMP_TYPE)MiniDumpWithFullMemory, pmei, NULL, NULL)) {
1095     jio_fprintf(stderr, &quot;Call to MiniDumpWriteDump() failed (Error 0x%x)\n&quot;, GetLastError());
1096   }
1097   CloseHandle(dumpFile);
1098   win32::exit_process_or_thread(win32::EPT_PROCESS, 1);
1099 }
1100 
1101 // Die immediately, no exit hook, no abort hook, no cleanup.
1102 void os::die() {
1103   win32::exit_process_or_thread(win32::EPT_PROCESS_DIE, -1);
1104 }
1105 
1106 // Directory routines copied from src/win32/native/java/io/dirent_md.c
1107 //  * dirent_md.c       1.15 00/02/02
1108 //
1109 // The declarations for DIR and struct dirent are in jvm_win32.h.
1110 
1111 // Caller must have already run dirname through JVM_NativePath, which removes
1112 // duplicate slashes and converts all instances of &#39;/&#39; into &#39;\\&#39;.
1113 
1114 DIR * os::opendir(const char *dirname) {
1115   assert(dirname != NULL, &quot;just checking&quot;);   // hotspot change
1116   DIR *dirp = (DIR *)malloc(sizeof(DIR), mtInternal);
1117   DWORD fattr;                                // hotspot change
1118   char alt_dirname[4] = { 0, 0, 0, 0 };
1119 
1120   if (dirp == 0) {
1121     errno = ENOMEM;
1122     return 0;
1123   }
1124 
1125   // Win32 accepts &quot;\&quot; in its POSIX stat(), but refuses to treat it
1126   // as a directory in FindFirstFile().  We detect this case here and
1127   // prepend the current drive name.
1128   //
1129   if (dirname[1] == &#39;\0&#39; &amp;&amp; dirname[0] == &#39;\\&#39;) {
1130     alt_dirname[0] = _getdrive() + &#39;A&#39; - 1;
1131     alt_dirname[1] = &#39;:&#39;;
1132     alt_dirname[2] = &#39;\\&#39;;
1133     alt_dirname[3] = &#39;\0&#39;;
1134     dirname = alt_dirname;
1135   }
1136 
1137   dirp-&gt;path = (char *)malloc(strlen(dirname) + 5, mtInternal);
1138   if (dirp-&gt;path == 0) {
1139     free(dirp);
1140     errno = ENOMEM;
1141     return 0;
1142   }
1143   strcpy(dirp-&gt;path, dirname);
1144 
1145   fattr = GetFileAttributes(dirp-&gt;path);
1146   if (fattr == 0xffffffff) {
1147     free(dirp-&gt;path);
1148     free(dirp);
1149     errno = ENOENT;
1150     return 0;
1151   } else if ((fattr &amp; FILE_ATTRIBUTE_DIRECTORY) == 0) {
1152     free(dirp-&gt;path);
1153     free(dirp);
1154     errno = ENOTDIR;
1155     return 0;
1156   }
1157 
1158   // Append &quot;*.*&quot;, or possibly &quot;\\*.*&quot;, to path
1159   if (dirp-&gt;path[1] == &#39;:&#39; &amp;&amp;
1160       (dirp-&gt;path[2] == &#39;\0&#39; ||
1161       (dirp-&gt;path[2] == &#39;\\&#39; &amp;&amp; dirp-&gt;path[3] == &#39;\0&#39;))) {
1162     // No &#39;\\&#39; needed for cases like &quot;Z:&quot; or &quot;Z:\&quot;
1163     strcat(dirp-&gt;path, &quot;*.*&quot;);
1164   } else {
1165     strcat(dirp-&gt;path, &quot;\\*.*&quot;);
1166   }
1167 
1168   dirp-&gt;handle = FindFirstFile(dirp-&gt;path, &amp;dirp-&gt;find_data);
1169   if (dirp-&gt;handle == INVALID_HANDLE_VALUE) {
1170     if (GetLastError() != ERROR_FILE_NOT_FOUND) {
1171       free(dirp-&gt;path);
1172       free(dirp);
1173       errno = EACCES;
1174       return 0;
1175     }
1176   }
1177   return dirp;
1178 }
1179 
1180 struct dirent * os::readdir(DIR *dirp) {
1181   assert(dirp != NULL, &quot;just checking&quot;);      // hotspot change
1182   if (dirp-&gt;handle == INVALID_HANDLE_VALUE) {
1183     return NULL;
1184   }
1185 
1186   strcpy(dirp-&gt;dirent.d_name, dirp-&gt;find_data.cFileName);
1187 
1188   if (!FindNextFile(dirp-&gt;handle, &amp;dirp-&gt;find_data)) {
1189     if (GetLastError() == ERROR_INVALID_HANDLE) {
1190       errno = EBADF;
1191       return NULL;
1192     }
1193     FindClose(dirp-&gt;handle);
1194     dirp-&gt;handle = INVALID_HANDLE_VALUE;
1195   }
1196 
1197   return &amp;dirp-&gt;dirent;
1198 }
1199 
1200 int os::closedir(DIR *dirp) {
1201   assert(dirp != NULL, &quot;just checking&quot;);      // hotspot change
1202   if (dirp-&gt;handle != INVALID_HANDLE_VALUE) {
1203     if (!FindClose(dirp-&gt;handle)) {
1204       errno = EBADF;
1205       return -1;
1206     }
1207     dirp-&gt;handle = INVALID_HANDLE_VALUE;
1208   }
1209   free(dirp-&gt;path);
1210   free(dirp);
1211   return 0;
1212 }
1213 
1214 // This must be hard coded because it&#39;s the system&#39;s temporary
1215 // directory not the java application&#39;s temp directory, ala java.io.tmpdir.
1216 const char* os::get_temp_directory() {
1217   static char path_buf[MAX_PATH];
1218   if (GetTempPath(MAX_PATH, path_buf) &gt; 0) {
1219     return path_buf;
1220   } else {
1221     path_buf[0] = &#39;\0&#39;;
1222     return path_buf;
1223   }
1224 }
1225 
1226 // Needs to be in os specific directory because windows requires another
1227 // header file &lt;direct.h&gt;
1228 const char* os::get_current_directory(char *buf, size_t buflen) {
1229   int n = static_cast&lt;int&gt;(buflen);
1230   if (buflen &gt; INT_MAX)  n = INT_MAX;
1231   return _getcwd(buf, n);
1232 }
1233 
1234 //-----------------------------------------------------------
1235 // Helper functions for fatal error handler
1236 #ifdef _WIN64
1237 // Helper routine which returns true if address in
1238 // within the NTDLL address space.
1239 //
1240 static bool _addr_in_ntdll(address addr) {
1241   HMODULE hmod;
1242   MODULEINFO minfo;
1243 
1244   hmod = GetModuleHandle(&quot;NTDLL.DLL&quot;);
1245   if (hmod == NULL) return false;
1246   if (!GetModuleInformation(GetCurrentProcess(), hmod,
1247                                           &amp;minfo, sizeof(MODULEINFO))) {
1248     return false;
1249   }
1250 
1251   if ((addr &gt;= minfo.lpBaseOfDll) &amp;&amp;
1252       (addr &lt; (address)((uintptr_t)minfo.lpBaseOfDll + (uintptr_t)minfo.SizeOfImage))) {
1253     return true;
1254   } else {
1255     return false;
1256   }
1257 }
1258 #endif
1259 
1260 struct _modinfo {
1261   address addr;
1262   char*   full_path;   // point to a char buffer
1263   int     buflen;      // size of the buffer
1264   address base_addr;
1265 };
1266 
1267 static int _locate_module_by_addr(const char * mod_fname, address base_addr,
1268                                   address top_address, void * param) {
1269   struct _modinfo *pmod = (struct _modinfo *)param;
1270   if (!pmod) return -1;
1271 
1272   if (base_addr   &lt;= pmod-&gt;addr &amp;&amp;
1273       top_address &gt; pmod-&gt;addr) {
1274     // if a buffer is provided, copy path name to the buffer
1275     if (pmod-&gt;full_path) {
1276       jio_snprintf(pmod-&gt;full_path, pmod-&gt;buflen, &quot;%s&quot;, mod_fname);
1277     }
1278     pmod-&gt;base_addr = base_addr;
1279     return 1;
1280   }
1281   return 0;
1282 }
1283 
1284 bool os::dll_address_to_library_name(address addr, char* buf,
1285                                      int buflen, int* offset) {
1286   // buf is not optional, but offset is optional
1287   assert(buf != NULL, &quot;sanity check&quot;);
1288 
1289 // NOTE: the reason we don&#39;t use SymGetModuleInfo() is it doesn&#39;t always
1290 //       return the full path to the DLL file, sometimes it returns path
1291 //       to the corresponding PDB file (debug info); sometimes it only
1292 //       returns partial path, which makes life painful.
1293 
1294   struct _modinfo mi;
1295   mi.addr      = addr;
1296   mi.full_path = buf;
1297   mi.buflen    = buflen;
1298   if (get_loaded_modules_info(_locate_module_by_addr, (void *)&amp;mi)) {
1299     // buf already contains path name
1300     if (offset) *offset = addr - mi.base_addr;
1301     return true;
1302   }
1303 
1304   buf[0] = &#39;\0&#39;;
1305   if (offset) *offset = -1;
1306   return false;
1307 }
1308 
1309 bool os::dll_address_to_function_name(address addr, char *buf,
1310                                       int buflen, int *offset,
1311                                       bool demangle) {
1312   // buf is not optional, but offset is optional
1313   assert(buf != NULL, &quot;sanity check&quot;);
1314 
1315   if (Decoder::decode(addr, buf, buflen, offset, demangle)) {
1316     return true;
1317   }
1318   if (offset != NULL)  *offset  = -1;
1319   buf[0] = &#39;\0&#39;;
1320   return false;
1321 }
1322 
1323 // save the start and end address of jvm.dll into param[0] and param[1]
1324 static int _locate_jvm_dll(const char* mod_fname, address base_addr,
1325                            address top_address, void * param) {
1326   if (!param) return -1;
1327 
1328   if (base_addr   &lt;= (address)_locate_jvm_dll &amp;&amp;
1329       top_address &gt; (address)_locate_jvm_dll) {
1330     ((address*)param)[0] = base_addr;
1331     ((address*)param)[1] = top_address;
1332     return 1;
1333   }
1334   return 0;
1335 }
1336 
1337 address vm_lib_location[2];    // start and end address of jvm.dll
1338 
1339 // check if addr is inside jvm.dll
1340 bool os::address_is_in_vm(address addr) {
1341   if (!vm_lib_location[0] || !vm_lib_location[1]) {
1342     if (!get_loaded_modules_info(_locate_jvm_dll, (void *)vm_lib_location)) {
1343       assert(false, &quot;Can&#39;t find jvm module.&quot;);
1344       return false;
1345     }
1346   }
1347 
1348   return (vm_lib_location[0] &lt;= addr) &amp;&amp; (addr &lt; vm_lib_location[1]);
1349 }
1350 
1351 // print module info; param is outputStream*
1352 static int _print_module(const char* fname, address base_address,
1353                          address top_address, void* param) {
1354   if (!param) return -1;
1355 
1356   outputStream* st = (outputStream*)param;
1357 
1358   st-&gt;print(PTR_FORMAT &quot; - &quot; PTR_FORMAT &quot; \t%s\n&quot;, base_address, top_address, fname);
1359   return 0;
1360 }
1361 
1362 // Loads .dll/.so and
1363 // in case of error it checks if .dll/.so was built for the
1364 // same architecture as Hotspot is running on
1365 void * os::dll_load(const char *name, char *ebuf, int ebuflen) {
1366   log_info(os)(&quot;attempting shared library load of %s&quot;, name);
1367 
1368   void * result = LoadLibrary(name);
1369   if (result != NULL) {
1370     Events::log(NULL, &quot;Loaded shared library %s&quot;, name);
1371     // Recalculate pdb search path if a DLL was loaded successfully.
1372     SymbolEngine::recalc_search_path();
1373     log_info(os)(&quot;shared library load of %s was successful&quot;, name);
1374     return result;
1375   }
1376   DWORD errcode = GetLastError();
1377   // Read system error message into ebuf
1378   // It may or may not be overwritten below (in the for loop and just above)
1379   lasterror(ebuf, (size_t) ebuflen);
1380   ebuf[ebuflen - 1] = &#39;\0&#39;;
1381   Events::log(NULL, &quot;Loading shared library %s failed, error code %lu&quot;, name, errcode);
1382   log_info(os)(&quot;shared library load of %s failed, error code %lu&quot;, name, errcode);
1383 
1384   if (errcode == ERROR_MOD_NOT_FOUND) {
1385     strncpy(ebuf, &quot;Can&#39;t find dependent libraries&quot;, ebuflen - 1);
1386     ebuf[ebuflen - 1] = &#39;\0&#39;;
1387     return NULL;
1388   }
1389 
1390   // Parsing dll below
1391   // If we can read dll-info and find that dll was built
1392   // for an architecture other than Hotspot is running in
1393   // - then print to buffer &quot;DLL was built for a different architecture&quot;
1394   // else call os::lasterror to obtain system error message
1395   int fd = ::open(name, O_RDONLY | O_BINARY, 0);
1396   if (fd &lt; 0) {
1397     return NULL;
1398   }
1399 
1400   uint32_t signature_offset;
1401   uint16_t lib_arch = 0;
1402   bool failed_to_get_lib_arch =
1403     ( // Go to position 3c in the dll
1404      (os::seek_to_file_offset(fd, IMAGE_FILE_PTR_TO_SIGNATURE) &lt; 0)
1405      ||
1406      // Read location of signature
1407      (sizeof(signature_offset) !=
1408      (os::read(fd, (void*)&amp;signature_offset, sizeof(signature_offset))))
1409      ||
1410      // Go to COFF File Header in dll
1411      // that is located after &quot;signature&quot; (4 bytes long)
1412      (os::seek_to_file_offset(fd,
1413      signature_offset + IMAGE_FILE_SIGNATURE_LENGTH) &lt; 0)
1414      ||
1415      // Read field that contains code of architecture
1416      // that dll was built for
1417      (sizeof(lib_arch) != (os::read(fd, (void*)&amp;lib_arch, sizeof(lib_arch))))
1418     );
1419 
1420   ::close(fd);
1421   if (failed_to_get_lib_arch) {
1422     // file i/o error - report os::lasterror(...) msg
1423     return NULL;
1424   }
1425 
1426   typedef struct {
1427     uint16_t arch_code;
1428     char* arch_name;
1429   } arch_t;
1430 
1431   static const arch_t arch_array[] = {
1432     {IMAGE_FILE_MACHINE_I386,      (char*)&quot;IA 32&quot;},
1433     {IMAGE_FILE_MACHINE_AMD64,     (char*)&quot;AMD 64&quot;}
1434   };
1435 #if (defined _M_AMD64)
1436   static const uint16_t running_arch = IMAGE_FILE_MACHINE_AMD64;
1437 #elif (defined _M_IX86)
1438   static const uint16_t running_arch = IMAGE_FILE_MACHINE_I386;
1439 #else
1440   #error Method os::dll_load requires that one of following \
1441          is defined :_M_AMD64 or _M_IX86
1442 #endif
1443 
1444 
1445   // Obtain a string for printf operation
1446   // lib_arch_str shall contain string what platform this .dll was built for
1447   // running_arch_str shall string contain what platform Hotspot was built for
1448   char *running_arch_str = NULL, *lib_arch_str = NULL;
1449   for (unsigned int i = 0; i &lt; ARRAY_SIZE(arch_array); i++) {
1450     if (lib_arch == arch_array[i].arch_code) {
1451       lib_arch_str = arch_array[i].arch_name;
1452     }
1453     if (running_arch == arch_array[i].arch_code) {
1454       running_arch_str = arch_array[i].arch_name;
1455     }
1456   }
1457 
1458   assert(running_arch_str,
1459          &quot;Didn&#39;t find running architecture code in arch_array&quot;);
1460 
1461   // If the architecture is right
1462   // but some other error took place - report os::lasterror(...) msg
1463   if (lib_arch == running_arch) {
1464     return NULL;
1465   }
1466 
1467   if (lib_arch_str != NULL) {
1468     ::_snprintf(ebuf, ebuflen - 1,
1469                 &quot;Can&#39;t load %s-bit .dll on a %s-bit platform&quot;,
1470                 lib_arch_str, running_arch_str);
1471   } else {
1472     // don&#39;t know what architecture this dll was build for
1473     ::_snprintf(ebuf, ebuflen - 1,
1474                 &quot;Can&#39;t load this .dll (machine code=0x%x) on a %s-bit platform&quot;,
1475                 lib_arch, running_arch_str);
1476   }
1477 
1478   return NULL;
1479 }
1480 
1481 void os::print_dll_info(outputStream *st) {
1482   st-&gt;print_cr(&quot;Dynamic libraries:&quot;);
1483   get_loaded_modules_info(_print_module, (void *)st);
1484 }
1485 
1486 int os::get_loaded_modules_info(os::LoadedModulesCallbackFunc callback, void *param) {
1487   HANDLE   hProcess;
1488 
1489 # define MAX_NUM_MODULES 128
1490   HMODULE     modules[MAX_NUM_MODULES];
1491   static char filename[MAX_PATH];
1492   int         result = 0;
1493 
1494   int pid = os::current_process_id();
1495   hProcess = OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,
1496                          FALSE, pid);
1497   if (hProcess == NULL) return 0;
1498 
1499   DWORD size_needed;
1500   if (!EnumProcessModules(hProcess, modules, sizeof(modules), &amp;size_needed)) {
1501     CloseHandle(hProcess);
1502     return 0;
1503   }
1504 
1505   // number of modules that are currently loaded
1506   int num_modules = size_needed / sizeof(HMODULE);
1507 
1508   for (int i = 0; i &lt; MIN2(num_modules, MAX_NUM_MODULES); i++) {
1509     // Get Full pathname:
1510     if (!GetModuleFileNameEx(hProcess, modules[i], filename, sizeof(filename))) {
1511       filename[0] = &#39;\0&#39;;
1512     }
1513 
1514     MODULEINFO modinfo;
1515     if (!GetModuleInformation(hProcess, modules[i], &amp;modinfo, sizeof(modinfo))) {
1516       modinfo.lpBaseOfDll = NULL;
1517       modinfo.SizeOfImage = 0;
1518     }
1519 
1520     // Invoke callback function
1521     result = callback(filename, (address)modinfo.lpBaseOfDll,
1522                       (address)((u8)modinfo.lpBaseOfDll + (u8)modinfo.SizeOfImage), param);
1523     if (result) break;
1524   }
1525 
1526   CloseHandle(hProcess);
1527   return result;
1528 }
1529 
1530 bool os::get_host_name(char* buf, size_t buflen) {
1531   DWORD size = (DWORD)buflen;
1532   return (GetComputerNameEx(ComputerNameDnsHostname, buf, &amp;size) == TRUE);
1533 }
1534 
1535 void os::get_summary_os_info(char* buf, size_t buflen) {
1536   stringStream sst(buf, buflen);
1537   os::win32::print_windows_version(&amp;sst);
1538   // chop off newline character
1539   char* nl = strchr(buf, &#39;\n&#39;);
1540   if (nl != NULL) *nl = &#39;\0&#39;;
1541 }
1542 
1543 int os::vsnprintf(char* buf, size_t len, const char* fmt, va_list args) {
1544 #if _MSC_VER &gt;= 1900
1545   // Starting with Visual Studio 2015, vsnprint is C99 compliant.
1546   int result = ::vsnprintf(buf, len, fmt, args);
1547   // If an encoding error occurred (result &lt; 0) then it&#39;s not clear
1548   // whether the buffer is NUL terminated, so ensure it is.
1549   if ((result &lt; 0) &amp;&amp; (len &gt; 0)) {
1550     buf[len - 1] = &#39;\0&#39;;
1551   }
1552   return result;
1553 #else
1554   // Before Visual Studio 2015, vsnprintf is not C99 compliant, so use
1555   // _vsnprintf, whose behavior seems to be *mostly* consistent across
1556   // versions.  However, when len == 0, avoid _vsnprintf too, and just
1557   // go straight to _vscprintf.  The output is going to be truncated in
1558   // that case, except in the unusual case of empty output.  More
1559   // importantly, the documentation for various versions of Visual Studio
1560   // are inconsistent about the behavior of _vsnprintf when len == 0,
1561   // including it possibly being an error.
1562   int result = -1;
1563   if (len &gt; 0) {
1564     result = _vsnprintf(buf, len, fmt, args);
1565     // If output (including NUL terminator) is truncated, the buffer
1566     // won&#39;t be NUL terminated.  Add the trailing NUL specified by C99.
1567     if ((result &lt; 0) || ((size_t)result &gt;= len)) {
1568       buf[len - 1] = &#39;\0&#39;;
1569     }
1570   }
1571   if (result &lt; 0) {
1572     result = _vscprintf(fmt, args);
1573   }
1574   return result;
1575 #endif // _MSC_VER dispatch
1576 }
1577 
1578 static inline time_t get_mtime(const char* filename) {
1579   struct stat st;
1580   int ret = os::stat(filename, &amp;st);
1581   assert(ret == 0, &quot;failed to stat() file &#39;%s&#39;: %s&quot;, filename, os::strerror(errno));
1582   return st.st_mtime;
1583 }
1584 
1585 int os::compare_file_modified_times(const char* file1, const char* file2) {
1586   time_t t1 = get_mtime(file1);
1587   time_t t2 = get_mtime(file2);
1588   return t1 - t2;
1589 }
1590 
1591 void os::print_os_info_brief(outputStream* st) {
1592   os::print_os_info(st);
1593 }
1594 
1595 void os::win32::print_uptime_info(outputStream* st) {
1596   unsigned long long ticks = GetTickCount64();
1597   os::print_dhm(st, &quot;OS uptime:&quot;, ticks/1000);
1598 }
1599 
1600 void os::print_os_info(outputStream* st) {
1601 #ifdef ASSERT
1602   char buffer[1024];
1603   st-&gt;print(&quot;HostName: &quot;);
1604   if (get_host_name(buffer, sizeof(buffer))) {
1605     st-&gt;print(&quot;%s &quot;, buffer);
1606   } else {
1607     st-&gt;print(&quot;N/A &quot;);
1608   }
1609 #endif
1610   st-&gt;print(&quot;OS:&quot;);
1611   os::win32::print_windows_version(st);
1612 
1613   os::win32::print_uptime_info(st);
1614 
1615 #ifdef _LP64
1616   VM_Version::print_platform_virtualization_info(st);
1617 #endif
1618 }
1619 
1620 void os::win32::print_windows_version(outputStream* st) {
1621   OSVERSIONINFOEX osvi;
1622   VS_FIXEDFILEINFO *file_info;
1623   TCHAR kernel32_path[MAX_PATH];
1624   UINT len, ret;
1625 
1626   // Use the GetVersionEx information to see if we&#39;re on a server or
1627   // workstation edition of Windows. Starting with Windows 8.1 we can&#39;t
1628   // trust the OS version information returned by this API.
1629   ZeroMemory(&amp;osvi, sizeof(OSVERSIONINFOEX));
1630   osvi.dwOSVersionInfoSize = sizeof(OSVERSIONINFOEX);
1631   if (!GetVersionEx((OSVERSIONINFO *)&amp;osvi)) {
1632     st-&gt;print_cr(&quot;Call to GetVersionEx failed&quot;);
1633     return;
1634   }
1635   bool is_workstation = (osvi.wProductType == VER_NT_WORKSTATION);
1636 
1637   // Get the full path to \Windows\System32\kernel32.dll and use that for
1638   // determining what version of Windows we&#39;re running on.
1639   len = MAX_PATH - (UINT)strlen(&quot;\\kernel32.dll&quot;) - 1;
1640   ret = GetSystemDirectory(kernel32_path, len);
1641   if (ret == 0 || ret &gt; len) {
1642     st-&gt;print_cr(&quot;Call to GetSystemDirectory failed&quot;);
1643     return;
1644   }
1645   strncat(kernel32_path, &quot;\\kernel32.dll&quot;, MAX_PATH - ret);
1646 
1647   DWORD version_size = GetFileVersionInfoSize(kernel32_path, NULL);
1648   if (version_size == 0) {
1649     st-&gt;print_cr(&quot;Call to GetFileVersionInfoSize failed&quot;);
1650     return;
1651   }
1652 
1653   LPTSTR version_info = (LPTSTR)os::malloc(version_size, mtInternal);
1654   if (version_info == NULL) {
1655     st-&gt;print_cr(&quot;Failed to allocate version_info&quot;);
1656     return;
1657   }
1658 
1659   if (!GetFileVersionInfo(kernel32_path, NULL, version_size, version_info)) {
1660     os::free(version_info);
1661     st-&gt;print_cr(&quot;Call to GetFileVersionInfo failed&quot;);
1662     return;
1663   }
1664 
1665   if (!VerQueryValue(version_info, TEXT(&quot;\\&quot;), (LPVOID*)&amp;file_info, &amp;len)) {
1666     os::free(version_info);
1667     st-&gt;print_cr(&quot;Call to VerQueryValue failed&quot;);
1668     return;
1669   }
1670 
1671   int major_version = HIWORD(file_info-&gt;dwProductVersionMS);
1672   int minor_version = LOWORD(file_info-&gt;dwProductVersionMS);
1673   int build_number = HIWORD(file_info-&gt;dwProductVersionLS);
1674   int build_minor = LOWORD(file_info-&gt;dwProductVersionLS);
1675   int os_vers = major_version * 1000 + minor_version;
1676   os::free(version_info);
1677 
1678   st-&gt;print(&quot; Windows &quot;);
1679   switch (os_vers) {
1680 
1681   case 6000:
1682     if (is_workstation) {
1683       st-&gt;print(&quot;Vista&quot;);
1684     } else {
1685       st-&gt;print(&quot;Server 2008&quot;);
1686     }
1687     break;
1688 
1689   case 6001:
1690     if (is_workstation) {
1691       st-&gt;print(&quot;7&quot;);
1692     } else {
1693       st-&gt;print(&quot;Server 2008 R2&quot;);
1694     }
1695     break;
1696 
1697   case 6002:
1698     if (is_workstation) {
1699       st-&gt;print(&quot;8&quot;);
1700     } else {
1701       st-&gt;print(&quot;Server 2012&quot;);
1702     }
1703     break;
1704 
1705   case 6003:
1706     if (is_workstation) {
1707       st-&gt;print(&quot;8.1&quot;);
1708     } else {
1709       st-&gt;print(&quot;Server 2012 R2&quot;);
1710     }
1711     break;
1712 
1713   case 10000:
1714     if (is_workstation) {
1715       st-&gt;print(&quot;10&quot;);
1716     } else {
1717       // distinguish Windows Server 2016 and 2019 by build number
1718       // Windows server 2019 GA 10/2018 build number is 17763
1719       if (build_number &gt; 17762) {
1720         st-&gt;print(&quot;Server 2019&quot;);
1721       } else {
1722         st-&gt;print(&quot;Server 2016&quot;);
1723       }
1724     }
1725     break;
1726 
1727   default:
1728     // Unrecognized windows, print out its major and minor versions
1729     st-&gt;print(&quot;%d.%d&quot;, major_version, minor_version);
1730     break;
1731   }
1732 
1733   // Retrieve SYSTEM_INFO from GetNativeSystemInfo call so that we could
1734   // find out whether we are running on 64 bit processor or not
1735   SYSTEM_INFO si;
1736   ZeroMemory(&amp;si, sizeof(SYSTEM_INFO));
1737   GetNativeSystemInfo(&amp;si);
1738   if (si.wProcessorArchitecture == PROCESSOR_ARCHITECTURE_AMD64) {
1739     st-&gt;print(&quot; , 64 bit&quot;);
1740   }
1741 
1742   st-&gt;print(&quot; Build %d&quot;, build_number);
1743   st-&gt;print(&quot; (%d.%d.%d.%d)&quot;, major_version, minor_version, build_number, build_minor);
1744   st-&gt;cr();
1745 }
1746 
1747 void os::pd_print_cpu_info(outputStream* st, char* buf, size_t buflen) {
1748   // Nothing to do for now.
1749 }
1750 
1751 void os::get_summary_cpu_info(char* buf, size_t buflen) {
1752   HKEY key;
1753   DWORD status = RegOpenKey(HKEY_LOCAL_MACHINE,
1754                &quot;HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0&quot;, &amp;key);
1755   if (status == ERROR_SUCCESS) {
1756     DWORD size = (DWORD)buflen;
1757     status = RegQueryValueEx(key, &quot;ProcessorNameString&quot;, NULL, NULL, (byte*)buf, &amp;size);
1758     if (status != ERROR_SUCCESS) {
1759         strncpy(buf, &quot;## __CPU__&quot;, buflen);
1760     }
1761     RegCloseKey(key);
1762   } else {
1763     // Put generic cpu info to return
1764     strncpy(buf, &quot;## __CPU__&quot;, buflen);
1765   }
1766 }
1767 
1768 void os::print_memory_info(outputStream* st) {
1769   st-&gt;print(&quot;Memory:&quot;);
1770   st-&gt;print(&quot; %dk page&quot;, os::vm_page_size()&gt;&gt;10);
1771 
1772   // Use GlobalMemoryStatusEx() because GlobalMemoryStatus() may return incorrect
1773   // value if total memory is larger than 4GB
1774   MEMORYSTATUSEX ms;
1775   ms.dwLength = sizeof(ms);
1776   int r1 = GlobalMemoryStatusEx(&amp;ms);
1777 
1778   if (r1 != 0) {
1779     st-&gt;print(&quot;, system-wide physical &quot; INT64_FORMAT &quot;M &quot;,
1780              (int64_t) ms.ullTotalPhys &gt;&gt; 20);
1781     st-&gt;print(&quot;(&quot; INT64_FORMAT &quot;M free)\n&quot;, (int64_t) ms.ullAvailPhys &gt;&gt; 20);
1782 
1783     st-&gt;print(&quot;TotalPageFile size &quot; INT64_FORMAT &quot;M &quot;,
1784              (int64_t) ms.ullTotalPageFile &gt;&gt; 20);
1785     st-&gt;print(&quot;(AvailPageFile size &quot; INT64_FORMAT &quot;M)&quot;,
1786              (int64_t) ms.ullAvailPageFile &gt;&gt; 20);
1787 
1788     // on 32bit Total/AvailVirtual are interesting (show us how close we get to 2-4 GB per process borders)
1789 #if defined(_M_IX86)
1790     st-&gt;print(&quot;, user-mode portion of virtual address-space &quot; INT64_FORMAT &quot;M &quot;,
1791              (int64_t) ms.ullTotalVirtual &gt;&gt; 20);
1792     st-&gt;print(&quot;(&quot; INT64_FORMAT &quot;M free)&quot;, (int64_t) ms.ullAvailVirtual &gt;&gt; 20);
1793 #endif
1794   } else {
1795     st-&gt;print(&quot;, GlobalMemoryStatusEx did not succeed so we miss some memory values.&quot;);
1796   }
1797 
1798   // extended memory statistics for a process
1799   PROCESS_MEMORY_COUNTERS_EX pmex;
1800   ZeroMemory(&amp;pmex, sizeof(PROCESS_MEMORY_COUNTERS_EX));
1801   pmex.cb = sizeof(pmex);
1802   int r2 = GetProcessMemoryInfo(GetCurrentProcess(), (PROCESS_MEMORY_COUNTERS*) &amp;pmex, sizeof(pmex));
1803 
1804   if (r2 != 0) {
1805     st-&gt;print(&quot;\ncurrent process WorkingSet (physical memory assigned to process): &quot; INT64_FORMAT &quot;M, &quot;,
1806              (int64_t) pmex.WorkingSetSize &gt;&gt; 20);
1807     st-&gt;print(&quot;peak: &quot; INT64_FORMAT &quot;M\n&quot;, (int64_t) pmex.PeakWorkingSetSize &gt;&gt; 20);
1808 
1809     st-&gt;print(&quot;current process commit charge (\&quot;private bytes\&quot;): &quot; INT64_FORMAT &quot;M, &quot;,
1810              (int64_t) pmex.PrivateUsage &gt;&gt; 20);
1811     st-&gt;print(&quot;peak: &quot; INT64_FORMAT &quot;M&quot;, (int64_t) pmex.PeakPagefileUsage &gt;&gt; 20);
1812   } else {
1813     st-&gt;print(&quot;\nGetProcessMemoryInfo did not succeed so we miss some memory values.&quot;);
1814   }
1815 
1816   st-&gt;cr();
1817 }
1818 
1819 bool os::signal_sent_by_kill(const void* siginfo) {
1820   // TODO: Is this possible?
1821   return false;
1822 }
1823 
1824 void os::print_siginfo(outputStream *st, const void* siginfo) {
1825   const EXCEPTION_RECORD* const er = (EXCEPTION_RECORD*)siginfo;
1826   st-&gt;print(&quot;siginfo:&quot;);
1827 
1828   char tmp[64];
1829   if (os::exception_name(er-&gt;ExceptionCode, tmp, sizeof(tmp)) == NULL) {
1830     strcpy(tmp, &quot;EXCEPTION_??&quot;);
1831   }
1832   st-&gt;print(&quot; %s (0x%x)&quot;, tmp, er-&gt;ExceptionCode);
1833 
1834   if ((er-&gt;ExceptionCode == EXCEPTION_ACCESS_VIOLATION ||
1835        er-&gt;ExceptionCode == EXCEPTION_IN_PAGE_ERROR) &amp;&amp;
1836        er-&gt;NumberParameters &gt;= 2) {
1837     switch (er-&gt;ExceptionInformation[0]) {
1838     case 0: st-&gt;print(&quot;, reading address&quot;); break;
1839     case 1: st-&gt;print(&quot;, writing address&quot;); break;
1840     case 8: st-&gt;print(&quot;, data execution prevention violation at address&quot;); break;
1841     default: st-&gt;print(&quot;, ExceptionInformation=&quot; INTPTR_FORMAT,
1842                        er-&gt;ExceptionInformation[0]);
1843     }
1844     st-&gt;print(&quot; &quot; INTPTR_FORMAT, er-&gt;ExceptionInformation[1]);
1845   } else {
1846     int num = er-&gt;NumberParameters;
1847     if (num &gt; 0) {
1848       st-&gt;print(&quot;, ExceptionInformation=&quot;);
1849       for (int i = 0; i &lt; num; i++) {
1850         st-&gt;print(INTPTR_FORMAT &quot; &quot;, er-&gt;ExceptionInformation[i]);
1851       }
1852     }
1853   }
1854   st-&gt;cr();
1855 }
1856 
1857 bool os::signal_thread(Thread* thread, int sig, const char* reason) {
1858   // TODO: Can we kill thread?
1859   return false;
1860 }
1861 
1862 void os::print_signal_handlers(outputStream* st, char* buf, size_t buflen) {
1863   // do nothing
1864 }
1865 
1866 static char saved_jvm_path[MAX_PATH] = {0};
1867 
1868 // Find the full path to the current module, jvm.dll
1869 void os::jvm_path(char *buf, jint buflen) {
1870   // Error checking.
1871   if (buflen &lt; MAX_PATH) {
1872     assert(false, &quot;must use a large-enough buffer&quot;);
1873     buf[0] = &#39;\0&#39;;
1874     return;
1875   }
1876   // Lazy resolve the path to current module.
1877   if (saved_jvm_path[0] != 0) {
1878     strcpy(buf, saved_jvm_path);
1879     return;
1880   }
1881 
1882   buf[0] = &#39;\0&#39;;
1883   if (Arguments::sun_java_launcher_is_altjvm()) {
1884     // Support for the java launcher&#39;s &#39;-XXaltjvm=&lt;path&gt;&#39; option. Check
1885     // for a JAVA_HOME environment variable and fix up the path so it
1886     // looks like jvm.dll is installed there (append a fake suffix
1887     // hotspot/jvm.dll).
1888     char* java_home_var = ::getenv(&quot;JAVA_HOME&quot;);
1889     if (java_home_var != NULL &amp;&amp; java_home_var[0] != 0 &amp;&amp;
1890         strlen(java_home_var) &lt; (size_t)buflen) {
1891       strncpy(buf, java_home_var, buflen);
1892 
1893       // determine if this is a legacy image or modules image
1894       // modules image doesn&#39;t have &quot;jre&quot; subdirectory
1895       size_t len = strlen(buf);
1896       char* jrebin_p = buf + len;
1897       jio_snprintf(jrebin_p, buflen-len, &quot;\\jre\\bin\\&quot;);
1898       if (0 != _access(buf, 0)) {
1899         jio_snprintf(jrebin_p, buflen-len, &quot;\\bin\\&quot;);
1900       }
1901       len = strlen(buf);
1902       jio_snprintf(buf + len, buflen-len, &quot;hotspot\\jvm.dll&quot;);
1903     }
1904   }
1905 
1906   if (buf[0] == &#39;\0&#39;) {
1907     GetModuleFileName(vm_lib_handle, buf, buflen);
1908   }
1909   strncpy(saved_jvm_path, buf, MAX_PATH);
1910   saved_jvm_path[MAX_PATH - 1] = &#39;\0&#39;;
1911 }
1912 
1913 
1914 void os::print_jni_name_prefix_on(outputStream* st, int args_size) {
1915 #ifndef _WIN64
1916   st-&gt;print(&quot;_&quot;);
1917 #endif
1918 }
1919 
1920 
1921 void os::print_jni_name_suffix_on(outputStream* st, int args_size) {
1922 #ifndef _WIN64
1923   st-&gt;print(&quot;@%d&quot;, args_size  * sizeof(int));
1924 #endif
1925 }
1926 
1927 // This method is a copy of JDK&#39;s sysGetLastErrorString
1928 // from src/windows/hpi/src/system_md.c
1929 
1930 size_t os::lasterror(char* buf, size_t len) {
1931   DWORD errval;
1932 
1933   if ((errval = GetLastError()) != 0) {
1934     // DOS error
1935     size_t n = (size_t)FormatMessage(
1936                                      FORMAT_MESSAGE_FROM_SYSTEM|FORMAT_MESSAGE_IGNORE_INSERTS,
1937                                      NULL,
1938                                      errval,
1939                                      0,
1940                                      buf,
1941                                      (DWORD)len,
1942                                      NULL);
1943     if (n &gt; 3) {
1944       // Drop final &#39;.&#39;, CR, LF
1945       if (buf[n - 1] == &#39;\n&#39;) n--;
1946       if (buf[n - 1] == &#39;\r&#39;) n--;
1947       if (buf[n - 1] == &#39;.&#39;) n--;
1948       buf[n] = &#39;\0&#39;;
1949     }
1950     return n;
1951   }
1952 
1953   if (errno != 0) {
1954     // C runtime error that has no corresponding DOS error code
1955     const char* s = os::strerror(errno);
1956     size_t n = strlen(s);
1957     if (n &gt;= len) n = len - 1;
1958     strncpy(buf, s, n);
1959     buf[n] = &#39;\0&#39;;
1960     return n;
1961   }
1962 
1963   return 0;
1964 }
1965 
1966 int os::get_last_error() {
1967   DWORD error = GetLastError();
1968   if (error == 0) {
1969     error = errno;
1970   }
1971   return (int)error;
1972 }
1973 
1974 // sun.misc.Signal
1975 // NOTE that this is a workaround for an apparent kernel bug where if
1976 // a signal handler for SIGBREAK is installed then that signal handler
1977 // takes priority over the console control handler for CTRL_CLOSE_EVENT.
1978 // See bug 4416763.
1979 static void (*sigbreakHandler)(int) = NULL;
1980 
1981 static void UserHandler(int sig, void *siginfo, void *context) {
1982   os::signal_notify(sig);
1983   // We need to reinstate the signal handler each time...
1984   os::signal(sig, (void*)UserHandler);
1985 }
1986 
1987 void* os::user_handler() {
1988   return (void*) UserHandler;
1989 }
1990 
1991 void* os::signal(int signal_number, void* handler) {
1992   if ((signal_number == SIGBREAK) &amp;&amp; (!ReduceSignalUsage)) {
1993     void (*oldHandler)(int) = sigbreakHandler;
1994     sigbreakHandler = (void (*)(int)) handler;
1995     return (void*) oldHandler;
1996   } else {
1997     return (void*)::signal(signal_number, (void (*)(int))handler);
1998   }
1999 }
2000 
2001 void os::signal_raise(int signal_number) {
2002   raise(signal_number);
2003 }
2004 
2005 // The Win32 C runtime library maps all console control events other than ^C
2006 // into SIGBREAK, which makes it impossible to distinguish ^BREAK from close,
2007 // logoff, and shutdown events.  We therefore install our own console handler
2008 // that raises SIGTERM for the latter cases.
2009 //
2010 static BOOL WINAPI consoleHandler(DWORD event) {
2011   switch (event) {
2012   case CTRL_C_EVENT:
2013     if (VMError::is_error_reported()) {
2014       // Ctrl-C is pressed during error reporting, likely because the error
2015       // handler fails to abort. Let VM die immediately.
2016       os::die();
2017     }
2018 
2019     os::signal_raise(SIGINT);
2020     return TRUE;
2021     break;
2022   case CTRL_BREAK_EVENT:
2023     if (sigbreakHandler != NULL) {
2024       (*sigbreakHandler)(SIGBREAK);
2025     }
2026     return TRUE;
2027     break;
2028   case CTRL_LOGOFF_EVENT: {
2029     // Don&#39;t terminate JVM if it is running in a non-interactive session,
2030     // such as a service process.
2031     USEROBJECTFLAGS flags;
2032     HANDLE handle = GetProcessWindowStation();
2033     if (handle != NULL &amp;&amp;
2034         GetUserObjectInformation(handle, UOI_FLAGS, &amp;flags,
2035         sizeof(USEROBJECTFLAGS), NULL)) {
2036       // If it is a non-interactive session, let next handler to deal
2037       // with it.
2038       if ((flags.dwFlags &amp; WSF_VISIBLE) == 0) {
2039         return FALSE;
2040       }
2041     }
2042   }
2043   case CTRL_CLOSE_EVENT:
2044   case CTRL_SHUTDOWN_EVENT:
2045     os::signal_raise(SIGTERM);
2046     return TRUE;
2047     break;
2048   default:
2049     break;
2050   }
2051   return FALSE;
2052 }
2053 
2054 // The following code is moved from os.cpp for making this
2055 // code platform specific, which it is by its very nature.
2056 
2057 // Return maximum OS signal used + 1 for internal use only
2058 // Used as exit signal for signal_thread
2059 int os::sigexitnum_pd() {
2060   return NSIG;
2061 }
2062 
2063 // a counter for each possible signal value, including signal_thread exit signal
2064 static volatile jint pending_signals[NSIG+1] = { 0 };
2065 static Semaphore* sig_sem = NULL;
2066 
2067 static void jdk_misc_signal_init() {
2068   // Initialize signal structures
2069   memset((void*)pending_signals, 0, sizeof(pending_signals));
2070 
2071   // Initialize signal semaphore
2072   sig_sem = new Semaphore();
2073 
2074   // Programs embedding the VM do not want it to attempt to receive
2075   // events like CTRL_LOGOFF_EVENT, which are used to implement the
2076   // shutdown hooks mechanism introduced in 1.3.  For example, when
2077   // the VM is run as part of a Windows NT service (i.e., a servlet
2078   // engine in a web server), the correct behavior is for any console
2079   // control handler to return FALSE, not TRUE, because the OS&#39;s
2080   // &quot;final&quot; handler for such events allows the process to continue if
2081   // it is a service (while terminating it if it is not a service).
2082   // To make this behavior uniform and the mechanism simpler, we
2083   // completely disable the VM&#39;s usage of these console events if -Xrs
2084   // (=ReduceSignalUsage) is specified.  This means, for example, that
2085   // the CTRL-BREAK thread dump mechanism is also disabled in this
2086   // case.  See bugs 4323062, 4345157, and related bugs.
2087 
2088   // Add a CTRL-C handler
2089   SetConsoleCtrlHandler(consoleHandler, TRUE);
2090 }
2091 
2092 void os::signal_notify(int sig) {
2093   if (sig_sem != NULL) {
2094     Atomic::inc(&amp;pending_signals[sig]);
2095     sig_sem-&gt;signal();
2096   } else {
2097     // Signal thread is not created with ReduceSignalUsage and jdk_misc_signal_init
2098     // initialization isn&#39;t called.
2099     assert(ReduceSignalUsage, &quot;signal semaphore should be created&quot;);
2100   }
2101 }
2102 
2103 static int check_pending_signals() {
2104   while (true) {
2105     for (int i = 0; i &lt; NSIG + 1; i++) {
2106       jint n = pending_signals[i];
2107       if (n &gt; 0 &amp;&amp; n == Atomic::cmpxchg(&amp;pending_signals[i], n, n - 1)) {
2108         return i;
2109       }
2110     }
2111     JavaThread *thread = JavaThread::current();
2112 
2113     ThreadBlockInVM tbivm(thread);
2114 
2115     bool threadIsSuspended;
2116     do {
2117       thread-&gt;set_suspend_equivalent();
2118       // cleared by handle_special_suspend_equivalent_condition() or java_suspend_self()
2119       sig_sem-&gt;wait();
2120 
2121       // were we externally suspended while we were waiting?
2122       threadIsSuspended = thread-&gt;handle_special_suspend_equivalent_condition();
2123       if (threadIsSuspended) {
2124         // The semaphore has been incremented, but while we were waiting
2125         // another thread suspended us. We don&#39;t want to continue running
2126         // while suspended because that would surprise the thread that
2127         // suspended us.
2128         sig_sem-&gt;signal();
2129 
2130         thread-&gt;java_suspend_self();
2131       }
2132     } while (threadIsSuspended);
2133   }
2134 }
2135 
2136 int os::signal_wait() {
2137   return check_pending_signals();
2138 }
2139 
2140 // Implicit OS exception handling
2141 
2142 LONG Handle_Exception(struct _EXCEPTION_POINTERS* exceptionInfo,
2143                       address handler) {
2144   JavaThread* thread = (JavaThread*) Thread::current_or_null();
2145   // Save pc in thread
2146 #ifdef _M_AMD64
2147   // Do not blow up if no thread info available.
2148   if (thread) {
2149     thread-&gt;set_saved_exception_pc((address)(DWORD_PTR)exceptionInfo-&gt;ContextRecord-&gt;Rip);
2150   }
2151   // Set pc to handler
2152   exceptionInfo-&gt;ContextRecord-&gt;Rip = (DWORD64)handler;
2153 #else
2154   // Do not blow up if no thread info available.
2155   if (thread) {
2156     thread-&gt;set_saved_exception_pc((address)(DWORD_PTR)exceptionInfo-&gt;ContextRecord-&gt;Eip);
2157   }
2158   // Set pc to handler
2159   exceptionInfo-&gt;ContextRecord-&gt;Eip = (DWORD)(DWORD_PTR)handler;
2160 #endif
2161 
2162   // Continue the execution
2163   return EXCEPTION_CONTINUE_EXECUTION;
2164 }
2165 
2166 
2167 // Used for PostMortemDump
2168 extern &quot;C&quot; void safepoints();
2169 extern &quot;C&quot; void find(int x);
2170 extern &quot;C&quot; void events();
2171 
2172 // According to Windows API documentation, an illegal instruction sequence should generate
2173 // the 0xC000001C exception code. However, real world experience shows that occasionnaly
2174 // the execution of an illegal instruction can generate the exception code 0xC000001E. This
2175 // seems to be an undocumented feature of Win NT 4.0 (and probably other Windows systems).
2176 
2177 #define EXCEPTION_ILLEGAL_INSTRUCTION_2 0xC000001E
2178 
2179 // From &quot;Execution Protection in the Windows Operating System&quot; draft 0.35
2180 // Once a system header becomes available, the &quot;real&quot; define should be
2181 // included or copied here.
2182 #define EXCEPTION_INFO_EXEC_VIOLATION 0x08
2183 
2184 // Windows Vista/2008 heap corruption check
2185 #define EXCEPTION_HEAP_CORRUPTION        0xC0000374
2186 
2187 // All Visual C++ exceptions thrown from code generated by the Microsoft Visual
2188 // C++ compiler contain this error code. Because this is a compiler-generated
2189 // error, the code is not listed in the Win32 API header files.
2190 // The code is actually a cryptic mnemonic device, with the initial &quot;E&quot;
2191 // standing for &quot;exception&quot; and the final 3 bytes (0x6D7363) representing the
2192 // ASCII values of &quot;msc&quot;.
2193 
2194 #define EXCEPTION_UNCAUGHT_CXX_EXCEPTION    0xE06D7363
2195 
2196 #define def_excpt(val) { #val, (val) }
2197 
2198 static const struct { const char* name; uint number; } exceptlabels[] = {
2199     def_excpt(EXCEPTION_ACCESS_VIOLATION),
2200     def_excpt(EXCEPTION_DATATYPE_MISALIGNMENT),
2201     def_excpt(EXCEPTION_BREAKPOINT),
2202     def_excpt(EXCEPTION_SINGLE_STEP),
2203     def_excpt(EXCEPTION_ARRAY_BOUNDS_EXCEEDED),
2204     def_excpt(EXCEPTION_FLT_DENORMAL_OPERAND),
2205     def_excpt(EXCEPTION_FLT_DIVIDE_BY_ZERO),
2206     def_excpt(EXCEPTION_FLT_INEXACT_RESULT),
2207     def_excpt(EXCEPTION_FLT_INVALID_OPERATION),
2208     def_excpt(EXCEPTION_FLT_OVERFLOW),
2209     def_excpt(EXCEPTION_FLT_STACK_CHECK),
2210     def_excpt(EXCEPTION_FLT_UNDERFLOW),
2211     def_excpt(EXCEPTION_INT_DIVIDE_BY_ZERO),
2212     def_excpt(EXCEPTION_INT_OVERFLOW),
2213     def_excpt(EXCEPTION_PRIV_INSTRUCTION),
2214     def_excpt(EXCEPTION_IN_PAGE_ERROR),
2215     def_excpt(EXCEPTION_ILLEGAL_INSTRUCTION),
2216     def_excpt(EXCEPTION_ILLEGAL_INSTRUCTION_2),
2217     def_excpt(EXCEPTION_NONCONTINUABLE_EXCEPTION),
2218     def_excpt(EXCEPTION_STACK_OVERFLOW),
2219     def_excpt(EXCEPTION_INVALID_DISPOSITION),
2220     def_excpt(EXCEPTION_GUARD_PAGE),
2221     def_excpt(EXCEPTION_INVALID_HANDLE),
2222     def_excpt(EXCEPTION_UNCAUGHT_CXX_EXCEPTION),
2223     def_excpt(EXCEPTION_HEAP_CORRUPTION)
2224 };
2225 
2226 #undef def_excpt
2227 
2228 const char* os::exception_name(int exception_code, char *buf, size_t size) {
2229   uint code = static_cast&lt;uint&gt;(exception_code);
2230   for (uint i = 0; i &lt; ARRAY_SIZE(exceptlabels); ++i) {
2231     if (exceptlabels[i].number == code) {
2232       jio_snprintf(buf, size, &quot;%s&quot;, exceptlabels[i].name);
2233       return buf;
2234     }
2235   }
2236 
2237   return NULL;
2238 }
2239 
2240 //-----------------------------------------------------------------------------
2241 LONG Handle_IDiv_Exception(struct _EXCEPTION_POINTERS* exceptionInfo) {
2242   // handle exception caused by idiv; should only happen for -MinInt/-1
2243   // (division by zero is handled explicitly)
2244 #ifdef  _M_AMD64
2245   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2246   address pc = (address)ctx-&gt;Rip;
2247   assert(pc[0] &gt;= Assembler::REX &amp;&amp; pc[0] &lt;= Assembler::REX_WRXB &amp;&amp; pc[1] == 0xF7 || pc[0] == 0xF7, &quot;not an idiv opcode&quot;);
2248   assert(pc[0] &gt;= Assembler::REX &amp;&amp; pc[0] &lt;= Assembler::REX_WRXB &amp;&amp; (pc[2] &amp; ~0x7) == 0xF8 || (pc[1] &amp; ~0x7) == 0xF8, &quot;cannot handle non-register operands&quot;);
2249   if (pc[0] == 0xF7) {
2250     // set correct result values and continue after idiv instruction
2251     ctx-&gt;Rip = (DWORD64)pc + 2;        // idiv reg, reg  is 2 bytes
2252   } else {
2253     ctx-&gt;Rip = (DWORD64)pc + 3;        // REX idiv reg, reg  is 3 bytes
2254   }
2255   // Do not set ctx-&gt;Rax as it already contains the correct value (either 32 or 64 bit, depending on the operation)
2256   // this is the case because the exception only happens for -MinValue/-1 and -MinValue is always in rax because of the
2257   // idiv opcode (0xF7).
2258   ctx-&gt;Rdx = (DWORD)0;             // remainder
2259   // Continue the execution
2260 #else
2261   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2262   address pc = (address)ctx-&gt;Eip;
2263   assert(pc[0] == 0xF7, &quot;not an idiv opcode&quot;);
2264   assert((pc[1] &amp; ~0x7) == 0xF8, &quot;cannot handle non-register operands&quot;);
2265   assert(ctx-&gt;Eax == min_jint, &quot;unexpected idiv exception&quot;);
2266   // set correct result values and continue after idiv instruction
2267   ctx-&gt;Eip = (DWORD)pc + 2;        // idiv reg, reg  is 2 bytes
2268   ctx-&gt;Eax = (DWORD)min_jint;      // result
2269   ctx-&gt;Edx = (DWORD)0;             // remainder
2270   // Continue the execution
2271 #endif
2272   return EXCEPTION_CONTINUE_EXECUTION;
2273 }
2274 
2275 //-----------------------------------------------------------------------------
2276 LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo) {
2277   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2278 #ifndef  _WIN64
2279   // handle exception caused by native method modifying control word
2280   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2281 
2282   switch (exception_code) {
2283   case EXCEPTION_FLT_DENORMAL_OPERAND:
2284   case EXCEPTION_FLT_DIVIDE_BY_ZERO:
2285   case EXCEPTION_FLT_INEXACT_RESULT:
2286   case EXCEPTION_FLT_INVALID_OPERATION:
2287   case EXCEPTION_FLT_OVERFLOW:
2288   case EXCEPTION_FLT_STACK_CHECK:
2289   case EXCEPTION_FLT_UNDERFLOW:
2290     jint fp_control_word = (* (jint*) StubRoutines::addr_fpu_cntrl_wrd_std());
2291     if (fp_control_word != ctx-&gt;FloatSave.ControlWord) {
2292       // Restore FPCW and mask out FLT exceptions
2293       ctx-&gt;FloatSave.ControlWord = fp_control_word | 0xffffffc0;
2294       // Mask out pending FLT exceptions
2295       ctx-&gt;FloatSave.StatusWord &amp;=  0xffffff00;
2296       return EXCEPTION_CONTINUE_EXECUTION;
2297     }
2298   }
2299 
2300   if (prev_uef_handler != NULL) {
2301     // We didn&#39;t handle this exception so pass it to the previous
2302     // UnhandledExceptionFilter.
2303     return (prev_uef_handler)(exceptionInfo);
2304   }
2305 #else // !_WIN64
2306   // On Windows, the mxcsr control bits are non-volatile across calls
2307   // See also CR 6192333
2308   //
2309   jint MxCsr = INITIAL_MXCSR;
2310   // we can&#39;t use StubRoutines::addr_mxcsr_std()
2311   // because in Win64 mxcsr is not saved there
2312   if (MxCsr != ctx-&gt;MxCsr) {
2313     ctx-&gt;MxCsr = MxCsr;
2314     return EXCEPTION_CONTINUE_EXECUTION;
2315   }
2316 #endif // !_WIN64
2317 
2318   return EXCEPTION_CONTINUE_SEARCH;
2319 }
2320 
2321 static inline void report_error(Thread* t, DWORD exception_code,
2322                                 address addr, void* siginfo, void* context) {
2323   VMError::report_and_die(t, exception_code, addr, siginfo, context);
2324 
2325   // If UseOsErrorReporting, this will return here and save the error file
2326   // somewhere where we can find it in the minidump.
2327 }
2328 
2329 bool os::win32::get_frame_at_stack_banging_point(JavaThread* thread,
2330         struct _EXCEPTION_POINTERS* exceptionInfo, address pc, frame* fr) {
2331   PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2332   address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2333   if (Interpreter::contains(pc)) {
2334     *fr = os::fetch_frame_from_context((void*)exceptionInfo-&gt;ContextRecord);
2335     if (!fr-&gt;is_first_java_frame()) {
2336       // get_frame_at_stack_banging_point() is only called when we
2337       // have well defined stacks so java_sender() calls do not need
2338       // to assert safe_for_sender() first.
2339       *fr = fr-&gt;java_sender();
2340     }
2341   } else {
2342     // more complex code with compiled code
2343     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);
2344     CodeBlob* cb = CodeCache::find_blob(pc);
2345     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {
2346       // Not sure where the pc points to, fallback to default
2347       // stack overflow handling
2348       return false;
2349     } else {
2350       *fr = os::fetch_frame_from_context((void*)exceptionInfo-&gt;ContextRecord);
2351       // in compiled code, the stack banging is performed just after the return pc
2352       // has been pushed on the stack
2353       *fr = frame(fr-&gt;sp() + 1, fr-&gt;fp(), (address)*(fr-&gt;sp()));
2354       if (!fr-&gt;is_java_frame()) {
2355         // See java_sender() comment above.
2356         *fr = fr-&gt;java_sender();
2357       }
2358     }
2359   }
2360   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);
2361   return true;
2362 }
2363 
2364 #if INCLUDE_AOT
2365 LONG WINAPI topLevelVectoredExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2366   PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2367   address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2368   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Rip;
2369 
2370   // Handle the case where we get an implicit exception in AOT generated
2371   // code.  AOT DLL&#39;s loaded are not registered for structured exceptions.
2372   // If the exception occurred in the codeCache or AOT code, pass control
2373   // to our normal exception handler.
2374   CodeBlob* cb = CodeCache::find_blob(pc);
2375   if (cb != NULL) {
2376     return topLevelExceptionFilter(exceptionInfo);
2377   }
2378 
2379   return EXCEPTION_CONTINUE_SEARCH;
2380 }
2381 #endif
2382 
2383 //-----------------------------------------------------------------------------
2384 LONG WINAPI topLevelExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2385   if (InterceptOSException) return EXCEPTION_CONTINUE_SEARCH;
2386   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2387 #ifdef _M_AMD64
2388   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Rip;
2389 #else
2390   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Eip;
2391 #endif
2392   Thread* t = Thread::current_or_null_safe();
2393 
2394   // Handle SafeFetch32 and SafeFetchN exceptions.
2395   if (StubRoutines::is_safefetch_fault(pc)) {
2396     return Handle_Exception(exceptionInfo, StubRoutines::continuation_for_safefetch_fault(pc));
2397   }
2398 
2399 #ifndef _WIN64
2400   // Execution protection violation - win32 running on AMD64 only
2401   // Handled first to avoid misdiagnosis as a &quot;normal&quot; access violation;
2402   // This is safe to do because we have a new/unique ExceptionInformation
2403   // code for this condition.
2404   if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2405     PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2406     int exception_subcode = (int) exceptionRecord-&gt;ExceptionInformation[0];
2407     address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2408 
2409     if (exception_subcode == EXCEPTION_INFO_EXEC_VIOLATION) {
2410       int page_size = os::vm_page_size();
2411 
2412       // Make sure the pc and the faulting address are sane.
2413       //
2414       // If an instruction spans a page boundary, and the page containing
2415       // the beginning of the instruction is executable but the following
2416       // page is not, the pc and the faulting address might be slightly
2417       // different - we still want to unguard the 2nd page in this case.
2418       //
2419       // 15 bytes seems to be a (very) safe value for max instruction size.
2420       bool pc_is_near_addr =
2421         (pointer_delta((void*) addr, (void*) pc, sizeof(char)) &lt; 15);
2422       bool instr_spans_page_boundary =
2423         (align_down((intptr_t) pc ^ (intptr_t) addr,
2424                          (intptr_t) page_size) &gt; 0);
2425 
2426       if (pc == addr || (pc_is_near_addr &amp;&amp; instr_spans_page_boundary)) {
2427         static volatile address last_addr =
2428           (address) os::non_memory_address_word();
2429 
2430         // In conservative mode, don&#39;t unguard unless the address is in the VM
2431         if (UnguardOnExecutionViolation &gt; 0 &amp;&amp; addr != last_addr &amp;&amp;
2432             (UnguardOnExecutionViolation &gt; 1 || os::address_is_in_vm(addr))) {
2433 
2434           // Set memory to RWX and retry
2435           address page_start = align_down(addr, page_size);
2436           bool res = os::protect_memory((char*) page_start, page_size,
2437                                         os::MEM_PROT_RWX);
2438 
2439           log_debug(os)(&quot;Execution protection violation &quot;
2440                         &quot;at &quot; INTPTR_FORMAT
2441                         &quot;, unguarding &quot; INTPTR_FORMAT &quot;: %s&quot;, p2i(addr),
2442                         p2i(page_start), (res ? &quot;success&quot; : os::strerror(errno)));
2443 
2444           // Set last_addr so if we fault again at the same address, we don&#39;t
2445           // end up in an endless loop.
2446           //
2447           // There are two potential complications here.  Two threads trapping
2448           // at the same address at the same time could cause one of the
2449           // threads to think it already unguarded, and abort the VM.  Likely
2450           // very rare.
2451           //
2452           // The other race involves two threads alternately trapping at
2453           // different addresses and failing to unguard the page, resulting in
2454           // an endless loop.  This condition is probably even more unlikely
2455           // than the first.
2456           //
2457           // Although both cases could be avoided by using locks or thread
2458           // local last_addr, these solutions are unnecessary complication:
2459           // this handler is a best-effort safety net, not a complete solution.
2460           // It is disabled by default and should only be used as a workaround
2461           // in case we missed any no-execute-unsafe VM code.
2462 
2463           last_addr = addr;
2464 
2465           return EXCEPTION_CONTINUE_EXECUTION;
2466         }
2467       }
2468 
2469       // Last unguard failed or not unguarding
2470       tty-&gt;print_raw_cr(&quot;Execution protection violation&quot;);
2471       report_error(t, exception_code, addr, exceptionInfo-&gt;ExceptionRecord,
2472                    exceptionInfo-&gt;ContextRecord);
2473       return EXCEPTION_CONTINUE_SEARCH;
2474     }
2475   }
2476 #endif // _WIN64
2477 
2478   if ((exception_code == EXCEPTION_ACCESS_VIOLATION) &amp;&amp;
2479       VM_Version::is_cpuinfo_segv_addr(pc)) {
2480     // Verify that OS save/restore AVX registers.
2481     return Handle_Exception(exceptionInfo, VM_Version::cpuinfo_cont_addr());
2482   }
2483 
2484   if (t != NULL &amp;&amp; t-&gt;is_Java_thread()) {
2485     JavaThread* thread = (JavaThread*) t;
2486     bool in_java = thread-&gt;thread_state() == _thread_in_Java;
2487 
2488     // Handle potential stack overflows up front.
2489     if (exception_code == EXCEPTION_STACK_OVERFLOW) {
2490       if (thread-&gt;stack_guards_enabled()) {
2491         if (in_java) {
2492           frame fr;
2493           PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2494           address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2495           if (os::win32::get_frame_at_stack_banging_point(thread, exceptionInfo, pc, &amp;fr)) {
2496             assert(fr.is_java_frame(), &quot;Must be a Java frame&quot;);
2497             SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);
2498           }
2499         }
2500         // Yellow zone violation.  The o/s has unprotected the first yellow
2501         // zone page for us.  Note:  must call disable_stack_yellow_zone to
2502         // update the enabled status, even if the zone contains only one page.
2503         assert(thread-&gt;thread_state() != _thread_in_vm, &quot;Undersized StackShadowPages&quot;);
2504         thread-&gt;disable_stack_yellow_reserved_zone();
2505         // If not in java code, return and hope for the best.
2506         return in_java
2507             ? Handle_Exception(exceptionInfo, SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW))
2508             :  EXCEPTION_CONTINUE_EXECUTION;
2509       } else {
2510         // Fatal red zone violation.
2511         thread-&gt;disable_stack_red_zone();
2512         tty-&gt;print_raw_cr(&quot;An unrecoverable stack overflow has occurred.&quot;);
2513         report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2514                       exceptionInfo-&gt;ContextRecord);
2515         return EXCEPTION_CONTINUE_SEARCH;
2516       }
2517     } else if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2518       // Either stack overflow or null pointer exception.
2519       if (in_java) {
2520         PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2521         address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2522         address stack_end = thread-&gt;stack_end();
2523         if (addr &lt; stack_end &amp;&amp; addr &gt;= stack_end - os::vm_page_size()) {
2524           // Stack overflow.
2525           assert(!os::uses_stack_guard_pages(),
2526                  &quot;should be caught by red zone code above.&quot;);
2527           return Handle_Exception(exceptionInfo,
2528                                   SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW));
2529         }
2530         // Check for safepoint polling and implicit null
2531         // We only expect null pointers in the stubs (vtable)
2532         // the rest are checked explicitly now.
2533         CodeBlob* cb = CodeCache::find_blob(pc);
2534         if (cb != NULL) {
2535           if (SafepointMechanism::is_poll_address(addr)) {
2536             address stub = SharedRuntime::get_poll_stub(pc);
2537             return Handle_Exception(exceptionInfo, stub);
2538           }
2539         }
2540         {
2541 #ifdef _WIN64
2542           // If it&#39;s a legal stack address map the entire region in
2543           //
2544           PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2545           address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2546           if (thread-&gt;is_in_usable_stack(addr)) {
2547             addr = (address)((uintptr_t)addr &amp;
2548                              (~((uintptr_t)os::vm_page_size() - (uintptr_t)1)));
2549             os::commit_memory((char *)addr, thread-&gt;stack_base() - addr,
2550                               !ExecMem);
2551             return EXCEPTION_CONTINUE_EXECUTION;
2552           } else
2553 #endif
2554           {
2555             // Null pointer exception.
2556             if (MacroAssembler::uses_implicit_null_check((void*)addr)) {
2557               address stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);
2558               if (stub != NULL) return Handle_Exception(exceptionInfo, stub);
2559             }
2560             report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2561                          exceptionInfo-&gt;ContextRecord);
2562             return EXCEPTION_CONTINUE_SEARCH;
2563           }
2564         }
2565       }
2566 
2567 #ifdef _WIN64
2568       // Special care for fast JNI field accessors.
2569       // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks
2570       // in and the heap gets shrunk before the field access.
2571       if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2572         address addr = JNI_FastGetField::find_slowcase_pc(pc);
2573         if (addr != (address)-1) {
2574           return Handle_Exception(exceptionInfo, addr);
2575         }
2576       }
2577 #endif
2578 
2579       // Stack overflow or null pointer exception in native code.
2580       report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2581                    exceptionInfo-&gt;ContextRecord);
2582       return EXCEPTION_CONTINUE_SEARCH;
2583     } // /EXCEPTION_ACCESS_VIOLATION
2584     // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
2585 
2586     if (exception_code == EXCEPTION_IN_PAGE_ERROR) {
2587       CompiledMethod* nm = NULL;
2588       JavaThread* thread = (JavaThread*)t;
2589       if (in_java) {
2590         CodeBlob* cb = CodeCache::find_blob_unsafe(pc);
2591         nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
2592       }
2593 
2594       bool is_unsafe_arraycopy = (thread-&gt;thread_state() == _thread_in_native || in_java) &amp;&amp; UnsafeCopyMemory::contains_pc(pc);
2595       if (((thread-&gt;thread_state() == _thread_in_vm ||
2596            thread-&gt;thread_state() == _thread_in_native ||
2597            is_unsafe_arraycopy) &amp;&amp;
2598           thread-&gt;doing_unsafe_access()) ||
2599           (nm != NULL &amp;&amp; nm-&gt;has_unsafe_access())) {
2600         address next_pc =  Assembler::locate_next_instruction(pc);
2601         if (is_unsafe_arraycopy) {
2602           next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
2603         }
2604         return Handle_Exception(exceptionInfo, SharedRuntime::handle_unsafe_access(thread, next_pc));
2605       }
2606     }
2607 
2608     if (in_java) {
2609       switch (exception_code) {
2610       case EXCEPTION_INT_DIVIDE_BY_ZERO:
2611         return Handle_Exception(exceptionInfo, SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_DIVIDE_BY_ZERO));
2612 
2613       case EXCEPTION_INT_OVERFLOW:
2614         return Handle_IDiv_Exception(exceptionInfo);
2615 
2616       } // switch
2617     }
2618     if (((thread-&gt;thread_state() == _thread_in_Java) ||
2619          (thread-&gt;thread_state() == _thread_in_native)) &amp;&amp;
2620          exception_code != EXCEPTION_UNCAUGHT_CXX_EXCEPTION) {
2621       LONG result=Handle_FLT_Exception(exceptionInfo);
2622       if (result==EXCEPTION_CONTINUE_EXECUTION) return result;
2623     }
2624   }
2625 
2626   if (exception_code != EXCEPTION_BREAKPOINT) {
2627     report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2628                  exceptionInfo-&gt;ContextRecord);
2629   }
2630   return EXCEPTION_CONTINUE_SEARCH;
2631 }
2632 
2633 #ifndef _WIN64
2634 // Special care for fast JNI accessors.
2635 // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks in and
2636 // the heap gets shrunk before the field access.
2637 // Need to install our own structured exception handler since native code may
2638 // install its own.
2639 LONG WINAPI fastJNIAccessorExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2640   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2641   if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2642     address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Eip;
2643     address addr = JNI_FastGetField::find_slowcase_pc(pc);
2644     if (addr != (address)-1) {
2645       return Handle_Exception(exceptionInfo, addr);
2646     }
2647   }
2648   return EXCEPTION_CONTINUE_SEARCH;
2649 }
2650 
2651 #define DEFINE_FAST_GETFIELD(Return, Fieldname, Result)                     \
2652   Return JNICALL jni_fast_Get##Result##Field_wrapper(JNIEnv *env,           \
2653                                                      jobject obj,           \
2654                                                      jfieldID fieldID) {    \
2655     __try {                                                                 \
2656       return (*JNI_FastGetField::jni_fast_Get##Result##Field_fp)(env,       \
2657                                                                  obj,       \
2658                                                                  fieldID);  \
2659     } __except(fastJNIAccessorExceptionFilter((_EXCEPTION_POINTERS*)        \
2660                                               _exception_info())) {         \
2661     }                                                                       \
2662     return 0;                                                               \
2663   }
2664 
2665 DEFINE_FAST_GETFIELD(jboolean, bool,   Boolean)
2666 DEFINE_FAST_GETFIELD(jbyte,    byte,   Byte)
2667 DEFINE_FAST_GETFIELD(jchar,    char,   Char)
2668 DEFINE_FAST_GETFIELD(jshort,   short,  Short)
2669 DEFINE_FAST_GETFIELD(jint,     int,    Int)
2670 DEFINE_FAST_GETFIELD(jlong,    long,   Long)
2671 DEFINE_FAST_GETFIELD(jfloat,   float,  Float)
2672 DEFINE_FAST_GETFIELD(jdouble,  double, Double)
2673 
2674 address os::win32::fast_jni_accessor_wrapper(BasicType type) {
2675   switch (type) {
2676   case T_BOOLEAN: return (address)jni_fast_GetBooleanField_wrapper;
2677   case T_BYTE:    return (address)jni_fast_GetByteField_wrapper;
2678   case T_CHAR:    return (address)jni_fast_GetCharField_wrapper;
2679   case T_SHORT:   return (address)jni_fast_GetShortField_wrapper;
2680   case T_INT:     return (address)jni_fast_GetIntField_wrapper;
2681   case T_LONG:    return (address)jni_fast_GetLongField_wrapper;
2682   case T_FLOAT:   return (address)jni_fast_GetFloatField_wrapper;
2683   case T_DOUBLE:  return (address)jni_fast_GetDoubleField_wrapper;
2684   default:        ShouldNotReachHere();
2685   }
2686   return (address)-1;
2687 }
2688 #endif
2689 
2690 // Virtual Memory
2691 
2692 int os::vm_page_size() { return os::win32::vm_page_size(); }
2693 int os::vm_allocation_granularity() {
2694   return os::win32::vm_allocation_granularity();
2695 }
2696 
2697 // Windows large page support is available on Windows 2003. In order to use
2698 // large page memory, the administrator must first assign additional privilege
2699 // to the user:
2700 //   + select Control Panel -&gt; Administrative Tools -&gt; Local Security Policy
2701 //   + select Local Policies -&gt; User Rights Assignment
2702 //   + double click &quot;Lock pages in memory&quot;, add users and/or groups
2703 //   + reboot
2704 // Note the above steps are needed for administrator as well, as administrators
2705 // by default do not have the privilege to lock pages in memory.
2706 //
2707 // Note about Windows 2003: although the API supports committing large page
2708 // memory on a page-by-page basis and VirtualAlloc() returns success under this
2709 // scenario, I found through experiment it only uses large page if the entire
2710 // memory region is reserved and committed in a single VirtualAlloc() call.
2711 // This makes Windows large page support more or less like Solaris ISM, in
2712 // that the entire heap must be committed upfront. This probably will change
2713 // in the future, if so the code below needs to be revisited.
2714 
2715 #ifndef MEM_LARGE_PAGES
2716   #define MEM_LARGE_PAGES 0x20000000
2717 #endif
2718 
2719 #define VirtualFreeChecked(mem, size, type)                       \
2720   do {                                                            \
2721     bool ret = VirtualFree(mem, size, type);                      \
2722     assert(ret, &quot;Failed to free memory: &quot; PTR_FORMAT, p2i(mem));  \
2723   } while (false)
2724 
2725 // The number of bytes is setup to match 1 pixel and 32 bits per pixel.
2726 static const int gdi_tiny_bitmap_width_bytes = 4;
2727 
2728 static HBITMAP gdi_create_tiny_bitmap(void* mem) {
2729   // The documentation for CreateBitmap states a word-alignment requirement.
2730   STATIC_ASSERT(is_aligned_(gdi_tiny_bitmap_width_bytes, sizeof(WORD)));
2731 
2732   // Some callers use this function to test if memory crossing separate memory
2733   // reservations can be used. Create a height of 2 to make sure that one pixel
2734   // ends up in the first reservation and the other in the second.
2735   int nHeight = 2;
2736 
2737   assert(is_aligned(mem, gdi_tiny_bitmap_width_bytes), &quot;Incorrect alignment&quot;);
2738 
2739   // Width is one pixel and correlates with gdi_tiny_bitmap_width_bytes.
2740   int nWidth = 1;
2741 
2742   // Calculate bit count - will be 32.
2743   UINT nBitCount = gdi_tiny_bitmap_width_bytes / nWidth * BitsPerByte;
2744 
2745   return CreateBitmap(
2746       nWidth,
2747       nHeight,
2748       1,         // nPlanes
2749       nBitCount,
2750       mem);      // lpBits
2751 }
2752 
2753 // It has been found that some of the GDI functions fail under these two situations:
2754 //  1) When used with large pages
2755 //  2) When mem crosses the boundary between two separate memory reservations.
2756 //
2757 // This is a small test used to see if the current GDI implementation is
2758 // susceptible to any of these problems.
2759 static bool gdi_can_use_memory(void* mem) {
2760   HBITMAP bitmap = gdi_create_tiny_bitmap(mem);
2761   if (bitmap != NULL) {
2762     DeleteObject(bitmap);
2763     return true;
2764   }
2765 
2766   // Verify that the bitmap could be created with a normal page.
2767   // If this fails, the testing method above isn&#39;t reliable.
2768 #ifdef ASSERT
2769   void* verify_mem = ::malloc(4 * 1024);
2770   HBITMAP verify_bitmap = gdi_create_tiny_bitmap(verify_mem);
2771   if (verify_bitmap == NULL) {
2772     fatal(&quot;Couldn&#39;t create test bitmap with malloced memory&quot;);
2773   } else {
2774     DeleteObject(verify_bitmap);
2775   }
2776   ::free(verify_mem);
2777 #endif
2778 
2779   return false;
2780 }
2781 
2782 // Test if GDI functions work when memory spans
2783 // two adjacent memory reservations.
2784 static bool gdi_can_use_split_reservation_memory(bool use_large_pages, size_t granule) {
2785   DWORD mem_large_pages = use_large_pages ? MEM_LARGE_PAGES : 0;
2786 
2787   // Find virtual memory range. Two granules for regions and one for alignment.
2788   void* reserved = VirtualAlloc(NULL,
2789                                 granule * 3,
2790                                 MEM_RESERVE,
2791                                 PAGE_NOACCESS);
2792   if (reserved == NULL) {
2793     // Can&#39;t proceed with test - pessimistically report false
2794     return false;
2795   }
2796   VirtualFreeChecked(reserved, 0, MEM_RELEASE);
2797 
2798   // Ensure proper alignment
2799   void* res0 = align_up(reserved, granule);
2800   void* res1 = (char*)res0 + granule;
2801 
2802   // Reserve and commit the first part
2803   void* mem0 = VirtualAlloc(res0,
2804                             granule,
2805                             MEM_RESERVE|MEM_COMMIT|mem_large_pages,
2806                             PAGE_READWRITE);
2807   if (mem0 != res0) {
2808     // Can&#39;t proceed with test - pessimistically report false
2809     return false;
2810   }
2811 
2812   // Reserve and commit the second part
2813   void* mem1 = VirtualAlloc(res1,
2814                             granule,
2815                             MEM_RESERVE|MEM_COMMIT|mem_large_pages,
2816                             PAGE_READWRITE);
2817   if (mem1 != res1) {
2818     VirtualFreeChecked(mem0, 0, MEM_RELEASE);
2819     // Can&#39;t proceed with test - pessimistically report false
2820     return false;
2821   }
2822 
2823   // Set the bitmap&#39;s bits to point one &quot;width&quot; bytes before, so that
2824   // the bitmap extends across the reservation boundary.
2825   void* bitmapBits = (char*)mem1 - gdi_tiny_bitmap_width_bytes;
2826 
2827   bool success = gdi_can_use_memory(bitmapBits);
2828 
2829   VirtualFreeChecked(mem1, 0, MEM_RELEASE);
2830   VirtualFreeChecked(mem0, 0, MEM_RELEASE);
2831 
2832   return success;
2833 }
2834 
2835 // Container for NUMA node list info
2836 class NUMANodeListHolder {
2837  private:
2838   int *_numa_used_node_list;  // allocated below
2839   int _numa_used_node_count;
2840 
2841   void free_node_list() {
2842     FREE_C_HEAP_ARRAY(int, _numa_used_node_list);
2843   }
2844 
2845  public:
2846   NUMANodeListHolder() {
2847     _numa_used_node_count = 0;
2848     _numa_used_node_list = NULL;
2849     // do rest of initialization in build routine (after function pointers are set up)
2850   }
2851 
2852   ~NUMANodeListHolder() {
2853     free_node_list();
2854   }
2855 
2856   bool build() {
2857     DWORD_PTR proc_aff_mask;
2858     DWORD_PTR sys_aff_mask;
2859     if (!GetProcessAffinityMask(GetCurrentProcess(), &amp;proc_aff_mask, &amp;sys_aff_mask)) return false;
2860     ULONG highest_node_number;
2861     if (!GetNumaHighestNodeNumber(&amp;highest_node_number)) return false;
2862     free_node_list();
2863     _numa_used_node_list = NEW_C_HEAP_ARRAY(int, highest_node_number + 1, mtInternal);
2864     for (unsigned int i = 0; i &lt;= highest_node_number; i++) {
2865       ULONGLONG proc_mask_numa_node;
2866       if (!GetNumaNodeProcessorMask(i, &amp;proc_mask_numa_node)) return false;
2867       if ((proc_aff_mask &amp; proc_mask_numa_node)!=0) {
2868         _numa_used_node_list[_numa_used_node_count++] = i;
2869       }
2870     }
2871     return (_numa_used_node_count &gt; 1);
2872   }
2873 
2874   int get_count() { return _numa_used_node_count; }
2875   int get_node_list_entry(int n) {
2876     // for indexes out of range, returns -1
2877     return (n &lt; _numa_used_node_count ? _numa_used_node_list[n] : -1);
2878   }
2879 
2880 } numa_node_list_holder;
2881 
2882 static size_t _large_page_size = 0;
2883 
2884 static bool request_lock_memory_privilege() {
2885   HANDLE hProcess = OpenProcess(PROCESS_QUERY_INFORMATION, FALSE,
2886                                 os::current_process_id());
2887 
2888   bool success = false;
2889   HANDLE hToken = NULL;
2890   LUID luid;
2891   if (hProcess != NULL &amp;&amp;
2892       OpenProcessToken(hProcess, TOKEN_ADJUST_PRIVILEGES, &amp;hToken) &amp;&amp;
2893       LookupPrivilegeValue(NULL, &quot;SeLockMemoryPrivilege&quot;, &amp;luid)) {
2894 
2895     TOKEN_PRIVILEGES tp;
2896     tp.PrivilegeCount = 1;
2897     tp.Privileges[0].Luid = luid;
2898     tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;
2899 
2900     // AdjustTokenPrivileges() may return TRUE even when it couldn&#39;t change the
2901     // privilege. Check GetLastError() too. See MSDN document.
2902     if (AdjustTokenPrivileges(hToken, false, &amp;tp, sizeof(tp), NULL, NULL) &amp;&amp;
2903         (GetLastError() == ERROR_SUCCESS)) {
2904       success = true;
2905     }
2906   }
2907 
2908   // Cleanup
2909   if (hProcess != NULL) {
2910     CloseHandle(hProcess);
2911   }
2912   if (hToken != NULL) {
2913     CloseHandle(hToken);
2914   }
2915 
2916   return success;
2917 }
2918 
2919 static bool numa_interleaving_init() {
2920   bool success = false;
2921 
2922   // print a warning if UseNUMAInterleaving flag is specified on command line
2923   bool warn_on_failure = !FLAG_IS_DEFAULT(UseNUMAInterleaving);
2924 
2925 #define WARN(msg) if (warn_on_failure) { warning(msg); }
2926 
2927   // NUMAInterleaveGranularity cannot be less than vm_allocation_granularity (or _large_page_size if using large pages)
2928   size_t min_interleave_granularity = UseLargePages ? _large_page_size : os::vm_allocation_granularity();
2929   NUMAInterleaveGranularity = align_up(NUMAInterleaveGranularity, min_interleave_granularity);
2930 
2931   if (!numa_node_list_holder.build()) {
2932     WARN(&quot;Process does not cover multiple NUMA nodes.&quot;);
2933     WARN(&quot;...Ignoring UseNUMAInterleaving flag.&quot;);
2934     return false;
2935   }
2936 
2937   if (!gdi_can_use_split_reservation_memory(UseLargePages, min_interleave_granularity)) {
2938     WARN(&quot;Windows GDI cannot handle split reservations.&quot;);
2939     WARN(&quot;...Ignoring UseNUMAInterleaving flag.&quot;);
2940     return false;
2941   }
2942 
2943   if (log_is_enabled(Debug, os, cpu)) {
2944     Log(os, cpu) log;
2945     log.debug(&quot;NUMA UsedNodeCount=%d, namely &quot;, numa_node_list_holder.get_count());
2946     for (int i = 0; i &lt; numa_node_list_holder.get_count(); i++) {
2947       log.debug(&quot;  %d &quot;, numa_node_list_holder.get_node_list_entry(i));
2948     }
2949   }
2950 
2951 #undef WARN
2952 
2953   return true;
2954 }
2955 
2956 // this routine is used whenever we need to reserve a contiguous VA range
2957 // but we need to make separate VirtualAlloc calls for each piece of the range
2958 // Reasons for doing this:
2959 //  * UseLargePagesIndividualAllocation was set (normally only needed on WS2003 but possible to be set otherwise)
2960 //  * UseNUMAInterleaving requires a separate node for each piece
2961 static char* allocate_pages_individually(size_t bytes, char* addr, DWORD flags,
2962                                          DWORD prot,
2963                                          bool should_inject_error = false) {
2964   char * p_buf;
2965   // note: at setup time we guaranteed that NUMAInterleaveGranularity was aligned up to a page size
2966   size_t page_size = UseLargePages ? _large_page_size : os::vm_allocation_granularity();
2967   size_t chunk_size = UseNUMAInterleaving ? NUMAInterleaveGranularity : page_size;
2968 
2969   // first reserve enough address space in advance since we want to be
2970   // able to break a single contiguous virtual address range into multiple
2971   // large page commits but WS2003 does not allow reserving large page space
2972   // so we just use 4K pages for reserve, this gives us a legal contiguous
2973   // address space. then we will deallocate that reservation, and re alloc
2974   // using large pages
2975   const size_t size_of_reserve = bytes + chunk_size;
2976   if (bytes &gt; size_of_reserve) {
2977     // Overflowed.
2978     return NULL;
2979   }
2980   p_buf = (char *) VirtualAlloc(addr,
2981                                 size_of_reserve,  // size of Reserve
2982                                 MEM_RESERVE,
2983                                 PAGE_READWRITE);
2984   // If reservation failed, return NULL
2985   if (p_buf == NULL) return NULL;
2986   MemTracker::record_virtual_memory_reserve((address)p_buf, size_of_reserve, CALLER_PC);
2987   os::release_memory(p_buf, bytes + chunk_size);
2988 
2989   // we still need to round up to a page boundary (in case we are using large pages)
2990   // but not to a chunk boundary (in case InterleavingGranularity doesn&#39;t align with page size)
2991   // instead we handle this in the bytes_to_rq computation below
2992   p_buf = align_up(p_buf, page_size);
2993 
2994   // now go through and allocate one chunk at a time until all bytes are
2995   // allocated
2996   size_t  bytes_remaining = bytes;
2997   // An overflow of align_up() would have been caught above
2998   // in the calculation of size_of_reserve.
2999   char * next_alloc_addr = p_buf;
3000   HANDLE hProc = GetCurrentProcess();
3001 
3002 #ifdef ASSERT
3003   // Variable for the failure injection
3004   int ran_num = os::random();
3005   size_t fail_after = ran_num % bytes;
3006 #endif
3007 
3008   int count=0;
3009   while (bytes_remaining) {
3010     // select bytes_to_rq to get to the next chunk_size boundary
3011 
3012     size_t bytes_to_rq = MIN2(bytes_remaining, chunk_size - ((size_t)next_alloc_addr % chunk_size));
3013     // Note allocate and commit
3014     char * p_new;
3015 
3016 #ifdef ASSERT
3017     bool inject_error_now = should_inject_error &amp;&amp; (bytes_remaining &lt;= fail_after);
3018 #else
3019     const bool inject_error_now = false;
3020 #endif
3021 
3022     if (inject_error_now) {
3023       p_new = NULL;
3024     } else {
3025       if (!UseNUMAInterleaving) {
3026         p_new = (char *) VirtualAlloc(next_alloc_addr,
3027                                       bytes_to_rq,
3028                                       flags,
3029                                       prot);
3030       } else {
3031         // get the next node to use from the used_node_list
3032         assert(numa_node_list_holder.get_count() &gt; 0, &quot;Multiple NUMA nodes expected&quot;);
3033         DWORD node = numa_node_list_holder.get_node_list_entry(count % numa_node_list_holder.get_count());
3034         p_new = (char *)VirtualAllocExNuma(hProc, next_alloc_addr, bytes_to_rq, flags, prot, node);
3035       }
3036     }
3037 
3038     if (p_new == NULL) {
3039       // Free any allocated pages
3040       if (next_alloc_addr &gt; p_buf) {
3041         // Some memory was committed so release it.
3042         size_t bytes_to_release = bytes - bytes_remaining;
3043         // NMT has yet to record any individual blocks, so it
3044         // need to create a dummy &#39;reserve&#39; record to match
3045         // the release.
3046         MemTracker::record_virtual_memory_reserve((address)p_buf,
3047                                                   bytes_to_release, CALLER_PC);
3048         os::release_memory(p_buf, bytes_to_release);
3049       }
3050 #ifdef ASSERT
3051       if (should_inject_error) {
3052         log_develop_debug(pagesize)(&quot;Reserving pages individually failed.&quot;);
3053       }
3054 #endif
3055       return NULL;
3056     }
3057 
3058     bytes_remaining -= bytes_to_rq;
3059     next_alloc_addr += bytes_to_rq;
3060     count++;
3061   }
3062   // Although the memory is allocated individually, it is returned as one.
3063   // NMT records it as one block.
3064   if ((flags &amp; MEM_COMMIT) != 0) {
3065     MemTracker::record_virtual_memory_reserve_and_commit((address)p_buf, bytes, CALLER_PC);
3066   } else {
3067     MemTracker::record_virtual_memory_reserve((address)p_buf, bytes, CALLER_PC);
3068   }
3069 
3070   // made it this far, success
3071   return p_buf;
3072 }
3073 
3074 static size_t large_page_init_decide_size() {
3075   // print a warning if any large page related flag is specified on command line
3076   bool warn_on_failure = !FLAG_IS_DEFAULT(UseLargePages) ||
3077                          !FLAG_IS_DEFAULT(LargePageSizeInBytes);
3078 
3079 #define WARN(msg) if (warn_on_failure) { warning(msg); }
3080 
3081   if (!request_lock_memory_privilege()) {
3082     WARN(&quot;JVM cannot use large page memory because it does not have enough privilege to lock pages in memory.&quot;);
3083     return 0;
3084   }
3085 
3086   size_t size = GetLargePageMinimum();
3087   if (size == 0) {
3088     WARN(&quot;Large page is not supported by the processor.&quot;);
3089     return 0;
3090   }
3091 
3092 #if defined(IA32) || defined(AMD64)
3093   if (size &gt; 4*M || LargePageSizeInBytes &gt; 4*M) {
3094     WARN(&quot;JVM cannot use large pages bigger than 4mb.&quot;);
3095     return 0;
3096   }
3097 #endif
3098 
3099   if (LargePageSizeInBytes &gt; 0 &amp;&amp; LargePageSizeInBytes % size == 0) {
3100     size = LargePageSizeInBytes;
3101   }
3102 
3103   // Now test allocating a page
3104   void* large_page = VirtualAlloc(NULL,
3105                                   size,
3106                                   MEM_RESERVE|MEM_COMMIT|MEM_LARGE_PAGES,
3107                                   PAGE_READWRITE);
3108   if (large_page == NULL) {
3109     WARN(&quot;JVM cannot allocate one single large page.&quot;);
3110     return 0;
3111   }
3112 
3113   // Detect if GDI can use memory backed by large pages
3114   if (!gdi_can_use_memory(large_page)) {
3115     WARN(&quot;JVM cannot use large pages because of bug in Windows GDI.&quot;);
3116     return 0;
3117   }
3118 
3119   // Release test page
3120   VirtualFreeChecked(large_page, 0, MEM_RELEASE);
3121 
3122 #undef WARN
3123 
3124   return size;
3125 }
3126 
3127 void os::large_page_init() {
3128   if (!UseLargePages) {
3129     return;
3130   }
3131 
3132   _large_page_size = large_page_init_decide_size();
3133 
3134   const size_t default_page_size = (size_t) vm_page_size();
3135   if (_large_page_size &gt; default_page_size) {
3136     _page_sizes[0] = _large_page_size;
3137     _page_sizes[1] = default_page_size;
3138     _page_sizes[2] = 0;
3139   }
3140 
3141   UseLargePages = _large_page_size != 0;
3142 
3143   if (UseLargePages &amp;&amp; UseLargePagesIndividualAllocation) {
3144     if (!gdi_can_use_split_reservation_memory(true /* use_large_pages */, _large_page_size)) {
3145       if (FLAG_IS_CMDLINE(UseLargePagesIndividualAllocation)) {
3146         warning(&quot;Windows GDI cannot handle split reservations.&quot;);
3147         warning(&quot;...Ignoring UseLargePagesIndividualAllocation flag.&quot;);
3148       }
3149       UseLargePagesIndividualAllocation = false;
3150     }
3151   }
3152 }
3153 
3154 int os::create_file_for_heap(const char* dir) {
3155 
3156   const char name_template[] = &quot;/jvmheap.XXXXXX&quot;;
3157 
3158   size_t fullname_len = strlen(dir) + strlen(name_template);
3159   char *fullname = (char*)os::malloc(fullname_len + 1, mtInternal);
3160   if (fullname == NULL) {
3161     vm_exit_during_initialization(err_msg(&quot;Malloc failed during creation of backing file for heap (%s)&quot;, os::strerror(errno)));
3162     return -1;
3163   }
3164   int n = snprintf(fullname, fullname_len + 1, &quot;%s%s&quot;, dir, name_template);
3165   assert((size_t)n == fullname_len, &quot;Unexpected number of characters in string&quot;);
3166 
3167   os::native_path(fullname);
3168 
3169   char *path = _mktemp(fullname);
3170   if (path == NULL) {
3171     warning(&quot;_mktemp could not create file name from template %s (%s)&quot;, fullname, os::strerror(errno));
3172     os::free(fullname);
3173     return -1;
3174   }
3175 
3176   int fd = _open(path, O_RDWR | O_CREAT | O_TEMPORARY | O_EXCL, S_IWRITE | S_IREAD);
3177 
3178   os::free(fullname);
3179   if (fd &lt; 0) {
3180     warning(&quot;Problem opening file for heap (%s)&quot;, os::strerror(errno));
3181     return -1;
3182   }
3183   return fd;
3184 }
3185 
3186 // If &#39;base&#39; is not NULL, function will return NULL if it cannot get &#39;base&#39;
3187 char* os::map_memory_to_file(char* base, size_t size, int fd) {
3188   assert(fd != -1, &quot;File descriptor is not valid&quot;);
3189 
3190   HANDLE fh = (HANDLE)_get_osfhandle(fd);
3191 #ifdef _LP64
3192   HANDLE fileMapping = CreateFileMapping(fh, NULL, PAGE_READWRITE,
3193     (DWORD)(size &gt;&gt; 32), (DWORD)(size &amp; 0xFFFFFFFF), NULL);
3194 #else
3195   HANDLE fileMapping = CreateFileMapping(fh, NULL, PAGE_READWRITE,
3196     0, (DWORD)size, NULL);
3197 #endif
3198   if (fileMapping == NULL) {
3199     if (GetLastError() == ERROR_DISK_FULL) {
3200       vm_exit_during_initialization(err_msg(&quot;Could not allocate sufficient disk space for Java heap&quot;));
3201     }
3202     else {
3203       vm_exit_during_initialization(err_msg(&quot;Error in mapping Java heap at the given filesystem directory&quot;));
3204     }
3205 
3206     return NULL;
3207   }
3208 
3209   LPVOID addr = MapViewOfFileEx(fileMapping, FILE_MAP_WRITE, 0, 0, size, base);
3210 
3211   CloseHandle(fileMapping);
3212 
3213   return (char*)addr;
3214 }
3215 
3216 char* os::replace_existing_mapping_with_file_mapping(char* base, size_t size, int fd) {
3217   assert(fd != -1, &quot;File descriptor is not valid&quot;);
3218   assert(base != NULL, &quot;Base address cannot be NULL&quot;);
3219 
3220   release_memory(base, size);
3221   return map_memory_to_file(base, size, fd);
3222 }
3223 
3224 // On win32, one cannot release just a part of reserved memory, it&#39;s an
3225 // all or nothing deal.  When we split a reservation, we must break the
3226 // reservation into two reservations.
3227 void os::split_reserved_memory(char *base, size_t size, size_t split) {
3228 
3229   char* const split_address = base + split;
3230   assert(size &gt; 0, &quot;Sanity&quot;);
3231   assert(size &gt; split, &quot;Sanity&quot;);
3232   assert(split &gt; 0, &quot;Sanity&quot;);
3233   assert(is_aligned(base, os::vm_allocation_granularity()), &quot;Sanity&quot;);
3234   assert(is_aligned(split_address, os::vm_allocation_granularity()), &quot;Sanity&quot;);
3235 
3236   release_memory(base, size);
3237   reserve_memory(split, base);
3238   reserve_memory(size - split, split_address);
3239 
3240 }
3241 
3242 // Multiple threads can race in this code but it&#39;s not possible to unmap small sections of
3243 // virtual space to get requested alignment, like posix-like os&#39;s.
3244 // Windows prevents multiple thread from remapping over each other so this loop is thread-safe.
3245 char* os::reserve_memory_aligned(size_t size, size_t alignment, int file_desc) {
3246   assert((alignment &amp; (os::vm_allocation_granularity() - 1)) == 0,
3247          &quot;Alignment must be a multiple of allocation granularity (page size)&quot;);
3248   assert((size &amp; (alignment -1)) == 0, &quot;size must be &#39;alignment&#39; aligned&quot;);
3249 
3250   size_t extra_size = size + alignment;
3251   assert(extra_size &gt;= size, &quot;overflow, size is too large to allow alignment&quot;);
3252 
3253   char* aligned_base = NULL;
3254 
3255   do {
3256     char* extra_base = os::reserve_memory(extra_size, NULL, alignment, file_desc);
3257     if (extra_base == NULL) {
3258       return NULL;
3259     }
3260     // Do manual alignment
3261     aligned_base = align_up(extra_base, alignment);
3262 
3263     if (file_desc != -1) {
3264       os::unmap_memory(extra_base, extra_size);
3265     } else {
3266       os::release_memory(extra_base, extra_size);
3267     }
3268 
3269     aligned_base = os::reserve_memory(size, aligned_base, 0, file_desc);
3270 
3271   } while (aligned_base == NULL);
3272 
3273   return aligned_base;
3274 }
3275 
3276 char* os::pd_reserve_memory(size_t bytes, char* addr, size_t alignment_hint) {
3277   assert((size_t)addr % os::vm_allocation_granularity() == 0,
3278          &quot;reserve alignment&quot;);
3279   assert(bytes % os::vm_page_size() == 0, &quot;reserve page size&quot;);
3280   char* res;
3281   // note that if UseLargePages is on, all the areas that require interleaving
3282   // will go thru reserve_memory_special rather than thru here.
3283   bool use_individual = (UseNUMAInterleaving &amp;&amp; !UseLargePages);
3284   if (!use_individual) {
3285     res = (char*)VirtualAlloc(addr, bytes, MEM_RESERVE, PAGE_READWRITE);
3286   } else {
3287     elapsedTimer reserveTimer;
3288     if (Verbose &amp;&amp; PrintMiscellaneous) reserveTimer.start();
3289     // in numa interleaving, we have to allocate pages individually
3290     // (well really chunks of NUMAInterleaveGranularity size)
3291     res = allocate_pages_individually(bytes, addr, MEM_RESERVE, PAGE_READWRITE);
3292     if (res == NULL) {
3293       warning(&quot;NUMA page allocation failed&quot;);
3294     }
3295     if (Verbose &amp;&amp; PrintMiscellaneous) {
3296       reserveTimer.stop();
3297       tty-&gt;print_cr(&quot;reserve_memory of %Ix bytes took &quot; JLONG_FORMAT &quot; ms (&quot; JLONG_FORMAT &quot; ticks)&quot;, bytes,
3298                     reserveTimer.milliseconds(), reserveTimer.ticks());
3299     }
3300   }
3301   assert(res == NULL || addr == NULL || addr == res,
3302          &quot;Unexpected address from reserve.&quot;);
3303 
3304   return res;
3305 }
3306 
3307 // Reserve memory at an arbitrary address, only if that area is
3308 // available (and not reserved for something else).
3309 char* os::pd_attempt_reserve_memory_at(size_t bytes, char* requested_addr) {
3310   // Windows os::reserve_memory() fails of the requested address range is
3311   // not avilable.
3312   return reserve_memory(bytes, requested_addr);
3313 }
3314 
3315 char* os::pd_attempt_reserve_memory_at(size_t bytes, char* requested_addr, int file_desc) {
3316   assert(file_desc &gt;= 0, &quot;file_desc is not valid&quot;);
3317   return map_memory_to_file(requested_addr, bytes, file_desc);
3318 }
3319 
3320 size_t os::large_page_size() {
3321   return _large_page_size;
3322 }
3323 
3324 bool os::can_commit_large_page_memory() {
3325   // Windows only uses large page memory when the entire region is reserved
3326   // and committed in a single VirtualAlloc() call. This may change in the
3327   // future, but with Windows 2003 it&#39;s not possible to commit on demand.
3328   return false;
3329 }
3330 
3331 bool os::can_execute_large_page_memory() {
3332   return true;
3333 }
3334 
3335 char* os::pd_reserve_memory_special(size_t bytes, size_t alignment, char* addr,
3336                                     bool exec) {
3337   assert(UseLargePages, &quot;only for large pages&quot;);
3338 
3339   if (!is_aligned(bytes, os::large_page_size()) || alignment &gt; os::large_page_size()) {
3340     return NULL; // Fallback to small pages.
3341   }
3342 
3343   const DWORD prot = exec ? PAGE_EXECUTE_READWRITE : PAGE_READWRITE;
3344   const DWORD flags = MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES;
3345 
3346   // with large pages, there are two cases where we need to use Individual Allocation
3347   // 1) the UseLargePagesIndividualAllocation flag is set (set by default on WS2003)
3348   // 2) NUMA Interleaving is enabled, in which case we use a different node for each page
3349   if (UseLargePagesIndividualAllocation || UseNUMAInterleaving) {
3350     log_debug(pagesize)(&quot;Reserving large pages individually.&quot;);
3351 
3352     char * p_buf = allocate_pages_individually(bytes, addr, flags, prot, LargePagesIndividualAllocationInjectError);
3353     if (p_buf == NULL) {
3354       // give an appropriate warning message
3355       if (UseNUMAInterleaving) {
3356         warning(&quot;NUMA large page allocation failed, UseLargePages flag ignored&quot;);
3357       }
3358       if (UseLargePagesIndividualAllocation) {
3359         warning(&quot;Individually allocated large pages failed, &quot;
3360                 &quot;use -XX:-UseLargePagesIndividualAllocation to turn off&quot;);
3361       }
3362       return NULL;
3363     }
3364 
3365     return p_buf;
3366 
3367   } else {
3368     log_debug(pagesize)(&quot;Reserving large pages in a single large chunk.&quot;);
3369 
3370     // normal policy just allocate it all at once
3371     DWORD flag = MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES;
3372     char * res = (char *)VirtualAlloc(addr, bytes, flag, prot);
3373 
3374     return res;
3375   }
3376 }
3377 
3378 bool os::pd_release_memory_special(char* base, size_t bytes) {
3379   assert(base != NULL, &quot;Sanity check&quot;);
3380   return pd_release_memory(base, bytes);
3381 }
3382 
3383 void os::print_statistics() {
3384 }
3385 
3386 static void warn_fail_commit_memory(char* addr, size_t bytes, bool exec) {
3387   int err = os::get_last_error();
3388   char buf[256];
3389   size_t buf_len = os::lasterror(buf, sizeof(buf));
3390   warning(&quot;INFO: os::commit_memory(&quot; PTR_FORMAT &quot;, &quot; SIZE_FORMAT
3391           &quot;, %d) failed; error=&#39;%s&#39; (DOS error/errno=%d)&quot;, addr, bytes,
3392           exec, buf_len != 0 ? buf : &quot;&lt;no_error_string&gt;&quot;, err);
3393 }
3394 
3395 bool os::pd_commit_memory(char* addr, size_t bytes, bool exec) {
3396   if (bytes == 0) {
3397     // Don&#39;t bother the OS with noops.
3398     return true;
3399   }
3400   assert((size_t) addr % os::vm_page_size() == 0, &quot;commit on page boundaries&quot;);
3401   assert(bytes % os::vm_page_size() == 0, &quot;commit in page-sized chunks&quot;);
3402   // Don&#39;t attempt to print anything if the OS call fails. We&#39;re
3403   // probably low on resources, so the print itself may cause crashes.
3404 
3405   // unless we have NUMAInterleaving enabled, the range of a commit
3406   // is always within a reserve covered by a single VirtualAlloc
3407   // in that case we can just do a single commit for the requested size
3408   if (!UseNUMAInterleaving) {
3409     if (VirtualAlloc(addr, bytes, MEM_COMMIT, PAGE_READWRITE) == NULL) {
3410       NOT_PRODUCT(warn_fail_commit_memory(addr, bytes, exec);)
3411       return false;
3412     }
3413     if (exec) {
3414       DWORD oldprot;
3415       // Windows doc says to use VirtualProtect to get execute permissions
3416       if (!VirtualProtect(addr, bytes, PAGE_EXECUTE_READWRITE, &amp;oldprot)) {
3417         NOT_PRODUCT(warn_fail_commit_memory(addr, bytes, exec);)
3418         return false;
3419       }
3420     }
3421     return true;
3422   } else {
3423 
3424     // when NUMAInterleaving is enabled, the commit might cover a range that
3425     // came from multiple VirtualAlloc reserves (using allocate_pages_individually).
3426     // VirtualQuery can help us determine that.  The RegionSize that VirtualQuery
3427     // returns represents the number of bytes that can be committed in one step.
3428     size_t bytes_remaining = bytes;
3429     char * next_alloc_addr = addr;
3430     while (bytes_remaining &gt; 0) {
3431       MEMORY_BASIC_INFORMATION alloc_info;
3432       VirtualQuery(next_alloc_addr, &amp;alloc_info, sizeof(alloc_info));
3433       size_t bytes_to_rq = MIN2(bytes_remaining, (size_t)alloc_info.RegionSize);
3434       if (VirtualAlloc(next_alloc_addr, bytes_to_rq, MEM_COMMIT,
3435                        PAGE_READWRITE) == NULL) {
3436         NOT_PRODUCT(warn_fail_commit_memory(next_alloc_addr, bytes_to_rq,
3437                                             exec);)
3438         return false;
3439       }
3440       if (exec) {
3441         DWORD oldprot;
3442         if (!VirtualProtect(next_alloc_addr, bytes_to_rq,
3443                             PAGE_EXECUTE_READWRITE, &amp;oldprot)) {
3444           NOT_PRODUCT(warn_fail_commit_memory(next_alloc_addr, bytes_to_rq,
3445                                               exec);)
3446           return false;
3447         }
3448       }
3449       bytes_remaining -= bytes_to_rq;
3450       next_alloc_addr += bytes_to_rq;
3451     }
3452   }
3453   // if we made it this far, return true
3454   return true;
3455 }
3456 
3457 bool os::pd_commit_memory(char* addr, size_t size, size_t alignment_hint,
3458                           bool exec) {
3459   // alignment_hint is ignored on this OS
3460   return pd_commit_memory(addr, size, exec);
3461 }
3462 
3463 void os::pd_commit_memory_or_exit(char* addr, size_t size, bool exec,
3464                                   const char* mesg) {
3465   assert(mesg != NULL, &quot;mesg must be specified&quot;);
3466   if (!pd_commit_memory(addr, size, exec)) {
3467     warn_fail_commit_memory(addr, size, exec);
3468     vm_exit_out_of_memory(size, OOM_MMAP_ERROR, &quot;%s&quot;, mesg);
3469   }
3470 }
3471 
3472 void os::pd_commit_memory_or_exit(char* addr, size_t size,
3473                                   size_t alignment_hint, bool exec,
3474                                   const char* mesg) {
3475   // alignment_hint is ignored on this OS
3476   pd_commit_memory_or_exit(addr, size, exec, mesg);
3477 }
3478 
3479 bool os::pd_uncommit_memory(char* addr, size_t bytes) {
3480   if (bytes == 0) {
3481     // Don&#39;t bother the OS with noops.
3482     return true;
3483   }
3484   assert((size_t) addr % os::vm_page_size() == 0, &quot;uncommit on page boundaries&quot;);
3485   assert(bytes % os::vm_page_size() == 0, &quot;uncommit in page-sized chunks&quot;);
3486   return (VirtualFree(addr, bytes, MEM_DECOMMIT) != 0);
3487 }
3488 
3489 bool os::pd_release_memory(char* addr, size_t bytes) {
3490   return VirtualFree(addr, 0, MEM_RELEASE) != 0;
3491 }
3492 
3493 bool os::pd_create_stack_guard_pages(char* addr, size_t size) {
3494   return os::commit_memory(addr, size, !ExecMem);
3495 }
3496 
3497 bool os::remove_stack_guard_pages(char* addr, size_t size) {
3498   return os::uncommit_memory(addr, size);
3499 }
3500 
3501 static bool protect_pages_individually(char* addr, size_t bytes, unsigned int p, DWORD *old_status) {
3502   uint count = 0;
3503   bool ret = false;
3504   size_t bytes_remaining = bytes;
3505   char * next_protect_addr = addr;
3506 
3507   // Use VirtualQuery() to get the chunk size.
3508   while (bytes_remaining) {
3509     MEMORY_BASIC_INFORMATION alloc_info;
3510     if (VirtualQuery(next_protect_addr, &amp;alloc_info, sizeof(alloc_info)) == 0) {
3511       return false;
3512     }
3513 
3514     size_t bytes_to_protect = MIN2(bytes_remaining, (size_t)alloc_info.RegionSize);
3515     // We used different API at allocate_pages_individually() based on UseNUMAInterleaving,
3516     // but we don&#39;t distinguish here as both cases are protected by same API.
3517     ret = VirtualProtect(next_protect_addr, bytes_to_protect, p, old_status) != 0;
3518     warning(&quot;Failed protecting pages individually for chunk #%u&quot;, count);
3519     if (!ret) {
3520       return false;
3521     }
3522 
3523     bytes_remaining -= bytes_to_protect;
3524     next_protect_addr += bytes_to_protect;
3525     count++;
3526   }
3527   return ret;
3528 }
3529 
3530 // Set protections specified
3531 bool os::protect_memory(char* addr, size_t bytes, ProtType prot,
3532                         bool is_committed) {
3533   unsigned int p = 0;
3534   switch (prot) {
3535   case MEM_PROT_NONE: p = PAGE_NOACCESS; break;
3536   case MEM_PROT_READ: p = PAGE_READONLY; break;
3537   case MEM_PROT_RW:   p = PAGE_READWRITE; break;
3538   case MEM_PROT_RWX:  p = PAGE_EXECUTE_READWRITE; break;
3539   default:
3540     ShouldNotReachHere();
3541   }
3542 
3543   DWORD old_status;
3544 
3545   // Strange enough, but on Win32 one can change protection only for committed
3546   // memory, not a big deal anyway, as bytes less or equal than 64K
3547   if (!is_committed) {
3548     commit_memory_or_exit(addr, bytes, prot == MEM_PROT_RWX,
3549                           &quot;cannot commit protection page&quot;);
3550   }
3551   // One cannot use os::guard_memory() here, as on Win32 guard page
3552   // have different (one-shot) semantics, from MSDN on PAGE_GUARD:
3553   //
3554   // Pages in the region become guard pages. Any attempt to access a guard page
3555   // causes the system to raise a STATUS_GUARD_PAGE exception and turn off
3556   // the guard page status. Guard pages thus act as a one-time access alarm.
3557   bool ret;
3558   if (UseNUMAInterleaving) {
3559     // If UseNUMAInterleaving is enabled, the pages may have been allocated a chunk at a time,
3560     // so we must protect the chunks individually.
3561     ret = protect_pages_individually(addr, bytes, p, &amp;old_status);
3562   } else {
3563     ret = VirtualProtect(addr, bytes, p, &amp;old_status) != 0;
3564   }
3565 #ifdef ASSERT
3566   if (!ret) {
3567     int err = os::get_last_error();
3568     char buf[256];
3569     size_t buf_len = os::lasterror(buf, sizeof(buf));
3570     warning(&quot;INFO: os::protect_memory(&quot; PTR_FORMAT &quot;, &quot; SIZE_FORMAT
3571           &quot;) failed; error=&#39;%s&#39; (DOS error/errno=%d)&quot;, addr, bytes,
3572           buf_len != 0 ? buf : &quot;&lt;no_error_string&gt;&quot;, err);
3573   }
3574 #endif
3575   return ret;
3576 }
3577 
3578 bool os::guard_memory(char* addr, size_t bytes) {
3579   DWORD old_status;
3580   return VirtualProtect(addr, bytes, PAGE_READWRITE | PAGE_GUARD, &amp;old_status) != 0;
3581 }
3582 
3583 bool os::unguard_memory(char* addr, size_t bytes) {
3584   DWORD old_status;
3585   return VirtualProtect(addr, bytes, PAGE_READWRITE, &amp;old_status) != 0;
3586 }
3587 
3588 void os::pd_realign_memory(char *addr, size_t bytes, size_t alignment_hint) { }
3589 void os::pd_free_memory(char *addr, size_t bytes, size_t alignment_hint) { }
3590 void os::numa_make_global(char *addr, size_t bytes)    { }
3591 void os::numa_make_local(char *addr, size_t bytes, int lgrp_hint)    { }
3592 bool os::numa_topology_changed()                       { return false; }
3593 size_t os::numa_get_groups_num()                       { return MAX2(numa_node_list_holder.get_count(), 1); }
3594 int os::numa_get_group_id()                            { return 0; }
3595 size_t os::numa_get_leaf_groups(int *ids, size_t size) {
3596   if (numa_node_list_holder.get_count() == 0 &amp;&amp; size &gt; 0) {
3597     // Provide an answer for UMA systems
3598     ids[0] = 0;
3599     return 1;
3600   } else {
3601     // check for size bigger than actual groups_num
3602     size = MIN2(size, numa_get_groups_num());
3603     for (int i = 0; i &lt; (int)size; i++) {
3604       ids[i] = numa_node_list_holder.get_node_list_entry(i);
3605     }
3606     return size;
3607   }
3608 }
3609 
3610 int os::numa_get_group_id_for_address(const void* address) {
3611   return 0;
3612 }
3613 
3614 bool os::get_page_info(char *start, page_info* info) {
3615   return false;
3616 }
3617 
3618 char *os::scan_pages(char *start, char* end, page_info* page_expected,
3619                      page_info* page_found) {
3620   return end;
3621 }
3622 
3623 char* os::non_memory_address_word() {
3624   // Must never look like an address returned by reserve_memory,
3625   // even in its subfields (as defined by the CPU immediate fields,
3626   // if the CPU splits constants across multiple instructions).
3627   return (char*)-1;
3628 }
3629 
3630 #define MAX_ERROR_COUNT 100
3631 #define SYS_THREAD_ERROR 0xffffffffUL
3632 
3633 void os::pd_start_thread(Thread* thread) {
3634   DWORD ret = ResumeThread(thread-&gt;osthread()-&gt;thread_handle());
3635   // Returns previous suspend state:
3636   // 0:  Thread was not suspended
3637   // 1:  Thread is running now
3638   // &gt;1: Thread is still suspended.
3639   assert(ret != SYS_THREAD_ERROR, &quot;StartThread failed&quot;); // should propagate back
3640 }
3641 
3642 
3643 // Short sleep, direct OS call.
3644 //
3645 // ms = 0, means allow others (if any) to run.
3646 //
3647 void os::naked_short_sleep(jlong ms) {
3648   assert(ms &lt; 1000, &quot;Un-interruptable sleep, short time use only&quot;);
3649   Sleep(ms);
3650 }
3651 
3652 // Windows does not provide sleep functionality with nanosecond resolution, so we
3653 // try to approximate this with spinning combined with yielding if another thread
3654 // is ready to run on the current processor.
3655 void os::naked_short_nanosleep(jlong ns) {
3656   assert(ns &gt; -1 &amp;&amp; ns &lt; NANOUNITS, &quot;Un-interruptable sleep, short time use only&quot;);
3657 
3658   int64_t start = os::javaTimeNanos();
3659   do {
3660     if (SwitchToThread() == 0) {
3661       // Nothing else is ready to run on this cpu, spin a little
3662       SpinPause();
3663     }
3664   } while (os::javaTimeNanos() - start &lt; ns);
3665 }
3666 
3667 // Sleep forever; naked call to OS-specific sleep; use with CAUTION
3668 void os::infinite_sleep() {
3669   while (true) {    // sleep forever ...
3670     Sleep(100000);  // ... 100 seconds at a time
3671   }
3672 }
3673 
3674 typedef BOOL (WINAPI * STTSignature)(void);
3675 
3676 void os::naked_yield() {
3677   // Consider passing back the return value from SwitchToThread().
3678   SwitchToThread();
3679 }
3680 
3681 // Win32 only gives you access to seven real priorities at a time,
3682 // so we compress Java&#39;s ten down to seven.  It would be better
3683 // if we dynamically adjusted relative priorities.
3684 
3685 int os::java_to_os_priority[CriticalPriority + 1] = {
3686   THREAD_PRIORITY_IDLE,                         // 0  Entry should never be used
3687   THREAD_PRIORITY_LOWEST,                       // 1  MinPriority
3688   THREAD_PRIORITY_LOWEST,                       // 2
3689   THREAD_PRIORITY_BELOW_NORMAL,                 // 3
3690   THREAD_PRIORITY_BELOW_NORMAL,                 // 4
3691   THREAD_PRIORITY_NORMAL,                       // 5  NormPriority
3692   THREAD_PRIORITY_NORMAL,                       // 6
3693   THREAD_PRIORITY_ABOVE_NORMAL,                 // 7
3694   THREAD_PRIORITY_ABOVE_NORMAL,                 // 8
3695   THREAD_PRIORITY_HIGHEST,                      // 9  NearMaxPriority
3696   THREAD_PRIORITY_HIGHEST,                      // 10 MaxPriority
3697   THREAD_PRIORITY_HIGHEST                       // 11 CriticalPriority
3698 };
3699 
3700 int prio_policy1[CriticalPriority + 1] = {
3701   THREAD_PRIORITY_IDLE,                         // 0  Entry should never be used
3702   THREAD_PRIORITY_LOWEST,                       // 1  MinPriority
3703   THREAD_PRIORITY_LOWEST,                       // 2
3704   THREAD_PRIORITY_BELOW_NORMAL,                 // 3
3705   THREAD_PRIORITY_BELOW_NORMAL,                 // 4
3706   THREAD_PRIORITY_NORMAL,                       // 5  NormPriority
3707   THREAD_PRIORITY_ABOVE_NORMAL,                 // 6
3708   THREAD_PRIORITY_ABOVE_NORMAL,                 // 7
3709   THREAD_PRIORITY_HIGHEST,                      // 8
3710   THREAD_PRIORITY_HIGHEST,                      // 9  NearMaxPriority
3711   THREAD_PRIORITY_TIME_CRITICAL,                // 10 MaxPriority
3712   THREAD_PRIORITY_TIME_CRITICAL                 // 11 CriticalPriority
3713 };
3714 
3715 static int prio_init() {
3716   // If ThreadPriorityPolicy is 1, switch tables
3717   if (ThreadPriorityPolicy == 1) {
3718     int i;
3719     for (i = 0; i &lt; CriticalPriority + 1; i++) {
3720       os::java_to_os_priority[i] = prio_policy1[i];
3721     }
3722   }
3723   if (UseCriticalJavaThreadPriority) {
3724     os::java_to_os_priority[MaxPriority] = os::java_to_os_priority[CriticalPriority];
3725   }
3726   return 0;
3727 }
3728 
3729 OSReturn os::set_native_priority(Thread* thread, int priority) {
3730   if (!UseThreadPriorities) return OS_OK;
3731   bool ret = SetThreadPriority(thread-&gt;osthread()-&gt;thread_handle(), priority) != 0;
3732   return ret ? OS_OK : OS_ERR;
3733 }
3734 
3735 OSReturn os::get_native_priority(const Thread* const thread,
3736                                  int* priority_ptr) {
3737   if (!UseThreadPriorities) {
3738     *priority_ptr = java_to_os_priority[NormPriority];
3739     return OS_OK;
3740   }
3741   int os_prio = GetThreadPriority(thread-&gt;osthread()-&gt;thread_handle());
3742   if (os_prio == THREAD_PRIORITY_ERROR_RETURN) {
3743     assert(false, &quot;GetThreadPriority failed&quot;);
3744     return OS_ERR;
3745   }
3746   *priority_ptr = os_prio;
3747   return OS_OK;
3748 }
3749 
3750 // GetCurrentThreadId() returns DWORD
3751 intx os::current_thread_id()  { return GetCurrentThreadId(); }
3752 
3753 static int _initial_pid = 0;
3754 
3755 int os::current_process_id() {
3756   return (_initial_pid ? _initial_pid : _getpid());
3757 }
3758 
3759 int    os::win32::_vm_page_size              = 0;
3760 int    os::win32::_vm_allocation_granularity = 0;
3761 int    os::win32::_processor_type            = 0;
3762 // Processor level is not available on non-NT systems, use vm_version instead
3763 int    os::win32::_processor_level           = 0;
3764 julong os::win32::_physical_memory           = 0;
3765 size_t os::win32::_default_stack_size        = 0;
3766 
3767 intx          os::win32::_os_thread_limit    = 0;
3768 volatile intx os::win32::_os_thread_count    = 0;
3769 
3770 bool   os::win32::_is_windows_server         = false;
3771 
3772 // 6573254
3773 // Currently, the bug is observed across all the supported Windows releases,
3774 // including the latest one (as of this writing - Windows Server 2012 R2)
3775 bool   os::win32::_has_exit_bug              = true;
3776 
3777 void os::win32::initialize_system_info() {
3778   SYSTEM_INFO si;
3779   GetSystemInfo(&amp;si);
3780   _vm_page_size    = si.dwPageSize;
3781   _vm_allocation_granularity = si.dwAllocationGranularity;
3782   _processor_type  = si.dwProcessorType;
3783   _processor_level = si.wProcessorLevel;
3784   set_processor_count(si.dwNumberOfProcessors);
3785 
3786   MEMORYSTATUSEX ms;
3787   ms.dwLength = sizeof(ms);
3788 
3789   // also returns dwAvailPhys (free physical memory bytes), dwTotalVirtual, dwAvailVirtual,
3790   // dwMemoryLoad (% of memory in use)
3791   GlobalMemoryStatusEx(&amp;ms);
3792   _physical_memory = ms.ullTotalPhys;
3793 
3794   if (FLAG_IS_DEFAULT(MaxRAM)) {
3795     // Adjust MaxRAM according to the maximum virtual address space available.
3796     FLAG_SET_DEFAULT(MaxRAM, MIN2(MaxRAM, (uint64_t) ms.ullTotalVirtual));
3797   }
3798 
3799   OSVERSIONINFOEX oi;
3800   oi.dwOSVersionInfoSize = sizeof(OSVERSIONINFOEX);
3801   GetVersionEx((OSVERSIONINFO*)&amp;oi);
3802   switch (oi.dwPlatformId) {
3803   case VER_PLATFORM_WIN32_NT:
3804     {
3805       int os_vers = oi.dwMajorVersion * 1000 + oi.dwMinorVersion;
3806       if (oi.wProductType == VER_NT_DOMAIN_CONTROLLER ||
3807           oi.wProductType == VER_NT_SERVER) {
3808         _is_windows_server = true;
3809       }
3810     }
3811     break;
3812   default: fatal(&quot;Unknown platform&quot;);
3813   }
3814 
3815   _default_stack_size = os::current_stack_size();
3816   assert(_default_stack_size &gt; (size_t) _vm_page_size, &quot;invalid stack size&quot;);
3817   assert((_default_stack_size &amp; (_vm_page_size - 1)) == 0,
3818          &quot;stack size not a multiple of page size&quot;);
3819 
3820   initialize_performance_counter();
3821 }
3822 
3823 
3824 HINSTANCE os::win32::load_Windows_dll(const char* name, char *ebuf,
3825                                       int ebuflen) {
3826   char path[MAX_PATH];
3827   DWORD size;
3828   DWORD pathLen = (DWORD)sizeof(path);
3829   HINSTANCE result = NULL;
3830 
3831   // only allow library name without path component
3832   assert(strchr(name, &#39;\\&#39;) == NULL, &quot;path not allowed&quot;);
3833   assert(strchr(name, &#39;:&#39;) == NULL, &quot;path not allowed&quot;);
3834   if (strchr(name, &#39;\\&#39;) != NULL || strchr(name, &#39;:&#39;) != NULL) {
3835     jio_snprintf(ebuf, ebuflen,
3836                  &quot;Invalid parameter while calling os::win32::load_windows_dll(): cannot take path: %s&quot;, name);
3837     return NULL;
3838   }
3839 
3840   // search system directory
3841   if ((size = GetSystemDirectory(path, pathLen)) &gt; 0) {
3842     if (size &gt;= pathLen) {
3843       return NULL; // truncated
3844     }
3845     if (jio_snprintf(path + size, pathLen - size, &quot;\\%s&quot;, name) == -1) {
3846       return NULL; // truncated
3847     }
3848     if ((result = (HINSTANCE)os::dll_load(path, ebuf, ebuflen)) != NULL) {
3849       return result;
3850     }
3851   }
3852 
3853   // try Windows directory
3854   if ((size = GetWindowsDirectory(path, pathLen)) &gt; 0) {
3855     if (size &gt;= pathLen) {
3856       return NULL; // truncated
3857     }
3858     if (jio_snprintf(path + size, pathLen - size, &quot;\\%s&quot;, name) == -1) {
3859       return NULL; // truncated
3860     }
3861     if ((result = (HINSTANCE)os::dll_load(path, ebuf, ebuflen)) != NULL) {
3862       return result;
3863     }
3864   }
3865 
3866   jio_snprintf(ebuf, ebuflen,
3867                &quot;os::win32::load_windows_dll() cannot load %s from system directories.&quot;, name);
3868   return NULL;
3869 }
3870 
3871 #define MAXIMUM_THREADS_TO_KEEP (16 * MAXIMUM_WAIT_OBJECTS)
3872 #define EXIT_TIMEOUT 300000 /* 5 minutes */
3873 
3874 static BOOL CALLBACK init_crit_sect_call(PINIT_ONCE, PVOID pcrit_sect, PVOID*) {
3875   InitializeCriticalSection((CRITICAL_SECTION*)pcrit_sect);
3876   return TRUE;
3877 }
3878 
3879 int os::win32::exit_process_or_thread(Ept what, int exit_code) {
3880   // Basic approach:
3881   //  - Each exiting thread registers its intent to exit and then does so.
3882   //  - A thread trying to terminate the process must wait for all
3883   //    threads currently exiting to complete their exit.
3884 
3885   if (os::win32::has_exit_bug()) {
3886     // The array holds handles of the threads that have started exiting by calling
3887     // _endthreadex().
3888     // Should be large enough to avoid blocking the exiting thread due to lack of
3889     // a free slot.
3890     static HANDLE handles[MAXIMUM_THREADS_TO_KEEP];
3891     static int handle_count = 0;
3892 
3893     static INIT_ONCE init_once_crit_sect = INIT_ONCE_STATIC_INIT;
3894     static CRITICAL_SECTION crit_sect;
3895     static volatile DWORD process_exiting = 0;
3896     int i, j;
3897     DWORD res;
3898     HANDLE hproc, hthr;
3899 
3900     // We only attempt to register threads until a process exiting
3901     // thread manages to set the process_exiting flag. Any threads
3902     // that come through here after the process_exiting flag is set
3903     // are unregistered and will be caught in the SuspendThread()
3904     // infinite loop below.
3905     bool registered = false;
3906 
3907     // The first thread that reached this point, initializes the critical section.
3908     if (!InitOnceExecuteOnce(&amp;init_once_crit_sect, init_crit_sect_call, &amp;crit_sect, NULL)) {
3909       warning(&quot;crit_sect initialization failed in %s: %d\n&quot;, __FILE__, __LINE__);
3910     } else if (Atomic::load_acquire(&amp;process_exiting) == 0) {
3911       if (what != EPT_THREAD) {
3912         // Atomically set process_exiting before the critical section
3913         // to increase the visibility between racing threads.
3914         Atomic::cmpxchg(&amp;process_exiting, (DWORD)0, GetCurrentThreadId());
3915       }
3916       EnterCriticalSection(&amp;crit_sect);
3917 
3918       if (what == EPT_THREAD &amp;&amp; Atomic::load_acquire(&amp;process_exiting) == 0) {
3919         // Remove from the array those handles of the threads that have completed exiting.
3920         for (i = 0, j = 0; i &lt; handle_count; ++i) {
3921           res = WaitForSingleObject(handles[i], 0 /* don&#39;t wait */);
3922           if (res == WAIT_TIMEOUT) {
3923             handles[j++] = handles[i];
3924           } else {
3925             if (res == WAIT_FAILED) {
3926               warning(&quot;WaitForSingleObject failed (%u) in %s: %d\n&quot;,
3927                       GetLastError(), __FILE__, __LINE__);
3928             }
3929             // Don&#39;t keep the handle, if we failed waiting for it.
3930             CloseHandle(handles[i]);
3931           }
3932         }
3933 
3934         // If there&#39;s no free slot in the array of the kept handles, we&#39;ll have to
3935         // wait until at least one thread completes exiting.
3936         if ((handle_count = j) == MAXIMUM_THREADS_TO_KEEP) {
3937           // Raise the priority of the oldest exiting thread to increase its chances
3938           // to complete sooner.
3939           SetThreadPriority(handles[0], THREAD_PRIORITY_ABOVE_NORMAL);
3940           res = WaitForMultipleObjects(MAXIMUM_WAIT_OBJECTS, handles, FALSE, EXIT_TIMEOUT);
3941           if (res &gt;= WAIT_OBJECT_0 &amp;&amp; res &lt; (WAIT_OBJECT_0 + MAXIMUM_WAIT_OBJECTS)) {
3942             i = (res - WAIT_OBJECT_0);
3943             handle_count = MAXIMUM_THREADS_TO_KEEP - 1;
3944             for (; i &lt; handle_count; ++i) {
3945               handles[i] = handles[i + 1];
3946             }
3947           } else {
3948             warning(&quot;WaitForMultipleObjects %s (%u) in %s: %d\n&quot;,
3949                     (res == WAIT_FAILED ? &quot;failed&quot; : &quot;timed out&quot;),
3950                     GetLastError(), __FILE__, __LINE__);
3951             // Don&#39;t keep handles, if we failed waiting for them.
3952             for (i = 0; i &lt; MAXIMUM_THREADS_TO_KEEP; ++i) {
3953               CloseHandle(handles[i]);
3954             }
3955             handle_count = 0;
3956           }
3957         }
3958 
3959         // Store a duplicate of the current thread handle in the array of handles.
3960         hproc = GetCurrentProcess();
3961         hthr = GetCurrentThread();
3962         if (!DuplicateHandle(hproc, hthr, hproc, &amp;handles[handle_count],
3963                              0, FALSE, DUPLICATE_SAME_ACCESS)) {
3964           warning(&quot;DuplicateHandle failed (%u) in %s: %d\n&quot;,
3965                   GetLastError(), __FILE__, __LINE__);
3966 
3967           // We can&#39;t register this thread (no more handles) so this thread
3968           // may be racing with a thread that is calling exit(). If the thread
3969           // that is calling exit() has managed to set the process_exiting
3970           // flag, then this thread will be caught in the SuspendThread()
3971           // infinite loop below which closes that race. A small timing
3972           // window remains before the process_exiting flag is set, but it
3973           // is only exposed when we are out of handles.
3974         } else {
3975           ++handle_count;
3976           registered = true;
3977 
3978           // The current exiting thread has stored its handle in the array, and now
3979           // should leave the critical section before calling _endthreadex().
3980         }
3981 
3982       } else if (what != EPT_THREAD &amp;&amp; handle_count &gt; 0) {
3983         jlong start_time, finish_time, timeout_left;
3984         // Before ending the process, make sure all the threads that had called
3985         // _endthreadex() completed.
3986 
3987         // Set the priority level of the current thread to the same value as
3988         // the priority level of exiting threads.
3989         // This is to ensure it will be given a fair chance to execute if
3990         // the timeout expires.
3991         hthr = GetCurrentThread();
3992         SetThreadPriority(hthr, THREAD_PRIORITY_ABOVE_NORMAL);
3993         start_time = os::javaTimeNanos();
3994         finish_time = start_time + ((jlong)EXIT_TIMEOUT * 1000000L);
3995         for (i = 0; ; ) {
3996           int portion_count = handle_count - i;
3997           if (portion_count &gt; MAXIMUM_WAIT_OBJECTS) {
3998             portion_count = MAXIMUM_WAIT_OBJECTS;
3999           }
4000           for (j = 0; j &lt; portion_count; ++j) {
4001             SetThreadPriority(handles[i + j], THREAD_PRIORITY_ABOVE_NORMAL);
4002           }
4003           timeout_left = (finish_time - start_time) / 1000000L;
4004           if (timeout_left &lt; 0) {
4005             timeout_left = 0;
4006           }
4007           res = WaitForMultipleObjects(portion_count, handles + i, TRUE, timeout_left);
4008           if (res == WAIT_FAILED || res == WAIT_TIMEOUT) {
4009             warning(&quot;WaitForMultipleObjects %s (%u) in %s: %d\n&quot;,
4010                     (res == WAIT_FAILED ? &quot;failed&quot; : &quot;timed out&quot;),
4011                     GetLastError(), __FILE__, __LINE__);
4012             // Reset portion_count so we close the remaining
4013             // handles due to this error.
4014             portion_count = handle_count - i;
4015           }
4016           for (j = 0; j &lt; portion_count; ++j) {
4017             CloseHandle(handles[i + j]);
4018           }
4019           if ((i += portion_count) &gt;= handle_count) {
4020             break;
4021           }
4022           start_time = os::javaTimeNanos();
4023         }
4024         handle_count = 0;
4025       }
4026 
4027       LeaveCriticalSection(&amp;crit_sect);
4028     }
4029 
4030     if (!registered &amp;&amp;
4031         Atomic::load_acquire(&amp;process_exiting) != 0 &amp;&amp;
4032         process_exiting != GetCurrentThreadId()) {
4033       // Some other thread is about to call exit(), so we don&#39;t let
4034       // the current unregistered thread proceed to exit() or _endthreadex()
4035       while (true) {
4036         SuspendThread(GetCurrentThread());
4037         // Avoid busy-wait loop, if SuspendThread() failed.
4038         Sleep(EXIT_TIMEOUT);
4039       }
4040     }
4041   }
4042 
4043   // We are here if either
4044   // - there&#39;s no &#39;race at exit&#39; bug on this OS release;
4045   // - initialization of the critical section failed (unlikely);
4046   // - the current thread has registered itself and left the critical section;
4047   // - the process-exiting thread has raised the flag and left the critical section.
4048   if (what == EPT_THREAD) {
4049     _endthreadex((unsigned)exit_code);
4050   } else if (what == EPT_PROCESS) {
4051     ::exit(exit_code);
4052   } else {
4053     _exit(exit_code);
4054   }
4055 
4056   // Should not reach here
4057   return exit_code;
4058 }
4059 
4060 #undef EXIT_TIMEOUT
4061 
4062 void os::win32::setmode_streams() {
4063   _setmode(_fileno(stdin), _O_BINARY);
4064   _setmode(_fileno(stdout), _O_BINARY);
4065   _setmode(_fileno(stderr), _O_BINARY);
4066 }
4067 
4068 void os::wait_for_keypress_at_exit(void) {
4069   if (PauseAtExit) {
4070     fprintf(stderr, &quot;Press any key to continue...\n&quot;);
4071     fgetc(stdin);
4072   }
4073 }
4074 
4075 
4076 bool os::message_box(const char* title, const char* message) {
4077   int result = MessageBox(NULL, message, title,
4078                           MB_YESNO | MB_ICONERROR | MB_SYSTEMMODAL | MB_DEFAULT_DESKTOP_ONLY);
4079   return result == IDYES;
4080 }
4081 
4082 #ifndef PRODUCT
4083 #ifndef _WIN64
4084 // Helpers to check whether NX protection is enabled
4085 int nx_exception_filter(_EXCEPTION_POINTERS *pex) {
4086   if (pex-&gt;ExceptionRecord-&gt;ExceptionCode == EXCEPTION_ACCESS_VIOLATION &amp;&amp;
4087       pex-&gt;ExceptionRecord-&gt;NumberParameters &gt; 0 &amp;&amp;
4088       pex-&gt;ExceptionRecord-&gt;ExceptionInformation[0] ==
4089       EXCEPTION_INFO_EXEC_VIOLATION) {
4090     return EXCEPTION_EXECUTE_HANDLER;
4091   }
4092   return EXCEPTION_CONTINUE_SEARCH;
4093 }
4094 
4095 void nx_check_protection() {
4096   // If NX is enabled we&#39;ll get an exception calling into code on the stack
4097   char code[] = { (char)0xC3 }; // ret
4098   void *code_ptr = (void *)code;
4099   __try {
4100     __asm call code_ptr
4101   } __except(nx_exception_filter((_EXCEPTION_POINTERS*)_exception_info())) {
4102     tty-&gt;print_raw_cr(&quot;NX protection detected.&quot;);
4103   }
4104 }
4105 #endif // _WIN64
4106 #endif // PRODUCT
4107 
4108 // This is called _before_ the global arguments have been parsed
4109 void os::init(void) {
4110   _initial_pid = _getpid();
4111 
4112   init_random(1234567);
4113 
4114   win32::initialize_system_info();
4115   win32::setmode_streams();
4116   init_page_sizes((size_t) win32::vm_page_size());
4117 
4118   // This may be overridden later when argument processing is done.
4119   FLAG_SET_ERGO(UseLargePagesIndividualAllocation, false);
4120 
4121   // Initialize main_process and main_thread
4122   main_process = GetCurrentProcess();  // Remember main_process is a pseudo handle
4123   if (!DuplicateHandle(main_process, GetCurrentThread(), main_process,
4124                        &amp;main_thread, THREAD_ALL_ACCESS, false, 0)) {
4125     fatal(&quot;DuplicateHandle failed\n&quot;);
4126   }
4127   main_thread_id = (int) GetCurrentThreadId();
4128 
4129   // initialize fast thread access - only used for 32-bit
4130   win32::initialize_thread_ptr_offset();
4131 }
4132 
4133 // To install functions for atexit processing
4134 extern &quot;C&quot; {
4135   static void perfMemory_exit_helper() {
4136     perfMemory_exit();
4137   }
4138 }
4139 
4140 static jint initSock();
4141 
4142 // this is called _after_ the global arguments have been parsed
4143 jint os::init_2(void) {
4144 
4145   // This could be set any time but all platforms
4146   // have to set it the same so we have to mirror Solaris.
4147   DEBUG_ONLY(os::set_mutex_init_done();)
4148 
4149   // Setup Windows Exceptions
4150 
4151 #if INCLUDE_AOT
4152   // If AOT is enabled we need to install a vectored exception handler
4153   // in order to forward implicit exceptions from code in AOT
4154   // generated DLLs.  This is necessary since these DLLs are not
4155   // registered for structured exceptions like codecache methods are.
4156   if (AOTLibrary != NULL &amp;&amp; (UseAOT || FLAG_IS_DEFAULT(UseAOT))) {
4157     topLevelVectoredExceptionHandler = AddVectoredExceptionHandler( 1, topLevelVectoredExceptionFilter);
4158   }
4159 #endif
4160 
4161   // for debugging float code generation bugs
4162   if (ForceFloatExceptions) {
4163 #ifndef  _WIN64
4164     static long fp_control_word = 0;
4165     __asm { fstcw fp_control_word }
4166     // see Intel PPro Manual, Vol. 2, p 7-16
4167     const long precision = 0x20;
4168     const long underflow = 0x10;
4169     const long overflow  = 0x08;
4170     const long zero_div  = 0x04;
4171     const long denorm    = 0x02;
4172     const long invalid   = 0x01;
4173     fp_control_word |= invalid;
4174     __asm { fldcw fp_control_word }
4175 #endif
4176   }
4177 
4178   // If stack_commit_size is 0, windows will reserve the default size,
4179   // but only commit a small portion of it.
4180   size_t stack_commit_size = align_up(ThreadStackSize*K, os::vm_page_size());
4181   size_t default_reserve_size = os::win32::default_stack_size();
4182   size_t actual_reserve_size = stack_commit_size;
4183   if (stack_commit_size &lt; default_reserve_size) {
4184     // If stack_commit_size == 0, we want this too
4185     actual_reserve_size = default_reserve_size;
4186   }
4187 
4188   // Check minimum allowable stack size for thread creation and to initialize
4189   // the java system classes, including StackOverflowError - depends on page
4190   // size.  Add two 4K pages for compiler2 recursion in main thread.
4191   // Add in 4*BytesPerWord 4K pages to account for VM stack during
4192   // class initialization depending on 32 or 64 bit VM.
4193   size_t min_stack_allowed =
4194             (size_t)(JavaThread::stack_guard_zone_size() +
4195                      JavaThread::stack_shadow_zone_size() +
4196                      (4*BytesPerWord COMPILER2_PRESENT(+2)) * 4 * K);
4197 
4198   min_stack_allowed = align_up(min_stack_allowed, os::vm_page_size());
4199 
4200   if (actual_reserve_size &lt; min_stack_allowed) {
4201     tty-&gt;print_cr(&quot;\nThe Java thread stack size specified is too small. &quot;
4202                   &quot;Specify at least %dk&quot;,
4203                   min_stack_allowed / K);
4204     return JNI_ERR;
4205   }
4206 
4207   JavaThread::set_stack_size_at_create(stack_commit_size);
4208 
4209   // Calculate theoretical max. size of Threads to guard gainst artifical
4210   // out-of-memory situations, where all available address-space has been
4211   // reserved by thread stacks.
4212   assert(actual_reserve_size != 0, &quot;Must have a stack&quot;);
4213 
4214   // Calculate the thread limit when we should start doing Virtual Memory
4215   // banging. Currently when the threads will have used all but 200Mb of space.
4216   //
4217   // TODO: consider performing a similar calculation for commit size instead
4218   // as reserve size, since on a 64-bit platform we&#39;ll run into that more
4219   // often than running out of virtual memory space.  We can use the
4220   // lower value of the two calculations as the os_thread_limit.
4221   size_t max_address_space = ((size_t)1 &lt;&lt; (BitsPerWord - 1)) - (200 * K * K);
4222   win32::_os_thread_limit = (intx)(max_address_space / actual_reserve_size);
4223 
4224   // at exit methods are called in the reverse order of their registration.
4225   // there is no limit to the number of functions registered. atexit does
4226   // not set errno.
4227 
4228   if (PerfAllowAtExitRegistration) {
4229     // only register atexit functions if PerfAllowAtExitRegistration is set.
4230     // atexit functions can be delayed until process exit time, which
4231     // can be problematic for embedded VM situations. Embedded VMs should
4232     // call DestroyJavaVM() to assure that VM resources are released.
4233 
4234     // note: perfMemory_exit_helper atexit function may be removed in
4235     // the future if the appropriate cleanup code can be added to the
4236     // VM_Exit VMOperation&#39;s doit method.
4237     if (atexit(perfMemory_exit_helper) != 0) {
4238       warning(&quot;os::init_2 atexit(perfMemory_exit_helper) failed&quot;);
4239     }
4240   }
4241 
4242 #ifndef _WIN64
4243   // Print something if NX is enabled (win32 on AMD64)
4244   NOT_PRODUCT(if (PrintMiscellaneous &amp;&amp; Verbose) nx_check_protection());
4245 #endif
4246 
4247   // initialize thread priority policy
4248   prio_init();
4249 
4250   if (UseNUMA &amp;&amp; !ForceNUMA) {
4251     UseNUMA = false; // We don&#39;t fully support this yet
4252   }
4253 
4254   if (UseNUMAInterleaving || (UseNUMA &amp;&amp; FLAG_IS_DEFAULT(UseNUMAInterleaving))) {
4255     if (!numa_interleaving_init()) {
4256       FLAG_SET_ERGO(UseNUMAInterleaving, false);
4257     } else if (!UseNUMAInterleaving) {
4258       // When NUMA requested, not-NUMA-aware allocations default to interleaving.
4259       FLAG_SET_ERGO(UseNUMAInterleaving, true);
4260     }
4261   }
4262 
4263   if (initSock() != JNI_OK) {
4264     return JNI_ERR;
4265   }
4266 
4267   SymbolEngine::recalc_search_path();
4268 
4269   // Initialize data for jdk.internal.misc.Signal
4270   if (!ReduceSignalUsage) {
4271     jdk_misc_signal_init();
4272   }
4273 
4274   return JNI_OK;
4275 }
4276 
4277 // combine the high and low DWORD into a ULONGLONG
4278 static ULONGLONG make_double_word(DWORD high_word, DWORD low_word) {
4279   ULONGLONG value = high_word;
4280   value &lt;&lt;= sizeof(high_word) * 8;
4281   value |= low_word;
4282   return value;
4283 }
4284 
4285 // Transfers data from WIN32_FILE_ATTRIBUTE_DATA structure to struct stat
4286 static void file_attribute_data_to_stat(struct stat* sbuf, WIN32_FILE_ATTRIBUTE_DATA file_data) {
4287   ::memset((void*)sbuf, 0, sizeof(struct stat));
4288   sbuf-&gt;st_size = (_off_t)make_double_word(file_data.nFileSizeHigh, file_data.nFileSizeLow);
4289   sbuf-&gt;st_mtime = make_double_word(file_data.ftLastWriteTime.dwHighDateTime,
4290                                   file_data.ftLastWriteTime.dwLowDateTime);
4291   sbuf-&gt;st_ctime = make_double_word(file_data.ftCreationTime.dwHighDateTime,
4292                                   file_data.ftCreationTime.dwLowDateTime);
4293   sbuf-&gt;st_atime = make_double_word(file_data.ftLastAccessTime.dwHighDateTime,
4294                                   file_data.ftLastAccessTime.dwLowDateTime);
4295   if ((file_data.dwFileAttributes &amp; FILE_ATTRIBUTE_DIRECTORY) != 0) {
4296     sbuf-&gt;st_mode |= S_IFDIR;
4297   } else {
4298     sbuf-&gt;st_mode |= S_IFREG;
4299   }
4300 }
4301 
4302 static errno_t convert_to_unicode(char const* char_path, LPWSTR* unicode_path) {
4303   // Get required buffer size to convert to Unicode
4304   int unicode_path_len = MultiByteToWideChar(CP_ACP,
4305                                              MB_ERR_INVALID_CHARS,
4306                                              char_path, -1,
4307                                              NULL, 0);
4308   if (unicode_path_len == 0) {
4309     return EINVAL;
4310   }
4311 
4312   *unicode_path = NEW_C_HEAP_ARRAY(WCHAR, unicode_path_len, mtInternal);
4313 
4314   int result = MultiByteToWideChar(CP_ACP,
4315                                    MB_ERR_INVALID_CHARS,
4316                                    char_path, -1,
4317                                    *unicode_path, unicode_path_len);
4318   assert(result == unicode_path_len, &quot;length already checked above&quot;);
4319 
4320   return ERROR_SUCCESS;
4321 }
4322 
4323 static errno_t get_full_path(LPCWSTR unicode_path, LPWSTR* full_path) {
4324   // Get required buffer size to convert to full path. The return
4325   // value INCLUDES the terminating null character.
4326   DWORD full_path_len = GetFullPathNameW(unicode_path, 0, NULL, NULL);
4327   if (full_path_len == 0) {
4328     return EINVAL;
4329   }
4330 
4331   *full_path = NEW_C_HEAP_ARRAY(WCHAR, full_path_len, mtInternal);
4332 
4333   // When the buffer has sufficient size, the return value EXCLUDES the
4334   // terminating null character
4335   DWORD result = GetFullPathNameW(unicode_path, full_path_len, *full_path, NULL);
4336   assert(result &lt;= full_path_len, &quot;length already checked above&quot;);
4337 
4338   return ERROR_SUCCESS;
4339 }
4340 
4341 static void set_path_prefix(char* buf, LPWSTR* prefix, int* prefix_off, bool* needs_fullpath) {
4342   *prefix_off = 0;
4343   *needs_fullpath = true;
4344 
4345   if (::isalpha(buf[0]) &amp;&amp; !::IsDBCSLeadByte(buf[0]) &amp;&amp; buf[1] == &#39;:&#39; &amp;&amp; buf[2] == &#39;\\&#39;) {
4346     *prefix = L&quot;\\\\?\\&quot;;
4347   } else if (buf[0] == &#39;\\&#39; &amp;&amp; buf[1] == &#39;\\&#39;) {
4348     if (buf[2] == &#39;?&#39; &amp;&amp; buf[3] == &#39;\\&#39;) {
4349       *prefix = L&quot;&quot;;
4350       *needs_fullpath = false;
4351     } else {
4352       *prefix = L&quot;\\\\?\\UNC&quot;;
4353       *prefix_off = 1; // Overwrite the first char with the prefix, so \\share\path becomes \\?\UNC\share\path
4354     }
4355   } else {
4356     *prefix = L&quot;\\\\?\\&quot;;
4357   }
4358 }
4359 
4360 // Returns the given path as an absolute wide path in unc format. The returned path is NULL
4361 // on error (with err being set accordingly) and should be freed via os::free() otherwise.
4362 // additional_space is the size of space, in wchar_t, the function will additionally add to
4363 // the allocation of return buffer (such that the size of the returned buffer is at least
4364 // wcslen(buf) + 1 + additional_space).
4365 static wchar_t* wide_abs_unc_path(char const* path, errno_t &amp; err, int additional_space = 0) {
4366   if ((path == NULL) || (path[0] == &#39;\0&#39;)) {
4367     err = ENOENT;
4368     return NULL;
4369   }
4370 
4371   // Need to allocate at least room for 3 characters, since os::native_path transforms C: to C:.
4372   size_t buf_len = 1 + MAX2((size_t)3, strlen(path));
4373   char* buf = NEW_C_HEAP_ARRAY(char, buf_len, mtInternal);
4374   strncpy(buf, path, buf_len);
4375   os::native_path(buf);
4376 
4377   LPWSTR prefix = NULL;
4378   int prefix_off = 0;
4379   bool needs_fullpath = true;
4380   set_path_prefix(buf, &amp;prefix, &amp;prefix_off, &amp;needs_fullpath);
4381 
4382   LPWSTR unicode_path = NULL;
4383   err = convert_to_unicode(buf, &amp;unicode_path);
4384   FREE_C_HEAP_ARRAY(char, buf);
4385   if (err != ERROR_SUCCESS) {
4386     return NULL;
4387   }
4388 
4389   LPWSTR converted_path = NULL;
4390   if (needs_fullpath) {
4391     err = get_full_path(unicode_path, &amp;converted_path);
4392   } else {
4393     converted_path = unicode_path;
4394   }
4395 
4396   LPWSTR result = NULL;
4397   if (converted_path != NULL) {
4398     size_t prefix_len = wcslen(prefix);
4399     size_t result_len = prefix_len - prefix_off + wcslen(converted_path) + additional_space + 1;
4400     result = NEW_C_HEAP_ARRAY(WCHAR, result_len, mtInternal);
4401     _snwprintf(result, result_len, L&quot;%s%s&quot;, prefix, &amp;converted_path[prefix_off]);
4402 
4403     // Remove trailing pathsep (not for \\?\&lt;DRIVE&gt;:\, since it would make it relative)
4404     result_len = wcslen(result);
4405     if ((result[result_len - 1] == L&#39;\\&#39;) &amp;&amp;
4406         !(::iswalpha(result[4]) &amp;&amp; result[5] == L&#39;:&#39; &amp;&amp; result_len == 7)) {
4407       result[result_len - 1] = L&#39;\0&#39;;
4408     }
4409   }
4410 
4411   if (converted_path != unicode_path) {
4412     FREE_C_HEAP_ARRAY(WCHAR, converted_path);
4413   }
4414   FREE_C_HEAP_ARRAY(WCHAR, unicode_path);
4415 
4416   return static_cast&lt;wchar_t*&gt;(result); // LPWSTR and wchat_t* are the same type on Windows.
4417 }
4418 
4419 int os::stat(const char *path, struct stat *sbuf) {
4420   errno_t err;
4421   wchar_t* wide_path = wide_abs_unc_path(path, err);
4422 
4423   if (wide_path == NULL) {
4424     errno = err;
4425     return -1;
4426   }
4427 
4428   WIN32_FILE_ATTRIBUTE_DATA file_data;;
4429   BOOL bret = ::GetFileAttributesExW(wide_path, GetFileExInfoStandard, &amp;file_data);
4430   os::free(wide_path);
4431 
4432   if (!bret) {
4433     errno = ::GetLastError();
4434     return -1;
4435   }
4436 
4437   file_attribute_data_to_stat(sbuf, file_data);
4438   return 0;
4439 }
4440 
4441 static HANDLE create_read_only_file_handle(const char* file) {
4442   errno_t err;
4443   wchar_t* wide_path = wide_abs_unc_path(file, err);
4444 
4445   if (wide_path == NULL) {
4446     errno = err;
4447     return INVALID_HANDLE_VALUE;
4448   }
4449 
4450   HANDLE handle = ::CreateFileW(wide_path, 0, FILE_SHARE_READ,
4451                                 NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);
4452   os::free(wide_path);
4453 
4454   return handle;
4455 }
4456 
4457 bool os::same_files(const char* file1, const char* file2) {
4458 
4459   if (file1 == NULL &amp;&amp; file2 == NULL) {
4460     return true;
4461   }
4462 
4463   if (file1 == NULL || file2 == NULL) {
4464     return false;
4465   }
4466 
4467   if (strcmp(file1, file2) == 0) {
4468     return true;
4469   }
4470 
4471   HANDLE handle1 = create_read_only_file_handle(file1);
4472   HANDLE handle2 = create_read_only_file_handle(file2);
4473   bool result = false;
4474 
4475   // if we could open both paths...
4476   if (handle1 != INVALID_HANDLE_VALUE &amp;&amp; handle2 != INVALID_HANDLE_VALUE) {
4477     BY_HANDLE_FILE_INFORMATION fileInfo1;
4478     BY_HANDLE_FILE_INFORMATION fileInfo2;
4479     if (::GetFileInformationByHandle(handle1, &amp;fileInfo1) &amp;&amp;
4480       ::GetFileInformationByHandle(handle2, &amp;fileInfo2)) {
4481       // the paths are the same if they refer to the same file (fileindex) on the same volume (volume serial number)
4482       if (fileInfo1.dwVolumeSerialNumber == fileInfo2.dwVolumeSerialNumber &amp;&amp;
4483         fileInfo1.nFileIndexHigh == fileInfo2.nFileIndexHigh &amp;&amp;
4484         fileInfo1.nFileIndexLow == fileInfo2.nFileIndexLow) {
4485         result = true;
4486       }
4487     }
4488   }
4489 
4490   //free the handles
4491   if (handle1 != INVALID_HANDLE_VALUE) {
4492     ::CloseHandle(handle1);
4493   }
4494 
4495   if (handle2 != INVALID_HANDLE_VALUE) {
4496     ::CloseHandle(handle2);
4497   }
4498 
4499   return result;
4500 }
4501 
4502 #define FT2INT64(ft) \
4503   ((jlong)((jlong)(ft).dwHighDateTime &lt;&lt; 32 | (julong)(ft).dwLowDateTime))
4504 
4505 
4506 // current_thread_cpu_time(bool) and thread_cpu_time(Thread*, bool)
4507 // are used by JVM M&amp;M and JVMTI to get user+sys or user CPU time
4508 // of a thread.
4509 //
4510 // current_thread_cpu_time() and thread_cpu_time(Thread*) returns
4511 // the fast estimate available on the platform.
4512 
4513 // current_thread_cpu_time() is not optimized for Windows yet
4514 jlong os::current_thread_cpu_time() {
4515   // return user + sys since the cost is the same
4516   return os::thread_cpu_time(Thread::current(), true /* user+sys */);
4517 }
4518 
4519 jlong os::thread_cpu_time(Thread* thread) {
4520   // consistent with what current_thread_cpu_time() returns.
4521   return os::thread_cpu_time(thread, true /* user+sys */);
4522 }
4523 
4524 jlong os::current_thread_cpu_time(bool user_sys_cpu_time) {
4525   return os::thread_cpu_time(Thread::current(), user_sys_cpu_time);
4526 }
4527 
4528 jlong os::thread_cpu_time(Thread* thread, bool user_sys_cpu_time) {
4529   // This code is copy from clasic VM -&gt; hpi::sysThreadCPUTime
4530   // If this function changes, os::is_thread_cpu_time_supported() should too
4531   FILETIME CreationTime;
4532   FILETIME ExitTime;
4533   FILETIME KernelTime;
4534   FILETIME UserTime;
4535 
4536   if (GetThreadTimes(thread-&gt;osthread()-&gt;thread_handle(), &amp;CreationTime,
4537                       &amp;ExitTime, &amp;KernelTime, &amp;UserTime) == 0) {
4538     return -1;
4539   } else if (user_sys_cpu_time) {
4540     return (FT2INT64(UserTime) + FT2INT64(KernelTime)) * 100;
4541   } else {
4542     return FT2INT64(UserTime) * 100;
4543   }
4544 }
4545 
4546 void os::current_thread_cpu_time_info(jvmtiTimerInfo *info_ptr) {
4547   info_ptr-&gt;max_value = ALL_64_BITS;        // the max value -- all 64 bits
4548   info_ptr-&gt;may_skip_backward = false;      // GetThreadTimes returns absolute time
4549   info_ptr-&gt;may_skip_forward = false;       // GetThreadTimes returns absolute time
4550   info_ptr-&gt;kind = JVMTI_TIMER_TOTAL_CPU;   // user+system time is returned
4551 }
4552 
4553 void os::thread_cpu_time_info(jvmtiTimerInfo *info_ptr) {
4554   info_ptr-&gt;max_value = ALL_64_BITS;        // the max value -- all 64 bits
4555   info_ptr-&gt;may_skip_backward = false;      // GetThreadTimes returns absolute time
4556   info_ptr-&gt;may_skip_forward = false;       // GetThreadTimes returns absolute time
4557   info_ptr-&gt;kind = JVMTI_TIMER_TOTAL_CPU;   // user+system time is returned
4558 }
4559 
4560 bool os::is_thread_cpu_time_supported() {
4561   // see os::thread_cpu_time
4562   FILETIME CreationTime;
4563   FILETIME ExitTime;
4564   FILETIME KernelTime;
4565   FILETIME UserTime;
4566 
4567   if (GetThreadTimes(GetCurrentThread(), &amp;CreationTime, &amp;ExitTime,
4568                       &amp;KernelTime, &amp;UserTime) == 0) {
4569     return false;
4570   } else {
4571     return true;
4572   }
4573 }
4574 
4575 // Windows does&#39;t provide a loadavg primitive so this is stubbed out for now.
4576 // It does have primitives (PDH API) to get CPU usage and run queue length.
4577 // &quot;\\Processor(_Total)\\% Processor Time&quot;, &quot;\\System\\Processor Queue Length&quot;
4578 // If we wanted to implement loadavg on Windows, we have a few options:
4579 //
4580 // a) Query CPU usage and run queue length and &quot;fake&quot; an answer by
4581 //    returning the CPU usage if it&#39;s under 100%, and the run queue
4582 //    length otherwise.  It turns out that querying is pretty slow
4583 //    on Windows, on the order of 200 microseconds on a fast machine.
4584 //    Note that on the Windows the CPU usage value is the % usage
4585 //    since the last time the API was called (and the first call
4586 //    returns 100%), so we&#39;d have to deal with that as well.
4587 //
4588 // b) Sample the &quot;fake&quot; answer using a sampling thread and store
4589 //    the answer in a global variable.  The call to loadavg would
4590 //    just return the value of the global, avoiding the slow query.
4591 //
4592 // c) Sample a better answer using exponential decay to smooth the
4593 //    value.  This is basically the algorithm used by UNIX kernels.
4594 //
4595 // Note that sampling thread starvation could affect both (b) and (c).
4596 int os::loadavg(double loadavg[], int nelem) {
4597   return -1;
4598 }
4599 
4600 
4601 // DontYieldALot=false by default: dutifully perform all yields as requested by JVM_Yield()
4602 bool os::dont_yield() {
4603   return DontYieldALot;
4604 }
4605 
4606 int os::open(const char *path, int oflag, int mode) {
4607   errno_t err;
4608   wchar_t* wide_path = wide_abs_unc_path(path, err);
4609 
4610   if (wide_path == NULL) {
4611     errno = err;
4612     return -1;
4613   }
4614   int fd = ::_wopen(wide_path, oflag | O_BINARY | O_NOINHERIT, mode);
4615   os::free(wide_path);
4616 
4617   if (fd == -1) {
4618     errno = ::GetLastError();
4619   }
4620 
4621   return fd;
4622 }
4623 
4624 FILE* os::open(int fd, const char* mode) {
4625   return ::_fdopen(fd, mode);
4626 }
4627 
4628 // Is a (classpath) directory empty?
4629 bool os::dir_is_empty(const char* path) {
4630   errno_t err;
4631   wchar_t* wide_path = wide_abs_unc_path(path, err, 2);
4632 
4633   if (wide_path == NULL) {
4634     errno = err;
4635     return false;
4636   }
4637 
4638   // Make sure we end with &quot;\\*&quot;
4639   if (wide_path[wcslen(wide_path) - 1] == L&#39;\\&#39;) {
4640     wcscat(wide_path, L&quot;*&quot;);
4641   } else {
4642     wcscat(wide_path, L&quot;\\*&quot;);
4643   }
4644 
4645   WIN32_FIND_DATAW fd;
4646   HANDLE f = ::FindFirstFileW(wide_path, &amp;fd);
4647   os::free(wide_path);
4648   bool is_empty = true;
4649 
4650   if (f != INVALID_HANDLE_VALUE) {
4651     while (is_empty &amp;&amp; ::FindNextFileW(f, &amp;fd)) {
4652       // An empty directory contains only the current directory file
4653       // and the previous directory file.
4654       if ((wcscmp(fd.cFileName, L&quot;.&quot;) != 0) &amp;&amp;
4655           (wcscmp(fd.cFileName, L&quot;..&quot;) != 0)) {
4656         is_empty = false;
4657       }
4658     }
4659     FindClose(f);
4660   } else {
4661     errno = ::GetLastError();
4662   }
4663 
4664   return is_empty;
4665 }
4666 
4667 // create binary file, rewriting existing file if required
4668 int os::create_binary_file(const char* path, bool rewrite_existing) {
4669   int oflags = _O_CREAT | _O_WRONLY | _O_BINARY;
4670   if (!rewrite_existing) {
4671     oflags |= _O_EXCL;
4672   }
4673   return ::open(path, oflags, _S_IREAD | _S_IWRITE);
4674 }
4675 
4676 // return current position of file pointer
4677 jlong os::current_file_offset(int fd) {
4678   return (jlong)::_lseeki64(fd, (__int64)0L, SEEK_CUR);
4679 }
4680 
4681 // move file pointer to the specified offset
4682 jlong os::seek_to_file_offset(int fd, jlong offset) {
4683   return (jlong)::_lseeki64(fd, (__int64)offset, SEEK_SET);
4684 }
4685 
4686 
4687 jlong os::lseek(int fd, jlong offset, int whence) {
4688   return (jlong) ::_lseeki64(fd, offset, whence);
4689 }
4690 
4691 ssize_t os::read_at(int fd, void *buf, unsigned int nBytes, jlong offset) {
4692   OVERLAPPED ov;
4693   DWORD nread;
4694   BOOL result;
4695 
4696   ZeroMemory(&amp;ov, sizeof(ov));
4697   ov.Offset = (DWORD)offset;
4698   ov.OffsetHigh = (DWORD)(offset &gt;&gt; 32);
4699 
4700   HANDLE h = (HANDLE)::_get_osfhandle(fd);
4701 
4702   result = ReadFile(h, (LPVOID)buf, nBytes, &amp;nread, &amp;ov);
4703 
4704   return result ? nread : 0;
4705 }
4706 
4707 
4708 // This method is a slightly reworked copy of JDK&#39;s sysNativePath
4709 // from src/windows/hpi/src/path_md.c
4710 
4711 // Convert a pathname to native format.  On win32, this involves forcing all
4712 // separators to be &#39;\\&#39; rather than &#39;/&#39; (both are legal inputs, but Win95
4713 // sometimes rejects &#39;/&#39;) and removing redundant separators.  The input path is
4714 // assumed to have been converted into the character encoding used by the local
4715 // system.  Because this might be a double-byte encoding, care is taken to
4716 // treat double-byte lead characters correctly.
4717 //
4718 // This procedure modifies the given path in place, as the result is never
4719 // longer than the original.  There is no error return; this operation always
4720 // succeeds.
4721 char * os::native_path(char *path) {
4722   char *src = path, *dst = path, *end = path;
4723   char *colon = NULL;  // If a drive specifier is found, this will
4724                        // point to the colon following the drive letter
4725 
4726   // Assumption: &#39;/&#39;, &#39;\\&#39;, &#39;:&#39;, and drive letters are never lead bytes
4727   assert(((!::IsDBCSLeadByte(&#39;/&#39;)) &amp;&amp; (!::IsDBCSLeadByte(&#39;\\&#39;))
4728           &amp;&amp; (!::IsDBCSLeadByte(&#39;:&#39;))), &quot;Illegal lead byte&quot;);
4729 
4730   // Check for leading separators
4731 #define isfilesep(c) ((c) == &#39;/&#39; || (c) == &#39;\\&#39;)
4732   while (isfilesep(*src)) {
4733     src++;
4734   }
4735 
4736   if (::isalpha(*src) &amp;&amp; !::IsDBCSLeadByte(*src) &amp;&amp; src[1] == &#39;:&#39;) {
4737     // Remove leading separators if followed by drive specifier.  This
4738     // hack is necessary to support file URLs containing drive
4739     // specifiers (e.g., &quot;file://c:/path&quot;).  As a side effect,
4740     // &quot;/c:/path&quot; can be used as an alternative to &quot;c:/path&quot;.
4741     *dst++ = *src++;
4742     colon = dst;
4743     *dst++ = &#39;:&#39;;
4744     src++;
4745   } else {
4746     src = path;
4747     if (isfilesep(src[0]) &amp;&amp; isfilesep(src[1])) {
4748       // UNC pathname: Retain first separator; leave src pointed at
4749       // second separator so that further separators will be collapsed
4750       // into the second separator.  The result will be a pathname
4751       // beginning with &quot;\\\\&quot; followed (most likely) by a host name.
4752       src = dst = path + 1;
4753       path[0] = &#39;\\&#39;;     // Force first separator to &#39;\\&#39;
4754     }
4755   }
4756 
4757   end = dst;
4758 
4759   // Remove redundant separators from remainder of path, forcing all
4760   // separators to be &#39;\\&#39; rather than &#39;/&#39;. Also, single byte space
4761   // characters are removed from the end of the path because those
4762   // are not legal ending characters on this operating system.
4763   //
4764   while (*src != &#39;\0&#39;) {
4765     if (isfilesep(*src)) {
4766       *dst++ = &#39;\\&#39;; src++;
4767       while (isfilesep(*src)) src++;
4768       if (*src == &#39;\0&#39;) {
4769         // Check for trailing separator
4770         end = dst;
4771         if (colon == dst - 2) break;  // &quot;z:\\&quot;
4772         if (dst == path + 1) break;   // &quot;\\&quot;
4773         if (dst == path + 2 &amp;&amp; isfilesep(path[0])) {
4774           // &quot;\\\\&quot; is not collapsed to &quot;\\&quot; because &quot;\\\\&quot; marks the
4775           // beginning of a UNC pathname.  Even though it is not, by
4776           // itself, a valid UNC pathname, we leave it as is in order
4777           // to be consistent with the path canonicalizer as well
4778           // as the win32 APIs, which treat this case as an invalid
4779           // UNC pathname rather than as an alias for the root
4780           // directory of the current drive.
4781           break;
4782         }
4783         end = --dst;  // Path does not denote a root directory, so
4784                       // remove trailing separator
4785         break;
4786       }
4787       end = dst;
4788     } else {
4789       if (::IsDBCSLeadByte(*src)) {  // Copy a double-byte character
4790         *dst++ = *src++;
4791         if (*src) *dst++ = *src++;
4792         end = dst;
4793       } else {  // Copy a single-byte character
4794         char c = *src++;
4795         *dst++ = c;
4796         // Space is not a legal ending character
4797         if (c != &#39; &#39;) end = dst;
4798       }
4799     }
4800   }
4801 
4802   *end = &#39;\0&#39;;
4803 
4804   // For &quot;z:&quot;, add &quot;.&quot; to work around a bug in the C runtime library
4805   if (colon == dst - 1) {
4806     path[2] = &#39;.&#39;;
4807     path[3] = &#39;\0&#39;;
4808   }
4809 
4810   return path;
4811 }
4812 
4813 // This code is a copy of JDK&#39;s sysSetLength
4814 // from src/windows/hpi/src/sys_api_md.c
4815 
4816 int os::ftruncate(int fd, jlong length) {
4817   HANDLE h = (HANDLE)::_get_osfhandle(fd);
4818   long high = (long)(length &gt;&gt; 32);
4819   DWORD ret;
4820 
4821   if (h == (HANDLE)(-1)) {
4822     return -1;
4823   }
4824 
4825   ret = ::SetFilePointer(h, (long)(length), &amp;high, FILE_BEGIN);
4826   if ((ret == 0xFFFFFFFF) &amp;&amp; (::GetLastError() != NO_ERROR)) {
4827     return -1;
4828   }
4829 
4830   if (::SetEndOfFile(h) == FALSE) {
4831     return -1;
4832   }
4833 
4834   return 0;
4835 }
4836 
4837 int os::get_fileno(FILE* fp) {
4838   return _fileno(fp);
4839 }
4840 
4841 // This code is a copy of JDK&#39;s sysSync
4842 // from src/windows/hpi/src/sys_api_md.c
4843 // except for the legacy workaround for a bug in Win 98
4844 
4845 int os::fsync(int fd) {
4846   HANDLE handle = (HANDLE)::_get_osfhandle(fd);
4847 
4848   if ((!::FlushFileBuffers(handle)) &amp;&amp;
4849       (GetLastError() != ERROR_ACCESS_DENIED)) {
4850     // from winerror.h
4851     return -1;
4852   }
4853   return 0;
4854 }
4855 
4856 static int nonSeekAvailable(int, long *);
4857 static int stdinAvailable(int, long *);
4858 
4859 // This code is a copy of JDK&#39;s sysAvailable
4860 // from src/windows/hpi/src/sys_api_md.c
4861 
4862 int os::available(int fd, jlong *bytes) {
4863   jlong cur, end;
4864   struct _stati64 stbuf64;
4865 
4866   if (::_fstati64(fd, &amp;stbuf64) &gt;= 0) {
4867     int mode = stbuf64.st_mode;
4868     if (S_ISCHR(mode) || S_ISFIFO(mode)) {
4869       int ret;
4870       long lpbytes;
4871       if (fd == 0) {
4872         ret = stdinAvailable(fd, &amp;lpbytes);
4873       } else {
4874         ret = nonSeekAvailable(fd, &amp;lpbytes);
4875       }
4876       (*bytes) = (jlong)(lpbytes);
4877       return ret;
4878     }
4879     if ((cur = ::_lseeki64(fd, 0L, SEEK_CUR)) == -1) {
4880       return FALSE;
4881     } else if ((end = ::_lseeki64(fd, 0L, SEEK_END)) == -1) {
4882       return FALSE;
4883     } else if (::_lseeki64(fd, cur, SEEK_SET) == -1) {
4884       return FALSE;
4885     }
4886     *bytes = end - cur;
4887     return TRUE;
4888   } else {
4889     return FALSE;
4890   }
4891 }
4892 
4893 void os::flockfile(FILE* fp) {
4894   _lock_file(fp);
4895 }
4896 
4897 void os::funlockfile(FILE* fp) {
4898   _unlock_file(fp);
4899 }
4900 
4901 // This code is a copy of JDK&#39;s nonSeekAvailable
4902 // from src/windows/hpi/src/sys_api_md.c
4903 
4904 static int nonSeekAvailable(int fd, long *pbytes) {
4905   // This is used for available on non-seekable devices
4906   // (like both named and anonymous pipes, such as pipes
4907   //  connected to an exec&#39;d process).
4908   // Standard Input is a special case.
4909   HANDLE han;
4910 
4911   if ((han = (HANDLE) ::_get_osfhandle(fd)) == (HANDLE)(-1)) {
4912     return FALSE;
4913   }
4914 
4915   if (! ::PeekNamedPipe(han, NULL, 0, NULL, (LPDWORD)pbytes, NULL)) {
4916     // PeekNamedPipe fails when at EOF.  In that case we
4917     // simply make *pbytes = 0 which is consistent with the
4918     // behavior we get on Solaris when an fd is at EOF.
4919     // The only alternative is to raise an Exception,
4920     // which isn&#39;t really warranted.
4921     //
4922     if (::GetLastError() != ERROR_BROKEN_PIPE) {
4923       return FALSE;
4924     }
4925     *pbytes = 0;
4926   }
4927   return TRUE;
4928 }
4929 
4930 #define MAX_INPUT_EVENTS 2000
4931 
4932 // This code is a copy of JDK&#39;s stdinAvailable
4933 // from src/windows/hpi/src/sys_api_md.c
4934 
4935 static int stdinAvailable(int fd, long *pbytes) {
4936   HANDLE han;
4937   DWORD numEventsRead = 0;  // Number of events read from buffer
4938   DWORD numEvents = 0;      // Number of events in buffer
4939   DWORD i = 0;              // Loop index
4940   DWORD curLength = 0;      // Position marker
4941   DWORD actualLength = 0;   // Number of bytes readable
4942   BOOL error = FALSE;       // Error holder
4943   INPUT_RECORD *lpBuffer;   // Pointer to records of input events
4944 
4945   if ((han = ::GetStdHandle(STD_INPUT_HANDLE)) == INVALID_HANDLE_VALUE) {
4946     return FALSE;
4947   }
4948 
4949   // Construct an array of input records in the console buffer
4950   error = ::GetNumberOfConsoleInputEvents(han, &amp;numEvents);
4951   if (error == 0) {
4952     return nonSeekAvailable(fd, pbytes);
4953   }
4954 
4955   // lpBuffer must fit into 64K or else PeekConsoleInput fails
4956   if (numEvents &gt; MAX_INPUT_EVENTS) {
4957     numEvents = MAX_INPUT_EVENTS;
4958   }
4959 
4960   lpBuffer = (INPUT_RECORD *)os::malloc(numEvents * sizeof(INPUT_RECORD), mtInternal);
4961   if (lpBuffer == NULL) {
4962     return FALSE;
4963   }
4964 
4965   error = ::PeekConsoleInput(han, lpBuffer, numEvents, &amp;numEventsRead);
4966   if (error == 0) {
4967     os::free(lpBuffer);
4968     return FALSE;
4969   }
4970 
4971   // Examine input records for the number of bytes available
4972   for (i=0; i&lt;numEvents; i++) {
4973     if (lpBuffer[i].EventType == KEY_EVENT) {
4974 
4975       KEY_EVENT_RECORD *keyRecord = (KEY_EVENT_RECORD *)
4976                                       &amp;(lpBuffer[i].Event);
4977       if (keyRecord-&gt;bKeyDown == TRUE) {
4978         CHAR *keyPressed = (CHAR *) &amp;(keyRecord-&gt;uChar);
4979         curLength++;
4980         if (*keyPressed == &#39;\r&#39;) {
4981           actualLength = curLength;
4982         }
4983       }
4984     }
4985   }
4986 
4987   if (lpBuffer != NULL) {
4988     os::free(lpBuffer);
4989   }
4990 
4991   *pbytes = (long) actualLength;
4992   return TRUE;
4993 }
4994 
4995 // Map a block of memory.
4996 char* os::pd_map_memory(int fd, const char* file_name, size_t file_offset,
4997                         char *addr, size_t bytes, bool read_only,
4998                         bool allow_exec) {
4999   HANDLE hFile;
5000   char* base;
5001 
5002   hFile = CreateFile(file_name, GENERIC_READ, FILE_SHARE_READ, NULL,
5003                      OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);
5004   if (hFile == NULL) {
5005     log_info(os)(&quot;CreateFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5006     return NULL;
5007   }
5008 
5009   if (allow_exec) {
5010     // CreateFileMapping/MapViewOfFileEx can&#39;t map executable memory
5011     // unless it comes from a PE image (which the shared archive is not.)
5012     // Even VirtualProtect refuses to give execute access to mapped memory
5013     // that was not previously executable.
5014     //
5015     // Instead, stick the executable region in anonymous memory.  Yuck.
5016     // Penalty is that ~4 pages will not be shareable - in the future
5017     // we might consider DLLizing the shared archive with a proper PE
5018     // header so that mapping executable + sharing is possible.
5019 
5020     base = (char*) VirtualAlloc(addr, bytes, MEM_COMMIT | MEM_RESERVE,
5021                                 PAGE_READWRITE);
5022     if (base == NULL) {
5023       log_info(os)(&quot;VirtualAlloc() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5024       CloseHandle(hFile);
5025       return NULL;
5026     }
5027 
5028     // Record virtual memory allocation
5029     MemTracker::record_virtual_memory_reserve_and_commit((address)addr, bytes, CALLER_PC);
5030 
5031     DWORD bytes_read;
5032     OVERLAPPED overlapped;
5033     overlapped.Offset = (DWORD)file_offset;
5034     overlapped.OffsetHigh = 0;
5035     overlapped.hEvent = NULL;
5036     // ReadFile guarantees that if the return value is true, the requested
5037     // number of bytes were read before returning.
5038     bool res = ReadFile(hFile, base, (DWORD)bytes, &amp;bytes_read, &amp;overlapped) != 0;
5039     if (!res) {
5040       log_info(os)(&quot;ReadFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5041       release_memory(base, bytes);
5042       CloseHandle(hFile);
5043       return NULL;
5044     }
5045   } else {
5046     HANDLE hMap = CreateFileMapping(hFile, NULL, PAGE_WRITECOPY, 0, 0,
5047                                     NULL /* file_name */);
5048     if (hMap == NULL) {
5049       log_info(os)(&quot;CreateFileMapping() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5050       CloseHandle(hFile);
5051       return NULL;
5052     }
5053 
5054     DWORD access = read_only ? FILE_MAP_READ : FILE_MAP_COPY;
5055     base = (char*)MapViewOfFileEx(hMap, access, 0, (DWORD)file_offset,
5056                                   (DWORD)bytes, addr);
5057     if (base == NULL) {
5058       log_info(os)(&quot;MapViewOfFileEx() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5059       CloseHandle(hMap);
5060       CloseHandle(hFile);
5061       return NULL;
5062     }
5063 
5064     if (CloseHandle(hMap) == 0) {
5065       log_info(os)(&quot;CloseHandle(hMap) failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5066       CloseHandle(hFile);
5067       return base;
5068     }
5069   }
5070 
5071   if (allow_exec) {
5072     DWORD old_protect;
5073     DWORD exec_access = read_only ? PAGE_EXECUTE_READ : PAGE_EXECUTE_READWRITE;
5074     bool res = VirtualProtect(base, bytes, exec_access, &amp;old_protect) != 0;
5075 
5076     if (!res) {
5077       log_info(os)(&quot;VirtualProtect() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5078       // Don&#39;t consider this a hard error, on IA32 even if the
5079       // VirtualProtect fails, we should still be able to execute
5080       CloseHandle(hFile);
5081       return base;
5082     }
5083   }
5084 
5085   if (CloseHandle(hFile) == 0) {
5086     log_info(os)(&quot;CloseHandle(hFile) failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5087     return base;
5088   }
5089 
5090   return base;
5091 }
5092 
5093 
5094 // Remap a block of memory.
5095 char* os::pd_remap_memory(int fd, const char* file_name, size_t file_offset,
5096                           char *addr, size_t bytes, bool read_only,
5097                           bool allow_exec) {
5098   // This OS does not allow existing memory maps to be remapped so we
5099   // would have to unmap the memory before we remap it.
5100 
5101   // Because there is a small window between unmapping memory and mapping
5102   // it in again with different protections, CDS archives are mapped RW
5103   // on windows, so this function isn&#39;t called.
5104   ShouldNotReachHere();
5105   return NULL;
5106 }
5107 
5108 
5109 // Unmap a block of memory.
5110 // Returns true=success, otherwise false.
5111 
5112 bool os::pd_unmap_memory(char* addr, size_t bytes) {
5113   MEMORY_BASIC_INFORMATION mem_info;
5114   if (VirtualQuery(addr, &amp;mem_info, sizeof(mem_info)) == 0) {
5115     log_info(os)(&quot;VirtualQuery() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5116     return false;
5117   }
5118 
5119   // Executable memory was not mapped using CreateFileMapping/MapViewOfFileEx.
5120   // Instead, executable region was allocated using VirtualAlloc(). See
5121   // pd_map_memory() above.
5122   //
5123   // The following flags should match the &#39;exec_access&#39; flages used for
5124   // VirtualProtect() in pd_map_memory().
5125   if (mem_info.Protect == PAGE_EXECUTE_READ ||
5126       mem_info.Protect == PAGE_EXECUTE_READWRITE) {
5127     return pd_release_memory(addr, bytes);
5128   }
5129 
5130   BOOL result = UnmapViewOfFile(addr);
5131   if (result == 0) {
5132     log_info(os)(&quot;UnmapViewOfFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5133     return false;
5134   }
5135   return true;
5136 }
5137 
5138 void os::pause() {
5139   char filename[MAX_PATH];
5140   if (PauseAtStartupFile &amp;&amp; PauseAtStartupFile[0]) {
5141     jio_snprintf(filename, MAX_PATH, &quot;%s&quot;, PauseAtStartupFile);
5142   } else {
5143     jio_snprintf(filename, MAX_PATH, &quot;./vm.paused.%d&quot;, current_process_id());
5144   }
5145 
5146   int fd = ::open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0666);
5147   if (fd != -1) {
5148     struct stat buf;
5149     ::close(fd);
5150     while (::stat(filename, &amp;buf) == 0) {
5151       Sleep(100);
5152     }
5153   } else {
5154     jio_fprintf(stderr,
5155                 &quot;Could not open pause file &#39;%s&#39;, continuing immediately.\n&quot;, filename);
5156   }
5157 }
5158 
5159 Thread* os::ThreadCrashProtection::_protected_thread = NULL;
5160 os::ThreadCrashProtection* os::ThreadCrashProtection::_crash_protection = NULL;
5161 volatile intptr_t os::ThreadCrashProtection::_crash_mux = 0;
5162 
5163 os::ThreadCrashProtection::ThreadCrashProtection() {
5164 }
5165 
5166 // See the caveats for this class in os_windows.hpp
5167 // Protects the callback call so that raised OS EXCEPTIONS causes a jump back
5168 // into this method and returns false. If no OS EXCEPTION was raised, returns
5169 // true.
5170 // The callback is supposed to provide the method that should be protected.
5171 //
5172 bool os::ThreadCrashProtection::call(os::CrashProtectionCallback&amp; cb) {
5173 
5174   Thread::muxAcquire(&amp;_crash_mux, &quot;CrashProtection&quot;);
5175 
5176   _protected_thread = Thread::current_or_null();
5177   assert(_protected_thread != NULL, &quot;Cannot crash protect a NULL thread&quot;);
5178 
5179   bool success = true;
5180   __try {
5181     _crash_protection = this;
5182     cb.call();
5183   } __except(EXCEPTION_EXECUTE_HANDLER) {
5184     // only for protection, nothing to do
5185     success = false;
5186   }
5187   _crash_protection = NULL;
5188   _protected_thread = NULL;
5189   Thread::muxRelease(&amp;_crash_mux);
5190   return success;
5191 }
5192 
5193 
5194 class HighResolutionInterval : public CHeapObj&lt;mtThread&gt; {
5195   // The default timer resolution seems to be 10 milliseconds.
5196   // (Where is this written down?)
5197   // If someone wants to sleep for only a fraction of the default,
5198   // then we set the timer resolution down to 1 millisecond for
5199   // the duration of their interval.
5200   // We carefully set the resolution back, since otherwise we
5201   // seem to incur an overhead (3%?) that we don&#39;t need.
5202   // CONSIDER: if ms is small, say 3, then we should run with a high resolution time.
5203   // Buf if ms is large, say 500, or 503, we should avoid the call to timeBeginPeriod().
5204   // Alternatively, we could compute the relative error (503/500 = .6%) and only use
5205   // timeBeginPeriod() if the relative error exceeded some threshold.
5206   // timeBeginPeriod() has been linked to problems with clock drift on win32 systems and
5207   // to decreased efficiency related to increased timer &quot;tick&quot; rates.  We want to minimize
5208   // (a) calls to timeBeginPeriod() and timeEndPeriod() and (b) time spent with high
5209   // resolution timers running.
5210  private:
5211   jlong resolution;
5212  public:
5213   HighResolutionInterval(jlong ms) {
5214     resolution = ms % 10L;
5215     if (resolution != 0) {
5216       MMRESULT result = timeBeginPeriod(1L);
5217     }
5218   }
5219   ~HighResolutionInterval() {
5220     if (resolution != 0) {
5221       MMRESULT result = timeEndPeriod(1L);
5222     }
5223     resolution = 0L;
5224   }
5225 };
5226 
5227 // An Event wraps a win32 &quot;CreateEvent&quot; kernel handle.
5228 //
5229 // We have a number of choices regarding &quot;CreateEvent&quot; win32 handle leakage:
5230 //
5231 // 1:  When a thread dies return the Event to the EventFreeList, clear the ParkHandle
5232 //     field, and call CloseHandle() on the win32 event handle.  Unpark() would
5233 //     need to be modified to tolerate finding a NULL (invalid) win32 event handle.
5234 //     In addition, an unpark() operation might fetch the handle field, but the
5235 //     event could recycle between the fetch and the SetEvent() operation.
5236 //     SetEvent() would either fail because the handle was invalid, or inadvertently work,
5237 //     as the win32 handle value had been recycled.  In an ideal world calling SetEvent()
5238 //     on an stale but recycled handle would be harmless, but in practice this might
5239 //     confuse other non-Sun code, so it&#39;s not a viable approach.
5240 //
5241 // 2:  Once a win32 event handle is associated with an Event, it remains associated
5242 //     with the Event.  The event handle is never closed.  This could be construed
5243 //     as handle leakage, but only up to the maximum # of threads that have been extant
5244 //     at any one time.  This shouldn&#39;t be an issue, as windows platforms typically
5245 //     permit a process to have hundreds of thousands of open handles.
5246 //
5247 // 3:  Same as (1), but periodically, at stop-the-world time, rundown the EventFreeList
5248 //     and release unused handles.
5249 //
5250 // 4:  Add a CRITICAL_SECTION to the Event to protect LD+SetEvent from LD;ST(null);CloseHandle.
5251 //     It&#39;s not clear, however, that we wouldn&#39;t be trading one type of leak for another.
5252 //
5253 // 5.  Use an RCU-like mechanism (Read-Copy Update).
5254 //     Or perhaps something similar to Maged Michael&#39;s &quot;Hazard pointers&quot;.
5255 //
5256 // We use (2).
5257 //
5258 // TODO-FIXME:
5259 // 1.  Reconcile Doug&#39;s JSR166 j.u.c park-unpark with the objectmonitor implementation.
5260 // 2.  Consider wrapping the WaitForSingleObject(Ex) calls in SEH try/finally blocks
5261 //     to recover from (or at least detect) the dreaded Windows 841176 bug.
5262 // 3.  Collapse the JSR166 parker event, and the objectmonitor ParkEvent
5263 //     into a single win32 CreateEvent() handle.
5264 //
5265 // Assumption:
5266 //    Only one parker can exist on an event, which is why we allocate
5267 //    them per-thread. Multiple unparkers can coexist.
5268 //
5269 // _Event transitions in park()
5270 //   -1 =&gt; -1 : illegal
5271 //    1 =&gt;  0 : pass - return immediately
5272 //    0 =&gt; -1 : block; then set _Event to 0 before returning
5273 //
5274 // _Event transitions in unpark()
5275 //    0 =&gt; 1 : just return
5276 //    1 =&gt; 1 : just return
5277 //   -1 =&gt; either 0 or 1; must signal target thread
5278 //         That is, we can safely transition _Event from -1 to either
5279 //         0 or 1.
5280 //
5281 // _Event serves as a restricted-range semaphore.
5282 //   -1 : thread is blocked, i.e. there is a waiter
5283 //    0 : neutral: thread is running or ready,
5284 //        could have been signaled after a wait started
5285 //    1 : signaled - thread is running or ready
5286 //
5287 // Another possible encoding of _Event would be with
5288 // explicit &quot;PARKED&quot; == 01b and &quot;SIGNALED&quot; == 10b bits.
5289 //
5290 
5291 int os::PlatformEvent::park(jlong Millis) {
5292   // Transitions for _Event:
5293   //   -1 =&gt; -1 : illegal
5294   //    1 =&gt;  0 : pass - return immediately
5295   //    0 =&gt; -1 : block; then set _Event to 0 before returning
5296 
5297   guarantee(_ParkHandle != NULL , &quot;Invariant&quot;);
5298   guarantee(Millis &gt; 0          , &quot;Invariant&quot;);
5299 
5300   // CONSIDER: defer assigning a CreateEvent() handle to the Event until
5301   // the initial park() operation.
5302   // Consider: use atomic decrement instead of CAS-loop
5303 
5304   int v;
5305   for (;;) {
5306     v = _Event;
5307     if (Atomic::cmpxchg(&amp;_Event, v, v-1) == v) break;
5308   }
5309   guarantee((v == 0) || (v == 1), &quot;invariant&quot;);
5310   if (v != 0) return OS_OK;
5311 
5312   // Do this the hard way by blocking ...
5313   // TODO: consider a brief spin here, gated on the success of recent
5314   // spin attempts by this thread.
5315   //
5316   // We decompose long timeouts into series of shorter timed waits.
5317   // Evidently large timo values passed in WaitForSingleObject() are problematic on some
5318   // versions of Windows.  See EventWait() for details.  This may be superstition.  Or not.
5319   // We trust the WAIT_TIMEOUT indication and don&#39;t track the elapsed wait time
5320   // with os::javaTimeNanos().  Furthermore, we assume that spurious returns from
5321   // ::WaitForSingleObject() caused by latent ::setEvent() operations will tend
5322   // to happen early in the wait interval.  Specifically, after a spurious wakeup (rv ==
5323   // WAIT_OBJECT_0 but _Event is still &lt; 0) we don&#39;t bother to recompute Millis to compensate
5324   // for the already waited time.  This policy does not admit any new outcomes.
5325   // In the future, however, we might want to track the accumulated wait time and
5326   // adjust Millis accordingly if we encounter a spurious wakeup.
5327 
5328   const int MAXTIMEOUT = 0x10000000;
5329   DWORD rv = WAIT_TIMEOUT;
5330   while (_Event &lt; 0 &amp;&amp; Millis &gt; 0) {
5331     DWORD prd = Millis;     // set prd = MAX (Millis, MAXTIMEOUT)
5332     if (Millis &gt; MAXTIMEOUT) {
5333       prd = MAXTIMEOUT;
5334     }
5335     HighResolutionInterval *phri = NULL;
5336     if (!ForceTimeHighResolution) {
5337       phri = new HighResolutionInterval(prd);
5338     }
5339     rv = ::WaitForSingleObject(_ParkHandle, prd);
5340     assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, &quot;WaitForSingleObject failed&quot;);
5341     if (rv == WAIT_TIMEOUT) {
5342       Millis -= prd;
5343     }
5344     delete phri; // if it is NULL, harmless
5345   }
5346   v = _Event;
5347   _Event = 0;
5348   // see comment at end of os::PlatformEvent::park() below:
5349   OrderAccess::fence();
5350   // If we encounter a nearly simultanous timeout expiry and unpark()
5351   // we return OS_OK indicating we awoke via unpark().
5352   // Implementor&#39;s license -- returning OS_TIMEOUT would be equally valid, however.
5353   return (v &gt;= 0) ? OS_OK : OS_TIMEOUT;
5354 }
5355 
5356 void os::PlatformEvent::park() {
5357   // Transitions for _Event:
5358   //   -1 =&gt; -1 : illegal
5359   //    1 =&gt;  0 : pass - return immediately
5360   //    0 =&gt; -1 : block; then set _Event to 0 before returning
5361 
5362   guarantee(_ParkHandle != NULL, &quot;Invariant&quot;);
5363   // Invariant: Only the thread associated with the Event/PlatformEvent
5364   // may call park().
5365   // Consider: use atomic decrement instead of CAS-loop
5366   int v;
5367   for (;;) {
5368     v = _Event;
5369     if (Atomic::cmpxchg(&amp;_Event, v, v-1) == v) break;
5370   }
5371   guarantee((v == 0) || (v == 1), &quot;invariant&quot;);
5372   if (v != 0) return;
5373 
5374   // Do this the hard way by blocking ...
5375   // TODO: consider a brief spin here, gated on the success of recent
5376   // spin attempts by this thread.
5377   while (_Event &lt; 0) {
5378     DWORD rv = ::WaitForSingleObject(_ParkHandle, INFINITE);
5379     assert(rv == WAIT_OBJECT_0, &quot;WaitForSingleObject failed&quot;);
5380   }
5381 
5382   // Usually we&#39;ll find _Event == 0 at this point, but as
5383   // an optional optimization we clear it, just in case can
5384   // multiple unpark() operations drove _Event up to 1.
5385   _Event = 0;
5386   OrderAccess::fence();
5387   guarantee(_Event &gt;= 0, &quot;invariant&quot;);
5388 }
5389 
5390 void os::PlatformEvent::unpark() {
5391   guarantee(_ParkHandle != NULL, &quot;Invariant&quot;);
5392 
5393   // Transitions for _Event:
5394   //    0 =&gt; 1 : just return
5395   //    1 =&gt; 1 : just return
5396   //   -1 =&gt; either 0 or 1; must signal target thread
5397   //         That is, we can safely transition _Event from -1 to either
5398   //         0 or 1.
5399   // See also: &quot;Semaphores in Plan 9&quot; by Mullender &amp; Cox
5400   //
5401   // Note: Forcing a transition from &quot;-1&quot; to &quot;1&quot; on an unpark() means
5402   // that it will take two back-to-back park() calls for the owning
5403   // thread to block. This has the benefit of forcing a spurious return
5404   // from the first park() call after an unpark() call which will help
5405   // shake out uses of park() and unpark() without condition variables.
5406 
5407   if (Atomic::xchg(&amp;_Event, 1) &gt;= 0) return;
5408 
5409   ::SetEvent(_ParkHandle);
5410 }
5411 
5412 
5413 // JSR166
5414 // -------------------------------------------------------
5415 
5416 // The Windows implementation of Park is very straightforward: Basic
5417 // operations on Win32 Events turn out to have the right semantics to
5418 // use them directly. We opportunistically resuse the event inherited
5419 // from Monitor.
5420 
5421 void Parker::park(bool isAbsolute, jlong time) {
5422   guarantee(_ParkEvent != NULL, &quot;invariant&quot;);
5423   // First, demultiplex/decode time arguments
5424   if (time &lt; 0) { // don&#39;t wait
5425     return;
5426   } else if (time == 0 &amp;&amp; !isAbsolute) {
5427     time = INFINITE;
5428   } else if (isAbsolute) {
5429     time -= os::javaTimeMillis(); // convert to relative time
5430     if (time &lt;= 0) {  // already elapsed
5431       return;
5432     }
5433   } else { // relative
5434     time /= 1000000;  // Must coarsen from nanos to millis
5435     if (time == 0) {  // Wait for the minimal time unit if zero
5436       time = 1;
5437     }
5438   }
5439 
5440   JavaThread* thread = JavaThread::current();
5441 
5442   // Don&#39;t wait if interrupted or already triggered
5443   if (thread-&gt;is_interrupted(false) ||
5444       WaitForSingleObject(_ParkEvent, 0) == WAIT_OBJECT_0) {
5445     ResetEvent(_ParkEvent);
5446     return;
5447   } else {
5448     ThreadBlockInVM tbivm(thread);
5449     OSThreadWaitState osts(thread-&gt;osthread(), false /* not Object.wait() */);
5450     thread-&gt;set_suspend_equivalent();
5451 
5452     WaitForSingleObject(_ParkEvent, time);
5453     ResetEvent(_ParkEvent);
5454 
5455     // If externally suspended while waiting, re-suspend
5456     if (thread-&gt;handle_special_suspend_equivalent_condition()) {
5457       thread-&gt;java_suspend_self();
5458     }
5459   }
5460 }
5461 
5462 void Parker::unpark() {
5463   guarantee(_ParkEvent != NULL, &quot;invariant&quot;);
5464   SetEvent(_ParkEvent);
5465 }
5466 
5467 // Platform Monitor implementation
5468 
5469 // Must already be locked
5470 int os::PlatformMonitor::wait(jlong millis) {
5471   assert(millis &gt;= 0, &quot;negative timeout&quot;);
5472   int ret = OS_TIMEOUT;
5473   int status = SleepConditionVariableCS(&amp;_cond, &amp;_mutex,
5474                                         millis == 0 ? INFINITE : millis);
5475   if (status != 0) {
5476     ret = OS_OK;
5477   }
5478   #ifndef PRODUCT
5479   else {
5480     DWORD err = GetLastError();
5481     assert(err == ERROR_TIMEOUT, &quot;SleepConditionVariableCS: %ld:&quot;, err);
5482   }
5483   #endif
5484   return ret;
5485 }
5486 
5487 // Run the specified command in a separate process. Return its exit value,
5488 // or -1 on failure (e.g. can&#39;t create a new process).
5489 int os::fork_and_exec(char* cmd, bool use_vfork_if_available) {
5490   STARTUPINFO si;
5491   PROCESS_INFORMATION pi;
5492   DWORD exit_code;
5493 
5494   char * cmd_string;
5495   const char * cmd_prefix = &quot;cmd /C &quot;;
5496   size_t len = strlen(cmd) + strlen(cmd_prefix) + 1;
5497   cmd_string = NEW_C_HEAP_ARRAY_RETURN_NULL(char, len, mtInternal);
5498   if (cmd_string == NULL) {
5499     return -1;
5500   }
5501   cmd_string[0] = &#39;\0&#39;;
5502   strcat(cmd_string, cmd_prefix);
5503   strcat(cmd_string, cmd);
5504 
5505   // now replace all &#39;\n&#39; with &#39;&amp;&#39;
5506   char * substring = cmd_string;
5507   while ((substring = strchr(substring, &#39;\n&#39;)) != NULL) {
5508     substring[0] = &#39;&amp;&#39;;
5509     substring++;
5510   }
5511   memset(&amp;si, 0, sizeof(si));
5512   si.cb = sizeof(si);
5513   memset(&amp;pi, 0, sizeof(pi));
5514   BOOL rslt = CreateProcess(NULL,   // executable name - use command line
5515                             cmd_string,    // command line
5516                             NULL,   // process security attribute
5517                             NULL,   // thread security attribute
5518                             TRUE,   // inherits system handles
5519                             0,      // no creation flags
5520                             NULL,   // use parent&#39;s environment block
5521                             NULL,   // use parent&#39;s starting directory
5522                             &amp;si,    // (in) startup information
5523                             &amp;pi);   // (out) process information
5524 
5525   if (rslt) {
5526     // Wait until child process exits.
5527     WaitForSingleObject(pi.hProcess, INFINITE);
5528 
5529     GetExitCodeProcess(pi.hProcess, &amp;exit_code);
5530 
5531     // Close process and thread handles.
5532     CloseHandle(pi.hProcess);
5533     CloseHandle(pi.hThread);
5534   } else {
5535     exit_code = -1;
5536   }
5537 
5538   FREE_C_HEAP_ARRAY(char, cmd_string);
5539   return (int)exit_code;
5540 }
5541 
5542 bool os::find(address addr, outputStream* st) {
5543   int offset = -1;
5544   bool result = false;
5545   char buf[256];
5546   if (os::dll_address_to_library_name(addr, buf, sizeof(buf), &amp;offset)) {
5547     st-&gt;print(PTR_FORMAT &quot; &quot;, addr);
5548     if (strlen(buf) &lt; sizeof(buf) - 1) {
5549       char* p = strrchr(buf, &#39;\\&#39;);
5550       if (p) {
5551         st-&gt;print(&quot;%s&quot;, p + 1);
5552       } else {
5553         st-&gt;print(&quot;%s&quot;, buf);
5554       }
5555     } else {
5556         // The library name is probably truncated. Let&#39;s omit the library name.
5557         // See also JDK-8147512.
5558     }
5559     if (os::dll_address_to_function_name(addr, buf, sizeof(buf), &amp;offset)) {
5560       st-&gt;print(&quot;::%s + 0x%x&quot;, buf, offset);
5561     }
5562     st-&gt;cr();
5563     result = true;
5564   }
5565   return result;
5566 }
5567 
5568 static jint initSock() {
5569   WSADATA wsadata;
5570 
5571   if (WSAStartup(MAKEWORD(2,2), &amp;wsadata) != 0) {
5572     jio_fprintf(stderr, &quot;Could not initialize Winsock (error: %d)\n&quot;,
5573                 ::GetLastError());
5574     return JNI_ERR;
5575   }
5576   return JNI_OK;
5577 }
5578 
5579 struct hostent* os::get_host_by_name(char* name) {
5580   return (struct hostent*)gethostbyname(name);
5581 }
5582 
5583 int os::socket_close(int fd) {
5584   return ::closesocket(fd);
5585 }
5586 
5587 int os::socket(int domain, int type, int protocol) {
5588   return ::socket(domain, type, protocol);
5589 }
5590 
5591 int os::connect(int fd, struct sockaddr* him, socklen_t len) {
5592   return ::connect(fd, him, len);
5593 }
5594 
5595 int os::recv(int fd, char* buf, size_t nBytes, uint flags) {
5596   return ::recv(fd, buf, (int)nBytes, flags);
5597 }
5598 
5599 int os::send(int fd, char* buf, size_t nBytes, uint flags) {
5600   return ::send(fd, buf, (int)nBytes, flags);
5601 }
5602 
5603 int os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {
5604   return ::send(fd, buf, (int)nBytes, flags);
5605 }
5606 
5607 // WINDOWS CONTEXT Flags for THREAD_SAMPLING
5608 #if defined(IA32)
5609   #define sampling_context_flags (CONTEXT_FULL | CONTEXT_FLOATING_POINT | CONTEXT_EXTENDED_REGISTERS)
5610 #elif defined (AMD64)
5611   #define sampling_context_flags (CONTEXT_FULL | CONTEXT_FLOATING_POINT)
5612 #endif
5613 
5614 // returns true if thread could be suspended,
5615 // false otherwise
5616 static bool do_suspend(HANDLE* h) {
5617   if (h != NULL) {
5618     if (SuspendThread(*h) != ~0) {
5619       return true;
5620     }
5621   }
5622   return false;
5623 }
5624 
5625 // resume the thread
5626 // calling resume on an active thread is a no-op
5627 static void do_resume(HANDLE* h) {
5628   if (h != NULL) {
5629     ResumeThread(*h);
5630   }
5631 }
5632 
5633 // retrieve a suspend/resume context capable handle
5634 // from the tid. Caller validates handle return value.
5635 void get_thread_handle_for_extended_context(HANDLE* h,
5636                                             OSThread::thread_id_t tid) {
5637   if (h != NULL) {
5638     *h = OpenThread(THREAD_SUSPEND_RESUME | THREAD_GET_CONTEXT | THREAD_QUERY_INFORMATION, FALSE, tid);
5639   }
5640 }
5641 
5642 // Thread sampling implementation
5643 //
5644 void os::SuspendedThreadTask::internal_do_task() {
5645   CONTEXT    ctxt;
5646   HANDLE     h = NULL;
5647 
5648   // get context capable handle for thread
5649   get_thread_handle_for_extended_context(&amp;h, _thread-&gt;osthread()-&gt;thread_id());
5650 
5651   // sanity
5652   if (h == NULL || h == INVALID_HANDLE_VALUE) {
5653     return;
5654   }
5655 
5656   // suspend the thread
5657   if (do_suspend(&amp;h)) {
5658     ctxt.ContextFlags = sampling_context_flags;
5659     // get thread context
5660     GetThreadContext(h, &amp;ctxt);
5661     SuspendedThreadTaskContext context(_thread, &amp;ctxt);
5662     // pass context to Thread Sampling impl
5663     do_task(context);
5664     // resume thread
5665     do_resume(&amp;h);
5666   }
5667 
5668   // close handle
5669   CloseHandle(h);
5670 }
5671 
5672 bool os::start_debugging(char *buf, int buflen) {
5673   int len = (int)strlen(buf);
5674   char *p = &amp;buf[len];
5675 
5676   jio_snprintf(p, buflen-len,
5677              &quot;\n\n&quot;
5678              &quot;Do you want to debug the problem?\n\n&quot;
5679              &quot;To debug, attach Visual Studio to process %d; then switch to thread 0x%x\n&quot;
5680              &quot;Select &#39;Yes&#39; to launch Visual Studio automatically (PATH must include msdev)\n&quot;
5681              &quot;Otherwise, select &#39;No&#39; to abort...&quot;,
5682              os::current_process_id(), os::current_thread_id());
5683 
5684   bool yes = os::message_box(&quot;Unexpected Error&quot;, buf);
5685 
5686   if (yes) {
5687     // os::breakpoint() calls DebugBreak(), which causes a breakpoint
5688     // exception. If VM is running inside a debugger, the debugger will
5689     // catch the exception. Otherwise, the breakpoint exception will reach
5690     // the default windows exception handler, which can spawn a debugger and
5691     // automatically attach to the dying VM.
5692     os::breakpoint();
5693     yes = false;
5694   }
5695   return yes;
5696 }
5697 
5698 void* os::get_default_process_handle() {
5699   return (void*)GetModuleHandle(NULL);
5700 }
5701 
5702 // Builds a platform dependent Agent_OnLoad_&lt;lib_name&gt; function name
5703 // which is used to find statically linked in agents.
5704 // Additionally for windows, takes into account __stdcall names.
5705 // Parameters:
5706 //            sym_name: Symbol in library we are looking for
5707 //            lib_name: Name of library to look in, NULL for shared libs.
5708 //            is_absolute_path == true if lib_name is absolute path to agent
5709 //                                     such as &quot;C:/a/b/L.dll&quot;
5710 //            == false if only the base name of the library is passed in
5711 //               such as &quot;L&quot;
5712 char* os::build_agent_function_name(const char *sym_name, const char *lib_name,
5713                                     bool is_absolute_path) {
5714   char *agent_entry_name;
5715   size_t len;
5716   size_t name_len;
5717   size_t prefix_len = strlen(JNI_LIB_PREFIX);
5718   size_t suffix_len = strlen(JNI_LIB_SUFFIX);
5719   const char *start;
5720 
5721   if (lib_name != NULL) {
5722     len = name_len = strlen(lib_name);
5723     if (is_absolute_path) {
5724       // Need to strip path, prefix and suffix
5725       if ((start = strrchr(lib_name, *os::file_separator())) != NULL) {
5726         lib_name = ++start;
5727       } else {
5728         // Need to check for drive prefix
5729         if ((start = strchr(lib_name, &#39;:&#39;)) != NULL) {
5730           lib_name = ++start;
5731         }
5732       }
5733       if (len &lt;= (prefix_len + suffix_len)) {
5734         return NULL;
5735       }
5736       lib_name += prefix_len;
5737       name_len = strlen(lib_name) - suffix_len;
5738     }
5739   }
5740   len = (lib_name != NULL ? name_len : 0) + strlen(sym_name) + 2;
5741   agent_entry_name = NEW_C_HEAP_ARRAY_RETURN_NULL(char, len, mtThread);
5742   if (agent_entry_name == NULL) {
5743     return NULL;
5744   }
5745   if (lib_name != NULL) {
5746     const char *p = strrchr(sym_name, &#39;@&#39;);
5747     if (p != NULL &amp;&amp; p != sym_name) {
5748       // sym_name == _Agent_OnLoad@XX
5749       strncpy(agent_entry_name, sym_name, (p - sym_name));
5750       agent_entry_name[(p-sym_name)] = &#39;\0&#39;;
5751       // agent_entry_name == _Agent_OnLoad
5752       strcat(agent_entry_name, &quot;_&quot;);
5753       strncat(agent_entry_name, lib_name, name_len);
5754       strcat(agent_entry_name, p);
5755       // agent_entry_name == _Agent_OnLoad_lib_name@XX
5756     } else {
5757       strcpy(agent_entry_name, sym_name);
5758       strcat(agent_entry_name, &quot;_&quot;);
5759       strncat(agent_entry_name, lib_name, name_len);
5760     }
5761   } else {
5762     strcpy(agent_entry_name, sym_name);
5763   }
5764   return agent_entry_name;
5765 }
5766 
5767 #ifndef PRODUCT
5768 
5769 // test the code path in reserve_memory_special() that tries to allocate memory in a single
5770 // contiguous memory block at a particular address.
5771 // The test first tries to find a good approximate address to allocate at by using the same
5772 // method to allocate some memory at any address. The test then tries to allocate memory in
5773 // the vicinity (not directly after it to avoid possible by-chance use of that location)
5774 // This is of course only some dodgy assumption, there is no guarantee that the vicinity of
5775 // the previously allocated memory is available for allocation. The only actual failure
5776 // that is reported is when the test tries to allocate at a particular location but gets a
5777 // different valid one. A NULL return value at this point is not considered an error but may
5778 // be legitimate.
5779 void TestReserveMemorySpecial_test() {
5780   if (!UseLargePages) {
5781     return;
5782   }
5783   // save current value of globals
5784   bool old_use_large_pages_individual_allocation = UseLargePagesIndividualAllocation;
5785   bool old_use_numa_interleaving = UseNUMAInterleaving;
5786 
5787   // set globals to make sure we hit the correct code path
5788   UseLargePagesIndividualAllocation = UseNUMAInterleaving = false;
5789 
5790   // do an allocation at an address selected by the OS to get a good one.
5791   const size_t large_allocation_size = os::large_page_size() * 4;
5792   char* result = os::reserve_memory_special(large_allocation_size, os::large_page_size(), NULL, false);
5793   if (result == NULL) {
5794   } else {
5795     os::release_memory_special(result, large_allocation_size);
5796 
5797     // allocate another page within the recently allocated memory area which seems to be a good location. At least
5798     // we managed to get it once.
5799     const size_t expected_allocation_size = os::large_page_size();
5800     char* expected_location = result + os::large_page_size();
5801     char* actual_location = os::reserve_memory_special(expected_allocation_size, os::large_page_size(), expected_location, false);
5802     if (actual_location == NULL) {
5803     } else {
5804       // release memory
5805       os::release_memory_special(actual_location, expected_allocation_size);
5806       // only now check, after releasing any memory to avoid any leaks.
5807       assert(actual_location == expected_location,
5808              &quot;Failed to allocate memory at requested location &quot; PTR_FORMAT &quot; of size &quot; SIZE_FORMAT &quot;, is &quot; PTR_FORMAT &quot; instead&quot;,
5809              expected_location, expected_allocation_size, actual_location);
5810     }
5811   }
5812 
5813   // restore globals
5814   UseLargePagesIndividualAllocation = old_use_large_pages_individual_allocation;
5815   UseNUMAInterleaving = old_use_numa_interleaving;
5816 }
5817 #endif // PRODUCT
5818 
5819 /*
5820   All the defined signal names for Windows.
5821 
5822   NOTE that not all of these names are accepted by FindSignal!
5823 
5824   For various reasons some of these may be rejected at runtime.
5825 
5826   Here are the names currently accepted by a user of sun.misc.Signal with
5827   1.4.1 (ignoring potential interaction with use of chaining, etc):
5828 
5829      (LIST TBD)
5830 
5831 */
5832 int os::get_signal_number(const char* name) {
5833   static const struct {
5834     const char* name;
5835     int         number;
5836   } siglabels [] =
5837     // derived from version 6.0 VC98/include/signal.h
5838   {&quot;ABRT&quot;,      SIGABRT,        // abnormal termination triggered by abort cl
5839   &quot;FPE&quot;,        SIGFPE,         // floating point exception
5840   &quot;SEGV&quot;,       SIGSEGV,        // segment violation
5841   &quot;INT&quot;,        SIGINT,         // interrupt
5842   &quot;TERM&quot;,       SIGTERM,        // software term signal from kill
5843   &quot;BREAK&quot;,      SIGBREAK,       // Ctrl-Break sequence
5844   &quot;ILL&quot;,        SIGILL};        // illegal instruction
5845   for (unsigned i = 0; i &lt; ARRAY_SIZE(siglabels); ++i) {
5846     if (strcmp(name, siglabels[i].name) == 0) {
5847       return siglabels[i].number;
5848     }
5849   }
5850   return -1;
5851 }
5852 
5853 // Fast current thread access
5854 
5855 int os::win32::_thread_ptr_offset = 0;
5856 
5857 static void call_wrapper_dummy() {}
5858 
5859 // We need to call the os_exception_wrapper once so that it sets
5860 // up the offset from FS of the thread pointer.
5861 void os::win32::initialize_thread_ptr_offset() {
5862   os::os_exception_wrapper((java_call_t)call_wrapper_dummy,
5863                            NULL, methodHandle(), NULL, NULL);
5864 }
5865 
5866 bool os::supports_map_sync() {
5867   return false;
5868 }
    </pre>
  </body>
</html>