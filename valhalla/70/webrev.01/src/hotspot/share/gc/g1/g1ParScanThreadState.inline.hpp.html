<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/g1/g1ParScanThreadState.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2014, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
 26 #define SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
 27 
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 29 #include &quot;gc/g1/g1OopStarChunkedList.inline.hpp&quot;
 30 #include &quot;gc/g1/g1ParScanThreadState.hpp&quot;
 31 #include &quot;gc/g1/g1RemSet.hpp&quot;
 32 #include &quot;oops/access.inline.hpp&quot;
 33 #include &quot;oops/oop.inline.hpp&quot;
 34 
 35 template &lt;class T&gt; void G1ParScanThreadState::do_oop_evac(T* p) {
 36   // Reference should not be NULL here as such are never pushed to the task queue.
 37   oop obj = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
 38 
 39   // Although we never intentionally push references outside of the collection
 40   // set, due to (benign) races in the claim mechanism during RSet scanning more
 41   // than one thread might claim the same card. So the same card may be
 42   // processed multiple times, and so we might get references into old gen here.
 43   // So we need to redo this check.
 44   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);
 45   // References pushed onto the work stack should never point to a humongous region
 46   // as they are not added to the collection set due to above precondition.
 47   assert(!region_attr.is_humongous(),
 48          &quot;Obj &quot; PTR_FORMAT &quot; should not refer to humongous region %u from &quot; PTR_FORMAT,
 49          p2i(obj), _g1h-&gt;addr_to_region(cast_from_oop&lt;HeapWord*&gt;(obj)), p2i(p));
 50 
 51   if (!region_attr.is_in_cset()) {
 52     // In this case somebody else already did all the work.
 53     return;
 54   }
 55 
 56   markWord m = obj-&gt;mark_raw();
 57   if (m.is_marked()) {
 58     obj = (oop) m.decode_pointer();
 59   } else {
 60     obj = copy_to_survivor_space(region_attr, obj, m);
 61   }
 62   RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, obj);
 63 
 64   assert(obj != NULL, &quot;Must be&quot;);
 65   if (HeapRegion::is_in_same_region(p, obj)) {
 66     return;
 67   }
 68   HeapRegion* from = _g1h-&gt;heap_region_containing(p);
 69   if (!from-&gt;is_young()) {
 70     enqueue_card_if_tracked(_g1h-&gt;region_attr(obj), p, obj);
 71   }
 72 }
 73 
 74 inline void G1ParScanThreadState::push_on_queue(ScannerTask task) {
 75   verify_task(task);
 76   _task_queue-&gt;push(task);
 77 }
 78 
 79 inline void G1ParScanThreadState::do_partial_array(PartialArrayScanTask task) {
 80   oop from_obj = task.to_source_array();
 81 
 82   assert(_g1h-&gt;is_in_reserved(from_obj), &quot;must be in heap.&quot;);
 83   assert(from_obj-&gt;is_objArray(), &quot;must be obj array&quot;);
 84   objArrayOop from_obj_array = objArrayOop(from_obj);
 85   // The from-space object contains the real length.
 86   int length                 = from_obj_array-&gt;length();
 87 
 88   assert(from_obj-&gt;is_forwarded(), &quot;must be forwarded&quot;);
 89   oop to_obj                 = from_obj-&gt;forwardee();
 90   assert(from_obj != to_obj, &quot;should not be chunking self-forwarded objects&quot;);
 91   objArrayOop to_obj_array   = objArrayOop(to_obj);
 92   // We keep track of the next start index in the length field of the
 93   // to-space object.
 94   int next_index             = to_obj_array-&gt;length();
 95   assert(0 &lt;= next_index &amp;&amp; next_index &lt; length,
 96          &quot;invariant, next index: %d, length: %d&quot;, next_index, length);
 97 
 98   int start                  = next_index;
 99   int end                    = length;
100   int remainder              = end - start;
101   // We&#39;ll try not to push a range that&#39;s smaller than ParGCArrayScanChunk.
102   if (remainder &gt; 2 * ParGCArrayScanChunk) {
103     end = start + ParGCArrayScanChunk;
104     to_obj_array-&gt;set_length(end);
105     // Push the remainder before we process the range in case another
106     // worker has run out of things to do and can steal it.
107     push_on_queue(ScannerTask(PartialArrayScanTask(from_obj)));
108   } else {
109     assert(length == end, &quot;sanity&quot;);
110     // We&#39;ll process the final range for this object. Restore the length
111     // so that the heap remains parsable in case of evacuation failure.
112     to_obj_array-&gt;set_length(end);
113   }
114 
115   HeapRegion* hr = _g1h-&gt;heap_region_containing(to_obj);
116   G1ScanInYoungSetter x(&amp;_scanner, hr-&gt;is_young());
117   // Process indexes [start,end). It will also process the header
118   // along with the first chunk (i.e., the chunk with start == 0).
119   // Note that at this point the length field of to_obj_array is not
120   // correct given that we are using it to keep track of the next
121   // start index. oop_iterate_range() (thankfully!) ignores the length
122   // field and only relies on the start / end parameters.  It does
123   // however return the size of the object which will be incorrect. So
124   // we have to ignore it even if we wanted to use it.
125   to_obj_array-&gt;oop_iterate_range(&amp;_scanner, start, end);
126 }
127 
128 inline void G1ParScanThreadState::dispatch_task(ScannerTask task) {
129   verify_task(task);
130   if (task.is_narrow_oop_ptr()) {
131     do_oop_evac(task.to_narrow_oop_ptr());
132   } else if (task.is_oop_ptr()) {
133     do_oop_evac(task.to_oop_ptr());
134   } else {
135     do_partial_array(task.to_partial_array_task());
136   }
137 }
138 
139 void G1ParScanThreadState::steal_and_trim_queue(ScannerTasksQueueSet *task_queues) {
140   ScannerTask stolen_task;
141   while (task_queues-&gt;steal(_worker_id, stolen_task)) {
142     dispatch_task(stolen_task);
143 
144     // We&#39;ve just processed a task and we might have made
145     // available new entries on the queues. So we have to make sure
146     // we drain the queues as necessary.
147     trim_queue();
148   }
149 }
150 
151 inline bool G1ParScanThreadState::needs_partial_trimming() const {
152   return !_task_queue-&gt;overflow_empty() ||
153          (_task_queue-&gt;size() &gt; _stack_trim_upper_threshold);
154 }
155 
156 inline bool G1ParScanThreadState::is_partially_trimmed() const {
157   return _task_queue-&gt;overflow_empty() &amp;&amp;
158          (_task_queue-&gt;size() &lt;= _stack_trim_lower_threshold);
159 }
160 
161 inline void G1ParScanThreadState::trim_queue_to_threshold(uint threshold) {
162   ScannerTask task;
163   // Drain the overflow stack first, so other threads can potentially steal.
164   while (_task_queue-&gt;pop_overflow(task)) {
165     if (!_task_queue-&gt;try_push_to_taskqueue(task)) {
166       dispatch_task(task);
167     }
168   }
169 
170   while (_task_queue-&gt;pop_local(task, threshold)) {
171     dispatch_task(task);
172   }
173 }
174 
175 inline void G1ParScanThreadState::trim_queue_partially() {
176   if (!needs_partial_trimming()) {
177     return;
178   }
179 
180   const Ticks start = Ticks::now();
181   do {
182     trim_queue_to_threshold(_stack_trim_lower_threshold);
183   } while (!is_partially_trimmed());
184   _trim_ticks += Ticks::now() - start;
185 }
186 
187 inline Tickspan G1ParScanThreadState::trim_ticks() const {
188   return _trim_ticks;
189 }
190 
191 inline void G1ParScanThreadState::reset_trim_ticks() {
192   _trim_ticks = Tickspan();
193 }
194 
195 template &lt;typename T&gt;
196 inline void G1ParScanThreadState::remember_root_into_optional_region(T* p) {
197   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
198   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
199   assert(index &lt; _num_optional_regions,
200          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
201   _oops_into_optional_regions[index].push_root(p);
202 }
203 
204 template &lt;typename T&gt;
205 inline void G1ParScanThreadState::remember_reference_into_optional_region(T* p) {
206   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
207   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
208   assert(index &lt; _num_optional_regions,
209          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
210   _oops_into_optional_regions[index].push_oop(p);
211   verify_task(p);
212 }
213 
214 G1OopStarChunkedList* G1ParScanThreadState::oops_into_optional_region(const HeapRegion* hr) {
215   assert(hr-&gt;index_in_opt_cset() &lt; _num_optional_regions,
216          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT &quot; &quot; HR_FORMAT,
217          hr-&gt;index_in_opt_cset(), _num_optional_regions, HR_FORMAT_PARAMS(hr));
218   return &amp;_oops_into_optional_regions[hr-&gt;index_in_opt_cset()];
219 }
220 
221 void G1ParScanThreadState::initialize_numa_stats() {
222   if (_numa-&gt;is_enabled()) {
223     LogTarget(Info, gc, heap, numa) lt;
224 
225     if (lt.is_enabled()) {
226       uint num_nodes = _numa-&gt;num_active_nodes();
227       // Record only if there are multiple active nodes.
228       _obj_alloc_stat = NEW_C_HEAP_ARRAY(size_t, num_nodes, mtGC);
229       memset(_obj_alloc_stat, 0, sizeof(size_t) * num_nodes);
230     }
231   }
232 }
233 
234 void G1ParScanThreadState::flush_numa_stats() {
235   if (_obj_alloc_stat != NULL) {
236     uint node_index = _numa-&gt;index_of_current_thread();
237     _numa-&gt;copy_statistics(G1NUMAStats::LocalObjProcessAtCopyToSurv, node_index, _obj_alloc_stat);
238   }
239 }
240 
241 void G1ParScanThreadState::update_numa_stats(uint node_index) {
242   if (_obj_alloc_stat != NULL) {
243     _obj_alloc_stat[node_index]++;
244   }
245 }
246 
247 #endif // SHARE_GC_G1_G1PARSCANTHREADSTATE_INLINE_HPP
    </pre>
  </body>
</html>