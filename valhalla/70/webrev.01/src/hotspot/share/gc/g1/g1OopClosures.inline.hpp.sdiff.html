<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1OopClosures.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1GCPhaseTimes.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1ParScanThreadState.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1OopClosures.inline.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 41 #include &quot;utilities/align.hpp&quot;
 42 
 43 template &lt;class T&gt;
 44 inline void G1ScanClosureBase::prefetch_and_push(T* p, const oop obj) {
 45   // We&#39;re not going to even bother checking whether the object is
 46   // already forwarded or not, as this usually causes an immediate
 47   // stall. We&#39;ll try to prefetch the object (for write, given that
 48   // we might need to install the forwarding reference) and we&#39;ll
 49   // get back to it when pop it from the queue
 50   Prefetch::write(obj-&gt;mark_addr_raw(), 0);
 51   Prefetch::read(obj-&gt;mark_addr_raw(), (HeapWordSize*2));
 52 
 53   // slightly paranoid test; I&#39;m trying to catch potential
 54   // problems before we go into push_on_queue to know where the
 55   // problem is coming from
 56   assert((obj == RawAccess&lt;&gt;::oop_load(p)) ||
 57          (obj-&gt;is_forwarded() &amp;&amp;
 58          obj-&gt;forwardee() == RawAccess&lt;&gt;::oop_load(p)),
 59          &quot;p should still be pointing to obj or to its forwardee&quot;);
 60 
<span class="line-modified"> 61   _par_scan_state-&gt;push_on_queue(p);</span>
 62 }
 63 
 64 template &lt;class T&gt;
 65 inline void G1ScanClosureBase::handle_non_cset_obj_common(G1HeapRegionAttr const region_attr, T* p, oop const obj) {
 66   if (region_attr.is_humongous()) {
 67     _g1h-&gt;set_humongous_is_live(obj);
 68   } else if (region_attr.is_optional()) {
 69     _par_scan_state-&gt;remember_reference_into_optional_region(p);
 70   }
 71 }
 72 
 73 inline void G1ScanClosureBase::trim_queue_partially() {
 74   _par_scan_state-&gt;trim_queue_partially();
 75 }
 76 
 77 template &lt;class T&gt;
 78 inline void G1ScanEvacuatedObjClosure::do_oop_work(T* p) {
 79   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
 80 
 81   if (CompressedOops::is_null(heap_oop)) {
</pre>
<hr />
<pre>
 85   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);
 86   if (region_attr.is_in_cset()) {
 87     prefetch_and_push(p, obj);
 88   } else if (!HeapRegion::is_in_same_region(p, obj)) {
 89     handle_non_cset_obj_common(region_attr, p, obj);
 90     assert(_scanning_in_young != Uninitialized, &quot;Scan location has not been initialized.&quot;);
 91     if (_scanning_in_young == True) {
 92       return;
 93     }
 94     _par_scan_state-&gt;enqueue_card_if_tracked(region_attr, p, obj);
 95   }
 96 }
 97 
 98 template &lt;class T&gt;
 99 inline void G1CMOopClosure::do_oop_work(T* p) {
100   _task-&gt;deal_with_reference(p);
101 }
102 
103 template &lt;class T&gt;
104 inline void G1RootRegionScanClosure::do_oop_work(T* p) {
<span class="line-modified">105   T heap_oop = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);</span>
106   if (CompressedOops::is_null(heap_oop)) {
107     return;
108   }
109   oop obj = CompressedOops::decode_not_null(heap_oop);
110   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
111 }
112 
113 template &lt;class T&gt;
114 inline static void check_obj_during_refinement(T* p, oop const obj) {
115 #ifdef ASSERT
116   G1CollectedHeap* g1h = G1CollectedHeap::heap();
117   // can&#39;t do because of races
118   // assert(oopDesc::is_oop_or_null(obj), &quot;expected an oop&quot;);
119   assert(is_object_aligned(obj), &quot;oop must be aligned&quot;);
120   assert(g1h-&gt;is_in_reserved(obj), &quot;oop must be in reserved&quot;);
121 
122   HeapRegion* from = g1h-&gt;heap_region_containing(p);
123 
124   assert(from != NULL, &quot;from region must be non-NULL&quot;);
125   assert(from-&gt;is_in_reserved(p) ||
126          (from-&gt;is_humongous() &amp;&amp;
127           g1h-&gt;heap_region_containing(p)-&gt;is_humongous() &amp;&amp;
128           from-&gt;humongous_start_region() == g1h-&gt;heap_region_containing(p)-&gt;humongous_start_region()),
129          &quot;p &quot; PTR_FORMAT &quot; is not in the same region %u or part of the correct humongous object starting at region %u.&quot;,
130          p2i(p), from-&gt;hrm_index(), from-&gt;humongous_start_region()-&gt;hrm_index());
131 #endif // ASSERT
132 }
133 
134 template &lt;class T&gt;
135 inline void G1ConcurrentRefineOopClosure::do_oop_work(T* p) {
<span class="line-modified">136   T o = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);</span>
137   if (CompressedOops::is_null(o)) {
138     return;
139   }
140   oop obj = CompressedOops::decode_not_null(o);
141 
142   check_obj_during_refinement(p, obj);
143 
144   if (HeapRegion::is_in_same_region(p, obj)) {
145     // Normally this closure should only be called with cross-region references.
146     // But since Java threads are manipulating the references concurrently and we
147     // reload the values things may have changed.
148     // Also this check lets slip through references from a humongous continues region
149     // to its humongous start region, as they are in different regions, and adds a
150     // remembered set entry. This is benign (apart from memory usage), as we never
151     // try to either evacuate or eager reclaim humonguous arrays of j.l.O.
152     return;
153   }
154 
155   HeapRegionRemSet* to_rem_set = _g1h-&gt;heap_region_containing(obj)-&gt;rem_set();
156 
</pre>
<hr />
<pre>
243     if (barrier == G1BarrierCLD) {
244       do_cld_barrier(forwardee);
245     }
246   } else {
247     if (state.is_humongous()) {
248       _g1h-&gt;set_humongous_is_live(obj);
249     } else if ((barrier != G1BarrierNoOptRoots) &amp;&amp; state.is_optional()) {
250       _par_scan_state-&gt;remember_root_into_optional_region(p);
251     }
252 
253     // The object is not in collection set. If we&#39;re a root scanning
254     // closure during an initial mark pause then attempt to mark the object.
255     if (do_mark_object == G1MarkFromRoot) {
256       mark_object(obj);
257     }
258   }
259   trim_queue_partially();
260 }
261 
262 template &lt;class T&gt; void G1RebuildRemSetClosure::do_oop_work(T* p) {
<span class="line-modified">263   oop const obj = RawAccess&lt;MO_VOLATILE&gt;::oop_load(p);</span>
264   if (obj == NULL) {
265     return;
266   }
267 
268   if (HeapRegion::is_in_same_region(p, obj)) {
269     return;
270   }
271 
272   HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
273   HeapRegionRemSet* rem_set = to-&gt;rem_set();
274   rem_set-&gt;add_reference(p, _worker_id);
275 }
276 
277 #endif // SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 41 #include &quot;utilities/align.hpp&quot;
 42 
 43 template &lt;class T&gt;
 44 inline void G1ScanClosureBase::prefetch_and_push(T* p, const oop obj) {
 45   // We&#39;re not going to even bother checking whether the object is
 46   // already forwarded or not, as this usually causes an immediate
 47   // stall. We&#39;ll try to prefetch the object (for write, given that
 48   // we might need to install the forwarding reference) and we&#39;ll
 49   // get back to it when pop it from the queue
 50   Prefetch::write(obj-&gt;mark_addr_raw(), 0);
 51   Prefetch::read(obj-&gt;mark_addr_raw(), (HeapWordSize*2));
 52 
 53   // slightly paranoid test; I&#39;m trying to catch potential
 54   // problems before we go into push_on_queue to know where the
 55   // problem is coming from
 56   assert((obj == RawAccess&lt;&gt;::oop_load(p)) ||
 57          (obj-&gt;is_forwarded() &amp;&amp;
 58          obj-&gt;forwardee() == RawAccess&lt;&gt;::oop_load(p)),
 59          &quot;p should still be pointing to obj or to its forwardee&quot;);
 60 
<span class="line-modified"> 61   _par_scan_state-&gt;push_on_queue(ScannerTask(p));</span>
 62 }
 63 
 64 template &lt;class T&gt;
 65 inline void G1ScanClosureBase::handle_non_cset_obj_common(G1HeapRegionAttr const region_attr, T* p, oop const obj) {
 66   if (region_attr.is_humongous()) {
 67     _g1h-&gt;set_humongous_is_live(obj);
 68   } else if (region_attr.is_optional()) {
 69     _par_scan_state-&gt;remember_reference_into_optional_region(p);
 70   }
 71 }
 72 
 73 inline void G1ScanClosureBase::trim_queue_partially() {
 74   _par_scan_state-&gt;trim_queue_partially();
 75 }
 76 
 77 template &lt;class T&gt;
 78 inline void G1ScanEvacuatedObjClosure::do_oop_work(T* p) {
 79   T heap_oop = RawAccess&lt;&gt;::oop_load(p);
 80 
 81   if (CompressedOops::is_null(heap_oop)) {
</pre>
<hr />
<pre>
 85   const G1HeapRegionAttr region_attr = _g1h-&gt;region_attr(obj);
 86   if (region_attr.is_in_cset()) {
 87     prefetch_and_push(p, obj);
 88   } else if (!HeapRegion::is_in_same_region(p, obj)) {
 89     handle_non_cset_obj_common(region_attr, p, obj);
 90     assert(_scanning_in_young != Uninitialized, &quot;Scan location has not been initialized.&quot;);
 91     if (_scanning_in_young == True) {
 92       return;
 93     }
 94     _par_scan_state-&gt;enqueue_card_if_tracked(region_attr, p, obj);
 95   }
 96 }
 97 
 98 template &lt;class T&gt;
 99 inline void G1CMOopClosure::do_oop_work(T* p) {
100   _task-&gt;deal_with_reference(p);
101 }
102 
103 template &lt;class T&gt;
104 inline void G1RootRegionScanClosure::do_oop_work(T* p) {
<span class="line-modified">105   T heap_oop = RawAccess&lt;MO_RELAXED&gt;::oop_load(p);</span>
106   if (CompressedOops::is_null(heap_oop)) {
107     return;
108   }
109   oop obj = CompressedOops::decode_not_null(heap_oop);
110   _cm-&gt;mark_in_next_bitmap(_worker_id, obj);
111 }
112 
113 template &lt;class T&gt;
114 inline static void check_obj_during_refinement(T* p, oop const obj) {
115 #ifdef ASSERT
116   G1CollectedHeap* g1h = G1CollectedHeap::heap();
117   // can&#39;t do because of races
118   // assert(oopDesc::is_oop_or_null(obj), &quot;expected an oop&quot;);
119   assert(is_object_aligned(obj), &quot;oop must be aligned&quot;);
120   assert(g1h-&gt;is_in_reserved(obj), &quot;oop must be in reserved&quot;);
121 
122   HeapRegion* from = g1h-&gt;heap_region_containing(p);
123 
124   assert(from != NULL, &quot;from region must be non-NULL&quot;);
125   assert(from-&gt;is_in_reserved(p) ||
126          (from-&gt;is_humongous() &amp;&amp;
127           g1h-&gt;heap_region_containing(p)-&gt;is_humongous() &amp;&amp;
128           from-&gt;humongous_start_region() == g1h-&gt;heap_region_containing(p)-&gt;humongous_start_region()),
129          &quot;p &quot; PTR_FORMAT &quot; is not in the same region %u or part of the correct humongous object starting at region %u.&quot;,
130          p2i(p), from-&gt;hrm_index(), from-&gt;humongous_start_region()-&gt;hrm_index());
131 #endif // ASSERT
132 }
133 
134 template &lt;class T&gt;
135 inline void G1ConcurrentRefineOopClosure::do_oop_work(T* p) {
<span class="line-modified">136   T o = RawAccess&lt;MO_RELAXED&gt;::oop_load(p);</span>
137   if (CompressedOops::is_null(o)) {
138     return;
139   }
140   oop obj = CompressedOops::decode_not_null(o);
141 
142   check_obj_during_refinement(p, obj);
143 
144   if (HeapRegion::is_in_same_region(p, obj)) {
145     // Normally this closure should only be called with cross-region references.
146     // But since Java threads are manipulating the references concurrently and we
147     // reload the values things may have changed.
148     // Also this check lets slip through references from a humongous continues region
149     // to its humongous start region, as they are in different regions, and adds a
150     // remembered set entry. This is benign (apart from memory usage), as we never
151     // try to either evacuate or eager reclaim humonguous arrays of j.l.O.
152     return;
153   }
154 
155   HeapRegionRemSet* to_rem_set = _g1h-&gt;heap_region_containing(obj)-&gt;rem_set();
156 
</pre>
<hr />
<pre>
243     if (barrier == G1BarrierCLD) {
244       do_cld_barrier(forwardee);
245     }
246   } else {
247     if (state.is_humongous()) {
248       _g1h-&gt;set_humongous_is_live(obj);
249     } else if ((barrier != G1BarrierNoOptRoots) &amp;&amp; state.is_optional()) {
250       _par_scan_state-&gt;remember_root_into_optional_region(p);
251     }
252 
253     // The object is not in collection set. If we&#39;re a root scanning
254     // closure during an initial mark pause then attempt to mark the object.
255     if (do_mark_object == G1MarkFromRoot) {
256       mark_object(obj);
257     }
258   }
259   trim_queue_partially();
260 }
261 
262 template &lt;class T&gt; void G1RebuildRemSetClosure::do_oop_work(T* p) {
<span class="line-modified">263   oop const obj = RawAccess&lt;MO_RELAXED&gt;::oop_load(p);</span>
264   if (obj == NULL) {
265     return;
266   }
267 
268   if (HeapRegion::is_in_same_region(p, obj)) {
269     return;
270   }
271 
272   HeapRegion* to = _g1h-&gt;heap_region_containing(obj);
273   HeapRegionRemSet* rem_set = to-&gt;rem_set();
274   rem_set-&gt;add_reference(p, _worker_id);
275 }
276 
277 #endif // SHARE_GC_G1_G1OOPCLOSURES_INLINE_HPP
</pre>
</td>
</tr>
</table>
<center><a href="g1GCPhaseTimes.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1ParScanThreadState.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>