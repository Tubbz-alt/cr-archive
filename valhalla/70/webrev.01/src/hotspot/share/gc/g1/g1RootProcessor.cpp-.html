<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/g1/g1RootProcessor.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;aot/aotLoader.hpp&quot;
 27 #include &quot;classfile/classLoaderDataGraph.hpp&quot;
 28 #include &quot;classfile/stringTable.hpp&quot;
 29 #include &quot;classfile/systemDictionary.hpp&quot;
 30 #include &quot;code/codeCache.hpp&quot;
 31 #include &quot;gc/g1/g1BarrierSet.hpp&quot;
 32 #include &quot;gc/g1/g1CodeBlobClosure.hpp&quot;
 33 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
 34 #include &quot;gc/g1/g1CollectorState.hpp&quot;
 35 #include &quot;gc/g1/g1GCPhaseTimes.hpp&quot;
 36 #include &quot;gc/g1/g1ParScanThreadState.inline.hpp&quot;
 37 #include &quot;gc/g1/g1Policy.hpp&quot;
 38 #include &quot;gc/g1/g1RootClosures.hpp&quot;
 39 #include &quot;gc/g1/g1RootProcessor.hpp&quot;
 40 #include &quot;gc/g1/heapRegion.inline.hpp&quot;
 41 #include &quot;gc/shared/referenceProcessor.hpp&quot;
 42 #include &quot;memory/allocation.inline.hpp&quot;
 43 #include &quot;memory/universe.hpp&quot;
 44 #include &quot;runtime/mutex.hpp&quot;
 45 #include &quot;services/management.hpp&quot;
 46 #include &quot;utilities/macros.hpp&quot;
 47 
 48 G1RootProcessor::G1RootProcessor(G1CollectedHeap* g1h, uint n_workers) :
 49     _g1h(g1h),
 50     _process_strong_tasks(G1RP_PS_NumElements),
 51     _srs(n_workers) {}
 52 
 53 void G1RootProcessor::evacuate_roots(G1ParScanThreadState* pss, uint worker_id) {
 54   G1GCPhaseTimes* phase_times = _g1h-&gt;phase_times();
 55 
 56   G1EvacPhaseTimesTracker timer(phase_times, pss, G1GCPhaseTimes::ExtRootScan, worker_id);
 57 
 58   G1EvacuationRootClosures* closures = pss-&gt;closures();
 59   process_java_roots(closures, phase_times, worker_id);
 60 
 61   process_vm_roots(closures, phase_times, worker_id);
 62 
 63   {
 64     // Now the CM ref_processor roots.
 65     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::CMRefRoots, worker_id);
 66     if (_process_strong_tasks.try_claim_task(G1RP_PS_refProcessor_oops_do)) {
 67       // We need to treat the discovered reference lists of the
 68       // concurrent mark ref processor as roots and keep entries
 69       // (which are added by the marking threads) on them live
 70       // until they can be processed at the end of marking.
 71       _g1h-&gt;ref_processor_cm()-&gt;weak_oops_do(closures-&gt;strong_oops());
 72     }
 73   }
 74 
 75   _process_strong_tasks.all_tasks_completed(n_workers());
 76 }
 77 
 78 // Adaptor to pass the closures to the strong roots in the VM.
 79 class StrongRootsClosures : public G1RootClosures {
 80   OopClosure* _roots;
 81   CLDClosure* _clds;
 82   CodeBlobClosure* _blobs;
 83 public:
 84   StrongRootsClosures(OopClosure* roots, CLDClosure* clds, CodeBlobClosure* blobs) :
 85       _roots(roots), _clds(clds), _blobs(blobs) {}
 86 
 87   OopClosure* weak_oops()   { return NULL; }
 88   OopClosure* strong_oops() { return _roots; }
 89 
 90   CLDClosure* weak_clds()        { return NULL; }
 91   CLDClosure* strong_clds()      { return _clds; }
 92 
 93   CodeBlobClosure* strong_codeblobs() { return _blobs; }
 94 };
 95 
 96 void G1RootProcessor::process_strong_roots(OopClosure* oops,
 97                                            CLDClosure* clds,
 98                                            CodeBlobClosure* blobs) {
 99   StrongRootsClosures closures(oops, clds, blobs);
100 
101   process_java_roots(&amp;closures, NULL, 0);
102   process_vm_roots(&amp;closures, NULL, 0);
103 
104   _process_strong_tasks.all_tasks_completed(n_workers());
105 }
106 
107 // Adaptor to pass the closures to all the roots in the VM.
108 class AllRootsClosures : public G1RootClosures {
109   OopClosure* _roots;
110   CLDClosure* _clds;
111 public:
112   AllRootsClosures(OopClosure* roots, CLDClosure* clds) :
113       _roots(roots), _clds(clds) {}
114 
115   OopClosure* weak_oops() { return _roots; }
116   OopClosure* strong_oops() { return _roots; }
117 
118   // By returning the same CLDClosure for both weak and strong CLDs we ensure
119   // that a single walk of the CLDG will invoke the closure on all CLDs i the
120   // system.
121   CLDClosure* weak_clds() { return _clds; }
122   CLDClosure* strong_clds() { return _clds; }
123 
124   // We don&#39;t want to visit code blobs more than once, so we return NULL for the
125   // strong case and walk the entire code cache as a separate step.
126   CodeBlobClosure* strong_codeblobs() { return NULL; }
127 };
128 
129 void G1RootProcessor::process_all_roots(OopClosure* oops,
130                                         CLDClosure* clds,
131                                         CodeBlobClosure* blobs) {
132   AllRootsClosures closures(oops, clds);
133 
134   process_java_roots(&amp;closures, NULL, 0);
135   process_vm_roots(&amp;closures, NULL, 0);
136 
137   process_code_cache_roots(blobs, NULL, 0);
138 
139   _process_strong_tasks.all_tasks_completed(n_workers());
140 }
141 
142 void G1RootProcessor::process_java_roots(G1RootClosures* closures,
143                                          G1GCPhaseTimes* phase_times,
144                                          uint worker_id) {
145   // We need to make make sure that the &quot;strong&quot; nmethods are processed first
146   // using the strong closure. Only after that we process the weakly reachable
147   // nmethods.
148   // We need to strictly separate the strong and weak nmethod processing because
149   // any processing claims that nmethod, i.e. will not be iterated again.
150   // Which means if an nmethod is processed first and claimed, the strong processing
151   // will not happen, and the oops reachable by that nmethod will not be marked
152   // properly.
153   //
154   // That is why we process strong nmethods first, synchronize all threads via a
155   // barrier, and only then allow weak processing. To minimize the wait time at
156   // that barrier we do the strong nmethod processing first, and immediately after-
157   // wards indicate that that thread is done. Hopefully other root processing after
158   // nmethod processing is enough so there is no need to wait.
159   //
160   // This is only required in the concurrent start pause with class unloading enabled.
161   {
162     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::ThreadRoots, worker_id);
163     bool is_par = n_workers() &gt; 1;
164     Threads::possibly_parallel_oops_do(is_par,
165                                        closures-&gt;strong_oops(),
166                                        closures-&gt;strong_codeblobs());
167   }
168 
169   {
170     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::CLDGRoots, worker_id);
171     if (_process_strong_tasks.try_claim_task(G1RP_PS_ClassLoaderDataGraph_oops_do)) {
172       ClassLoaderDataGraph::roots_cld_do(closures-&gt;strong_clds(), closures-&gt;weak_clds());
173     }
174   }
175 }
176 
177 void G1RootProcessor::process_vm_roots(G1RootClosures* closures,
178                                        G1GCPhaseTimes* phase_times,
179                                        uint worker_id) {
180   OopClosure* strong_roots = closures-&gt;strong_oops();
181 
182   {
183     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::UniverseRoots, worker_id);
184     if (_process_strong_tasks.try_claim_task(G1RP_PS_Universe_oops_do)) {
185       Universe::oops_do(strong_roots);
186     }
187   }
188 
189   {
190     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::JNIRoots, worker_id);
191     if (_process_strong_tasks.try_claim_task(G1RP_PS_JNIHandles_oops_do)) {
192       JNIHandles::oops_do(strong_roots);
193     }
194   }
195 
196   {
197     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::ObjectSynchronizerRoots, worker_id);
198     if (_process_strong_tasks.try_claim_task(G1RP_PS_ObjectSynchronizer_oops_do)) {
199       ObjectSynchronizer::oops_do(strong_roots);
200     }
201   }
202 
203   {
204     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::ManagementRoots, worker_id);
205     if (_process_strong_tasks.try_claim_task(G1RP_PS_Management_oops_do)) {
206       Management::oops_do(strong_roots);
207     }
208   }
209 
210   {
211     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::JVMTIRoots, worker_id);
212     if (_process_strong_tasks.try_claim_task(G1RP_PS_jvmti_oops_do)) {
213       JvmtiExport::oops_do(strong_roots);
214     }
215   }
216 
217 #if INCLUDE_AOT
218   if (UseAOT) {
219     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::AOTCodeRoots, worker_id);
220     if (_process_strong_tasks.try_claim_task(G1RP_PS_aot_oops_do)) {
221         AOTLoader::oops_do(strong_roots);
222     }
223   }
224 #endif
225 
226   {
227     G1GCParPhaseTimesTracker x(phase_times, G1GCPhaseTimes::SystemDictionaryRoots, worker_id);
228     if (_process_strong_tasks.try_claim_task(G1RP_PS_SystemDictionary_oops_do)) {
229       SystemDictionary::oops_do(strong_roots);
230     }
231   }
232 }
233 
234 void G1RootProcessor::process_code_cache_roots(CodeBlobClosure* code_closure,
235                                                G1GCPhaseTimes* phase_times,
236                                                uint worker_id) {
237   if (_process_strong_tasks.try_claim_task(G1RP_PS_CodeCache_oops_do)) {
238     CodeCache::blobs_do(code_closure);
239   }
240 }
241 
242 uint G1RootProcessor::n_workers() const {
243   return _srs.n_threads();
244 }
    </pre>
  </body>
</html>