<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="methodHandles_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;

  48 #include &quot;runtime/stubRoutines.hpp&quot;
  49 #include &quot;runtime/thread.hpp&quot;
  50 #include &quot;utilities/macros.hpp&quot;

  51 #include &quot;crc32c.h&quot;



  52 
  53 #ifdef PRODUCT
  54 #define BLOCK_COMMENT(str) /* nothing */
  55 #define STOP(error) stop(error)
  56 #else
  57 #define BLOCK_COMMENT(str) block_comment(str)
  58 #define STOP(error) block_comment(error); stop(error)
  59 #endif
  60 
  61 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  62 
  63 #ifdef ASSERT
  64 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  65 #endif
  66 
  67 static Assembler::Condition reverse[] = {
  68     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  69     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  70     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  71     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1623 }
1624 
1625 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1626 
1627   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1628   pass_arg1(this, arg_1);
1629   pass_arg0(this, arg_0);
1630   call_VM_leaf(entry_point, 2);
1631 }
1632 
1633 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1634   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1635   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1636   pass_arg2(this, arg_2);
1637   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1638   pass_arg1(this, arg_1);
1639   pass_arg0(this, arg_0);
1640   call_VM_leaf(entry_point, 3);
1641 }
1642 




1643 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1644   pass_arg0(this, arg_0);
1645   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1646 }
1647 
1648 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1649 
1650   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1651   pass_arg1(this, arg_1);
1652   pass_arg0(this, arg_0);
1653   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1654 }
1655 
1656 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1657   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1658   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1659   pass_arg2(this, arg_2);
1660   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1661   pass_arg1(this, arg_1);
1662   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2591     lea(rscratch1, src);
2592     Assembler::mulss(dst, Address(rscratch1, 0));
2593   }
2594 }
2595 
2596 void MacroAssembler::null_check(Register reg, int offset) {
2597   if (needs_explicit_null_check(offset)) {
2598     // provoke OS NULL exception if reg = NULL by
2599     // accessing M[reg] w/o changing any (non-CC) registers
2600     // NOTE: cmpl is plenty here to provoke a segv
2601     cmpptr(rax, Address(reg, 0));
2602     // Note: should probably use testl(rax, Address(reg, 0));
2603     //       may be shorter code (however, this version of
2604     //       testl needs to be implemented first)
2605   } else {
2606     // nothing to do, (later) access of M[reg + offset]
2607     // will provoke OS NULL exception if reg = NULL
2608   }
2609 }
2610 






























































































2611 void MacroAssembler::os_breakpoint() {
2612   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2613   // (e.g., MSVC can&#39;t call ps() otherwise)
2614   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2615 }
2616 
2617 void MacroAssembler::unimplemented(const char* what) {
2618   const char* buf = NULL;
2619   {
2620     ResourceMark rm;
2621     stringStream ss;
2622     ss.print(&quot;unimplemented: %s&quot;, what);
2623     buf = code_string(ss.as_string());
2624   }
2625   stop(buf);
2626 }
2627 
2628 #ifdef _LP64
2629 #define XSTATE_BV 0x200
2630 #endif
</pre>
<hr />
<pre>
3289 }
3290 
3291 // C++ bool manipulation
3292 void MacroAssembler::testbool(Register dst) {
3293   if(sizeof(bool) == 1)
3294     testb(dst, 0xff);
3295   else if(sizeof(bool) == 2) {
3296     // testw implementation needed for two byte bools
3297     ShouldNotReachHere();
3298   } else if(sizeof(bool) == 4)
3299     testl(dst, dst);
3300   else
3301     // unsupported
3302     ShouldNotReachHere();
3303 }
3304 
3305 void MacroAssembler::testptr(Register dst, Register src) {
3306   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3307 }
3308 

































































































































3309 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3310 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3311                                    Register var_size_in_bytes,
3312                                    int con_size_in_bytes,
3313                                    Register t1,
3314                                    Register t2,
3315                                    Label&amp; slow_case) {
3316   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3317   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3318 }
3319 
3320 // Defines obj, preserves var_size_in_bytes
3321 void MacroAssembler::eden_allocate(Register thread, Register obj,
3322                                    Register var_size_in_bytes,
3323                                    int con_size_in_bytes,
3324                                    Register t1,
3325                                    Label&amp; slow_case) {
3326   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3327   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3328 }
</pre>
<hr />
<pre>
3366     // clear topmost word (no jump would be needed if conditional assignment worked here)
3367     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3368     // index could be 0 now, must check again
3369     jcc(Assembler::zero, done);
3370     bind(even);
3371   }
3372 #endif // !_LP64
3373   // initialize remaining object fields: index is a multiple of 2 now
3374   {
3375     Label loop;
3376     bind(loop);
3377     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3378     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3379     decrement(index);
3380     jcc(Assembler::notZero, loop);
3381   }
3382 
3383   bind(done);
3384 }
3385 


















































3386 // Look up the method for a megamorphic invokeinterface call.
3387 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3388 // The receiver klass is in recv_klass.
3389 // On success, the result will be in method_result, and execution falls through.
3390 // On failure, execution transfers to the given label.
3391 void MacroAssembler::lookup_interface_method(Register recv_klass,
3392                                              Register intf_klass,
3393                                              RegisterOrConstant itable_index,
3394                                              Register method_result,
3395                                              Register scan_temp,
3396                                              Label&amp; L_no_such_interface,
3397                                              bool return_method) {
3398   assert_different_registers(recv_klass, intf_klass, scan_temp);
3399   assert_different_registers(method_result, intf_klass, scan_temp);
3400   assert(recv_klass != method_result || !return_method,
3401          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3402 
3403   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3404          &quot;caller must use same register for non-constant itable index as for method&quot;);
3405 
</pre>
<hr />
<pre>
3714   } else {
3715     Label L;
3716     jccb(negate_condition(cc), L);
3717     movl(dst, src);
3718     bind(L);
3719   }
3720 }
3721 
3722 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
3723   if (VM_Version::supports_cmov()) {
3724     cmovl(cc, dst, src);
3725   } else {
3726     Label L;
3727     jccb(negate_condition(cc), L);
3728     movl(dst, src);
3729     bind(L);
3730   }
3731 }
3732 
3733 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">3734   if (!VerifyOops) return;</span>




3735 
3736   // Pass register number to verify_oop_subroutine
3737   const char* b = NULL;
3738   {
3739     ResourceMark rm;
3740     stringStream ss;
3741     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
3742     b = code_string(ss.as_string());
3743   }
3744   BLOCK_COMMENT(&quot;verify_oop {&quot;);
3745 #ifdef _LP64
3746   push(rscratch1);                    // save r10, trashed by movptr()
3747 #endif
3748   push(rax);                          // save rax,
3749   push(reg);                          // pass register argument
3750   ExternalAddress buffer((address) b);
3751   // avoid using pushptr, as it modifies scratch registers
3752   // and our contract is not to modify anything
3753   movptr(rax, buffer.addr());
3754   push(rax);
</pre>
<hr />
<pre>
3812   int stackElementSize = Interpreter::stackElementSize;
3813   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
3814 #ifdef ASSERT
3815   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
3816   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
3817 #endif
3818   Register             scale_reg    = noreg;
3819   Address::ScaleFactor scale_factor = Address::no_scale;
3820   if (arg_slot.is_constant()) {
3821     offset += arg_slot.as_constant() * stackElementSize;
3822   } else {
3823     scale_reg    = arg_slot.as_register();
3824     scale_factor = Address::times(stackElementSize);
3825   }
3826   offset += wordSize;           // return PC is on stack
3827   return Address(rsp, scale_reg, scale_factor, offset);
3828 }
3829 
3830 
3831 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">3832   if (!VerifyOops) return;</span>




3833 
3834   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
3835   // Pass register number to verify_oop_subroutine
3836   const char* b = NULL;
3837   {
3838     ResourceMark rm;
3839     stringStream ss;
3840     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
3841     b = code_string(ss.as_string());
3842   }
3843 #ifdef _LP64
3844   push(rscratch1);                    // save r10, trashed by movptr()
3845 #endif
3846   push(rax);                          // save rax,
3847   // addr may contain rsp so we will have to adjust it based on the push
3848   // we just did (and on 64 bit we do two pushes)
3849   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
3850   // stores rax into addr which is backwards of what was intended.
3851   if (addr.uses(rsp)) {
3852     lea(rax, addr);
</pre>
<hr />
<pre>
4308 
4309 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4310   // get mirror
4311   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4312   load_method_holder(mirror, method);
4313   movptr(mirror, Address(mirror, mirror_offset));
4314   resolve_oop_handle(mirror, tmp);
4315 }
4316 
4317 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4318   load_method_holder(rresult, rmethod);
4319   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4320 }
4321 
4322 void MacroAssembler::load_method_holder(Register holder, Register method) {
4323   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4324   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4325   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4326 }
4327 








4328 void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {
4329   assert_different_registers(src, tmp);
4330   assert_different_registers(dst, tmp);
4331 #ifdef _LP64
4332   if (UseCompressedClassPointers) {
4333     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
4334     decode_klass_not_null(dst, tmp);
4335   } else
4336 #endif
<span class="line-modified">4337     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
4338 }
4339 
4340 void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {
4341   load_klass(dst, src, tmp);
4342   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4343 }
4344 
4345 void MacroAssembler::store_klass(Register dst, Register src, Register tmp) {
4346   assert_different_registers(src, tmp);
4347   assert_different_registers(dst, tmp);
4348 #ifdef _LP64
4349   if (UseCompressedClassPointers) {
4350     encode_klass_not_null(src, tmp);
4351     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4352   } else
4353 #endif
4354     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4355 }
4356 
4357 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4358                                     Register tmp1, Register thread_tmp) {
4359   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4360   decorators = AccessInternal::decorator_fixup(decorators);
4361   bool as_raw = (decorators &amp; AS_RAW) != 0;
4362   if (as_raw) {
4363     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4364   } else {
4365     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4366   }
4367 }
4368 
4369 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4370                                      Register tmp1, Register tmp2) {</span>
4371   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4372   decorators = AccessInternal::decorator_fixup(decorators);
4373   bool as_raw = (decorators &amp; AS_RAW) != 0;
4374   if (as_raw) {
<span class="line-modified">4375     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>






















4376   } else {
<span class="line-modified">4377     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>
4378   }
4379 }
4380 


















4381 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4382   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4383   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4384     decorators |= ACCESS_READ | ACCESS_WRITE;
4385   }
4386   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4387   return bs-&gt;resolve(this, decorators, obj);
4388 }
4389 
4390 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4391                                    Register thread_tmp, DecoratorSet decorators) {
4392   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4393 }
4394 
4395 // Doesn&#39;t do verfication, generates fixed size code
4396 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4397                                             Register thread_tmp, DecoratorSet decorators) {
4398   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4399 }
4400 
4401 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4402                                     Register tmp2, DecoratorSet decorators) {</span>
<span class="line-modified">4403   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);</span>
4404 }
4405 
4406 // Used for storing NULLs.
4407 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4408   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
4409 }
4410 
4411 #ifdef _LP64
4412 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4413   if (UseCompressedClassPointers) {
4414     // Store to klass gap in destination
4415     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4416   }
4417 }
4418 
4419 #ifdef ASSERT
4420 void MacroAssembler::verify_heapbase(const char* msg) {
4421   assert (UseCompressedOops, &quot;should be compressed&quot;);
4422   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4423   if (CheckCompressedOops) {
4424     Label ok;
4425     push(rscratch1); // cmpptr trashes rscratch1
4426     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4427     jcc(Assembler::equal, ok);
4428     STOP(msg);
</pre>
<hr />
<pre>
4703   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
4704 }
4705 
4706 void MacroAssembler::reinit_heapbase() {
4707   if (UseCompressedOops) {
4708     if (Universe::heap() != NULL) {
4709       if (CompressedOops::base() == NULL) {
4710         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
4711       } else {
4712         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
4713       }
4714     } else {
4715       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4716     }
4717   }
4718 }
4719 
4720 #endif // _LP64
4721 
4722 // C2 compiled method&#39;s prolog code.
<span class="line-modified">4723 void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {</span>




4724 
4725   // WARNING: Initial instruction MUST be 5 bytes or longer so that
4726   // NativeJump::patch_verified_entry will be able to patch out the entry
4727   // code safely. The push to verify stack depth is ok at 5 bytes,
4728   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
4729   // stack bang then we must use the 6 byte frame allocation even if
4730   // we have no frame. :-(
4731   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
4732 
4733   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
4734   // Remove word for return addr
4735   framesize -= wordSize;
4736   stack_bang_size -= wordSize;
4737 
4738   // Calls to C2R adapters often do not accept exceptional returns.
4739   // We require that their callers must bang for them.  But be careful, because
4740   // some VM calls (such as call site linkage) can use several kilobytes of
4741   // stack.  But the stack safety zone should account for that.
4742   // See bugs 4446381, 4468289, 4497237.
4743   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
4756     // Create frame
4757     if (framesize) {
4758       subptr(rsp, framesize);
4759     }
4760   } else {
4761     // Create frame (force generation of a 4 byte immediate value)
4762     subptr_imm32(rsp, framesize);
4763 
4764     // Save RBP register now.
4765     framesize -= wordSize;
4766     movptr(Address(rsp, framesize), rbp);
4767     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
4768     if (PreserveFramePointer) {
4769       movptr(rbp, rsp);
4770       if (framesize &gt; 0) {
4771         addptr(rbp, framesize);
4772       }
4773     }
4774   }
4775 






4776   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
4777     framesize -= wordSize;
4778     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
4779   }
4780 
4781 #ifndef _LP64
4782   // If method sets FPU control word do it now
4783   if (fp_mode_24b) {
4784     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
4785   }
4786   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
4787     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
4788   }
4789 #endif
4790 
4791 #ifdef ASSERT
4792   if (VerifyStackAtCalls) {
4793     Label L;
4794     push(rax);
4795     mov(rax, rsp);
4796     andptr(rax, StackAlignmentInBytes-1);
4797     cmpptr(rax, StackAlignmentInBytes-wordSize);
4798     pop(rax);
4799     jcc(Assembler::equal, L);
4800     STOP(&quot;Stack is not properly aligned!&quot;);
4801     bind(L);
4802   }
4803 #endif
<span class="line-removed">4804 </span>
<span class="line-removed">4805   if (!is_stub) {</span>
<span class="line-removed">4806     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-removed">4807     bs-&gt;nmethod_entry_barrier(this);</span>
<span class="line-removed">4808   }</span>
4809 }
4810 
4811 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">4812 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, XMMRegister xtmp) {</span>
4813   // cnt - number of qwords (8-byte words).
4814   // base - start address, qword aligned.
4815   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;

4816   if (UseAVX &gt;= 2) {
<span class="line-modified">4817     vpxor(xtmp, xtmp, xtmp, AVX_256bit);</span>

4818   } else {
<span class="line-modified">4819     pxor(xtmp, xtmp);</span>
4820   }
4821   jmp(L_zero_64_bytes);
4822 
4823   BIND(L_loop);
4824   if (UseAVX &gt;= 2) {
4825     vmovdqu(Address(base,  0), xtmp);
4826     vmovdqu(Address(base, 32), xtmp);
4827   } else {
4828     movdqu(Address(base,  0), xtmp);
4829     movdqu(Address(base, 16), xtmp);
4830     movdqu(Address(base, 32), xtmp);
4831     movdqu(Address(base, 48), xtmp);
4832   }
4833   addptr(base, 64);
4834 
4835   BIND(L_zero_64_bytes);
4836   subptr(cnt, 8);
4837   jccb(Assembler::greaterEqual, L_loop);
4838   addptr(cnt, 4);
4839   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
4843   } else {
4844     movdqu(Address(base,  0), xtmp);
4845     movdqu(Address(base, 16), xtmp);
4846   }
4847   addptr(base, 32);
4848   subptr(cnt, 4);
4849 
4850   BIND(L_tail);
4851   addptr(cnt, 4);
4852   jccb(Assembler::lessEqual, L_end);
4853   decrement(cnt);
4854 
4855   BIND(L_sloop);
4856   movq(Address(base, 0), xtmp);
4857   addptr(base, 8);
4858   decrement(cnt);
4859   jccb(Assembler::greaterEqual, L_sloop);
4860   BIND(L_end);
4861 }
4862 
<span class="line-modified">4863 void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp, bool is_large) {</span>







































































































































































































































































































































































4864   // cnt - number of qwords (8-byte words).
4865   // base - start address, qword aligned.
4866   // is_large - if optimizers know cnt is larger than InitArrayShortSize
4867   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">4868   assert(tmp==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
4869   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
4870   assert(InitArrayShortSize % BytesPerLong == 0,
4871     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
4872 
4873   Label DONE;
4874 
<span class="line-removed">4875   if (!is_large || !UseXMMForObjInit) {</span>
<span class="line-removed">4876     xorptr(tmp, tmp);</span>
<span class="line-removed">4877   }</span>
<span class="line-removed">4878 </span>
4879   if (!is_large) {
4880     Label LOOP, LONG;
4881     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
4882     jccb(Assembler::greater, LONG);
4883 
4884     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4885 
4886     decrement(cnt);
4887     jccb(Assembler::negative, DONE); // Zero length
4888 
4889     // Use individual pointer-sized stores for small counts:
4890     BIND(LOOP);
<span class="line-modified">4891     movptr(Address(base, cnt, Address::times_ptr), tmp);</span>
4892     decrement(cnt);
4893     jccb(Assembler::greaterEqual, LOOP);
4894     jmpb(DONE);
4895 
4896     BIND(LONG);
4897   }
4898 
4899   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">4900   if (UseFastStosb) {</span>
4901     shlptr(cnt, 3); // convert to number of bytes
4902     rep_stosb();
4903   } else if (UseXMMForObjInit) {
<span class="line-modified">4904     movptr(tmp, base);</span>
<span class="line-removed">4905     xmm_clear_mem(tmp, cnt, xtmp);</span>
4906   } else {
4907     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4908     rep_stos();
4909   }
4910 
4911   BIND(DONE);
4912 }
4913 
4914 void MacroAssembler::generate_fill(BasicType t, bool aligned,
4915                                    Register to, Register value, Register count,
4916                                    Register rtmp, XMMRegister xtmp) {
4917   ShortBranchVerifier sbv(this);
4918   assert_different_registers(to, value, count, rtmp);
4919   Label L_exit;
4920   Label L_fill_2_bytes, L_fill_4_bytes;
4921 
4922   int shift = -1;
4923   switch (t) {
4924     case T_BYTE:
4925       shift = 2;
</pre>
</td>
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  48 #include &quot;runtime/signature_cc.hpp&quot;</span>
  49 #include &quot;runtime/stubRoutines.hpp&quot;
  50 #include &quot;runtime/thread.hpp&quot;
  51 #include &quot;utilities/macros.hpp&quot;
<span class="line-added">  52 #include &quot;vmreg_x86.inline.hpp&quot;</span>
  53 #include &quot;crc32c.h&quot;
<span class="line-added">  54 #ifdef COMPILER2</span>
<span class="line-added">  55 #include &quot;opto/output.hpp&quot;</span>
<span class="line-added">  56 #endif</span>
  57 
  58 #ifdef PRODUCT
  59 #define BLOCK_COMMENT(str) /* nothing */
  60 #define STOP(error) stop(error)
  61 #else
  62 #define BLOCK_COMMENT(str) block_comment(str)
  63 #define STOP(error) block_comment(error); stop(error)
  64 #endif
  65 
  66 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  67 
  68 #ifdef ASSERT
  69 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  70 #endif
  71 
  72 static Assembler::Condition reverse[] = {
  73     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  74     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  75     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  76     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1628 }
1629 
1630 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1631 
1632   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1633   pass_arg1(this, arg_1);
1634   pass_arg0(this, arg_0);
1635   call_VM_leaf(entry_point, 2);
1636 }
1637 
1638 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1639   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1640   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1641   pass_arg2(this, arg_2);
1642   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1643   pass_arg1(this, arg_1);
1644   pass_arg0(this, arg_0);
1645   call_VM_leaf(entry_point, 3);
1646 }
1647 
<span class="line-added">1648 void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="line-added">1649   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="line-added">1650 }</span>
<span class="line-added">1651 </span>
1652 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1653   pass_arg0(this, arg_0);
1654   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1655 }
1656 
1657 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1658 
1659   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1660   pass_arg1(this, arg_1);
1661   pass_arg0(this, arg_0);
1662   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1663 }
1664 
1665 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1666   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1667   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1668   pass_arg2(this, arg_2);
1669   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1670   pass_arg1(this, arg_1);
1671   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2600     lea(rscratch1, src);
2601     Assembler::mulss(dst, Address(rscratch1, 0));
2602   }
2603 }
2604 
2605 void MacroAssembler::null_check(Register reg, int offset) {
2606   if (needs_explicit_null_check(offset)) {
2607     // provoke OS NULL exception if reg = NULL by
2608     // accessing M[reg] w/o changing any (non-CC) registers
2609     // NOTE: cmpl is plenty here to provoke a segv
2610     cmpptr(rax, Address(reg, 0));
2611     // Note: should probably use testl(rax, Address(reg, 0));
2612     //       may be shorter code (however, this version of
2613     //       testl needs to be implemented first)
2614   } else {
2615     // nothing to do, (later) access of M[reg + offset]
2616     // will provoke OS NULL exception if reg = NULL
2617   }
2618 }
2619 
<span class="line-added">2620 void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="line-added">2621   movl(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="line-added">2622   testl(temp_reg, JVM_ACC_VALUE);</span>
<span class="line-added">2623   jcc(Assembler::notZero, is_value);</span>
<span class="line-added">2624 }</span>
<span class="line-added">2625 </span>
<span class="line-added">2626 void MacroAssembler::test_klass_is_empty_value(Register klass, Register temp_reg, Label&amp; is_empty_value) {</span>
<span class="line-added">2627 #ifdef ASSERT</span>
<span class="line-added">2628   {</span>
<span class="line-added">2629     Label done_check;</span>
<span class="line-added">2630     test_klass_is_value(klass, temp_reg, done_check);</span>
<span class="line-added">2631     stop(&quot;test_klass_is_empty_value with non value klass&quot;);</span>
<span class="line-added">2632     bind(done_check);</span>
<span class="line-added">2633   }</span>
<span class="line-added">2634 #endif</span>
<span class="line-added">2635   movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));</span>
<span class="line-added">2636   testl(temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());</span>
<span class="line-added">2637   jcc(Assembler::notZero, is_empty_value);</span>
<span class="line-added">2638 }</span>
<span class="line-added">2639 </span>
<span class="line-added">2640 void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="line-added">2641   movl(temp_reg, flags);</span>
<span class="line-added">2642   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2643   andl(temp_reg, 0x1);</span>
<span class="line-added">2644   testl(temp_reg, temp_reg);</span>
<span class="line-added">2645   jcc(Assembler::notZero, is_flattenable);</span>
<span class="line-added">2646 }</span>
<span class="line-added">2647 </span>
<span class="line-added">2648 void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; notFlattenable) {</span>
<span class="line-added">2649   movl(temp_reg, flags);</span>
<span class="line-added">2650   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2651   andl(temp_reg, 0x1);</span>
<span class="line-added">2652   testl(temp_reg, temp_reg);</span>
<span class="line-added">2653   jcc(Assembler::zero, notFlattenable);</span>
<span class="line-added">2654 }</span>
<span class="line-added">2655 </span>
<span class="line-added">2656 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="line-added">2657   movl(temp_reg, flags);</span>
<span class="line-added">2658   shrl(temp_reg, ConstantPoolCacheEntry::is_flattened_field_shift);</span>
<span class="line-added">2659   andl(temp_reg, 0x1);</span>
<span class="line-added">2660   testl(temp_reg, temp_reg);</span>
<span class="line-added">2661   jcc(Assembler::notZero, is_flattened);</span>
<span class="line-added">2662 }</span>
<span class="line-added">2663 </span>
<span class="line-added">2664 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2665                                               Label&amp;is_flattened_array) {</span>
<span class="line-added">2666   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2667   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2668   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2669   test_flattened_array_layout(temp_reg, is_flattened_array);</span>
<span class="line-added">2670 }</span>
<span class="line-added">2671 </span>
<span class="line-added">2672 void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2673                                                   Label&amp;is_non_flattened_array) {</span>
<span class="line-added">2674   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2675   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2676   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2677   test_non_flattened_array_layout(temp_reg, is_non_flattened_array);</span>
<span class="line-added">2678 }</span>
<span class="line-added">2679 </span>
<span class="line-added">2680 void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {</span>
<span class="line-added">2681   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2682   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2683   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2684   test_null_free_array_layout(temp_reg, is_null_free_array);</span>
<span class="line-added">2685 }</span>
<span class="line-added">2686 </span>
<span class="line-added">2687 void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {</span>
<span class="line-added">2688   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2689   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2690   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2691   test_non_null_free_array_layout(temp_reg, is_non_null_free_array);</span>
<span class="line-added">2692 }</span>
<span class="line-added">2693 </span>
<span class="line-added">2694 void MacroAssembler::test_flattened_array_layout(Register lh, Label&amp; is_flattened_array) {</span>
<span class="line-added">2695   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="line-added">2696   jcc(Assembler::notZero, is_flattened_array);</span>
<span class="line-added">2697 }</span>
<span class="line-added">2698 void MacroAssembler::test_non_flattened_array_layout(Register lh, Label&amp; is_non_flattened_array) {</span>
<span class="line-added">2699   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="line-added">2700   jcc(Assembler::zero, is_non_flattened_array);</span>
<span class="line-added">2701 }</span>
<span class="line-added">2702 </span>
<span class="line-added">2703 void MacroAssembler::test_null_free_array_layout(Register lh, Label&amp; is_null_free_array) {</span>
<span class="line-added">2704   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="line-added">2705   jcc(Assembler::notZero, is_null_free_array);</span>
<span class="line-added">2706 }</span>
<span class="line-added">2707 </span>
<span class="line-added">2708 void MacroAssembler::test_non_null_free_array_layout(Register lh, Label&amp; is_non_null_free_array) {</span>
<span class="line-added">2709   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="line-added">2710   jcc(Assembler::zero, is_non_null_free_array);</span>
<span class="line-added">2711 }</span>
<span class="line-added">2712 </span>
<span class="line-added">2713 </span>
2714 void MacroAssembler::os_breakpoint() {
2715   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2716   // (e.g., MSVC can&#39;t call ps() otherwise)
2717   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2718 }
2719 
2720 void MacroAssembler::unimplemented(const char* what) {
2721   const char* buf = NULL;
2722   {
2723     ResourceMark rm;
2724     stringStream ss;
2725     ss.print(&quot;unimplemented: %s&quot;, what);
2726     buf = code_string(ss.as_string());
2727   }
2728   stop(buf);
2729 }
2730 
2731 #ifdef _LP64
2732 #define XSTATE_BV 0x200
2733 #endif
</pre>
<hr />
<pre>
3392 }
3393 
3394 // C++ bool manipulation
3395 void MacroAssembler::testbool(Register dst) {
3396   if(sizeof(bool) == 1)
3397     testb(dst, 0xff);
3398   else if(sizeof(bool) == 2) {
3399     // testw implementation needed for two byte bools
3400     ShouldNotReachHere();
3401   } else if(sizeof(bool) == 4)
3402     testl(dst, dst);
3403   else
3404     // unsupported
3405     ShouldNotReachHere();
3406 }
3407 
3408 void MacroAssembler::testptr(Register dst, Register src) {
3409   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3410 }
3411 
<span class="line-added">3412 // Object / value buffer allocation...</span>
<span class="line-added">3413 //</span>
<span class="line-added">3414 // Kills klass and rsi on LP64</span>
<span class="line-added">3415 void MacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="line-added">3416                                        Register t1, Register t2,</span>
<span class="line-added">3417                                        bool clear_fields, Label&amp; alloc_failed)</span>
<span class="line-added">3418 {</span>
<span class="line-added">3419   Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;</span>
<span class="line-added">3420   Register layout_size = t1;</span>
<span class="line-added">3421   assert(new_obj == rax, &quot;needs to be rax, according to barrier asm eden_allocate&quot;);</span>
<span class="line-added">3422   assert_different_registers(klass, new_obj, t1, t2);</span>
<span class="line-added">3423 </span>
<span class="line-added">3424 #ifdef ASSERT</span>
<span class="line-added">3425   {</span>
<span class="line-added">3426     Label L;</span>
<span class="line-added">3427     cmpb(Address(klass, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="line-added">3428     jcc(Assembler::equal, L);</span>
<span class="line-added">3429     stop(&quot;klass not initialized&quot;);</span>
<span class="line-added">3430     bind(L);</span>
<span class="line-added">3431   }</span>
<span class="line-added">3432 #endif</span>
<span class="line-added">3433 </span>
<span class="line-added">3434   // get instance_size in InstanceKlass (scaled to a count of bytes)</span>
<span class="line-added">3435   movl(layout_size, Address(klass, Klass::layout_helper_offset()));</span>
<span class="line-added">3436   // test to see if it has a finalizer or is malformed in some way</span>
<span class="line-added">3437   testl(layout_size, Klass::_lh_instance_slow_path_bit);</span>
<span class="line-added">3438   jcc(Assembler::notZero, slow_case_no_pop);</span>
<span class="line-added">3439 </span>
<span class="line-added">3440   // Allocate the instance:</span>
<span class="line-added">3441   //  If TLAB is enabled:</span>
<span class="line-added">3442   //    Try to allocate in the TLAB.</span>
<span class="line-added">3443   //    If fails, go to the slow path.</span>
<span class="line-added">3444   //  Else If inline contiguous allocations are enabled:</span>
<span class="line-added">3445   //    Try to allocate in eden.</span>
<span class="line-added">3446   //    If fails due to heap end, go to slow path.</span>
<span class="line-added">3447   //</span>
<span class="line-added">3448   //  If TLAB is enabled OR inline contiguous is enabled:</span>
<span class="line-added">3449   //    Initialize the allocation.</span>
<span class="line-added">3450   //    Exit.</span>
<span class="line-added">3451   //</span>
<span class="line-added">3452   //  Go to slow path.</span>
<span class="line-added">3453   const bool allow_shared_alloc =</span>
<span class="line-added">3454     Universe::heap()-&gt;supports_inline_contig_alloc();</span>
<span class="line-added">3455 </span>
<span class="line-added">3456   push(klass);</span>
<span class="line-added">3457   const Register thread = LP64_ONLY(r15_thread) NOT_LP64(klass);</span>
<span class="line-added">3458 #ifndef _LP64</span>
<span class="line-added">3459   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3460     get_thread(thread);</span>
<span class="line-added">3461   }</span>
<span class="line-added">3462 #endif // _LP64</span>
<span class="line-added">3463 </span>
<span class="line-added">3464   if (UseTLAB) {</span>
<span class="line-added">3465     tlab_allocate(thread, new_obj, layout_size, 0, klass, t2, slow_case);</span>
<span class="line-added">3466     if (ZeroTLAB || (!clear_fields)) {</span>
<span class="line-added">3467       // the fields have been already cleared</span>
<span class="line-added">3468       jmp(initialize_header);</span>
<span class="line-added">3469     } else {</span>
<span class="line-added">3470       // initialize both the header and fields</span>
<span class="line-added">3471       jmp(initialize_object);</span>
<span class="line-added">3472     }</span>
<span class="line-added">3473   } else {</span>
<span class="line-added">3474     // Allocation in the shared Eden, if allowed.</span>
<span class="line-added">3475     //</span>
<span class="line-added">3476     eden_allocate(thread, new_obj, layout_size, 0, t2, slow_case);</span>
<span class="line-added">3477   }</span>
<span class="line-added">3478 </span>
<span class="line-added">3479   // If UseTLAB or allow_shared_alloc are true, the object is created above and</span>
<span class="line-added">3480   // there is an initialize need. Otherwise, skip and go to the slow path.</span>
<span class="line-added">3481   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3482     if (clear_fields) {</span>
<span class="line-added">3483       // The object is initialized before the header.  If the object size is</span>
<span class="line-added">3484       // zero, go directly to the header initialization.</span>
<span class="line-added">3485       bind(initialize_object);</span>
<span class="line-added">3486       decrement(layout_size, sizeof(oopDesc));</span>
<span class="line-added">3487       jcc(Assembler::zero, initialize_header);</span>
<span class="line-added">3488 </span>
<span class="line-added">3489       // Initialize topmost object field, divide size by 8, check if odd and</span>
<span class="line-added">3490       // test if zero.</span>
<span class="line-added">3491       Register zero = klass;</span>
<span class="line-added">3492       xorl(zero, zero);    // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3493       shrl(layout_size, LogBytesPerLong); // divide by 2*oopSize and set carry flag if odd</span>
<span class="line-added">3494 </span>
<span class="line-added">3495   #ifdef ASSERT</span>
<span class="line-added">3496       // make sure instance_size was multiple of 8</span>
<span class="line-added">3497       Label L;</span>
<span class="line-added">3498       // Ignore partial flag stall after shrl() since it is debug VM</span>
<span class="line-added">3499       jcc(Assembler::carryClear, L);</span>
<span class="line-added">3500       stop(&quot;object size is not multiple of 2 - adjust this code&quot;);</span>
<span class="line-added">3501       bind(L);</span>
<span class="line-added">3502       // must be &gt; 0, no extra check needed here</span>
<span class="line-added">3503   #endif</span>
<span class="line-added">3504 </span>
<span class="line-added">3505       // initialize remaining object fields: instance_size was a multiple of 8</span>
<span class="line-added">3506       {</span>
<span class="line-added">3507         Label loop;</span>
<span class="line-added">3508         bind(loop);</span>
<span class="line-added">3509         movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 1*oopSize), zero);</span>
<span class="line-added">3510         NOT_LP64(movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 2*oopSize), zero));</span>
<span class="line-added">3511         decrement(layout_size);</span>
<span class="line-added">3512         jcc(Assembler::notZero, loop);</span>
<span class="line-added">3513       }</span>
<span class="line-added">3514     } // clear_fields</span>
<span class="line-added">3515 </span>
<span class="line-added">3516     // initialize object header only.</span>
<span class="line-added">3517     bind(initialize_header);</span>
<span class="line-added">3518     pop(klass);</span>
<span class="line-added">3519     Register mark_word = t2;</span>
<span class="line-added">3520     movptr(mark_word, Address(klass, Klass::prototype_header_offset()));</span>
<span class="line-added">3521     movptr(Address(new_obj, oopDesc::mark_offset_in_bytes ()), mark_word);</span>
<span class="line-added">3522 #ifdef _LP64</span>
<span class="line-added">3523     xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3524     store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops</span>
<span class="line-added">3525 #endif</span>
<span class="line-added">3526     movptr(t2, klass);         // preserve klass</span>
<span class="line-added">3527     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">3528     store_klass(new_obj, t2, tmp_store_klass);  // src klass reg is potentially compressed</span>
<span class="line-added">3529 </span>
<span class="line-added">3530     jmp(done);</span>
<span class="line-added">3531   }</span>
<span class="line-added">3532 </span>
<span class="line-added">3533   bind(slow_case);</span>
<span class="line-added">3534   pop(klass);</span>
<span class="line-added">3535   bind(slow_case_no_pop);</span>
<span class="line-added">3536   jmp(alloc_failed);</span>
<span class="line-added">3537 </span>
<span class="line-added">3538   bind(done);</span>
<span class="line-added">3539 }</span>
<span class="line-added">3540 </span>
3541 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3542 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3543                                    Register var_size_in_bytes,
3544                                    int con_size_in_bytes,
3545                                    Register t1,
3546                                    Register t2,
3547                                    Label&amp; slow_case) {
3548   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3549   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3550 }
3551 
3552 // Defines obj, preserves var_size_in_bytes
3553 void MacroAssembler::eden_allocate(Register thread, Register obj,
3554                                    Register var_size_in_bytes,
3555                                    int con_size_in_bytes,
3556                                    Register t1,
3557                                    Label&amp; slow_case) {
3558   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3559   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3560 }
</pre>
<hr />
<pre>
3598     // clear topmost word (no jump would be needed if conditional assignment worked here)
3599     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3600     // index could be 0 now, must check again
3601     jcc(Assembler::zero, done);
3602     bind(even);
3603   }
3604 #endif // !_LP64
3605   // initialize remaining object fields: index is a multiple of 2 now
3606   {
3607     Label loop;
3608     bind(loop);
3609     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3610     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3611     decrement(index);
3612     jcc(Assembler::notZero, loop);
3613   }
3614 
3615   bind(done);
3616 }
3617 
<span class="line-added">3618 void MacroAssembler::get_value_field_klass(Register klass, Register index, Register value_klass) {</span>
<span class="line-added">3619   movptr(value_klass, Address(klass, InstanceKlass::value_field_klasses_offset()));</span>
<span class="line-added">3620 #ifdef ASSERT</span>
<span class="line-added">3621   {</span>
<span class="line-added">3622     Label done;</span>
<span class="line-added">3623     cmpptr(value_klass, 0);</span>
<span class="line-added">3624     jcc(Assembler::notEqual, done);</span>
<span class="line-added">3625     stop(&quot;get_value_field_klass contains no inline klasses&quot;);</span>
<span class="line-added">3626     bind(done);</span>
<span class="line-added">3627   }</span>
<span class="line-added">3628 #endif</span>
<span class="line-added">3629   movptr(value_klass, Address(value_klass, index, Address::times_ptr));</span>
<span class="line-added">3630 }</span>
<span class="line-added">3631 </span>
<span class="line-added">3632 void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3633 #ifdef ASSERT</span>
<span class="line-added">3634   {</span>
<span class="line-added">3635     Label done_check;</span>
<span class="line-added">3636     test_klass_is_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3637     stop(&quot;get_default_value_oop from non-value klass&quot;);</span>
<span class="line-added">3638     bind(done_check);</span>
<span class="line-added">3639   }</span>
<span class="line-added">3640 #endif</span>
<span class="line-added">3641   Register offset = temp_reg;</span>
<span class="line-added">3642   // Getting the offset of the pre-allocated default value</span>
<span class="line-added">3643   movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_valueklass_fixed_block_offset())));</span>
<span class="line-added">3644   movl(offset, Address(offset, in_bytes(ValueKlass::default_value_offset_offset())));</span>
<span class="line-added">3645 </span>
<span class="line-added">3646   // Getting the mirror</span>
<span class="line-added">3647   movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="line-added">3648   resolve_oop_handle(obj, value_klass);</span>
<span class="line-added">3649 </span>
<span class="line-added">3650   // Getting the pre-allocated default value from the mirror</span>
<span class="line-added">3651   Address field(obj, offset, Address::times_1);</span>
<span class="line-added">3652   load_heap_oop(obj, field);</span>
<span class="line-added">3653 }</span>
<span class="line-added">3654 </span>
<span class="line-added">3655 void MacroAssembler::get_empty_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3656 #ifdef ASSERT</span>
<span class="line-added">3657   {</span>
<span class="line-added">3658     Label done_check;</span>
<span class="line-added">3659     test_klass_is_empty_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3660     stop(&quot;get_empty_value from non-empty value klass&quot;);</span>
<span class="line-added">3661     bind(done_check);</span>
<span class="line-added">3662   }</span>
<span class="line-added">3663 #endif</span>
<span class="line-added">3664   get_default_value_oop(value_klass, temp_reg, obj);</span>
<span class="line-added">3665 }</span>
<span class="line-added">3666 </span>
<span class="line-added">3667 </span>
3668 // Look up the method for a megamorphic invokeinterface call.
3669 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3670 // The receiver klass is in recv_klass.
3671 // On success, the result will be in method_result, and execution falls through.
3672 // On failure, execution transfers to the given label.
3673 void MacroAssembler::lookup_interface_method(Register recv_klass,
3674                                              Register intf_klass,
3675                                              RegisterOrConstant itable_index,
3676                                              Register method_result,
3677                                              Register scan_temp,
3678                                              Label&amp; L_no_such_interface,
3679                                              bool return_method) {
3680   assert_different_registers(recv_klass, intf_klass, scan_temp);
3681   assert_different_registers(method_result, intf_klass, scan_temp);
3682   assert(recv_klass != method_result || !return_method,
3683          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3684 
3685   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3686          &quot;caller must use same register for non-constant itable index as for method&quot;);
3687 
</pre>
<hr />
<pre>
3996   } else {
3997     Label L;
3998     jccb(negate_condition(cc), L);
3999     movl(dst, src);
4000     bind(L);
4001   }
4002 }
4003 
4004 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
4005   if (VM_Version::supports_cmov()) {
4006     cmovl(cc, dst, src);
4007   } else {
4008     Label L;
4009     jccb(negate_condition(cc), L);
4010     movl(dst, src);
4011     bind(L);
4012   }
4013 }
4014 
4015 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">4016   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">4017     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">4018     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">4019     return;</span>
<span class="line-added">4020   }</span>
4021 
4022   // Pass register number to verify_oop_subroutine
4023   const char* b = NULL;
4024   {
4025     ResourceMark rm;
4026     stringStream ss;
4027     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
4028     b = code_string(ss.as_string());
4029   }
4030   BLOCK_COMMENT(&quot;verify_oop {&quot;);
4031 #ifdef _LP64
4032   push(rscratch1);                    // save r10, trashed by movptr()
4033 #endif
4034   push(rax);                          // save rax,
4035   push(reg);                          // pass register argument
4036   ExternalAddress buffer((address) b);
4037   // avoid using pushptr, as it modifies scratch registers
4038   // and our contract is not to modify anything
4039   movptr(rax, buffer.addr());
4040   push(rax);
</pre>
<hr />
<pre>
4098   int stackElementSize = Interpreter::stackElementSize;
4099   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
4100 #ifdef ASSERT
4101   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
4102   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
4103 #endif
4104   Register             scale_reg    = noreg;
4105   Address::ScaleFactor scale_factor = Address::no_scale;
4106   if (arg_slot.is_constant()) {
4107     offset += arg_slot.as_constant() * stackElementSize;
4108   } else {
4109     scale_reg    = arg_slot.as_register();
4110     scale_factor = Address::times(stackElementSize);
4111   }
4112   offset += wordSize;           // return PC is on stack
4113   return Address(rsp, scale_reg, scale_factor, offset);
4114 }
4115 
4116 
4117 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">4118   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">4119     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">4120     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">4121     return;</span>
<span class="line-added">4122   }</span>
4123 
4124   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
4125   // Pass register number to verify_oop_subroutine
4126   const char* b = NULL;
4127   {
4128     ResourceMark rm;
4129     stringStream ss;
4130     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
4131     b = code_string(ss.as_string());
4132   }
4133 #ifdef _LP64
4134   push(rscratch1);                    // save r10, trashed by movptr()
4135 #endif
4136   push(rax);                          // save rax,
4137   // addr may contain rsp so we will have to adjust it based on the push
4138   // we just did (and on 64 bit we do two pushes)
4139   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
4140   // stores rax into addr which is backwards of what was intended.
4141   if (addr.uses(rsp)) {
4142     lea(rax, addr);
</pre>
<hr />
<pre>
4598 
4599 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4600   // get mirror
4601   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4602   load_method_holder(mirror, method);
4603   movptr(mirror, Address(mirror, mirror_offset));
4604   resolve_oop_handle(mirror, tmp);
4605 }
4606 
4607 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4608   load_method_holder(rresult, rmethod);
4609   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4610 }
4611 
4612 void MacroAssembler::load_method_holder(Register holder, Register method) {
4613   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4614   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4615   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4616 }
4617 
<span class="line-added">4618 void MacroAssembler::load_metadata(Register dst, Register src) {</span>
<span class="line-added">4619   if (UseCompressedClassPointers) {</span>
<span class="line-added">4620     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4621   } else {</span>
<span class="line-added">4622     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4623   }</span>
<span class="line-added">4624 }</span>
<span class="line-added">4625 </span>
4626 void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {
4627   assert_different_registers(src, tmp);
4628   assert_different_registers(dst, tmp);
4629 #ifdef _LP64
4630   if (UseCompressedClassPointers) {
4631     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
4632     decode_klass_not_null(dst, tmp);
4633   } else
4634 #endif
<span class="line-modified">4635   movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
4636 }
4637 
4638 void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {
4639   load_klass(dst, src, tmp);
4640   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4641 }
4642 
4643 void MacroAssembler::store_klass(Register dst, Register src, Register tmp) {
4644   assert_different_registers(src, tmp);
4645   assert_different_registers(dst, tmp);
4646 #ifdef _LP64
4647   if (UseCompressedClassPointers) {
4648     encode_klass_not_null(src, tmp);
4649     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4650   } else
4651 #endif
4652     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4653 }
4654 
4655 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4656                                     Register tmp1, Register thread_tmp) {
4657   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4658   decorators = AccessInternal::decorator_fixup(decorators);
4659   bool as_raw = (decorators &amp; AS_RAW) != 0;
4660   if (as_raw) {
4661     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4662   } else {
4663     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4664   }
4665 }
4666 
4667 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4668                                      Register tmp1, Register tmp2, Register tmp3) {</span>
4669   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4670   decorators = AccessInternal::decorator_fixup(decorators);
4671   bool as_raw = (decorators &amp; AS_RAW) != 0;
4672   if (as_raw) {
<span class="line-modified">4673     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4674   } else {</span>
<span class="line-added">4675     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4676   }</span>
<span class="line-added">4677 }</span>
<span class="line-added">4678 </span>
<span class="line-added">4679 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,</span>
<span class="line-added">4680                                        Register value_klass) {</span>
<span class="line-added">4681   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added">4682   bs-&gt;value_copy(this, decorators, src, dst, value_klass);</span>
<span class="line-added">4683 }</span>
<span class="line-added">4684 </span>
<span class="line-added">4685 void MacroAssembler::first_field_offset(Register value_klass, Register offset) {</span>
<span class="line-added">4686   movptr(offset, Address(value_klass, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">4687   movl(offset, Address(offset, ValueKlass::first_field_offset_offset()));</span>
<span class="line-added">4688 }</span>
<span class="line-added">4689 </span>
<span class="line-added">4690 void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {</span>
<span class="line-added">4691   // ((address) (void*) o) + vk-&gt;first_field_offset();</span>
<span class="line-added">4692   Register offset = (data == oop) ? rscratch1 : data;</span>
<span class="line-added">4693   first_field_offset(value_klass, offset);</span>
<span class="line-added">4694   if (data == oop) {</span>
<span class="line-added">4695     addptr(data, offset);</span>
4696   } else {
<span class="line-modified">4697     lea(data, Address(oop, offset));</span>
4698   }
4699 }
4700 
<span class="line-added">4701 void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,</span>
<span class="line-added">4702                                                 Register index, Register data) {</span>
<span class="line-added">4703   assert(index != rcx, &quot;index needs to shift by rcx&quot;);</span>
<span class="line-added">4704   assert_different_registers(array, array_klass, index);</span>
<span class="line-added">4705   assert_different_registers(rcx, array, index);</span>
<span class="line-added">4706 </span>
<span class="line-added">4707   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));</span>
<span class="line-added">4708   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));</span>
<span class="line-added">4709 </span>
<span class="line-added">4710   // Klass::layout_helper_log2_element_size(lh)</span>
<span class="line-added">4711   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;</span>
<span class="line-added">4712   shrl(rcx, Klass::_lh_log2_element_size_shift);</span>
<span class="line-added">4713   andl(rcx, Klass::_lh_log2_element_size_mask);</span>
<span class="line-added">4714   shlptr(index); // index &lt;&lt; rcx</span>
<span class="line-added">4715 </span>
<span class="line-added">4716   lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_VALUETYPE)));</span>
<span class="line-added">4717 }</span>
<span class="line-added">4718 </span>
4719 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4720   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4721   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4722     decorators |= ACCESS_READ | ACCESS_WRITE;
4723   }
4724   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4725   return bs-&gt;resolve(this, decorators, obj);
4726 }
4727 
4728 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4729                                    Register thread_tmp, DecoratorSet decorators) {
4730   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4731 }
4732 
4733 // Doesn&#39;t do verfication, generates fixed size code
4734 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4735                                             Register thread_tmp, DecoratorSet decorators) {
4736   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4737 }
4738 
4739 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4740                                     Register tmp2, Register tmp3, DecoratorSet decorators) {</span>
<span class="line-modified">4741   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2, tmp3);</span>
4742 }
4743 
4744 // Used for storing NULLs.
4745 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4746   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
4747 }
4748 
4749 #ifdef _LP64
4750 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4751   if (UseCompressedClassPointers) {
4752     // Store to klass gap in destination
4753     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4754   }
4755 }
4756 
4757 #ifdef ASSERT
4758 void MacroAssembler::verify_heapbase(const char* msg) {
4759   assert (UseCompressedOops, &quot;should be compressed&quot;);
4760   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4761   if (CheckCompressedOops) {
4762     Label ok;
4763     push(rscratch1); // cmpptr trashes rscratch1
4764     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4765     jcc(Assembler::equal, ok);
4766     STOP(msg);
</pre>
<hr />
<pre>
5041   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
5042 }
5043 
5044 void MacroAssembler::reinit_heapbase() {
5045   if (UseCompressedOops) {
5046     if (Universe::heap() != NULL) {
5047       if (CompressedOops::base() == NULL) {
5048         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
5049       } else {
5050         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
5051       }
5052     } else {
5053       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
5054     }
5055   }
5056 }
5057 
5058 #endif // _LP64
5059 
5060 // C2 compiled method&#39;s prolog code.
<span class="line-modified">5061 void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="line-added">5062   int framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-added">5063   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-added">5064   bool fp_mode_24b = false;</span>
<span class="line-added">5065   int stack_bang_size = C-&gt;output()-&gt;need_stack_bang(bangsize) ? bangsize : 0;</span>
5066 
5067   // WARNING: Initial instruction MUST be 5 bytes or longer so that
5068   // NativeJump::patch_verified_entry will be able to patch out the entry
5069   // code safely. The push to verify stack depth is ok at 5 bytes,
5070   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
5071   // stack bang then we must use the 6 byte frame allocation even if
5072   // we have no frame. :-(
5073   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
5074 
5075   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
5076   // Remove word for return addr
5077   framesize -= wordSize;
5078   stack_bang_size -= wordSize;
5079 
5080   // Calls to C2R adapters often do not accept exceptional returns.
5081   // We require that their callers must bang for them.  But be careful, because
5082   // some VM calls (such as call site linkage) can use several kilobytes of
5083   // stack.  But the stack safety zone should account for that.
5084   // See bugs 4446381, 4468289, 4497237.
5085   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
5098     // Create frame
5099     if (framesize) {
5100       subptr(rsp, framesize);
5101     }
5102   } else {
5103     // Create frame (force generation of a 4 byte immediate value)
5104     subptr_imm32(rsp, framesize);
5105 
5106     // Save RBP register now.
5107     framesize -= wordSize;
5108     movptr(Address(rsp, framesize), rbp);
5109     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
5110     if (PreserveFramePointer) {
5111       movptr(rbp, rsp);
5112       if (framesize &gt; 0) {
5113         addptr(rbp, framesize);
5114       }
5115     }
5116   }
5117 
<span class="line-added">5118   if (C-&gt;needs_stack_repair()) {</span>
<span class="line-added">5119     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="line-added">5120     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="line-added">5121     movptr(Address(rsp, C-&gt;output()-&gt;sp_inc_offset()), sp_inc + framesize + wordSize);</span>
<span class="line-added">5122   }</span>
<span class="line-added">5123 </span>
5124   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
5125     framesize -= wordSize;
5126     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
5127   }
5128 
5129 #ifndef _LP64
5130   // If method sets FPU control word do it now
5131   if (fp_mode_24b) {
5132     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
5133   }
5134   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
5135     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
5136   }
5137 #endif
5138 
5139 #ifdef ASSERT
5140   if (VerifyStackAtCalls) {
5141     Label L;
5142     push(rax);
5143     mov(rax, rsp);
5144     andptr(rax, StackAlignmentInBytes-1);
5145     cmpptr(rax, StackAlignmentInBytes-wordSize);
5146     pop(rax);
5147     jcc(Assembler::equal, L);
5148     STOP(&quot;Stack is not properly aligned!&quot;);
5149     bind(L);
5150   }
5151 #endif





5152 }
5153 
5154 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">5155 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp) {</span>
5156   // cnt - number of qwords (8-byte words).
5157   // base - start address, qword aligned.
5158   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;
<span class="line-added">5159   movdq(xtmp, val);</span>
5160   if (UseAVX &gt;= 2) {
<span class="line-modified">5161     punpcklqdq(xtmp, xtmp);</span>
<span class="line-added">5162     vinserti128_high(xtmp, xtmp);</span>
5163   } else {
<span class="line-modified">5164     punpcklqdq(xtmp, xtmp);</span>
5165   }
5166   jmp(L_zero_64_bytes);
5167 
5168   BIND(L_loop);
5169   if (UseAVX &gt;= 2) {
5170     vmovdqu(Address(base,  0), xtmp);
5171     vmovdqu(Address(base, 32), xtmp);
5172   } else {
5173     movdqu(Address(base,  0), xtmp);
5174     movdqu(Address(base, 16), xtmp);
5175     movdqu(Address(base, 32), xtmp);
5176     movdqu(Address(base, 48), xtmp);
5177   }
5178   addptr(base, 64);
5179 
5180   BIND(L_zero_64_bytes);
5181   subptr(cnt, 8);
5182   jccb(Assembler::greaterEqual, L_loop);
5183   addptr(cnt, 4);
5184   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
5188   } else {
5189     movdqu(Address(base,  0), xtmp);
5190     movdqu(Address(base, 16), xtmp);
5191   }
5192   addptr(base, 32);
5193   subptr(cnt, 4);
5194 
5195   BIND(L_tail);
5196   addptr(cnt, 4);
5197   jccb(Assembler::lessEqual, L_end);
5198   decrement(cnt);
5199 
5200   BIND(L_sloop);
5201   movq(Address(base, 0), xtmp);
5202   addptr(base, 8);
5203   decrement(cnt);
5204   jccb(Assembler::greaterEqual, L_sloop);
5205   BIND(L_end);
5206 }
5207 
<span class="line-modified">5208 int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="line-added">5209   // A value type might be returned. If fields are in registers we</span>
<span class="line-added">5210   // need to allocate a value type instance and initialize it with</span>
<span class="line-added">5211   // the value of the fields.</span>
<span class="line-added">5212   Label skip;</span>
<span class="line-added">5213   // We only need a new buffered value if a new one is not returned</span>
<span class="line-added">5214   testptr(rax, 1);</span>
<span class="line-added">5215   jcc(Assembler::zero, skip);</span>
<span class="line-added">5216   int call_offset = -1;</span>
<span class="line-added">5217 </span>
<span class="line-added">5218 #ifdef _LP64</span>
<span class="line-added">5219   Label slow_case;</span>
<span class="line-added">5220 </span>
<span class="line-added">5221   // Try to allocate a new buffered value (from the heap)</span>
<span class="line-added">5222   if (UseTLAB) {</span>
<span class="line-added">5223     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.</span>
<span class="line-added">5224     if (vk != NULL) {</span>
<span class="line-added">5225       // Called from C1, where the return type is statically known.</span>
<span class="line-added">5226       movptr(rbx, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="line-added">5227       jint lh = vk-&gt;layout_helper();</span>
<span class="line-added">5228       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="line-added">5229       movl(r14, lh);</span>
<span class="line-added">5230     } else {</span>
<span class="line-added">5231       // Call from interpreter. RAX contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="line-added">5232       mov(rbx, rax);</span>
<span class="line-added">5233       andptr(rbx, -2);</span>
<span class="line-added">5234       movl(r14, Address(rbx, Klass::layout_helper_offset()));</span>
<span class="line-added">5235     }</span>
<span class="line-added">5236 </span>
<span class="line-added">5237     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5238     lea(r14, Address(r13, r14, Address::times_1));</span>
<span class="line-added">5239     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="line-added">5240     jcc(Assembler::above, slow_case);</span>
<span class="line-added">5241     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);</span>
<span class="line-added">5242     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());</span>
<span class="line-added">5243 </span>
<span class="line-added">5244     xorl(rax, rax); // use zero reg to clear memory (shorter code)</span>
<span class="line-added">5245     store_klass_gap(r13, rax);  // zero klass gap for compressed oops</span>
<span class="line-added">5246 </span>
<span class="line-added">5247     if (vk == NULL) {</span>
<span class="line-added">5248       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="line-added">5249       mov(rax, rbx);</span>
<span class="line-added">5250     }</span>
<span class="line-added">5251     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">5252     store_klass(r13, rbx, tmp_store_klass);  // klass</span>
<span class="line-added">5253 </span>
<span class="line-added">5254     // We have our new buffered value, initialize its fields with a</span>
<span class="line-added">5255     // value class specific handler</span>
<span class="line-added">5256     if (vk != NULL) {</span>
<span class="line-added">5257       // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="line-added">5258       mov(rax, r13);</span>
<span class="line-added">5259       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="line-added">5260     } else {</span>
<span class="line-added">5261       movptr(rbx, Address(rax, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">5262       movptr(rbx, Address(rbx, ValueKlass::pack_handler_offset()));</span>
<span class="line-added">5263       mov(rax, r13);</span>
<span class="line-added">5264       call(rbx);</span>
<span class="line-added">5265     }</span>
<span class="line-added">5266     jmp(skip);</span>
<span class="line-added">5267   }</span>
<span class="line-added">5268 </span>
<span class="line-added">5269   bind(slow_case);</span>
<span class="line-added">5270   // We failed to allocate a new value, fall back to a runtime</span>
<span class="line-added">5271   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="line-added">5272   // tell. That runtime call will take care of preserving them</span>
<span class="line-added">5273   // across a GC if there&#39;s one.</span>
<span class="line-added">5274 #endif</span>
<span class="line-added">5275 </span>
<span class="line-added">5276   if (from_interpreter) {</span>
<span class="line-added">5277     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="line-added">5278   } else {</span>
<span class="line-added">5279     call(RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="line-added">5280     call_offset = offset();</span>
<span class="line-added">5281   }</span>
<span class="line-added">5282 </span>
<span class="line-added">5283   bind(skip);</span>
<span class="line-added">5284   return call_offset;</span>
<span class="line-added">5285 }</span>
<span class="line-added">5286 </span>
<span class="line-added">5287 </span>
<span class="line-added">5288 // Move a value between registers/stack slots and update the reg_state</span>
<span class="line-added">5289 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5290   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5291     return true; // Already written</span>
<span class="line-added">5292   }</span>
<span class="line-added">5293   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="line-added">5294     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5295       return false; // Not yet writable</span>
<span class="line-added">5296     }</span>
<span class="line-added">5297     if (from-&gt;is_reg()) {</span>
<span class="line-added">5298       if (to-&gt;is_reg()) {</span>
<span class="line-added">5299         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5300           if (bt == T_DOUBLE) {</span>
<span class="line-added">5301             movdbl(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5302           } else {</span>
<span class="line-added">5303             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5304             movflt(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5305           }</span>
<span class="line-added">5306         } else {</span>
<span class="line-added">5307           movq(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="line-added">5308         }</span>
<span class="line-added">5309       } else {</span>
<span class="line-added">5310         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5311         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5312         Address to_addr = Address(rsp, st_off);</span>
<span class="line-added">5313         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5314           if (bt == T_DOUBLE) {</span>
<span class="line-added">5315             movdbl(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5316           } else {</span>
<span class="line-added">5317             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5318             movflt(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5319           }</span>
<span class="line-added">5320         } else {</span>
<span class="line-added">5321           movq(to_addr, from-&gt;as_Register());</span>
<span class="line-added">5322         }</span>
<span class="line-added">5323       }</span>
<span class="line-added">5324     } else {</span>
<span class="line-added">5325       Address from_addr = Address(rsp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="line-added">5326       if (to-&gt;is_reg()) {</span>
<span class="line-added">5327         if (to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5328           if (bt == T_DOUBLE) {</span>
<span class="line-added">5329             movdbl(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5330           } else {</span>
<span class="line-added">5331             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5332             movflt(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5333           }</span>
<span class="line-added">5334         } else {</span>
<span class="line-added">5335           movq(to-&gt;as_Register(), from_addr);</span>
<span class="line-added">5336         }</span>
<span class="line-added">5337       } else {</span>
<span class="line-added">5338         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5339         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5340         movq(r13, from_addr);</span>
<span class="line-added">5341         movq(Address(rsp, st_off), r13);</span>
<span class="line-added">5342       }</span>
<span class="line-added">5343     }</span>
<span class="line-added">5344   }</span>
<span class="line-added">5345   // Update register states</span>
<span class="line-added">5346   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5347   reg_state[to-&gt;value()] = reg_written;</span>
<span class="line-added">5348   return true;</span>
<span class="line-added">5349 }</span>
<span class="line-added">5350 </span>
<span class="line-added">5351 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-added">5352 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-added">5353                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5354   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="line-added">5355   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5356 </span>
<span class="line-added">5357   int vt = 1;</span>
<span class="line-added">5358   bool done = true;</span>
<span class="line-added">5359   bool mark_done = true;</span>
<span class="line-added">5360   do {</span>
<span class="line-added">5361     sig_index--;</span>
<span class="line-added">5362     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="line-added">5363     if (bt == T_VALUETYPE) {</span>
<span class="line-added">5364       vt--;</span>
<span class="line-added">5365     } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">5366                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="line-added">5367                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="line-added">5368       vt++;</span>
<span class="line-added">5369     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="line-added">5370       to_index--; // Ignore this</span>
<span class="line-added">5371     } else {</span>
<span class="line-added">5372       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="line-added">5373       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="line-added">5374       VMReg to = pair_to.first();</span>
<span class="line-added">5375 </span>
<span class="line-added">5376       if (bt == T_VOID) continue;</span>
<span class="line-added">5377 </span>
<span class="line-added">5378       int idx = (int)to-&gt;value();</span>
<span class="line-added">5379       if (reg_state[idx] == reg_readonly) {</span>
<span class="line-added">5380          if (idx != from-&gt;value()) {</span>
<span class="line-added">5381            mark_done = false;</span>
<span class="line-added">5382          }</span>
<span class="line-added">5383          done = false;</span>
<span class="line-added">5384          continue;</span>
<span class="line-added">5385       } else if (reg_state[idx] == reg_written) {</span>
<span class="line-added">5386         continue;</span>
<span class="line-added">5387       } else {</span>
<span class="line-added">5388         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="line-added">5389         reg_state[idx] = reg_written;</span>
<span class="line-added">5390        }</span>
<span class="line-added">5391 </span>
<span class="line-added">5392       if (fromReg == noreg) {</span>
<span class="line-added">5393         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5394         movq(r10, Address(rsp, st_off));</span>
<span class="line-added">5395         fromReg = r10;</span>
<span class="line-added">5396       }</span>
<span class="line-added">5397 </span>
<span class="line-added">5398       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="line-added">5399       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5400       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5401 </span>
<span class="line-added">5402       Address fromAddr = Address(fromReg, off);</span>
<span class="line-added">5403       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="line-added">5404       if (!to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5405         Register dst = to-&gt;is_stack() ? r13 : to-&gt;as_Register();</span>
<span class="line-added">5406         if (is_oop) {</span>
<span class="line-added">5407           load_heap_oop(dst, fromAddr);</span>
<span class="line-added">5408         } else {</span>
<span class="line-added">5409           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="line-added">5410         }</span>
<span class="line-added">5411         if (to-&gt;is_stack()) {</span>
<span class="line-added">5412           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5413           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5414           movq(Address(rsp, st_off), dst);</span>
<span class="line-added">5415         }</span>
<span class="line-added">5416       } else {</span>
<span class="line-added">5417         if (bt == T_DOUBLE) {</span>
<span class="line-added">5418           movdbl(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5419         } else {</span>
<span class="line-added">5420           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5421           movflt(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5422         }</span>
<span class="line-added">5423       }</span>
<span class="line-added">5424     }</span>
<span class="line-added">5425   } while (vt != 0);</span>
<span class="line-added">5426   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="line-added">5427     // This is okay because no one else will write to that slot</span>
<span class="line-added">5428     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5429   }</span>
<span class="line-added">5430   return done;</span>
<span class="line-added">5431 }</span>
<span class="line-added">5432 </span>
<span class="line-added">5433 // Pack fields back into a value type oop</span>
<span class="line-added">5434 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-added">5435                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-added">5436                                        int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5437   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5438   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="line-added">5439 </span>
<span class="line-added">5440   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5441     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5442     return true; // Already written</span>
<span class="line-added">5443   }</span>
<span class="line-added">5444 </span>
<span class="line-added">5445   Register val_array = rax;</span>
<span class="line-added">5446   Register val_obj_tmp = r11;</span>
<span class="line-added">5447   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling</span>
<span class="line-added">5448   Register tmp1 = r10;</span>
<span class="line-added">5449   Register tmp2 = r13;</span>
<span class="line-added">5450   Register tmp3 = rbx;</span>
<span class="line-added">5451   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="line-added">5452 </span>
<span class="line-added">5453   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5454     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="line-added">5455       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5456       return false; // Not yet writable</span>
<span class="line-added">5457     }</span>
<span class="line-added">5458     val_obj = val_obj_tmp;</span>
<span class="line-added">5459   }</span>
<span class="line-added">5460 </span>
<span class="line-added">5461   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="line-added">5462   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="line-added">5463 </span>
<span class="line-added">5464   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5465   VMRegPair from_pair;</span>
<span class="line-added">5466   BasicType bt;</span>
<span class="line-added">5467   while (stream.next(from_pair, bt)) {</span>
<span class="line-added">5468     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="line-added">5469     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5470     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5471     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">5472 </span>
<span class="line-added">5473     VMReg from_r1 = from_pair.first();</span>
<span class="line-added">5474     VMReg from_r2 = from_pair.second();</span>
<span class="line-added">5475 </span>
<span class="line-added">5476     // Pack the scalarized field into the value object.</span>
<span class="line-added">5477     Address dst(val_obj, off);</span>
<span class="line-added">5478     if (!from_r1-&gt;is_XMMRegister()) {</span>
<span class="line-added">5479       Register from_reg;</span>
<span class="line-added">5480       if (from_r1-&gt;is_stack()) {</span>
<span class="line-added">5481         from_reg = from_reg_tmp;</span>
<span class="line-added">5482         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5483         load_sized_value(from_reg, Address(rsp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">5484       } else {</span>
<span class="line-added">5485         from_reg = from_r1-&gt;as_Register();</span>
<span class="line-added">5486       }</span>
<span class="line-added">5487       assert_different_registers(dst.base(), from_reg, tmp1, tmp2, tmp3, val_array);</span>
<span class="line-added">5488       if (is_oop) {</span>
<span class="line-added">5489         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="line-added">5490       } else {</span>
<span class="line-added">5491         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="line-added">5492       }</span>
<span class="line-added">5493     } else {</span>
<span class="line-added">5494       if (from_r2-&gt;is_valid()) {</span>
<span class="line-added">5495         movdbl(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5496       } else {</span>
<span class="line-added">5497         movflt(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5498       }</span>
<span class="line-added">5499     }</span>
<span class="line-added">5500     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="line-added">5501   }</span>
<span class="line-added">5502   sig_index = stream.sig_cc_index();</span>
<span class="line-added">5503   from_index = stream.regs_cc_index();</span>
<span class="line-added">5504 </span>
<span class="line-added">5505   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="line-added">5506   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="line-added">5507   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="line-added">5508 </span>
<span class="line-added">5509   return true;</span>
<span class="line-added">5510 }</span>
<span class="line-added">5511 </span>
<span class="line-added">5512 // Unpack all value type arguments passed as oops</span>
<span class="line-added">5513 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-added">5514   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="line-added">5515   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="line-added">5516   verified_entry(C, sp_inc);</span>
<span class="line-added">5517 }</span>
<span class="line-added">5518 </span>
<span class="line-added">5519 void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-added">5520                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">5521                                         int args_passed, int args_on_stack, VMRegPair* regs,</span>
<span class="line-added">5522                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {</span>
<span class="line-added">5523   // Check if we need to extend the stack for packing/unpacking</span>
<span class="line-added">5524   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {</span>
<span class="line-added">5525     // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-added">5526     // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-added">5527     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-added">5528     pop(r13);</span>
<span class="line-added">5529     subptr(rsp, sp_inc);</span>
<span class="line-added">5530     push(r13);</span>
<span class="line-added">5531   }</span>
<span class="line-added">5532 </span>
<span class="line-added">5533   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="line-added">5534   if (is_packing) {</span>
<span class="line-added">5535     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="line-added">5536     // rsp[0] during shuffling.</span>
<span class="line-added">5537     ret_off = 0;</span>
<span class="line-added">5538   } else {</span>
<span class="line-added">5539     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="line-added">5540     ret_off = sp_inc;</span>
<span class="line-added">5541   }</span>
<span class="line-added">5542 </span>
<span class="line-added">5543   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-added">5544                             sig_bt, sig_cc,</span>
<span class="line-added">5545                             args_passed, args_on_stack, regs,</span>
<span class="line-added">5546                             args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-added">5547                             sp_inc, ret_off);</span>
<span class="line-added">5548 }</span>
<span class="line-added">5549 </span>
<span class="line-added">5550 VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="line-added">5551   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="line-added">5552 }</span>
<span class="line-added">5553 </span>
<span class="line-added">5554 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {</span>
<span class="line-added">5555   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="line-added">5556   if (needs_stack_repair) {</span>
<span class="line-added">5557     movq(rbp, Address(rsp, initial_framesize));</span>
<span class="line-added">5558     addq(rsp, Address(rsp, sp_inc_offset));</span>
<span class="line-added">5559   } else {</span>
<span class="line-added">5560     if (initial_framesize &gt; 0) {</span>
<span class="line-added">5561       addq(rsp, initial_framesize);</span>
<span class="line-added">5562     }</span>
<span class="line-added">5563     pop(rbp);</span>
<span class="line-added">5564   }</span>
<span class="line-added">5565 }</span>
<span class="line-added">5566 </span>
<span class="line-added">5567 void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {</span>
5568   // cnt - number of qwords (8-byte words).
5569   // base - start address, qword aligned.
5570   // is_large - if optimizers know cnt is larger than InitArrayShortSize
5571   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">5572   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
5573   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
5574   assert(InitArrayShortSize % BytesPerLong == 0,
5575     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
5576 
5577   Label DONE;
5578 




5579   if (!is_large) {
5580     Label LOOP, LONG;
5581     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
5582     jccb(Assembler::greater, LONG);
5583 
5584     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5585 
5586     decrement(cnt);
5587     jccb(Assembler::negative, DONE); // Zero length
5588 
5589     // Use individual pointer-sized stores for small counts:
5590     BIND(LOOP);
<span class="line-modified">5591     movptr(Address(base, cnt, Address::times_ptr), val);</span>
5592     decrement(cnt);
5593     jccb(Assembler::greaterEqual, LOOP);
5594     jmpb(DONE);
5595 
5596     BIND(LONG);
5597   }
5598 
5599   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">5600   if (UseFastStosb &amp;&amp; !word_copy_only) {</span>
5601     shlptr(cnt, 3); // convert to number of bytes
5602     rep_stosb();
5603   } else if (UseXMMForObjInit) {
<span class="line-modified">5604     xmm_clear_mem(base, cnt, val, xtmp);</span>

5605   } else {
5606     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5607     rep_stos();
5608   }
5609 
5610   BIND(DONE);
5611 }
5612 
5613 void MacroAssembler::generate_fill(BasicType t, bool aligned,
5614                                    Register to, Register value, Register count,
5615                                    Register rtmp, XMMRegister xtmp) {
5616   ShortBranchVerifier sbv(this);
5617   assert_different_registers(to, value, count, rtmp);
5618   Label L_exit;
5619   Label L_fill_2_bytes, L_fill_4_bytes;
5620 
5621   int shift = -1;
5622   switch (t) {
5623     case T_BYTE:
5624       shift = 2;
</pre>
</td>
</tr>
</table>
<center><a href="c1_globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="methodHandles_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>