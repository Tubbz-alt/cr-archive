diff a/.hgtags b/.hgtags
--- a/.hgtags
+++ b/.hgtags
@@ -637,5 +637,6 @@
 44aef192b488a48cce12422394691a6b1d16b98e jdk-15+18
 7cc27caabe6e342151e8baf549beb07a9c755ec2 jdk-15+19
 46bca5e5e6fb26efd07245d26fe96a9c3260f51e jdk-15+20
 12b55fad80f30d24b1f8fdb3b947ea6465ef9518 jdk-15+21
 7223c6d610343fd8323af9d07d501e01fa1a7696 jdk-15+22
+f143729ca00ec14a98ea5c7f73acba88da97746e jdk-15+23
diff a/make/Images.gmk b/make/Images.gmk
--- a/make/Images.gmk
+++ b/make/Images.gmk
@@ -120,20 +120,23 @@
 JLINK_JRE_TARGETS := $(jlink_jre)
 
 ifeq ($(BUILD_CDS_ARCHIVE), true)
   ifeq ($(OPENJDK_TARGET_OS), windows)
     CDS_ARCHIVE := bin/server/classes.jsa
+    CDS_NOCOOPS_ARCHIVE := bin/server/classes_nocoops.jsa
   else
     CDS_ARCHIVE := lib/server/classes.jsa
+    CDS_NOCOOPS_ARCHIVE := lib/server/classes_nocoops.jsa
   endif
 
   $(eval $(call SetupExecute, gen_cds_archive_jdk, \
       WARN := Creating CDS archive for jdk image, \
       DEPS := $(jlink_jdk), \
       OUTPUT_FILE := $(JDK_IMAGE_DIR)/$(CDS_ARCHIVE), \
       SUPPORT_DIR := $(SUPPORT_OUTPUTDIR)/images/jdk, \
       COMMAND := $(FIXPATH) $(JDK_IMAGE_DIR)/bin/java -Xshare:dump \
+          -XX:SharedArchiveFile=$(JDK_IMAGE_DIR)/$(CDS_ARCHIVE) \
           -Xmx128M -Xms128M $(LOG_INFO), \
   ))
 
   JDK_TARGETS += $(gen_cds_archive_jdk)
 
@@ -141,14 +144,44 @@
       WARN := Creating CDS archive for jre image, \
       DEPS := $(jlink_jre), \
       OUTPUT_FILE := $(JRE_IMAGE_DIR)/$(CDS_ARCHIVE), \
       SUPPORT_DIR := $(SUPPORT_OUTPUTDIR)/images/jre, \
       COMMAND := $(FIXPATH) $(JRE_IMAGE_DIR)/bin/java -Xshare:dump \
+          -XX:SharedArchiveFile=$(JRE_IMAGE_DIR)/$(CDS_ARCHIVE) \
           -Xmx128M -Xms128M $(LOG_INFO), \
   ))
 
   JRE_TARGETS += $(gen_cds_archive_jre)
+
+  ifeq ($(call isTargetCpuBits, 64), true)
+    $(eval $(call SetupExecute, gen_cds_nocoops_archive_jdk, \
+        WARN := Creating CDS-NOCOOPS archive for jdk image, \
+        DEPS := $(jlink_jdk), \
+        OUTPUT_FILE := $(JDK_IMAGE_DIR)/$(CDS_NOCOOPS_ARCHIVE), \
+        SUPPORT_DIR := $(SUPPORT_OUTPUTDIR)/images/jdk, \
+        COMMAND := $(FIXPATH) $(JDK_IMAGE_DIR)/bin/java -Xshare:dump \
+            -XX:SharedArchiveFile=$(JDK_IMAGE_DIR)/$(CDS_NOCOOPS_ARCHIVE) \
+            -XX:-UseCompressedOops \
+            -Xmx128M -Xms128M $(LOG_INFO), \
+    ))
+
+    JDK_TARGETS += $(gen_cds_nocoops_archive_jdk)
+
+    $(eval $(call SetupExecute, gen_cds_nocoops_archive_jre, \
+        WARN := Creating CDS-NOCOOPS archive for jre image, \
+        DEPS := $(jlink_jre), \
+        OUTPUT_FILE := $(JRE_IMAGE_DIR)/$(CDS_NOCOOPS_ARCHIVE), \
+        SUPPORT_DIR := $(SUPPORT_OUTPUTDIR)/images/jre, \
+        COMMAND := $(FIXPATH) $(JRE_IMAGE_DIR)/bin/java -Xshare:dump \
+            -XX:SharedArchiveFile=$(JRE_IMAGE_DIR)/$(CDS_NOCOOPS_ARCHIVE) \
+            -XX:-UseCompressedOops \
+            -Xmx128M -Xms128M $(LOG_INFO), \
+    ))
+
+    JRE_TARGETS += $(gen_cds_nocoops_archive_jre)
+  endif
+
 endif
 
 ################################################################################
 # src.zip
 
diff a/make/conf/jib-profiles.js b/make/conf/jib-profiles.js
--- a/make/conf/jib-profiles.js
+++ b/make/conf/jib-profiles.js
@@ -996,13 +996,15 @@
     var devkit_platform = (input.target_cpu == "x86"
         ? input.target_os + "_x64"
         : input.target_platform);
 
     var devkit_cross_prefix = "";
-    if (input.build_platform != input.target_platform
-       && input.build_platform != devkit_platform) {
-        devkit_cross_prefix = input.build_platform + "-to-";
+    if (!(input.target_os == "windows" && isWsl(input))) {
+        if (input.build_platform != input.target_platform
+           && input.build_platform != devkit_platform) {
+            devkit_cross_prefix = input.build_platform + "-to-";
+        }
     }
 
     var boot_jdk_platform = (input.build_os == "macosx" ? "osx" : input.build_os)
         + "-" + input.build_cpu;
     var boot_jdk_ext = (input.build_os == "windows" ? ".zip" : ".tar.gz")
diff a/make/modules/java.base/gensrc/GensrcVarHandles.gmk b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
--- a/make/modules/java.base/gensrc/GensrcVarHandles.gmk
+++ b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
@@ -284,6 +284,6 @@
 # List the types to generate source for, with capitalized first letter
 VARHANDLES_MEMORY_ADDRESS_TYPES := Byte Short Char Int Long Float Double
 $(foreach t, $(VARHANDLES_MEMORY_ADDRESS_TYPES), \
   $(eval $(call GenerateVarHandleMemoryAddress,VAR_HANDLE_MEMORY_ADDRESS_$t,$t)))
 
-GENSRC_JAVA_BASE += $(GENSRC_VARHANDLES)
+TARGETS += $(GENSRC_VARHANDLES)
diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -15354,11 +15354,11 @@
   ins_cost(CALL_COST);
   format %{ "ShouldNotReachHere" %}
 
   ins_encode %{
     if (is_reachable()) {
-      __ dpcs1(0xdead + 1);
+      __ dcps1(0xdead + 1);
     }
   %}
 
   ins_pipe(pipe_class_default);
 %}
diff a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
@@ -5940,15 +5940,22 @@
 
     if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos)) {
       StubRoutines::_dcos = generate_dsin_dcos(/* isCos = */ true);
     }
 
-
     StubRoutines::_load_value_type_fields_in_regs =
          generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_value_type_fields_in_regs), "load_value_type_fields_in_regs", false);
     StubRoutines::_store_value_type_fields_to_buf =
          generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_value_type_fields_to_buf), "store_value_type_fields_to_buf", true);
+
+    // Safefetch stubs.
+    generate_safefetch("SafeFetch32", sizeof(int),     &StubRoutines::_safefetch32_entry,
+                                                       &StubRoutines::_safefetch32_fault_pc,
+                                                       &StubRoutines::_safefetch32_continuation_pc);
+    generate_safefetch("SafeFetchN", sizeof(intptr_t), &StubRoutines::_safefetchN_entry,
+                                                       &StubRoutines::_safefetchN_fault_pc,
+                                                       &StubRoutines::_safefetchN_continuation_pc);
   }
 
   void generate_all() {
     // support for verify_oop (must happen after universe_init)
     StubRoutines::_verify_oop_subroutine_entry     = generate_verify_oop();
@@ -6048,17 +6055,10 @@
     // generate Adler32 intrinsics code
     if (UseAdler32Intrinsics) {
       StubRoutines::_updateBytesAdler32 = generate_updateBytesAdler32();
     }
 
-    // Safefetch stubs.
-    generate_safefetch("SafeFetch32", sizeof(int),     &StubRoutines::_safefetch32_entry,
-                                                       &StubRoutines::_safefetch32_fault_pc,
-                                                       &StubRoutines::_safefetch32_continuation_pc);
-    generate_safefetch("SafeFetchN", sizeof(intptr_t), &StubRoutines::_safefetchN_entry,
-                                                       &StubRoutines::_safefetchN_fault_pc,
-                                                       &StubRoutines::_safefetchN_continuation_pc);
     StubRoutines::aarch64::set_completed();
   }
 
  public:
   StubGenerator(CodeBuffer* code, bool all) : StubCodeGenerator(code) {
diff a/src/hotspot/cpu/x86/c1_globals_x86.hpp b/src/hotspot/cpu/x86/c1_globals_x86.hpp
--- a/src/hotspot/cpu/x86/c1_globals_x86.hpp
+++ b/src/hotspot/cpu/x86/c1_globals_x86.hpp
@@ -41,11 +41,10 @@
 define_pd_global(bool, UseOnStackReplacement,          true );
 define_pd_global(bool, TieredCompilation,              true);
 define_pd_global(intx, CompileThreshold,               1500 );
 
 define_pd_global(intx,   OnStackReplacePercentage,     933  );
-define_pd_global(intx,   FreqInlineSize,               325  );
 define_pd_global(size_t, NewSizeThreadIncrease,        4*K  );
 define_pd_global(uintx,  InitialCodeCacheSize,         160*K);
 define_pd_global(uintx,  ReservedCodeCacheSize,        32*M );
 define_pd_global(uintx,  NonProfiledCodeHeapSize,      13*M );
 define_pd_global(uintx,  ProfiledCodeHeapSize,         14*M );
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -901,22 +901,23 @@
   PRINT_REG(rcx, regs[14]);
   PRINT_REG(rdx, regs[13]);
   PRINT_REG(rdi, regs[8]);
   PRINT_REG(rsi, regs[9]);
   PRINT_REG(rbp, regs[10]);
-  PRINT_REG(rsp, regs[11]);
+  // rsp is actually not stored by pusha(), compute the old rsp from regs (rsp after pusha): regs + 16 = old rsp
+  PRINT_REG(rsp, (intptr_t)(&regs[16]));
   PRINT_REG(r8 , regs[7]);
   PRINT_REG(r9 , regs[6]);
   PRINT_REG(r10, regs[5]);
   PRINT_REG(r11, regs[4]);
   PRINT_REG(r12, regs[3]);
   PRINT_REG(r13, regs[2]);
   PRINT_REG(r14, regs[1]);
   PRINT_REG(r15, regs[0]);
 #undef PRINT_REG
-  // Print some words near top of staack.
-  int64_t* rsp = (int64_t*) regs[11];
+  // Print some words near the top of the stack.
+  int64_t* rsp = &regs[16];
   int64_t* dump_sp = rsp;
   for (int col1 = 0; col1 < 8; col1++) {
     tty->print("(rsp+0x%03x) 0x%016lx: ", (int)((intptr_t)dump_sp - (intptr_t)rsp), (intptr_t)dump_sp);
     os::print_location(tty, *dump_sp++);
   }
diff a/src/hotspot/cpu/x86/methodHandles_x86.cpp b/src/hotspot/cpu/x86/methodHandles_x86.cpp
--- a/src/hotspot/cpu/x86/methodHandles_x86.cpp
+++ b/src/hotspot/cpu/x86/methodHandles_x86.cpp
@@ -509,11 +509,21 @@
     tty->print_cr("Registers:");
     const int saved_regs_count = RegisterImpl::number_of_registers;
     for (int i = 0; i < saved_regs_count; i++) {
       Register r = as_Register(i);
       // The registers are stored in reverse order on the stack (by pusha).
+#ifdef AMD64
+      assert(RegisterImpl::number_of_registers == 16, "sanity");
+      if (r == rsp) {
+        // rsp is actually not stored by pusha(), compute the old rsp from saved_regs (rsp after pusha): saved_regs + 16 = old rsp
+        tty->print("%3s=" PTR_FORMAT, r->name(), (intptr_t)(&saved_regs[16]));
+      } else {
+        tty->print("%3s=" PTR_FORMAT, r->name(), saved_regs[((saved_regs_count - 1) - i)]);
+      }
+#else
       tty->print("%3s=" PTR_FORMAT, r->name(), saved_regs[((saved_regs_count - 1) - i)]);
+#endif
       if ((i + 1) % 4 == 0) {
         tty->cr();
       } else {
         tty->print(", ");
       }
diff a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
--- a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
+++ b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
@@ -6570,10 +6570,18 @@
       }
       if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {
         StubRoutines::_dtan = generate_libmTan();
       }
     }
+
+    // Safefetch stubs.
+    generate_safefetch("SafeFetch32", sizeof(int),     &StubRoutines::_safefetch32_entry,
+                                                       &StubRoutines::_safefetch32_fault_pc,
+                                                       &StubRoutines::_safefetch32_continuation_pc);
+    generate_safefetch("SafeFetchN", sizeof(intptr_t), &StubRoutines::_safefetchN_entry,
+                                                       &StubRoutines::_safefetchN_fault_pc,
+                                                       &StubRoutines::_safefetchN_continuation_pc);
   }
 
   void generate_all() {
     // Generates all stubs and initializes the entry points
 
@@ -6689,18 +6697,10 @@
       StubRoutines::x86::_left_shift_mask = base64_left_shift_mask_addr();
       StubRoutines::x86::_right_shift_mask = base64_right_shift_mask_addr();
       StubRoutines::_base64_encodeBlock = generate_base64_encodeBlock();
     }
 
-    // Safefetch stubs.
-    generate_safefetch("SafeFetch32", sizeof(int),     &StubRoutines::_safefetch32_entry,
-                                                       &StubRoutines::_safefetch32_fault_pc,
-                                                       &StubRoutines::_safefetch32_continuation_pc);
-    generate_safefetch("SafeFetchN", sizeof(intptr_t), &StubRoutines::_safefetchN_entry,
-                                                       &StubRoutines::_safefetchN_fault_pc,
-                                                       &StubRoutines::_safefetchN_continuation_pc);
-
     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()->barrier_set_nmethod();
     if (bs_nm != NULL) {
       StubRoutines::x86::_method_entry_barrier = generate_method_entry_barrier();
     }
 #ifdef COMPILER2
diff a/src/hotspot/share/c1/c1_GraphBuilder.cpp b/src/hotspot/share/c1/c1_GraphBuilder.cpp
--- a/src/hotspot/share/c1/c1_GraphBuilder.cpp
+++ b/src/hotspot/share/c1/c1_GraphBuilder.cpp
@@ -36,10 +36,11 @@
 #include "ci/ciValueKlass.hpp"
 #include "compiler/compilationPolicy.hpp"
 #include "compiler/compileBroker.hpp"
 #include "compiler/compilerEvent.hpp"
 #include "interpreter/bytecode.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "memory/resourceArea.hpp"
 #include "oops/oop.inline.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/vm_version.hpp"
 #include "utilities/bitMap.inline.hpp"
@@ -710,14 +711,14 @@
   , _ignore_return(false)
 {
   if (parent != NULL) {
     _max_inline_size = (intx) ((float) NestedInliningSizeRatio * (float) parent->max_inline_size() / 100.0f);
   } else {
-    _max_inline_size = MaxInlineSize;
+    _max_inline_size = C1MaxInlineSize;
   }
-  if (_max_inline_size < MaxTrivialSize) {
-    _max_inline_size = MaxTrivialSize;
+  if (_max_inline_size < C1MaxTrivialSize) {
+    _max_inline_size = C1MaxTrivialSize;
   }
 }
 
 
 void GraphBuilder::kill_all() {
@@ -4096,22 +4097,28 @@
   }
 
   // now perform tests that are based on flag settings
   bool inlinee_by_directive = compilation()->directive()->should_inline(callee);
   if (callee->force_inline() || inlinee_by_directive) {
-    if (inline_level() > MaxForceInlineLevel                    ) INLINE_BAILOUT("MaxForceInlineLevel");
-    if (recursive_inline_level(callee) > MaxRecursiveInlineLevel) INLINE_BAILOUT("recursive inlining too deep");
+    if (inline_level() > MaxForceInlineLevel                      ) INLINE_BAILOUT("MaxForceInlineLevel");
+    if (recursive_inline_level(callee) > C1MaxRecursiveInlineLevel) INLINE_BAILOUT("recursive inlining too deep");
 
     const char* msg = "";
     if (callee->force_inline())  msg = "force inline by annotation";
     if (inlinee_by_directive)    msg = "force inline by CompileCommand";
     print_inlining(callee, msg);
   } else {
     // use heuristic controls on inlining
-    if (inline_level() > MaxInlineLevel                         ) INLINE_BAILOUT("inlining too deep");
-    if (recursive_inline_level(callee) > MaxRecursiveInlineLevel) INLINE_BAILOUT("recursive inlining too deep");
+    if (inline_level() > C1MaxInlineLevel                       ) INLINE_BAILOUT("inlining too deep");
+    int callee_recursive_level = recursive_inline_level(callee);
+    if (callee_recursive_level > C1MaxRecursiveInlineLevel      ) INLINE_BAILOUT("recursive inlining too deep");
     if (callee->code_size_for_inlining() > max_inline_size()    ) INLINE_BAILOUT("callee is too large");
+    // Additional condition to limit stack usage for non-recursive calls.
+    if ((callee_recursive_level == 0) &&
+        (callee->max_stack() + callee->max_locals() - callee->size_of_parameters() > C1InlineStackLimit)) {
+      INLINE_BAILOUT("callee uses too much stack");
+    }
 
     // don't inline throwable methods unless the inlining tree is rooted in a throwable class
     if (callee->name() == ciSymbol::object_initializer_name() &&
         callee->holder()->is_subclass_of(ciEnv::current()->Throwable_klass())) {
       // Throwable constructor call
diff a/src/hotspot/share/c1/c1_Instruction.hpp b/src/hotspot/share/c1/c1_Instruction.hpp
--- a/src/hotspot/share/c1/c1_Instruction.hpp
+++ b/src/hotspot/share/c1/c1_Instruction.hpp
@@ -323,11 +323,10 @@
   ValueStack*  _state_before;                    // Copy of state with input operands still on stack (or NULL)
   ValueStack*  _exception_state;                 // Copy of state for exception handling
   XHandlers*   _exception_handlers;              // Flat list of exception handlers covering this instruction
 
   friend class UseCountComputer;
-  friend class BlockBegin;
 
   void update_exception_state(ValueStack* state);
 
  protected:
   BlockBegin*  _block;                           // Block that contains this instruction
@@ -369,11 +368,10 @@
 
  public:
   void* operator new(size_t size) throw() {
     Compilation* c = Compilation::current();
     void* res = c->arena()->Amalloc(size);
-    ((Instruction*)res)->_id = c->get_next_id();
     return res;
   }
 
   static const int no_bci = -99;
 
@@ -431,11 +429,11 @@
     return Compilation::current()->number_of_instructions();
   }
 
   // creation
   Instruction(ValueType* type, ValueStack* state_before = NULL, bool type_is_constant = false)
-  :
+  : _id(Compilation::current()->get_next_id()),
 #ifndef PRODUCT
   _printable_bci(-99),
 #endif
     _use_count(0)
   , _pin_state(0)
@@ -1783,12 +1781,10 @@
 
  public:
    void* operator new(size_t size) throw() {
     Compilation* c = Compilation::current();
     void* res = c->arena()->Amalloc(size);
-    ((BlockBegin*)res)->_id = c->get_next_id();
-    ((BlockBegin*)res)->_block_id = c->get_next_block_id();
     return res;
   }
 
   // initialization/counting
   static int  number_of_blocks() {
@@ -1796,10 +1792,11 @@
   }
 
   // creation
   BlockBegin(int bci)
   : StateSplit(illegalType)
+  , _block_id(Compilation::current()->get_next_block_id())
   , _bci(bci)
   , _depth_first_number(-1)
   , _linear_scan_number(-1)
   , _dominator_depth(-1)
   , _loop_depth(0)
diff a/src/hotspot/share/c1/c1_ValueMap.cpp b/src/hotspot/share/c1/c1_ValueMap.cpp
--- a/src/hotspot/share/c1/c1_ValueMap.cpp
+++ b/src/hotspot/share/c1/c1_ValueMap.cpp
@@ -486,10 +486,11 @@
 
 GlobalValueNumbering::GlobalValueNumbering(IR* ir)
   : _compilation(ir->compilation())
   , _current_map(NULL)
   , _value_maps(ir->linear_scan_order()->length(), ir->linear_scan_order()->length(), NULL)
+  , _has_substitutions(false)
 {
   TRACE_VALUE_NUMBERING(tty->print_cr("****** start of global value numbering"));
 
   ShortLoopOptimizer short_loop_optimizer(this);
 
diff a/src/hotspot/share/ci/ciEnv.cpp b/src/hotspot/share/ci/ciEnv.cpp
--- a/src/hotspot/share/ci/ciEnv.cpp
+++ b/src/hotspot/share/ci/ciEnv.cpp
@@ -43,10 +43,11 @@
 #include "compiler/compilerEvent.hpp"
 #include "compiler/compileLog.hpp"
 #include "compiler/disassembler.hpp"
 #include "gc/shared/collectedHeap.inline.hpp"
 #include "interpreter/linkResolver.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "logging/log.hpp"
 #include "memory/allocation.inline.hpp"
 #include "memory/oopFactory.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
diff a/src/hotspot/share/classfile/bytecodeAssembler.cpp b/src/hotspot/share/classfile/bytecodeAssembler.cpp
--- a/src/hotspot/share/classfile/bytecodeAssembler.cpp
+++ b/src/hotspot/share/classfile/bytecodeAssembler.cpp
@@ -30,16 +30,16 @@
 #include "oops/constantPool.hpp"
 #include "runtime/handles.inline.hpp"
 #include "utilities/bytes.hpp"
 
 u2 BytecodeConstantPool::find_or_add(BytecodeCPEntry const& bcpe) {
-  u2 index;
-  u2* probe = _indices.get(bcpe);
-  if (probe == NULL) {
-    index = _entries.length();
+
+  u2 index = _entries.length();
+  bool created = false;
+  u2* probe = _indices.put_if_absent(bcpe, index, &created);
+  if (created) {
     _entries.append(bcpe);
-    _indices.put(bcpe, index);
   } else {
     index = *probe;
   }
   return index + _orig->length();
 }
diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -4492,27 +4492,10 @@
   int first_nonstatic_oop_offset = 0; // will be set for first oop field
 
   bool compact_fields  = true;
   bool allocate_oops_first = false;
 
-  // The next classes have predefined hard-coded fields offsets
-  // (see in JavaClasses::compute_hard_coded_offsets()).
-  // Use default fields allocation order for them.
-  if (_loader_data->class_loader() == NULL &&
-      (_class_name == vmSymbols::java_lang_ref_Reference() ||
-       _class_name == vmSymbols::java_lang_Boolean() ||
-       _class_name == vmSymbols::java_lang_Character() ||
-       _class_name == vmSymbols::java_lang_Float() ||
-       _class_name == vmSymbols::java_lang_Double() ||
-       _class_name == vmSymbols::java_lang_Byte() ||
-       _class_name == vmSymbols::java_lang_Short() ||
-       _class_name == vmSymbols::java_lang_Integer() ||
-       _class_name == vmSymbols::java_lang_Long())) {
-    allocate_oops_first = true;     // Allocate oops first
-    compact_fields   = false; // Don't compact fields
-  }
-
   int next_nonstatic_oop_offset = 0;
   int next_nonstatic_double_offset = 0;
 
   // Rearrange fields for a given allocation style
   if (allocate_oops_first) {
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -3636,10 +3636,48 @@
   bool is_reference = ik->reference_type() != REF_NONE;
   assert(!is_reference || ik->is_subclass_of(SystemDictionary::Reference_klass()), "sanity");
   return is_reference;
 }
 
+#define REFERENCE_FIELDS_DO(macro) \
+  macro(referent_offset,   k, "referent", object_signature, false); \
+  macro(queue_offset,      k, "queue", referencequeue_signature, false); \
+  macro(next_offset,       k, "next", reference_signature, false); \
+  macro(discovered_offset, k, "discovered", reference_signature, false);
+
+void java_lang_ref_Reference::compute_offsets() {
+  if (_offsets_initialized) {
+    return;
+  }
+  _offsets_initialized = true;
+  InstanceKlass* k = SystemDictionary::Reference_klass();
+  REFERENCE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void java_lang_ref_Reference::serialize_offsets(SerializeClosure* f) {
+  f->do_bool(&_offsets_initialized);
+  REFERENCE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+}
+#endif
+
+#define BOXING_FIELDS_DO(macro) \
+  macro(value_offset,      integerKlass, "value", int_signature, false); \
+  macro(long_value_offset, longKlass, "value", long_signature, false);
+
+void java_lang_boxing_object::compute_offsets() {
+  InstanceKlass* integerKlass = SystemDictionary::Integer_klass();
+  InstanceKlass* longKlass = SystemDictionary::Long_klass();
+  BOXING_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void java_lang_boxing_object::serialize_offsets(SerializeClosure* f) {
+  BOXING_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+}
+#endif
+
 // Support for java_lang_ref_SoftReference
 //
 
 #define SOFTREFERENCE_FIELDS_DO(macro) \
   macro(timestamp_offset,    k, "timestamp", long_signature, false); \
@@ -4402,10 +4440,11 @@
 int java_lang_reflect_Parameter::modifiers_offset;
 int java_lang_reflect_Parameter::index_offset;
 int java_lang_reflect_Parameter::executable_offset;
 int java_lang_boxing_object::value_offset;
 int java_lang_boxing_object::long_value_offset;
+bool java_lang_ref_Reference::_offsets_initialized;
 int java_lang_ref_Reference::referent_offset;
 int java_lang_ref_Reference::queue_offset;
 int java_lang_ref_Reference::next_offset;
 int java_lang_ref_Reference::discovered_offset;
 int java_lang_ref_SoftReference::timestamp_offset;
@@ -4866,16 +4905,10 @@
    jvalue v;
    java_lang_boxing_object::get_value(obj, &v);
    return v.z;
 }
 
-// Use with care. This function makes a lot of assumptions about the contents of the object.
-// So naturally, only hardcode offsets if you know what you are doing.
-static int member_offset(int hardcoded_offset, int elementSize) {
-  return align_up((hardcoded_offset * elementSize) + instanceOopDesc::base_offset_in_bytes(), elementSize);
-}
-
 #define RECORDCOMPONENT_FIELDS_DO(macro) \
   macro(clazz_offset,       k, "clazz",       class_signature,  false); \
   macro(name_offset,        k, "name",        string_signature, false); \
   macro(type_offset,        k, "type",        class_signature,  false); \
   macro(accessor_offset,    k, "accessor",    reflect_method_signature, false); \
@@ -4921,26 +4954,10 @@
 
 void java_lang_reflect_RecordComponent::set_typeAnnotations(oop element, oop value) {
   element->obj_field_put(typeAnnotations_offset, value);
 }
 
-// Compute hard-coded offsets
-// Invoked before SystemDictionary::initialize, so pre-loaded classes
-// are not available to determine the offset_of_static_fields.
-void JavaClasses::compute_hard_coded_offsets() {
-
-  // java_lang_boxing_object
-  java_lang_boxing_object::value_offset      = member_offset(java_lang_boxing_object::hc_value_offset, BytesPerInt);
-  java_lang_boxing_object::long_value_offset = member_offset(java_lang_boxing_object::hc_value_offset, BytesPerLong);
-
-  // java_lang_ref_Reference
-  java_lang_ref_Reference::referent_offset    = member_offset(java_lang_ref_Reference::hc_referent_offset, heapOopSize);
-  java_lang_ref_Reference::queue_offset       = member_offset(java_lang_ref_Reference::hc_queue_offset, heapOopSize);
-  java_lang_ref_Reference::next_offset        = member_offset(java_lang_ref_Reference::hc_next_offset, heapOopSize);
-  java_lang_ref_Reference::discovered_offset  = member_offset(java_lang_ref_Reference::hc_discovered_offset, heapOopSize);
-}
-
 #define DO_COMPUTE_OFFSETS(k) k::compute_offsets();
 
 // Compute non-hard-coded field offsets of all the classes in this file
 void JavaClasses::compute_offsets() {
   if (UseSharedSpaces) {
@@ -4953,12 +4970,12 @@
     // by JavaClasses::serialize_offsets, without computing the offsets again.
     return;
   }
 
   // We have already called the compute_offsets() of the
-  // BASIC_JAVA_CLASSES_DO_PART1 classes (java_lang_String and java_lang_Class)
-  // earlier inside SystemDictionary::resolve_well_known_classes()
+  // BASIC_JAVA_CLASSES_DO_PART1 classes (java_lang_String, java_lang_Class and
+  // java_lang_ref_Reference) earlier inside SystemDictionary::resolve_well_known_classes()
   BASIC_JAVA_CLASSES_DO_PART2(DO_COMPUTE_OFFSETS);
 }
 
 #if INCLUDE_CDS
 #define DO_SERIALIZE_OFFSETS(k) k::serialize_offsets(soc);
@@ -5041,18 +5058,10 @@
   CHECK_OFFSET("java/lang/Byte",      java_lang_boxing_object, value, "B");
   CHECK_OFFSET("java/lang/Short",     java_lang_boxing_object, value, "S");
   CHECK_OFFSET("java/lang/Integer",   java_lang_boxing_object, value, "I");
   CHECK_LONG_OFFSET("java/lang/Long", java_lang_boxing_object, value, "J");
 
-  // java.lang.ref.Reference
-
-  CHECK_OFFSET("java/lang/ref/Reference", java_lang_ref_Reference, referent, "Ljava/lang/Object;");
-  CHECK_OFFSET("java/lang/ref/Reference", java_lang_ref_Reference, queue, "Ljava/lang/ref/ReferenceQueue;");
-  CHECK_OFFSET("java/lang/ref/Reference", java_lang_ref_Reference, next, "Ljava/lang/ref/Reference;");
-  // Fake field
-  //CHECK_OFFSET("java/lang/ref/Reference", java_lang_ref_Reference, discovered, "Ljava/lang/ref/Reference;");
-
   if (!valid) vm_exit_during_initialization("Hard-coded field offset verification failed");
 }
 
 #endif // PRODUCT
 
diff a/src/hotspot/share/classfile/javaClasses.hpp b/src/hotspot/share/classfile/javaClasses.hpp
--- a/src/hotspot/share/classfile/javaClasses.hpp
+++ b/src/hotspot/share/classfile/javaClasses.hpp
@@ -31,28 +31,15 @@
 #include "runtime/os.hpp"
 
 class RecordComponent;
 
 // Interface for manipulating the basic Java classes.
-//
-// All dependencies on layout of actual Java classes should be kept here.
-// If the layout of any of the classes above changes the offsets must be adjusted.
-//
-// For most classes we hardwire the offsets for performance reasons. In certain
-// cases (e.g. java.security.AccessControlContext) we compute the offsets at
-// startup since the layout here differs between JDK1.2 and JDK1.3.
-//
-// Note that fields (static and non-static) are arranged with oops before non-oops
-// on a per class basis. The offsets below have to reflect this ordering.
-//
-// When editing the layouts please update the check_offset verification code
-// correspondingly. The names in the enums must be identical to the actual field
-// names in order for the verification code to work.
 
 #define BASIC_JAVA_CLASSES_DO_PART1(f) \
   f(java_lang_Class) \
   f(java_lang_String) \
+  f(java_lang_ref_Reference) \
   //end
 
 #define BASIC_JAVA_CLASSES_DO_PART2(f) \
   f(java_lang_System) \
   f(java_lang_ClassLoader) \
@@ -85,10 +72,11 @@
   f(java_lang_StackFrameInfo) \
   f(java_lang_LiveStackFrameInfo) \
   f(java_util_concurrent_locks_AbstractOwnableSynchronizer) \
   f(jdk_internal_misc_UnsafeConstants) \
   f(jdk_internal_vm_jni_SubElementSelector) \
+  f(java_lang_boxing_object) \
   //end
 
 #define BASIC_JAVA_CLASSES_DO(f) \
         BASIC_JAVA_CLASSES_DO_PART1(f) \
         BASIC_JAVA_CLASSES_DO_PART2(f)
@@ -537,17 +525,10 @@
 class java_lang_Throwable: AllStatic {
   friend class BacktraceBuilder;
   friend class BacktraceIterator;
 
  private:
-  // Offsets
-  enum {
-    hc_backtrace_offset     =  0,
-    hc_detailMessage_offset =  1,
-    hc_cause_offset         =  2,  // New since 1.4
-    hc_stackTrace_offset    =  3   // New since 1.4
-  };
   // Trace constants
   enum {
     trace_methods_offset = 0,
     trace_bcis_offset    = 1,
     trace_mirrors_offset = 2,
@@ -894,13 +875,10 @@
 
 // This could be separated out into 8 individual classes.
 
 class java_lang_boxing_object: AllStatic {
  private:
-  enum {
-   hc_value_offset = 0
-  };
   static int value_offset;
   static int long_value_offset;
 
   static oop initialize_and_allocate(BasicType type, TRAPS);
  public:
@@ -918,27 +896,25 @@
   static int value_offset_in_bytes(BasicType type) {
     return ( type == T_LONG || type == T_DOUBLE ) ? long_value_offset :
                                                     value_offset;
   }
 
+  static void compute_offsets();
+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
+
   // Debugging
   friend class JavaClasses;
 };
 
 
 
 // Interface to java.lang.ref.Reference objects
 
 class java_lang_ref_Reference: AllStatic {
- public:
-  enum {
-   hc_referent_offset   = 0,
-   hc_queue_offset      = 1,
-   hc_next_offset       = 2,
-   hc_discovered_offset = 3  // Is not last, see SoftRefs.
-  };
+  static bool _offsets_initialized;
 
+ public:
   static int referent_offset;
   static int queue_offset;
   static int next_offset;
   static int discovered_offset;
 
@@ -958,10 +934,13 @@
   static inline oop queue(oop ref);
   static inline void set_queue(oop ref, oop value);
   static bool is_referent_field(oop obj, ptrdiff_t offset);
   static inline bool is_final(oop ref);
   static inline bool is_phantom(oop ref);
+
+  static void compute_offsets();
+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 };
 
 
 // Interface to java.lang.ref.SoftReference objects
 
@@ -1763,11 +1742,10 @@
     MAX_enum
   };
 
   static int compute_injected_offset(InjectedFieldID id);
 
-  static void compute_hard_coded_offsets();
   static void compute_offsets();
   static void check_offsets() PRODUCT_RETURN;
   static void serialize_offsets(SerializeClosure* soc) NOT_CDS_RETURN;
   static InjectedField* get_injected(Symbol* class_name, int* field_count);
   static bool is_supported_for_archiving(oop obj) NOT_CDS_JAVA_HEAP_RETURN_(false);
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -2140,10 +2140,17 @@
   Universe::fixup_mirrors(CHECK);
 
   // do a bunch more:
   resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(Reference_klass), scan, CHECK);
 
+  // The offsets for jlr.Reference must be computed before
+  // InstanceRefKlass::update_nonstatic_oop_maps is called. That function uses
+  // the offsets to remove the referent and discovered fields from the oop maps,
+  // as they are treated in a special way by the GC. Removing these oops from the
+  // oop maps must be done before the usual subclasses of jlr.Reference are loaded.
+  java_lang_ref_Reference::compute_offsets();
+
   // Preload ref klasses and set reference types
   WK_KLASS(Reference_klass)->set_reference_type(REF_OTHER);
   InstanceRefKlass::update_nonstatic_oop_maps(WK_KLASS(Reference_klass));
 
   resolve_wk_klasses_through(WK_KLASS_ENUM_NAME(PhantomReference_klass), scan, CHECK);
diff a/src/hotspot/share/classfile/vmSymbols.hpp b/src/hotspot/share/classfile/vmSymbols.hpp
--- a/src/hotspot/share/classfile/vmSymbols.hpp
+++ b/src/hotspot/share/classfile/vmSymbols.hpp
@@ -556,10 +556,11 @@
   template(object_array_signature,                    "[Ljava/lang/Object;")                                      \
   template(class_signature,                           "Ljava/lang/Class;")                                        \
   template(string_signature,                          "Ljava/lang/String;")                                       \
   template(string_array_signature,                    "[Ljava/lang/String;")                                      \
   template(reference_signature,                       "Ljava/lang/ref/Reference;")                                \
+  template(referencequeue_signature,                  "Ljava/lang/ref/ReferenceQueue;")                           \
   template(executable_signature,                      "Ljava/lang/reflect/Executable;")                           \
   template(module_signature,                          "Ljava/lang/Module;")                                       \
   template(concurrenthashmap_signature,               "Ljava/util/concurrent/ConcurrentHashMap;")                 \
   template(String_StringBuilder_signature,            "(Ljava/lang/String;)Ljava/lang/StringBuilder;")            \
   template(int_StringBuilder_signature,               "(I)Ljava/lang/StringBuilder;")                             \
diff a/src/hotspot/share/code/compiledMethod.cpp b/src/hotspot/share/code/compiledMethod.cpp
--- a/src/hotspot/share/code/compiledMethod.cpp
+++ b/src/hotspot/share/code/compiledMethod.cpp
@@ -504,21 +504,43 @@
   if (nm != NULL) {
     // Clean inline caches pointing to both zombie and not_entrant methods
     if (clean_all || !nm->is_in_use() || nm->is_unloading() || (nm->method()->code() != nm)) {
       // Inline cache cleaning should only be initiated on CompiledMethods that have been
       // observed to be is_alive(). However, with concurrent code cache unloading, it is
-      // possible that by now, the state has been racingly flipped to unloaded if the nmethod
-      // being cleaned is_unloading(). This is fine, because if that happens, then the inline
+      // possible that by now, the state has become !is_alive. This can happen in two ways:
+      // 1) It can be racingly flipped to unloaded if the nmethod // being cleaned (from the
+      // sweeper) is_unloading(). This is fine, because if that happens, then the inline
       // caches have already been cleaned under the same CompiledICLocker that we now hold during
       // inline cache cleaning, and we will simply walk the inline caches again, and likely not
       // find much of interest to clean. However, this race prevents us from asserting that the
       // nmethod is_alive(). The is_unloading() function is completely monotonic; once set due
       // to an oop dying, it remains set forever until freed. Because of that, all unloaded
       // nmethods are is_unloading(), but notably, an unloaded nmethod may also subsequently
-      // become zombie (when the sweeper converts it to zombie). Therefore, the most precise
-      // sanity check we can check for in this context is to not allow zombies.
-      assert(!from->is_zombie(), "should not clean inline caches on zombies");
+      // become zombie (when the sweeper converts it to zombie).
+      // 2) It can be racingly flipped to zombie if the nmethod being cleaned (by the concurrent
+      // GC) cleans a zombie nmethod that is concurrently made zombie by the sweeper. In this
+      // scenario, the sweeper will first transition the nmethod to zombie, and then when
+      // unregistering from the GC, it will wait until the GC is done. The GC will then clean
+      // the inline caches *with IC stubs*, even though no IC stubs are needed. This is fine,
+      // as long as the IC stubs are guaranteed to be released until the next safepoint, where
+      // IC finalization requires live IC stubs to not be associated with zombie nmethods.
+      // This is guaranteed, because the sweeper does not have a single safepoint check until
+      // after it completes the whole transition function; it will wake up after the GC is
+      // done with concurrent code cache cleaning (which blocks out safepoints using the
+      // suspendible threads set), and then call clear_ic_callsites, which will release the
+      // associated IC stubs, before a subsequent safepoint poll can be reached. This
+      // guarantees that the spuriously created IC stubs are released appropriately before
+      // IC finalization in a safepoint gets to run. Therefore, this race is fine. This is also
+      // valid in a scenario where an inline cache of a zombie nmethod gets a spurious IC stub,
+      // and then when cleaning another inline cache, fails to request an IC stub because we
+      // exhausted the IC stub buffer. In this scenario, the GC will request a safepoint after
+      // yielding the suspendible therad set, effectively unblocking safepoints. Before such
+      // a safepoint can be reached, the sweeper similarly has to wake up, clear the IC stubs,
+      // and reach the next safepoint poll, after the whole transition function has completed.
+      // Due to the various races that can cause an nmethod to first be is_alive() and then
+      // racingly become !is_alive(), it is unfortunately not possible to assert the nmethod
+      // is_alive(), !is_unloaded() or !is_zombie() here.
       if (!ic->set_to_clean(!from->is_unloading())) {
         return false;
       }
       assert(ic->is_clean(), "nmethod " PTR_FORMAT "not clean %s", p2i(from), from->method()->name_and_sig_as_C_string());
     }
diff a/src/hotspot/share/compiler/compileBroker.cpp b/src/hotspot/share/compiler/compileBroker.cpp
--- a/src/hotspot/share/compiler/compileBroker.cpp
+++ b/src/hotspot/share/compiler/compileBroker.cpp
@@ -35,10 +35,11 @@
 #include "compiler/compileLog.hpp"
 #include "compiler/compilerEvent.hpp"
 #include "compiler/compilerOracle.hpp"
 #include "compiler/directivesParser.hpp"
 #include "interpreter/linkResolver.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "logging/log.hpp"
 #include "logging/logStream.hpp"
 #include "memory/allocation.inline.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
diff a/src/hotspot/share/gc/parallel/psParallelCompact.cpp b/src/hotspot/share/gc/parallel/psParallelCompact.cpp
--- a/src/hotspot/share/gc/parallel/psParallelCompact.cpp
+++ b/src/hotspot/share/gc/parallel/psParallelCompact.cpp
@@ -1863,21 +1863,21 @@
           young_gen->from_space()->clear(SpaceDecorator::Mangle);
           young_gen->swap_spaces();
         }
 
         // Calculate optimal free space amounts
-        assert(young_gen->max_size() >
+        assert(young_gen->max_gen_size() >
           young_gen->from_space()->capacity_in_bytes() +
           young_gen->to_space()->capacity_in_bytes(),
           "Sizes of space in young gen are out-of-bounds");
 
         size_t young_live = young_gen->used_in_bytes();
         size_t eden_live = young_gen->eden_space()->used_in_bytes();
         size_t old_live = old_gen->used_in_bytes();
         size_t cur_eden = young_gen->eden_space()->capacity_in_bytes();
         size_t max_old_gen_size = old_gen->max_gen_size();
-        size_t max_eden_size = young_gen->max_size() -
+        size_t max_eden_size = young_gen->max_gen_size() -
           young_gen->from_space()->capacity_in_bytes() -
           young_gen->to_space()->capacity_in_bytes();
 
         // Used for diagnostics
         size_policy->clear_generation_free_space_flags();
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
@@ -481,18 +481,18 @@
   return TypeFunc::make(domain, range);
 }
 
 const TypeFunc* ShenandoahBarrierSetC2::shenandoah_load_reference_barrier_Type() {
   const Type **fields = TypeTuple::fields(2);
-  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL; // original field value
-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;   // original load address
+  fields[TypeFunc::Parms+0] = TypeOopPtr::BOTTOM; // original field value
+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM; // original load address
 
   const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);
 
   // create result type (range)
   fields = TypeTuple::fields(1);
-  fields[TypeFunc::Parms+0] = TypeInstPtr::NOTNULL;
+  fields[TypeFunc::Parms+0] = TypeOopPtr::BOTTOM;
   const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+1, fields);
 
   return TypeFunc::make(domain, range);
 }
 
@@ -523,11 +523,10 @@
   } else {
     assert(access.is_opt_access(), "only for optimization passes");
     assert(((decorators & C2_TIGHTLY_COUPLED_ALLOC) != 0 || !ShenandoahSATBBarrier) && (decorators & C2_ARRAY_COPY) != 0, "unexpected caller of this code");
     C2OptAccess& opt_access = static_cast<C2OptAccess&>(access);
     PhaseGVN& gvn =  opt_access.gvn();
-    MergeMemNode* mm = opt_access.mem();
 
     if (ShenandoahStoreValEnqueueBarrier) {
       Node* enqueue = gvn.transform(new ShenandoahEnqueueBarrierNode(val.node()));
       val.set_node(enqueue);
     }
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
@@ -786,11 +786,10 @@
 Node* ShenandoahBarrierC2Support::find_bottom_mem(Node* ctrl, PhaseIdealLoop* phase) {
   Node* mem = NULL;
   Node* c = ctrl;
   do {
     if (c->is_Region()) {
-      Node* phi_bottom = NULL;
       for (DUIterator_Fast imax, i = c->fast_outs(imax); i < imax && mem == NULL; i++) {
         Node* u = c->fast_out(i);
         if (u->is_Phi() && u->bottom_type() == Type::MEMORY) {
           if (u->adr_type() == TypePtr::BOTTOM) {
             mem = u;
@@ -916,80 +915,10 @@
     phase->register_new_node(null_cmp,  old_ctrl);
     phase->register_new_node(null_test, old_ctrl);
   }
 }
 
-Node* ShenandoahBarrierC2Support::clone_null_check(Node*& c, Node* val, Node* unc_ctrl, PhaseIdealLoop* phase) {
-  IdealLoopTree *loop = phase->get_loop(c);
-  Node* iff = unc_ctrl->in(0);
-  assert(iff->is_If(), "broken");
-  Node* new_iff = iff->clone();
-  new_iff->set_req(0, c);
-  phase->register_control(new_iff, loop, c);
-  Node* iffalse = new IfFalseNode(new_iff->as_If());
-  phase->register_control(iffalse, loop, new_iff);
-  Node* iftrue = new IfTrueNode(new_iff->as_If());
-  phase->register_control(iftrue, loop, new_iff);
-  c = iftrue;
-  const Type *t = phase->igvn().type(val);
-  assert(val->Opcode() == Op_CastPP, "expect cast to non null here");
-  Node* uncasted_val = val->in(1);
-  val = new CastPPNode(uncasted_val, t);
-  val->init_req(0, c);
-  phase->register_new_node(val, c);
-  return val;
-}
-
-void ShenandoahBarrierC2Support::fix_null_check(Node* unc, Node* unc_ctrl, Node* new_unc_ctrl,
-                                                Unique_Node_List& uses, PhaseIdealLoop* phase) {
-  IfNode* iff = unc_ctrl->in(0)->as_If();
-  Node* proj = iff->proj_out(0);
-  assert(proj != unc_ctrl, "bad projection");
-  Node* use = proj->unique_ctrl_out();
-
-  assert(use == unc || use->is_Region(), "what else?");
-
-  uses.clear();
-  if (use == unc) {
-    phase->set_idom(use, new_unc_ctrl, phase->dom_depth(use));
-    for (uint i = 1; i < unc->req(); i++) {
-      Node* n = unc->in(i);
-      if (phase->has_ctrl(n) && phase->get_ctrl(n) == proj) {
-        uses.push(n);
-      }
-    }
-  } else {
-    assert(use->is_Region(), "what else?");
-    uint idx = 1;
-    for (; use->in(idx) != proj; idx++);
-    for (DUIterator_Fast imax, i = use->fast_outs(imax); i < imax; i++) {
-      Node* u = use->fast_out(i);
-      if (u->is_Phi() && phase->get_ctrl(u->in(idx)) == proj) {
-        uses.push(u->in(idx));
-      }
-    }
-  }
-  for(uint next = 0; next < uses.size(); next++ ) {
-    Node *n = uses.at(next);
-    assert(phase->get_ctrl(n) == proj, "bad control");
-    phase->set_ctrl_and_loop(n, new_unc_ctrl);
-    if (n->in(0) == proj) {
-      phase->igvn().replace_input_of(n, 0, new_unc_ctrl);
-    }
-    for (uint i = 0; i < n->req(); i++) {
-      Node* m = n->in(i);
-      if (m != NULL && phase->has_ctrl(m) && phase->get_ctrl(m) == proj) {
-        uses.push(m);
-      }
-    }
-  }
-
-  phase->igvn().rehash_node_delayed(use);
-  int nb = use->replace_edge(proj, new_unc_ctrl);
-  assert(nb == 1, "only use expected");
-}
-
 void ShenandoahBarrierC2Support::test_in_cset(Node*& ctrl, Node*& not_cset_ctrl, Node* val, Node* raw_mem, PhaseIdealLoop* phase) {
   Node* old_ctrl = ctrl;
   PhaseIterGVN& igvn = phase->igvn();
 
   Node* raw_val        = new CastP2XNode(old_ctrl, val);
@@ -1195,84 +1124,19 @@
           assert(branch == NULL || branch == NodeSentinel, "was not looking for a branch");
           if (branch == NodeSentinel) {
             continue;
           }
 
-          phase->igvn().replace_input_of(u, 1, val);
-          phase->igvn().replace_input_of(lrb, ShenandoahLoadReferenceBarrierNode::ValueIn, u);
-          phase->set_ctrl(u, u->in(0));
-          phase->set_ctrl(lrb, u->in(0));
-          unc = u->in(0)->as_Proj()->is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
-          unc_ctrl = u->in(0);
-          val = u;
-
-          for (DUIterator_Fast jmax, j = val->fast_outs(jmax); j < jmax; j++) {
-            Node* u = val->fast_out(j);
-            if (u == lrb) continue;
-            phase->igvn().rehash_node_delayed(u);
-            int nb = u->replace_edge(val, lrb);
-            --j; jmax -= nb;
-          }
-
-          RegionNode* r = new RegionNode(3);
-          IfNode* iff = unc_ctrl->in(0)->as_If();
-
-          Node* ctrl_use = unc_ctrl->unique_ctrl_out();
-          Node* unc_ctrl_clone = unc_ctrl->clone();
-          phase->register_control(unc_ctrl_clone, loop, iff);
-          Node* c = unc_ctrl_clone;
-          Node* new_cast = clone_null_check(c, val, unc_ctrl_clone, phase);
-          r->init_req(1, new_cast->in(0)->in(0)->as_If()->proj_out(0));
-
-          phase->igvn().replace_input_of(unc_ctrl, 0, c->in(0));
-          phase->set_idom(unc_ctrl, c->in(0), phase->dom_depth(unc_ctrl));
-          phase->lazy_replace(c, unc_ctrl);
-          c = NULL;;
-          phase->igvn().replace_input_of(val, 0, unc_ctrl_clone);
-          phase->set_ctrl(val, unc_ctrl_clone);
-
-          IfNode* new_iff = new_cast->in(0)->in(0)->as_If();
-          fix_null_check(unc, unc_ctrl_clone, r, uses, phase);
-          Node* iff_proj = iff->proj_out(0);
-          r->init_req(2, iff_proj);
-          phase->register_control(r, phase->ltree_root(), iff);
-
-          Node* new_bol = new_iff->in(1)->clone();
-          Node* new_cmp = new_bol->in(1)->clone();
-          assert(new_cmp->Opcode() == Op_CmpP, "broken");
-          assert(new_cmp->in(1) == val->in(1), "broken");
-          new_bol->set_req(1, new_cmp);
-          new_cmp->set_req(1, lrb);
-          phase->register_new_node(new_bol, new_iff->in(0));
-          phase->register_new_node(new_cmp, new_iff->in(0));
-          phase->igvn().replace_input_of(new_iff, 1, new_bol);
-          phase->igvn().replace_input_of(new_cast, 1, lrb);
-
-          for (DUIterator_Fast imax, i = lrb->fast_outs(imax); i < imax; i++) {
-            Node* u = lrb->fast_out(i);
-            if (u == new_cast || u == new_cmp) {
-              continue;
-            }
-            phase->igvn().rehash_node_delayed(u);
-            int nb = u->replace_edge(lrb, new_cast);
-            assert(nb > 0, "no update?");
-            --i; imax -= nb;
-          }
-
-          for (DUIterator_Fast imax, i = val->fast_outs(imax); i < imax; i++) {
-            Node* u = val->fast_out(i);
-            if (u == lrb) {
-              continue;
-            }
-            phase->igvn().rehash_node_delayed(u);
-            int nb = u->replace_edge(val, new_cast);
-            assert(nb > 0, "no update?");
-            --i; imax -= nb;
-          }
-
-          ctrl = unc_ctrl_clone;
-          phase->set_ctrl_and_loop(lrb, ctrl);
+          Node* iff = u->in(0)->in(0);
+          Node* bol = iff->in(1)->clone();
+          Node* cmp = bol->in(1)->clone();
+          cmp->set_req(1, lrb);
+          bol->set_req(1, cmp);
+          phase->igvn().replace_input_of(iff, 1, bol);
+          phase->set_ctrl(lrb, iff->in(0));
+          phase->register_new_node(cmp, iff->in(0));
+          phase->register_new_node(bol, iff->in(0));
           break;
         }
       }
     }
     if ((ctrl->is_Proj() && ctrl->in(0)->is_CallJava()) || ctrl->is_CallJava()) {
@@ -1308,10 +1172,13 @@
           }
         } while(stack.size() > 0);
         continue;
       }
       CallProjections* projs = call->extract_projections(false, false);
+#ifdef ASSERT
+      VectorSet cloned(Thread::current()->resource_area());
+#endif
       Node* lrb_clone = lrb->clone();
       phase->register_new_node(lrb_clone, projs->catchall_catchproj);
       phase->set_ctrl(lrb, projs->fallthrough_catchproj);
 
       stack.push(lrb, 0);
@@ -1336,10 +1203,11 @@
           Node* c = phase->ctrl_or_self(u);
           if (phase->is_dominator(call, c) && phase->is_dominator(c, projs->fallthrough_proj)) {
             stack.set_index(idx+1);
             assert(!u->is_CFG(), "");
             stack.push(u, 0);
+            assert(!cloned.test_set(u->_idx), "only one clone");
             Node* u_clone = u->clone();
             int nb = u_clone->replace_edge(n, n_clone);
             assert(nb > 0, "should have replaced some uses");
             phase->register_new_node(u_clone, projs->catchall_catchproj);
             clones.push(u_clone);
@@ -1363,13 +1231,37 @@
                 phase->igvn().rehash_node_delayed(u);
                 int nb = u->replace_edge(n, n_clone);
                 assert(nb > 0, "should have replaced some uses");
                 replaced = true;
               } else if (!phase->is_dominator(projs->fallthrough_catchproj, c)) {
-                phase->igvn().rehash_node_delayed(u);
-                int nb = u->replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
-                assert(nb > 0, "should have replaced some uses");
+                if (u->is_If()) {
+                  // Can't break If/Bool/Cmp chain
+                  assert(n->is_Bool(), "unexpected If shape");
+                  assert(stack.node_at(stack.size()-2)->is_Cmp(), "unexpected If shape");
+                  assert(n_clone->is_Bool(), "unexpected clone");
+                  assert(clones.at(clones.size()-2)->is_Cmp(), "unexpected clone");
+                  Node* bol_clone = n->clone();
+                  Node* cmp_clone = stack.node_at(stack.size()-2)->clone();
+                  bol_clone->set_req(1, cmp_clone);
+
+                  Node* nn = stack.node_at(stack.size()-3);
+                  Node* nn_clone = clones.at(clones.size()-3);
+                  assert(nn->Opcode() == nn_clone->Opcode(), "mismatch");
+
+                  int nb = cmp_clone->replace_edge(nn, create_phis_on_call_return(ctrl, c, nn, nn_clone, projs, phase));
+                  assert(nb > 0, "should have replaced some uses");
+
+                  phase->register_new_node(bol_clone, u->in(0));
+                  phase->register_new_node(cmp_clone, u->in(0));
+
+                  phase->igvn().replace_input_of(u, 1, bol_clone);
+
+                } else {
+                  phase->igvn().rehash_node_delayed(u);
+                  int nb = u->replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
+                  assert(nb > 0, "should have replaced some uses");
+                }
                 replaced = true;
               }
             }
             if (!replaced) {
               stack.set_index(idx+1);
@@ -1419,86 +1311,47 @@
     Node* raw_mem = fixer.find_mem(ctrl, lrb);
     Node* init_raw_mem = raw_mem;
     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
 
     IdealLoopTree *loop = phase->get_loop(ctrl);
-    CallStaticJavaNode* unc = lrb->pin_and_expand_null_check(phase->igvn());
-    Node* unc_ctrl = NULL;
-    if (unc != NULL) {
-      if (val->in(ShenandoahLoadReferenceBarrierNode::Control) != ctrl) {
-        unc = NULL;
-      } else {
-        unc_ctrl = val->in(ShenandoahLoadReferenceBarrierNode::Control);
-      }
-    }
-
-    Node* uncasted_val = val;
-    if (unc != NULL) {
-      uncasted_val = val->in(1);
-    }
 
     Node* heap_stable_ctrl = NULL;
     Node* null_ctrl = NULL;
 
     assert(val->bottom_type()->make_oopptr(), "need oop");
     assert(val->bottom_type()->make_oopptr()->const_oop() == NULL, "expect non-constant");
 
-    enum { _heap_stable = 1, _not_cset, _evac_path, _null_path, PATH_LIMIT };
+    enum { _heap_stable = 1, _not_cset, _evac_path, PATH_LIMIT };
     Node* region = new RegionNode(PATH_LIMIT);
-    Node* val_phi = new PhiNode(region, uncasted_val->bottom_type()->is_oopptr());
+    Node* val_phi = new PhiNode(region, val->bottom_type()->is_oopptr());
     Node* raw_mem_phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
 
     // Stable path.
     test_gc_state(ctrl, raw_mem, heap_stable_ctrl, phase, ShenandoahHeap::HAS_FORWARDED);
     IfNode* heap_stable_iff = heap_stable_ctrl->in(0)->as_If();
 
     // Heap stable case
     region->init_req(_heap_stable, heap_stable_ctrl);
-    val_phi->init_req(_heap_stable, uncasted_val);
+    val_phi->init_req(_heap_stable, val);
     raw_mem_phi->init_req(_heap_stable, raw_mem);
 
-    Node* reg2_ctrl = NULL;
-    // Null case
-    test_null(ctrl, val, null_ctrl, phase);
-    if (null_ctrl != NULL) {
-      reg2_ctrl = null_ctrl->in(0);
-      region->init_req(_null_path, null_ctrl);
-      val_phi->init_req(_null_path, uncasted_val);
-      raw_mem_phi->init_req(_null_path, raw_mem);
-    } else {
-      region->del_req(_null_path);
-      val_phi->del_req(_null_path);
-      raw_mem_phi->del_req(_null_path);
-    }
-
     // Test for in-cset.
     // Wires !in_cset(obj) to slot 2 of region and phis
     Node* not_cset_ctrl = NULL;
-    test_in_cset(ctrl, not_cset_ctrl, uncasted_val, raw_mem, phase);
+    test_in_cset(ctrl, not_cset_ctrl, val, raw_mem, phase);
     if (not_cset_ctrl != NULL) {
-      if (reg2_ctrl == NULL) reg2_ctrl = not_cset_ctrl->in(0);
-      region->init_req(_not_cset, not_cset_ctrl);
+      region->init_req(_not_cset, not_cset_ctrl);
       val_phi->init_req(_not_cset, uncasted_val);
       raw_mem_phi->init_req(_not_cset, raw_mem);
     }
 
     // Resolve object when orig-value is in cset.
     // Make the unconditional resolve for fwdptr.
-    Node* new_val = uncasted_val;
-    if (unc_ctrl != NULL) {
-      // Clone the null check in this branch to allow implicit null check
-      new_val = clone_null_check(ctrl, val, unc_ctrl, phase);
-      fix_null_check(unc, unc_ctrl, ctrl->in(0)->as_If()->proj_out(0), uses, phase);
-
-      IfNode* iff = unc_ctrl->in(0)->as_If();
-      phase->igvn().replace_input_of(iff, 1, phase->igvn().intcon(1));
-    }
 
     // Call lrb-stub and wire up that path in slots 4
     Node* result_mem = NULL;
 
-    Node* fwd = new_val;
     Node* addr;
     if (ShenandoahSelfFixing) {
       VectorSet visited(Thread::current()->resource_area());
       addr = get_load_addr(phase, visited, lrb);
     } else {
@@ -1527,13 +1380,13 @@
           addr->set_req(AddPNode::Address, addr2);
           phase->register_new_node(addr, ctrl);
         }
       }
     }
-    call_lrb_stub(ctrl, fwd, addr, result_mem, raw_mem, lrb->is_native(), phase);
+    call_lrb_stub(ctrl, val, addr, result_mem, raw_mem, lrb->is_native(), phase);
     region->init_req(_evac_path, ctrl);
-    val_phi->init_req(_evac_path, fwd);
+    val_phi->init_req(_evac_path, val);
     raw_mem_phi->init_req(_evac_path, result_mem);
 
     phase->register_control(region, loop, heap_stable_iff);
     Node* out_val = val_phi;
     phase->register_new_node(val_phi, region);
@@ -1541,24 +1394,10 @@
 
     fix_ctrl(lrb, region, fixer, uses, uses_to_ignore, last, phase);
 
     ctrl = orig_ctrl;
 
-    if (unc != NULL) {
-      for (DUIterator_Fast imax, i = val->fast_outs(imax); i < imax; i++) {
-        Node* u = val->fast_out(i);
-        Node* c = phase->ctrl_or_self(u);
-        if (u != lrb && (c != ctrl || is_dominator_same_ctrl(c, lrb, u, phase))) {
-          phase->igvn().rehash_node_delayed(u);
-          int nb = u->replace_edge(val, out_val);
-          --i, imax -= nb;
-        }
-      }
-      if (val->outcnt() == 0) {
-        phase->igvn()._worklist.push(val);
-      }
-    }
     phase->igvn().replace_node(lrb, out_val);
 
     follow_barrier_uses(out_val, ctrl, uses, phase);
 
     for(uint next = 0; next < uses.size(); next++ ) {
@@ -1827,11 +1666,10 @@
     phase->register_new_node(cmp, entry_c);
     bol = bol->clone();
     bol->set_req(1, cmp);
     phase->register_new_node(bol, entry_c);
 
-    Node* old_bol =iff->in(1);
     phase->igvn().replace_input_of(iff, 1, bol);
   }
 }
 
 bool ShenandoahBarrierC2Support::identical_backtoback_ifs(Node* n, PhaseIdealLoop* phase) {
@@ -2284,21 +2122,11 @@
               Node* call = in->in(0)->in(0);
               assert(call->is_Call(), "");
               mem = call->in(TypeFunc::Memory);
             } else if (in->Opcode() == Op_NeverBranch) {
               Node* head = in->in(0);
-              assert(head->is_Region() && head->req() == 3, "unexpected infinite loop graph shape");
-              assert(_phase->is_dominator(head, head->in(1)) || _phase->is_dominator(head, head->in(2)), "no back branch?");
-              Node* tail = _phase->is_dominator(head, head->in(1)) ? head->in(1) : head->in(2);
-              Node* c = tail;
-              while (c != head) {
-                if (c->is_SafePoint() && !c->is_CallLeaf()) {
-                  mem = c->in(TypeFunc::Memory);
-                }
-                c = _phase->idom(c);
-              }
-              assert(mem != NULL, "should have found safepoint");
+              assert(head->is_Region(), "unexpected infinite loop graph shape");
 
               Node* phi_mem = NULL;
               for (DUIterator_Fast jmax, j = head->fast_outs(jmax); j < jmax; j++) {
                 Node* u = head->fast_out(j);
                 if (u->is_Phi() && u->bottom_type() == Type::MEMORY) {
@@ -2311,11 +2139,32 @@
                       phi_mem = u;
                     }
                   }
                 }
               }
-              if (phi_mem != NULL) {
+              if (phi_mem == NULL) {
+                for (uint j = 1; j < head->req(); j++) {
+                  Node* tail = head->in(j);
+                  if (!_phase->is_dominator(head, tail)) {
+                    continue;
+                  }
+                  Node* c = tail;
+                  while (c != head) {
+                    if (c->is_SafePoint() && !c->is_CallLeaf()) {
+                      Node* m =c->in(TypeFunc::Memory);
+                      if (m->is_MergeMem()) {
+                        m = m->as_MergeMem()->memory_at(_alias);
+                      }
+                      assert(mem == NULL || mem == m, "several memory states");
+                      mem = m;
+                    }
+                    c = _phase->idom(c);
+                  }
+                  assert(mem != NULL, "should have found safepoint");
+                }
+                assert(mem != NULL, "should have found safepoint");
+              } else {
                 mem = phi_mem;
               }
             }
           }
         } else {
@@ -2407,11 +2256,11 @@
   while (progress) {
     progress = false;
     iteration++;
     assert(iteration <= 2+max_depth || _phase->C->has_irreducible_loop() || has_never_branch(_phase->C->root()), "");
     if (trace) { tty->print_cr("XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"); }
-    IdealLoopTree* last_updated_ilt = NULL;
+
     for (int i = rpo_list.size() - 1; i >= 0; i--) {
       Node* c = rpo_list.at(i);
 
       Node* prev_mem = _memory_nodes[c->_idx];
       if (c->is_Region() && (_include_lsm || !c->is_OuterStripMinedLoop())) {
@@ -2420,11 +2269,11 @@
         for (uint j = 1; j < c->req() && unique != NodeSentinel; j++) {
           Node* m = _memory_nodes[c->in(j)->_idx];
           assert(m != NULL || (c->is_Loop() && j == LoopNode::LoopBackControl && iteration == 1) || _phase->C->has_irreducible_loop() || has_never_branch(_phase->C->root()), "expect memory state");
           if (m != NULL) {
             if (m == prev_region && ((c->is_Loop() && j == LoopNode::LoopBackControl) || (prev_region->is_Phi() && prev_region->in(0) == c))) {
-              assert(c->is_Loop() && j == LoopNode::LoopBackControl || _phase->C->has_irreducible_loop(), "");
+              assert(c->is_Loop() && j == LoopNode::LoopBackControl || _phase->C->has_irreducible_loop() || has_never_branch(_phase->C->root()), "");
               // continue
             } else if (unique == NULL) {
               unique = m;
             } else if (m == unique) {
               // continue
@@ -3322,28 +3171,5 @@
   }
 
   // No need for barrier found.
   return true;
 }
-
-CallStaticJavaNode* ShenandoahLoadReferenceBarrierNode::pin_and_expand_null_check(PhaseIterGVN& igvn) {
-  Node* val = in(ValueIn);
-
-  const Type* val_t = igvn.type(val);
-
-  if (val_t->meet(TypePtr::NULL_PTR) != val_t &&
-      val->Opcode() == Op_CastPP &&
-      val->in(0) != NULL &&
-      val->in(0)->Opcode() == Op_IfTrue &&
-      val->in(0)->as_Proj()->is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &&
-      val->in(0)->in(0)->is_If() &&
-      val->in(0)->in(0)->in(1)->Opcode() == Op_Bool &&
-      val->in(0)->in(0)->in(1)->as_Bool()->_test._test == BoolTest::ne &&
-      val->in(0)->in(0)->in(1)->in(1)->Opcode() == Op_CmpP &&
-      val->in(0)->in(0)->in(1)->in(1)->in(1) == val->in(1) &&
-      val->in(0)->in(0)->in(1)->in(1)->in(2)->bottom_type() == TypePtr::NULL_PTR) {
-    assert(val->in(0)->in(0)->in(1)->in(1)->in(1) == val->in(1), "");
-    CallStaticJavaNode* unc = val->in(0)->as_Proj()->is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
-    return unc;
-  }
-  return NULL;
-}
diff a/src/hotspot/share/interpreter/templateInterpreter.cpp b/src/hotspot/share/interpreter/templateInterpreter.cpp
--- a/src/hotspot/share/interpreter/templateInterpreter.cpp
+++ b/src/hotspot/share/interpreter/templateInterpreter.cpp
@@ -37,27 +37,31 @@
 
 #ifndef CC_INTERP
 
 # define __ _masm->
 
-void TemplateInterpreter::initialize() {
+void TemplateInterpreter::initialize_stub() {
   // assertions
   assert(_code == NULL, "must only initialize once");
   assert((int)Bytecodes::number_of_codes <= (int)DispatchTable::length,
          "dispatch table too small");
 
+  // allocate interpreter
+  int code_size = InterpreterCodeSize;
+  NOT_PRODUCT(code_size *= 4;)  // debug uses extra interpreter code space
+  _code = new StubQueue(new InterpreterCodeletInterface, code_size, NULL,
+                        "Interpreter");
+}
+
+void TemplateInterpreter::initialize_code() {
   AbstractInterpreter::initialize();
 
   TemplateTable::initialize();
 
   // generate interpreter
   { ResourceMark rm;
     TraceTime timer("Interpreter generation", TRACETIME_LOG(Info, startuptime));
-    int code_size = InterpreterCodeSize;
-    NOT_PRODUCT(code_size *= 4;)  // debug uses extra interpreter code space
-    _code = new StubQueue(new InterpreterCodeletInterface, code_size, NULL,
-                          "Interpreter");
     TemplateInterpreterGenerator g(_code);
     // Free the unused memory not occupied by the interpreter and the stubs
     _code->deallocate_unused_tail();
   }
 
diff a/src/hotspot/share/jvmci/jvmciCompilerToVM.cpp b/src/hotspot/share/jvmci/jvmciCompilerToVM.cpp
--- a/src/hotspot/share/jvmci/jvmciCompilerToVM.cpp
+++ b/src/hotspot/share/jvmci/jvmciCompilerToVM.cpp
@@ -30,10 +30,11 @@
 #include "compiler/compileBroker.hpp"
 #include "compiler/compilerEvent.hpp"
 #include "compiler/disassembler.hpp"
 #include "interpreter/linkResolver.hpp"
 #include "interpreter/bytecodeStream.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "jvmci/jvmciCompilerToVM.hpp"
 #include "jvmci/jvmciCodeInstaller.hpp"
 #include "jvmci/jvmciRuntime.hpp"
 #include "logging/log.hpp"
 #include "logging/logTag.hpp"
diff a/src/hotspot/share/memory/oopFactory.cpp b/src/hotspot/share/memory/oopFactory.cpp
--- a/src/hotspot/share/memory/oopFactory.cpp
+++ b/src/hotspot/share/memory/oopFactory.cpp
@@ -91,14 +91,10 @@
     UTF8::convert_to_unicode(utf8_str, result->char_at_addr(0), length);
   }
   return result;
 }
 
-typeArrayOop oopFactory::new_tenured_charArray(int length, TRAPS) {
-  return TypeArrayKlass::cast(Universe::charArrayKlassObj())->allocate(length, THREAD);
-}
-
 typeArrayOop oopFactory::new_typeArray(BasicType type, int length, TRAPS) {
   Klass* type_asKlassOop = Universe::typeArrayKlassObj(type);
   TypeArrayKlass* type_asArrayKlass = TypeArrayKlass::cast(type_asKlassOop);
   typeArrayOop result = type_asArrayKlass->allocate(length, THREAD);
   return result;
@@ -168,10 +164,5 @@
 
 objArrayHandle oopFactory::new_objArray_handle(Klass* klass, int length, TRAPS) {
   objArrayOop obj = new_objArray(klass, length, CHECK_(objArrayHandle()));
   return objArrayHandle(THREAD, obj);
 }
-
-typeArrayHandle oopFactory::new_byteArray_handle(int length, TRAPS) {
-  typeArrayOop obj = new_byteArray(length, CHECK_(typeArrayHandle()));
-  return typeArrayHandle(THREAD, obj);
-}
diff a/src/hotspot/share/memory/oopFactory.hpp b/src/hotspot/share/memory/oopFactory.hpp
--- a/src/hotspot/share/memory/oopFactory.hpp
+++ b/src/hotspot/share/memory/oopFactory.hpp
@@ -46,11 +46,10 @@
 
   // create java.lang.Object[]
   static objArrayOop     new_objectArray(int length, TRAPS);
 
   static typeArrayOop    new_charArray(const char* utf8_str,  TRAPS);
-  static typeArrayOop    new_tenured_charArray(int length, TRAPS);
 
   static typeArrayOop    new_typeArray(BasicType type, int length, TRAPS);
   static typeArrayOop    new_typeArray_nozero(BasicType type, int length, TRAPS);
   static typeArrayOop    new_symbolArray(int length, TRAPS);
 
@@ -68,11 +67,10 @@
 
   // Helper conversions from value to obj array...
   static objArrayHandle  copy_valueArray_to_objArray(valueArrayHandle array, TRAPS);
   static objArrayHandle  ensure_objArray(oop array, TRAPS); // copy into new objArray if not already an objArray
 
-  // Helpers that return handles
+  // Helper that returns a Handle
   static objArrayHandle  new_objArray_handle(Klass* klass, int length, TRAPS);
-  static typeArrayHandle new_byteArray_handle(int length, TRAPS);
 };
 
 #endif // SHARE_MEMORY_OOPFACTORY_HPP
diff a/src/hotspot/share/memory/universe.cpp b/src/hotspot/share/memory/universe.cpp
--- a/src/hotspot/share/memory/universe.cpp
+++ b/src/hotspot/share/memory/universe.cpp
@@ -205,10 +205,11 @@
   f->do_oop((oop*)&_main_thread_group);
   f->do_oop((oop*)&_system_thread_group);
   f->do_oop((oop*)&_vm_exception);
   f->do_oop((oop*)&_reference_pending_list);
   debug_only(f->do_oop((oop*)&_fullgc_alot_dummy_array);)
+  ThreadsSMRSupport::exiting_threads_oops_do(f);
 }
 
 void LatestMethodCache::metaspace_pointers_do(MetaspaceClosure* it) {
   it->push(&_klass);
 }
@@ -666,12 +667,10 @@
   guarantee(sizeof(oop) % sizeof(HeapWord) == 0,
             "oop size is not not a multiple of HeapWord size");
 
   TraceTime timer("Genesis", TRACETIME_LOG(Info, startuptime));
 
-  JavaClasses::compute_hard_coded_offsets();
-
   initialize_global_behaviours();
 
   GCConfig::arguments()->initialize_heap_sizes();
 
   jint status = Universe::initialize_heap();
diff a/src/hotspot/share/oops/access.hpp b/src/hotspot/share/oops/access.hpp
--- a/src/hotspot/share/oops/access.hpp
+++ b/src/hotspot/share/oops/access.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2017, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2017, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -128,12 +128,12 @@
   static void verify_heap_value_decorators() {
     const DecoratorSet heap_value_decorators = IN_HEAP | IS_DEST_UNINITIALIZED;
     verify_decorators<expected_mo_decorators | heap_value_decorators>();
   }
 
-  static const DecoratorSet load_mo_decorators = MO_UNORDERED | MO_VOLATILE | MO_RELAXED | MO_ACQUIRE | MO_SEQ_CST;
-  static const DecoratorSet store_mo_decorators = MO_UNORDERED | MO_VOLATILE | MO_RELAXED | MO_RELEASE | MO_SEQ_CST;
+  static const DecoratorSet load_mo_decorators = MO_UNORDERED | MO_RELAXED | MO_ACQUIRE | MO_SEQ_CST;
+  static const DecoratorSet store_mo_decorators = MO_UNORDERED | MO_RELAXED | MO_RELEASE | MO_SEQ_CST;
   static const DecoratorSet atomic_xchg_mo_decorators = MO_SEQ_CST;
   static const DecoratorSet atomic_cmpxchg_mo_decorators = MO_RELAXED | MO_SEQ_CST;
 
 protected:
   template <typename T>
@@ -373,11 +373,10 @@
     (ref_strength_decorators ^ ON_UNKNOWN_OOP_REF) == 0
   ));
   const DecoratorSet memory_ordering_decorators = decorators & MO_DECORATOR_MASK;
   STATIC_ASSERT(memory_ordering_decorators == 0 || ( // make sure memory ordering decorators are disjoint if set
     (memory_ordering_decorators ^ MO_UNORDERED) == 0 ||
-    (memory_ordering_decorators ^ MO_VOLATILE) == 0 ||
     (memory_ordering_decorators ^ MO_RELAXED) == 0 ||
     (memory_ordering_decorators ^ MO_ACQUIRE) == 0 ||
     (memory_ordering_decorators ^ MO_RELEASE) == 0 ||
     (memory_ordering_decorators ^ MO_SEQ_CST) == 0
   ));
diff a/src/hotspot/share/oops/accessBackend.hpp b/src/hotspot/share/oops/accessBackend.hpp
--- a/src/hotspot/share/oops/accessBackend.hpp
+++ b/src/hotspot/share/oops/accessBackend.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2017, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2017, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -256,17 +256,10 @@
   template <DecoratorSet ds, typename T>
   static typename EnableIf<
     HasDecorator<ds, MO_RELAXED>::value, T>::type
   load_internal(void* addr);
 
-  template <DecoratorSet ds, typename T>
-  static inline typename EnableIf<
-    HasDecorator<ds, MO_VOLATILE>::value, T>::type
-  load_internal(void* addr) {
-    return *reinterpret_cast<const volatile T*>(addr);
-  }
-
   template <DecoratorSet ds, typename T>
   static inline typename EnableIf<
     HasDecorator<ds, MO_UNORDERED>::value, T>::type
   load_internal(void* addr) {
     return *reinterpret_cast<T*>(addr);
@@ -285,17 +278,10 @@
   template <DecoratorSet ds, typename T>
   static typename EnableIf<
     HasDecorator<ds, MO_RELAXED>::value>::type
   store_internal(void* addr, T value);
 
-  template <DecoratorSet ds, typename T>
-  static inline typename EnableIf<
-    HasDecorator<ds, MO_VOLATILE>::value>::type
-  store_internal(void* addr, T value) {
-    (void)const_cast<T&>(*reinterpret_cast<volatile T*>(addr) = value);
-  }
-
   template <DecoratorSet ds, typename T>
   static inline typename EnableIf<
     HasDecorator<ds, MO_UNORDERED>::value>::type
   store_internal(void* addr, T value) {
     *reinterpret_cast<T*>(addr) = value;
@@ -1163,11 +1149,11 @@
                                                        dst_obj, dst_offset_in_bytes, dst_raw,
                                                        length);
   }
 
   // Step 1: Set default decorators. This step remembers if a type was volatile
-  // and then sets the MO_VOLATILE decorator by default. Otherwise, a default
+  // and then sets the MO_RELAXED decorator by default. Otherwise, a default
   // memory ordering is set for the access, and the implied decorator rules
   // are applied to select sensible defaults for decorators that have not been
   // explicitly set. For example, default object referent strength is set to strong.
   // This step also decays the types passed in (e.g. getting rid of CV qualifiers
   // and references from the types). This step also perform some type verification
@@ -1187,14 +1173,14 @@
     verify_types<decorators, T>();
     typedef typename Decay<P>::type DecayedP;
     typedef typename Decay<T>::type DecayedT;
     DecayedT decayed_value = value;
     // If a volatile address is passed in but no memory ordering decorator,
-    // set the memory ordering to MO_VOLATILE by default.
+    // set the memory ordering to MO_RELAXED by default.
     const DecoratorSet expanded_decorators = DecoratorFixup<
       (IsVolatile<P>::value && !HasDecorator<decorators, MO_DECORATOR_MASK>::value) ?
-      (MO_VOLATILE | decorators) : decorators>::value;
+      (MO_RELAXED | decorators) : decorators>::value;
     store_reduce_types<expanded_decorators>(const_cast<DecayedP*>(addr), decayed_value);
   }
 
   template <DecoratorSet decorators, typename T>
   inline void store_at(oop base, ptrdiff_t offset, T value) {
@@ -1213,14 +1199,14 @@
     typedef typename Decay<P>::type DecayedP;
     typedef typename Conditional<HasDecorator<decorators, INTERNAL_VALUE_IS_OOP>::value,
                                  typename OopOrNarrowOop<T>::type,
                                  typename Decay<T>::type>::type DecayedT;
     // If a volatile address is passed in but no memory ordering decorator,
-    // set the memory ordering to MO_VOLATILE by default.
+    // set the memory ordering to MO_RELAXED by default.
     const DecoratorSet expanded_decorators = DecoratorFixup<
       (IsVolatile<P>::value && !HasDecorator<decorators, MO_DECORATOR_MASK>::value) ?
-      (MO_VOLATILE | decorators) : decorators>::value;
+      (MO_RELAXED | decorators) : decorators>::value;
     return load_reduce_types<expanded_decorators, DecayedT>(const_cast<DecayedP*>(addr));
   }
 
   template <DecoratorSet decorators, typename T>
   inline T load_at(oop base, ptrdiff_t offset) {
diff a/src/hotspot/share/oops/accessDecorators.hpp b/src/hotspot/share/oops/accessDecorators.hpp
--- a/src/hotspot/share/oops/accessDecorators.hpp
+++ b/src/hotspot/share/oops/accessDecorators.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -76,25 +76,24 @@
 // Explicitly specifying the stronger ordering implies that the guarantees of the weaker
 // property holds too. The names come from the C++11 atomic operations, and typically
 // have a JMM equivalent property.
 // The equivalence may be viewed like this:
 // MO_UNORDERED is equivalent to JMM plain.
-// MO_VOLATILE has no equivalence in JMM, because it's a C++ thing.
 // MO_RELAXED is equivalent to JMM opaque.
 // MO_ACQUIRE is equivalent to JMM acquire.
 // MO_RELEASE is equivalent to JMM release.
 // MO_SEQ_CST is equivalent to JMM volatile.
 //
 // === Stores ===
 //  * MO_UNORDERED (Default): No guarantees.
 //    - The compiler and hardware are free to reorder aggressively. And they will.
-//  * MO_VOLATILE: Volatile stores (in the C++ sense).
-//    - The stores are not reordered by the compiler (but possibly the HW) w.r.t. other
-//      volatile accesses in program order (but possibly non-volatile accesses).
 //  * MO_RELAXED: Relaxed atomic stores.
 //    - The stores are atomic.
-//    - Guarantees from volatile stores hold.
+//    - The stores are not reordered by the compiler (but possibly the HW) w.r.t
+//      other ordered accesses in program order.
+//    - Also used for C++ volatile stores, since actual usage of volatile
+//      requires no word tearing.
 //  * MO_RELEASE: Releasing stores.
 //    - The releasing store will make its preceding memory accesses observable to memory accesses
 //      subsequent to an acquiring load observing this releasing store.
 //    - Guarantees from relaxed stores hold.
 //  * MO_SEQ_CST: Sequentially consistent stores.
@@ -102,16 +101,16 @@
 //    - Preceding loads and stores in program order are not reordered with subsequent loads and stores in program order.
 //    - Guarantees from releasing stores hold.
 // === Loads ===
 //  * MO_UNORDERED (Default): No guarantees
 //    - The compiler and hardware are free to reorder aggressively. And they will.
-//  * MO_VOLATILE: Volatile loads (in the C++ sense).
-//    - The loads are not reordered by the compiler (but possibly the HW) w.r.t. other
-//      volatile accesses in program order (but possibly non-volatile accesses).
 //  * MO_RELAXED: Relaxed atomic loads.
 //    - The loads are atomic.
-//    - Guarantees from volatile loads hold.
+//    - The loads are not reordered by the compiler (but possibly the HW) w.r.t.
+//      other ordered accesses in program order.
+//    - Also used for C++ volatile loads, since actual usage of volatile
+//      requires no word tearing.
 //  * MO_ACQUIRE: Acquiring loads.
 //    - An acquiring load will make subsequent memory accesses observe the memory accesses
 //      preceding the releasing store that the acquiring load observed.
 //    - Guarantees from relaxed loads hold.
 //  * MO_SEQ_CST: Sequentially consistent loads.
@@ -127,16 +126,15 @@
 //  * MO_RELAXED: Atomic but relaxed atomic xchg.
 //    - Guarantees from MO_RELAXED loads and MO_RELAXED stores hold.
 //  * MO_SEQ_CST: Sequentially consistent xchg.
 //    - Guarantees from MO_SEQ_CST loads and MO_SEQ_CST stores hold.
 const DecoratorSet MO_UNORDERED      = UCONST64(1) << 6;
-const DecoratorSet MO_VOLATILE       = UCONST64(1) << 7;
-const DecoratorSet MO_RELAXED        = UCONST64(1) << 8;
-const DecoratorSet MO_ACQUIRE        = UCONST64(1) << 9;
-const DecoratorSet MO_RELEASE        = UCONST64(1) << 10;
-const DecoratorSet MO_SEQ_CST        = UCONST64(1) << 11;
-const DecoratorSet MO_DECORATOR_MASK = MO_UNORDERED | MO_VOLATILE | MO_RELAXED |
+const DecoratorSet MO_RELAXED        = UCONST64(1) << 7;
+const DecoratorSet MO_ACQUIRE        = UCONST64(1) << 8;
+const DecoratorSet MO_RELEASE        = UCONST64(1) << 9;
+const DecoratorSet MO_SEQ_CST        = UCONST64(1) << 10;
+const DecoratorSet MO_DECORATOR_MASK = MO_UNORDERED | MO_RELAXED |
                                        MO_ACQUIRE | MO_RELEASE | MO_SEQ_CST;
 
 // === Barrier Strength Decorators ===
 // * AS_RAW: The access will translate into a raw memory access, hence ignoring all semantic concerns
 //   except memory ordering and compressed oops. This will bypass runtime function pointer dispatching
@@ -152,13 +150,13 @@
 //   extreme caution in isolated scopes.
 // * AS_NORMAL: The accesses will be resolved to an accessor on the BarrierSet class, giving the
 //   responsibility of performing the access and what barriers to be performed to the GC. This is the default.
 //   Note that primitive accesses will only be resolved on the barrier set if the appropriate build-time
 //   decorator for enabling primitive barriers is enabled for the build.
-const DecoratorSet AS_RAW                  = UCONST64(1) << 12;
-const DecoratorSet AS_NO_KEEPALIVE         = UCONST64(1) << 13;
-const DecoratorSet AS_NORMAL               = UCONST64(1) << 14;
+const DecoratorSet AS_RAW                  = UCONST64(1) << 11;
+const DecoratorSet AS_NO_KEEPALIVE         = UCONST64(1) << 12;
+const DecoratorSet AS_NORMAL               = UCONST64(1) << 13;
 const DecoratorSet AS_DECORATOR_MASK       = AS_RAW | AS_NO_KEEPALIVE | AS_NORMAL;
 
 // === Reference Strength Decorators ===
 // These decorators only apply to accesses on oop-like types (oop/narrowOop).
 // * ON_STRONG_OOP_REF: Memory access is performed on a strongly reachable reference.
@@ -166,36 +164,36 @@
 // * ON_PHANTOM_OOP_REF: The memory access is performed on a phantomly reachable reference.
 //   This is the same ring of strength as jweak and weak oops in the VM.
 // * ON_UNKNOWN_OOP_REF: The memory access is performed on a reference of unknown strength.
 //   This could for example come from the unsafe API.
 // * Default (no explicit reference strength specified): ON_STRONG_OOP_REF
-const DecoratorSet ON_STRONG_OOP_REF  = UCONST64(1) << 15;
-const DecoratorSet ON_WEAK_OOP_REF    = UCONST64(1) << 16;
-const DecoratorSet ON_PHANTOM_OOP_REF = UCONST64(1) << 17;
-const DecoratorSet ON_UNKNOWN_OOP_REF = UCONST64(1) << 18;
+const DecoratorSet ON_STRONG_OOP_REF  = UCONST64(1) << 14;
+const DecoratorSet ON_WEAK_OOP_REF    = UCONST64(1) << 15;
+const DecoratorSet ON_PHANTOM_OOP_REF = UCONST64(1) << 16;
+const DecoratorSet ON_UNKNOWN_OOP_REF = UCONST64(1) << 17;
 const DecoratorSet ON_DECORATOR_MASK  = ON_STRONG_OOP_REF | ON_WEAK_OOP_REF |
                                         ON_PHANTOM_OOP_REF | ON_UNKNOWN_OOP_REF;
 
 // === Access Location ===
 // Accesses can take place in, e.g. the heap, old or young generation, different native roots, or native memory off the heap.
 // The location is important to the GC as it may imply different actions. The following decorators are used:
 // * IN_HEAP: The access is performed in the heap. Many barriers such as card marking will
 //   be omitted if this decorator is not set.
 // * IN_NATIVE: The access is performed in an off-heap data structure.
-const DecoratorSet IN_HEAP            = UCONST64(1) << 19;
-const DecoratorSet IN_NATIVE          = UCONST64(1) << 20;
+const DecoratorSet IN_HEAP            = UCONST64(1) << 18;
+const DecoratorSet IN_NATIVE          = UCONST64(1) << 19;
 const DecoratorSet IN_DECORATOR_MASK  = IN_HEAP | IN_NATIVE;
 
 // == Boolean Flag Decorators ==
 // * IS_ARRAY: The access is performed on a heap allocated array. This is sometimes a special case
 //   for some GCs.
 // * IS_DEST_UNINITIALIZED: This property can be important to e.g. SATB barriers by
 //   marking that the previous value is uninitialized nonsense rather than a real value.
 // * IS_NOT_NULL: This property can make certain barriers faster such as compressing oops.
-const DecoratorSet IS_ARRAY              = UCONST64(1) << 21;
-const DecoratorSet IS_DEST_UNINITIALIZED = UCONST64(1) << 22;
-const DecoratorSet IS_NOT_NULL           = UCONST64(1) << 23;
+const DecoratorSet IS_ARRAY              = UCONST64(1) << 20;
+const DecoratorSet IS_DEST_UNINITIALIZED = UCONST64(1) << 21;
+const DecoratorSet IS_NOT_NULL           = UCONST64(1) << 22;
 
 // == Arraycopy Decorators ==
 // * ARRAYCOPY_CHECKCAST: This property means that the class of the objects in source
 //   are not guaranteed to be subclasses of the class of the destination array. This requires
 //   a check-cast barrier during the copying operation. If this is not set, it is assumed
@@ -205,30 +203,29 @@
 // * ARRAYCOPY_DISJOINT: This property means that it is known that the two array ranges
 //   are disjoint.
 // * ARRAYCOPY_ARRAYOF: The copy is in the arrayof form.
 // * ARRAYCOPY_ATOMIC: The accesses have to be atomic over the size of its elements.
 // * ARRAYCOPY_ALIGNED: The accesses have to be aligned on a HeapWord.
-const DecoratorSet ARRAYCOPY_CHECKCAST            = UCONST64(1) << 24;
-const DecoratorSet ARRAYCOPY_NOTNULL              = UCONST64(1) << 25;
-const DecoratorSet ARRAYCOPY_DISJOINT             = UCONST64(1) << 26;
-const DecoratorSet ARRAYCOPY_ARRAYOF              = UCONST64(1) << 27;
-const DecoratorSet ARRAYCOPY_ATOMIC               = UCONST64(1) << 28;
-const DecoratorSet ARRAYCOPY_ALIGNED              = UCONST64(1) << 29;
+const DecoratorSet ARRAYCOPY_CHECKCAST            = UCONST64(1) << 23;
+const DecoratorSet ARRAYCOPY_NOTNULL              = UCONST64(1) << 24;
+const DecoratorSet ARRAYCOPY_DISJOINT             = UCONST64(1) << 25;
+const DecoratorSet ARRAYCOPY_ARRAYOF              = UCONST64(1) << 26;
+const DecoratorSet ARRAYCOPY_ATOMIC               = UCONST64(1) << 27;
+const DecoratorSet ARRAYCOPY_ALIGNED              = UCONST64(1) << 28;
 const DecoratorSet ARRAYCOPY_DECORATOR_MASK       = ARRAYCOPY_CHECKCAST | ARRAYCOPY_NOTNULL |
-                                                    ARRAYCOPY_DISJOINT | ARRAYCOPY_DISJOINT |
-                                                    ARRAYCOPY_ARRAYOF | ARRAYCOPY_ATOMIC |
-                                                    ARRAYCOPY_ALIGNED;
+                                                    ARRAYCOPY_DISJOINT | ARRAYCOPY_ARRAYOF |
+                                                    ARRAYCOPY_ATOMIC | ARRAYCOPY_ALIGNED;
 
 // == Resolve barrier decorators ==
 // * ACCESS_READ: Indicate that the resolved object is accessed read-only. This allows the GC
 //   backend to use weaker and more efficient barriers.
 // * ACCESS_WRITE: Indicate that the resolved object is used for write access.
-const DecoratorSet ACCESS_READ                    = UCONST64(1) << 30;
-const DecoratorSet ACCESS_WRITE                   = UCONST64(1) << 31;
+const DecoratorSet ACCESS_READ                    = UCONST64(1) << 29;
+const DecoratorSet ACCESS_WRITE                   = UCONST64(1) << 30;
 
 // Keep track of the last decorator.
-const DecoratorSet DECORATOR_LAST = UCONST64(1) << 31;
+const DecoratorSet DECORATOR_LAST = UCONST64(1) << 30;
 
 namespace AccessInternal {
   // This class adds implied decorators that follow according to decorator rules.
   // For example adding default reference strength and default memory ordering
   // semantics.
diff a/src/hotspot/share/oops/method.cpp b/src/hotspot/share/oops/method.cpp
--- a/src/hotspot/share/oops/method.cpp
+++ b/src/hotspot/share/oops/method.cpp
@@ -1222,20 +1222,16 @@
 // is ready to be called from interpreter, compiler, and vtables.
 void Method::link_method(const methodHandle& h_method, TRAPS) {
   // If the code cache is full, we may reenter this function for the
   // leftover methods that weren't linked.
   if (is_shared()) {
-#ifdef ASSERT
-    address entry = Interpreter::entry_for_cds_method(h_method);
-    assert(entry != NULL && entry == _i2i_entry,
-           "should be correctly set during dump time");
-#endif
+    // Can't assert that the adapters are sane, because methods get linked before
+    // the interpreter is generated, and hence before its adapters are generated.
+    // If you messed them up you will notice soon enough though, don't you worry.
     if (adapter() != NULL) {
       return;
     }
-    assert(entry == _from_interpreted_entry,
-           "should be correctly set during dump time");
   } else if (_i2i_entry != NULL) {
     return;
   }
   assert( _code == NULL, "nothing compiled yet" );
 
diff a/src/hotspot/share/oops/oop.hpp b/src/hotspot/share/oops/oop.hpp
--- a/src/hotspot/share/oops/oop.hpp
+++ b/src/hotspot/share/oops/oop.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -72,12 +72,12 @@
  public:
   inline markWord  mark()          const;
   inline markWord  mark_raw()      const;
   inline markWord* mark_addr_raw() const;
 
-  inline void set_mark(volatile markWord m);
-  inline void set_mark_raw(volatile markWord m);
+  inline void set_mark(markWord m);
+  inline void set_mark_raw(markWord m);
   static inline void set_mark_raw(HeapWord* mem, markWord m);
 
   inline void release_set_mark(markWord m);
   inline markWord cas_set_mark(markWord new_mark, markWord old_mark);
   inline markWord cas_set_mark_raw(markWord new_mark, markWord old_mark, atomic_memory_order order = memory_order_conservative);
diff a/src/hotspot/share/oops/oop.inline.hpp b/src/hotspot/share/oops/oop.inline.hpp
--- a/src/hotspot/share/oops/oop.inline.hpp
+++ b/src/hotspot/share/oops/oop.inline.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -41,11 +41,11 @@
 
 // Implementation of all inlined member functions defined in oop.hpp
 // We need a separate file to avoid circular references
 
 markWord oopDesc::mark() const {
-  uintptr_t v = HeapAccess<MO_VOLATILE>::load_at(as_oop(), mark_offset_in_bytes());
+  uintptr_t v = HeapAccess<MO_RELAXED>::load_at(as_oop(), mark_offset_in_bytes());
   return markWord(v);
 }
 
 markWord oopDesc::mark_raw() const {
   return Atomic::load(&_mark);
@@ -54,11 +54,11 @@
 markWord* oopDesc::mark_addr_raw() const {
   return (markWord*) &_mark;
 }
 
 void oopDesc::set_mark(markWord m) {
-  HeapAccess<MO_VOLATILE>::store_at(as_oop(), mark_offset_in_bytes(), m.value());
+  HeapAccess<MO_RELAXED>::store_at(as_oop(), mark_offset_in_bytes(), m.value());
 }
 
 void oopDesc::set_mark_raw(markWord m) {
   Atomic::store(&_mark, m);
 }
diff a/src/hotspot/share/opto/bytecodeInfo.cpp b/src/hotspot/share/opto/bytecodeInfo.cpp
--- a/src/hotspot/share/opto/bytecodeInfo.cpp
+++ b/src/hotspot/share/opto/bytecodeInfo.cpp
@@ -28,10 +28,11 @@
 #include "classfile/vmSymbols.hpp"
 #include "compiler/compileBroker.hpp"
 #include "compiler/compilerEvent.hpp"
 #include "compiler/compileLog.hpp"
 #include "interpreter/linkResolver.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "opto/callGenerator.hpp"
 #include "opto/parse.hpp"
 #include "runtime/handles.inline.hpp"
 #include "utilities/events.hpp"
diff a/src/hotspot/share/opto/c2_globals.hpp b/src/hotspot/share/opto/c2_globals.hpp
--- a/src/hotspot/share/opto/c2_globals.hpp
+++ b/src/hotspot/share/opto/c2_globals.hpp
@@ -495,11 +495,12 @@
                                                                             \
   notproduct(bool, PrintLockStatistics, false,                              \
           "Print precise statistics on the dynamic lock usage")             \
                                                                             \
   diagnostic(bool, PrintPreciseBiasedLockingStatistics, false,              \
-          "Print per-lock-site statistics of biased locking in JVM")        \
+          "(Deprecated) Print per-lock-site statistics of biased locking "  \
+          "in JVM")                                                         \
                                                                             \
   diagnostic(bool, PrintPreciseRTMLockingStatistics, false,                 \
           "Print per-lock-site statistics of rtm locking in JVM")           \
                                                                             \
   notproduct(bool, PrintEliminateLocks, false,                              \
@@ -549,11 +550,11 @@
                                                                             \
   notproduct(bool, VerifyConnectionGraph , true,                            \
           "Verify Connection Graph construction in Escape Analysis")        \
                                                                             \
   product(bool, UseOptoBiasInlining, true,                                  \
-          "Generate biased locking code in C2 ideal graph")                 \
+          "(Deprecated) Generate biased locking code in C2 ideal graph")    \
                                                                             \
   product(bool, OptimizeStringConcat, true,                                 \
           "Optimize the construction of Strings by StringBuilder")          \
                                                                             \
   notproduct(bool, PrintOptimizeStringConcat, false,                        \
@@ -682,10 +683,39 @@
           constraint(AliasLevelConstraintFunc,AfterErgo)                    \
                                                                             \
   develop(bool, VerifyAliases, false,                                       \
           "perform extra checks on the results of alias analysis")          \
                                                                             \
+  product(intx, MaxInlineLevel, 15,                                         \
+          "maximum number of nested calls that are inlined by high tier "   \
+          "compiler")                                                       \
+          range(0, max_jint)                                                \
+                                                                            \
+  product(intx, MaxRecursiveInlineLevel, 1,                                 \
+          "maximum number of nested recursive calls that are inlined by "   \
+          "high tier compiler")                                             \
+          range(0, max_jint)                                                \
+                                                                            \
+  product_pd(intx, InlineSmallCode,                                         \
+          "Only inline already compiled methods if their code size is "     \
+          "less than this")                                                 \
+          range(0, max_jint)                                                \
+                                                                            \
+  product(intx, MaxInlineSize, 35,                                          \
+          "The maximum bytecode size of a method to be inlined by high "    \
+          "tier compiler")                                                  \
+          range(0, max_jint)                                                \
+                                                                            \
+  product_pd(intx, FreqInlineSize,                                          \
+          "The maximum bytecode size of a frequent method to be inlined")   \
+          range(0, max_jint)                                                \
+                                                                            \
+  product(intx, MaxTrivialSize, 6,                                          \
+          "The maximum bytecode size of a trivial method to be inlined by " \
+          "high tier compiler")                                             \
+          range(0, max_jint)                                                \
+                                                                            \
   product(bool, IncrementalInline, true,                                    \
           "do post parse inlining")                                         \
                                                                             \
   develop(bool, AlwaysIncrementalInline, false,                             \
           "do all inlining incrementally")                                  \
diff a/src/hotspot/share/opto/compile.cpp b/src/hotspot/share/opto/compile.cpp
--- a/src/hotspot/share/opto/compile.cpp
+++ b/src/hotspot/share/opto/compile.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -33,10 +33,11 @@
 #include "compiler/compileLog.hpp"
 #include "compiler/disassembler.hpp"
 #include "compiler/oopMap.hpp"
 #include "gc/shared/barrierSet.hpp"
 #include "gc/shared/c2/barrierSetC2.hpp"
+#include "jfr/jfrEvents.hpp"
 #include "memory/resourceArea.hpp"
 #include "opto/addnode.hpp"
 #include "opto/block.hpp"
 #include "opto/c2compiler.hpp"
 #include "opto/callGenerator.hpp"
@@ -4996,10 +4997,43 @@
       allocates++;
     }
   }
 }
 
+void Compile::print_method(CompilerPhaseType cpt, int level, int idx) {
+  EventCompilerPhase event;
+  if (event.should_commit()) {
+    CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, cpt, C->_compile_id, level);
+  }
+
+#ifndef PRODUCT
+  if (should_print(level)) {
+    char output[1024];
+    if (idx != 0) {
+      jio_snprintf(output, sizeof(output), "%s:%d", CompilerPhaseTypeHelper::to_string(cpt), idx);
+    } else {
+      jio_snprintf(output, sizeof(output), "%s", CompilerPhaseTypeHelper::to_string(cpt));
+    }
+    _printer->print_method(output, level);
+  }
+#endif
+  C->_latest_stage_start_counter.stamp();
+}
+
+void Compile::end_method(int level) {
+  EventCompilerPhase event;
+  if (event.should_commit()) {
+    CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, PHASE_END, C->_compile_id, level);
+  }
+
+#ifndef PRODUCT
+  if (_printer && _printer->should_print(level)) {
+    _printer->end_method();
+  }
+#endif
+}
+
 
 #ifndef PRODUCT
 IdealGraphPrinter* Compile::_debug_file_printer = NULL;
 IdealGraphPrinter* Compile::_debug_network_printer = NULL;
 
diff a/src/hotspot/share/opto/compile.hpp b/src/hotspot/share/opto/compile.hpp
--- a/src/hotspot/share/opto/compile.hpp
+++ b/src/hotspot/share/opto/compile.hpp
@@ -641,49 +641,20 @@
 #else
     return false;
 #endif
   }
 
-  void print_method(CompilerPhaseType cpt, int level = 1, int idx = 0) {
-    EventCompilerPhase event;
-    if (event.should_commit()) {
-      CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, cpt, C->_compile_id, level);
-    }
-
-#ifndef PRODUCT
-    if (should_print(level)) {
-      char output[1024];
-      if (idx != 0) {
-        jio_snprintf(output, sizeof(output), "%s:%d", CompilerPhaseTypeHelper::to_string(cpt), idx);
-      } else {
-        jio_snprintf(output, sizeof(output), "%s", CompilerPhaseTypeHelper::to_string(cpt));
-      }
-      _printer->print_method(output, level);
-    }
-#endif
-    C->_latest_stage_start_counter.stamp();
-  }
+  void print_method(CompilerPhaseType cpt, int level = 1, int idx = 0);
 
 #ifndef PRODUCT
   void igv_print_method_to_file(const char* phase_name = "Debug", bool append = false);
   void igv_print_method_to_network(const char* phase_name = "Debug");
   static IdealGraphPrinter* debug_file_printer() { return _debug_file_printer; }
   static IdealGraphPrinter* debug_network_printer() { return _debug_network_printer; }
 #endif
 
-  void end_method(int level = 1) {
-    EventCompilerPhase event;
-    if (event.should_commit()) {
-      CompilerEvent::PhaseEvent::post(event, C->_latest_stage_start_counter, PHASE_END, C->_compile_id, level);
-    }
-
-#ifndef PRODUCT
-    if (_printer && _printer->should_print(level)) {
-      _printer->end_method();
-    }
-#endif
-  }
+  void end_method(int level = 1);
 
   int           macro_count()             const { return _macro_nodes->length(); }
   int           predicate_count()         const { return _predicate_opaqs->length();}
   int           expensive_count()         const { return _expensive_nodes->length(); }
   Node*         macro_node(int idx)       const { return _macro_nodes->at(idx); }
diff a/src/hotspot/share/prims/whitebox.cpp b/src/hotspot/share/prims/whitebox.cpp
--- a/src/hotspot/share/prims/whitebox.cpp
+++ b/src/hotspot/share/prims/whitebox.cpp
@@ -2314,10 +2314,64 @@
   Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve(mirror));
   // Return size in bytes.
   return k->size() * wordSize;
 WB_END
 
+// See test/hotspot/jtreg/runtime/Thread/ThreadObjAccessAtExit.java.
+// It explains how the thread's priority field is used for test state coordination.
+//
+WB_ENTRY(void, WB_CheckThreadObjOfTerminatingThread(JNIEnv* env, jobject wb, jobject target_handle))
+  oop target_oop = JNIHandles::resolve_non_null(target_handle);
+  jlong tid = java_lang_Thread::thread_id(target_oop);
+  JavaThread* target = java_lang_Thread::thread(target_oop);
+
+  // Grab a ThreadsListHandle to protect the target thread whilst terminating
+  ThreadsListHandle tlh;
+
+  // Look up the target thread by tid to ensure it is present
+  JavaThread* t = tlh.list()->find_JavaThread_from_java_tid(tid);
+  if (t == NULL) {
+    THROW_MSG(vmSymbols::java_lang_RuntimeException(), "Target thread not found in ThreadsList!");
+  }
+
+  tty->print_cr("WB_CheckThreadObjOfTerminatingThread: target thread is protected");
+  // Allow target to terminate by boosting priority
+  java_lang_Thread::set_priority(t->threadObj(), ThreadPriority(NormPriority + 1));
+
+  // Now wait for the target to terminate
+  while (!target->is_terminated()) {
+    ThreadBlockInVM tbivm(thread);  // just in case target is involved in a safepoint
+    os::naked_short_sleep(0);
+  }
+
+  tty->print_cr("WB_CheckThreadObjOfTerminatingThread: target thread is terminated");
+
+  // Now release the GC inducing thread - we have to re-resolve the external oop that
+  // was passed in as GC may have occurred and we don't know if we can trust t->threadObj() now.
+  oop original = JNIHandles::resolve_non_null(target_handle);
+  java_lang_Thread::set_priority(original, ThreadPriority(NormPriority + 2));
+
+  tty->print_cr("WB_CheckThreadObjOfTerminatingThread: GC has been initiated - checking threadObj:");
+
+  // The Java code should be creating garbage and triggering GC, which would potentially move
+  // the threadObj oop. If the exiting thread is properly protected then its threadObj should
+  // remain valid and equal to our initial target_handle. Loop a few times to give GC a chance to
+  // kick in.
+  for (int i = 0; i < 5; i++) {
+    oop original = JNIHandles::resolve_non_null(target_handle);
+    oop current = t->threadObj();
+    if (original != current) {
+      tty->print_cr("WB_CheckThreadObjOfTerminatingThread: failed comparison on iteration %d", i);
+      THROW_MSG(vmSymbols::java_lang_RuntimeException(), "Target thread oop has changed!");
+    } else {
+      tty->print_cr("WB_CheckThreadObjOfTerminatingThread: successful comparison on iteration %d", i);
+      ThreadBlockInVM tbivm(thread);
+      os::naked_short_sleep(50);
+    }
+  }
+WB_END
+
 #define CC (char*)
 
 static JNINativeMethod methods[] = {
   {CC"getObjectAddress0",                CC"(Ljava/lang/Object;)J", (void*)&WB_GetObjectAddress  },
   {CC"getObjectSize0",                   CC"(Ljava/lang/Object;)J", (void*)&WB_GetObjectSize     },
@@ -2545,10 +2599,11 @@
   {CC"isJavaHeapArchiveSupported",        CC"()Z",    (void*)&WB_IsJavaHeapArchiveSupported },
   {CC"cdsMemoryMappingFailed",            CC"()Z",    (void*)&WB_CDSMemoryMappingFailed },
 
   {CC"clearInlineCaches0",  CC"(Z)V",                 (void*)&WB_ClearInlineCaches },
   {CC"handshakeWalkStack", CC"(Ljava/lang/Thread;Z)I", (void*)&WB_HandshakeWalkStack },
+  {CC"checkThreadObjOfTerminatingThread", CC"(Ljava/lang/Thread;)V", (void*)&WB_CheckThreadObjOfTerminatingThread },
   {CC"addCompilerDirective",    CC"(Ljava/lang/String;)I",
                                                       (void*)&WB_AddCompilerDirective },
   {CC"removeCompilerDirective",   CC"(I)V",           (void*)&WB_RemoveCompilerDirective },
   {CC"isGCSupported",             CC"(I)Z",           (void*)&WB_IsGCSupported},
   {CC"isGCSelected",              CC"(I)Z",           (void*)&WB_IsGCSelected},
diff a/src/hotspot/share/runtime/arguments.cpp b/src/hotspot/share/runtime/arguments.cpp
--- a/src/hotspot/share/runtime/arguments.cpp
+++ b/src/hotspot/share/runtime/arguments.cpp
@@ -523,10 +523,20 @@
   { "AllowRedefinitionToAddDeleteMethods", JDK_Version::jdk(13), JDK_Version::undefined(), JDK_Version::undefined() },
   { "FlightRecorder",               JDK_Version::jdk(13), JDK_Version::undefined(), JDK_Version::undefined() },
   { "PrintVMQWaitTime",             JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
   { "UseNewFieldLayout",            JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
   { "ForceNUMA",                    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "UseBiasedLocking",             JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "BiasedLockingStartupDelay",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "PrintBiasedLockingStatistics", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "BiasedLockingBulkRebiasThreshold",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "BiasedLockingBulkRevokeThreshold",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "BiasedLockingDecayTime",              JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "UseOptoBiasInlining",                 JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "PrintPreciseBiasedLockingStatistics", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "InitialBootClassLoaderMetaspaceSize", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
+  { "UseLargePagesInMetaspace",            JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },
 
   // --- Deprecated alias flags (see also aliased_jvm_flags) - sorted by obsolete_in then expired_in:
   { "DefaultMaxRAMFraction",        JDK_Version::jdk(8),  JDK_Version::undefined(), JDK_Version::undefined() },
   { "CreateMinidumpOnCrash",        JDK_Version::jdk(9),  JDK_Version::undefined(), JDK_Version::undefined() },
   { "TLABStats",                    JDK_Version::jdk(12), JDK_Version::undefined(), JDK_Version::undefined() },
@@ -560,10 +570,20 @@
   { "not deprecated or obsolete",   JDK_Version::undefined(), JDK_Version::undefined(), JDK_Version::jdk(9) },
   { "dup option",                   JDK_Version::jdk(9), JDK_Version::undefined(), JDK_Version::undefined() },
   { "dup option",                   JDK_Version::jdk(9), JDK_Version::undefined(), JDK_Version::undefined() },
 #endif
 
+#ifndef COMPILER2
+  // These flags were generally available, but are C2 only, now.
+  { "MaxInlineLevel",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "MaxRecursiveInlineLevel",      JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "InlineSmallCode",              JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "MaxInlineSize",                JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "FreqInlineSize",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "MaxTrivialSize",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+#endif
+
   { NULL, JDK_Version(0), JDK_Version(0) }
 };
 
 // Flags that are aliases for other flags.
 typedef struct {
@@ -3525,17 +3545,25 @@
 
   delete options;
   return status;
 }
 
-void Arguments::set_shared_spaces_flags() {
+jint Arguments::set_shared_spaces_flags_and_archive_paths() {
   if (DumpSharedSpaces) {
     if (RequireSharedSpaces) {
       warning("Cannot dump shared archive while using shared archive");
     }
     UseSharedSpaces = false;
   }
+#if INCLUDE_CDS
+  // Initialize shared archive paths which could include both base and dynamic archive paths
+  // This must be after set_ergonomics_flags() called so flag UseCompressedOops is set properly.
+  if (!init_shared_archive_paths()) {
+    return JNI_ENOMEM;
+  }
+#endif  // INCLUDE_CDS
+  return JNI_OK;
 }
 
 #if INCLUDE_CDS
 // Sharing support
 // Construct the path to the archive
@@ -3547,11 +3575,12 @@
   if (end != NULL) *end = '\0';
   size_t jvm_path_len = strlen(jvm_path);
   size_t file_sep_len = strlen(os::file_separator());
   const size_t len = jvm_path_len + file_sep_len + 20;
   default_archive_path = NEW_C_HEAP_ARRAY(char, len, mtArguments);
-  jio_snprintf(default_archive_path, len, "%s%sclasses.jsa",
+  jio_snprintf(default_archive_path, len,
+               UseCompressedOops ? "%s%sclasses.jsa": "%s%sclasses_nocoops.jsa",
                jvm_path, os::file_separator());
   return default_archive_path;
 }
 
 int Arguments::num_archives(const char* archive_path) {
@@ -3992,17 +4021,10 @@
 
   if (result != JNI_OK) {
     return result;
   }
 
-#if INCLUDE_CDS
-  // Initialize shared archive paths which could include both base and dynamic archive paths
-  if (!init_shared_archive_paths()) {
-    return JNI_ENOMEM;
-  }
-#endif
-
   // Delay warning until here so that we've had a chance to process
   // the -XX:-PrintWarnings flag
   if (needs_hotspotrc_warning) {
     warning("%s file is present but has been ignored.  "
             "Run with -XX:Flags=%s to load the file.",
@@ -4086,11 +4108,12 @@
   // Set heap size based on available physical memory
   set_heap_size();
 
   GCConfig::arguments()->initialize();
 
-  set_shared_spaces_flags();
+  result = set_shared_spaces_flags_and_archive_paths();
+  if (result != JNI_OK) return result;
 
   // Initialize Metaspace flags and alignments
   Metaspace::ergo_initialize();
 
   // Set compiler flags after GC is selected and GC specific
diff a/src/hotspot/share/runtime/globals.hpp b/src/hotspot/share/runtime/globals.hpp
--- a/src/hotspot/share/runtime/globals.hpp
+++ b/src/hotspot/share/runtime/globals.hpp
@@ -176,11 +176,11 @@
                                                                             \
   develop(bool, LargePagesIndividualAllocationInjectError, false,           \
           "Fail large pages individual allocation")                         \
                                                                             \
   product(bool, UseLargePagesInMetaspace, false,                            \
-          "Use large page memory in metaspace. "                            \
+          "(Deprecated) Use large page memory in metaspace. "               \
           "Only used if UseLargePages is enabled.")                         \
                                                                             \
   product(bool, UseNUMA, false,                                             \
           "Use NUMA if available")                                          \
                                                                             \
@@ -793,36 +793,38 @@
           "Enable @Contended annotation support")                           \
                                                                             \
   product(bool, RestrictContended, true,                                    \
           "Restrict @Contended to trusted classes")                         \
                                                                             \
-  product(bool, UseBiasedLocking, true,                                     \
-          "Enable biased locking in JVM")                                   \
+  product(bool, UseBiasedLocking, false,                                    \
+          "(Deprecated) Enable biased locking in JVM")                      \
                                                                             \
   product(intx, BiasedLockingStartupDelay, 0,                               \
-          "Number of milliseconds to wait before enabling biased locking")  \
+          "(Deprecated) Number of milliseconds to wait before enabling "    \
+          "biased locking")                                                 \
           range(0, (intx)(max_jint-(max_jint%PeriodicTask::interval_gran))) \
           constraint(BiasedLockingStartupDelayFunc,AfterErgo)               \
                                                                             \
   diagnostic(bool, PrintBiasedLockingStatistics, false,                     \
-          "Print statistics of biased locking in JVM")                      \
+          "(Deprecated) Print statistics of biased locking in JVM")         \
                                                                             \
   product(intx, BiasedLockingBulkRebiasThreshold, 20,                       \
-          "Threshold of number of revocations per type to try to "          \
-          "rebias all objects in the heap of that type")                    \
+          "(Deprecated) Threshold of number of revocations per type to "    \
+          "try to rebias all objects in the heap of that type")             \
           range(0, max_intx)                                                \
           constraint(BiasedLockingBulkRebiasThresholdFunc,AfterErgo)        \
                                                                             \
   product(intx, BiasedLockingBulkRevokeThreshold, 40,                       \
-          "Threshold of number of revocations per type to permanently "     \
-          "revoke biases of all objects in the heap of that type")          \
+          "(Deprecated) Threshold of number of revocations per type to "    \
+          "permanently revoke biases of all objects in the heap of that "   \
+          "type")                                                           \
           range(0, max_intx)                                                \
           constraint(BiasedLockingBulkRevokeThresholdFunc,AfterErgo)        \
                                                                             \
   product(intx, BiasedLockingDecayTime, 25000,                              \
-          "Decay time (in milliseconds) to re-enable bulk rebiasing of a "  \
-          "type after previous bulk rebias")                                \
+          "(Deprecated) Decay time (in milliseconds) to re-enable bulk "    \
+          "rebiasing of a type after previous bulk rebias")                 \
           range(500, max_intx)                                              \
           constraint(BiasedLockingDecayTimeFunc,AfterErgo)                  \
                                                                             \
   product(bool, ExitOnOutOfMemoryError, false,                              \
           "JVM exits on the first occurrence of an out-of-memory error")    \
@@ -909,11 +911,11 @@
   product(bool, IgnoreEmptyClassPaths, false,                               \
           "Ignore empty path elements in -classpath")                       \
                                                                             \
   product(size_t, InitialBootClassLoaderMetaspaceSize,                      \
           NOT_LP64(2200*K) LP64_ONLY(4*M),                                  \
-          "Initial size of the boot class loader data metaspace")           \
+          "(Deprecated) Initial size of the boot class loader data metaspace") \
           range(30*K, max_uintx/BytesPerWord)                               \
           constraint(InitialBootClassLoaderMetaspaceSizeConstraintFunc, AfterErgo)\
                                                                             \
   product(bool, PrintHeapAtSIGBREAK, true,                                  \
           "Print heap layout in response to SIGBREAK")                      \
@@ -1469,40 +1471,15 @@
           "maximum number of elements to print")                            \
                                                                             \
   notproduct(intx, MaxSubklassPrintSize, 4,                                 \
           "maximum number of subklasses to print when printing klass")      \
                                                                             \
-  product(intx, MaxInlineLevel, 15,                                         \
-          "maximum number of nested calls that are inlined")                \
-          range(0, max_jint)                                                \
-                                                                            \
-  product(intx, MaxRecursiveInlineLevel, 1,                                 \
-          "maximum number of nested recursive calls that are inlined")      \
-          range(0, max_jint)                                                \
-                                                                            \
   develop(intx, MaxForceInlineLevel, 100,                                   \
           "maximum number of nested calls that are forced for inlining "    \
           "(using CompileCommand or marked w/ @ForceInline)")               \
           range(0, max_jint)                                                \
                                                                             \
-  product_pd(intx, InlineSmallCode,                                         \
-          "Only inline already compiled methods if their code size is "     \
-          "less than this")                                                 \
-          range(0, max_jint)                                                \
-                                                                            \
-  product(intx, MaxInlineSize, 35,                                          \
-          "The maximum bytecode size of a method to be inlined")            \
-          range(0, max_jint)                                                \
-                                                                            \
-  product_pd(intx, FreqInlineSize,                                          \
-          "The maximum bytecode size of a frequent method to be inlined")   \
-          range(0, max_jint)                                                \
-                                                                            \
-  product(intx, MaxTrivialSize, 6,                                          \
-          "The maximum bytecode size of a trivial method to be inlined")    \
-          range(0, max_jint)                                                \
-                                                                            \
   product(intx, MinInliningThreshold, 250,                                  \
           "The minimum invocation count a method needs to have to be "      \
           "inlined")                                                        \
           range(0, max_jint)                                                \
                                                                             \
diff a/src/hotspot/share/runtime/init.cpp b/src/hotspot/share/runtime/init.cpp
--- a/src/hotspot/share/runtime/init.cpp
+++ b/src/hotspot/share/runtime/init.cpp
@@ -64,12 +64,13 @@
 void VM_Version_init();
 void stubRoutines_init1();
 jint universe_init();          // depends on codeCache_init and stubRoutines_init
 // depends on universe_init, must be before interpreter_init (currently only on SPARC)
 void gc_barrier_stubs_init();
-void interpreter_init();       // before any methods loaded
-void invocationCounter_init(); // before any methods loaded
+void interpreter_init_stub();  // before any methods loaded
+void interpreter_init_code();  // after methods loaded, but before they are linked
+void invocationCounter_init(); // after methods loaded, but before they are linked
 void accessFlags_init();
 void InterfaceSupport_init();
 void universe2_init();  // dependent on codeCache_init and stubRoutines_init, loads primordial classes
 void referenceProcessor_init();
 void jni_handles_init();
@@ -117,18 +118,19 @@
   jint status = universe_init();  // dependent on codeCache_init and
                                   // stubRoutines_init1 and metaspace_init.
   if (status != JNI_OK)
     return status;
 
-  gc_barrier_stubs_init();   // depends on universe_init, must be before interpreter_init
-  interpreter_init();        // before any methods loaded
-  invocationCounter_init();  // before any methods loaded
+  gc_barrier_stubs_init();  // depends on universe_init, must be before interpreter_init
+  interpreter_init_stub();  // before methods get loaded
   accessFlags_init();
   InterfaceSupport_init();
   SharedRuntime::generate_stubs();
   universe2_init();  // dependent on codeCache_init and stubRoutines_init1
   javaClasses_init();// must happen after vtable initialization, before referenceProcessor_init
+  interpreter_init_code();  // after javaClasses_init and before any method gets linked
+  invocationCounter_init(); // after javaClasses_init and before any method gets linked
   referenceProcessor_init();
   jni_handles_init();
 #if INCLUDE_VM_STRUCTS
   vmStructs_init();
 #endif // INCLUDE_VM_STRUCTS
diff a/src/hotspot/share/runtime/thread.cpp b/src/hotspot/share/runtime/thread.cpp
--- a/src/hotspot/share/runtime/thread.cpp
+++ b/src/hotspot/share/runtime/thread.cpp
@@ -2169,10 +2169,18 @@
 
   if (JvmtiEnv::environments_might_exist()) {
     JvmtiExport::cleanup_thread(this);
   }
 
+  // We need to cache the thread name for logging purposes below as once
+  // we have called on_thread_detach this thread must not access any oops.
+  char* thread_name = NULL;
+  if (log_is_enabled(Debug, os, thread, timer)) {
+    ResourceMark rm(this);
+    thread_name = os::strdup(get_thread_name());
+  }
+
   // We must flush any deferred card marks and other various GC barrier
   // related buffers (e.g. G1 SATB buffer and G1 dirty card queue buffer)
   // before removing a thread from the list of active threads.
   BarrierSet::barrier_set()->on_thread_detach(this);
 
@@ -2187,21 +2195,21 @@
   // Remove from list of active threads list, and notify VM thread if we are the last non-daemon thread
   Threads::remove(this, daemon);
 
   if (log_is_enabled(Debug, os, thread, timer)) {
     _timer_exit_phase4.stop();
-    ResourceMark rm(this);
     log_debug(os, thread, timer)("name='%s'"
                                  ", exit-phase1=" JLONG_FORMAT
                                  ", exit-phase2=" JLONG_FORMAT
                                  ", exit-phase3=" JLONG_FORMAT
                                  ", exit-phase4=" JLONG_FORMAT,
-                                 get_thread_name(),
+                                 thread_name,
                                  _timer_exit_phase1.milliseconds(),
                                  _timer_exit_phase2.milliseconds(),
                                  _timer_exit_phase3.milliseconds(),
                                  _timer_exit_phase4.milliseconds());
+    os::free(thread_name);
   }
 }
 
 void JavaThread::cleanup_failed_attach_current_thread(bool is_daemon) {
   if (active_handles() != NULL) {
diff a/src/hotspot/share/runtime/thread.hpp b/src/hotspot/share/runtime/thread.hpp
--- a/src/hotspot/share/runtime/thread.hpp
+++ b/src/hotspot/share/runtime/thread.hpp
@@ -1017,10 +1017,11 @@
 class JavaThread: public Thread {
   friend class VMStructs;
   friend class JVMCIVMStructs;
   friend class WhiteBox;
   friend class VTBuffer;
+  friend class ThreadsSMRSupport; // to access _threadObj for exiting_threads_oops_do
  private:
   bool           _on_thread_list;                // Is set when this JavaThread is added to the Threads list
   oop            _threadObj;                     // The Java level thread object
 
 #ifdef ASSERT
@@ -1360,11 +1361,11 @@
 
   void handshake_process_by_self() {
     _handshake.process_by_self();
   }
 
-  bool handshake_try_process(HandshakeOperation* op) {
+  HandshakeState::ProcessResult handshake_try_process(HandshakeOperation* op) {
     return _handshake.try_process(op);
   }
 
 #ifdef ASSERT
   Thread* active_handshaker() const {
diff a/src/java.base/share/classes/java/io/ObjectStreamClass.java b/src/java.base/share/classes/java/io/ObjectStreamClass.java
--- a/src/java.base/share/classes/java/io/ObjectStreamClass.java
+++ b/src/java.base/share/classes/java/io/ObjectStreamClass.java
@@ -1587,11 +1587,11 @@
         PrivilegedAction<MethodHandle> pa = () -> {
             Class<?>[] paramTypes = Arrays.stream(cls.getRecordComponents())
                                           .map(RecordComponent::getType)
                                           .toArray(Class<?>[]::new);
             try {
-                Constructor<?> ctr = cls.getConstructor(paramTypes);
+                Constructor<?> ctr = cls.getDeclaredConstructor(paramTypes);
                 ctr.setAccessible(true);
                 return MethodHandles.lookup().unreflectConstructor(ctr);
             } catch (IllegalAccessException | NoSuchMethodException e) {
                 return null;
             }
diff a/src/java.base/share/classes/java/lang/System.java b/src/java.base/share/classes/java/lang/System.java
--- a/src/java.base/share/classes/java/lang/System.java
+++ b/src/java.base/share/classes/java/lang/System.java
@@ -35,10 +35,11 @@
 import java.io.PrintStream;
 import java.io.UnsupportedEncodingException;
 import java.lang.annotation.Annotation;
 import java.lang.invoke.MethodHandle;
 import java.lang.invoke.MethodType;
+import java.lang.invoke.StringConcatFactory;
 import java.lang.module.ModuleDescriptor;
 import java.lang.reflect.Constructor;
 import java.lang.reflect.Executable;
 import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
@@ -60,10 +61,11 @@
 import java.util.Set;
 import java.util.function.Supplier;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.stream.Stream;
 
+import jdk.internal.misc.Unsafe;
 import jdk.internal.util.StaticProperty;
 import jdk.internal.module.ModuleBootstrap;
 import jdk.internal.module.ServicesCatalog;
 import jdk.internal.reflect.CallerSensitive;
 import jdk.internal.reflect.Reflection;
@@ -2047,10 +2049,11 @@
      * @param printStackTrace print stack trace when exception occurs
      *
      * @return JNI_OK for success, JNI_ERR for failure
      */
     private static int initPhase2(boolean printToStderr, boolean printStackTrace) {
+
         try {
             bootLayer = ModuleBootstrap.boot();
         } catch (Exception | Error e) {
             logInitException(printToStderr, printStackTrace,
                              "Error occurred during initialization of boot layer", e);
@@ -2063,19 +2066,27 @@
         return 0; // JNI_OK
     }
 
     /*
      * Invoked by VM.  Phase 3 is the final system initialization:
-     * 1. set security manager
-     * 2. set system class loader
-     * 3. set TCCL
+     * 1. eagerly initialize bootstrap method factories that might interact
+     *    negatively with custom security managers and custom class loaders
+     * 2. set security manager
+     * 3. set system class loader
+     * 4. set TCCL
      *
      * This method must be called after the module system initialization.
      * The security manager and system class loader may be a custom class from
      * the application classpath or modulepath.
      */
     private static void initPhase3() {
+
+        // Initialize the StringConcatFactory eagerly to avoid potential
+        // bootstrap circularity issues that could be caused by a custom
+        // SecurityManager
+        Unsafe.getUnsafe().ensureClassInitialized(StringConcatFactory.class);
+
         String smProp = System.getProperty("java.security.manager");
         if (smProp != null) {
             switch (smProp) {
                 case "disallow":
                     allowSecurityManager = NEVER;
@@ -2269,10 +2280,14 @@
 
             public MethodHandle stringConcatHelper(String name, MethodType methodType) {
                 return StringConcatHelper.lookupStatic(name, methodType);
             }
 
+            public long stringConcatInitialCoder() {
+                return StringConcatHelper.initialCoder();
+            }
+
             public Object classData(Class<?> c) {
                 return c.getClassData();
             }
         });
     }
diff a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
@@ -254,15 +254,15 @@
             }
 
             // M2 != M1, set previous lookup class to M1 and drop MODULE access
             newPreviousClass = callerClass;
             newModes &= ~Lookup.MODULE;
-        }
-
-        if (!callerModule.isNamed() && targetModule.isNamed()) {
-            IllegalAccessLogger logger = IllegalAccessLogger.illegalAccessLogger();
-            if (logger != null) {
+
+            if (!callerModule.isNamed() && targetModule.isNamed()) {
+                IllegalAccessLogger logger = IllegalAccessLogger.illegalAccessLogger();
+                if (logger != null) {
+                    logger.logIfOpenedForIllegalAccess(caller, targetClass);
                 logger.logIfOpenedForIllegalAccess(caller, targetClass);
             }
         }
         return Lookup.newLookup(targetClass, newPreviousClass, newModes);
     }
@@ -2225,12 +2225,12 @@
             if (name.startsWith("java.lang.invoke."))
                 throw newIllegalArgumentException("illegal lookupClass: "+lookupClass);
         }
 
         /**
-         * Displays the name of the class from which lookups are to be made.
-         * followed with "/" and the name of the {@linkplain #previousLookupClass()
+         * Displays the name of the class from which lookups are to be made,
+         * followed by "/" and the name of the {@linkplain #previousLookupClass()
          * previous lookup class} if present.
          * (The name is the one reported by {@link java.lang.Class#getName() Class.getName}.)
          * If there are restrictions on the access permitted to this lookup,
          * this is indicated by adding a suffix to the class name, consisting
          * of a slash and a keyword.  The keyword represents the strongest
diff a/src/java.base/share/classes/module-info.java b/src/java.base/share/classes/module-info.java
--- a/src/java.base/share/classes/module-info.java
+++ b/src/java.base/share/classes/module-info.java
@@ -291,10 +291,11 @@
         jdk.jartool;
     exports sun.security.provider to
         java.rmi,
         java.security.jgss,
         jdk.crypto.cryptoki,
+        jdk.crypto.ec,
         jdk.security.auth;
     exports sun.security.provider.certpath to
         java.naming;
     exports sun.security.rsa to
         jdk.crypto.cryptoki;
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
@@ -388,11 +388,11 @@
     /** Modifier masks.
      */
     public static final int
         AccessFlags           = PUBLIC | PROTECTED | PRIVATE,
         LocalClassFlags       = FINAL | ABSTRACT | STRICTFP | ENUM | SYNTHETIC | VALUE,
-        LocalRecordFlags      = LocalClassFlags | STATIC,
+        StaticLocalFlags      = LocalClassFlags | STATIC | INTERFACE | ANNOTATION,
         MemberClassFlags      = LocalClassFlags | INTERFACE | AccessFlags,
         MemberRecordFlags     = MemberClassFlags | STATIC,
         ClassFlags            = LocalClassFlags | INTERFACE | PUBLIC | ANNOTATION,
         InterfaceVarFlags     = FINAL | STATIC | PUBLIC,
         ConstructorFlags      = AccessFlags,
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
@@ -1530,11 +1530,14 @@
             return null;
         }
 
         public RecordComponent getRecordComponent(JCVariableDecl var, boolean addIfMissing, List<JCAnnotation> annotations) {
             for (RecordComponent rc : recordComponents) {
-                if (rc.name == var.name) {
+                /* it could be that a record erroneously declares two record components with the same name, in that
+                 * case we need to use the position to disambiguate
+                 */
+                if (rc.name == var.name && var.pos == rc.pos) {
                     return rc;
                 }
             }
             RecordComponent rc = null;
             if (addIfMissing) {
@@ -1865,22 +1868,33 @@
 
     @SuppressWarnings("preview")
     public static class RecordComponent extends VarSymbol implements RecordComponentElement {
         public MethodSymbol accessor;
         public JCTree.JCMethodDecl accessorMeth;
+        /* the original annotations applied to the record component
+         */
         private final List<JCAnnotation> originalAnnos;
+        /* if the user happens to erroneously declare two components with the same name, we need a way to differentiate
+         * them, the code will fail anyway but we need to keep the information for better error recovery
+         */
+        private final int pos;
 
         /**
          * Construct a record component, given its flags, name, type and owner.
          */
         public RecordComponent(JCVariableDecl fieldDecl, List<JCAnnotation> annotations) {
             super(PUBLIC, fieldDecl.sym.name, fieldDecl.sym.type, fieldDecl.sym.owner);
             this.originalAnnos = annotations;
+            this.pos = fieldDecl.pos;
         }
 
         public List<JCAnnotation> getOriginalAnnos() { return originalAnnos; }
 
+        public boolean isVarargs() {
+            return type.hasTag(TypeTag.ARRAY) && ((ArrayType)type).isVarargs();
+        }
+
         @Override @DefinedBy(Api.LANGUAGE_MODEL)
         @SuppressWarnings("preview")
         public ElementKind getKind() {
             return ElementKind.RECORD_COMPONENT;
         }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
@@ -288,20 +288,22 @@
      */
     boolean isAssignableAsBlankFinal(VarSymbol v, Env<AttrContext> env) {
         Symbol owner = env.info.scope.owner;
            // owner refers to the innermost variable, method or
            // initializer block declaration at this point.
-        return
+        boolean isAssignable =
             v.owner == owner
             ||
             ((owner.name == names.init ||    // i.e. we are in a constructor
               owner.kind == VAR ||           // i.e. we are in a variable initializer
               (owner.flags() & BLOCK) != 0)  // i.e. we are in an initializer block
              &&
              v.owner == owner.owner
              &&
              ((v.flags() & STATIC) != 0) == Resolve.isStatic(env));
+        boolean insideCompactConstructor = env.enclMethod != null && TreeInfo.isCompactConstructor(env.enclMethod);
+        return isAssignable & !insideCompactConstructor;
     }
 
     /** Check that variable can be assigned to.
      *  @param pos    The current source code position.
      *  @param v      The assigned variable
@@ -1105,39 +1107,63 @@
                             log.error(tree, Errors.FirstStatementMustBeCallToAnotherConstructor);
                         }
                     } else {
                         // but if it is the canonical:
 
-                        // if user generated, then it shouldn't explicitly invoke any other constructor
+                        /* if user generated, then it shouldn't:
+                         *     - have an accessibility stricter than that of the record type
+                         *     - explicitly invoke any other constructor
+                         */
                         if ((tree.sym.flags_field & GENERATEDCONSTR) == 0) {
+                            if (Check.protection(m.flags()) > Check.protection(env.enclClass.sym.flags())) {
+                                log.error(tree,
+                                        (env.enclClass.sym.flags() & AccessFlags) == 0 ?
+                                            Errors.InvalidCanonicalConstructorInRecord(
+                                                Fragments.Canonical,
+                                                env.enclClass.sym.name,
+                                                Fragments.CanonicalMustNotHaveStrongerAccess("package")
+                                            ) :
+                                            Errors.InvalidCanonicalConstructorInRecord(
+                                                    Fragments.Canonical,
+                                                    env.enclClass.sym.name,
+                                                    Fragments.CanonicalMustNotHaveStrongerAccess(asFlagSet(env.enclClass.sym.flags() & AccessFlags))
+                                            )
+                                );
+                            }
+
                             JCMethodInvocation app = TreeInfo.firstConstructorCall(tree);
                             if (app != null &&
                                     (TreeInfo.name(app.meth) == names._this ||
                                             TreeInfo.name(app.meth) == names._super) &&
                                     checkFirstConstructorStat(app, tree, false)) {
                                 log.error(tree, Errors.InvalidCanonicalConstructorInRecord(
-                                        Fragments.Canonical, tree.sym.name,
+                                        Fragments.Canonical, env.enclClass.sym.name,
                                         Fragments.CanonicalMustNotContainExplicitConstructorInvocation));
                             }
                         }
 
                         // also we want to check that no type variables have been defined
                         if (!tree.typarams.isEmpty()) {
                             log.error(tree, Errors.InvalidCanonicalConstructorInRecord(
-                                    Fragments.Canonical, tree.sym.name, Fragments.CanonicalMustNotDeclareTypeVariables));
+                                    Fragments.Canonical, env.enclClass.sym.name, Fragments.CanonicalMustNotDeclareTypeVariables));
                         }
 
                         /* and now we need to check that the constructor's arguments are exactly the same as those of the
                          * record components
                          */
-                        List<Type> recordComponentTypes = TreeInfo.recordFields(env.enclClass).map(vd -> vd.sym.type);
+                        List<? extends RecordComponent> recordComponents = env.enclClass.sym.getRecordComponents();
+                        List<Type> recordFieldTypes = TreeInfo.recordFields(env.enclClass).map(vd -> vd.sym.type);
                         for (JCVariableDecl param: tree.params) {
-                            if (!types.isSameType(param.type, recordComponentTypes.head)) {
+                            boolean paramIsVarArgs = (param.sym.flags_field & VARARGS) != 0;
+                            if (!types.isSameType(param.type, recordFieldTypes.head) ||
+                                    (recordComponents.head.isVarargs() != paramIsVarArgs)) {
                                 log.error(param, Errors.InvalidCanonicalConstructorInRecord(
-                                        Fragments.Canonical, tree.sym.name, Fragments.TypeMustBeIdenticalToCorrespondingRecordComponentType));
+                                        Fragments.Canonical, env.enclClass.sym.name,
+                                        Fragments.TypeMustBeIdenticalToCorrespondingRecordComponentType));
                             }
-                            recordComponentTypes = recordComponentTypes.tail;
+                            recordComponents = recordComponents.tail;
+                            recordFieldTypes = recordFieldTypes.tail;
                         }
                     }
                 }
             }
 
@@ -1207,15 +1233,10 @@
                         List<Name> initParamNames = tree.sym.params.map(p -> p.name);
                         if (!initParamNames.equals(recordComponentNames)) {
                             log.error(tree, Errors.InvalidCanonicalConstructorInRecord(
                                     Fragments.Canonical, env.enclClass.sym.name, Fragments.CanonicalWithNameMismatch));
                         }
-                        if (!tree.sym.isPublic()) {
-                            log.error(tree, Errors.InvalidCanonicalConstructorInRecord(
-                                    TreeInfo.isCompactConstructor(tree) ? Fragments.Compact : Fragments.Canonical,
-                                    env.enclClass.sym.name, Fragments.CanonicalConstructorMustBePublic));
-                        }
                         if (tree.sym.type.asMethodType().thrown != null && !tree.sym.type.asMethodType().thrown.isEmpty()) {
                             log.error(tree,
                                     Errors.InvalidCanonicalConstructorInRecord(
                                             TreeInfo.isCompactConstructor(tree) ? Fragments.Compact : Fragments.Canonical,
                                             env.enclClass.sym.name,
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
@@ -1369,30 +1369,27 @@
                 ((flags) & Flags.DEFAULT) != 0)
                 implicit |= sym.owner.flags_field & STRICTFP;
             break;
         case TYP:
             if (sym.isLocal()) {
-                mask = (flags & RECORD) != 0 ? LocalRecordFlags : LocalClassFlags;
-                if ((flags & RECORD) != 0) {
-                    implicit = STATIC;
+                boolean implicitlyStatic = !sym.isAnonymous() &&
+                        ((flags & RECORD) != 0 || (flags & ENUM) != 0 || (flags & INTERFACE) != 0);
+                boolean staticOrImplicitlyStatic = (flags & STATIC) != 0 || implicitlyStatic;
+                mask = staticOrImplicitlyStatic && allowRecords ? StaticLocalFlags : LocalClassFlags;
+                implicit = implicitlyStatic ? STATIC : implicit;
+                if (staticOrImplicitlyStatic) {
                     if (sym.owner.kind == TYP) {
-                        log.error(pos, Errors.RecordDeclarationNotAllowedInInnerClasses);
+                        log.error(pos, Errors.StaticDeclarationNotAllowedInInnerClasses);
                     }
                 }
-                if ((sym.owner.flags_field & STATIC) == 0 &&
-                    (flags & ENUM) != 0) {
-                    log.error(pos, Errors.EnumsMustBeStatic);
-                }
             } else if (sym.owner.kind == TYP) {
                 mask = (flags & RECORD) != 0 ? MemberRecordFlags : MemberClassFlags;
                 if (sym.owner.owner.kind == PCK ||
                     (sym.owner.flags_field & STATIC) != 0)
                     mask |= STATIC;
-                else if ((flags & ENUM) != 0) {
-                    log.error(pos, Errors.EnumsMustBeStatic);
-                } else if ((flags & RECORD) != 0) {
-                    log.error(pos, Errors.RecordDeclarationNotAllowedInInnerClasses);
+                else if ((flags & ENUM) != 0 || (flags & RECORD) != 0) {
+                    log.error(pos, Errors.StaticDeclarationNotAllowedInInnerClasses);
                 }
                 // Nested interfaces and enums are always STATIC (Spec ???)
                 if ((flags & (INTERFACE | ENUM | RECORD)) != 0 ) implicit = STATIC;
             } else {
                 mask = ClassFlags;
@@ -1422,11 +1419,11 @@
                 log.error(pos, ((flags & ANNOTATION) != 0) ? Errors.AnnotationDeclNotAllowedHere : Errors.IntfNotAllowedHere);
                 mask |= INTERFACE;
             }
             else {
                 log.error(pos,
-                          Errors.ModNotAllowedHere(asFlagSet(illegal)));
+                        Errors.ModNotAllowedHere(asFlagSet(illegal)));
             }
         }
         else if ((sym.kind == TYP ||
                   // ISSUE: Disallowing abstract&private is no longer appropriate
                   // in the presence of inner classes. Should it be deleted here?
@@ -2240,15 +2237,25 @@
      *                      for errors.
      *  @param m            The overriding method.
      */
     void checkOverride(Env<AttrContext> env, JCMethodDecl tree, MethodSymbol m) {
         ClassSymbol origin = (ClassSymbol)m.owner;
-        if ((origin.flags() & ENUM) != 0 && names.finalize.equals(m.name))
+        if ((origin.flags() & ENUM) != 0 && names.finalize.equals(m.name)) {
             if (m.overrides(syms.enumFinalFinalize, origin, types, false)) {
                 log.error(tree.pos(), Errors.EnumNoFinalize);
                 return;
             }
+        }
+        if (allowRecords && origin.isRecord()) {
+            // let's find out if this is a user defined accessor in which case the @Override annotation is acceptable
+            Optional<? extends RecordComponent> recordComponent = origin.getRecordComponents().stream()
+                    .filter(rc -> rc.accessor == tree.sym && (rc.accessor.flags_field & GENERATED_MEMBER) == 0).findFirst();
+            if (recordComponent.isPresent()) {
+                return;
+            }
+        }
+
         for (Type t = origin.type; t.hasTag(CLASS);
              t = types.supertype(t)) {
             if (t != origin.type) {
                 checkOverride(tree, t, origin, m);
             }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
@@ -56,11 +56,10 @@
 import static com.sun.tools.javac.code.TypeTag.CLASS;
 import static com.sun.tools.javac.code.TypeTag.ERROR;
 import com.sun.tools.javac.resources.CompilerProperties.Fragments;
 
 import static com.sun.tools.javac.code.TypeTag.*;
-import static com.sun.tools.javac.code.TypeTag.BOT;
 import static com.sun.tools.javac.tree.JCTree.Tag.*;
 
 import com.sun.tools.javac.util.Dependencies.CompletionCause;
 import com.sun.tools.javac.util.JCDiagnostic.DiagnosticFlag;
 import com.sun.tools.javac.util.JCDiagnostic.DiagnosticPosition;
@@ -1034,11 +1033,10 @@
                                 (((JCMethodDecl)t).sym.flags_field & Flags.GENERATEDCONSTR) == 0).collect(List.collector()));
             }
             List<JCTree> defsToEnter = isRecord ?
                     tree.defs.diff(alreadyEntered) : tree.defs;
             memberEnter.memberEnter(defsToEnter, env);
-            List<JCTree> defsBeforeAddingNewMembers = tree.defs;
             if (isRecord) {
                 addRecordMembersIfNeeded(tree, env);
             }
             if ((tree.mods.flags & (Flags.VALUE | Flags.INTERFACE)) == Flags.VALUE && !tree.sym.type.hasTag(ERROR)) {
                 addValueMembers(tree, env);
@@ -1060,11 +1058,11 @@
                 List<JCAnnotation> originalAnnos = rec.getOriginalAnnos().isEmpty() ?
                         rec.getOriginalAnnos() :
                         new TreeCopier<JCTree>(make.at(tree.pos)).copy(rec.getOriginalAnnos());
                 JCMethodDecl getter = make.at(tree.pos).
                         MethodDef(
-                                make.Modifiers(Flags.PUBLIC | Flags.GENERATED_MEMBER, originalAnnos),
+                                make.Modifiers(PUBLIC | Flags.GENERATED_MEMBER, originalAnnos),
                           tree.sym.name,
                           /* we need to special case for the case when the user declared the type as an ident
                            * if we don't do that then we can have issues if type annotations are applied to the
                            * return type: javac issues an error if a type annotation is applied to java.lang.String
                            * but applying a type annotation to String is kosher
@@ -1223,11 +1221,11 @@
          *  to the symbol table.
          */
         private void addRecordMembersIfNeeded(JCClassDecl tree, Env<AttrContext> env) {
             if (lookupMethod(tree.sym, names.toString, List.nil()) == null) {
                 JCMethodDecl toString = make.
-                    MethodDef(make.Modifiers(Flags.PUBLIC | Flags.RECORD | Flags.GENERATED_MEMBER),
+                    MethodDef(make.Modifiers(Flags.PUBLIC | Flags.RECORD | Flags.FINAL | Flags.GENERATED_MEMBER),
                               names.toString,
                               make.Type(syms.stringType),
                               List.nil(),
                               List.nil(),
                               List.nil(),
@@ -1323,13 +1321,10 @@
                 long flags;
                 if ((owner().flags() & ENUM) != 0 &&
                     (types.supertype(owner().type).tsym == syms.enumSym)) {
                     // constructors of true enums are private
                     flags = PRIVATE | GENERATEDCONSTR;
-                } else if ((owner().flags_field & RECORD) != 0) {
-                    // record constructors are public
-                    flags = PUBLIC | GENERATEDCONSTR;
                 } else {
                     flags = (owner().flags() & AccessFlags) | GENERATEDCONSTR;
                 }
                 constructorSymbol = new MethodSymbol(flags, names.init,
                     constructorType(), owner());
@@ -1413,25 +1408,29 @@
             return params.map(vd -> vd.name);
         }
     }
 
     class RecordConstructorHelper extends BasicConstructorHelper {
-
-        List<VarSymbol> recordFieldSymbols;
+        boolean lastIsVarargs;
         List<JCVariableDecl> recordFieldDecls;
 
-        RecordConstructorHelper(TypeSymbol owner, List<JCVariableDecl> recordFieldDecls) {
+        RecordConstructorHelper(ClassSymbol owner, List<JCVariableDecl> recordFieldDecls) {
             super(owner);
             this.recordFieldDecls = recordFieldDecls;
-            this.recordFieldSymbols = recordFieldDecls.map(vd -> vd.sym);
+            this.lastIsVarargs = owner.getRecordComponents().stream().anyMatch(rc -> rc.isVarargs());
         }
 
         @Override
         public Type constructorType() {
             if (constructorType == null) {
-                List<Type> argtypes = recordFieldSymbols.map(v -> (v.flags_field & Flags.VARARGS) != 0 ? types.elemtype(v.type) : v.type);
-                constructorType = new MethodType(argtypes, syms.voidType, List.nil(), syms.methodClass);
+                ListBuffer<Type> argtypes = new ListBuffer<>();
+                JCVariableDecl lastField = recordFieldDecls.last();
+                for (JCVariableDecl field : recordFieldDecls) {
+                    argtypes.add(field == lastField && lastIsVarargs ? types.elemtype(field.sym.type) : field.sym.type);
+                }
+
+                constructorType = new MethodType(argtypes.toList(), syms.voidType, List.nil(), syms.methodClass);
             }
             return constructorType;
         }
 
         @Override
@@ -1440,15 +1439,18 @@
             /* if we have to generate a default constructor for records we will treat it as the compact one
              * to trigger field initialization later on
              */
             csym.flags_field |= Flags.COMPACT_RECORD_CONSTRUCTOR | GENERATEDCONSTR;
             ListBuffer<VarSymbol> params = new ListBuffer<>();
-            for (VarSymbol p : recordFieldSymbols) {
-                params.add(new VarSymbol(GENERATED_MEMBER | PARAMETER | RECORD | ((p.flags_field & Flags.VARARGS) != 0 ? Flags.VARARGS : 0), p.name, p.type, csym));
+            JCVariableDecl lastField = recordFieldDecls.last();
+            for (JCVariableDecl field : recordFieldDecls) {
+                params.add(new VarSymbol(
+                        GENERATED_MEMBER | PARAMETER | RECORD | (field == lastField && lastIsVarargs ? Flags.VARARGS : 0),
+                        field.name, field.sym.type, csym));
             }
             csym.params = params.toList();
-            csym.flags_field |= RECORD | PUBLIC;
+            csym.flags_field |= RECORD;
             return csym;
         }
 
         @Override
         public JCMethodDecl finalAdjustment(JCMethodDecl md) {
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
@@ -2652,11 +2652,13 @@
         case INTERFACE:
         case CLASS:
             dc = token.comment(CommentStyle.JAVADOC);
             return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), dc));
         case ENUM:
-            log.error(DiagnosticFlag.SYNTAX, token.pos, Errors.LocalEnum);
+            if (!allowRecords) {
+                log.error(DiagnosticFlag.SYNTAX, token.pos, Errors.LocalEnum);
+            }
             dc = token.comment(CommentStyle.JAVADOC);
             return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), dc));
         case IDENTIFIER:
             if (token.name() == names.yield && allowYieldStatement) {
                 Token next = S.token(1);
@@ -4025,19 +4027,27 @@
         accept(RBRACE);
         return defs.toList();
     }
 
     private EnumeratorEstimate estimateEnumeratorOrMember(Name enumName) {
-        if (token.kind == TokenKind.IDENTIFIER && token.name() != enumName) {
+        // if we are seeing a record declaration inside of an enum we want the same error message as expected for a
+        // let's say an interface declaration inside an enum
+        if (token.kind == TokenKind.IDENTIFIER && token.name() != enumName &&
+                (!allowRecords || !isRecordStart())) {
             Token next = S.token(1);
             switch (next.kind) {
                 case LPAREN: case LBRACE: case COMMA: case SEMI:
                     return EnumeratorEstimate.ENUMERATOR;
             }
         }
         switch (token.kind) {
             case IDENTIFIER: case MONKEYS_AT: case LT:
+                if (token.kind == IDENTIFIER) {
+                    if (allowRecords && isRecordStart()) {
+                        return EnumeratorEstimate.MEMBER;
+                    }
+                }
                 return EnumeratorEstimate.UNKNOWN;
             default:
                 return EnumeratorEstimate.MEMBER;
         }
     }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties b/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
@@ -826,13 +826,10 @@
     modifier {0} not allowed here
 
 compiler.err.intf.not.allowed.here=\
     interface not allowed here
 
-compiler.err.enums.must.be.static=\
-    enum declarations allowed only in static contexts
-
 # 0: symbol, 1: symbol
 compiler.err.name.clash.same.erasure=\
     name clash: {0} and {1} have the same erasure
 
 # 0: name, 1: list of type, 2: symbol, 3: name, 4: list of type, 5: symbol
@@ -3491,13 +3488,10 @@
     canonical
 
 compiler.misc.compact=\
     compact
 
-compiler.misc.canonical.constructor.must.be.public=\
-    canonical constructor must be public
-
 # 0: fragment
 compiler.misc.throws.clause.not.allowed.for.canonical.constructor=\
     throws clause not allowed for {0} constructor
 
 compiler.misc.canonical.with.name.mismatch=\
@@ -3508,15 +3502,19 @@
 
 compiler.misc.canonical.must.not.declare.type.variables=\
     canonical constructor must not declare type variables
 
 compiler.misc.type.must.be.identical.to.corresponding.record.component.type=\
-    type must match that of the corresponding record component\
+    type and arity must match that of the corresponding record component\
 
 compiler.misc.canonical.must.not.contain.explicit.constructor.invocation=\
     canonical constructor must not contain explicit constructor invocation
 
+# 0: set of flag or string
+compiler.misc.canonical.must.not.have.stronger.access=\
+    attempting to assign stronger access privileges; was {0}
+
 # other
 compiler.err.record.cannot.declare.instance.fields=\
     field declaration must be static\n\
     (consider replacing field with record component)
 
@@ -3528,12 +3526,12 @@
     constructor is not canonical, so its first statement must invoke another constructor
 
 compiler.err.instance.initializer.not.allowed.in.records=\
     instance initializers not allowed in records
 
-compiler.err.record.declaration.not.allowed.in.inner.classes=\
-    record declarations not allowed in inner classes
+compiler.err.static.declaration.not.allowed.in.inner.classes=\
+    static declarations not allowed in inner classes
 
 compiler.err.record.header.expected=\
     record header expected
 
 ############################################
diff a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotResolvedObjectTypeImpl.java b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotResolvedObjectTypeImpl.java
--- a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotResolvedObjectTypeImpl.java
+++ b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotResolvedObjectTypeImpl.java
@@ -817,11 +817,11 @@
     }
 
     @Override
     public String getSourceFileName() {
         if (isArray()) {
-            throw new JVMCIError("Cannot call getSourceFileName() on an array klass type: %s", this);
+            return null;
         }
         return getConstantPool().getSourceFileName();
     }
 
     @Override
diff a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ArrayTypeImpl.java b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ArrayTypeImpl.java
--- a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ArrayTypeImpl.java
+++ b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ArrayTypeImpl.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2017, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -57,11 +57,12 @@
             throw exc.toJDIException();
         }
     }
 
     public String componentSignature() {
-        return signature().substring(1); // Just skip the leading '['
+        JNITypeParser sig = new JNITypeParser(signature());
+        return sig.componentSignature();
     }
 
     public String componentTypeName() {
         JNITypeParser parser = new JNITypeParser(componentSignature());
         return parser.typeName();
@@ -88,12 +89,13 @@
      * the same class loader. Since array set operations don't have an
      * implicit enclosing type like field and variable set operations,
      * this method is sometimes needed for proper type checking.
      */
     Type findComponentType(String signature) throws ClassNotLoadedException {
-        byte tag = (byte)signature.charAt(0);
-        if (PacketStream.isObjectTag(tag)) {
+
+        JNITypeParser sig = new JNITypeParser(signature);
+        if (sig.isReference()) {
             // It's a reference type
             JNITypeParser parser = new JNITypeParser(componentSignature());
             List<ReferenceType> list = vm.classesBySignature(componentSignature());
             Iterator<ReferenceType> iter = list.iterator();
             while (iter.hasNext()) {
@@ -107,11 +109,11 @@
             }
             // Component class has not yet been loaded
             throw new ClassNotLoadedException(componentTypeName());
         } else {
             // It's a primitive type
-            return vm.primitiveTypeMirror(tag);
+            return vm.primitiveTypeMirror(sig.jdwpTag());
         }
     }
 
     public Type componentType() throws ClassNotLoadedException {
         return findComponentType(componentSignature());
diff a/src/jdk.jdi/share/classes/com/sun/tools/jdi/JNITypeParser.java b/src/jdk.jdi/share/classes/com/sun/tools/jdi/JNITypeParser.java
--- a/src/jdk.jdi/share/classes/com/sun/tools/jdi/JNITypeParser.java
+++ b/src/jdk.jdi/share/classes/com/sun/tools/jdi/JNITypeParser.java
@@ -111,14 +111,73 @@
             count++;
         }
         return count;
     }
 
+    byte jdwpTag() {
+        return (byte) signature().charAt(0);
+    }
+
     String componentSignature(int level) {
+        assert level <= dimensionCount();
         return signature().substring(level);
     }
 
+    String componentSignature() {
+        assert isArray();
+        return componentSignature(1);
+    }
+
+    boolean isArray() {
+        return jdwpTag() == JDWP.Tag.ARRAY;
+    }
+
+    boolean isVoid() {
+        return jdwpTag() == JDWP.Tag.VOID;
+    }
+
+    boolean isBoolean() {
+        return jdwpTag() == JDWP.Tag.BOOLEAN;
+    }
+
+    boolean isReference() {
+        byte tag = jdwpTag();
+        return tag == JDWP.Tag.ARRAY ||
+                tag == JDWP.Tag.OBJECT;
+    }
+
+    boolean isPrimitive() {
+        switch (jdwpTag()) {
+            case (JDWP.Tag.BOOLEAN):
+            case (JDWP.Tag.BYTE):
+            case (JDWP.Tag.CHAR):
+            case (JDWP.Tag.SHORT):
+            case (JDWP.Tag.INT):
+            case (JDWP.Tag.LONG):
+            case (JDWP.Tag.FLOAT):
+            case (JDWP.Tag.DOUBLE):
+                return true;
+        }
+        return false;
+    }
+
+    static String convertSignatureToClassname(String classSignature) {
+        assert classSignature.startsWith("L") && classSignature.endsWith(";");
+
+        // trim leading "L" and trailing ";"
+        String name = classSignature.substring(1, classSignature.length() - 1);
+        int index = name.indexOf(".");  // check if it is a hidden class
+        if (index < 0) {
+            return name.replace('/', '.');
+        } else {
+            // map the type descriptor from: "L" + N + "." + <suffix> + ";"
+            // to class name: N.replace('/', '.') + "/" + <suffix>
+            return name.substring(0, index).replace('/', '.')
+                    + "/" + name.substring(index + 1);
+        }
+    }
+
     private synchronized List<String> signatureList() {
         if (signatureList == null) {
             signatureList = new ArrayList<>(10);
             String elem;
 
diff a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ObjectReferenceImpl.java b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ObjectReferenceImpl.java
--- a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ObjectReferenceImpl.java
+++ b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ObjectReferenceImpl.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2017, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -612,21 +612,20 @@
         /*
          * Do these simpler checks before attempting a query of the destination's
          * type which might cause a confusing ClassNotLoadedException if
          * the destination is primitive or an array.
          */
-        /*
-         * TO DO: Centralize JNI signature knowledge
-         */
-        if (destination.signature().length() == 1) {
+
+        JNITypeParser destSig = new JNITypeParser(destination.signature());
+        JNITypeParser sourceSig = new JNITypeParser(type().signature());
+        if (destSig.isPrimitive()) {
             throw new InvalidTypeException("Can't assign object value to primitive");
         }
-        if ((destination.signature().charAt(0) == '[') &&
-            (type().signature().charAt(0) != '[')) {
+        if (destSig.isArray() && !sourceSig.isArray()) {
             throw new InvalidTypeException("Can't assign non-array value to an array");
         }
-        if ("void".equals(destination.typeName())) {
+        if (destSig.isVoid()) {
             throw new InvalidTypeException("Can't assign object value to a void");
         }
 
         // Validate assignment
         ReferenceType destType = (ReferenceTypeImpl)destination.type();
diff a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ValueImpl.java b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ValueImpl.java
--- a/src/jdk.jdi/share/classes/com/sun/tools/jdi/ValueImpl.java
+++ b/src/jdk.jdi/share/classes/com/sun/tools/jdi/ValueImpl.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2017, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -38,14 +38,12 @@
 
     static ValueImpl prepareForAssignment(Value value,
                                           ValueContainer destination)
                   throws InvalidTypeException, ClassNotLoadedException {
         if (value == null) {
-            /*
-             * TO DO: Centralize JNI signature knowledge
-             */
-            if (destination.signature().length() == 1) {
+            JNITypeParser sig = new JNITypeParser(destination.signature());
+            if (sig.isPrimitive()) {
                 throw new InvalidTypeException("Can't set a primitive type to null");
             }
             if (destination.signature().charAt(0) == 'Q') {
                 throw new InvalidTypeException("Can't set an inline type to null");
             }
diff a/src/jdk.jdwp.agent/share/native/libjdwp/signature.h b/src/jdk.jdwp.agent/share/native/libjdwp/signature.h
--- /dev/null
+++ b/src/jdk.jdwp.agent/share/native/libjdwp/signature.h
@@ -0,0 +1,67 @@
+/*
+ * Copyright (c) 2020, Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.  Oracle designates this
+ * particular file as subject to the "Classpath" exception as provided
+ * by Oracle in the LICENSE file that accompanied this code.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+#ifndef JDWP_SIGNATURE_H
+#define JDWP_SIGNATURE_H
+
+#define JVM_TYPE_ASSERT(typeKey)\
+JDI_ASSERT_MSG(JDWP_Tag_OBJECT == typeKey || \
+               JDWP_Tag_ARRAY == typeKey || \
+               JDWP_Tag_INLINE_OBJECT == typeKey || \
+               JDWP_Tag_BOOLEAN == typeKey || \
+               JDWP_Tag_BYTE == typeKey || \
+               JDWP_Tag_CHAR == typeKey || \
+               JDWP_Tag_DOUBLE == typeKey || \
+               JDWP_Tag_FLOAT == typeKey || \
+               JDWP_Tag_INT == typeKey || \
+               JDWP_Tag_LONG == typeKey || \
+               JDWP_Tag_SHORT == typeKey || \
+               JDWP_Tag_VOID == typeKey, \
+               "Tag is not a JVM basic type")
+
+static inline jbyte jdwpTag(const char *signature) {
+     JVM_TYPE_ASSERT(signature[0]);
+     return signature[0];
+}
+
+static inline jboolean isReferenceTag(jbyte typeKey) {
+    JVM_TYPE_ASSERT(typeKey);
+    return (typeKey == JDWP_TAG(OBJECT)) || (typeKey == JDWP_TAG(ARRAY)) || (typeKey == JDWP_TAG(INLINE_OBJECT));
+}
+
+static inline jboolean isArrayTag(jbyte typeKey) {
+    JVM_TYPE_ASSERT(typeKey);
+    return (typeKey == JDWP_TAG(ARRAY));
+}
+
+char* componentTypeSignature(const char *signature);
+
+void convertSignatureToClassname(char *convert);
+
+void methodSignature_init(char *signature, void **cursor);
+jboolean methodSignature_nextArgumentExists(void **cursor, jbyte *argumentTag);
+jbyte methodSignature_returnTag(char *signature);
+
+#endif
diff a/src/jdk.jdwp.agent/share/native/libjdwp/util.c b/src/jdk.jdwp.agent/share/native/libjdwp/util.c
--- a/src/jdk.jdwp.agent/share/native/libjdwp/util.c
+++ b/src/jdk.jdwp.agent/share/native/libjdwp/util.c
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -30,10 +30,12 @@
 #include "eventHandler.h"
 #include "threadControl.h"
 #include "outStream.h"
 #include "inStream.h"
 #include "invoker.h"
+#include "signature.h"
+
 
 /* Global data area */
 BackendGlobalData *gdata = NULL;
 
 /* Forward declarations */
@@ -169,10 +171,12 @@
         EXIT_ERROR(AGENT_ERROR_NULL_POINTER,NULL);
     }
     return method;
 }
 
+
+
 void
 util_initialize(JNIEnv *env)
 {
     WITH_LOCAL_REFS(env, 6) {
 
@@ -342,31 +346,28 @@
     error = fieldSignature(clazz, field, NULL, &signature, NULL);
     if (error != JVMTI_ERROR_NONE) {
         outStream_setError(out, map2jdwpError(error));
         return;
     }
-    typeKey = signature[0];
+    typeKey = jdwpTag(signature);
     jvmtiDeallocate(signature);
 
+    if (isReferenceTag(typeKey)) {
+
+        jobject value = JNI_FUNC_PTR(env,GetObjectField)(env, object, field);
+        (void)outStream_writeByte(out, specificTypeKey(env, value));
+        (void)outStream_writeObjectRef(env, out, value);
+        return;
+
+    }
+
     /*
-     * For primitive types, the type key is bounced back as is. Objects
-     * are handled in the switch statement below.
+     * For primitive types, the type key is bounced back as is.
      */
-    if ((typeKey != JDWP_TAG(OBJECT)) && (typeKey != JDWP_TAG(ARRAY)) && (typeKey != JDWP_TAG(INLINE_OBJECT))) {
-        (void)outStream_writeByte(out, typeKey);
-    }
+    (void)outStream_writeByte(out, typeKey);
 
     switch (typeKey) {
-        case JDWP_TAG(OBJECT):
-        case JDWP_TAG(ARRAY):
-        case JDWP_TAG(INLINE_OBJECT): {
-            jobject value = JNI_FUNC_PTR(env,GetObjectField)(env, object, field);
-            (void)outStream_writeByte(out, specificTypeKey(env, value));
-            (void)outStream_writeObjectRef(env, out, value);
-            break;
-        }
-
         case JDWP_TAG(BYTE):
             (void)outStream_writeByte(out,
                       JNI_FUNC_PTR(env,GetByteField)(env, object, field));
             break;
 
@@ -418,31 +419,28 @@
     error = fieldSignature(clazz, field, NULL, &signature, NULL);
     if (error != JVMTI_ERROR_NONE) {
         outStream_setError(out, map2jdwpError(error));
         return;
     }
-    typeKey = signature[0];
+    typeKey = jdwpTag(signature);
     jvmtiDeallocate(signature);
 
-    /*
-     * For primitive types, the type key is bounced back as is. Objects
-     * are handled in the switch statement below.
-     */
-    if ((typeKey != JDWP_TAG(OBJECT)) && (typeKey != JDWP_TAG(ARRAY)) && (typeKey != JDWP_TAG(INLINE_OBJECT))) {
-        (void)outStream_writeByte(out, typeKey);
+
+    if (isReferenceTag(typeKey)) {
+
+        jobject value = JNI_FUNC_PTR(env,GetStaticObjectField)(env, clazz, field);
+        (void)outStream_writeByte(out, specificTypeKey(env, value));
+        (void)outStream_writeObjectRef(env, out, value);
+
+        return;
     }
 
+    /*
+     * For primitive types, the type key is bounced back as is.
+     */
+    (void)outStream_writeByte(out, typeKey);
     switch (typeKey) {
-        case JDWP_TAG(OBJECT):
-        case JDWP_TAG(ARRAY):
-        case JDWP_TAG(INLINE_OBJECT): {
-            jobject value = JNI_FUNC_PTR(env,GetStaticObjectField)(env, clazz, field);
-            (void)outStream_writeByte(out, specificTypeKey(env, value));
-            (void)outStream_writeObjectRef(env, out, value);
-            break;
-        }
-
         case JDWP_TAG(BYTE):
             (void)outStream_writeByte(out,
                       JNI_FUNC_PTR(env,GetStaticByteField)(env, clazz, field));
             break;
 
@@ -571,11 +569,11 @@
         if (arguments == NULL) {
             outStream_setError(out, JDWP_ERROR(OUT_OF_MEMORY));
             return JNI_TRUE;
         }
         for (i = 0; (i < argumentCount) && !inStream_error(in); i++) {
-            arguments[i] = inStream_readValue(in, NULL);
+            arguments[i] = inStream_readValue(in);
         }
         if (inStream_error(in)) {
             return JNI_TRUE;
         }
     }
@@ -978,36 +976,10 @@
 {
     return JVMTI_FUNC_PTR(gdata->jvmti,GetSourceDebugExtension)
                 (gdata->jvmti, clazz, extensionPtr);
 }
 
-/*
- * Convert the signature "Ljava/lang/Foo;" to a
- * classname "java.lang.Foo" compatible with the pattern.
- * Signature is overwritten in-place.
- */
-void
-convertSignatureToClassname(char *convert)
-{
-    char *p;
-
-    p = convert + 1;
-    while ((*p != ';') && (*p != '\0')) {
-        char c = *p;
-        if (c == '/') {
-            *(p-1) = '.';
-        } else if (c == '.') {
-            // class signature of a hidden class is "Ljava/lang/Foo.1234;"
-            // map to "java.lang.Foo/1234"
-            *(p-1) = '/';
-        } else {
-            *(p-1) = c;
-        }
-        p++;
-    }
-    *(p-1) = '\0';
-}
 
 static void
 handleInterrupt(void)
 {
     /*
diff a/test/hotspot/jtreg/ProblemList.txt b/test/hotspot/jtreg/ProblemList.txt
--- a/test/hotspot/jtreg/ProblemList.txt
+++ b/test/hotspot/jtreg/ProblemList.txt
@@ -170,11 +170,12 @@
 
 # :hotspot_runtime
 
 runtime/jni/terminatedThread/TestTerminatedThread.java 8219652 aix-ppc64
 runtime/ReservedStack/ReservedStackTest.java 8231031 generic-all
-runtime/cds/DeterministicDump.java 8244536 windows-all 
+
+runtime/cds/appcds/SignedJar.java 8245264 generic-all
 
 # Valhalla TODO:
 runtime/CompressedOops/CompressedClassPointers.java 8210258 generic-all
 runtime/RedefineTests/RedefineLeak.java 8205032 generic-all
 runtime/SharedArchiveFile/BootAppendTests.java 8210258 generic-all
diff a/test/hotspot/jtreg/runtime/cds/appcds/dynamicArchive/DynamicArchiveRelocationTest.java b/test/hotspot/jtreg/runtime/cds/appcds/dynamicArchive/DynamicArchiveRelocationTest.java
--- a/test/hotspot/jtreg/runtime/cds/appcds/dynamicArchive/DynamicArchiveRelocationTest.java
+++ b/test/hotspot/jtreg/runtime/cds/appcds/dynamicArchive/DynamicArchiveRelocationTest.java
@@ -29,12 +29,14 @@
  * @summary Testing relocation of dynamic CDS archive (during both dump time and run time)
  * @comment JDK-8231610 Relocate the CDS archive if it cannot be mapped to the requested address
  * @bug 8231610
  * @library /test/lib /test/hotspot/jtreg/runtime/cds/appcds /test/hotspot/jtreg/runtime/cds/appcds/test-classes
  * @build HelloRelocation
+ * @build sun.hotspot.WhiteBox
  * @run driver ClassFileInstaller -jar hello.jar HelloRelocation HelloInlineClassApp HelloInlineClassApp$Point HelloInlineClassApp$Point$ref
- * @run driver DynamicArchiveRelocationTest
+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox sun.hotspot.WhiteBox$WhiteBoxPermission
+ * @run main/othervm -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath/a:. DynamicArchiveRelocationTest
  */
 
 import jdk.test.lib.process.OutputAnalyzer;
 import jtreg.SkippedException;
 
@@ -91,11 +93,11 @@
         String runtimeMsg = "Try to map archive(s) at an alternative address";
         String unlockArg = "-XX:+UnlockDiagnosticVMOptions";
 
         // (1) Dump base archive (static)
 
-        OutputAnalyzer out = dumpBaseArchive(baseArchiveName, unlockArg, dumpBaseRelocArg, logArg);
+        OutputAnalyzer out = TestCommon.dumpBaseArchive(baseArchiveName, unlockArg, dumpBaseRelocArg, logArg);
         if (dump_base_reloc) {
             out.shouldContain("ArchiveRelocationMode == 1: always allocate class space at an alternative address");
             out.shouldContain("Relocating archive from");
         }
 
diff a/test/lib/sun/hotspot/WhiteBox.java b/test/lib/sun/hotspot/WhiteBox.java
--- a/test/lib/sun/hotspot/WhiteBox.java
+++ b/test/lib/sun/hotspot/WhiteBox.java
@@ -625,6 +625,9 @@
 
   // Number of loaded AOT libraries
   public native int aotLibrariesCount();
 
   public native int getKlassMetadataSize(Class<?> c);
+
+  // ThreadSMR GC safety check for threadObj
+  public native void checkThreadObjOfTerminatingThread(Thread target);
 }
