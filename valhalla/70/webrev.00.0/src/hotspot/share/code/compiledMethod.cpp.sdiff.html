<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/code/compiledMethod.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../classfile/vmSymbols.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../compiler/compileBroker.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/code/compiledMethod.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
489         ShouldNotReachHere();
490       }
491     }
492   }
493 
494   return ic-&gt;set_to_clean();
495 }
496 
497 // Clean references to unloaded nmethods at addr from this one, which is not unloaded.
498 template &lt;class CompiledICorStaticCall&gt;
499 static bool clean_if_nmethod_is_unloaded(CompiledICorStaticCall *ic, address addr, CompiledMethod* from,
500                                          bool clean_all) {
501   // Ok, to lookup references to zombies here
502   CodeBlob *cb = CodeCache::find_blob_unsafe(addr);
503   CompiledMethod* nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
504   if (nm != NULL) {
505     // Clean inline caches pointing to both zombie and not_entrant methods
506     if (clean_all || !nm-&gt;is_in_use() || nm-&gt;is_unloading() || (nm-&gt;method()-&gt;code() != nm)) {
507       // Inline cache cleaning should only be initiated on CompiledMethods that have been
508       // observed to be is_alive(). However, with concurrent code cache unloading, it is
<span class="line-modified">509       // possible that by now, the state has been racingly flipped to unloaded if the nmethod</span>
<span class="line-modified">510       // being cleaned is_unloading(). This is fine, because if that happens, then the inline</span>

511       // caches have already been cleaned under the same CompiledICLocker that we now hold during
512       // inline cache cleaning, and we will simply walk the inline caches again, and likely not
513       // find much of interest to clean. However, this race prevents us from asserting that the
514       // nmethod is_alive(). The is_unloading() function is completely monotonic; once set due
515       // to an oop dying, it remains set forever until freed. Because of that, all unloaded
516       // nmethods are is_unloading(), but notably, an unloaded nmethod may also subsequently
<span class="line-modified">517       // become zombie (when the sweeper converts it to zombie). Therefore, the most precise</span>
<span class="line-modified">518       // sanity check we can check for in this context is to not allow zombies.</span>
<span class="line-modified">519       assert(!from-&gt;is_zombie(), &quot;should not clean inline caches on zombies&quot;);</span>





















520       if (!ic-&gt;set_to_clean(!from-&gt;is_unloading())) {
521         return false;
522       }
523       assert(ic-&gt;is_clean(), &quot;nmethod &quot; PTR_FORMAT &quot;not clean %s&quot;, p2i(from), from-&gt;method()-&gt;name_and_sig_as_C_string());
524     }
525   }
526   return true;
527 }
528 
529 static bool clean_if_nmethod_is_unloaded(CompiledIC *ic, CompiledMethod* from,
530                                          bool clean_all) {
531   return clean_if_nmethod_is_unloaded(ic, ic-&gt;ic_destination(), from, clean_all);
532 }
533 
534 static bool clean_if_nmethod_is_unloaded(CompiledStaticCall *csc, CompiledMethod* from,
535                                          bool clean_all) {
536   return clean_if_nmethod_is_unloaded(csc, csc-&gt;destination(), from, clean_all);
537 }
538 
539 // Cleans caches in nmethods that point to either classes that are unloaded
</pre>
</td>
<td>
<hr />
<pre>
489         ShouldNotReachHere();
490       }
491     }
492   }
493 
494   return ic-&gt;set_to_clean();
495 }
496 
497 // Clean references to unloaded nmethods at addr from this one, which is not unloaded.
498 template &lt;class CompiledICorStaticCall&gt;
499 static bool clean_if_nmethod_is_unloaded(CompiledICorStaticCall *ic, address addr, CompiledMethod* from,
500                                          bool clean_all) {
501   // Ok, to lookup references to zombies here
502   CodeBlob *cb = CodeCache::find_blob_unsafe(addr);
503   CompiledMethod* nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
504   if (nm != NULL) {
505     // Clean inline caches pointing to both zombie and not_entrant methods
506     if (clean_all || !nm-&gt;is_in_use() || nm-&gt;is_unloading() || (nm-&gt;method()-&gt;code() != nm)) {
507       // Inline cache cleaning should only be initiated on CompiledMethods that have been
508       // observed to be is_alive(). However, with concurrent code cache unloading, it is
<span class="line-modified">509       // possible that by now, the state has become !is_alive. This can happen in two ways:</span>
<span class="line-modified">510       // 1) It can be racingly flipped to unloaded if the nmethod // being cleaned (from the</span>
<span class="line-added">511       // sweeper) is_unloading(). This is fine, because if that happens, then the inline</span>
512       // caches have already been cleaned under the same CompiledICLocker that we now hold during
513       // inline cache cleaning, and we will simply walk the inline caches again, and likely not
514       // find much of interest to clean. However, this race prevents us from asserting that the
515       // nmethod is_alive(). The is_unloading() function is completely monotonic; once set due
516       // to an oop dying, it remains set forever until freed. Because of that, all unloaded
517       // nmethods are is_unloading(), but notably, an unloaded nmethod may also subsequently
<span class="line-modified">518       // become zombie (when the sweeper converts it to zombie).</span>
<span class="line-modified">519       // 2) It can be racingly flipped to zombie if the nmethod being cleaned (by the concurrent</span>
<span class="line-modified">520       // GC) cleans a zombie nmethod that is concurrently made zombie by the sweeper. In this</span>
<span class="line-added">521       // scenario, the sweeper will first transition the nmethod to zombie, and then when</span>
<span class="line-added">522       // unregistering from the GC, it will wait until the GC is done. The GC will then clean</span>
<span class="line-added">523       // the inline caches *with IC stubs*, even though no IC stubs are needed. This is fine,</span>
<span class="line-added">524       // as long as the IC stubs are guaranteed to be released until the next safepoint, where</span>
<span class="line-added">525       // IC finalization requires live IC stubs to not be associated with zombie nmethods.</span>
<span class="line-added">526       // This is guaranteed, because the sweeper does not have a single safepoint check until</span>
<span class="line-added">527       // after it completes the whole transition function; it will wake up after the GC is</span>
<span class="line-added">528       // done with concurrent code cache cleaning (which blocks out safepoints using the</span>
<span class="line-added">529       // suspendible threads set), and then call clear_ic_callsites, which will release the</span>
<span class="line-added">530       // associated IC stubs, before a subsequent safepoint poll can be reached. This</span>
<span class="line-added">531       // guarantees that the spuriously created IC stubs are released appropriately before</span>
<span class="line-added">532       // IC finalization in a safepoint gets to run. Therefore, this race is fine. This is also</span>
<span class="line-added">533       // valid in a scenario where an inline cache of a zombie nmethod gets a spurious IC stub,</span>
<span class="line-added">534       // and then when cleaning another inline cache, fails to request an IC stub because we</span>
<span class="line-added">535       // exhausted the IC stub buffer. In this scenario, the GC will request a safepoint after</span>
<span class="line-added">536       // yielding the suspendible therad set, effectively unblocking safepoints. Before such</span>
<span class="line-added">537       // a safepoint can be reached, the sweeper similarly has to wake up, clear the IC stubs,</span>
<span class="line-added">538       // and reach the next safepoint poll, after the whole transition function has completed.</span>
<span class="line-added">539       // Due to the various races that can cause an nmethod to first be is_alive() and then</span>
<span class="line-added">540       // racingly become !is_alive(), it is unfortunately not possible to assert the nmethod</span>
<span class="line-added">541       // is_alive(), !is_unloaded() or !is_zombie() here.</span>
542       if (!ic-&gt;set_to_clean(!from-&gt;is_unloading())) {
543         return false;
544       }
545       assert(ic-&gt;is_clean(), &quot;nmethod &quot; PTR_FORMAT &quot;not clean %s&quot;, p2i(from), from-&gt;method()-&gt;name_and_sig_as_C_string());
546     }
547   }
548   return true;
549 }
550 
551 static bool clean_if_nmethod_is_unloaded(CompiledIC *ic, CompiledMethod* from,
552                                          bool clean_all) {
553   return clean_if_nmethod_is_unloaded(ic, ic-&gt;ic_destination(), from, clean_all);
554 }
555 
556 static bool clean_if_nmethod_is_unloaded(CompiledStaticCall *csc, CompiledMethod* from,
557                                          bool clean_all) {
558   return clean_if_nmethod_is_unloaded(csc, csc-&gt;destination(), from, clean_all);
559 }
560 
561 // Cleans caches in nmethods that point to either classes that are unloaded
</pre>
</td>
</tr>
</table>
<center><a href="../classfile/vmSymbols.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../compiler/compileBroker.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>