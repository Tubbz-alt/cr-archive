<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../ppc/globals_ppc.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  29 #include &quot;jvm.h&quot;
  30 #include &quot;asm/assembler.hpp&quot;
  31 #include &quot;asm/assembler.inline.hpp&quot;
  32 #include &quot;gc/shared/barrierSet.hpp&quot;
  33 #include &quot;gc/shared/cardTable.hpp&quot;
  34 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  35 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;compiler/disassembler.hpp&quot;
  38 #include &quot;memory/resourceArea.hpp&quot;
  39 #include &quot;memory/universe.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/accessDecorators.hpp&quot;
  42 #include &quot;oops/compressedOops.inline.hpp&quot;
  43 #include &quot;oops/klass.inline.hpp&quot;
  44 #include &quot;runtime/biasedLocking.hpp&quot;
  45 #include &quot;runtime/icache.hpp&quot;
  46 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  47 #include &quot;runtime/jniHandles.inline.hpp&quot;
  48 #include &quot;runtime/sharedRuntime.hpp&quot;

  49 #include &quot;runtime/thread.hpp&quot;
  50 #include &quot;utilities/powerOfTwo.hpp&quot;
  51 #ifdef COMPILER1
  52 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  53 #endif
  54 #ifdef COMPILER2
  55 #include &quot;oops/oop.hpp&quot;
  56 #include &quot;opto/compile.hpp&quot;
  57 #include &quot;opto/node.hpp&quot;
  58 #include &quot;opto/output.hpp&quot;
  59 #endif
  60 
  61 #ifdef PRODUCT
  62 #define BLOCK_COMMENT(str) /* nothing */
  63 #define STOP(error) stop(error)
  64 #else
  65 #define BLOCK_COMMENT(str) block_comment(str)
  66 #define STOP(error) block_comment(error); stop(error)
  67 #endif
  68 
</pre>
<hr />
<pre>
1299   ldrb(scratch, Address(klass, InstanceKlass::init_state_offset()));
1300   subs(zr, scratch, InstanceKlass::fully_initialized);
1301   br(Assembler::EQ, *L_fast_path);
1302 
1303   // Fast path check: current thread is initializer thread
1304   ldr(scratch, Address(klass, InstanceKlass::init_thread_offset()));
1305   cmp(rthread, scratch);
1306 
1307   if (L_slow_path == &amp;L_fallthrough) {
1308     br(Assembler::EQ, *L_fast_path);
1309     bind(*L_slow_path);
1310   } else if (L_fast_path == &amp;L_fallthrough) {
1311     br(Assembler::NE, *L_slow_path);
1312     bind(*L_fast_path);
1313   } else {
1314     Unimplemented();
1315   }
1316 }
1317 
1318 void MacroAssembler::verify_oop(Register reg, const char* s) {
<span class="line-modified">1319   if (!VerifyOops) return;</span>




1320 
1321   // Pass register number to verify_oop_subroutine
1322   const char* b = NULL;
1323   {
1324     ResourceMark rm;
1325     stringStream ss;
1326     ss.print(&quot;verify_oop: %s: %s&quot;, reg-&gt;name(), s);
1327     b = code_string(ss.as_string());
1328   }
1329   BLOCK_COMMENT(&quot;verify_oop {&quot;);
1330 
1331   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1332   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1333 
1334   mov(r0, reg);
1335   mov(rscratch1, (address)b);
1336 
1337   // call indirectly to solve generation ordering problem
1338   lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));
1339   ldr(rscratch2, Address(rscratch2));
1340   blr(rscratch2);
1341 
1342   ldp(rscratch2, lr, Address(post(sp, 2 * wordSize)));
1343   ldp(r0, rscratch1, Address(post(sp, 2 * wordSize)));
1344 
1345   BLOCK_COMMENT(&quot;} verify_oop&quot;);
1346 }
1347 
1348 void MacroAssembler::verify_oop_addr(Address addr, const char* s) {
<span class="line-modified">1349   if (!VerifyOops) return;</span>




1350 
1351   const char* b = NULL;
1352   {
1353     ResourceMark rm;
1354     stringStream ss;
1355     ss.print(&quot;verify_oop_addr: %s&quot;, s);
1356     b = code_string(ss.as_string());
1357   }
1358   BLOCK_COMMENT(&quot;verify_oop_addr {&quot;);
1359 
1360   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1361   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1362 
1363   // addr may contain sp so we will have to adjust it based on the
1364   // pushes that we just did.
1365   if (addr.uses(sp)) {
1366     lea(r0, addr);
1367     ldr(r0, Address(r0, 4 * wordSize));
1368   } else {
1369     ldr(r0, addr);
</pre>
<hr />
<pre>
1422 
1423 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0) {
1424   pass_arg0(this, arg_0);
1425   call_VM_leaf_base(entry_point, 1);
1426 }
1427 
1428 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1429   pass_arg0(this, arg_0);
1430   pass_arg1(this, arg_1);
1431   call_VM_leaf_base(entry_point, 2);
1432 }
1433 
1434 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0,
1435                                   Register arg_1, Register arg_2) {
1436   pass_arg0(this, arg_0);
1437   pass_arg1(this, arg_1);
1438   pass_arg2(this, arg_2);
1439   call_VM_leaf_base(entry_point, 3);
1440 }
1441 




1442 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1443   pass_arg0(this, arg_0);
1444   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1445 }
1446 
1447 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1448 
1449   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1450   pass_arg1(this, arg_1);
1451   pass_arg0(this, arg_0);
1452   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1453 }
1454 
1455 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1456   assert(arg_0 != c_rarg2, &quot;smashed arg&quot;);
1457   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1458   pass_arg2(this, arg_2);
1459   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1460   pass_arg1(this, arg_1);
1461   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
1471   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1472   pass_arg2(this, arg_2);
1473   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1474   pass_arg1(this, arg_1);
1475   pass_arg0(this, arg_0);
1476   MacroAssembler::call_VM_leaf_base(entry_point, 4);
1477 }
1478 
1479 void MacroAssembler::null_check(Register reg, int offset) {
1480   if (needs_explicit_null_check(offset)) {
1481     // provoke OS NULL exception if reg = NULL by
1482     // accessing M[reg] w/o changing any registers
1483     // NOTE: this is plenty to provoke a segv
1484     ldr(zr, Address(reg));
1485   } else {
1486     // nothing to do, (later) access of M[reg + offset]
1487     // will provoke OS NULL exception if reg = NULL
1488   }
1489 }
1490 

































1491 // MacroAssembler protected routines needed to implement
1492 // public methods
1493 
1494 void MacroAssembler::mov(Register r, Address dest) {
1495   code_section()-&gt;relocate(pc(), dest.rspec());
1496   u_int64_t imm64 = (u_int64_t)dest.target();
1497   movptr(r, imm64);
1498 }
1499 
1500 // Move a constant pointer into r.  In AArch64 mode the virtual
1501 // address space is 48 bits in size, so we only need three
1502 // instructions to create a patchable instruction sequence that can
1503 // reach anywhere.
1504 void MacroAssembler::movptr(Register r, uintptr_t imm64) {
1505 #ifndef PRODUCT
1506   {
1507     char buffer[64];
1508     snprintf(buffer, sizeof(buffer), &quot;0x%&quot; PRIX64, imm64);
1509     block_comment(buffer);
1510   }
</pre>
<hr />
<pre>
3682 }
3683 
3684 void MacroAssembler::cmpptr(Register src1, Address src2) {
3685   unsigned long offset;
3686   adrp(rscratch1, src2, offset);
3687   ldr(rscratch1, Address(rscratch1, offset));
3688   cmp(src1, rscratch1);
3689 }
3690 
3691 void MacroAssembler::cmpoop(Register obj1, Register obj2) {
3692   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3693   bs-&gt;obj_equals(this, obj1, obj2);
3694 }
3695 
3696 void MacroAssembler::load_method_holder(Register holder, Register method) {
3697   ldr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
3698   ldr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
3699   ldr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
3700 }
3701 
<span class="line-modified">3702 void MacroAssembler::load_klass(Register dst, Register src) {</span>
3703   if (UseCompressedClassPointers) {
3704     ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));
<span class="line-removed">3705     decode_klass_not_null(dst);</span>
3706   } else {
3707     ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
3708   }
3709 }
3710 










3711 // ((OopHandle)result).resolve();
3712 void MacroAssembler::resolve_oop_handle(Register result, Register tmp) {
3713   // OopHandle::resolve is an indirection.
3714   access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp, noreg);
3715 }
3716 
3717 void MacroAssembler::load_mirror(Register dst, Register method, Register tmp) {
3718   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
3719   ldr(dst, Address(rmethod, Method::const_offset()));
3720   ldr(dst, Address(dst, ConstMethod::constants_offset()));
3721   ldr(dst, Address(dst, ConstantPool::pool_holder_offset_in_bytes()));
3722   ldr(dst, Address(dst, mirror_offset));
3723   resolve_oop_handle(dst, tmp);
3724 }
3725 









3726 void MacroAssembler::cmp_klass(Register oop, Register trial_klass, Register tmp) {
3727   if (UseCompressedClassPointers) {
3728     ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3729     if (CompressedKlassPointers::base() == NULL) {
3730       cmp(trial_klass, tmp, LSL, CompressedKlassPointers::shift());
3731       return;
3732     } else if (((uint64_t)CompressedKlassPointers::base() &amp; 0xffffffff) == 0
3733                &amp;&amp; CompressedKlassPointers::shift() == 0) {
3734       // Only the bottom 32 bits matter
3735       cmpw(trial_klass, tmp);
3736       return;
3737     }
3738     decode_klass_not_null(tmp);
3739   } else {
3740     ldr(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3741   }
3742   cmp(trial_klass, tmp);
3743 }
3744 
3745 void MacroAssembler::load_prototype_header(Register dst, Register src) {
</pre>
<hr />
<pre>
4043   narrowKlass nk = CompressedKlassPointers::encode(k);
4044   movz(dst, (nk &gt;&gt; 16), 16);
4045   movk(dst, nk &amp; 0xffff);
4046 }
4047 
4048 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators,
4049                                     Register dst, Address src,
4050                                     Register tmp1, Register thread_tmp) {
4051   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4052   decorators = AccessInternal::decorator_fixup(decorators);
4053   bool as_raw = (decorators &amp; AS_RAW) != 0;
4054   if (as_raw) {
4055     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4056   } else {
4057     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4058   }
4059 }
4060 
4061 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators,
4062                                      Address dst, Register src,
<span class="line-modified">4063                                      Register tmp1, Register thread_tmp) {</span>

4064   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4065   decorators = AccessInternal::decorator_fixup(decorators);
4066   bool as_raw = (decorators &amp; AS_RAW) != 0;
4067   if (as_raw) {
<span class="line-modified">4068     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp);</span>
4069   } else {
<span class="line-modified">4070     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, thread_tmp);</span>
4071   }
4072 }
4073 
4074 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4075   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4076   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4077     decorators |= ACCESS_READ | ACCESS_WRITE;
4078   }
4079   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4080   return bs-&gt;resolve(this, decorators, obj);
4081 }
4082 
4083 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4084                                    Register thread_tmp, DecoratorSet decorators) {
4085   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4086 }
4087 
4088 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4089                                             Register thread_tmp, DecoratorSet decorators) {
4090   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4091 }
4092 
4093 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4094                                     Register thread_tmp, DecoratorSet decorators) {</span>
<span class="line-modified">4095   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);</span>
4096 }
4097 
4098 // Used for storing NULLs.
4099 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4100   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
4101 }
4102 
4103 Address MacroAssembler::allocate_metadata_address(Metadata* obj) {
4104   assert(oop_recorder() != NULL, &quot;this assembler needs a Recorder&quot;);
4105   int index = oop_recorder()-&gt;allocate_metadata_index(obj);
4106   RelocationHolder rspec = metadata_Relocation::spec(index);
4107   return Address((address)obj, rspec);
4108 }
4109 
4110 // Move an oop into a register.  immediate is true if we want
4111 // immediate instrcutions, i.e. we are not going to patch this
4112 // instruction while the code is being executed by another thread.  In
4113 // that case we can use move immediates rather than the constant pool.
4114 void MacroAssembler::movoop(Register dst, jobject obj, bool immediate) {
4115   int oop_index;
4116   if (obj == NULL) {
4117     oop_index = oop_recorder()-&gt;allocate_oop_index(obj);
4118   } else {
4119 #ifdef ASSERT
4120     {
</pre>
<hr />
<pre>
5148 // get_thread() can be called anywhere inside generated code so we
5149 // need to save whatever non-callee save context might get clobbered
5150 // by the call to JavaThread::aarch64_get_thread_helper() or, indeed,
5151 // the call setup code.
5152 //
5153 // aarch64_get_thread_helper() clobbers only r0, r1, and flags.
5154 //
5155 void MacroAssembler::get_thread(Register dst) {
5156   RegSet saved_regs = RegSet::range(r0, r1) + lr - dst;
5157   push(saved_regs, sp);
5158 
5159   mov(lr, CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper));
5160   blr(lr);
5161   if (dst != c_rarg0) {
5162     mov(dst, c_rarg0);
5163   }
5164 
5165   pop(saved_regs, sp);
5166 }
5167 






































































































































































































































































































































































































5168 void MacroAssembler::cache_wb(Address line) {
5169   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5170   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5171   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5172   // would like to assert this
5173   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5174   if (VM_Version::supports_dcpop()) {
5175     // writeback using clear virtual address to point of persistence
5176     dc(Assembler::CVAP, line.base());
5177   } else {
5178     // no need to generate anything as Unsafe.writebackMemory should
5179     // never invoke this stub
5180   }
5181 }
5182 
5183 void MacroAssembler::cache_wbsync(bool is_pre) {
5184   // we only need a barrier post sync
5185   if (!is_pre) {
5186     membar(Assembler::AnyAny);
5187   }
</pre>
</td>
<td>
<hr />
<pre>
  29 #include &quot;jvm.h&quot;
  30 #include &quot;asm/assembler.hpp&quot;
  31 #include &quot;asm/assembler.inline.hpp&quot;
  32 #include &quot;gc/shared/barrierSet.hpp&quot;
  33 #include &quot;gc/shared/cardTable.hpp&quot;
  34 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  35 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;compiler/disassembler.hpp&quot;
  38 #include &quot;memory/resourceArea.hpp&quot;
  39 #include &quot;memory/universe.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/accessDecorators.hpp&quot;
  42 #include &quot;oops/compressedOops.inline.hpp&quot;
  43 #include &quot;oops/klass.inline.hpp&quot;
  44 #include &quot;runtime/biasedLocking.hpp&quot;
  45 #include &quot;runtime/icache.hpp&quot;
  46 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  47 #include &quot;runtime/jniHandles.inline.hpp&quot;
  48 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  49 #include &quot;runtime/signature_cc.hpp&quot;</span>
  50 #include &quot;runtime/thread.hpp&quot;
  51 #include &quot;utilities/powerOfTwo.hpp&quot;
  52 #ifdef COMPILER1
  53 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  54 #endif
  55 #ifdef COMPILER2
  56 #include &quot;oops/oop.hpp&quot;
  57 #include &quot;opto/compile.hpp&quot;
  58 #include &quot;opto/node.hpp&quot;
  59 #include &quot;opto/output.hpp&quot;
  60 #endif
  61 
  62 #ifdef PRODUCT
  63 #define BLOCK_COMMENT(str) /* nothing */
  64 #define STOP(error) stop(error)
  65 #else
  66 #define BLOCK_COMMENT(str) block_comment(str)
  67 #define STOP(error) block_comment(error); stop(error)
  68 #endif
  69 
</pre>
<hr />
<pre>
1300   ldrb(scratch, Address(klass, InstanceKlass::init_state_offset()));
1301   subs(zr, scratch, InstanceKlass::fully_initialized);
1302   br(Assembler::EQ, *L_fast_path);
1303 
1304   // Fast path check: current thread is initializer thread
1305   ldr(scratch, Address(klass, InstanceKlass::init_thread_offset()));
1306   cmp(rthread, scratch);
1307 
1308   if (L_slow_path == &amp;L_fallthrough) {
1309     br(Assembler::EQ, *L_fast_path);
1310     bind(*L_slow_path);
1311   } else if (L_fast_path == &amp;L_fallthrough) {
1312     br(Assembler::NE, *L_slow_path);
1313     bind(*L_fast_path);
1314   } else {
1315     Unimplemented();
1316   }
1317 }
1318 
1319 void MacroAssembler::verify_oop(Register reg, const char* s) {
<span class="line-modified">1320   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">1321     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">1322     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">1323     return;</span>
<span class="line-added">1324   }</span>
1325 
1326   // Pass register number to verify_oop_subroutine
1327   const char* b = NULL;
1328   {
1329     ResourceMark rm;
1330     stringStream ss;
1331     ss.print(&quot;verify_oop: %s: %s&quot;, reg-&gt;name(), s);
1332     b = code_string(ss.as_string());
1333   }
1334   BLOCK_COMMENT(&quot;verify_oop {&quot;);
1335 
1336   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1337   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1338 
1339   mov(r0, reg);
1340   mov(rscratch1, (address)b);
1341 
1342   // call indirectly to solve generation ordering problem
1343   lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));
1344   ldr(rscratch2, Address(rscratch2));
1345   blr(rscratch2);
1346 
1347   ldp(rscratch2, lr, Address(post(sp, 2 * wordSize)));
1348   ldp(r0, rscratch1, Address(post(sp, 2 * wordSize)));
1349 
1350   BLOCK_COMMENT(&quot;} verify_oop&quot;);
1351 }
1352 
1353 void MacroAssembler::verify_oop_addr(Address addr, const char* s) {
<span class="line-modified">1354   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">1355     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">1356     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">1357     return;</span>
<span class="line-added">1358   }</span>
1359 
1360   const char* b = NULL;
1361   {
1362     ResourceMark rm;
1363     stringStream ss;
1364     ss.print(&quot;verify_oop_addr: %s&quot;, s);
1365     b = code_string(ss.as_string());
1366   }
1367   BLOCK_COMMENT(&quot;verify_oop_addr {&quot;);
1368 
1369   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1370   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1371 
1372   // addr may contain sp so we will have to adjust it based on the
1373   // pushes that we just did.
1374   if (addr.uses(sp)) {
1375     lea(r0, addr);
1376     ldr(r0, Address(r0, 4 * wordSize));
1377   } else {
1378     ldr(r0, addr);
</pre>
<hr />
<pre>
1431 
1432 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0) {
1433   pass_arg0(this, arg_0);
1434   call_VM_leaf_base(entry_point, 1);
1435 }
1436 
1437 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1438   pass_arg0(this, arg_0);
1439   pass_arg1(this, arg_1);
1440   call_VM_leaf_base(entry_point, 2);
1441 }
1442 
1443 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0,
1444                                   Register arg_1, Register arg_2) {
1445   pass_arg0(this, arg_0);
1446   pass_arg1(this, arg_1);
1447   pass_arg2(this, arg_2);
1448   call_VM_leaf_base(entry_point, 3);
1449 }
1450 
<span class="line-added">1451 void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="line-added">1452   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="line-added">1453 }</span>
<span class="line-added">1454 </span>
1455 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1456   pass_arg0(this, arg_0);
1457   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1458 }
1459 
1460 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1461 
1462   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1463   pass_arg1(this, arg_1);
1464   pass_arg0(this, arg_0);
1465   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1466 }
1467 
1468 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1469   assert(arg_0 != c_rarg2, &quot;smashed arg&quot;);
1470   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1471   pass_arg2(this, arg_2);
1472   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1473   pass_arg1(this, arg_1);
1474   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
1484   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1485   pass_arg2(this, arg_2);
1486   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1487   pass_arg1(this, arg_1);
1488   pass_arg0(this, arg_0);
1489   MacroAssembler::call_VM_leaf_base(entry_point, 4);
1490 }
1491 
1492 void MacroAssembler::null_check(Register reg, int offset) {
1493   if (needs_explicit_null_check(offset)) {
1494     // provoke OS NULL exception if reg = NULL by
1495     // accessing M[reg] w/o changing any registers
1496     // NOTE: this is plenty to provoke a segv
1497     ldr(zr, Address(reg));
1498   } else {
1499     // nothing to do, (later) access of M[reg + offset]
1500     // will provoke OS NULL exception if reg = NULL
1501   }
1502 }
1503 
<span class="line-added">1504 void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="line-added">1505   ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="line-added">1506   andr(temp_reg, temp_reg, JVM_ACC_VALUE);</span>
<span class="line-added">1507   cbnz(temp_reg, is_value);</span>
<span class="line-added">1508 }</span>
<span class="line-added">1509 </span>
<span class="line-added">1510 void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="line-added">1511   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1512   tbnz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, is_flattenable);</span>
<span class="line-added">1513 }</span>
<span class="line-added">1514 </span>
<span class="line-added">1515 void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; not_flattenable) {</span>
<span class="line-added">1516   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1517   tbz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, not_flattenable);</span>
<span class="line-added">1518 }</span>
<span class="line-added">1519 </span>
<span class="line-added">1520 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="line-added">1521   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1522   tbnz(flags, ConstantPoolCacheEntry::is_flattened_field_shift, is_flattened);</span>
<span class="line-added">1523 }</span>
<span class="line-added">1524 </span>
<span class="line-added">1525 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label&amp; is_flattened_array) {</span>
<span class="line-added">1526   load_storage_props(temp_reg, oop);</span>
<span class="line-added">1527   andr(temp_reg, temp_reg, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">1528   cbnz(temp_reg, is_flattened_array);</span>
<span class="line-added">1529 }</span>
<span class="line-added">1530 </span>
<span class="line-added">1531 void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp; is_null_free_array) {</span>
<span class="line-added">1532   load_storage_props(temp_reg, oop);</span>
<span class="line-added">1533   andr(temp_reg, temp_reg, ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1534   cbnz(temp_reg, is_null_free_array);</span>
<span class="line-added">1535 }</span>
<span class="line-added">1536 </span>
1537 // MacroAssembler protected routines needed to implement
1538 // public methods
1539 
1540 void MacroAssembler::mov(Register r, Address dest) {
1541   code_section()-&gt;relocate(pc(), dest.rspec());
1542   u_int64_t imm64 = (u_int64_t)dest.target();
1543   movptr(r, imm64);
1544 }
1545 
1546 // Move a constant pointer into r.  In AArch64 mode the virtual
1547 // address space is 48 bits in size, so we only need three
1548 // instructions to create a patchable instruction sequence that can
1549 // reach anywhere.
1550 void MacroAssembler::movptr(Register r, uintptr_t imm64) {
1551 #ifndef PRODUCT
1552   {
1553     char buffer[64];
1554     snprintf(buffer, sizeof(buffer), &quot;0x%&quot; PRIX64, imm64);
1555     block_comment(buffer);
1556   }
</pre>
<hr />
<pre>
3728 }
3729 
3730 void MacroAssembler::cmpptr(Register src1, Address src2) {
3731   unsigned long offset;
3732   adrp(rscratch1, src2, offset);
3733   ldr(rscratch1, Address(rscratch1, offset));
3734   cmp(src1, rscratch1);
3735 }
3736 
3737 void MacroAssembler::cmpoop(Register obj1, Register obj2) {
3738   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3739   bs-&gt;obj_equals(this, obj1, obj2);
3740 }
3741 
3742 void MacroAssembler::load_method_holder(Register holder, Register method) {
3743   ldr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
3744   ldr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
3745   ldr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
3746 }
3747 
<span class="line-modified">3748 void MacroAssembler::load_metadata(Register dst, Register src) {</span>
3749   if (UseCompressedClassPointers) {
3750     ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));

3751   } else {
3752     ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
3753   }
3754 }
3755 
<span class="line-added">3756 void MacroAssembler::load_klass(Register dst, Register src) {</span>
<span class="line-added">3757   load_metadata(dst, src);</span>
<span class="line-added">3758   if (UseCompressedClassPointers) {</span>
<span class="line-added">3759     andr(dst, dst, oopDesc::compressed_klass_mask());</span>
<span class="line-added">3760     decode_klass_not_null(dst);</span>
<span class="line-added">3761   } else {</span>
<span class="line-added">3762     ubfm(dst, dst, 0, 63 - oopDesc::storage_props_nof_bits);</span>
<span class="line-added">3763   }</span>
<span class="line-added">3764 }</span>
<span class="line-added">3765 </span>
3766 // ((OopHandle)result).resolve();
3767 void MacroAssembler::resolve_oop_handle(Register result, Register tmp) {
3768   // OopHandle::resolve is an indirection.
3769   access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp, noreg);
3770 }
3771 
3772 void MacroAssembler::load_mirror(Register dst, Register method, Register tmp) {
3773   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
3774   ldr(dst, Address(rmethod, Method::const_offset()));
3775   ldr(dst, Address(dst, ConstMethod::constants_offset()));
3776   ldr(dst, Address(dst, ConstantPool::pool_holder_offset_in_bytes()));
3777   ldr(dst, Address(dst, mirror_offset));
3778   resolve_oop_handle(dst, tmp);
3779 }
3780 
<span class="line-added">3781 void MacroAssembler::load_storage_props(Register dst, Register src) {</span>
<span class="line-added">3782   load_metadata(dst, src);</span>
<span class="line-added">3783   if (UseCompressedClassPointers) {</span>
<span class="line-added">3784     asrw(dst, dst, oopDesc::narrow_storage_props_shift);</span>
<span class="line-added">3785   } else {</span>
<span class="line-added">3786     asr(dst, dst, oopDesc::wide_storage_props_shift);</span>
<span class="line-added">3787   }</span>
<span class="line-added">3788 }</span>
<span class="line-added">3789 </span>
3790 void MacroAssembler::cmp_klass(Register oop, Register trial_klass, Register tmp) {
3791   if (UseCompressedClassPointers) {
3792     ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3793     if (CompressedKlassPointers::base() == NULL) {
3794       cmp(trial_klass, tmp, LSL, CompressedKlassPointers::shift());
3795       return;
3796     } else if (((uint64_t)CompressedKlassPointers::base() &amp; 0xffffffff) == 0
3797                &amp;&amp; CompressedKlassPointers::shift() == 0) {
3798       // Only the bottom 32 bits matter
3799       cmpw(trial_klass, tmp);
3800       return;
3801     }
3802     decode_klass_not_null(tmp);
3803   } else {
3804     ldr(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3805   }
3806   cmp(trial_klass, tmp);
3807 }
3808 
3809 void MacroAssembler::load_prototype_header(Register dst, Register src) {
</pre>
<hr />
<pre>
4107   narrowKlass nk = CompressedKlassPointers::encode(k);
4108   movz(dst, (nk &gt;&gt; 16), 16);
4109   movk(dst, nk &amp; 0xffff);
4110 }
4111 
4112 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators,
4113                                     Register dst, Address src,
4114                                     Register tmp1, Register thread_tmp) {
4115   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4116   decorators = AccessInternal::decorator_fixup(decorators);
4117   bool as_raw = (decorators &amp; AS_RAW) != 0;
4118   if (as_raw) {
4119     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4120   } else {
4121     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4122   }
4123 }
4124 
4125 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators,
4126                                      Address dst, Register src,
<span class="line-modified">4127                                      Register tmp1, Register thread_tmp, Register tmp3) {</span>
<span class="line-added">4128 </span>
4129   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4130   decorators = AccessInternal::decorator_fixup(decorators);
4131   bool as_raw = (decorators &amp; AS_RAW) != 0;
4132   if (as_raw) {
<span class="line-modified">4133     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);</span>
4134   } else {
<span class="line-modified">4135     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);</span>
4136   }
4137 }
4138 
4139 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4140   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4141   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4142     decorators |= ACCESS_READ | ACCESS_WRITE;
4143   }
4144   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4145   return bs-&gt;resolve(this, decorators, obj);
4146 }
4147 
4148 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4149                                    Register thread_tmp, DecoratorSet decorators) {
4150   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4151 }
4152 
4153 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4154                                             Register thread_tmp, DecoratorSet decorators) {
4155   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4156 }
4157 
4158 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4159                                     Register thread_tmp, Register tmp3, DecoratorSet decorators) {</span>
<span class="line-modified">4160   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp, tmp3);</span>
4161 }
4162 
4163 // Used for storing NULLs.
4164 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4165   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
4166 }
4167 
4168 Address MacroAssembler::allocate_metadata_address(Metadata* obj) {
4169   assert(oop_recorder() != NULL, &quot;this assembler needs a Recorder&quot;);
4170   int index = oop_recorder()-&gt;allocate_metadata_index(obj);
4171   RelocationHolder rspec = metadata_Relocation::spec(index);
4172   return Address((address)obj, rspec);
4173 }
4174 
4175 // Move an oop into a register.  immediate is true if we want
4176 // immediate instrcutions, i.e. we are not going to patch this
4177 // instruction while the code is being executed by another thread.  In
4178 // that case we can use move immediates rather than the constant pool.
4179 void MacroAssembler::movoop(Register dst, jobject obj, bool immediate) {
4180   int oop_index;
4181   if (obj == NULL) {
4182     oop_index = oop_recorder()-&gt;allocate_oop_index(obj);
4183   } else {
4184 #ifdef ASSERT
4185     {
</pre>
<hr />
<pre>
5213 // get_thread() can be called anywhere inside generated code so we
5214 // need to save whatever non-callee save context might get clobbered
5215 // by the call to JavaThread::aarch64_get_thread_helper() or, indeed,
5216 // the call setup code.
5217 //
5218 // aarch64_get_thread_helper() clobbers only r0, r1, and flags.
5219 //
5220 void MacroAssembler::get_thread(Register dst) {
5221   RegSet saved_regs = RegSet::range(r0, r1) + lr - dst;
5222   push(saved_regs, sp);
5223 
5224   mov(lr, CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper));
5225   blr(lr);
5226   if (dst != c_rarg0) {
5227     mov(dst, c_rarg0);
5228   }
5229 
5230   pop(saved_regs, sp);
5231 }
5232 
<span class="line-added">5233 // C2 compiled method&#39;s prolog code</span>
<span class="line-added">5234 // Moved here from aarch64.ad to support Valhalla code belows</span>
<span class="line-added">5235 void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="line-added">5236 </span>
<span class="line-added">5237 // n.b. frame size includes space for return pc and rfp</span>
<span class="line-added">5238   const long framesize = C-&gt;frame_size_in_bytes();</span>
<span class="line-added">5239   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2 * wordSize alignment&quot;);</span>
<span class="line-added">5240 </span>
<span class="line-added">5241   // insert a nop at the start of the prolog so we can patch in a</span>
<span class="line-added">5242   // branch if we need to invalidate the method later</span>
<span class="line-added">5243   nop();</span>
<span class="line-added">5244 </span>
<span class="line-added">5245   int bangsize = C-&gt;bang_size_in_bytes();</span>
<span class="line-added">5246   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
<span class="line-added">5247      generate_stack_overflow_check(bangsize);</span>
<span class="line-added">5248 </span>
<span class="line-added">5249   build_frame(framesize);</span>
<span class="line-added">5250 </span>
<span class="line-added">5251   if (VerifyStackAtCalls) {</span>
<span class="line-added">5252     Unimplemented();</span>
<span class="line-added">5253   }</span>
<span class="line-added">5254 }</span>
<span class="line-added">5255 </span>
<span class="line-added">5256 int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="line-added">5257   // A value type might be returned. If fields are in registers we</span>
<span class="line-added">5258   // need to allocate a value type instance and initialize it with</span>
<span class="line-added">5259   // the value of the fields.</span>
<span class="line-added">5260   Label skip;</span>
<span class="line-added">5261   // We only need a new buffered value if a new one is not returned</span>
<span class="line-added">5262   cmp(r0, (u1) 1);</span>
<span class="line-added">5263   br(Assembler::EQ, skip);</span>
<span class="line-added">5264   int call_offset = -1;</span>
<span class="line-added">5265 </span>
<span class="line-added">5266   Label slow_case;</span>
<span class="line-added">5267 </span>
<span class="line-added">5268   // Try to allocate a new buffered value (from the heap)</span>
<span class="line-added">5269   if (UseTLAB) {</span>
<span class="line-added">5270 </span>
<span class="line-added">5271     if (vk != NULL) {</span>
<span class="line-added">5272       // Called from C1, where the return type is statically known.</span>
<span class="line-added">5273       mov(r1, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="line-added">5274       jint lh = vk-&gt;layout_helper();</span>
<span class="line-added">5275       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="line-added">5276       mov(r14, lh);</span>
<span class="line-added">5277     } else {</span>
<span class="line-added">5278        // Call from interpreter. R0 contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="line-added">5279        andr(r1, r0, -2);</span>
<span class="line-added">5280        // get obj size</span>
<span class="line-added">5281        ldrw(r14, Address(rscratch1 /*klass*/, Klass::layout_helper_offset()));</span>
<span class="line-added">5282     }</span>
<span class="line-added">5283 </span>
<span class="line-added">5284      ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5285 </span>
<span class="line-added">5286      // check whether we have space in TLAB,</span>
<span class="line-added">5287      // rscratch1 contains pointer to just allocated obj</span>
<span class="line-added">5288       lea(r14, Address(r13, r14));</span>
<span class="line-added">5289       ldr(rscratch1, Address(rthread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="line-added">5290 </span>
<span class="line-added">5291       cmp(r14, rscratch1);</span>
<span class="line-added">5292       br(Assembler::GT, slow_case);</span>
<span class="line-added">5293 </span>
<span class="line-added">5294       // OK we have room in TLAB,</span>
<span class="line-added">5295       // Set new TLAB top</span>
<span class="line-added">5296       str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5297 </span>
<span class="line-added">5298       // Set new class always locked</span>
<span class="line-added">5299       mov(rscratch1, (uint64_t) markWord::always_locked_prototype().value());</span>
<span class="line-added">5300       str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">5301 </span>
<span class="line-added">5302       store_klass_gap(r13, zr);  // zero klass gap for compressed oops</span>
<span class="line-added">5303       if (vk == NULL) {</span>
<span class="line-added">5304         // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="line-added">5305          mov(r0, r1);</span>
<span class="line-added">5306       }</span>
<span class="line-added">5307 </span>
<span class="line-added">5308       store_klass(r13, r1);  // klass</span>
<span class="line-added">5309 </span>
<span class="line-added">5310       if (vk != NULL) {</span>
<span class="line-added">5311         // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="line-added">5312         mov(r0, r13);</span>
<span class="line-added">5313         far_call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="line-added">5314       } else {</span>
<span class="line-added">5315 </span>
<span class="line-added">5316         // We have our new buffered value, initialize its fields with a</span>
<span class="line-added">5317         // value class specific handler</span>
<span class="line-added">5318         ldr(r1, Address(r0, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">5319         ldr(r1, Address(r1, ValueKlass::pack_handler_offset()));</span>
<span class="line-added">5320 </span>
<span class="line-added">5321         // Mov new class to r0 and call pack_handler</span>
<span class="line-added">5322         mov(r0, r13);</span>
<span class="line-added">5323         blr(r1);</span>
<span class="line-added">5324       }</span>
<span class="line-added">5325       b(skip);</span>
<span class="line-added">5326   }</span>
<span class="line-added">5327 </span>
<span class="line-added">5328   bind(slow_case);</span>
<span class="line-added">5329   // We failed to allocate a new value, fall back to a runtime</span>
<span class="line-added">5330   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="line-added">5331   // tell. That runtime call will take care of preserving them</span>
<span class="line-added">5332   // across a GC if there&#39;s one.</span>
<span class="line-added">5333 </span>
<span class="line-added">5334 </span>
<span class="line-added">5335   if (from_interpreter) {</span>
<span class="line-added">5336     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="line-added">5337   } else {</span>
<span class="line-added">5338     ldr(rscratch1, RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="line-added">5339     blr(rscratch1);</span>
<span class="line-added">5340     call_offset = offset();</span>
<span class="line-added">5341   }</span>
<span class="line-added">5342 </span>
<span class="line-added">5343   bind(skip);</span>
<span class="line-added">5344   return call_offset;</span>
<span class="line-added">5345 }</span>
<span class="line-added">5346 </span>
<span class="line-added">5347 // Move a value between registers/stack slots and update the reg_state</span>
<span class="line-added">5348 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5349   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5350     return true; // Already written</span>
<span class="line-added">5351   }</span>
<span class="line-added">5352 </span>
<span class="line-added">5353   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="line-added">5354     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5355       return false; // Not yet writable</span>
<span class="line-added">5356     }</span>
<span class="line-added">5357     if (from-&gt;is_reg()) {</span>
<span class="line-added">5358       if (to-&gt;is_reg()) {</span>
<span class="line-added">5359         mov(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="line-added">5360       } else {</span>
<span class="line-added">5361         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5362         Address to_addr = Address(sp, st_off);</span>
<span class="line-added">5363         if (from-&gt;is_FloatRegister()) {</span>
<span class="line-added">5364           if (bt == T_DOUBLE) {</span>
<span class="line-added">5365              strd(from-&gt;as_FloatRegister(), to_addr);</span>
<span class="line-added">5366           } else {</span>
<span class="line-added">5367              assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5368              strs(from-&gt;as_FloatRegister(), to_addr);</span>
<span class="line-added">5369           }</span>
<span class="line-added">5370         } else {</span>
<span class="line-added">5371           str(from-&gt;as_Register(), to_addr);</span>
<span class="line-added">5372         }</span>
<span class="line-added">5373       }</span>
<span class="line-added">5374     } else {</span>
<span class="line-added">5375       Address from_addr = Address(sp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="line-added">5376       if (to-&gt;is_reg()) {</span>
<span class="line-added">5377         if (to-&gt;is_FloatRegister()) {</span>
<span class="line-added">5378           if (bt == T_DOUBLE) {</span>
<span class="line-added">5379              ldrd(to-&gt;as_FloatRegister(), from_addr);</span>
<span class="line-added">5380           } else {</span>
<span class="line-added">5381             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5382             ldrs(to-&gt;as_FloatRegister(), from_addr);</span>
<span class="line-added">5383           }</span>
<span class="line-added">5384         } else {</span>
<span class="line-added">5385           ldr(to-&gt;as_Register(), from_addr);</span>
<span class="line-added">5386         }</span>
<span class="line-added">5387       } else {</span>
<span class="line-added">5388         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5389         ldr(rscratch1, from_addr);</span>
<span class="line-added">5390         str(rscratch1, Address(sp, st_off));</span>
<span class="line-added">5391       }</span>
<span class="line-added">5392     }</span>
<span class="line-added">5393   }</span>
<span class="line-added">5394 </span>
<span class="line-added">5395   // Update register states</span>
<span class="line-added">5396   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5397   reg_state[to-&gt;value()] = reg_written;</span>
<span class="line-added">5398   return true;</span>
<span class="line-added">5399 }</span>
<span class="line-added">5400 </span>
<span class="line-added">5401 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-added">5402 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-added">5403                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5404   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="line-added">5405   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5406 </span>
<span class="line-added">5407 </span>
<span class="line-added">5408   int vt = 1;</span>
<span class="line-added">5409   bool done = true;</span>
<span class="line-added">5410   bool mark_done = true;</span>
<span class="line-added">5411   do {</span>
<span class="line-added">5412     sig_index--;</span>
<span class="line-added">5413     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="line-added">5414     if (bt == T_VALUETYPE) {</span>
<span class="line-added">5415       vt--;</span>
<span class="line-added">5416     } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">5417                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="line-added">5418                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="line-added">5419       vt++;</span>
<span class="line-added">5420     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="line-added">5421       to_index--; // Ignore this</span>
<span class="line-added">5422     } else {</span>
<span class="line-added">5423       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="line-added">5424       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="line-added">5425       VMReg to = pair_to.first();</span>
<span class="line-added">5426 </span>
<span class="line-added">5427       if (bt == T_VOID) continue;</span>
<span class="line-added">5428 </span>
<span class="line-added">5429       int idx = (int) to-&gt;value();</span>
<span class="line-added">5430       if (reg_state[idx] == reg_readonly) {</span>
<span class="line-added">5431          if (idx != from-&gt;value()) {</span>
<span class="line-added">5432            mark_done = false;</span>
<span class="line-added">5433          }</span>
<span class="line-added">5434          done = false;</span>
<span class="line-added">5435          continue;</span>
<span class="line-added">5436       } else if (reg_state[idx] == reg_written) {</span>
<span class="line-added">5437         continue;</span>
<span class="line-added">5438       } else {</span>
<span class="line-added">5439         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="line-added">5440         reg_state[idx] = reg_written;</span>
<span class="line-added">5441       }</span>
<span class="line-added">5442 </span>
<span class="line-added">5443       if (fromReg == noreg) {</span>
<span class="line-added">5444         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5445         ldr(rscratch2, Address(sp, st_off));</span>
<span class="line-added">5446         fromReg = rscratch2;</span>
<span class="line-added">5447       }</span>
<span class="line-added">5448 </span>
<span class="line-added">5449       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="line-added">5450       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5451       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5452 </span>
<span class="line-added">5453       Address fromAddr = Address(fromReg, off);</span>
<span class="line-added">5454       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="line-added">5455 </span>
<span class="line-added">5456       if (!to-&gt;is_FloatRegister()) {</span>
<span class="line-added">5457 </span>
<span class="line-added">5458         Register dst = to-&gt;is_stack() ? rscratch1 : to-&gt;as_Register();</span>
<span class="line-added">5459 </span>
<span class="line-added">5460         if (is_oop) {</span>
<span class="line-added">5461           load_heap_oop(dst, fromAddr);</span>
<span class="line-added">5462         } else {</span>
<span class="line-added">5463           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="line-added">5464         }</span>
<span class="line-added">5465         if (to-&gt;is_stack()) {</span>
<span class="line-added">5466           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5467           str(dst, Address(sp, st_off));</span>
<span class="line-added">5468         }</span>
<span class="line-added">5469       } else {</span>
<span class="line-added">5470         if (bt == T_DOUBLE) {</span>
<span class="line-added">5471           ldrd(to-&gt;as_FloatRegister(), fromAddr);</span>
<span class="line-added">5472         } else {</span>
<span class="line-added">5473           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5474           ldrs(to-&gt;as_FloatRegister(), fromAddr);</span>
<span class="line-added">5475         }</span>
<span class="line-added">5476      }</span>
<span class="line-added">5477 </span>
<span class="line-added">5478     }</span>
<span class="line-added">5479 </span>
<span class="line-added">5480   } while (vt != 0);</span>
<span class="line-added">5481 </span>
<span class="line-added">5482   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="line-added">5483     // This is okay because no one else will write to that slot</span>
<span class="line-added">5484     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5485   }</span>
<span class="line-added">5486   return done;</span>
<span class="line-added">5487 }</span>
<span class="line-added">5488 </span>
<span class="line-added">5489 // Pack fields back into a value type oop</span>
<span class="line-added">5490 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-added">5491                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-added">5492                                        int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5493   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5494   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="line-added">5495 </span>
<span class="line-added">5496   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5497     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5498     return true; // Already written</span>
<span class="line-added">5499   }</span>
<span class="line-added">5500 </span>
<span class="line-added">5501   Register val_array = r0;</span>
<span class="line-added">5502   Register val_obj_tmp = r11;</span>
<span class="line-added">5503   Register from_reg_tmp = r10;</span>
<span class="line-added">5504   Register tmp1 = r14;</span>
<span class="line-added">5505   Register tmp2 = r13;</span>
<span class="line-added">5506   Register tmp3 = r1;</span>
<span class="line-added">5507   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="line-added">5508 </span>
<span class="line-added">5509   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5510     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="line-added">5511       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5512       return false; // Not yet writable</span>
<span class="line-added">5513     }</span>
<span class="line-added">5514     val_obj = val_obj_tmp;</span>
<span class="line-added">5515   }</span>
<span class="line-added">5516 </span>
<span class="line-added">5517   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="line-added">5518   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="line-added">5519 </span>
<span class="line-added">5520   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5521   VMRegPair from_pair;</span>
<span class="line-added">5522   BasicType bt;</span>
<span class="line-added">5523 </span>
<span class="line-added">5524   while (stream.next(from_pair, bt)) {</span>
<span class="line-added">5525     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="line-added">5526     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5527     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5528     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">5529 </span>
<span class="line-added">5530     VMReg from_r1 = from_pair.first();</span>
<span class="line-added">5531     VMReg from_r2 = from_pair.second();</span>
<span class="line-added">5532 </span>
<span class="line-added">5533     // Pack the scalarized field into the value object.</span>
<span class="line-added">5534     Address dst(val_obj, off);</span>
<span class="line-added">5535 </span>
<span class="line-added">5536     if (!from_r1-&gt;is_FloatRegister()) {</span>
<span class="line-added">5537       Register from_reg;</span>
<span class="line-added">5538       if (from_r1-&gt;is_stack()) {</span>
<span class="line-added">5539         from_reg = from_reg_tmp;</span>
<span class="line-added">5540         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5541         load_sized_value(from_reg, Address(sp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">5542       } else {</span>
<span class="line-added">5543         from_reg = from_r1-&gt;as_Register();</span>
<span class="line-added">5544       }</span>
<span class="line-added">5545 </span>
<span class="line-added">5546       if (is_oop) {</span>
<span class="line-added">5547         DecoratorSet decorators = IN_HEAP | ACCESS_WRITE;</span>
<span class="line-added">5548         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, decorators);</span>
<span class="line-added">5549       } else {</span>
<span class="line-added">5550         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="line-added">5551       }</span>
<span class="line-added">5552     } else {</span>
<span class="line-added">5553       if (from_r2-&gt;is_valid()) {</span>
<span class="line-added">5554         strd(from_r1-&gt;as_FloatRegister(), dst);</span>
<span class="line-added">5555       } else {</span>
<span class="line-added">5556         strs(from_r1-&gt;as_FloatRegister(), dst);</span>
<span class="line-added">5557       }</span>
<span class="line-added">5558     }</span>
<span class="line-added">5559 </span>
<span class="line-added">5560     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="line-added">5561   }</span>
<span class="line-added">5562   sig_index = stream.sig_cc_index();</span>
<span class="line-added">5563   from_index = stream.regs_cc_index();</span>
<span class="line-added">5564 </span>
<span class="line-added">5565   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="line-added">5566   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="line-added">5567   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="line-added">5568 </span>
<span class="line-added">5569   return true;</span>
<span class="line-added">5570 }</span>
<span class="line-added">5571 </span>
<span class="line-added">5572 // Unpack all value type arguments passed as oops</span>
<span class="line-added">5573 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-added">5574   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="line-added">5575   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="line-added">5576   verified_entry(C, sp_inc);</span>
<span class="line-added">5577 }</span>
<span class="line-added">5578 </span>
<span class="line-added">5579 int MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-added">5580                                        BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">5581                                        int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-added">5582                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
<span class="line-added">5583   // Check if we need to extend the stack for packing/unpacking</span>
<span class="line-added">5584   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;</span>
<span class="line-added">5585   if (sp_inc &gt; 0) {</span>
<span class="line-added">5586     sp_inc = align_up(sp_inc, StackAlignmentInBytes);</span>
<span class="line-added">5587     if (!is_packing) {</span>
<span class="line-added">5588       // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-added">5589       // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-added">5590       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-added">5591       // FIXME: We need not to preserve return address on aarch64</span>
<span class="line-added">5592       pop(rscratch1);</span>
<span class="line-added">5593       sub(sp, sp, sp_inc);</span>
<span class="line-added">5594       push(rscratch1);</span>
<span class="line-added">5595     }</span>
<span class="line-added">5596   } else {</span>
<span class="line-added">5597     // The scalarized calling convention needs less stack space than the unscalarized one.</span>
<span class="line-added">5598     // No need to extend the stack, the caller will take care of these adjustments.</span>
<span class="line-added">5599     sp_inc = 0;</span>
<span class="line-added">5600   }</span>
<span class="line-added">5601 </span>
<span class="line-added">5602   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="line-added">5603   if (is_packing) {</span>
<span class="line-added">5604     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="line-added">5605     // rsp[0] during shuffling.</span>
<span class="line-added">5606     ret_off = 0;</span>
<span class="line-added">5607   } else {</span>
<span class="line-added">5608     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="line-added">5609     ret_off = sp_inc;</span>
<span class="line-added">5610   }</span>
<span class="line-added">5611 </span>
<span class="line-added">5612   return shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-added">5613                                    sig_bt, sig_cc,</span>
<span class="line-added">5614                                    args_passed, args_on_stack, regs,</span>
<span class="line-added">5615                                    args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-added">5616                                    sp_inc, ret_off);</span>
<span class="line-added">5617 }</span>
<span class="line-added">5618 </span>
<span class="line-added">5619 VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="line-added">5620   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="line-added">5621 }</span>
<span class="line-added">5622 </span>
5623 void MacroAssembler::cache_wb(Address line) {
5624   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5625   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5626   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5627   // would like to assert this
5628   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5629   if (VM_Version::supports_dcpop()) {
5630     // writeback using clear virtual address to point of persistence
5631     dc(Assembler::CVAP, line.base());
5632   } else {
5633     // no need to generate anything as Unsafe.writebackMemory should
5634     // never invoke this stub
5635   }
5636 }
5637 
5638 void MacroAssembler::cache_wbsync(bool is_pre) {
5639   // we only need a barrier post sync
5640   if (!is_pre) {
5641     membar(Assembler::AnyAny);
5642   }
</pre>
</td>
</tr>
</table>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../ppc/globals_ppc.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>