<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
 1643   C2_MacroAssembler _masm(&amp;cbuf);
 1644 
<a name="1" id="anc1"></a><span class="line-modified"> 1645   __ verified_entry(C, 0);</span>
<span class="line-modified"> 1646   __ bind(*_verified_entry);</span>


























 1647 
 1648   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1649 
 1650   if (C-&gt;has_mach_constant_base_node()) {
 1651     // NOTE: We set the table base offset here because users might be
 1652     // emitted before MachConstantBaseNode.
 1653     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1654     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1655   }
 1656 }
 1657 
 1658 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1659 {
 1660   return MachNode::size(ra_); // too many variables; just compute it
 1661                               // the hard way
 1662 }
 1663 
 1664 int MachPrologNode::reloc() const
 1665 {
 1666   return 0;
 1667 }
 1668 
 1669 //=============================================================================
 1670 
 1671 #ifndef PRODUCT
 1672 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1673   Compile* C = ra_-&gt;C;
 1674   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1675 
 1676   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1677 
 1678   if (framesize == 0) {
 1679     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1680   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1681     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1682     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1683   } else {
 1684     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1685     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1686     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1687   }
 1688 
 1689   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1690     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1691     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1692     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1693   }
 1694 }
 1695 #endif
 1696 
 1697 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1698   Compile* C = ra_-&gt;C;
 1699   C2_MacroAssembler _masm(&amp;cbuf);
 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1701 
 1702   __ remove_frame(framesize);
 1703 
 1704   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1705     __ reserved_stack_check();
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1710   }
 1711 }
 1712 
 1713 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1714   // Variable size. Determine dynamically.
 1715   return MachNode::size(ra_);
 1716 }
 1717 
 1718 int MachEpilogNode::reloc() const {
 1719   // Return number of relocatable values contained in this instruction.
 1720   return 1; // 1 for polling page.
 1721 }
 1722 
 1723 const Pipeline * MachEpilogNode::pipeline() const {
 1724   return MachNode::pipeline_class();
 1725 }
 1726 
 1727 //=============================================================================
 1728 
 1729 // Figure out which register class each belongs in: rc_int, rc_float or
 1730 // rc_stack.
 1731 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1732 
 1733 static enum RC rc_class(OptoReg::Name reg) {
 1734 
 1735   if (reg == OptoReg::Bad) {
 1736     return rc_bad;
 1737   }
 1738 
 1739   // we have 30 int registers * 2 halves
 1740   // (rscratch1 and rscratch2 are omitted)
 1741   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1742 
 1743   if (reg &lt; slots_of_int_registers) {
 1744     return rc_int;
 1745   }
 1746 
 1747   // we have 32 float register * 4 halves
 1748   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1749     return rc_float;
 1750   }
 1751 
 1752   // Between float regs &amp; stack is the flags regs.
 1753   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1754 
 1755   return rc_stack;
 1756 }
 1757 
 1758 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1759   Compile* C = ra_-&gt;C;
 1760 
 1761   // Get registers to move.
 1762   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1763   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1764   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1765   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1766 
 1767   enum RC src_hi_rc = rc_class(src_hi);
 1768   enum RC src_lo_rc = rc_class(src_lo);
 1769   enum RC dst_hi_rc = rc_class(dst_hi);
 1770   enum RC dst_lo_rc = rc_class(dst_lo);
 1771 
 1772   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1773 
 1774   if (src_hi != OptoReg::Bad) {
 1775     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1776            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1777            &quot;expected aligned-adjacent pairs&quot;);
 1778   }
 1779 
 1780   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1781     return 0;            // Self copy, no move.
 1782   }
 1783 
 1784   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1785               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1786   int src_offset = ra_-&gt;reg2offset(src_lo);
 1787   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1788 
 1789   if (bottom_type()-&gt;isa_vect() != NULL) {
 1790     uint ireg = ideal_reg();
 1791     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1792     if (cbuf) {
 1793       C2_MacroAssembler _masm(cbuf);
 1794       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1795       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1796         // stack-&gt;stack
 1797         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1798         if (ireg == Op_VecD) {
 1799           __ unspill(rscratch1, true, src_offset);
 1800           __ spill(rscratch1, true, dst_offset);
 1801         } else {
 1802           __ spill_copy128(src_offset, dst_offset);
 1803         }
 1804       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1805         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1806                ireg == Op_VecD ? __ T8B : __ T16B,
 1807                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1808       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1809         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1810                        ireg == Op_VecD ? __ D : __ Q,
 1811                        ra_-&gt;reg2offset(dst_lo));
 1812       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1813         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1814                        ireg == Op_VecD ? __ D : __ Q,
 1815                        ra_-&gt;reg2offset(src_lo));
 1816       } else {
 1817         ShouldNotReachHere();
 1818       }
 1819     }
 1820   } else if (cbuf) {
 1821     C2_MacroAssembler _masm(cbuf);
 1822     switch (src_lo_rc) {
 1823     case rc_int:
 1824       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1825         if (is64) {
 1826             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1827                    as_Register(Matcher::_regEncode[src_lo]));
 1828         } else {
 1829             C2_MacroAssembler _masm(cbuf);
 1830             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1831                     as_Register(Matcher::_regEncode[src_lo]));
 1832         }
 1833       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1834         if (is64) {
 1835             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1836                      as_Register(Matcher::_regEncode[src_lo]));
 1837         } else {
 1838             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1839                      as_Register(Matcher::_regEncode[src_lo]));
 1840         }
 1841       } else {                    // gpr --&gt; stack spill
 1842         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1843         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1844       }
 1845       break;
 1846     case rc_float:
 1847       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1848         if (is64) {
 1849             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1850                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1851         } else {
 1852             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1853                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1854         }
 1855       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1856           if (cbuf) {
 1857             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1859         } else {
 1860             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1861                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1862         }
 1863       } else {                    // fpr --&gt; stack spill
 1864         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1865         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1866                  is64 ? __ D : __ S, dst_offset);
 1867       }
 1868       break;
 1869     case rc_stack:
 1870       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1871         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1872       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1873         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                    is64 ? __ D : __ S, src_offset);
 1875       } else {                    // stack --&gt; stack copy
 1876         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1877         __ unspill(rscratch1, is64, src_offset);
 1878         __ spill(rscratch1, is64, dst_offset);
 1879       }
 1880       break;
 1881     default:
 1882       assert(false, &quot;bad rc_class for spill&quot;);
 1883       ShouldNotReachHere();
 1884     }
 1885   }
 1886 
 1887   if (st) {
 1888     st-&gt;print(&quot;spill &quot;);
 1889     if (src_lo_rc == rc_stack) {
 1890       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1891     } else {
 1892       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1893     }
 1894     if (dst_lo_rc == rc_stack) {
 1895       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1896     } else {
 1897       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1898     }
 1899     if (bottom_type()-&gt;isa_vect() != NULL) {
 1900       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1901     } else {
 1902       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1903     }
 1904   }
 1905 
 1906   return 0;
 1907 
 1908 }
 1909 
 1910 #ifndef PRODUCT
 1911 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1912   if (!ra_)
 1913     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1914   else
 1915     implementation(NULL, ra_, false, st);
 1916 }
 1917 #endif
 1918 
 1919 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1920   implementation(&amp;cbuf, ra_, false, NULL);
 1921 }
 1922 
 1923 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1924   return MachNode::size(ra_);
 1925 }
 1926 
 1927 //=============================================================================
 1928 
 1929 #ifndef PRODUCT
 1930 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg = ra_-&gt;get_reg_first(this);
 1933   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1934             Matcher::regName[reg], offset);
 1935 }
 1936 #endif
 1937 
 1938 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   C2_MacroAssembler _masm(&amp;cbuf);
 1940 
 1941   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1942   int reg    = ra_-&gt;get_encode(this);
 1943 
 1944   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1945     __ add(as_Register(reg), sp, offset);
 1946   } else {
 1947     ShouldNotReachHere();
 1948   }
 1949 }
 1950 
 1951 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1952   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1953   return 4;
 1954 }
 1955 
<a name="2" id="anc2"></a><span class="line-modified"> 1956 ///=============================================================================</span>
<span class="line-added"> 1957 #ifndef PRODUCT</span>
<span class="line-added"> 1958 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const</span>
<span class="line-added"> 1959 {</span>
<span class="line-added"> 1960   st-&gt;print_cr(&quot;# MachVEPNode&quot;);</span>
<span class="line-added"> 1961   if (!_verified) {</span>
<span class="line-added"> 1962     st-&gt;print_cr(&quot;\t load_class&quot;);</span>
<span class="line-added"> 1963   } else {</span>
<span class="line-added"> 1964     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);</span>
<span class="line-added"> 1965   }</span>
<span class="line-added"> 1966 }</span>
<span class="line-added"> 1967 #endif</span>
<span class="line-added"> 1968 </span>
<span class="line-added"> 1969 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 1970 {</span>
<span class="line-added"> 1971   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-added"> 1972 </span>
<span class="line-added"> 1973   if (!_verified) {</span>
<span class="line-added"> 1974     Label skip;</span>
<span class="line-added"> 1975     __ cmp_klass(j_rarg0, rscratch2, rscratch1);</span>
<span class="line-added"> 1976     __ br(Assembler::EQ, skip);</span>
<span class="line-added"> 1977       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
<span class="line-added"> 1978     __ bind(skip);</span>
<span class="line-added"> 1979 </span>
<span class="line-added"> 1980   } else {</span>
<span class="line-added"> 1981     // Unpack value type args passed as oop and then jump to</span>
<span class="line-added"> 1982     // the verified entry point (skipping the unverified entry).</span>
<span class="line-added"> 1983     __ unpack_value_args(ra_-&gt;C, _receiver_only);</span>
<span class="line-added"> 1984     __ b(*_verified_entry);</span>
<span class="line-added"> 1985   }</span>
<span class="line-added"> 1986 }</span>
<span class="line-added"> 1987 </span>
<span class="line-added"> 1988 </span>
<span class="line-added"> 1989 uint MachVEPNode::size(PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 1990 {</span>
<span class="line-added"> 1991   return MachNode::size(ra_); // too many variables; just compute it the hard way</span>
<span class="line-added"> 1992 }</span>
<span class="line-added"> 1993 </span>
 1994 
<a name="3" id="anc3"></a><span class="line-added"> 1995 //=============================================================================</span>
 1996 #ifndef PRODUCT
 1997 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1998 {
 1999   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2000   if (UseCompressedClassPointers) {
 2001     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2002     if (CompressedKlassPointers::shift() != 0) {
 2003       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2004     }
 2005   } else {
 2006    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2007   }
 2008   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2009   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2010 }
 2011 #endif
 2012 
 2013 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2014 {
 2015   // This is the unverified entry point.
 2016   C2_MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a><span class="line-added"> 2017   Label skip;</span>
 2018 
<a name="5" id="anc5"></a><span class="line-added"> 2019   // UseCompressedClassPointers logic are inside cmp_klass</span>
 2020   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
<a name="6" id="anc6"></a><span class="line-modified"> 2021 </span>
 2022   // TODO
 2023   // can we avoid this skip and still use a reloc?
 2024   __ br(Assembler::EQ, skip);
 2025   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2026   __ bind(skip);
 2027 }
 2028 
 2029 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2030 {
 2031   return MachNode::size(ra_);
 2032 }
 2033 
 2034 // REQUIRED EMIT CODE
 2035 
 2036 //=============================================================================
 2037 
 2038 // Emit exception handler code.
 2039 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2040 {
 2041   // mov rscratch1 #exception_blob_entry_point
 2042   // br rscratch1
 2043   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2044   // That&#39;s why we must use the macroassembler to generate a handler.
 2045   C2_MacroAssembler _masm(&amp;cbuf);
 2046   address base = __ start_a_stub(size_exception_handler());
 2047   if (base == NULL) {
 2048     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2049     return 0;  // CodeBuffer::expand failed
 2050   }
 2051   int offset = __ offset();
 2052   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2053   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2054   __ end_a_stub();
 2055   return offset;
 2056 }
 2057 
 2058 // Emit deopt handler code.
 2059 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2060 {
 2061   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2062   // That&#39;s why we must use the macroassembler to generate a handler.
 2063   C2_MacroAssembler _masm(&amp;cbuf);
 2064   address base = __ start_a_stub(size_deopt_handler());
 2065   if (base == NULL) {
 2066     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2067     return 0;  // CodeBuffer::expand failed
 2068   }
 2069   int offset = __ offset();
 2070 
 2071   __ adr(lr, __ pc());
 2072   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2073 
 2074   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2075   __ end_a_stub();
 2076   return offset;
 2077 }
 2078 
 2079 // REQUIRED MATCHER CODE
 2080 
 2081 //=============================================================================
 2082 
 2083 const bool Matcher::match_rule_supported(int opcode) {
 2084   if (!has_match_rule(opcode))
 2085     return false;
 2086 
 2087   bool ret_value = true;
 2088   switch (opcode) {
 2089     case Op_CacheWB:
 2090     case Op_CacheWBPreSync:
 2091     case Op_CacheWBPostSync:
 2092       if (!VM_Version::supports_data_cache_line_flush()) {
 2093         ret_value = false;
 2094       }
 2095       break;
 2096   }
 2097 
 2098   return ret_value; // Per default match rules are supported.
 2099 }
 2100 
 2101 // Identify extra cases that we might want to provide match rules for vector nodes and
 2102 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2103 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2104   if (!match_rule_supported(opcode)) {
 2105     return false;
 2106   }
 2107 
 2108   // Special cases which require vector length
 2109   switch (opcode) {
 2110     case Op_MulAddVS2VI: {
 2111       if (vlen != 4) {
 2112         return false;
 2113       }
 2114       break;
 2115     }
 2116   }
 2117 
 2118   return true; // Per default match rules are supported.
 2119 }
 2120 
 2121 const bool Matcher::has_predicated_vectors(void) {
 2122   return false;
 2123 }
 2124 
 2125 const int Matcher::float_pressure(int default_pressure_threshold) {
 2126   return default_pressure_threshold;
 2127 }
 2128 
 2129 int Matcher::regnum_to_fpu_offset(int regnum)
 2130 {
 2131   Unimplemented();
 2132   return 0;
 2133 }
 2134 
 2135 // Is this branch offset short enough that a short branch can be used?
 2136 //
 2137 // NOTE: If the platform does not provide any short branch variants, then
 2138 //       this method should return false for offset 0.
 2139 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2140   // The passed offset is relative to address of the branch.
 2141 
 2142   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2143 }
 2144 
 2145 const bool Matcher::isSimpleConstant64(jlong value) {
 2146   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2147   // Probably always true, even if a temp register is required.
 2148   return true;
 2149 }
 2150 
 2151 // true just means we have fast l2f conversion
 2152 const bool Matcher::convL2FSupported(void) {
 2153   return true;
 2154 }
 2155 
 2156 // Vector width in bytes.
 2157 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2158   int size = MIN2(16,(int)MaxVectorSize);
 2159   // Minimum 2 values in vector
 2160   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2161   // But never &lt; 4
 2162   if (size &lt; 4) size = 0;
 2163   return size;
 2164 }
 2165 
 2166 // Limits on vector size (number of elements) loaded into vector.
 2167 const int Matcher::max_vector_size(const BasicType bt) {
 2168   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2169 }
 2170 const int Matcher::min_vector_size(const BasicType bt) {
 2171 //  For the moment limit the vector size to 8 bytes
 2172     int size = 8 / type2aelembytes(bt);
 2173     if (size &lt; 2) size = 2;
 2174     return size;
 2175 }
 2176 
 2177 // Vector ideal reg.
 2178 const uint Matcher::vector_ideal_reg(int len) {
 2179   switch(len) {
 2180     case  8: return Op_VecD;
 2181     case 16: return Op_VecX;
 2182   }
 2183   ShouldNotReachHere();
 2184   return 0;
 2185 }
 2186 
 2187 // AES support not yet implemented
 2188 const bool Matcher::pass_original_key_for_aes() {
 2189   return false;
 2190 }
 2191 
 2192 // aarch64 supports misaligned vectors store/load.
 2193 const bool Matcher::misaligned_vectors_ok() {
 2194   return true;
 2195 }
 2196 
 2197 // false =&gt; size gets scaled to BytesPerLong, ok.
 2198 const bool Matcher::init_array_count_is_in_bytes = false;
 2199 
 2200 // Use conditional move (CMOVL)
 2201 const int Matcher::long_cmove_cost() {
 2202   // long cmoves are no more expensive than int cmoves
 2203   return 0;
 2204 }
 2205 
 2206 const int Matcher::float_cmove_cost() {
 2207   // float cmoves are no more expensive than int cmoves
 2208   return 0;
 2209 }
 2210 
 2211 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2212 const bool Matcher::require_postalloc_expand = false;
 2213 
 2214 // Do we need to mask the count passed to shift instructions or does
 2215 // the cpu only look at the lower 5/6 bits anyway?
 2216 const bool Matcher::need_masked_shift_count = false;
 2217 
 2218 // No support for generic vector operands.
 2219 const bool Matcher::supports_generic_vector_operands  = false;
 2220 
 2221 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2222   ShouldNotReachHere(); // generic vector operands not supported
 2223   return NULL;
 2224 }
 2225 
 2226 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2227   ShouldNotReachHere();  // generic vector operands not supported
 2228   return false;
 2229 }
 2230 
 2231 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2232   ShouldNotReachHere();  // generic vector operands not supported
 2233   return false;
 2234 }
 2235 
 2236 // This affects two different things:
 2237 //  - how Decode nodes are matched
 2238 //  - how ImplicitNullCheck opportunities are recognized
 2239 // If true, the matcher will try to remove all Decodes and match them
 2240 // (as operands) into nodes. NullChecks are not prepared to deal with
 2241 // Decodes by final_graph_reshaping().
 2242 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2243 // for a NullCheck. The matcher matches the Decode node into a register.
 2244 // Implicit_null_check optimization moves the Decode along with the
 2245 // memory operation back up before the NullCheck.
 2246 bool Matcher::narrow_oop_use_complex_address() {
 2247   return CompressedOops::shift() == 0;
 2248 }
 2249 
 2250 bool Matcher::narrow_klass_use_complex_address() {
 2251 // TODO
 2252 // decide whether we need to set this to true
 2253   return false;
 2254 }
 2255 
 2256 bool Matcher::const_oop_prefer_decode() {
 2257   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2258   return CompressedOops::base() == NULL;
 2259 }
 2260 
 2261 bool Matcher::const_klass_prefer_decode() {
 2262   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2263   return CompressedKlassPointers::base() == NULL;
 2264 }
 2265 
 2266 // Is it better to copy float constants, or load them directly from
 2267 // memory?  Intel can load a float constant from a direct address,
 2268 // requiring no extra registers.  Most RISCs will have to materialize
 2269 // an address into a register first, so they would do better to copy
 2270 // the constant from stack.
 2271 const bool Matcher::rematerialize_float_constants = false;
 2272 
 2273 // If CPU can load and store mis-aligned doubles directly then no
 2274 // fixup is needed.  Else we split the double into 2 integer pieces
 2275 // and move it piece-by-piece.  Only happens when passing doubles into
 2276 // C code as the Java calling convention forces doubles to be aligned.
 2277 const bool Matcher::misaligned_doubles_ok = true;
 2278 
 2279 // No-op on amd64
 2280 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2281   Unimplemented();
 2282 }
 2283 
 2284 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2285 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2286 
 2287 // Are floats converted to double when stored to stack during
 2288 // deoptimization?
 2289 bool Matcher::float_in_double() { return false; }
 2290 
 2291 // Do ints take an entire long register or just half?
 2292 // The relevant question is how the int is callee-saved:
 2293 // the whole long is written but de-opt&#39;ing will have to extract
 2294 // the relevant 32 bits.
 2295 const bool Matcher::int_in_long = true;
 2296 
 2297 // Return whether or not this register is ever used as an argument.
 2298 // This function is used on startup to build the trampoline stubs in
 2299 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2300 // call in the trampoline, and arguments in those registers not be
 2301 // available to the callee.
 2302 bool Matcher::can_be_java_arg(int reg)
 2303 {
 2304   return
 2305     reg ==  R0_num || reg == R0_H_num ||
 2306     reg ==  R1_num || reg == R1_H_num ||
 2307     reg ==  R2_num || reg == R2_H_num ||
 2308     reg ==  R3_num || reg == R3_H_num ||
 2309     reg ==  R4_num || reg == R4_H_num ||
 2310     reg ==  R5_num || reg == R5_H_num ||
 2311     reg ==  R6_num || reg == R6_H_num ||
 2312     reg ==  R7_num || reg == R7_H_num ||
 2313     reg ==  V0_num || reg == V0_H_num ||
 2314     reg ==  V1_num || reg == V1_H_num ||
 2315     reg ==  V2_num || reg == V2_H_num ||
 2316     reg ==  V3_num || reg == V3_H_num ||
 2317     reg ==  V4_num || reg == V4_H_num ||
 2318     reg ==  V5_num || reg == V5_H_num ||
 2319     reg ==  V6_num || reg == V6_H_num ||
 2320     reg ==  V7_num || reg == V7_H_num;
 2321 }
 2322 
 2323 bool Matcher::is_spillable_arg(int reg)
 2324 {
 2325   return can_be_java_arg(reg);
 2326 }
 2327 
 2328 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2329   return false;
 2330 }
 2331 
 2332 RegMask Matcher::divI_proj_mask() {
 2333   ShouldNotReachHere();
 2334   return RegMask();
 2335 }
 2336 
 2337 // Register for MODI projection of divmodI.
 2338 RegMask Matcher::modI_proj_mask() {
 2339   ShouldNotReachHere();
 2340   return RegMask();
 2341 }
 2342 
 2343 // Register for DIVL projection of divmodL.
 2344 RegMask Matcher::divL_proj_mask() {
 2345   ShouldNotReachHere();
 2346   return RegMask();
 2347 }
 2348 
 2349 // Register for MODL projection of divmodL.
 2350 RegMask Matcher::modL_proj_mask() {
 2351   ShouldNotReachHere();
 2352   return RegMask();
 2353 }
 2354 
 2355 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2356   return FP_REG_mask();
 2357 }
 2358 
 2359 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2360   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2361     Node* u = addp-&gt;fast_out(i);
 2362     if (u-&gt;is_Mem()) {
 2363       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2364       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2365       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2366         return false;
 2367       }
 2368     }
 2369   }
 2370   return true;
 2371 }
 2372 
 2373 const bool Matcher::convi2l_type_required = false;
 2374 
 2375 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2376 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2377   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2378     mstack.push(m, Visit);           // m = ShiftCntV
 2379     return true;
 2380   }
 2381   return false;
 2382 }
 2383 
 2384 // Should the Matcher clone shifts on addressing modes, expecting them
 2385 // to be subsumed into complex addressing expressions or compute them
 2386 // into registers?
 2387 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2388   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2389     return true;
 2390   }
 2391 
 2392   Node *off = m-&gt;in(AddPNode::Offset);
 2393   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2394       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2395       // Are there other uses besides address expressions?
 2396       !is_visited(off)) {
 2397     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2398     mstack.push(off-&gt;in(2), Visit);
 2399     Node *conv = off-&gt;in(1);
 2400     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2401         // Are there other uses besides address expressions?
 2402         !is_visited(conv)) {
 2403       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2404       mstack.push(conv-&gt;in(1), Pre_Visit);
 2405     } else {
 2406       mstack.push(conv, Pre_Visit);
 2407     }
 2408     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2409     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2410     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2411     return true;
 2412   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2413              // Are there other uses besides address expressions?
 2414              !is_visited(off)) {
 2415     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2416     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2417     mstack.push(off-&gt;in(1), Pre_Visit);
 2418     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2419     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2420     return true;
 2421   }
 2422   return false;
 2423 }
 2424 
 2425 void Compile::reshape_address(AddPNode* addp) {
 2426 }
 2427 
<a name="7" id="anc7"></a>
 2428 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2429   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2430   {                                                                     \
 2431     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2432     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2433     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2434     __ INSN(REG, as_Register(BASE));                                    \
 2435   }
 2436 
 2437 
 2438 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2439   {
 2440     Address::extend scale;
 2441 
 2442     // Hooboy, this is fugly.  We need a way to communicate to the
 2443     // encoder that the index needs to be sign extended, so we have to
 2444     // enumerate all the cases.
 2445     switch (opcode) {
 2446     case INDINDEXSCALEDI2L:
 2447     case INDINDEXSCALEDI2LN:
 2448     case INDINDEXI2L:
 2449     case INDINDEXI2LN:
 2450       scale = Address::sxtw(size);
 2451       break;
 2452     default:
 2453       scale = Address::lsl(size);
 2454     }
 2455 
 2456     if (index == -1) {
 2457       return Address(base, disp);
 2458     } else {
 2459       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2460       return Address(base, as_Register(index), scale);
 2461     }
 2462   }
 2463 
 2464 
 2465 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2466 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2467 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2468 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2469                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2470 
 2471   // Used for all non-volatile memory accesses.  The use of
 2472   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2473   // offsets is something of a kludge.
 2474   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2475                         Register reg, int opcode,
 2476                         Register base, int index, int scale, int disp,
 2477                         int size_in_memory)
 2478   {
 2479     Address addr = mem2address(opcode, base, index, scale, disp);
 2480     if (addr.getMode() == Address::base_plus_offset) {
 2481       /* If we get an out-of-range offset it is a bug in the compiler,
 2482          so we assert here. */
 2483       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2484              &quot;c2 compiler bug&quot;);
 2485       /* Fix up any out-of-range offsets. */
 2486       assert_different_registers(rscratch1, base);
 2487       assert_different_registers(rscratch1, reg);
 2488       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2489     }
 2490     (masm.*insn)(reg, addr);
 2491   }
 2492 
 2493   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2494                         FloatRegister reg, int opcode,
 2495                         Register base, int index, int size, int disp,
 2496                         int size_in_memory)
 2497   {
 2498     Address::extend scale;
 2499 
 2500     switch (opcode) {
 2501     case INDINDEXSCALEDI2L:
 2502     case INDINDEXSCALEDI2LN:
 2503       scale = Address::sxtw(size);
 2504       break;
 2505     default:
 2506       scale = Address::lsl(size);
 2507     }
 2508 
 2509     if (index == -1) {
 2510       /* If we get an out-of-range offset it is a bug in the compiler,
 2511          so we assert here. */
 2512       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2513       /* Fix up any out-of-range offsets. */
 2514       assert_different_registers(rscratch1, base);
 2515       Address addr = Address(base, disp);
 2516       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2517       (masm.*insn)(reg, addr);
 2518     } else {
 2519       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2520       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2521     }
 2522   }
 2523 
 2524   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2525                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2526                         int opcode, Register base, int index, int size, int disp)
 2527   {
 2528     if (index == -1) {
 2529       (masm.*insn)(reg, T, Address(base, disp));
 2530     } else {
 2531       assert(disp == 0, &quot;unsupported address mode&quot;);
 2532       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2533     }
 2534   }
 2535 
 2536 %}
 2537 
 2538 
 2539 
 2540 //----------ENCODING BLOCK-----------------------------------------------------
 2541 // This block specifies the encoding classes used by the compiler to
 2542 // output byte streams.  Encoding classes are parameterized macros
 2543 // used by Machine Instruction Nodes in order to generate the bit
 2544 // encoding of the instruction.  Operands specify their base encoding
 2545 // interface with the interface keyword.  There are currently
 2546 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2547 // COND_INTER.  REG_INTER causes an operand to generate a function
 2548 // which returns its register number when queried.  CONST_INTER causes
 2549 // an operand to generate a function which returns the value of the
 2550 // constant when queried.  MEMORY_INTER causes an operand to generate
 2551 // four functions which return the Base Register, the Index Register,
 2552 // the Scale Value, and the Offset Value of the operand when queried.
 2553 // COND_INTER causes an operand to generate six functions which return
 2554 // the encoding code (ie - encoding bits for the instruction)
 2555 // associated with each basic boolean condition for a conditional
 2556 // instruction.
 2557 //
 2558 // Instructions specify two basic values for encoding.  Again, a
 2559 // function is available to check if the constant displacement is an
 2560 // oop. They use the ins_encode keyword to specify their encoding
 2561 // classes (which must be a sequence of enc_class names, and their
 2562 // parameters, specified in the encoding block), and they use the
 2563 // opcode keyword to specify, in order, their primary, secondary, and
 2564 // tertiary opcode.  Only the opcode sections which a particular
 2565 // instruction needs for encoding need to be specified.
 2566 encode %{
 2567   // Build emit functions for each basic byte or larger field in the
 2568   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2569   // from C++ code in the enc_class source block.  Emit functions will
 2570   // live in the main source block for now.  In future, we can
 2571   // generalize this by adding a syntax that specifies the sizes of
 2572   // fields in an order, so that the adlc can build the emit functions
 2573   // automagically
 2574 
 2575   // catch all for unimplemented encodings
 2576   enc_class enc_unimplemented %{
 2577     C2_MacroAssembler _masm(&amp;cbuf);
 2578     __ unimplemented(&quot;C2 catch all&quot;);
 2579   %}
 2580 
 2581   // BEGIN Non-volatile memory access
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2666     Register dst_reg = as_Register($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2674     Register dst_reg = as_Register($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2682     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2690     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2691     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strb0(memory1 mem) %{
 2706     C2_MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strh0(memory2 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2732                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2733   %}
 2734 
 2735   // This encoding class is generated automatically from ad_encode.m4.
 2736   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2737   enc_class aarch64_enc_strw0(memory4 mem) %{
 2738     C2_MacroAssembler _masm(&amp;cbuf);
 2739     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2746     Register src_reg = as_Register($src$$reg);
 2747     // we sometimes get asked to store the stack pointer into the
 2748     // current thread -- we cannot do that directly on AArch64
 2749     if (src_reg == r31_sp) {
 2750       C2_MacroAssembler _masm(&amp;cbuf);
 2751       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2752       __ mov(rscratch2, sp);
 2753       src_reg = rscratch2;
 2754     }
 2755     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_str0(memory8 mem) %{
 2762     C2_MacroAssembler _masm(&amp;cbuf);
 2763     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2764                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2765   %}
 2766 
 2767   // This encoding class is generated automatically from ad_encode.m4.
 2768   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2769   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2770     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2771     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2772                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2773   %}
 2774 
 2775   // This encoding class is generated automatically from ad_encode.m4.
 2776   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2777   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2778     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2779     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2786     C2_MacroAssembler _masm(&amp;cbuf);
 2787     address con = (address)$src$$constant;
 2788     // need to do this the hard way until we can manage relocs
 2789     // for 32 bit constants
 2790     __ movoop(rscratch2, (jobject)con);
 2791     if (con) __ encode_heap_oop_not_null(rscratch2);
 2792     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2793                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2794   %}
 2795 
 2796   // This encoding class is generated automatically from ad_encode.m4.
 2797   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2798   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2799     C2_MacroAssembler _masm(&amp;cbuf);
 2800     address con = (address)$src$$constant;
 2801     // need to do this the hard way until we can manage relocs
 2802     // for 32 bit constants
 2803     __ movoop(rscratch2, (jobject)con);
 2804     __ encode_klass_not_null(rscratch2);
 2805     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2806                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2807   %}
 2808 
 2809   // This encoding class is generated automatically from ad_encode.m4.
 2810   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2811   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2812       C2_MacroAssembler _masm(&amp;cbuf);
 2813       __ membar(Assembler::StoreStore);
 2814       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2815                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2816   %}
 2817 
 2818   // END Non-volatile memory access
 2819 
 2820   // Vector loads and stores
 2821   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2822     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2823     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2824        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2825   %}
 2826 
 2827   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2828     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2829     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2830        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2831   %}
 2832 
 2833   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2834     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2835     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2836        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2837   %}
 2838 
 2839   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2840     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2841     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2842        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2843   %}
 2844 
 2845   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2846     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2847     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2848        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2849   %}
 2850 
 2851   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2852     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2853     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2854        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2855   %}
 2856 
 2857   // volatile loads and stores
 2858 
 2859   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2860     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2861                  rscratch1, stlrb);
 2862   %}
 2863 
 2864   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2865     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2866                  rscratch1, stlrh);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2870     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2871                  rscratch1, stlrw);
 2872   %}
 2873 
 2874 
 2875   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2876     Register dst_reg = as_Register($dst$$reg);
 2877     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2878              rscratch1, ldarb);
 2879     __ sxtbw(dst_reg, dst_reg);
 2880   %}
 2881 
 2882   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2883     Register dst_reg = as_Register($dst$$reg);
 2884     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2885              rscratch1, ldarb);
 2886     __ sxtb(dst_reg, dst_reg);
 2887   %}
 2888 
 2889   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2890     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2891              rscratch1, ldarb);
 2892   %}
 2893 
 2894   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2895     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2896              rscratch1, ldarb);
 2897   %}
 2898 
 2899   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2900     Register dst_reg = as_Register($dst$$reg);
 2901     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2902              rscratch1, ldarh);
 2903     __ sxthw(dst_reg, dst_reg);
 2904   %}
 2905 
 2906   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2907     Register dst_reg = as_Register($dst$$reg);
 2908     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarh);
 2910     __ sxth(dst_reg, dst_reg);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2914     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldarh);
 2916   %}
 2917 
 2918   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2919     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2920              rscratch1, ldarh);
 2921   %}
 2922 
 2923   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2924     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldarw);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2929     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldarw);
 2931   %}
 2932 
 2933   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2934     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2935              rscratch1, ldar);
 2936   %}
 2937 
 2938   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2939     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2940              rscratch1, ldarw);
 2941     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2942   %}
 2943 
 2944   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2945     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2946              rscratch1, ldar);
 2947     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2948   %}
 2949 
 2950   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2951     Register src_reg = as_Register($src$$reg);
 2952     // we sometimes get asked to store the stack pointer into the
 2953     // current thread -- we cannot do that directly on AArch64
 2954     if (src_reg == r31_sp) {
 2955       C2_MacroAssembler _masm(&amp;cbuf);
 2956       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2957       __ mov(rscratch2, sp);
 2958       src_reg = rscratch2;
 2959     }
 2960     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlr);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2965     {
 2966       C2_MacroAssembler _masm(&amp;cbuf);
 2967       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2968       __ fmovs(rscratch2, src_reg);
 2969     }
 2970     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2971                  rscratch1, stlrw);
 2972   %}
 2973 
 2974   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2975     {
 2976       C2_MacroAssembler _masm(&amp;cbuf);
 2977       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2978       __ fmovd(rscratch2, src_reg);
 2979     }
 2980     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2981                  rscratch1, stlr);
 2982   %}
 2983 
 2984   // synchronized read/update encodings
 2985 
 2986   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2987     C2_MacroAssembler _masm(&amp;cbuf);
 2988     Register dst_reg = as_Register($dst$$reg);
 2989     Register base = as_Register($mem$$base);
 2990     int index = $mem$$index;
 2991     int scale = $mem$$scale;
 2992     int disp = $mem$$disp;
 2993     if (index == -1) {
 2994        if (disp != 0) {
 2995         __ lea(rscratch1, Address(base, disp));
 2996         __ ldaxr(dst_reg, rscratch1);
 2997       } else {
 2998         // TODO
 2999         // should we ever get anything other than this case?
 3000         __ ldaxr(dst_reg, base);
 3001       }
 3002     } else {
 3003       Register index_reg = as_Register(index);
 3004       if (disp == 0) {
 3005         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3006         __ ldaxr(dst_reg, rscratch1);
 3007       } else {
 3008         __ lea(rscratch1, Address(base, disp));
 3009         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3010         __ ldaxr(dst_reg, rscratch1);
 3011       }
 3012     }
 3013   %}
 3014 
 3015   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3016     C2_MacroAssembler _masm(&amp;cbuf);
 3017     Register src_reg = as_Register($src$$reg);
 3018     Register base = as_Register($mem$$base);
 3019     int index = $mem$$index;
 3020     int scale = $mem$$scale;
 3021     int disp = $mem$$disp;
 3022     if (index == -1) {
 3023        if (disp != 0) {
 3024         __ lea(rscratch2, Address(base, disp));
 3025         __ stlxr(rscratch1, src_reg, rscratch2);
 3026       } else {
 3027         // TODO
 3028         // should we ever get anything other than this case?
 3029         __ stlxr(rscratch1, src_reg, base);
 3030       }
 3031     } else {
 3032       Register index_reg = as_Register(index);
 3033       if (disp == 0) {
 3034         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3035         __ stlxr(rscratch1, src_reg, rscratch2);
 3036       } else {
 3037         __ lea(rscratch2, Address(base, disp));
 3038         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3039         __ stlxr(rscratch1, src_reg, rscratch2);
 3040       }
 3041     }
 3042     __ cmpw(rscratch1, zr);
 3043   %}
 3044 
 3045   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3046     C2_MacroAssembler _masm(&amp;cbuf);
 3047     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3048     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3049                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3050                /*weak*/ false, noreg);
 3051   %}
 3052 
 3053   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3054     C2_MacroAssembler _masm(&amp;cbuf);
 3055     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3056     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3057                Assembler::word, /*acquire*/ false, /*release*/ true,
 3058                /*weak*/ false, noreg);
 3059   %}
 3060 
 3061   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3062     C2_MacroAssembler _masm(&amp;cbuf);
 3063     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3064     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3065                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3066                /*weak*/ false, noreg);
 3067   %}
 3068 
 3069   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077 
 3078   // The only difference between aarch64_enc_cmpxchg and
 3079   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3080   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3081   // lock.
 3082   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3083     C2_MacroAssembler _masm(&amp;cbuf);
 3084     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3085     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3086                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3087                /*weak*/ false, noreg);
 3088   %}
 3089 
 3090   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3091     C2_MacroAssembler _masm(&amp;cbuf);
 3092     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3093     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3094                Assembler::word, /*acquire*/ true, /*release*/ true,
 3095                /*weak*/ false, noreg);
 3096   %}
 3097 
 3098   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3099     C2_MacroAssembler _masm(&amp;cbuf);
 3100     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3101     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3102                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3103                /*weak*/ false, noreg);
 3104   %}
 3105 
 3106   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3107     C2_MacroAssembler _masm(&amp;cbuf);
 3108     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3109     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3110                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3111                /*weak*/ false, noreg);
 3112   %}
 3113 
 3114   // auxiliary used for CompareAndSwapX to set result register
 3115   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3116     C2_MacroAssembler _masm(&amp;cbuf);
 3117     Register res_reg = as_Register($res$$reg);
 3118     __ cset(res_reg, Assembler::EQ);
 3119   %}
 3120 
 3121   // prefetch encodings
 3122 
 3123   enc_class aarch64_enc_prefetchw(memory mem) %{
 3124     C2_MacroAssembler _masm(&amp;cbuf);
 3125     Register base = as_Register($mem$$base);
 3126     int index = $mem$$index;
 3127     int scale = $mem$$scale;
 3128     int disp = $mem$$disp;
 3129     if (index == -1) {
 3130       __ prfm(Address(base, disp), PSTL1KEEP);
 3131     } else {
 3132       Register index_reg = as_Register(index);
 3133       if (disp == 0) {
 3134         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3135       } else {
 3136         __ lea(rscratch1, Address(base, disp));
 3137 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3138       }
 3139     }
 3140   %}
 3141 
 3142   /// mov envcodings
 3143 
 3144   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3145     C2_MacroAssembler _masm(&amp;cbuf);
 3146     u_int32_t con = (u_int32_t)$src$$constant;
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     if (con == 0) {
 3149       __ movw(dst_reg, zr);
 3150     } else {
 3151       __ movw(dst_reg, con);
 3152     }
 3153   %}
 3154 
 3155   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3156     C2_MacroAssembler _masm(&amp;cbuf);
 3157     Register dst_reg = as_Register($dst$$reg);
 3158     u_int64_t con = (u_int64_t)$src$$constant;
 3159     if (con == 0) {
 3160       __ mov(dst_reg, zr);
 3161     } else {
 3162       __ mov(dst_reg, con);
 3163     }
 3164   %}
 3165 
 3166   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3167     C2_MacroAssembler _masm(&amp;cbuf);
 3168     Register dst_reg = as_Register($dst$$reg);
 3169     address con = (address)$src$$constant;
 3170     if (con == NULL || con == (address)1) {
 3171       ShouldNotReachHere();
 3172     } else {
 3173       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3174       if (rtype == relocInfo::oop_type) {
 3175         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3176       } else if (rtype == relocInfo::metadata_type) {
 3177         __ mov_metadata(dst_reg, (Metadata*)con);
 3178       } else {
 3179         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3180         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3181           __ mov(dst_reg, con);
 3182         } else {
 3183           unsigned long offset;
 3184           __ adrp(dst_reg, con, offset);
 3185           __ add(dst_reg, dst_reg, offset);
 3186         }
 3187       }
 3188     }
 3189   %}
 3190 
 3191   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3192     C2_MacroAssembler _masm(&amp;cbuf);
 3193     Register dst_reg = as_Register($dst$$reg);
 3194     __ mov(dst_reg, zr);
 3195   %}
 3196 
 3197   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3198     C2_MacroAssembler _masm(&amp;cbuf);
 3199     Register dst_reg = as_Register($dst$$reg);
 3200     __ mov(dst_reg, (u_int64_t)1);
 3201   %}
 3202 
 3203   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3204     C2_MacroAssembler _masm(&amp;cbuf);
 3205     __ load_byte_map_base($dst$$Register);
 3206   %}
 3207 
 3208   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3209     C2_MacroAssembler _masm(&amp;cbuf);
 3210     Register dst_reg = as_Register($dst$$reg);
 3211     address con = (address)$src$$constant;
 3212     if (con == NULL) {
 3213       ShouldNotReachHere();
 3214     } else {
 3215       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3216       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3217       __ set_narrow_oop(dst_reg, (jobject)con);
 3218     }
 3219   %}
 3220 
 3221   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3222     C2_MacroAssembler _masm(&amp;cbuf);
 3223     Register dst_reg = as_Register($dst$$reg);
 3224     __ mov(dst_reg, zr);
 3225   %}
 3226 
 3227   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3228     C2_MacroAssembler _masm(&amp;cbuf);
 3229     Register dst_reg = as_Register($dst$$reg);
 3230     address con = (address)$src$$constant;
 3231     if (con == NULL) {
 3232       ShouldNotReachHere();
 3233     } else {
 3234       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3235       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3236       __ set_narrow_klass(dst_reg, (Klass *)con);
 3237     }
 3238   %}
 3239 
 3240   // arithmetic encodings
 3241 
 3242   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3243     C2_MacroAssembler _masm(&amp;cbuf);
 3244     Register dst_reg = as_Register($dst$$reg);
 3245     Register src_reg = as_Register($src1$$reg);
 3246     int32_t con = (int32_t)$src2$$constant;
 3247     // add has primary == 0, subtract has primary == 1
 3248     if ($primary) { con = -con; }
 3249     if (con &lt; 0) {
 3250       __ subw(dst_reg, src_reg, -con);
 3251     } else {
 3252       __ addw(dst_reg, src_reg, con);
 3253     }
 3254   %}
 3255 
 3256   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3257     C2_MacroAssembler _masm(&amp;cbuf);
 3258     Register dst_reg = as_Register($dst$$reg);
 3259     Register src_reg = as_Register($src1$$reg);
 3260     int32_t con = (int32_t)$src2$$constant;
 3261     // add has primary == 0, subtract has primary == 1
 3262     if ($primary) { con = -con; }
 3263     if (con &lt; 0) {
 3264       __ sub(dst_reg, src_reg, -con);
 3265     } else {
 3266       __ add(dst_reg, src_reg, con);
 3267     }
 3268   %}
 3269 
 3270   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     C2_MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3279     C2_MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3284   %}
 3285 
 3286   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3287     C2_MacroAssembler _masm(&amp;cbuf);
 3288    Register dst_reg = as_Register($dst$$reg);
 3289    Register src1_reg = as_Register($src1$$reg);
 3290    Register src2_reg = as_Register($src2$$reg);
 3291     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3292   %}
 3293 
 3294   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3295     C2_MacroAssembler _masm(&amp;cbuf);
 3296    Register dst_reg = as_Register($dst$$reg);
 3297    Register src1_reg = as_Register($src1$$reg);
 3298    Register src2_reg = as_Register($src2$$reg);
 3299     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3300   %}
 3301 
 3302   // compare instruction encodings
 3303 
 3304   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3305     C2_MacroAssembler _masm(&amp;cbuf);
 3306     Register reg1 = as_Register($src1$$reg);
 3307     Register reg2 = as_Register($src2$$reg);
 3308     __ cmpw(reg1, reg2);
 3309   %}
 3310 
 3311   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3312     C2_MacroAssembler _masm(&amp;cbuf);
 3313     Register reg = as_Register($src1$$reg);
 3314     int32_t val = $src2$$constant;
 3315     if (val &gt;= 0) {
 3316       __ subsw(zr, reg, val);
 3317     } else {
 3318       __ addsw(zr, reg, -val);
 3319     }
 3320   %}
 3321 
 3322   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3323     C2_MacroAssembler _masm(&amp;cbuf);
 3324     Register reg1 = as_Register($src1$$reg);
 3325     u_int32_t val = (u_int32_t)$src2$$constant;
 3326     __ movw(rscratch1, val);
 3327     __ cmpw(reg1, rscratch1);
 3328   %}
 3329 
 3330   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3331     C2_MacroAssembler _masm(&amp;cbuf);
 3332     Register reg1 = as_Register($src1$$reg);
 3333     Register reg2 = as_Register($src2$$reg);
 3334     __ cmp(reg1, reg2);
 3335   %}
 3336 
 3337   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3338     C2_MacroAssembler _masm(&amp;cbuf);
 3339     Register reg = as_Register($src1$$reg);
 3340     int64_t val = $src2$$constant;
 3341     if (val &gt;= 0) {
 3342       __ subs(zr, reg, val);
 3343     } else if (val != -val) {
 3344       __ adds(zr, reg, -val);
 3345     } else {
 3346     // aargh, Long.MIN_VALUE is a special case
 3347       __ orr(rscratch1, zr, (u_int64_t)val);
 3348       __ subs(zr, reg, rscratch1);
 3349     }
 3350   %}
 3351 
 3352   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3353     C2_MacroAssembler _masm(&amp;cbuf);
 3354     Register reg1 = as_Register($src1$$reg);
 3355     u_int64_t val = (u_int64_t)$src2$$constant;
 3356     __ mov(rscratch1, val);
 3357     __ cmp(reg1, rscratch1);
 3358   %}
 3359 
 3360   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3361     C2_MacroAssembler _masm(&amp;cbuf);
 3362     Register reg1 = as_Register($src1$$reg);
 3363     Register reg2 = as_Register($src2$$reg);
 3364     __ cmp(reg1, reg2);
 3365   %}
 3366 
 3367   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3368     C2_MacroAssembler _masm(&amp;cbuf);
 3369     Register reg1 = as_Register($src1$$reg);
 3370     Register reg2 = as_Register($src2$$reg);
 3371     __ cmpw(reg1, reg2);
 3372   %}
 3373 
 3374   enc_class aarch64_enc_testp(iRegP src) %{
 3375     C2_MacroAssembler _masm(&amp;cbuf);
 3376     Register reg = as_Register($src$$reg);
 3377     __ cmp(reg, zr);
 3378   %}
 3379 
 3380   enc_class aarch64_enc_testn(iRegN src) %{
 3381     C2_MacroAssembler _masm(&amp;cbuf);
 3382     Register reg = as_Register($src$$reg);
 3383     __ cmpw(reg, zr);
 3384   %}
 3385 
 3386   enc_class aarch64_enc_b(label lbl) %{
 3387     C2_MacroAssembler _masm(&amp;cbuf);
 3388     Label *L = $lbl$$label;
 3389     __ b(*L);
 3390   %}
 3391 
 3392   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3393     C2_MacroAssembler _masm(&amp;cbuf);
 3394     Label *L = $lbl$$label;
 3395     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3396   %}
 3397 
 3398   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3399     C2_MacroAssembler _masm(&amp;cbuf);
 3400     Label *L = $lbl$$label;
 3401     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3402   %}
 3403 
 3404   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3405   %{
 3406      Register sub_reg = as_Register($sub$$reg);
 3407      Register super_reg = as_Register($super$$reg);
 3408      Register temp_reg = as_Register($temp$$reg);
 3409      Register result_reg = as_Register($result$$reg);
 3410 
 3411      Label miss;
 3412      C2_MacroAssembler _masm(&amp;cbuf);
 3413      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3414                                      NULL, &amp;miss,
 3415                                      /*set_cond_codes:*/ true);
 3416      if ($primary) {
 3417        __ mov(result_reg, zr);
 3418      }
 3419      __ bind(miss);
 3420   %}
 3421 
 3422   enc_class aarch64_enc_java_static_call(method meth) %{
 3423     C2_MacroAssembler _masm(&amp;cbuf);
 3424 
 3425     address addr = (address)$meth$$method;
 3426     address call;
 3427     if (!_method) {
 3428       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3429       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3430     } else {
 3431       int method_index = resolved_method_index(cbuf);
 3432       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3433                                                   : static_call_Relocation::spec(method_index);
 3434       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3435 
 3436       // Emit stub for static call
 3437       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3438       if (stub == NULL) {
 3439         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3440         return;
 3441       }
 3442     }
 3443     if (call == NULL) {
 3444       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3445       return;
 3446     }
 3447   %}
 3448 
 3449   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3450     C2_MacroAssembler _masm(&amp;cbuf);
 3451     int method_index = resolved_method_index(cbuf);
 3452     address call = __ ic_call((address)$meth$$method, method_index);
 3453     if (call == NULL) {
 3454       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3455       return;
 3456     }
 3457   %}
 3458 
 3459   enc_class aarch64_enc_call_epilog() %{
 3460     C2_MacroAssembler _masm(&amp;cbuf);
 3461     if (VerifyStackAtCalls) {
 3462       // Check that stack depth is unchanged: find majik cookie on stack
 3463       __ call_Unimplemented();
 3464     }
 3465   %}
 3466 
 3467   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3468     C2_MacroAssembler _masm(&amp;cbuf);
 3469 
 3470     // some calls to generated routines (arraycopy code) are scheduled
 3471     // by C2 as runtime calls. if so we can call them using a br (they
 3472     // will be in a reachable segment) otherwise we have to use a blr
 3473     // which loads the absolute address into a register.
 3474     address entry = (address)$meth$$method;
 3475     CodeBlob *cb = CodeCache::find_blob(entry);
 3476     if (cb) {
 3477       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3478       if (call == NULL) {
 3479         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3480         return;
 3481       }
 3482     } else {
 3483       Label retaddr;
 3484       __ adr(rscratch2, retaddr);
 3485       __ lea(rscratch1, RuntimeAddress(entry));
 3486       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3487       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3488       __ blr(rscratch1);
 3489       __ bind(retaddr);
 3490       __ add(sp, sp, 2 * wordSize);
 3491     }
 3492   %}
 3493 
 3494   enc_class aarch64_enc_rethrow() %{
 3495     C2_MacroAssembler _masm(&amp;cbuf);
 3496     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3497   %}
 3498 
 3499   enc_class aarch64_enc_ret() %{
 3500     C2_MacroAssembler _masm(&amp;cbuf);
 3501     __ ret(lr);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3505     C2_MacroAssembler _masm(&amp;cbuf);
 3506     Register target_reg = as_Register($jump_target$$reg);
 3507     __ br(target_reg);
 3508   %}
 3509 
 3510   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3511     C2_MacroAssembler _masm(&amp;cbuf);
 3512     Register target_reg = as_Register($jump_target$$reg);
 3513     // exception oop should be in r0
 3514     // ret addr has been popped into lr
 3515     // callee expects it in r3
 3516     __ mov(r3, lr);
 3517     __ br(target_reg);
 3518   %}
 3519 
 3520   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3521     C2_MacroAssembler _masm(&amp;cbuf);
 3522     Register oop = as_Register($object$$reg);
 3523     Register box = as_Register($box$$reg);
 3524     Register disp_hdr = as_Register($tmp$$reg);
 3525     Register tmp = as_Register($tmp2$$reg);
 3526     Label cont;
 3527     Label object_has_monitor;
 3528     Label cas_failed;
 3529 
 3530     assert_different_registers(oop, box, tmp, disp_hdr);
 3531 
 3532     // Load markWord from object into displaced_header.
 3533     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3534 
 3535     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3536       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3537     }
 3538 
 3539     // Check for existing monitor
 3540     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3541 
 3542     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3543     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3544 
 3545     // Initialize the box. (Must happen before we update the object mark!)
 3546     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3547 
 3548     // Compare object markWord with an unlocked value (tmp) and if
 3549     // equal exchange the stack address of our box with object markWord.
 3550     // On failure disp_hdr contains the possibly locked markWord.
 3551     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3552                /*release*/ true, /*weak*/ false, disp_hdr);
 3553     __ br(Assembler::EQ, cont);
 3554 
 3555     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3556 
 3557     // If the compare-and-exchange succeeded, then we found an unlocked
 3558     // object, will have now locked it will continue at label cont
 3559 
 3560     __ bind(cas_failed);
 3561     // We did not see an unlocked object so try the fast recursive case.
 3562 
 3563     // Check if the owner is self by comparing the value in the
 3564     // markWord of object (disp_hdr) with the stack pointer.
 3565     __ mov(rscratch1, sp);
 3566     __ sub(disp_hdr, disp_hdr, rscratch1);
 3567     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3568     // If condition is true we are cont and hence we can store 0 as the
 3569     // displaced header in the box, which indicates that it is a recursive lock.
 3570     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3571     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3572 
 3573     __ b(cont);
 3574 
 3575     // Handle existing monitor.
 3576     __ bind(object_has_monitor);
 3577 
 3578     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3579     // otherwise m-&gt;owner may contain a thread or a stack address.
 3580     //
 3581     // Try to CAS m-&gt;owner from NULL to current thread.
 3582     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3583     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3584                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3585 
 3586     // Store a non-null value into the box to avoid looking like a re-entrant
 3587     // lock. The fast-path monitor unlock code checks for
 3588     // markWord::monitor_value so use markWord::unused_mark which has the
 3589     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3590     __ mov(tmp, (address)markWord::unused_mark().value());
 3591     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3592 
 3593     __ bind(cont);
 3594     // flag == EQ indicates success
 3595     // flag == NE indicates failure
 3596   %}
 3597 
 3598   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3599     C2_MacroAssembler _masm(&amp;cbuf);
 3600     Register oop = as_Register($object$$reg);
 3601     Register box = as_Register($box$$reg);
 3602     Register disp_hdr = as_Register($tmp$$reg);
 3603     Register tmp = as_Register($tmp2$$reg);
 3604     Label cont;
 3605     Label object_has_monitor;
 3606 
 3607     assert_different_registers(oop, box, tmp, disp_hdr);
 3608 
 3609     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3610       __ biased_locking_exit(oop, tmp, cont);
 3611     }
 3612 
 3613     // Find the lock address and load the displaced header from the stack.
 3614     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3615 
 3616     // If the displaced header is 0, we have a recursive unlock.
 3617     __ cmp(disp_hdr, zr);
 3618     __ br(Assembler::EQ, cont);
 3619 
 3620     // Handle existing monitor.
 3621     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3622     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3623 
 3624     // Check if it is still a light weight lock, this is is true if we
 3625     // see the stack address of the basicLock in the markWord of the
 3626     // object.
 3627 
 3628     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3629                /*release*/ true, /*weak*/ false, tmp);
 3630     __ b(cont);
 3631 
 3632     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3633 
 3634     // Handle existing monitor.
 3635     __ bind(object_has_monitor);
 3636     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3637     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3638     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3639     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3640     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3641     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3642     __ cmp(rscratch1, zr); // Sets flags for result
 3643     __ br(Assembler::NE, cont);
 3644 
 3645     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3646     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3647     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3648     __ cmp(rscratch1, zr); // Sets flags for result
 3649     __ cbnz(rscratch1, cont);
 3650     // need a release store here
 3651     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3652     __ stlr(zr, tmp); // set unowned
 3653 
 3654     __ bind(cont);
 3655     // flag == EQ indicates success
 3656     // flag == NE indicates failure
 3657   %}
 3658 
 3659 %}
 3660 
 3661 //----------FRAME--------------------------------------------------------------
 3662 // Definition of frame structure and management information.
 3663 //
 3664 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3665 //                             |   (to get allocators register number
 3666 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3667 //  r   CALLER     |        |
 3668 //  o     |        +--------+      pad to even-align allocators stack-slot
 3669 //  w     V        |  pad0  |        numbers; owned by CALLER
 3670 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3671 //  h     ^        |   in   |  5
 3672 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3673 //  |     |        |        |  3
 3674 //  |     |        +--------+
 3675 //  V     |        | old out|      Empty on Intel, window on Sparc
 3676 //        |    old |preserve|      Must be even aligned.
 3677 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3678 //        |        |   in   |  3   area for Intel ret address
 3679 //     Owned by    |preserve|      Empty on Sparc.
 3680 //       SELF      +--------+
 3681 //        |        |  pad2  |  2   pad to align old SP
 3682 //        |        +--------+  1
 3683 //        |        | locks  |  0
 3684 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3685 //        |        |  pad1  | 11   pad to align new SP
 3686 //        |        +--------+
 3687 //        |        |        | 10
 3688 //        |        | spills |  9   spills
 3689 //        V        |        |  8   (pad0 slot for callee)
 3690 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3691 //        ^        |  out   |  7
 3692 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3693 //     Owned by    +--------+
 3694 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3695 //        |    new |preserve|      Must be even-aligned.
 3696 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3697 //        |        |        |
 3698 //
 3699 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3700 //         known from SELF&#39;s arguments and the Java calling convention.
 3701 //         Region 6-7 is determined per call site.
 3702 // Note 2: If the calling convention leaves holes in the incoming argument
 3703 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3704 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3705 //         incoming area, as the Java calling convention is completely under
 3706 //         the control of the AD file.  Doubles can be sorted and packed to
 3707 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3708 //         varargs C calling conventions.
 3709 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3710 //         even aligned with pad0 as needed.
 3711 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3712 //           (the latter is true on Intel but is it false on AArch64?)
 3713 //         region 6-11 is even aligned; it may be padded out more so that
 3714 //         the region from SP to FP meets the minimum stack alignment.
 3715 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3716 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3717 //         SP meets the minimum alignment.
 3718 
 3719 frame %{
 3720   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3721   stack_direction(TOWARDS_LOW);
 3722 
 3723   // These three registers define part of the calling convention
 3724   // between compiled code and the interpreter.
 3725 
 3726   // Inline Cache Register or methodOop for I2C.
 3727   inline_cache_reg(R12);
 3728 
 3729   // Method Oop Register when calling interpreter.
 3730   interpreter_method_oop_reg(R12);
 3731 
 3732   // Number of stack slots consumed by locking an object
 3733   sync_stack_slots(2);
 3734 
 3735   // Compiled code&#39;s Frame Pointer
 3736   frame_pointer(R31);
 3737 
 3738   // Interpreter stores its frame pointer in a register which is
 3739   // stored to the stack by I2CAdaptors.
 3740   // I2CAdaptors convert from interpreted java to compiled java.
 3741   interpreter_frame_pointer(R29);
 3742 
 3743   // Stack alignment requirement
 3744   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3745 
 3746   // Number of stack slots between incoming argument block and the start of
 3747   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3748   // EPILOG must remove this many slots. aarch64 needs two slots for
 3749   // return address and fp.
 3750   // TODO think this is correct but check
 3751   in_preserve_stack_slots(4);
 3752 
 3753   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3754   // for calls to C.  Supports the var-args backing area for register parms.
 3755   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3756 
 3757   // The after-PROLOG location of the return address.  Location of
 3758   // return address specifies a type (REG or STACK) and a number
 3759   // representing the register number (i.e. - use a register name) or
 3760   // stack slot.
 3761   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3762   // Otherwise, it is above the locks and verification slot and alignment word
 3763   // TODO this may well be correct but need to check why that - 2 is there
 3764   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3765   // which folds in the space used for monitors
 3766   return_addr(STACK - 2 +
 3767               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3768                         Compile::current()-&gt;fixed_slots()),
 3769                        stack_alignment_in_slots()));
 3770 
 3771   // Body of function which returns an integer array locating
 3772   // arguments either in registers or in stack slots.  Passed an array
 3773   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3774   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3775   // arguments for a CALLEE.  Incoming stack arguments are
 3776   // automatically biased by the preserve_stack_slots field above.
 3777 
 3778   calling_convention
 3779   %{
 3780     // No difference between ingoing/outgoing just pass false
 3781     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3782   %}
 3783 
 3784   c_calling_convention
 3785   %{
 3786     // This is obviously always outgoing
 3787     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3788   %}
 3789 
 3790   // Location of compiled Java return values.  Same as C for now.
 3791   return_value
 3792   %{
 3793     // TODO do we allow ideal_reg == Op_RegN???
 3794     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3795            &quot;only return normal values&quot;);
 3796 
 3797     static const int lo[Op_RegL + 1] = { // enum name
 3798       0,                                 // Op_Node
 3799       0,                                 // Op_Set
 3800       R0_num,                            // Op_RegN
 3801       R0_num,                            // Op_RegI
 3802       R0_num,                            // Op_RegP
 3803       V0_num,                            // Op_RegF
 3804       V0_num,                            // Op_RegD
 3805       R0_num                             // Op_RegL
 3806     };
 3807 
 3808     static const int hi[Op_RegL + 1] = { // enum name
 3809       0,                                 // Op_Node
 3810       0,                                 // Op_Set
 3811       OptoReg::Bad,                      // Op_RegN
 3812       OptoReg::Bad,                      // Op_RegI
 3813       R0_H_num,                          // Op_RegP
 3814       OptoReg::Bad,                      // Op_RegF
 3815       V0_H_num,                          // Op_RegD
 3816       R0_H_num                           // Op_RegL
 3817     };
 3818 
 3819     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3820   %}
 3821 %}
 3822 
 3823 //----------ATTRIBUTES---------------------------------------------------------
 3824 //----------Operand Attributes-------------------------------------------------
 3825 op_attrib op_cost(1);        // Required cost attribute
 3826 
 3827 //----------Instruction Attributes---------------------------------------------
 3828 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3829 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3830 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3831                                 // a non-matching short branch variant
 3832                                 // of some long branch?
 3833 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3834                                 // be a power of 2) specifies the
 3835                                 // alignment that some part of the
 3836                                 // instruction (not necessarily the
 3837                                 // start) requires.  If &gt; 1, a
 3838                                 // compute_padding() function must be
 3839                                 // provided for the instruction
 3840 
 3841 //----------OPERANDS-----------------------------------------------------------
 3842 // Operand definitions must precede instruction definitions for correct parsing
 3843 // in the ADLC because operands constitute user defined types which are used in
 3844 // instruction definitions.
 3845 
 3846 //----------Simple Operands----------------------------------------------------
 3847 
 3848 // Integer operands 32 bit
 3849 // 32 bit immediate
 3850 operand immI()
 3851 %{
 3852   match(ConI);
 3853 
 3854   op_cost(0);
 3855   format %{ %}
 3856   interface(CONST_INTER);
 3857 %}
 3858 
 3859 // 32 bit zero
 3860 operand immI0()
 3861 %{
 3862   predicate(n-&gt;get_int() == 0);
 3863   match(ConI);
 3864 
 3865   op_cost(0);
 3866   format %{ %}
 3867   interface(CONST_INTER);
 3868 %}
 3869 
 3870 // 32 bit unit increment
 3871 operand immI_1()
 3872 %{
 3873   predicate(n-&gt;get_int() == 1);
 3874   match(ConI);
 3875 
 3876   op_cost(0);
 3877   format %{ %}
 3878   interface(CONST_INTER);
 3879 %}
 3880 
 3881 // 32 bit unit decrement
 3882 operand immI_M1()
 3883 %{
 3884   predicate(n-&gt;get_int() == -1);
 3885   match(ConI);
 3886 
 3887   op_cost(0);
 3888   format %{ %}
 3889   interface(CONST_INTER);
 3890 %}
 3891 
 3892 // Shift values for add/sub extension shift
 3893 operand immIExt()
 3894 %{
 3895   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3896   match(ConI);
 3897 
 3898   op_cost(0);
 3899   format %{ %}
 3900   interface(CONST_INTER);
 3901 %}
 3902 
 3903 operand immI_le_4()
 3904 %{
 3905   predicate(n-&gt;get_int() &lt;= 4);
 3906   match(ConI);
 3907 
 3908   op_cost(0);
 3909   format %{ %}
 3910   interface(CONST_INTER);
 3911 %}
 3912 
 3913 operand immI_31()
 3914 %{
 3915   predicate(n-&gt;get_int() == 31);
 3916   match(ConI);
 3917 
 3918   op_cost(0);
 3919   format %{ %}
 3920   interface(CONST_INTER);
 3921 %}
 3922 
 3923 operand immI_8()
 3924 %{
 3925   predicate(n-&gt;get_int() == 8);
 3926   match(ConI);
 3927 
 3928   op_cost(0);
 3929   format %{ %}
 3930   interface(CONST_INTER);
 3931 %}
 3932 
 3933 operand immI_16()
 3934 %{
 3935   predicate(n-&gt;get_int() == 16);
 3936   match(ConI);
 3937 
 3938   op_cost(0);
 3939   format %{ %}
 3940   interface(CONST_INTER);
 3941 %}
 3942 
 3943 operand immI_24()
 3944 %{
 3945   predicate(n-&gt;get_int() == 24);
 3946   match(ConI);
 3947 
 3948   op_cost(0);
 3949   format %{ %}
 3950   interface(CONST_INTER);
 3951 %}
 3952 
 3953 operand immI_32()
 3954 %{
 3955   predicate(n-&gt;get_int() == 32);
 3956   match(ConI);
 3957 
 3958   op_cost(0);
 3959   format %{ %}
 3960   interface(CONST_INTER);
 3961 %}
 3962 
 3963 operand immI_48()
 3964 %{
 3965   predicate(n-&gt;get_int() == 48);
 3966   match(ConI);
 3967 
 3968   op_cost(0);
 3969   format %{ %}
 3970   interface(CONST_INTER);
 3971 %}
 3972 
 3973 operand immI_56()
 3974 %{
 3975   predicate(n-&gt;get_int() == 56);
 3976   match(ConI);
 3977 
 3978   op_cost(0);
 3979   format %{ %}
 3980   interface(CONST_INTER);
 3981 %}
 3982 
 3983 operand immI_63()
 3984 %{
 3985   predicate(n-&gt;get_int() == 63);
 3986   match(ConI);
 3987 
 3988   op_cost(0);
 3989   format %{ %}
 3990   interface(CONST_INTER);
 3991 %}
 3992 
 3993 operand immI_64()
 3994 %{
 3995   predicate(n-&gt;get_int() == 64);
 3996   match(ConI);
 3997 
 3998   op_cost(0);
 3999   format %{ %}
 4000   interface(CONST_INTER);
 4001 %}
 4002 
 4003 operand immI_255()
 4004 %{
 4005   predicate(n-&gt;get_int() == 255);
 4006   match(ConI);
 4007 
 4008   op_cost(0);
 4009   format %{ %}
 4010   interface(CONST_INTER);
 4011 %}
 4012 
 4013 operand immI_65535()
 4014 %{
 4015   predicate(n-&gt;get_int() == 65535);
 4016   match(ConI);
 4017 
 4018   op_cost(0);
 4019   format %{ %}
 4020   interface(CONST_INTER);
 4021 %}
 4022 
 4023 operand immL_255()
 4024 %{
 4025   predicate(n-&gt;get_long() == 255L);
 4026   match(ConL);
 4027 
 4028   op_cost(0);
 4029   format %{ %}
 4030   interface(CONST_INTER);
 4031 %}
 4032 
 4033 operand immL_65535()
 4034 %{
 4035   predicate(n-&gt;get_long() == 65535L);
 4036   match(ConL);
 4037 
 4038   op_cost(0);
 4039   format %{ %}
 4040   interface(CONST_INTER);
 4041 %}
 4042 
 4043 operand immL_4294967295()
 4044 %{
 4045   predicate(n-&gt;get_long() == 4294967295L);
 4046   match(ConL);
 4047 
 4048   op_cost(0);
 4049   format %{ %}
 4050   interface(CONST_INTER);
 4051 %}
 4052 
 4053 operand immL_bitmask()
 4054 %{
 4055   predicate((n-&gt;get_long() != 0)
 4056             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4057             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4058   match(ConL);
 4059 
 4060   op_cost(0);
 4061   format %{ %}
 4062   interface(CONST_INTER);
 4063 %}
 4064 
 4065 operand immI_bitmask()
 4066 %{
 4067   predicate((n-&gt;get_int() != 0)
 4068             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4069             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4070   match(ConI);
 4071 
 4072   op_cost(0);
 4073   format %{ %}
 4074   interface(CONST_INTER);
 4075 %}
 4076 
 4077 // Scale values for scaled offset addressing modes (up to long but not quad)
 4078 operand immIScale()
 4079 %{
 4080   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4081   match(ConI);
 4082 
 4083   op_cost(0);
 4084   format %{ %}
 4085   interface(CONST_INTER);
 4086 %}
 4087 
 4088 // 26 bit signed offset -- for pc-relative branches
 4089 operand immI26()
 4090 %{
 4091   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4092   match(ConI);
 4093 
 4094   op_cost(0);
 4095   format %{ %}
 4096   interface(CONST_INTER);
 4097 %}
 4098 
 4099 // 19 bit signed offset -- for pc-relative loads
 4100 operand immI19()
 4101 %{
 4102   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4103   match(ConI);
 4104 
 4105   op_cost(0);
 4106   format %{ %}
 4107   interface(CONST_INTER);
 4108 %}
 4109 
 4110 // 12 bit unsigned offset -- for base plus immediate loads
 4111 operand immIU12()
 4112 %{
 4113   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4114   match(ConI);
 4115 
 4116   op_cost(0);
 4117   format %{ %}
 4118   interface(CONST_INTER);
 4119 %}
 4120 
 4121 operand immLU12()
 4122 %{
 4123   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4124   match(ConL);
 4125 
 4126   op_cost(0);
 4127   format %{ %}
 4128   interface(CONST_INTER);
 4129 %}
 4130 
 4131 // Offset for scaled or unscaled immediate loads and stores
 4132 operand immIOffset()
 4133 %{
 4134   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4135   match(ConI);
 4136 
 4137   op_cost(0);
 4138   format %{ %}
 4139   interface(CONST_INTER);
 4140 %}
 4141 
 4142 operand immIOffset1()
 4143 %{
 4144   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4145   match(ConI);
 4146 
 4147   op_cost(0);
 4148   format %{ %}
 4149   interface(CONST_INTER);
 4150 %}
 4151 
 4152 operand immIOffset2()
 4153 %{
 4154   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4155   match(ConI);
 4156 
 4157   op_cost(0);
 4158   format %{ %}
 4159   interface(CONST_INTER);
 4160 %}
 4161 
 4162 operand immIOffset4()
 4163 %{
 4164   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4165   match(ConI);
 4166 
 4167   op_cost(0);
 4168   format %{ %}
 4169   interface(CONST_INTER);
 4170 %}
 4171 
 4172 operand immIOffset8()
 4173 %{
 4174   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4175   match(ConI);
 4176 
 4177   op_cost(0);
 4178   format %{ %}
 4179   interface(CONST_INTER);
 4180 %}
 4181 
 4182 operand immIOffset16()
 4183 %{
 4184   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4185   match(ConI);
 4186 
 4187   op_cost(0);
 4188   format %{ %}
 4189   interface(CONST_INTER);
 4190 %}
 4191 
 4192 operand immLoffset()
 4193 %{
 4194   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4195   match(ConL);
 4196 
 4197   op_cost(0);
 4198   format %{ %}
 4199   interface(CONST_INTER);
 4200 %}
 4201 
 4202 operand immLoffset1()
 4203 %{
 4204   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4205   match(ConL);
 4206 
 4207   op_cost(0);
 4208   format %{ %}
 4209   interface(CONST_INTER);
 4210 %}
 4211 
 4212 operand immLoffset2()
 4213 %{
 4214   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4215   match(ConL);
 4216 
 4217   op_cost(0);
 4218   format %{ %}
 4219   interface(CONST_INTER);
 4220 %}
 4221 
 4222 operand immLoffset4()
 4223 %{
 4224   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4225   match(ConL);
 4226 
 4227   op_cost(0);
 4228   format %{ %}
 4229   interface(CONST_INTER);
 4230 %}
 4231 
 4232 operand immLoffset8()
 4233 %{
 4234   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4235   match(ConL);
 4236 
 4237   op_cost(0);
 4238   format %{ %}
 4239   interface(CONST_INTER);
 4240 %}
 4241 
 4242 operand immLoffset16()
 4243 %{
 4244   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4245   match(ConL);
 4246 
 4247   op_cost(0);
 4248   format %{ %}
 4249   interface(CONST_INTER);
 4250 %}
 4251 
 4252 // 32 bit integer valid for add sub immediate
 4253 operand immIAddSub()
 4254 %{
 4255   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4256   match(ConI);
 4257   op_cost(0);
 4258   format %{ %}
 4259   interface(CONST_INTER);
 4260 %}
 4261 
 4262 // 32 bit unsigned integer valid for logical immediate
 4263 // TODO -- check this is right when e.g the mask is 0x80000000
 4264 operand immILog()
 4265 %{
 4266   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4267   match(ConI);
 4268 
 4269   op_cost(0);
 4270   format %{ %}
 4271   interface(CONST_INTER);
 4272 %}
 4273 
 4274 // Integer operands 64 bit
 4275 // 64 bit immediate
 4276 operand immL()
 4277 %{
 4278   match(ConL);
 4279 
 4280   op_cost(0);
 4281   format %{ %}
 4282   interface(CONST_INTER);
 4283 %}
 4284 
 4285 // 64 bit zero
 4286 operand immL0()
 4287 %{
 4288   predicate(n-&gt;get_long() == 0);
 4289   match(ConL);
 4290 
 4291   op_cost(0);
 4292   format %{ %}
 4293   interface(CONST_INTER);
 4294 %}
 4295 
 4296 // 64 bit unit increment
 4297 operand immL_1()
 4298 %{
 4299   predicate(n-&gt;get_long() == 1);
 4300   match(ConL);
 4301 
 4302   op_cost(0);
 4303   format %{ %}
 4304   interface(CONST_INTER);
 4305 %}
 4306 
 4307 // 64 bit unit decrement
 4308 operand immL_M1()
 4309 %{
 4310   predicate(n-&gt;get_long() == -1);
 4311   match(ConL);
 4312 
 4313   op_cost(0);
 4314   format %{ %}
 4315   interface(CONST_INTER);
 4316 %}
 4317 
 4318 // 32 bit offset of pc in thread anchor
 4319 
 4320 operand immL_pc_off()
 4321 %{
 4322   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4323                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4324   match(ConL);
 4325 
 4326   op_cost(0);
 4327   format %{ %}
 4328   interface(CONST_INTER);
 4329 %}
 4330 
 4331 // 64 bit integer valid for add sub immediate
 4332 operand immLAddSub()
 4333 %{
 4334   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4335   match(ConL);
 4336   op_cost(0);
 4337   format %{ %}
 4338   interface(CONST_INTER);
 4339 %}
 4340 
 4341 // 64 bit integer valid for logical immediate
 4342 operand immLLog()
 4343 %{
 4344   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4345   match(ConL);
 4346   op_cost(0);
 4347   format %{ %}
 4348   interface(CONST_INTER);
 4349 %}
 4350 
 4351 // Long Immediate: low 32-bit mask
 4352 operand immL_32bits()
 4353 %{
 4354   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4355   match(ConL);
 4356   op_cost(0);
 4357   format %{ %}
 4358   interface(CONST_INTER);
 4359 %}
 4360 
 4361 // Pointer operands
 4362 // Pointer Immediate
 4363 operand immP()
 4364 %{
 4365   match(ConP);
 4366 
 4367   op_cost(0);
 4368   format %{ %}
 4369   interface(CONST_INTER);
 4370 %}
 4371 
 4372 // NULL Pointer Immediate
 4373 operand immP0()
 4374 %{
 4375   predicate(n-&gt;get_ptr() == 0);
 4376   match(ConP);
 4377 
 4378   op_cost(0);
 4379   format %{ %}
 4380   interface(CONST_INTER);
 4381 %}
 4382 
 4383 // Pointer Immediate One
 4384 // this is used in object initialization (initial object header)
 4385 operand immP_1()
 4386 %{
 4387   predicate(n-&gt;get_ptr() == 1);
 4388   match(ConP);
 4389 
 4390   op_cost(0);
 4391   format %{ %}
 4392   interface(CONST_INTER);
 4393 %}
 4394 
 4395 // Card Table Byte Map Base
 4396 operand immByteMapBase()
 4397 %{
 4398   // Get base of card map
 4399   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4400             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4401   match(ConP);
 4402 
 4403   op_cost(0);
 4404   format %{ %}
 4405   interface(CONST_INTER);
 4406 %}
 4407 
 4408 // Pointer Immediate Minus One
 4409 // this is used when we want to write the current PC to the thread anchor
 4410 operand immP_M1()
 4411 %{
 4412   predicate(n-&gt;get_ptr() == -1);
 4413   match(ConP);
 4414 
 4415   op_cost(0);
 4416   format %{ %}
 4417   interface(CONST_INTER);
 4418 %}
 4419 
 4420 // Pointer Immediate Minus Two
 4421 // this is used when we want to write the current PC to the thread anchor
 4422 operand immP_M2()
 4423 %{
 4424   predicate(n-&gt;get_ptr() == -2);
 4425   match(ConP);
 4426 
 4427   op_cost(0);
 4428   format %{ %}
 4429   interface(CONST_INTER);
 4430 %}
 4431 
 4432 // Float and Double operands
 4433 // Double Immediate
 4434 operand immD()
 4435 %{
 4436   match(ConD);
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // Double Immediate: +0.0d
 4443 operand immD0()
 4444 %{
 4445   predicate(jlong_cast(n-&gt;getd()) == 0);
 4446   match(ConD);
 4447 
 4448   op_cost(0);
 4449   format %{ %}
 4450   interface(CONST_INTER);
 4451 %}
 4452 
 4453 // constant &#39;double +0.0&#39;.
 4454 operand immDPacked()
 4455 %{
 4456   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4457   match(ConD);
 4458   op_cost(0);
 4459   format %{ %}
 4460   interface(CONST_INTER);
 4461 %}
 4462 
 4463 // Float Immediate
 4464 operand immF()
 4465 %{
 4466   match(ConF);
 4467   op_cost(0);
 4468   format %{ %}
 4469   interface(CONST_INTER);
 4470 %}
 4471 
 4472 // Float Immediate: +0.0f.
 4473 operand immF0()
 4474 %{
 4475   predicate(jint_cast(n-&gt;getf()) == 0);
 4476   match(ConF);
 4477 
 4478   op_cost(0);
 4479   format %{ %}
 4480   interface(CONST_INTER);
 4481 %}
 4482 
 4483 //
 4484 operand immFPacked()
 4485 %{
 4486   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4487   match(ConF);
 4488   op_cost(0);
 4489   format %{ %}
 4490   interface(CONST_INTER);
 4491 %}
 4492 
 4493 // Narrow pointer operands
 4494 // Narrow Pointer Immediate
 4495 operand immN()
 4496 %{
 4497   match(ConN);
 4498 
 4499   op_cost(0);
 4500   format %{ %}
 4501   interface(CONST_INTER);
 4502 %}
 4503 
 4504 // Narrow NULL Pointer Immediate
 4505 operand immN0()
 4506 %{
 4507   predicate(n-&gt;get_narrowcon() == 0);
 4508   match(ConN);
 4509 
 4510   op_cost(0);
 4511   format %{ %}
 4512   interface(CONST_INTER);
 4513 %}
 4514 
 4515 operand immNKlass()
 4516 %{
 4517   match(ConNKlass);
 4518 
 4519   op_cost(0);
 4520   format %{ %}
 4521   interface(CONST_INTER);
 4522 %}
 4523 
 4524 // Integer 32 bit Register Operands
 4525 // Integer 32 bitRegister (excludes SP)
 4526 operand iRegI()
 4527 %{
 4528   constraint(ALLOC_IN_RC(any_reg32));
 4529   match(RegI);
 4530   match(iRegINoSp);
 4531   op_cost(0);
 4532   format %{ %}
 4533   interface(REG_INTER);
 4534 %}
 4535 
 4536 // Integer 32 bit Register not Special
 4537 operand iRegINoSp()
 4538 %{
 4539   constraint(ALLOC_IN_RC(no_special_reg32));
 4540   match(RegI);
 4541   op_cost(0);
 4542   format %{ %}
 4543   interface(REG_INTER);
 4544 %}
 4545 
 4546 // Integer 64 bit Register Operands
 4547 // Integer 64 bit Register (includes SP)
 4548 operand iRegL()
 4549 %{
 4550   constraint(ALLOC_IN_RC(any_reg));
 4551   match(RegL);
 4552   match(iRegLNoSp);
 4553   op_cost(0);
 4554   format %{ %}
 4555   interface(REG_INTER);
 4556 %}
 4557 
 4558 // Integer 64 bit Register not Special
 4559 operand iRegLNoSp()
 4560 %{
 4561   constraint(ALLOC_IN_RC(no_special_reg));
 4562   match(RegL);
 4563   match(iRegL_R0);
 4564   format %{ %}
 4565   interface(REG_INTER);
 4566 %}
 4567 
 4568 // Pointer Register Operands
 4569 // Pointer Register
 4570 operand iRegP()
 4571 %{
 4572   constraint(ALLOC_IN_RC(ptr_reg));
 4573   match(RegP);
 4574   match(iRegPNoSp);
 4575   match(iRegP_R0);
 4576   //match(iRegP_R2);
 4577   //match(iRegP_R4);
 4578   //match(iRegP_R5);
 4579   match(thread_RegP);
 4580   op_cost(0);
 4581   format %{ %}
 4582   interface(REG_INTER);
 4583 %}
 4584 
 4585 // Pointer 64 bit Register not Special
 4586 operand iRegPNoSp()
 4587 %{
 4588   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4589   match(RegP);
 4590   // match(iRegP);
 4591   // match(iRegP_R0);
 4592   // match(iRegP_R2);
 4593   // match(iRegP_R4);
 4594   // match(iRegP_R5);
 4595   // match(thread_RegP);
 4596   op_cost(0);
 4597   format %{ %}
 4598   interface(REG_INTER);
 4599 %}
 4600 
 4601 // Pointer 64 bit Register R0 only
 4602 operand iRegP_R0()
 4603 %{
 4604   constraint(ALLOC_IN_RC(r0_reg));
 4605   match(RegP);
 4606   // match(iRegP);
 4607   match(iRegPNoSp);
 4608   op_cost(0);
 4609   format %{ %}
 4610   interface(REG_INTER);
 4611 %}
 4612 
 4613 // Pointer 64 bit Register R1 only
 4614 operand iRegP_R1()
 4615 %{
 4616   constraint(ALLOC_IN_RC(r1_reg));
 4617   match(RegP);
 4618   // match(iRegP);
 4619   match(iRegPNoSp);
 4620   op_cost(0);
 4621   format %{ %}
 4622   interface(REG_INTER);
 4623 %}
 4624 
 4625 // Pointer 64 bit Register R2 only
 4626 operand iRegP_R2()
 4627 %{
 4628   constraint(ALLOC_IN_RC(r2_reg));
 4629   match(RegP);
 4630   // match(iRegP);
 4631   match(iRegPNoSp);
 4632   op_cost(0);
 4633   format %{ %}
 4634   interface(REG_INTER);
 4635 %}
 4636 
 4637 // Pointer 64 bit Register R3 only
 4638 operand iRegP_R3()
 4639 %{
 4640   constraint(ALLOC_IN_RC(r3_reg));
 4641   match(RegP);
 4642   // match(iRegP);
 4643   match(iRegPNoSp);
 4644   op_cost(0);
 4645   format %{ %}
 4646   interface(REG_INTER);
 4647 %}
 4648 
 4649 // Pointer 64 bit Register R4 only
 4650 operand iRegP_R4()
 4651 %{
 4652   constraint(ALLOC_IN_RC(r4_reg));
 4653   match(RegP);
 4654   // match(iRegP);
 4655   match(iRegPNoSp);
 4656   op_cost(0);
 4657   format %{ %}
 4658   interface(REG_INTER);
 4659 %}
 4660 
 4661 // Pointer 64 bit Register R5 only
 4662 operand iRegP_R5()
 4663 %{
 4664   constraint(ALLOC_IN_RC(r5_reg));
 4665   match(RegP);
 4666   // match(iRegP);
 4667   match(iRegPNoSp);
 4668   op_cost(0);
 4669   format %{ %}
 4670   interface(REG_INTER);
 4671 %}
 4672 
 4673 // Pointer 64 bit Register R10 only
 4674 operand iRegP_R10()
 4675 %{
 4676   constraint(ALLOC_IN_RC(r10_reg));
 4677   match(RegP);
 4678   // match(iRegP);
 4679   match(iRegPNoSp);
 4680   op_cost(0);
 4681   format %{ %}
 4682   interface(REG_INTER);
 4683 %}
 4684 
 4685 // Long 64 bit Register R0 only
 4686 operand iRegL_R0()
 4687 %{
 4688   constraint(ALLOC_IN_RC(r0_reg));
 4689   match(RegL);
 4690   match(iRegLNoSp);
 4691   op_cost(0);
 4692   format %{ %}
 4693   interface(REG_INTER);
 4694 %}
 4695 
 4696 // Long 64 bit Register R2 only
 4697 operand iRegL_R2()
 4698 %{
 4699   constraint(ALLOC_IN_RC(r2_reg));
 4700   match(RegL);
 4701   match(iRegLNoSp);
 4702   op_cost(0);
 4703   format %{ %}
 4704   interface(REG_INTER);
 4705 %}
 4706 
 4707 // Long 64 bit Register R3 only
 4708 operand iRegL_R3()
 4709 %{
 4710   constraint(ALLOC_IN_RC(r3_reg));
 4711   match(RegL);
 4712   match(iRegLNoSp);
 4713   op_cost(0);
 4714   format %{ %}
 4715   interface(REG_INTER);
 4716 %}
 4717 
 4718 // Long 64 bit Register R11 only
 4719 operand iRegL_R11()
 4720 %{
 4721   constraint(ALLOC_IN_RC(r11_reg));
 4722   match(RegL);
 4723   match(iRegLNoSp);
 4724   op_cost(0);
 4725   format %{ %}
 4726   interface(REG_INTER);
 4727 %}
 4728 
 4729 // Pointer 64 bit Register FP only
 4730 operand iRegP_FP()
 4731 %{
 4732   constraint(ALLOC_IN_RC(fp_reg));
 4733   match(RegP);
 4734   // match(iRegP);
 4735   op_cost(0);
 4736   format %{ %}
 4737   interface(REG_INTER);
 4738 %}
 4739 
 4740 // Register R0 only
 4741 operand iRegI_R0()
 4742 %{
 4743   constraint(ALLOC_IN_RC(int_r0_reg));
 4744   match(RegI);
 4745   match(iRegINoSp);
 4746   op_cost(0);
 4747   format %{ %}
 4748   interface(REG_INTER);
 4749 %}
 4750 
 4751 // Register R2 only
 4752 operand iRegI_R2()
 4753 %{
 4754   constraint(ALLOC_IN_RC(int_r2_reg));
 4755   match(RegI);
 4756   match(iRegINoSp);
 4757   op_cost(0);
 4758   format %{ %}
 4759   interface(REG_INTER);
 4760 %}
 4761 
 4762 // Register R3 only
 4763 operand iRegI_R3()
 4764 %{
 4765   constraint(ALLOC_IN_RC(int_r3_reg));
 4766   match(RegI);
 4767   match(iRegINoSp);
 4768   op_cost(0);
 4769   format %{ %}
 4770   interface(REG_INTER);
 4771 %}
 4772 
 4773 
 4774 // Register R4 only
 4775 operand iRegI_R4()
 4776 %{
 4777   constraint(ALLOC_IN_RC(int_r4_reg));
 4778   match(RegI);
 4779   match(iRegINoSp);
 4780   op_cost(0);
 4781   format %{ %}
 4782   interface(REG_INTER);
 4783 %}
 4784 
 4785 
 4786 // Pointer Register Operands
 4787 // Narrow Pointer Register
 4788 operand iRegN()
 4789 %{
 4790   constraint(ALLOC_IN_RC(any_reg32));
 4791   match(RegN);
 4792   match(iRegNNoSp);
 4793   op_cost(0);
 4794   format %{ %}
 4795   interface(REG_INTER);
 4796 %}
 4797 
 4798 operand iRegN_R0()
 4799 %{
 4800   constraint(ALLOC_IN_RC(r0_reg));
 4801   match(iRegN);
 4802   op_cost(0);
 4803   format %{ %}
 4804   interface(REG_INTER);
 4805 %}
 4806 
 4807 operand iRegN_R2()
 4808 %{
 4809   constraint(ALLOC_IN_RC(r2_reg));
 4810   match(iRegN);
 4811   op_cost(0);
 4812   format %{ %}
 4813   interface(REG_INTER);
 4814 %}
 4815 
 4816 operand iRegN_R3()
 4817 %{
 4818   constraint(ALLOC_IN_RC(r3_reg));
 4819   match(iRegN);
 4820   op_cost(0);
 4821   format %{ %}
 4822   interface(REG_INTER);
 4823 %}
 4824 
 4825 // Integer 64 bit Register not Special
 4826 operand iRegNNoSp()
 4827 %{
 4828   constraint(ALLOC_IN_RC(no_special_reg32));
 4829   match(RegN);
 4830   op_cost(0);
 4831   format %{ %}
 4832   interface(REG_INTER);
 4833 %}
 4834 
 4835 // heap base register -- used for encoding immN0
 4836 
 4837 operand iRegIHeapbase()
 4838 %{
 4839   constraint(ALLOC_IN_RC(heapbase_reg));
 4840   match(RegI);
 4841   op_cost(0);
 4842   format %{ %}
 4843   interface(REG_INTER);
 4844 %}
 4845 
 4846 // Float Register
 4847 // Float register operands
 4848 operand vRegF()
 4849 %{
 4850   constraint(ALLOC_IN_RC(float_reg));
 4851   match(RegF);
 4852 
 4853   op_cost(0);
 4854   format %{ %}
 4855   interface(REG_INTER);
 4856 %}
 4857 
 4858 // Double Register
 4859 // Double register operands
 4860 operand vRegD()
 4861 %{
 4862   constraint(ALLOC_IN_RC(double_reg));
 4863   match(RegD);
 4864 
 4865   op_cost(0);
 4866   format %{ %}
 4867   interface(REG_INTER);
 4868 %}
 4869 
 4870 operand vecD()
 4871 %{
 4872   constraint(ALLOC_IN_RC(vectord_reg));
 4873   match(VecD);
 4874 
 4875   op_cost(0);
 4876   format %{ %}
 4877   interface(REG_INTER);
 4878 %}
 4879 
 4880 operand vecX()
 4881 %{
 4882   constraint(ALLOC_IN_RC(vectorx_reg));
 4883   match(VecX);
 4884 
 4885   op_cost(0);
 4886   format %{ %}
 4887   interface(REG_INTER);
 4888 %}
 4889 
 4890 operand vRegD_V0()
 4891 %{
 4892   constraint(ALLOC_IN_RC(v0_reg));
 4893   match(RegD);
 4894   op_cost(0);
 4895   format %{ %}
 4896   interface(REG_INTER);
 4897 %}
 4898 
 4899 operand vRegD_V1()
 4900 %{
 4901   constraint(ALLOC_IN_RC(v1_reg));
 4902   match(RegD);
 4903   op_cost(0);
 4904   format %{ %}
 4905   interface(REG_INTER);
 4906 %}
 4907 
 4908 operand vRegD_V2()
 4909 %{
 4910   constraint(ALLOC_IN_RC(v2_reg));
 4911   match(RegD);
 4912   op_cost(0);
 4913   format %{ %}
 4914   interface(REG_INTER);
 4915 %}
 4916 
 4917 operand vRegD_V3()
 4918 %{
 4919   constraint(ALLOC_IN_RC(v3_reg));
 4920   match(RegD);
 4921   op_cost(0);
 4922   format %{ %}
 4923   interface(REG_INTER);
 4924 %}
 4925 
 4926 operand vRegD_V4()
 4927 %{
 4928   constraint(ALLOC_IN_RC(v4_reg));
 4929   match(RegD);
 4930   op_cost(0);
 4931   format %{ %}
 4932   interface(REG_INTER);
 4933 %}
 4934 
 4935 operand vRegD_V5()
 4936 %{
 4937   constraint(ALLOC_IN_RC(v5_reg));
 4938   match(RegD);
 4939   op_cost(0);
 4940   format %{ %}
 4941   interface(REG_INTER);
 4942 %}
 4943 
 4944 operand vRegD_V6()
 4945 %{
 4946   constraint(ALLOC_IN_RC(v6_reg));
 4947   match(RegD);
 4948   op_cost(0);
 4949   format %{ %}
 4950   interface(REG_INTER);
 4951 %}
 4952 
 4953 operand vRegD_V7()
 4954 %{
 4955   constraint(ALLOC_IN_RC(v7_reg));
 4956   match(RegD);
 4957   op_cost(0);
 4958   format %{ %}
 4959   interface(REG_INTER);
 4960 %}
 4961 
 4962 operand vRegD_V8()
 4963 %{
 4964   constraint(ALLOC_IN_RC(v8_reg));
 4965   match(RegD);
 4966   op_cost(0);
 4967   format %{ %}
 4968   interface(REG_INTER);
 4969 %}
 4970 
 4971 operand vRegD_V9()
 4972 %{
 4973   constraint(ALLOC_IN_RC(v9_reg));
 4974   match(RegD);
 4975   op_cost(0);
 4976   format %{ %}
 4977   interface(REG_INTER);
 4978 %}
 4979 
 4980 operand vRegD_V10()
 4981 %{
 4982   constraint(ALLOC_IN_RC(v10_reg));
 4983   match(RegD);
 4984   op_cost(0);
 4985   format %{ %}
 4986   interface(REG_INTER);
 4987 %}
 4988 
 4989 operand vRegD_V11()
 4990 %{
 4991   constraint(ALLOC_IN_RC(v11_reg));
 4992   match(RegD);
 4993   op_cost(0);
 4994   format %{ %}
 4995   interface(REG_INTER);
 4996 %}
 4997 
 4998 operand vRegD_V12()
 4999 %{
 5000   constraint(ALLOC_IN_RC(v12_reg));
 5001   match(RegD);
 5002   op_cost(0);
 5003   format %{ %}
 5004   interface(REG_INTER);
 5005 %}
 5006 
 5007 operand vRegD_V13()
 5008 %{
 5009   constraint(ALLOC_IN_RC(v13_reg));
 5010   match(RegD);
 5011   op_cost(0);
 5012   format %{ %}
 5013   interface(REG_INTER);
 5014 %}
 5015 
 5016 operand vRegD_V14()
 5017 %{
 5018   constraint(ALLOC_IN_RC(v14_reg));
 5019   match(RegD);
 5020   op_cost(0);
 5021   format %{ %}
 5022   interface(REG_INTER);
 5023 %}
 5024 
 5025 operand vRegD_V15()
 5026 %{
 5027   constraint(ALLOC_IN_RC(v15_reg));
 5028   match(RegD);
 5029   op_cost(0);
 5030   format %{ %}
 5031   interface(REG_INTER);
 5032 %}
 5033 
 5034 operand vRegD_V16()
 5035 %{
 5036   constraint(ALLOC_IN_RC(v16_reg));
 5037   match(RegD);
 5038   op_cost(0);
 5039   format %{ %}
 5040   interface(REG_INTER);
 5041 %}
 5042 
 5043 operand vRegD_V17()
 5044 %{
 5045   constraint(ALLOC_IN_RC(v17_reg));
 5046   match(RegD);
 5047   op_cost(0);
 5048   format %{ %}
 5049   interface(REG_INTER);
 5050 %}
 5051 
 5052 operand vRegD_V18()
 5053 %{
 5054   constraint(ALLOC_IN_RC(v18_reg));
 5055   match(RegD);
 5056   op_cost(0);
 5057   format %{ %}
 5058   interface(REG_INTER);
 5059 %}
 5060 
 5061 operand vRegD_V19()
 5062 %{
 5063   constraint(ALLOC_IN_RC(v19_reg));
 5064   match(RegD);
 5065   op_cost(0);
 5066   format %{ %}
 5067   interface(REG_INTER);
 5068 %}
 5069 
 5070 operand vRegD_V20()
 5071 %{
 5072   constraint(ALLOC_IN_RC(v20_reg));
 5073   match(RegD);
 5074   op_cost(0);
 5075   format %{ %}
 5076   interface(REG_INTER);
 5077 %}
 5078 
 5079 operand vRegD_V21()
 5080 %{
 5081   constraint(ALLOC_IN_RC(v21_reg));
 5082   match(RegD);
 5083   op_cost(0);
 5084   format %{ %}
 5085   interface(REG_INTER);
 5086 %}
 5087 
 5088 operand vRegD_V22()
 5089 %{
 5090   constraint(ALLOC_IN_RC(v22_reg));
 5091   match(RegD);
 5092   op_cost(0);
 5093   format %{ %}
 5094   interface(REG_INTER);
 5095 %}
 5096 
 5097 operand vRegD_V23()
 5098 %{
 5099   constraint(ALLOC_IN_RC(v23_reg));
 5100   match(RegD);
 5101   op_cost(0);
 5102   format %{ %}
 5103   interface(REG_INTER);
 5104 %}
 5105 
 5106 operand vRegD_V24()
 5107 %{
 5108   constraint(ALLOC_IN_RC(v24_reg));
 5109   match(RegD);
 5110   op_cost(0);
 5111   format %{ %}
 5112   interface(REG_INTER);
 5113 %}
 5114 
 5115 operand vRegD_V25()
 5116 %{
 5117   constraint(ALLOC_IN_RC(v25_reg));
 5118   match(RegD);
 5119   op_cost(0);
 5120   format %{ %}
 5121   interface(REG_INTER);
 5122 %}
 5123 
 5124 operand vRegD_V26()
 5125 %{
 5126   constraint(ALLOC_IN_RC(v26_reg));
 5127   match(RegD);
 5128   op_cost(0);
 5129   format %{ %}
 5130   interface(REG_INTER);
 5131 %}
 5132 
 5133 operand vRegD_V27()
 5134 %{
 5135   constraint(ALLOC_IN_RC(v27_reg));
 5136   match(RegD);
 5137   op_cost(0);
 5138   format %{ %}
 5139   interface(REG_INTER);
 5140 %}
 5141 
 5142 operand vRegD_V28()
 5143 %{
 5144   constraint(ALLOC_IN_RC(v28_reg));
 5145   match(RegD);
 5146   op_cost(0);
 5147   format %{ %}
 5148   interface(REG_INTER);
 5149 %}
 5150 
 5151 operand vRegD_V29()
 5152 %{
 5153   constraint(ALLOC_IN_RC(v29_reg));
 5154   match(RegD);
 5155   op_cost(0);
 5156   format %{ %}
 5157   interface(REG_INTER);
 5158 %}
 5159 
 5160 operand vRegD_V30()
 5161 %{
 5162   constraint(ALLOC_IN_RC(v30_reg));
 5163   match(RegD);
 5164   op_cost(0);
 5165   format %{ %}
 5166   interface(REG_INTER);
 5167 %}
 5168 
 5169 operand vRegD_V31()
 5170 %{
 5171   constraint(ALLOC_IN_RC(v31_reg));
 5172   match(RegD);
 5173   op_cost(0);
 5174   format %{ %}
 5175   interface(REG_INTER);
 5176 %}
 5177 
 5178 // Flags register, used as output of signed compare instructions
 5179 
 5180 // note that on AArch64 we also use this register as the output for
 5181 // for floating point compare instructions (CmpF CmpD). this ensures
 5182 // that ordered inequality tests use GT, GE, LT or LE none of which
 5183 // pass through cases where the result is unordered i.e. one or both
 5184 // inputs to the compare is a NaN. this means that the ideal code can
 5185 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5186 // (where the comparison should always fail). EQ and NE tests are
 5187 // always generated in ideal code so that unordered folds into the NE
 5188 // case, matching the behaviour of AArch64 NE.
 5189 //
 5190 // This differs from x86 where the outputs of FP compares use a
 5191 // special FP flags registers and where compares based on this
 5192 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5193 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5194 // to explicitly handle the unordered case in branches. x86 also has
 5195 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5196 
 5197 operand rFlagsReg()
 5198 %{
 5199   constraint(ALLOC_IN_RC(int_flags));
 5200   match(RegFlags);
 5201 
 5202   op_cost(0);
 5203   format %{ &quot;RFLAGS&quot; %}
 5204   interface(REG_INTER);
 5205 %}
 5206 
 5207 // Flags register, used as output of unsigned compare instructions
 5208 operand rFlagsRegU()
 5209 %{
 5210   constraint(ALLOC_IN_RC(int_flags));
 5211   match(RegFlags);
 5212 
 5213   op_cost(0);
 5214   format %{ &quot;RFLAGSU&quot; %}
 5215   interface(REG_INTER);
 5216 %}
 5217 
 5218 // Special Registers
 5219 
 5220 // Method Register
 5221 operand inline_cache_RegP(iRegP reg)
 5222 %{
 5223   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5224   match(reg);
 5225   match(iRegPNoSp);
 5226   op_cost(0);
 5227   format %{ %}
 5228   interface(REG_INTER);
 5229 %}
 5230 
 5231 operand interpreter_method_oop_RegP(iRegP reg)
 5232 %{
 5233   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5234   match(reg);
 5235   match(iRegPNoSp);
 5236   op_cost(0);
 5237   format %{ %}
 5238   interface(REG_INTER);
 5239 %}
 5240 
 5241 // Thread Register
 5242 operand thread_RegP(iRegP reg)
 5243 %{
 5244   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5245   match(reg);
 5246   op_cost(0);
 5247   format %{ %}
 5248   interface(REG_INTER);
 5249 %}
 5250 
 5251 operand lr_RegP(iRegP reg)
 5252 %{
 5253   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5254   match(reg);
 5255   op_cost(0);
 5256   format %{ %}
 5257   interface(REG_INTER);
 5258 %}
 5259 
 5260 //----------Memory Operands----------------------------------------------------
 5261 
 5262 operand indirect(iRegP reg)
 5263 %{
 5264   constraint(ALLOC_IN_RC(ptr_reg));
 5265   match(reg);
 5266   op_cost(0);
 5267   format %{ &quot;[$reg]&quot; %}
 5268   interface(MEMORY_INTER) %{
 5269     base($reg);
 5270     index(0xffffffff);
 5271     scale(0x0);
 5272     disp(0x0);
 5273   %}
 5274 %}
 5275 
 5276 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5277 %{
 5278   constraint(ALLOC_IN_RC(ptr_reg));
 5279   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5280   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5281   op_cost(0);
 5282   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5283   interface(MEMORY_INTER) %{
 5284     base($reg);
 5285     index($ireg);
 5286     scale($scale);
 5287     disp(0x0);
 5288   %}
 5289 %}
 5290 
 5291 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5292 %{
 5293   constraint(ALLOC_IN_RC(ptr_reg));
 5294   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5295   match(AddP reg (LShiftL lreg scale));
 5296   op_cost(0);
 5297   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5298   interface(MEMORY_INTER) %{
 5299     base($reg);
 5300     index($lreg);
 5301     scale($scale);
 5302     disp(0x0);
 5303   %}
 5304 %}
 5305 
 5306 operand indIndexI2L(iRegP reg, iRegI ireg)
 5307 %{
 5308   constraint(ALLOC_IN_RC(ptr_reg));
 5309   match(AddP reg (ConvI2L ireg));
 5310   op_cost(0);
 5311   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5312   interface(MEMORY_INTER) %{
 5313     base($reg);
 5314     index($ireg);
 5315     scale(0x0);
 5316     disp(0x0);
 5317   %}
 5318 %}
 5319 
 5320 operand indIndex(iRegP reg, iRegL lreg)
 5321 %{
 5322   constraint(ALLOC_IN_RC(ptr_reg));
 5323   match(AddP reg lreg);
 5324   op_cost(0);
 5325   format %{ &quot;$reg, $lreg&quot; %}
 5326   interface(MEMORY_INTER) %{
 5327     base($reg);
 5328     index($lreg);
 5329     scale(0x0);
 5330     disp(0x0);
 5331   %}
 5332 %}
 5333 
 5334 operand indOffI(iRegP reg, immIOffset off)
 5335 %{
 5336   constraint(ALLOC_IN_RC(ptr_reg));
 5337   match(AddP reg off);
 5338   op_cost(0);
 5339   format %{ &quot;[$reg, $off]&quot; %}
 5340   interface(MEMORY_INTER) %{
 5341     base($reg);
 5342     index(0xffffffff);
 5343     scale(0x0);
 5344     disp($off);
 5345   %}
 5346 %}
 5347 
 5348 operand indOffI1(iRegP reg, immIOffset1 off)
 5349 %{
 5350   constraint(ALLOC_IN_RC(ptr_reg));
 5351   match(AddP reg off);
 5352   op_cost(0);
 5353   format %{ &quot;[$reg, $off]&quot; %}
 5354   interface(MEMORY_INTER) %{
 5355     base($reg);
 5356     index(0xffffffff);
 5357     scale(0x0);
 5358     disp($off);
 5359   %}
 5360 %}
 5361 
 5362 operand indOffI2(iRegP reg, immIOffset2 off)
 5363 %{
 5364   constraint(ALLOC_IN_RC(ptr_reg));
 5365   match(AddP reg off);
 5366   op_cost(0);
 5367   format %{ &quot;[$reg, $off]&quot; %}
 5368   interface(MEMORY_INTER) %{
 5369     base($reg);
 5370     index(0xffffffff);
 5371     scale(0x0);
 5372     disp($off);
 5373   %}
 5374 %}
 5375 
 5376 operand indOffI4(iRegP reg, immIOffset4 off)
 5377 %{
 5378   constraint(ALLOC_IN_RC(ptr_reg));
 5379   match(AddP reg off);
 5380   op_cost(0);
 5381   format %{ &quot;[$reg, $off]&quot; %}
 5382   interface(MEMORY_INTER) %{
 5383     base($reg);
 5384     index(0xffffffff);
 5385     scale(0x0);
 5386     disp($off);
 5387   %}
 5388 %}
 5389 
 5390 operand indOffI8(iRegP reg, immIOffset8 off)
 5391 %{
 5392   constraint(ALLOC_IN_RC(ptr_reg));
 5393   match(AddP reg off);
 5394   op_cost(0);
 5395   format %{ &quot;[$reg, $off]&quot; %}
 5396   interface(MEMORY_INTER) %{
 5397     base($reg);
 5398     index(0xffffffff);
 5399     scale(0x0);
 5400     disp($off);
 5401   %}
 5402 %}
 5403 
 5404 operand indOffI16(iRegP reg, immIOffset16 off)
 5405 %{
 5406   constraint(ALLOC_IN_RC(ptr_reg));
 5407   match(AddP reg off);
 5408   op_cost(0);
 5409   format %{ &quot;[$reg, $off]&quot; %}
 5410   interface(MEMORY_INTER) %{
 5411     base($reg);
 5412     index(0xffffffff);
 5413     scale(0x0);
 5414     disp($off);
 5415   %}
 5416 %}
 5417 
 5418 operand indOffL(iRegP reg, immLoffset off)
 5419 %{
 5420   constraint(ALLOC_IN_RC(ptr_reg));
 5421   match(AddP reg off);
 5422   op_cost(0);
 5423   format %{ &quot;[$reg, $off]&quot; %}
 5424   interface(MEMORY_INTER) %{
 5425     base($reg);
 5426     index(0xffffffff);
 5427     scale(0x0);
 5428     disp($off);
 5429   %}
 5430 %}
 5431 
 5432 operand indOffL1(iRegP reg, immLoffset1 off)
 5433 %{
 5434   constraint(ALLOC_IN_RC(ptr_reg));
 5435   match(AddP reg off);
 5436   op_cost(0);
 5437   format %{ &quot;[$reg, $off]&quot; %}
 5438   interface(MEMORY_INTER) %{
 5439     base($reg);
 5440     index(0xffffffff);
 5441     scale(0x0);
 5442     disp($off);
 5443   %}
 5444 %}
 5445 
 5446 operand indOffL2(iRegP reg, immLoffset2 off)
 5447 %{
 5448   constraint(ALLOC_IN_RC(ptr_reg));
 5449   match(AddP reg off);
 5450   op_cost(0);
 5451   format %{ &quot;[$reg, $off]&quot; %}
 5452   interface(MEMORY_INTER) %{
 5453     base($reg);
 5454     index(0xffffffff);
 5455     scale(0x0);
 5456     disp($off);
 5457   %}
 5458 %}
 5459 
 5460 operand indOffL4(iRegP reg, immLoffset4 off)
 5461 %{
 5462   constraint(ALLOC_IN_RC(ptr_reg));
 5463   match(AddP reg off);
 5464   op_cost(0);
 5465   format %{ &quot;[$reg, $off]&quot; %}
 5466   interface(MEMORY_INTER) %{
 5467     base($reg);
 5468     index(0xffffffff);
 5469     scale(0x0);
 5470     disp($off);
 5471   %}
 5472 %}
 5473 
 5474 operand indOffL8(iRegP reg, immLoffset8 off)
 5475 %{
 5476   constraint(ALLOC_IN_RC(ptr_reg));
 5477   match(AddP reg off);
 5478   op_cost(0);
 5479   format %{ &quot;[$reg, $off]&quot; %}
 5480   interface(MEMORY_INTER) %{
 5481     base($reg);
 5482     index(0xffffffff);
 5483     scale(0x0);
 5484     disp($off);
 5485   %}
 5486 %}
 5487 
 5488 operand indOffL16(iRegP reg, immLoffset16 off)
 5489 %{
 5490   constraint(ALLOC_IN_RC(ptr_reg));
 5491   match(AddP reg off);
 5492   op_cost(0);
 5493   format %{ &quot;[$reg, $off]&quot; %}
 5494   interface(MEMORY_INTER) %{
 5495     base($reg);
 5496     index(0xffffffff);
 5497     scale(0x0);
 5498     disp($off);
 5499   %}
 5500 %}
 5501 
 5502 operand indirectN(iRegN reg)
 5503 %{
 5504   predicate(CompressedOops::shift() == 0);
 5505   constraint(ALLOC_IN_RC(ptr_reg));
 5506   match(DecodeN reg);
 5507   op_cost(0);
 5508   format %{ &quot;[$reg]\t# narrow&quot; %}
 5509   interface(MEMORY_INTER) %{
 5510     base($reg);
 5511     index(0xffffffff);
 5512     scale(0x0);
 5513     disp(0x0);
 5514   %}
 5515 %}
 5516 
 5517 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5518 %{
 5519   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5520   constraint(ALLOC_IN_RC(ptr_reg));
 5521   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5522   op_cost(0);
 5523   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5524   interface(MEMORY_INTER) %{
 5525     base($reg);
 5526     index($ireg);
 5527     scale($scale);
 5528     disp(0x0);
 5529   %}
 5530 %}
 5531 
 5532 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5533 %{
 5534   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5535   constraint(ALLOC_IN_RC(ptr_reg));
 5536   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5537   op_cost(0);
 5538   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5539   interface(MEMORY_INTER) %{
 5540     base($reg);
 5541     index($lreg);
 5542     scale($scale);
 5543     disp(0x0);
 5544   %}
 5545 %}
 5546 
 5547 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5548 %{
 5549   predicate(CompressedOops::shift() == 0);
 5550   constraint(ALLOC_IN_RC(ptr_reg));
 5551   match(AddP (DecodeN reg) (ConvI2L ireg));
 5552   op_cost(0);
 5553   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5554   interface(MEMORY_INTER) %{
 5555     base($reg);
 5556     index($ireg);
 5557     scale(0x0);
 5558     disp(0x0);
 5559   %}
 5560 %}
 5561 
 5562 operand indIndexN(iRegN reg, iRegL lreg)
 5563 %{
 5564   predicate(CompressedOops::shift() == 0);
 5565   constraint(ALLOC_IN_RC(ptr_reg));
 5566   match(AddP (DecodeN reg) lreg);
 5567   op_cost(0);
 5568   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5569   interface(MEMORY_INTER) %{
 5570     base($reg);
 5571     index($lreg);
 5572     scale(0x0);
 5573     disp(0x0);
 5574   %}
 5575 %}
 5576 
 5577 operand indOffIN(iRegN reg, immIOffset off)
 5578 %{
 5579   predicate(CompressedOops::shift() == 0);
 5580   constraint(ALLOC_IN_RC(ptr_reg));
 5581   match(AddP (DecodeN reg) off);
 5582   op_cost(0);
 5583   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5584   interface(MEMORY_INTER) %{
 5585     base($reg);
 5586     index(0xffffffff);
 5587     scale(0x0);
 5588     disp($off);
 5589   %}
 5590 %}
 5591 
 5592 operand indOffLN(iRegN reg, immLoffset off)
 5593 %{
 5594   predicate(CompressedOops::shift() == 0);
 5595   constraint(ALLOC_IN_RC(ptr_reg));
 5596   match(AddP (DecodeN reg) off);
 5597   op_cost(0);
 5598   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5599   interface(MEMORY_INTER) %{
 5600     base($reg);
 5601     index(0xffffffff);
 5602     scale(0x0);
 5603     disp($off);
 5604   %}
 5605 %}
 5606 
 5607 
 5608 
 5609 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5610 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5611 %{
 5612   constraint(ALLOC_IN_RC(ptr_reg));
 5613   match(AddP reg off);
 5614   op_cost(0);
 5615   format %{ &quot;[$reg, $off]&quot; %}
 5616   interface(MEMORY_INTER) %{
 5617     base($reg);
 5618     index(0xffffffff);
 5619     scale(0x0);
 5620     disp($off);
 5621   %}
 5622 %}
 5623 
 5624 //----------Special Memory Operands--------------------------------------------
 5625 // Stack Slot Operand - This operand is used for loading and storing temporary
 5626 //                      values on the stack where a match requires a value to
 5627 //                      flow through memory.
 5628 operand stackSlotP(sRegP reg)
 5629 %{
 5630   constraint(ALLOC_IN_RC(stack_slots));
 5631   op_cost(100);
 5632   // No match rule because this operand is only generated in matching
 5633   // match(RegP);
 5634   format %{ &quot;[$reg]&quot; %}
 5635   interface(MEMORY_INTER) %{
 5636     base(0x1e);  // RSP
 5637     index(0x0);  // No Index
 5638     scale(0x0);  // No Scale
 5639     disp($reg);  // Stack Offset
 5640   %}
 5641 %}
 5642 
 5643 operand stackSlotI(sRegI reg)
 5644 %{
 5645   constraint(ALLOC_IN_RC(stack_slots));
 5646   // No match rule because this operand is only generated in matching
 5647   // match(RegI);
 5648   format %{ &quot;[$reg]&quot; %}
 5649   interface(MEMORY_INTER) %{
 5650     base(0x1e);  // RSP
 5651     index(0x0);  // No Index
 5652     scale(0x0);  // No Scale
 5653     disp($reg);  // Stack Offset
 5654   %}
 5655 %}
 5656 
 5657 operand stackSlotF(sRegF reg)
 5658 %{
 5659   constraint(ALLOC_IN_RC(stack_slots));
 5660   // No match rule because this operand is only generated in matching
 5661   // match(RegF);
 5662   format %{ &quot;[$reg]&quot; %}
 5663   interface(MEMORY_INTER) %{
 5664     base(0x1e);  // RSP
 5665     index(0x0);  // No Index
 5666     scale(0x0);  // No Scale
 5667     disp($reg);  // Stack Offset
 5668   %}
 5669 %}
 5670 
 5671 operand stackSlotD(sRegD reg)
 5672 %{
 5673   constraint(ALLOC_IN_RC(stack_slots));
 5674   // No match rule because this operand is only generated in matching
 5675   // match(RegD);
 5676   format %{ &quot;[$reg]&quot; %}
 5677   interface(MEMORY_INTER) %{
 5678     base(0x1e);  // RSP
 5679     index(0x0);  // No Index
 5680     scale(0x0);  // No Scale
 5681     disp($reg);  // Stack Offset
 5682   %}
 5683 %}
 5684 
 5685 operand stackSlotL(sRegL reg)
 5686 %{
 5687   constraint(ALLOC_IN_RC(stack_slots));
 5688   // No match rule because this operand is only generated in matching
 5689   // match(RegL);
 5690   format %{ &quot;[$reg]&quot; %}
 5691   interface(MEMORY_INTER) %{
 5692     base(0x1e);  // RSP
 5693     index(0x0);  // No Index
 5694     scale(0x0);  // No Scale
 5695     disp($reg);  // Stack Offset
 5696   %}
 5697 %}
 5698 
 5699 // Operands for expressing Control Flow
 5700 // NOTE: Label is a predefined operand which should not be redefined in
 5701 //       the AD file. It is generically handled within the ADLC.
 5702 
 5703 //----------Conditional Branch Operands----------------------------------------
 5704 // Comparison Op  - This is the operation of the comparison, and is limited to
 5705 //                  the following set of codes:
 5706 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5707 //
 5708 // Other attributes of the comparison, such as unsignedness, are specified
 5709 // by the comparison instruction that sets a condition code flags register.
 5710 // That result is represented by a flags operand whose subtype is appropriate
 5711 // to the unsignedness (etc.) of the comparison.
 5712 //
 5713 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5714 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5715 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5716 
 5717 // used for signed integral comparisons and fp comparisons
 5718 
 5719 operand cmpOp()
 5720 %{
 5721   match(Bool);
 5722 
 5723   format %{ &quot;&quot; %}
 5724   interface(COND_INTER) %{
 5725     equal(0x0, &quot;eq&quot;);
 5726     not_equal(0x1, &quot;ne&quot;);
 5727     less(0xb, &quot;lt&quot;);
 5728     greater_equal(0xa, &quot;ge&quot;);
 5729     less_equal(0xd, &quot;le&quot;);
 5730     greater(0xc, &quot;gt&quot;);
 5731     overflow(0x6, &quot;vs&quot;);
 5732     no_overflow(0x7, &quot;vc&quot;);
 5733   %}
 5734 %}
 5735 
 5736 // used for unsigned integral comparisons
 5737 
 5738 operand cmpOpU()
 5739 %{
 5740   match(Bool);
 5741 
 5742   format %{ &quot;&quot; %}
 5743   interface(COND_INTER) %{
 5744     equal(0x0, &quot;eq&quot;);
 5745     not_equal(0x1, &quot;ne&quot;);
 5746     less(0x3, &quot;lo&quot;);
 5747     greater_equal(0x2, &quot;hs&quot;);
 5748     less_equal(0x9, &quot;ls&quot;);
 5749     greater(0x8, &quot;hi&quot;);
 5750     overflow(0x6, &quot;vs&quot;);
 5751     no_overflow(0x7, &quot;vc&quot;);
 5752   %}
 5753 %}
 5754 
 5755 // used for certain integral comparisons which can be
 5756 // converted to cbxx or tbxx instructions
 5757 
 5758 operand cmpOpEqNe()
 5759 %{
 5760   match(Bool);
 5761   op_cost(0);
 5762   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5763             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5764 
 5765   format %{ &quot;&quot; %}
 5766   interface(COND_INTER) %{
 5767     equal(0x0, &quot;eq&quot;);
 5768     not_equal(0x1, &quot;ne&quot;);
 5769     less(0xb, &quot;lt&quot;);
 5770     greater_equal(0xa, &quot;ge&quot;);
 5771     less_equal(0xd, &quot;le&quot;);
 5772     greater(0xc, &quot;gt&quot;);
 5773     overflow(0x6, &quot;vs&quot;);
 5774     no_overflow(0x7, &quot;vc&quot;);
 5775   %}
 5776 %}
 5777 
 5778 // used for certain integral comparisons which can be
 5779 // converted to cbxx or tbxx instructions
 5780 
 5781 operand cmpOpLtGe()
 5782 %{
 5783   match(Bool);
 5784   op_cost(0);
 5785 
 5786   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5787             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5788 
 5789   format %{ &quot;&quot; %}
 5790   interface(COND_INTER) %{
 5791     equal(0x0, &quot;eq&quot;);
 5792     not_equal(0x1, &quot;ne&quot;);
 5793     less(0xb, &quot;lt&quot;);
 5794     greater_equal(0xa, &quot;ge&quot;);
 5795     less_equal(0xd, &quot;le&quot;);
 5796     greater(0xc, &quot;gt&quot;);
 5797     overflow(0x6, &quot;vs&quot;);
 5798     no_overflow(0x7, &quot;vc&quot;);
 5799   %}
 5800 %}
 5801 
 5802 // used for certain unsigned integral comparisons which can be
 5803 // converted to cbxx or tbxx instructions
 5804 
 5805 operand cmpOpUEqNeLtGe()
 5806 %{
 5807   match(Bool);
 5808   op_cost(0);
 5809 
 5810   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5811             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5812             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5813             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5814 
 5815   format %{ &quot;&quot; %}
 5816   interface(COND_INTER) %{
 5817     equal(0x0, &quot;eq&quot;);
 5818     not_equal(0x1, &quot;ne&quot;);
 5819     less(0xb, &quot;lt&quot;);
 5820     greater_equal(0xa, &quot;ge&quot;);
 5821     less_equal(0xd, &quot;le&quot;);
 5822     greater(0xc, &quot;gt&quot;);
 5823     overflow(0x6, &quot;vs&quot;);
 5824     no_overflow(0x7, &quot;vc&quot;);
 5825   %}
 5826 %}
 5827 
 5828 // Special operand allowing long args to int ops to be truncated for free
 5829 
 5830 operand iRegL2I(iRegL reg) %{
 5831 
 5832   op_cost(0);
 5833 
 5834   match(ConvL2I reg);
 5835 
 5836   format %{ &quot;l2i($reg)&quot; %}
 5837 
 5838   interface(REG_INTER)
 5839 %}
 5840 
 5841 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5842 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5843 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5844 
 5845 //----------OPERAND CLASSES----------------------------------------------------
 5846 // Operand Classes are groups of operands that are used as to simplify
 5847 // instruction definitions by not requiring the AD writer to specify
 5848 // separate instructions for every form of operand when the
 5849 // instruction accepts multiple operand types with the same basic
 5850 // encoding and format. The classic case of this is memory operands.
 5851 
 5852 // memory is used to define read/write location for load/store
 5853 // instruction defs. we can turn a memory op into an Address
 5854 
 5855 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5856                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5857 
 5858 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5859                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5860 
 5861 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5862                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5863 
 5864 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5865                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5866 
 5867 // All of the memory operands. For the pipeline description.
 5868 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5869                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5870                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5871 
 5872 
 5873 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5874 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5875 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5876 // can be elided because the 32-bit instruction will just employ the
 5877 // lower 32 bits anyway.
 5878 //
 5879 // n.b. this does not elide all L2I conversions. if the truncated
 5880 // value is consumed by more than one operation then the ConvL2I
 5881 // cannot be bundled into the consuming nodes so an l2i gets planted
 5882 // (actually a movw $dst $src) and the downstream instructions consume
 5883 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5884 // movw is actually redundant but its not too costly.
 5885 
 5886 opclass iRegIorL2I(iRegI, iRegL2I);
 5887 
 5888 //----------PIPELINE-----------------------------------------------------------
 5889 // Rules which define the behavior of the target architectures pipeline.
 5890 
 5891 // For specific pipelines, eg A53, define the stages of that pipeline
 5892 //pipe_desc(ISS, EX1, EX2, WR);
 5893 #define ISS S0
 5894 #define EX1 S1
 5895 #define EX2 S2
 5896 #define WR  S3
 5897 
 5898 // Integer ALU reg operation
 5899 pipeline %{
 5900 
 5901 attributes %{
 5902   // ARM instructions are of fixed length
 5903   fixed_size_instructions;        // Fixed size instructions TODO does
 5904   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5905   // ARM instructions come in 32-bit word units
 5906   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5907   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5908   instruction_fetch_units = 1;       // of 64 bytes
 5909 
 5910   // List of nop instructions
 5911   nops( MachNop );
 5912 %}
 5913 
 5914 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5915 // or description. we do use pipeline classes to introduce fixed
 5916 // latencies
 5917 
 5918 //----------RESOURCES----------------------------------------------------------
 5919 // Resources are the functional units available to the machine
 5920 
 5921 resources( INS0, INS1, INS01 = INS0 | INS1,
 5922            ALU0, ALU1, ALU = ALU0 | ALU1,
 5923            MAC,
 5924            DIV,
 5925            BRANCH,
 5926            LDST,
 5927            NEON_FP);
 5928 
 5929 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5930 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5931 
 5932 // Define the pipeline as a generic 6 stage pipeline
 5933 pipe_desc(S0, S1, S2, S3, S4, S5);
 5934 
 5935 //----------PIPELINE CLASSES---------------------------------------------------
 5936 // Pipeline Classes describe the stages in which input and output are
 5937 // referenced by the hardware pipeline.
 5938 
 5939 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5940 %{
 5941   single_instruction;
 5942   src1   : S1(read);
 5943   src2   : S2(read);
 5944   dst    : S5(write);
 5945   INS01  : ISS;
 5946   NEON_FP : S5;
 5947 %}
 5948 
 5949 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5950 %{
 5951   single_instruction;
 5952   src1   : S1(read);
 5953   src2   : S2(read);
 5954   dst    : S5(write);
 5955   INS01  : ISS;
 5956   NEON_FP : S5;
 5957 %}
 5958 
 5959 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5960 %{
 5961   single_instruction;
 5962   src    : S1(read);
 5963   dst    : S5(write);
 5964   INS01  : ISS;
 5965   NEON_FP : S5;
 5966 %}
 5967 
 5968 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5969 %{
 5970   single_instruction;
 5971   src    : S1(read);
 5972   dst    : S5(write);
 5973   INS01  : ISS;
 5974   NEON_FP : S5;
 5975 %}
 5976 
 5977 pipe_class fp_d2f(vRegF dst, vRegD src)
 5978 %{
 5979   single_instruction;
 5980   src    : S1(read);
 5981   dst    : S5(write);
 5982   INS01  : ISS;
 5983   NEON_FP : S5;
 5984 %}
 5985 
 5986 pipe_class fp_f2d(vRegD dst, vRegF src)
 5987 %{
 5988   single_instruction;
 5989   src    : S1(read);
 5990   dst    : S5(write);
 5991   INS01  : ISS;
 5992   NEON_FP : S5;
 5993 %}
 5994 
 5995 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5996 %{
 5997   single_instruction;
 5998   src    : S1(read);
 5999   dst    : S5(write);
 6000   INS01  : ISS;
 6001   NEON_FP : S5;
 6002 %}
 6003 
 6004 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6005 %{
 6006   single_instruction;
 6007   src    : S1(read);
 6008   dst    : S5(write);
 6009   INS01  : ISS;
 6010   NEON_FP : S5;
 6011 %}
 6012 
 6013 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6014 %{
 6015   single_instruction;
 6016   src    : S1(read);
 6017   dst    : S5(write);
 6018   INS01  : ISS;
 6019   NEON_FP : S5;
 6020 %}
 6021 
 6022 pipe_class fp_l2f(vRegF dst, iRegL src)
 6023 %{
 6024   single_instruction;
 6025   src    : S1(read);
 6026   dst    : S5(write);
 6027   INS01  : ISS;
 6028   NEON_FP : S5;
 6029 %}
 6030 
 6031 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6032 %{
 6033   single_instruction;
 6034   src    : S1(read);
 6035   dst    : S5(write);
 6036   INS01  : ISS;
 6037   NEON_FP : S5;
 6038 %}
 6039 
 6040 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6041 %{
 6042   single_instruction;
 6043   src    : S1(read);
 6044   dst    : S5(write);
 6045   INS01  : ISS;
 6046   NEON_FP : S5;
 6047 %}
 6048 
 6049 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6050 %{
 6051   single_instruction;
 6052   src    : S1(read);
 6053   dst    : S5(write);
 6054   INS01  : ISS;
 6055   NEON_FP : S5;
 6056 %}
 6057 
 6058 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6059 %{
 6060   single_instruction;
 6061   src    : S1(read);
 6062   dst    : S5(write);
 6063   INS01  : ISS;
 6064   NEON_FP : S5;
 6065 %}
 6066 
 6067 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6068 %{
 6069   single_instruction;
 6070   src1   : S1(read);
 6071   src2   : S2(read);
 6072   dst    : S5(write);
 6073   INS0   : ISS;
 6074   NEON_FP : S5;
 6075 %}
 6076 
 6077 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6078 %{
 6079   single_instruction;
 6080   src1   : S1(read);
 6081   src2   : S2(read);
 6082   dst    : S5(write);
 6083   INS0   : ISS;
 6084   NEON_FP : S5;
 6085 %}
 6086 
 6087 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6088 %{
 6089   single_instruction;
 6090   cr     : S1(read);
 6091   src1   : S1(read);
 6092   src2   : S1(read);
 6093   dst    : S3(write);
 6094   INS01  : ISS;
 6095   NEON_FP : S3;
 6096 %}
 6097 
 6098 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6099 %{
 6100   single_instruction;
 6101   cr     : S1(read);
 6102   src1   : S1(read);
 6103   src2   : S1(read);
 6104   dst    : S3(write);
 6105   INS01  : ISS;
 6106   NEON_FP : S3;
 6107 %}
 6108 
 6109 pipe_class fp_imm_s(vRegF dst)
 6110 %{
 6111   single_instruction;
 6112   dst    : S3(write);
 6113   INS01  : ISS;
 6114   NEON_FP : S3;
 6115 %}
 6116 
 6117 pipe_class fp_imm_d(vRegD dst)
 6118 %{
 6119   single_instruction;
 6120   dst    : S3(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S3;
 6123 %}
 6124 
 6125 pipe_class fp_load_constant_s(vRegF dst)
 6126 %{
 6127   single_instruction;
 6128   dst    : S4(write);
 6129   INS01  : ISS;
 6130   NEON_FP : S4;
 6131 %}
 6132 
 6133 pipe_class fp_load_constant_d(vRegD dst)
 6134 %{
 6135   single_instruction;
 6136   dst    : S4(write);
 6137   INS01  : ISS;
 6138   NEON_FP : S4;
 6139 %}
 6140 
 6141 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6142 %{
 6143   single_instruction;
 6144   dst    : S5(write);
 6145   src1   : S1(read);
 6146   src2   : S1(read);
 6147   INS01  : ISS;
 6148   NEON_FP : S5;
 6149 %}
 6150 
 6151 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6152 %{
 6153   single_instruction;
 6154   dst    : S5(write);
 6155   src1   : S1(read);
 6156   src2   : S1(read);
 6157   INS0   : ISS;
 6158   NEON_FP : S5;
 6159 %}
 6160 
 6161 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6162 %{
 6163   single_instruction;
 6164   dst    : S5(write);
 6165   src1   : S1(read);
 6166   src2   : S1(read);
 6167   dst    : S1(read);
 6168   INS01  : ISS;
 6169   NEON_FP : S5;
 6170 %}
 6171 
 6172 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6173 %{
 6174   single_instruction;
 6175   dst    : S5(write);
 6176   src1   : S1(read);
 6177   src2   : S1(read);
 6178   dst    : S1(read);
 6179   INS0   : ISS;
 6180   NEON_FP : S5;
 6181 %}
 6182 
 6183 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6184 %{
 6185   single_instruction;
 6186   dst    : S4(write);
 6187   src1   : S2(read);
 6188   src2   : S2(read);
 6189   INS01  : ISS;
 6190   NEON_FP : S4;
 6191 %}
 6192 
 6193 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6194 %{
 6195   single_instruction;
 6196   dst    : S4(write);
 6197   src1   : S2(read);
 6198   src2   : S2(read);
 6199   INS0   : ISS;
 6200   NEON_FP : S4;
 6201 %}
 6202 
 6203 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6204 %{
 6205   single_instruction;
 6206   dst    : S3(write);
 6207   src1   : S2(read);
 6208   src2   : S2(read);
 6209   INS01  : ISS;
 6210   NEON_FP : S3;
 6211 %}
 6212 
 6213 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6214 %{
 6215   single_instruction;
 6216   dst    : S3(write);
 6217   src1   : S2(read);
 6218   src2   : S2(read);
 6219   INS0   : ISS;
 6220   NEON_FP : S3;
 6221 %}
 6222 
 6223 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6224 %{
 6225   single_instruction;
 6226   dst    : S3(write);
 6227   src    : S1(read);
 6228   shift  : S1(read);
 6229   INS01  : ISS;
 6230   NEON_FP : S3;
 6231 %}
 6232 
 6233 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6234 %{
 6235   single_instruction;
 6236   dst    : S3(write);
 6237   src    : S1(read);
 6238   shift  : S1(read);
 6239   INS0   : ISS;
 6240   NEON_FP : S3;
 6241 %}
 6242 
 6243 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6244 %{
 6245   single_instruction;
 6246   dst    : S3(write);
 6247   src    : S1(read);
 6248   INS01  : ISS;
 6249   NEON_FP : S3;
 6250 %}
 6251 
 6252 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6253 %{
 6254   single_instruction;
 6255   dst    : S3(write);
 6256   src    : S1(read);
 6257   INS0   : ISS;
 6258   NEON_FP : S3;
 6259 %}
 6260 
 6261 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6262 %{
 6263   single_instruction;
 6264   dst    : S5(write);
 6265   src1   : S1(read);
 6266   src2   : S1(read);
 6267   INS01  : ISS;
 6268   NEON_FP : S5;
 6269 %}
 6270 
 6271 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6272 %{
 6273   single_instruction;
 6274   dst    : S5(write);
 6275   src1   : S1(read);
 6276   src2   : S1(read);
 6277   INS0   : ISS;
 6278   NEON_FP : S5;
 6279 %}
 6280 
 6281 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6282 %{
 6283   single_instruction;
 6284   dst    : S5(write);
 6285   src1   : S1(read);
 6286   src2   : S1(read);
 6287   INS0   : ISS;
 6288   NEON_FP : S5;
 6289 %}
 6290 
 6291 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6292 %{
 6293   single_instruction;
 6294   dst    : S5(write);
 6295   src1   : S1(read);
 6296   src2   : S1(read);
 6297   INS0   : ISS;
 6298   NEON_FP : S5;
 6299 %}
 6300 
 6301 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6302 %{
 6303   single_instruction;
 6304   dst    : S5(write);
 6305   src    : S1(read);
 6306   INS0   : ISS;
 6307   NEON_FP : S5;
 6308 %}
 6309 
 6310 pipe_class vunop_fp64(vecD dst, vecD src)
 6311 %{
 6312   single_instruction;
 6313   dst    : S5(write);
 6314   src    : S1(read);
 6315   INS01  : ISS;
 6316   NEON_FP : S5;
 6317 %}
 6318 
 6319 pipe_class vunop_fp128(vecX dst, vecX src)
 6320 %{
 6321   single_instruction;
 6322   dst    : S5(write);
 6323   src    : S1(read);
 6324   INS0   : ISS;
 6325   NEON_FP : S5;
 6326 %}
 6327 
 6328 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6329 %{
 6330   single_instruction;
 6331   dst    : S3(write);
 6332   src    : S1(read);
 6333   INS01  : ISS;
 6334   NEON_FP : S3;
 6335 %}
 6336 
 6337 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6338 %{
 6339   single_instruction;
 6340   dst    : S3(write);
 6341   src    : S1(read);
 6342   INS01  : ISS;
 6343   NEON_FP : S3;
 6344 %}
 6345 
 6346 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6347 %{
 6348   single_instruction;
 6349   dst    : S3(write);
 6350   src    : S1(read);
 6351   INS01  : ISS;
 6352   NEON_FP : S3;
 6353 %}
 6354 
 6355 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6356 %{
 6357   single_instruction;
 6358   dst    : S3(write);
 6359   src    : S1(read);
 6360   INS01  : ISS;
 6361   NEON_FP : S3;
 6362 %}
 6363 
 6364 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6365 %{
 6366   single_instruction;
 6367   dst    : S3(write);
 6368   src    : S1(read);
 6369   INS01  : ISS;
 6370   NEON_FP : S3;
 6371 %}
 6372 
 6373 pipe_class vmovi_reg_imm64(vecD dst)
 6374 %{
 6375   single_instruction;
 6376   dst    : S3(write);
 6377   INS01  : ISS;
 6378   NEON_FP : S3;
 6379 %}
 6380 
 6381 pipe_class vmovi_reg_imm128(vecX dst)
 6382 %{
 6383   single_instruction;
 6384   dst    : S3(write);
 6385   INS0   : ISS;
 6386   NEON_FP : S3;
 6387 %}
 6388 
 6389 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6390 %{
 6391   single_instruction;
 6392   dst    : S5(write);
 6393   mem    : ISS(read);
 6394   INS01  : ISS;
 6395   NEON_FP : S3;
 6396 %}
 6397 
 6398 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6399 %{
 6400   single_instruction;
 6401   dst    : S5(write);
 6402   mem    : ISS(read);
 6403   INS01  : ISS;
 6404   NEON_FP : S3;
 6405 %}
 6406 
 6407 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6408 %{
 6409   single_instruction;
 6410   mem    : ISS(read);
 6411   src    : S2(read);
 6412   INS01  : ISS;
 6413   NEON_FP : S3;
 6414 %}
 6415 
 6416 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6417 %{
 6418   single_instruction;
 6419   mem    : ISS(read);
 6420   src    : S2(read);
 6421   INS01  : ISS;
 6422   NEON_FP : S3;
 6423 %}
 6424 
 6425 //------- Integer ALU operations --------------------------
 6426 
 6427 // Integer ALU reg-reg operation
 6428 // Operands needed in EX1, result generated in EX2
 6429 // Eg.  ADD     x0, x1, x2
 6430 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6431 %{
 6432   single_instruction;
 6433   dst    : EX2(write);
 6434   src1   : EX1(read);
 6435   src2   : EX1(read);
 6436   INS01  : ISS; // Dual issue as instruction 0 or 1
 6437   ALU    : EX2;
 6438 %}
 6439 
 6440 // Integer ALU reg-reg operation with constant shift
 6441 // Shifted register must be available in LATE_ISS instead of EX1
 6442 // Eg.  ADD     x0, x1, x2, LSL #2
 6443 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6444 %{
 6445   single_instruction;
 6446   dst    : EX2(write);
 6447   src1   : EX1(read);
 6448   src2   : ISS(read);
 6449   INS01  : ISS;
 6450   ALU    : EX2;
 6451 %}
 6452 
 6453 // Integer ALU reg operation with constant shift
 6454 // Eg.  LSL     x0, x1, #shift
 6455 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6456 %{
 6457   single_instruction;
 6458   dst    : EX2(write);
 6459   src1   : ISS(read);
 6460   INS01  : ISS;
 6461   ALU    : EX2;
 6462 %}
 6463 
 6464 // Integer ALU reg-reg operation with variable shift
 6465 // Both operands must be available in LATE_ISS instead of EX1
 6466 // Result is available in EX1 instead of EX2
 6467 // Eg.  LSLV    x0, x1, x2
 6468 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6469 %{
 6470   single_instruction;
 6471   dst    : EX1(write);
 6472   src1   : ISS(read);
 6473   src2   : ISS(read);
 6474   INS01  : ISS;
 6475   ALU    : EX1;
 6476 %}
 6477 
 6478 // Integer ALU reg-reg operation with extract
 6479 // As for _vshift above, but result generated in EX2
 6480 // Eg.  EXTR    x0, x1, x2, #N
 6481 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6482 %{
 6483   single_instruction;
 6484   dst    : EX2(write);
 6485   src1   : ISS(read);
 6486   src2   : ISS(read);
 6487   INS1   : ISS; // Can only dual issue as Instruction 1
 6488   ALU    : EX1;
 6489 %}
 6490 
 6491 // Integer ALU reg operation
 6492 // Eg.  NEG     x0, x1
 6493 pipe_class ialu_reg(iRegI dst, iRegI src)
 6494 %{
 6495   single_instruction;
 6496   dst    : EX2(write);
 6497   src    : EX1(read);
 6498   INS01  : ISS;
 6499   ALU    : EX2;
 6500 %}
 6501 
 6502 // Integer ALU reg mmediate operation
 6503 // Eg.  ADD     x0, x1, #N
 6504 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6505 %{
 6506   single_instruction;
 6507   dst    : EX2(write);
 6508   src1   : EX1(read);
 6509   INS01  : ISS;
 6510   ALU    : EX2;
 6511 %}
 6512 
 6513 // Integer ALU immediate operation (no source operands)
 6514 // Eg.  MOV     x0, #N
 6515 pipe_class ialu_imm(iRegI dst)
 6516 %{
 6517   single_instruction;
 6518   dst    : EX1(write);
 6519   INS01  : ISS;
 6520   ALU    : EX1;
 6521 %}
 6522 
 6523 //------- Compare operation -------------------------------
 6524 
 6525 // Compare reg-reg
 6526 // Eg.  CMP     x0, x1
 6527 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6528 %{
 6529   single_instruction;
 6530 //  fixed_latency(16);
 6531   cr     : EX2(write);
 6532   op1    : EX1(read);
 6533   op2    : EX1(read);
 6534   INS01  : ISS;
 6535   ALU    : EX2;
 6536 %}
 6537 
 6538 // Compare reg-reg
 6539 // Eg.  CMP     x0, #N
 6540 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6541 %{
 6542   single_instruction;
 6543 //  fixed_latency(16);
 6544   cr     : EX2(write);
 6545   op1    : EX1(read);
 6546   INS01  : ISS;
 6547   ALU    : EX2;
 6548 %}
 6549 
 6550 //------- Conditional instructions ------------------------
 6551 
 6552 // Conditional no operands
 6553 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6554 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6555 %{
 6556   single_instruction;
 6557   cr     : EX1(read);
 6558   dst    : EX2(write);
 6559   INS01  : ISS;
 6560   ALU    : EX2;
 6561 %}
 6562 
 6563 // Conditional 2 operand
 6564 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6565 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6566 %{
 6567   single_instruction;
 6568   cr     : EX1(read);
 6569   src1   : EX1(read);
 6570   src2   : EX1(read);
 6571   dst    : EX2(write);
 6572   INS01  : ISS;
 6573   ALU    : EX2;
 6574 %}
 6575 
 6576 // Conditional 2 operand
 6577 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6578 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6579 %{
 6580   single_instruction;
 6581   cr     : EX1(read);
 6582   src    : EX1(read);
 6583   dst    : EX2(write);
 6584   INS01  : ISS;
 6585   ALU    : EX2;
 6586 %}
 6587 
 6588 //------- Multiply pipeline operations --------------------
 6589 
 6590 // Multiply reg-reg
 6591 // Eg.  MUL     w0, w1, w2
 6592 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6593 %{
 6594   single_instruction;
 6595   dst    : WR(write);
 6596   src1   : ISS(read);
 6597   src2   : ISS(read);
 6598   INS01  : ISS;
 6599   MAC    : WR;
 6600 %}
 6601 
 6602 // Multiply accumulate
 6603 // Eg.  MADD    w0, w1, w2, w3
 6604 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6605 %{
 6606   single_instruction;
 6607   dst    : WR(write);
 6608   src1   : ISS(read);
 6609   src2   : ISS(read);
 6610   src3   : ISS(read);
 6611   INS01  : ISS;
 6612   MAC    : WR;
 6613 %}
 6614 
 6615 // Eg.  MUL     w0, w1, w2
 6616 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6617 %{
 6618   single_instruction;
 6619   fixed_latency(3); // Maximum latency for 64 bit mul
 6620   dst    : WR(write);
 6621   src1   : ISS(read);
 6622   src2   : ISS(read);
 6623   INS01  : ISS;
 6624   MAC    : WR;
 6625 %}
 6626 
 6627 // Multiply accumulate
 6628 // Eg.  MADD    w0, w1, w2, w3
 6629 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6630 %{
 6631   single_instruction;
 6632   fixed_latency(3); // Maximum latency for 64 bit mul
 6633   dst    : WR(write);
 6634   src1   : ISS(read);
 6635   src2   : ISS(read);
 6636   src3   : ISS(read);
 6637   INS01  : ISS;
 6638   MAC    : WR;
 6639 %}
 6640 
 6641 //------- Divide pipeline operations --------------------
 6642 
 6643 // Eg.  SDIV    w0, w1, w2
 6644 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6645 %{
 6646   single_instruction;
 6647   fixed_latency(8); // Maximum latency for 32 bit divide
 6648   dst    : WR(write);
 6649   src1   : ISS(read);
 6650   src2   : ISS(read);
 6651   INS0   : ISS; // Can only dual issue as instruction 0
 6652   DIV    : WR;
 6653 %}
 6654 
 6655 // Eg.  SDIV    x0, x1, x2
 6656 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6657 %{
 6658   single_instruction;
 6659   fixed_latency(16); // Maximum latency for 64 bit divide
 6660   dst    : WR(write);
 6661   src1   : ISS(read);
 6662   src2   : ISS(read);
 6663   INS0   : ISS; // Can only dual issue as instruction 0
 6664   DIV    : WR;
 6665 %}
 6666 
 6667 //------- Load pipeline operations ------------------------
 6668 
 6669 // Load - prefetch
 6670 // Eg.  PFRM    &lt;mem&gt;
 6671 pipe_class iload_prefetch(memory mem)
 6672 %{
 6673   single_instruction;
 6674   mem    : ISS(read);
 6675   INS01  : ISS;
 6676   LDST   : WR;
 6677 %}
 6678 
 6679 // Load - reg, mem
 6680 // Eg.  LDR     x0, &lt;mem&gt;
 6681 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6682 %{
 6683   single_instruction;
 6684   dst    : WR(write);
 6685   mem    : ISS(read);
 6686   INS01  : ISS;
 6687   LDST   : WR;
 6688 %}
 6689 
 6690 // Load - reg, reg
 6691 // Eg.  LDR     x0, [sp, x1]
 6692 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6693 %{
 6694   single_instruction;
 6695   dst    : WR(write);
 6696   src    : ISS(read);
 6697   INS01  : ISS;
 6698   LDST   : WR;
 6699 %}
 6700 
 6701 //------- Store pipeline operations -----------------------
 6702 
 6703 // Store - zr, mem
 6704 // Eg.  STR     zr, &lt;mem&gt;
 6705 pipe_class istore_mem(memory mem)
 6706 %{
 6707   single_instruction;
 6708   mem    : ISS(read);
 6709   INS01  : ISS;
 6710   LDST   : WR;
 6711 %}
 6712 
 6713 // Store - reg, mem
 6714 // Eg.  STR     x0, &lt;mem&gt;
 6715 pipe_class istore_reg_mem(iRegI src, memory mem)
 6716 %{
 6717   single_instruction;
 6718   mem    : ISS(read);
 6719   src    : EX2(read);
 6720   INS01  : ISS;
 6721   LDST   : WR;
 6722 %}
 6723 
 6724 // Store - reg, reg
 6725 // Eg. STR      x0, [sp, x1]
 6726 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6727 %{
 6728   single_instruction;
 6729   dst    : ISS(read);
 6730   src    : EX2(read);
 6731   INS01  : ISS;
 6732   LDST   : WR;
 6733 %}
 6734 
 6735 //------- Store pipeline operations -----------------------
 6736 
 6737 // Branch
 6738 pipe_class pipe_branch()
 6739 %{
 6740   single_instruction;
 6741   INS01  : ISS;
 6742   BRANCH : EX1;
 6743 %}
 6744 
 6745 // Conditional branch
 6746 pipe_class pipe_branch_cond(rFlagsReg cr)
 6747 %{
 6748   single_instruction;
 6749   cr     : EX1(read);
 6750   INS01  : ISS;
 6751   BRANCH : EX1;
 6752 %}
 6753 
 6754 // Compare &amp; Branch
 6755 // EG.  CBZ/CBNZ
 6756 pipe_class pipe_cmp_branch(iRegI op1)
 6757 %{
 6758   single_instruction;
 6759   op1    : EX1(read);
 6760   INS01  : ISS;
 6761   BRANCH : EX1;
 6762 %}
 6763 
 6764 //------- Synchronisation operations ----------------------
 6765 
 6766 // Any operation requiring serialization.
 6767 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6768 pipe_class pipe_serial()
 6769 %{
 6770   single_instruction;
 6771   force_serialization;
 6772   fixed_latency(16);
 6773   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6774   LDST   : WR;
 6775 %}
 6776 
 6777 // Generic big/slow expanded idiom - also serialized
 6778 pipe_class pipe_slow()
 6779 %{
 6780   instruction_count(10);
 6781   multiple_bundles;
 6782   force_serialization;
 6783   fixed_latency(16);
 6784   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6785   LDST   : WR;
 6786 %}
 6787 
 6788 // Empty pipeline class
 6789 pipe_class pipe_class_empty()
 6790 %{
 6791   single_instruction;
 6792   fixed_latency(0);
 6793 %}
 6794 
 6795 // Default pipeline class.
 6796 pipe_class pipe_class_default()
 6797 %{
 6798   single_instruction;
 6799   fixed_latency(2);
 6800 %}
 6801 
 6802 // Pipeline class for compares.
 6803 pipe_class pipe_class_compare()
 6804 %{
 6805   single_instruction;
 6806   fixed_latency(16);
 6807 %}
 6808 
 6809 // Pipeline class for memory operations.
 6810 pipe_class pipe_class_memory()
 6811 %{
 6812   single_instruction;
 6813   fixed_latency(16);
 6814 %}
 6815 
 6816 // Pipeline class for call.
 6817 pipe_class pipe_class_call()
 6818 %{
 6819   single_instruction;
 6820   fixed_latency(100);
 6821 %}
 6822 
 6823 // Define the class for the Nop node.
 6824 define %{
 6825    MachNop = pipe_class_empty;
 6826 %}
 6827 
 6828 %}
 6829 //----------INSTRUCTIONS-------------------------------------------------------
 6830 //
 6831 // match      -- States which machine-independent subtree may be replaced
 6832 //               by this instruction.
 6833 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6834 //               selection to identify a minimum cost tree of machine
 6835 //               instructions that matches a tree of machine-independent
 6836 //               instructions.
 6837 // format     -- A string providing the disassembly for this instruction.
 6838 //               The value of an instruction&#39;s operand may be inserted
 6839 //               by referring to it with a &#39;$&#39; prefix.
 6840 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6841 //               to within an encode class as $primary, $secondary, and $tertiary
 6842 //               rrspectively.  The primary opcode is commonly used to
 6843 //               indicate the type of machine instruction, while secondary
 6844 //               and tertiary are often used for prefix options or addressing
 6845 //               modes.
 6846 // ins_encode -- A list of encode classes with parameters. The encode class
 6847 //               name must have been defined in an &#39;enc_class&#39; specification
 6848 //               in the encode section of the architecture description.
 6849 
 6850 // ============================================================================
 6851 // Memory (Load/Store) Instructions
 6852 
 6853 // Load Instructions
 6854 
 6855 // Load Byte (8 bit signed)
 6856 instruct loadB(iRegINoSp dst, memory1 mem)
 6857 %{
 6858   match(Set dst (LoadB mem));
 6859   predicate(!needs_acquiring_load(n));
 6860 
 6861   ins_cost(4 * INSN_COST);
 6862   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6863 
 6864   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6865 
 6866   ins_pipe(iload_reg_mem);
 6867 %}
 6868 
 6869 // Load Byte (8 bit signed) into long
 6870 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6871 %{
 6872   match(Set dst (ConvI2L (LoadB mem)));
 6873   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6874 
 6875   ins_cost(4 * INSN_COST);
 6876   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6877 
 6878   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6879 
 6880   ins_pipe(iload_reg_mem);
 6881 %}
 6882 
 6883 // Load Byte (8 bit unsigned)
 6884 instruct loadUB(iRegINoSp dst, memory1 mem)
 6885 %{
 6886   match(Set dst (LoadUB mem));
 6887   predicate(!needs_acquiring_load(n));
 6888 
 6889   ins_cost(4 * INSN_COST);
 6890   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6891 
 6892   ins_encode(aarch64_enc_ldrb(dst, mem));
 6893 
 6894   ins_pipe(iload_reg_mem);
 6895 %}
 6896 
 6897 // Load Byte (8 bit unsigned) into long
 6898 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6899 %{
 6900   match(Set dst (ConvI2L (LoadUB mem)));
 6901   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6902 
 6903   ins_cost(4 * INSN_COST);
 6904   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6905 
 6906   ins_encode(aarch64_enc_ldrb(dst, mem));
 6907 
 6908   ins_pipe(iload_reg_mem);
 6909 %}
 6910 
 6911 // Load Short (16 bit signed)
 6912 instruct loadS(iRegINoSp dst, memory2 mem)
 6913 %{
 6914   match(Set dst (LoadS mem));
 6915   predicate(!needs_acquiring_load(n));
 6916 
 6917   ins_cost(4 * INSN_COST);
 6918   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6919 
 6920   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6921 
 6922   ins_pipe(iload_reg_mem);
 6923 %}
 6924 
 6925 // Load Short (16 bit signed) into long
 6926 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6927 %{
 6928   match(Set dst (ConvI2L (LoadS mem)));
 6929   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6930 
 6931   ins_cost(4 * INSN_COST);
 6932   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6933 
 6934   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6935 
 6936   ins_pipe(iload_reg_mem);
 6937 %}
 6938 
 6939 // Load Char (16 bit unsigned)
 6940 instruct loadUS(iRegINoSp dst, memory2 mem)
 6941 %{
 6942   match(Set dst (LoadUS mem));
 6943   predicate(!needs_acquiring_load(n));
 6944 
 6945   ins_cost(4 * INSN_COST);
 6946   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6947 
 6948   ins_encode(aarch64_enc_ldrh(dst, mem));
 6949 
 6950   ins_pipe(iload_reg_mem);
 6951 %}
 6952 
 6953 // Load Short/Char (16 bit unsigned) into long
 6954 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6955 %{
 6956   match(Set dst (ConvI2L (LoadUS mem)));
 6957   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6958 
 6959   ins_cost(4 * INSN_COST);
 6960   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6961 
 6962   ins_encode(aarch64_enc_ldrh(dst, mem));
 6963 
 6964   ins_pipe(iload_reg_mem);
 6965 %}
 6966 
 6967 // Load Integer (32 bit signed)
 6968 instruct loadI(iRegINoSp dst, memory4 mem)
 6969 %{
 6970   match(Set dst (LoadI mem));
 6971   predicate(!needs_acquiring_load(n));
 6972 
 6973   ins_cost(4 * INSN_COST);
 6974   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6975 
 6976   ins_encode(aarch64_enc_ldrw(dst, mem));
 6977 
 6978   ins_pipe(iload_reg_mem);
 6979 %}
 6980 
 6981 // Load Integer (32 bit signed) into long
 6982 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6983 %{
 6984   match(Set dst (ConvI2L (LoadI mem)));
 6985   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6986 
 6987   ins_cost(4 * INSN_COST);
 6988   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6989 
 6990   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6991 
 6992   ins_pipe(iload_reg_mem);
 6993 %}
 6994 
 6995 // Load Integer (32 bit unsigned) into long
 6996 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6997 %{
 6998   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6999   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7000 
 7001   ins_cost(4 * INSN_COST);
 7002   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7003 
 7004   ins_encode(aarch64_enc_ldrw(dst, mem));
 7005 
 7006   ins_pipe(iload_reg_mem);
 7007 %}
 7008 
 7009 // Load Long (64 bit signed)
 7010 instruct loadL(iRegLNoSp dst, memory8 mem)
 7011 %{
 7012   match(Set dst (LoadL mem));
 7013   predicate(!needs_acquiring_load(n));
 7014 
 7015   ins_cost(4 * INSN_COST);
 7016   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7017 
 7018   ins_encode(aarch64_enc_ldr(dst, mem));
 7019 
 7020   ins_pipe(iload_reg_mem);
 7021 %}
 7022 
 7023 // Load Range
 7024 instruct loadRange(iRegINoSp dst, memory4 mem)
 7025 %{
 7026   match(Set dst (LoadRange mem));
 7027 
 7028   ins_cost(4 * INSN_COST);
 7029   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7030 
 7031   ins_encode(aarch64_enc_ldrw(dst, mem));
 7032 
 7033   ins_pipe(iload_reg_mem);
 7034 %}
 7035 
 7036 // Load Pointer
 7037 instruct loadP(iRegPNoSp dst, memory8 mem)
 7038 %{
 7039   match(Set dst (LoadP mem));
 7040   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7041 
 7042   ins_cost(4 * INSN_COST);
 7043   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7044 
 7045   ins_encode(aarch64_enc_ldr(dst, mem));
 7046 
 7047   ins_pipe(iload_reg_mem);
 7048 %}
 7049 
 7050 // Load Compressed Pointer
 7051 instruct loadN(iRegNNoSp dst, memory4 mem)
 7052 %{
 7053   match(Set dst (LoadN mem));
 7054   predicate(!needs_acquiring_load(n));
 7055 
 7056   ins_cost(4 * INSN_COST);
 7057   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7058 
 7059   ins_encode(aarch64_enc_ldrw(dst, mem));
 7060 
 7061   ins_pipe(iload_reg_mem);
 7062 %}
 7063 
 7064 // Load Klass Pointer
 7065 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7066 %{
 7067   match(Set dst (LoadKlass mem));
 7068   predicate(!needs_acquiring_load(n));
 7069 
 7070   ins_cost(4 * INSN_COST);
 7071   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7072 
 7073   ins_encode(aarch64_enc_ldr(dst, mem));
 7074 
 7075   ins_pipe(iload_reg_mem);
 7076 %}
 7077 
 7078 // Load Narrow Klass Pointer
 7079 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7080 %{
 7081   match(Set dst (LoadNKlass mem));
 7082   predicate(!needs_acquiring_load(n));
 7083 
 7084   ins_cost(4 * INSN_COST);
 7085   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7086 
 7087   ins_encode(aarch64_enc_ldrw(dst, mem));
 7088 
 7089   ins_pipe(iload_reg_mem);
 7090 %}
 7091 
 7092 // Load Float
 7093 instruct loadF(vRegF dst, memory4 mem)
 7094 %{
 7095   match(Set dst (LoadF mem));
 7096   predicate(!needs_acquiring_load(n));
 7097 
 7098   ins_cost(4 * INSN_COST);
 7099   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7100 
 7101   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7102 
 7103   ins_pipe(pipe_class_memory);
 7104 %}
 7105 
 7106 // Load Double
 7107 instruct loadD(vRegD dst, memory8 mem)
 7108 %{
 7109   match(Set dst (LoadD mem));
 7110   predicate(!needs_acquiring_load(n));
 7111 
 7112   ins_cost(4 * INSN_COST);
 7113   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7114 
 7115   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7116 
 7117   ins_pipe(pipe_class_memory);
 7118 %}
 7119 
 7120 
 7121 // Load Int Constant
 7122 instruct loadConI(iRegINoSp dst, immI src)
 7123 %{
 7124   match(Set dst src);
 7125 
 7126   ins_cost(INSN_COST);
 7127   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7128 
 7129   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7130 
 7131   ins_pipe(ialu_imm);
 7132 %}
 7133 
 7134 // Load Long Constant
 7135 instruct loadConL(iRegLNoSp dst, immL src)
 7136 %{
 7137   match(Set dst src);
 7138 
 7139   ins_cost(INSN_COST);
 7140   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7141 
 7142   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7143 
 7144   ins_pipe(ialu_imm);
 7145 %}
 7146 
 7147 // Load Pointer Constant
 7148 
 7149 instruct loadConP(iRegPNoSp dst, immP con)
 7150 %{
 7151   match(Set dst con);
 7152 
 7153   ins_cost(INSN_COST * 4);
 7154   format %{
 7155     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7156   %}
 7157 
 7158   ins_encode(aarch64_enc_mov_p(dst, con));
 7159 
 7160   ins_pipe(ialu_imm);
 7161 %}
 7162 
 7163 // Load Null Pointer Constant
 7164 
 7165 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7166 %{
 7167   match(Set dst con);
 7168 
 7169   ins_cost(INSN_COST);
 7170   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7171 
 7172   ins_encode(aarch64_enc_mov_p0(dst, con));
 7173 
 7174   ins_pipe(ialu_imm);
 7175 %}
 7176 
 7177 // Load Pointer Constant One
 7178 
 7179 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7180 %{
 7181   match(Set dst con);
 7182 
 7183   ins_cost(INSN_COST);
 7184   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7185 
 7186   ins_encode(aarch64_enc_mov_p1(dst, con));
 7187 
 7188   ins_pipe(ialu_imm);
 7189 %}
 7190 
 7191 // Load Byte Map Base Constant
 7192 
 7193 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7194 %{
 7195   match(Set dst con);
 7196 
 7197   ins_cost(INSN_COST);
 7198   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7199 
 7200   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7201 
 7202   ins_pipe(ialu_imm);
 7203 %}
 7204 
 7205 // Load Narrow Pointer Constant
 7206 
 7207 instruct loadConN(iRegNNoSp dst, immN con)
 7208 %{
 7209   match(Set dst con);
 7210 
 7211   ins_cost(INSN_COST * 4);
 7212   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7213 
 7214   ins_encode(aarch64_enc_mov_n(dst, con));
 7215 
 7216   ins_pipe(ialu_imm);
 7217 %}
 7218 
 7219 // Load Narrow Null Pointer Constant
 7220 
 7221 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7222 %{
 7223   match(Set dst con);
 7224 
 7225   ins_cost(INSN_COST);
 7226   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7227 
 7228   ins_encode(aarch64_enc_mov_n0(dst, con));
 7229 
 7230   ins_pipe(ialu_imm);
 7231 %}
 7232 
 7233 // Load Narrow Klass Constant
 7234 
 7235 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7236 %{
 7237   match(Set dst con);
 7238 
 7239   ins_cost(INSN_COST);
 7240   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7241 
 7242   ins_encode(aarch64_enc_mov_nk(dst, con));
 7243 
 7244   ins_pipe(ialu_imm);
 7245 %}
 7246 
 7247 // Load Packed Float Constant
 7248 
 7249 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7250   match(Set dst con);
 7251   ins_cost(INSN_COST * 4);
 7252   format %{ &quot;fmovs  $dst, $con&quot;%}
 7253   ins_encode %{
 7254     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7255   %}
 7256 
 7257   ins_pipe(fp_imm_s);
 7258 %}
 7259 
 7260 // Load Float Constant
 7261 
 7262 instruct loadConF(vRegF dst, immF con) %{
 7263   match(Set dst con);
 7264 
 7265   ins_cost(INSN_COST * 4);
 7266 
 7267   format %{
 7268     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7269   %}
 7270 
 7271   ins_encode %{
 7272     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7273   %}
 7274 
 7275   ins_pipe(fp_load_constant_s);
 7276 %}
 7277 
 7278 // Load Packed Double Constant
 7279 
 7280 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7281   match(Set dst con);
 7282   ins_cost(INSN_COST);
 7283   format %{ &quot;fmovd  $dst, $con&quot;%}
 7284   ins_encode %{
 7285     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7286   %}
 7287 
 7288   ins_pipe(fp_imm_d);
 7289 %}
 7290 
 7291 // Load Double Constant
 7292 
 7293 instruct loadConD(vRegD dst, immD con) %{
 7294   match(Set dst con);
 7295 
 7296   ins_cost(INSN_COST * 5);
 7297   format %{
 7298     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7299   %}
 7300 
 7301   ins_encode %{
 7302     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7303   %}
 7304 
 7305   ins_pipe(fp_load_constant_d);
 7306 %}
 7307 
 7308 // Store Instructions
 7309 
 7310 // Store CMS card-mark Immediate
 7311 instruct storeimmCM0(immI0 zero, memory1 mem)
 7312 %{
 7313   match(Set mem (StoreCM mem zero));
 7314 
 7315   ins_cost(INSN_COST);
 7316   format %{ &quot;storestore (elided)\n\t&quot;
 7317             &quot;strb zr, $mem\t# byte&quot; %}
 7318 
 7319   ins_encode(aarch64_enc_strb0(mem));
 7320 
 7321   ins_pipe(istore_mem);
 7322 %}
 7323 
 7324 // Store CMS card-mark Immediate with intervening StoreStore
 7325 // needed when using CMS with no conditional card marking
 7326 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7327 %{
 7328   match(Set mem (StoreCM mem zero));
 7329 
 7330   ins_cost(INSN_COST * 2);
 7331   format %{ &quot;storestore\n\t&quot;
 7332             &quot;dmb ishst&quot;
 7333             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7334 
 7335   ins_encode(aarch64_enc_strb0_ordered(mem));
 7336 
 7337   ins_pipe(istore_mem);
 7338 %}
 7339 
 7340 // Store Byte
 7341 instruct storeB(iRegIorL2I src, memory1 mem)
 7342 %{
 7343   match(Set mem (StoreB mem src));
 7344   predicate(!needs_releasing_store(n));
 7345 
 7346   ins_cost(INSN_COST);
 7347   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7348 
 7349   ins_encode(aarch64_enc_strb(src, mem));
 7350 
 7351   ins_pipe(istore_reg_mem);
 7352 %}
 7353 
 7354 
 7355 instruct storeimmB0(immI0 zero, memory1 mem)
 7356 %{
 7357   match(Set mem (StoreB mem zero));
 7358   predicate(!needs_releasing_store(n));
 7359 
 7360   ins_cost(INSN_COST);
 7361   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7362 
 7363   ins_encode(aarch64_enc_strb0(mem));
 7364 
 7365   ins_pipe(istore_mem);
 7366 %}
 7367 
 7368 // Store Char/Short
 7369 instruct storeC(iRegIorL2I src, memory2 mem)
 7370 %{
 7371   match(Set mem (StoreC mem src));
 7372   predicate(!needs_releasing_store(n));
 7373 
 7374   ins_cost(INSN_COST);
 7375   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7376 
 7377   ins_encode(aarch64_enc_strh(src, mem));
 7378 
 7379   ins_pipe(istore_reg_mem);
 7380 %}
 7381 
 7382 instruct storeimmC0(immI0 zero, memory2 mem)
 7383 %{
 7384   match(Set mem (StoreC mem zero));
 7385   predicate(!needs_releasing_store(n));
 7386 
 7387   ins_cost(INSN_COST);
 7388   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7389 
 7390   ins_encode(aarch64_enc_strh0(mem));
 7391 
 7392   ins_pipe(istore_mem);
 7393 %}
 7394 
 7395 // Store Integer
 7396 
 7397 instruct storeI(iRegIorL2I src, memory4 mem)
 7398 %{
 7399   match(Set mem(StoreI mem src));
 7400   predicate(!needs_releasing_store(n));
 7401 
 7402   ins_cost(INSN_COST);
 7403   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7404 
 7405   ins_encode(aarch64_enc_strw(src, mem));
 7406 
 7407   ins_pipe(istore_reg_mem);
 7408 %}
 7409 
 7410 instruct storeimmI0(immI0 zero, memory4 mem)
 7411 %{
 7412   match(Set mem(StoreI mem zero));
 7413   predicate(!needs_releasing_store(n));
 7414 
 7415   ins_cost(INSN_COST);
 7416   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7417 
 7418   ins_encode(aarch64_enc_strw0(mem));
 7419 
 7420   ins_pipe(istore_mem);
 7421 %}
 7422 
 7423 // Store Long (64 bit signed)
 7424 instruct storeL(iRegL src, memory8 mem)
 7425 %{
 7426   match(Set mem (StoreL mem src));
 7427   predicate(!needs_releasing_store(n));
 7428 
 7429   ins_cost(INSN_COST);
 7430   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7431 
 7432   ins_encode(aarch64_enc_str(src, mem));
 7433 
 7434   ins_pipe(istore_reg_mem);
 7435 %}
 7436 
 7437 // Store Long (64 bit signed)
 7438 instruct storeimmL0(immL0 zero, memory8 mem)
 7439 %{
 7440   match(Set mem (StoreL mem zero));
 7441   predicate(!needs_releasing_store(n));
 7442 
 7443   ins_cost(INSN_COST);
 7444   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7445 
 7446   ins_encode(aarch64_enc_str0(mem));
 7447 
 7448   ins_pipe(istore_mem);
 7449 %}
 7450 
 7451 // Store Pointer
 7452 instruct storeP(iRegP src, memory8 mem)
 7453 %{
 7454   match(Set mem (StoreP mem src));
 7455   predicate(!needs_releasing_store(n));
 7456 
 7457   ins_cost(INSN_COST);
 7458   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7459 
 7460   ins_encode(aarch64_enc_str(src, mem));
 7461 
 7462   ins_pipe(istore_reg_mem);
 7463 %}
 7464 
 7465 // Store Pointer
 7466 instruct storeimmP0(immP0 zero, memory8 mem)
 7467 %{
 7468   match(Set mem (StoreP mem zero));
 7469   predicate(!needs_releasing_store(n));
 7470 
 7471   ins_cost(INSN_COST);
 7472   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7473 
 7474   ins_encode(aarch64_enc_str0(mem));
 7475 
 7476   ins_pipe(istore_mem);
 7477 %}
 7478 
 7479 // Store Compressed Pointer
 7480 instruct storeN(iRegN src, memory4 mem)
 7481 %{
 7482   match(Set mem (StoreN mem src));
 7483   predicate(!needs_releasing_store(n));
 7484 
 7485   ins_cost(INSN_COST);
 7486   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7487 
 7488   ins_encode(aarch64_enc_strw(src, mem));
 7489 
 7490   ins_pipe(istore_reg_mem);
 7491 %}
 7492 
 7493 instruct storeImmN0(immN0 zero, memory4 mem)
 7494 %{
 7495   match(Set mem (StoreN mem zero));
 7496   predicate(!needs_releasing_store(n));
 7497 
 7498   ins_cost(INSN_COST);
 7499   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7500 
 7501   ins_encode(aarch64_enc_strw0(mem));
 7502 
 7503   ins_pipe(istore_mem);
 7504 %}
 7505 
 7506 // Store Float
 7507 instruct storeF(vRegF src, memory4 mem)
 7508 %{
 7509   match(Set mem (StoreF mem src));
 7510   predicate(!needs_releasing_store(n));
 7511 
 7512   ins_cost(INSN_COST);
 7513   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7514 
 7515   ins_encode( aarch64_enc_strs(src, mem) );
 7516 
 7517   ins_pipe(pipe_class_memory);
 7518 %}
 7519 
 7520 // TODO
 7521 // implement storeImmF0 and storeFImmPacked
 7522 
 7523 // Store Double
 7524 instruct storeD(vRegD src, memory8 mem)
 7525 %{
 7526   match(Set mem (StoreD mem src));
 7527   predicate(!needs_releasing_store(n));
 7528 
 7529   ins_cost(INSN_COST);
 7530   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7531 
 7532   ins_encode( aarch64_enc_strd(src, mem) );
 7533 
 7534   ins_pipe(pipe_class_memory);
 7535 %}
 7536 
 7537 // Store Compressed Klass Pointer
 7538 instruct storeNKlass(iRegN src, memory4 mem)
 7539 %{
 7540   predicate(!needs_releasing_store(n));
 7541   match(Set mem (StoreNKlass mem src));
 7542 
 7543   ins_cost(INSN_COST);
 7544   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7545 
 7546   ins_encode(aarch64_enc_strw(src, mem));
 7547 
 7548   ins_pipe(istore_reg_mem);
 7549 %}
 7550 
 7551 // TODO
 7552 // implement storeImmD0 and storeDImmPacked
 7553 
 7554 // prefetch instructions
 7555 // Must be safe to execute with invalid address (cannot fault).
 7556 
 7557 instruct prefetchalloc( memory8 mem ) %{
 7558   match(PrefetchAllocation mem);
 7559 
 7560   ins_cost(INSN_COST);
 7561   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7562 
 7563   ins_encode( aarch64_enc_prefetchw(mem) );
 7564 
 7565   ins_pipe(iload_prefetch);
 7566 %}
 7567 
 7568 //  ---------------- volatile loads and stores ----------------
 7569 
 7570 // Load Byte (8 bit signed)
 7571 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7572 %{
 7573   match(Set dst (LoadB mem));
 7574 
 7575   ins_cost(VOLATILE_REF_COST);
 7576   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7577 
 7578   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7579 
 7580   ins_pipe(pipe_serial);
 7581 %}
 7582 
 7583 // Load Byte (8 bit signed) into long
 7584 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7585 %{
 7586   match(Set dst (ConvI2L (LoadB mem)));
 7587 
 7588   ins_cost(VOLATILE_REF_COST);
 7589   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7590 
 7591   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7592 
 7593   ins_pipe(pipe_serial);
 7594 %}
 7595 
 7596 // Load Byte (8 bit unsigned)
 7597 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7598 %{
 7599   match(Set dst (LoadUB mem));
 7600 
 7601   ins_cost(VOLATILE_REF_COST);
 7602   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7603 
 7604   ins_encode(aarch64_enc_ldarb(dst, mem));
 7605 
 7606   ins_pipe(pipe_serial);
 7607 %}
 7608 
 7609 // Load Byte (8 bit unsigned) into long
 7610 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7611 %{
 7612   match(Set dst (ConvI2L (LoadUB mem)));
 7613 
 7614   ins_cost(VOLATILE_REF_COST);
 7615   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7616 
 7617   ins_encode(aarch64_enc_ldarb(dst, mem));
 7618 
 7619   ins_pipe(pipe_serial);
 7620 %}
 7621 
 7622 // Load Short (16 bit signed)
 7623 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7624 %{
 7625   match(Set dst (LoadS mem));
 7626 
 7627   ins_cost(VOLATILE_REF_COST);
 7628   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7629 
 7630   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7631 
 7632   ins_pipe(pipe_serial);
 7633 %}
 7634 
 7635 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7636 %{
 7637   match(Set dst (LoadUS mem));
 7638 
 7639   ins_cost(VOLATILE_REF_COST);
 7640   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7641 
 7642   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7643 
 7644   ins_pipe(pipe_serial);
 7645 %}
 7646 
 7647 // Load Short/Char (16 bit unsigned) into long
 7648 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7649 %{
 7650   match(Set dst (ConvI2L (LoadUS mem)));
 7651 
 7652   ins_cost(VOLATILE_REF_COST);
 7653   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7654 
 7655   ins_encode(aarch64_enc_ldarh(dst, mem));
 7656 
 7657   ins_pipe(pipe_serial);
 7658 %}
 7659 
 7660 // Load Short/Char (16 bit signed) into long
 7661 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7662 %{
 7663   match(Set dst (ConvI2L (LoadS mem)));
 7664 
 7665   ins_cost(VOLATILE_REF_COST);
 7666   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7667 
 7668   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7669 
 7670   ins_pipe(pipe_serial);
 7671 %}
 7672 
 7673 // Load Integer (32 bit signed)
 7674 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7675 %{
 7676   match(Set dst (LoadI mem));
 7677 
 7678   ins_cost(VOLATILE_REF_COST);
 7679   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7680 
 7681   ins_encode(aarch64_enc_ldarw(dst, mem));
 7682 
 7683   ins_pipe(pipe_serial);
 7684 %}
 7685 
 7686 // Load Integer (32 bit unsigned) into long
 7687 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7688 %{
 7689   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7690 
 7691   ins_cost(VOLATILE_REF_COST);
 7692   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7693 
 7694   ins_encode(aarch64_enc_ldarw(dst, mem));
 7695 
 7696   ins_pipe(pipe_serial);
 7697 %}
 7698 
 7699 // Load Long (64 bit signed)
 7700 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7701 %{
 7702   match(Set dst (LoadL mem));
 7703 
 7704   ins_cost(VOLATILE_REF_COST);
 7705   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7706 
 7707   ins_encode(aarch64_enc_ldar(dst, mem));
 7708 
 7709   ins_pipe(pipe_serial);
 7710 %}
 7711 
 7712 // Load Pointer
 7713 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7714 %{
 7715   match(Set dst (LoadP mem));
 7716   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7717 
 7718   ins_cost(VOLATILE_REF_COST);
 7719   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7720 
 7721   ins_encode(aarch64_enc_ldar(dst, mem));
 7722 
 7723   ins_pipe(pipe_serial);
 7724 %}
 7725 
 7726 // Load Compressed Pointer
 7727 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7728 %{
 7729   match(Set dst (LoadN mem));
 7730 
 7731   ins_cost(VOLATILE_REF_COST);
 7732   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7733 
 7734   ins_encode(aarch64_enc_ldarw(dst, mem));
 7735 
 7736   ins_pipe(pipe_serial);
 7737 %}
 7738 
 7739 // Load Float
 7740 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7741 %{
 7742   match(Set dst (LoadF mem));
 7743 
 7744   ins_cost(VOLATILE_REF_COST);
 7745   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7746 
 7747   ins_encode( aarch64_enc_fldars(dst, mem) );
 7748 
 7749   ins_pipe(pipe_serial);
 7750 %}
 7751 
 7752 // Load Double
 7753 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7754 %{
 7755   match(Set dst (LoadD mem));
 7756 
 7757   ins_cost(VOLATILE_REF_COST);
 7758   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7759 
 7760   ins_encode( aarch64_enc_fldard(dst, mem) );
 7761 
 7762   ins_pipe(pipe_serial);
 7763 %}
 7764 
 7765 // Store Byte
 7766 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7767 %{
 7768   match(Set mem (StoreB mem src));
 7769 
 7770   ins_cost(VOLATILE_REF_COST);
 7771   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7772 
 7773   ins_encode(aarch64_enc_stlrb(src, mem));
 7774 
 7775   ins_pipe(pipe_class_memory);
 7776 %}
 7777 
 7778 // Store Char/Short
 7779 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7780 %{
 7781   match(Set mem (StoreC mem src));
 7782 
 7783   ins_cost(VOLATILE_REF_COST);
 7784   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7785 
 7786   ins_encode(aarch64_enc_stlrh(src, mem));
 7787 
 7788   ins_pipe(pipe_class_memory);
 7789 %}
 7790 
 7791 // Store Integer
 7792 
 7793 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7794 %{
 7795   match(Set mem(StoreI mem src));
 7796 
 7797   ins_cost(VOLATILE_REF_COST);
 7798   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7799 
 7800   ins_encode(aarch64_enc_stlrw(src, mem));
 7801 
 7802   ins_pipe(pipe_class_memory);
 7803 %}
 7804 
 7805 // Store Long (64 bit signed)
 7806 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7807 %{
 7808   match(Set mem (StoreL mem src));
 7809 
 7810   ins_cost(VOLATILE_REF_COST);
 7811   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7812 
 7813   ins_encode(aarch64_enc_stlr(src, mem));
 7814 
 7815   ins_pipe(pipe_class_memory);
 7816 %}
 7817 
 7818 // Store Pointer
 7819 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7820 %{
 7821   match(Set mem (StoreP mem src));
 7822 
 7823   ins_cost(VOLATILE_REF_COST);
 7824   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7825 
 7826   ins_encode(aarch64_enc_stlr(src, mem));
 7827 
 7828   ins_pipe(pipe_class_memory);
 7829 %}
 7830 
 7831 // Store Compressed Pointer
 7832 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7833 %{
 7834   match(Set mem (StoreN mem src));
 7835 
 7836   ins_cost(VOLATILE_REF_COST);
 7837   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7838 
 7839   ins_encode(aarch64_enc_stlrw(src, mem));
 7840 
 7841   ins_pipe(pipe_class_memory);
 7842 %}
 7843 
 7844 // Store Float
 7845 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7846 %{
 7847   match(Set mem (StoreF mem src));
 7848 
 7849   ins_cost(VOLATILE_REF_COST);
 7850   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7851 
 7852   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7853 
 7854   ins_pipe(pipe_class_memory);
 7855 %}
 7856 
 7857 // TODO
 7858 // implement storeImmF0 and storeFImmPacked
 7859 
 7860 // Store Double
 7861 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7862 %{
 7863   match(Set mem (StoreD mem src));
 7864 
 7865   ins_cost(VOLATILE_REF_COST);
 7866   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7867 
 7868   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7869 
 7870   ins_pipe(pipe_class_memory);
 7871 %}
 7872 
 7873 //  ---------------- end of volatile loads and stores ----------------
 7874 
 7875 instruct cacheWB(indirect addr)
 7876 %{
 7877   predicate(VM_Version::supports_data_cache_line_flush());
 7878   match(CacheWB addr);
 7879 
 7880   ins_cost(100);
 7881   format %{&quot;cache wb $addr&quot; %}
 7882   ins_encode %{
 7883     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7884     assert($addr$$disp == 0, &quot;should be&quot;);
 7885     __ cache_wb(Address($addr$$base$$Register, 0));
 7886   %}
 7887   ins_pipe(pipe_slow); // XXX
 7888 %}
 7889 
 7890 instruct cacheWBPreSync()
 7891 %{
 7892   predicate(VM_Version::supports_data_cache_line_flush());
 7893   match(CacheWBPreSync);
 7894 
 7895   ins_cost(100);
 7896   format %{&quot;cache wb presync&quot; %}
 7897   ins_encode %{
 7898     __ cache_wbsync(true);
 7899   %}
 7900   ins_pipe(pipe_slow); // XXX
 7901 %}
 7902 
 7903 instruct cacheWBPostSync()
 7904 %{
 7905   predicate(VM_Version::supports_data_cache_line_flush());
 7906   match(CacheWBPostSync);
 7907 
 7908   ins_cost(100);
 7909   format %{&quot;cache wb postsync&quot; %}
 7910   ins_encode %{
 7911     __ cache_wbsync(false);
 7912   %}
 7913   ins_pipe(pipe_slow); // XXX
 7914 %}
 7915 
 7916 // ============================================================================
 7917 // BSWAP Instructions
 7918 
 7919 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7920   match(Set dst (ReverseBytesI src));
 7921 
 7922   ins_cost(INSN_COST);
 7923   format %{ &quot;revw  $dst, $src&quot; %}
 7924 
 7925   ins_encode %{
 7926     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7927   %}
 7928 
 7929   ins_pipe(ialu_reg);
 7930 %}
 7931 
 7932 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7933   match(Set dst (ReverseBytesL src));
 7934 
 7935   ins_cost(INSN_COST);
 7936   format %{ &quot;rev  $dst, $src&quot; %}
 7937 
 7938   ins_encode %{
 7939     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7940   %}
 7941 
 7942   ins_pipe(ialu_reg);
 7943 %}
 7944 
 7945 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7946   match(Set dst (ReverseBytesUS src));
 7947 
 7948   ins_cost(INSN_COST);
 7949   format %{ &quot;rev16w  $dst, $src&quot; %}
 7950 
 7951   ins_encode %{
 7952     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7953   %}
 7954 
 7955   ins_pipe(ialu_reg);
 7956 %}
 7957 
 7958 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7959   match(Set dst (ReverseBytesS src));
 7960 
 7961   ins_cost(INSN_COST);
 7962   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7963             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7964 
 7965   ins_encode %{
 7966     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7967     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7968   %}
 7969 
 7970   ins_pipe(ialu_reg);
 7971 %}
 7972 
 7973 // ============================================================================
 7974 // Zero Count Instructions
 7975 
 7976 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7977   match(Set dst (CountLeadingZerosI src));
 7978 
 7979   ins_cost(INSN_COST);
 7980   format %{ &quot;clzw  $dst, $src&quot; %}
 7981   ins_encode %{
 7982     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7983   %}
 7984 
 7985   ins_pipe(ialu_reg);
 7986 %}
 7987 
 7988 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7989   match(Set dst (CountLeadingZerosL src));
 7990 
 7991   ins_cost(INSN_COST);
 7992   format %{ &quot;clz   $dst, $src&quot; %}
 7993   ins_encode %{
 7994     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7995   %}
 7996 
 7997   ins_pipe(ialu_reg);
 7998 %}
 7999 
 8000 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8001   match(Set dst (CountTrailingZerosI src));
 8002 
 8003   ins_cost(INSN_COST * 2);
 8004   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8005             &quot;clzw   $dst, $dst&quot; %}
 8006   ins_encode %{
 8007     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8008     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8009   %}
 8010 
 8011   ins_pipe(ialu_reg);
 8012 %}
 8013 
 8014 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8015   match(Set dst (CountTrailingZerosL src));
 8016 
 8017   ins_cost(INSN_COST * 2);
 8018   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8019             &quot;clz    $dst, $dst&quot; %}
 8020   ins_encode %{
 8021     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8022     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8023   %}
 8024 
 8025   ins_pipe(ialu_reg);
 8026 %}
 8027 
 8028 //---------- Population Count Instructions -------------------------------------
 8029 //
 8030 
 8031 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8032   predicate(UsePopCountInstruction);
 8033   match(Set dst (PopCountI src));
 8034   effect(TEMP tmp);
 8035   ins_cost(INSN_COST * 13);
 8036 
 8037   format %{ &quot;movw   $src, $src\n\t&quot;
 8038             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8039             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8040             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8041             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8042   ins_encode %{
 8043     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8044     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8045     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8046     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8047     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8048   %}
 8049 
 8050   ins_pipe(pipe_class_default);
 8051 %}
 8052 
 8053 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8054   predicate(UsePopCountInstruction);
 8055   match(Set dst (PopCountI (LoadI mem)));
 8056   effect(TEMP tmp);
 8057   ins_cost(INSN_COST * 13);
 8058 
 8059   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8060             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8061             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8062             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8063   ins_encode %{
 8064     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8065     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8066               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8067     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8068     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8069     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8070   %}
 8071 
 8072   ins_pipe(pipe_class_default);
 8073 %}
 8074 
 8075 // Note: Long.bitCount(long) returns an int.
 8076 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8077   predicate(UsePopCountInstruction);
 8078   match(Set dst (PopCountL src));
 8079   effect(TEMP tmp);
 8080   ins_cost(INSN_COST * 13);
 8081 
 8082   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8083             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8084             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8085             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8086   ins_encode %{
 8087     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8088     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8089     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8090     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8091   %}
 8092 
 8093   ins_pipe(pipe_class_default);
 8094 %}
 8095 
 8096 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8097   predicate(UsePopCountInstruction);
 8098   match(Set dst (PopCountL (LoadL mem)));
 8099   effect(TEMP tmp);
 8100   ins_cost(INSN_COST * 13);
 8101 
 8102   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8103             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8104             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8105             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8106   ins_encode %{
 8107     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8108     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8109               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8110     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8111     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8112     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8113   %}
 8114 
 8115   ins_pipe(pipe_class_default);
 8116 %}
 8117 
 8118 // ============================================================================
 8119 // MemBar Instruction
 8120 
 8121 instruct load_fence() %{
 8122   match(LoadFence);
 8123   ins_cost(VOLATILE_REF_COST);
 8124 
 8125   format %{ &quot;load_fence&quot; %}
 8126 
 8127   ins_encode %{
 8128     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8129   %}
 8130   ins_pipe(pipe_serial);
 8131 %}
 8132 
 8133 instruct unnecessary_membar_acquire() %{
 8134   predicate(unnecessary_acquire(n));
 8135   match(MemBarAcquire);
 8136   ins_cost(0);
 8137 
 8138   format %{ &quot;membar_acquire (elided)&quot; %}
 8139 
 8140   ins_encode %{
 8141     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8142   %}
 8143 
 8144   ins_pipe(pipe_class_empty);
 8145 %}
 8146 
 8147 instruct membar_acquire() %{
 8148   match(MemBarAcquire);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;membar_acquire\n\t&quot;
 8152             &quot;dmb ish&quot; %}
 8153 
 8154   ins_encode %{
 8155     __ block_comment(&quot;membar_acquire&quot;);
 8156     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8157   %}
 8158 
 8159   ins_pipe(pipe_serial);
 8160 %}
 8161 
 8162 
 8163 instruct membar_acquire_lock() %{
 8164   match(MemBarAcquireLock);
 8165   ins_cost(VOLATILE_REF_COST);
 8166 
 8167   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8168 
 8169   ins_encode %{
 8170     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8171   %}
 8172 
 8173   ins_pipe(pipe_serial);
 8174 %}
 8175 
 8176 instruct store_fence() %{
 8177   match(StoreFence);
 8178   ins_cost(VOLATILE_REF_COST);
 8179 
 8180   format %{ &quot;store_fence&quot; %}
 8181 
 8182   ins_encode %{
 8183     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8184   %}
 8185   ins_pipe(pipe_serial);
 8186 %}
 8187 
 8188 instruct unnecessary_membar_release() %{
 8189   predicate(unnecessary_release(n));
 8190   match(MemBarRelease);
 8191   ins_cost(0);
 8192 
 8193   format %{ &quot;membar_release (elided)&quot; %}
 8194 
 8195   ins_encode %{
 8196     __ block_comment(&quot;membar_release (elided)&quot;);
 8197   %}
 8198   ins_pipe(pipe_serial);
 8199 %}
 8200 
 8201 instruct membar_release() %{
 8202   match(MemBarRelease);
 8203   ins_cost(VOLATILE_REF_COST);
 8204 
 8205   format %{ &quot;membar_release\n\t&quot;
 8206             &quot;dmb ish&quot; %}
 8207 
 8208   ins_encode %{
 8209     __ block_comment(&quot;membar_release&quot;);
 8210     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8211   %}
 8212   ins_pipe(pipe_serial);
 8213 %}
 8214 
 8215 instruct membar_storestore() %{
 8216   match(MemBarStoreStore);
 8217   ins_cost(VOLATILE_REF_COST);
 8218 
 8219   format %{ &quot;MEMBAR-store-store&quot; %}
 8220 
 8221   ins_encode %{
 8222     __ membar(Assembler::StoreStore);
 8223   %}
 8224   ins_pipe(pipe_serial);
 8225 %}
 8226 
 8227 instruct membar_release_lock() %{
 8228   match(MemBarReleaseLock);
 8229   ins_cost(VOLATILE_REF_COST);
 8230 
 8231   format %{ &quot;membar_release_lock (elided)&quot; %}
 8232 
 8233   ins_encode %{
 8234     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8235   %}
 8236 
 8237   ins_pipe(pipe_serial);
 8238 %}
 8239 
 8240 instruct unnecessary_membar_volatile() %{
 8241   predicate(unnecessary_volatile(n));
 8242   match(MemBarVolatile);
 8243   ins_cost(0);
 8244 
 8245   format %{ &quot;membar_volatile (elided)&quot; %}
 8246 
 8247   ins_encode %{
 8248     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8249   %}
 8250 
 8251   ins_pipe(pipe_serial);
 8252 %}
 8253 
 8254 instruct membar_volatile() %{
 8255   match(MemBarVolatile);
 8256   ins_cost(VOLATILE_REF_COST*100);
 8257 
 8258   format %{ &quot;membar_volatile\n\t&quot;
 8259              &quot;dmb ish&quot;%}
 8260 
 8261   ins_encode %{
 8262     __ block_comment(&quot;membar_volatile&quot;);
 8263     __ membar(Assembler::StoreLoad);
 8264   %}
 8265 
 8266   ins_pipe(pipe_serial);
 8267 %}
 8268 
 8269 // ============================================================================
 8270 // Cast/Convert Instructions
 8271 
 8272 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8273   match(Set dst (CastX2P src));
 8274 
 8275   ins_cost(INSN_COST);
 8276   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8277 
 8278   ins_encode %{
 8279     if ($dst$$reg != $src$$reg) {
 8280       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8281     }
 8282   %}
 8283 
 8284   ins_pipe(ialu_reg);
 8285 %}
 8286 
<a name="8" id="anc8"></a><span class="line-added"> 8287 instruct castN2X(iRegLNoSp dst, iRegN src) %{</span>
<span class="line-added"> 8288   match(Set dst (CastP2X src));</span>
<span class="line-added"> 8289 </span>
<span class="line-added"> 8290   ins_cost(INSN_COST);</span>
<span class="line-added"> 8291   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}</span>
<span class="line-added"> 8292 </span>
<span class="line-added"> 8293   ins_encode %{</span>
<span class="line-added"> 8294     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8295       __ mov(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8296     }</span>
<span class="line-added"> 8297   %}</span>
<span class="line-added"> 8298 </span>
<span class="line-added"> 8299   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8300 %}</span>
<span class="line-added"> 8301 </span>
 8302 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8303   match(Set dst (CastP2X src));
 8304 
 8305   ins_cost(INSN_COST);
 8306   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8307 
 8308   ins_encode %{
 8309     if ($dst$$reg != $src$$reg) {
 8310       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8311     }
 8312   %}
 8313 
 8314   ins_pipe(ialu_reg);
 8315 %}
 8316 
<a name="9" id="anc9"></a><span class="line-added"> 8317 instruct castN2I(iRegINoSp dst, iRegN src) %{</span>
<span class="line-added"> 8318   match(Set dst (CastN2I src));</span>
<span class="line-added"> 8319 </span>
<span class="line-added"> 8320   ins_cost(INSN_COST);</span>
<span class="line-added"> 8321   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}</span>
<span class="line-added"> 8322 </span>
<span class="line-added"> 8323   ins_encode %{</span>
<span class="line-added"> 8324     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8325       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8326     }</span>
<span class="line-added"> 8327   %}</span>
<span class="line-added"> 8328 </span>
<span class="line-added"> 8329   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8330 %}</span>
<span class="line-added"> 8331 </span>
<span class="line-added"> 8332 instruct castI2N(iRegNNoSp dst, iRegI src) %{</span>
<span class="line-added"> 8333   match(Set dst (CastI2N src));</span>
<span class="line-added"> 8334 </span>
<span class="line-added"> 8335   ins_cost(INSN_COST);</span>
<span class="line-added"> 8336   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}</span>
<span class="line-added"> 8337 </span>
<span class="line-added"> 8338   ins_encode %{</span>
<span class="line-added"> 8339     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8340       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8341     }</span>
<span class="line-added"> 8342   %}</span>
<span class="line-added"> 8343 </span>
<span class="line-added"> 8344   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8345 %}</span>
<span class="line-added"> 8346 </span>
<span class="line-added"> 8347 </span>
 8348 // Convert oop into int for vectors alignment masking
 8349 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8350   match(Set dst (ConvL2I (CastP2X src)));
 8351 
 8352   ins_cost(INSN_COST);
 8353   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8354   ins_encode %{
 8355     __ movw($dst$$Register, $src$$Register);
 8356   %}
 8357 
 8358   ins_pipe(ialu_reg);
 8359 %}
 8360 
 8361 // Convert compressed oop into int for vectors alignment masking
 8362 // in case of 32bit oops (heap &lt; 4Gb).
 8363 instruct convN2I(iRegINoSp dst, iRegN src)
 8364 %{
 8365   predicate(CompressedOops::shift() == 0);
 8366   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8367 
 8368   ins_cost(INSN_COST);
 8369   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8370   ins_encode %{
 8371     __ movw($dst$$Register, $src$$Register);
 8372   %}
 8373 
 8374   ins_pipe(ialu_reg);
 8375 %}
 8376 
 8377 
 8378 // Convert oop pointer into compressed form
 8379 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8380   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8381   match(Set dst (EncodeP src));
 8382   effect(KILL cr);
 8383   ins_cost(INSN_COST * 3);
 8384   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8385   ins_encode %{
 8386     Register s = $src$$Register;
 8387     Register d = $dst$$Register;
 8388     __ encode_heap_oop(d, s);
 8389   %}
 8390   ins_pipe(ialu_reg);
 8391 %}
 8392 
 8393 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8394   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8395   match(Set dst (EncodeP src));
 8396   ins_cost(INSN_COST * 3);
 8397   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8398   ins_encode %{
 8399     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8400   %}
 8401   ins_pipe(ialu_reg);
 8402 %}
 8403 
 8404 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8405   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8406             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8407   match(Set dst (DecodeN src));
 8408   ins_cost(INSN_COST * 3);
 8409   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8410   ins_encode %{
 8411     Register s = $src$$Register;
 8412     Register d = $dst$$Register;
 8413     __ decode_heap_oop(d, s);
 8414   %}
 8415   ins_pipe(ialu_reg);
 8416 %}
 8417 
 8418 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8419   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8420             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8421   match(Set dst (DecodeN src));
 8422   ins_cost(INSN_COST * 3);
 8423   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8424   ins_encode %{
 8425     Register s = $src$$Register;
 8426     Register d = $dst$$Register;
 8427     __ decode_heap_oop_not_null(d, s);
 8428   %}
 8429   ins_pipe(ialu_reg);
 8430 %}
 8431 
 8432 // n.b. AArch64 implementations of encode_klass_not_null and
 8433 // decode_klass_not_null do not modify the flags register so, unlike
 8434 // Intel, we don&#39;t kill CR as a side effect here
 8435 
 8436 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8437   match(Set dst (EncodePKlass src));
 8438 
 8439   ins_cost(INSN_COST * 3);
 8440   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8441 
 8442   ins_encode %{
 8443     Register src_reg = as_Register($src$$reg);
 8444     Register dst_reg = as_Register($dst$$reg);
 8445     __ encode_klass_not_null(dst_reg, src_reg);
 8446   %}
 8447 
 8448    ins_pipe(ialu_reg);
 8449 %}
 8450 
 8451 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8452   match(Set dst (DecodeNKlass src));
 8453 
 8454   ins_cost(INSN_COST * 3);
 8455   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8456 
 8457   ins_encode %{
 8458     Register src_reg = as_Register($src$$reg);
 8459     Register dst_reg = as_Register($dst$$reg);
 8460     if (dst_reg != src_reg) {
 8461       __ decode_klass_not_null(dst_reg, src_reg);
 8462     } else {
 8463       __ decode_klass_not_null(dst_reg);
 8464     }
 8465   %}
 8466 
 8467    ins_pipe(ialu_reg);
 8468 %}
 8469 
 8470 instruct checkCastPP(iRegPNoSp dst)
 8471 %{
 8472   match(Set dst (CheckCastPP dst));
 8473 
 8474   size(0);
 8475   format %{ &quot;# checkcastPP of $dst&quot; %}
 8476   ins_encode(/* empty encoding */);
 8477   ins_pipe(pipe_class_empty);
 8478 %}
 8479 
 8480 instruct castPP(iRegPNoSp dst)
 8481 %{
 8482   match(Set dst (CastPP dst));
 8483 
 8484   size(0);
 8485   format %{ &quot;# castPP of $dst&quot; %}
 8486   ins_encode(/* empty encoding */);
 8487   ins_pipe(pipe_class_empty);
 8488 %}
 8489 
 8490 instruct castII(iRegI dst)
 8491 %{
 8492   match(Set dst (CastII dst));
 8493 
 8494   size(0);
 8495   format %{ &quot;# castII of $dst&quot; %}
 8496   ins_encode(/* empty encoding */);
 8497   ins_cost(0);
 8498   ins_pipe(pipe_class_empty);
 8499 %}
 8500 
 8501 // ============================================================================
 8502 // Atomic operation instructions
 8503 //
 8504 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8505 // Store{PIL}Conditional instructions using a normal load for the
 8506 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8507 //
 8508 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8509 // pair to lock object allocations from Eden space when not using
 8510 // TLABs.
 8511 //
 8512 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8513 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8514 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8515 // only for 64-bit.
 8516 //
 8517 // We implement LoadPLocked and StorePLocked instructions using,
 8518 // respectively the AArch64 hw load-exclusive and store-conditional
 8519 // instructions. Whereas we must implement each of
 8520 // Store{IL}Conditional using a CAS which employs a pair of
 8521 // instructions comprising a load-exclusive followed by a
 8522 // store-conditional.
 8523 
 8524 
 8525 // Locked-load (linked load) of the current heap-top
 8526 // used when updating the eden heap top
 8527 // implemented using ldaxr on AArch64
 8528 
 8529 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8530 %{
 8531   match(Set dst (LoadPLocked mem));
 8532 
 8533   ins_cost(VOLATILE_REF_COST);
 8534 
 8535   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8536 
 8537   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8538 
 8539   ins_pipe(pipe_serial);
 8540 %}
 8541 
 8542 // Conditional-store of the updated heap-top.
 8543 // Used during allocation of the shared heap.
 8544 // Sets flag (EQ) on success.
 8545 // implemented using stlxr on AArch64.
 8546 
 8547 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8548 %{
 8549   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8550 
 8551   ins_cost(VOLATILE_REF_COST);
 8552 
 8553  // TODO
 8554  // do we need to do a store-conditional release or can we just use a
 8555  // plain store-conditional?
 8556 
 8557   format %{
 8558     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8559     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8560   %}
 8561 
 8562   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8563 
 8564   ins_pipe(pipe_serial);
 8565 %}
 8566 
 8567 
 8568 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8569 // when attempting to rebias a lock towards the current thread.  We
 8570 // must use the acquire form of cmpxchg in order to guarantee acquire
 8571 // semantics in this case.
 8572 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8573 %{
 8574   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8575 
 8576   ins_cost(VOLATILE_REF_COST);
 8577 
 8578   format %{
 8579     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8580     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8581   %}
 8582 
 8583   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8584 
 8585   ins_pipe(pipe_slow);
 8586 %}
 8587 
 8588 // storeIConditional also has acquire semantics, for no better reason
 8589 // than matching storeLConditional.  At the time of writing this
 8590 // comment storeIConditional was not used anywhere by AArch64.
 8591 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8592 %{
 8593   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8594 
 8595   ins_cost(VOLATILE_REF_COST);
 8596 
 8597   format %{
 8598     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8599     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8600   %}
 8601 
 8602   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8603 
 8604   ins_pipe(pipe_slow);
 8605 %}
 8606 
 8607 // standard CompareAndSwapX when we are using barriers
 8608 // these have higher priority than the rules selected by a predicate
 8609 
 8610 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8611 // can&#39;t match them
 8612 
 8613 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8614 
 8615   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8616   ins_cost(2 * VOLATILE_REF_COST);
 8617 
 8618   effect(KILL cr);
 8619 
 8620   format %{
 8621     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8622     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8623   %}
 8624 
 8625   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8626             aarch64_enc_cset_eq(res));
 8627 
 8628   ins_pipe(pipe_slow);
 8629 %}
 8630 
 8631 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8632 
 8633   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8634   ins_cost(2 * VOLATILE_REF_COST);
 8635 
 8636   effect(KILL cr);
 8637 
 8638   format %{
 8639     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8640     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8641   %}
 8642 
 8643   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8644             aarch64_enc_cset_eq(res));
 8645 
 8646   ins_pipe(pipe_slow);
 8647 %}
 8648 
 8649 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8650 
 8651   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8652   ins_cost(2 * VOLATILE_REF_COST);
 8653 
 8654   effect(KILL cr);
 8655 
 8656  format %{
 8657     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8658     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8659  %}
 8660 
 8661  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8662             aarch64_enc_cset_eq(res));
 8663 
 8664   ins_pipe(pipe_slow);
 8665 %}
 8666 
 8667 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8668 
 8669   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8670   ins_cost(2 * VOLATILE_REF_COST);
 8671 
 8672   effect(KILL cr);
 8673 
 8674  format %{
 8675     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8676     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8677  %}
 8678 
 8679  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8680             aarch64_enc_cset_eq(res));
 8681 
 8682   ins_pipe(pipe_slow);
 8683 %}
 8684 
 8685 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8686 
 8687   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8688   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8689   ins_cost(2 * VOLATILE_REF_COST);
 8690 
 8691   effect(KILL cr);
 8692 
 8693  format %{
 8694     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8695     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8696  %}
 8697 
 8698  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8699             aarch64_enc_cset_eq(res));
 8700 
 8701   ins_pipe(pipe_slow);
 8702 %}
 8703 
 8704 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8705 
 8706   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8707   ins_cost(2 * VOLATILE_REF_COST);
 8708 
 8709   effect(KILL cr);
 8710 
 8711  format %{
 8712     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8713     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8714  %}
 8715 
 8716  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8717             aarch64_enc_cset_eq(res));
 8718 
 8719   ins_pipe(pipe_slow);
 8720 %}
 8721 
 8722 // alternative CompareAndSwapX when we are eliding barriers
 8723 
 8724 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8725 
 8726   predicate(needs_acquiring_load_exclusive(n));
 8727   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8728   ins_cost(VOLATILE_REF_COST);
 8729 
 8730   effect(KILL cr);
 8731 
 8732   format %{
 8733     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8734     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8735   %}
 8736 
 8737   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8738             aarch64_enc_cset_eq(res));
 8739 
 8740   ins_pipe(pipe_slow);
 8741 %}
 8742 
 8743 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8744 
 8745   predicate(needs_acquiring_load_exclusive(n));
 8746   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8747   ins_cost(VOLATILE_REF_COST);
 8748 
 8749   effect(KILL cr);
 8750 
 8751   format %{
 8752     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8753     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8754   %}
 8755 
 8756   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8757             aarch64_enc_cset_eq(res));
 8758 
 8759   ins_pipe(pipe_slow);
 8760 %}
 8761 
 8762 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8763 
 8764   predicate(needs_acquiring_load_exclusive(n));
 8765   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8766   ins_cost(VOLATILE_REF_COST);
 8767 
 8768   effect(KILL cr);
 8769 
 8770  format %{
 8771     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8772     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8773  %}
 8774 
 8775  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8776             aarch64_enc_cset_eq(res));
 8777 
 8778   ins_pipe(pipe_slow);
 8779 %}
 8780 
 8781 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8782 
 8783   predicate(needs_acquiring_load_exclusive(n));
 8784   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8785   ins_cost(VOLATILE_REF_COST);
 8786 
 8787   effect(KILL cr);
 8788 
 8789  format %{
 8790     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8791     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8792  %}
 8793 
 8794  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8795             aarch64_enc_cset_eq(res));
 8796 
 8797   ins_pipe(pipe_slow);
 8798 %}
 8799 
 8800 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8801 
 8802   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8803   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8804   ins_cost(VOLATILE_REF_COST);
 8805 
 8806   effect(KILL cr);
 8807 
 8808  format %{
 8809     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8810     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8811  %}
 8812 
 8813  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8814             aarch64_enc_cset_eq(res));
 8815 
 8816   ins_pipe(pipe_slow);
 8817 %}
 8818 
 8819 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8820 
 8821   predicate(needs_acquiring_load_exclusive(n));
 8822   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8823   ins_cost(VOLATILE_REF_COST);
 8824 
 8825   effect(KILL cr);
 8826 
 8827  format %{
 8828     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8829     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8830  %}
 8831 
 8832  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8833             aarch64_enc_cset_eq(res));
 8834 
 8835   ins_pipe(pipe_slow);
 8836 %}
 8837 
 8838 
 8839 // ---------------------------------------------------------------------
 8840 
 8841 
 8842 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8843 
 8844 // Sundry CAS operations.  Note that release is always true,
 8845 // regardless of the memory ordering of the CAS.  This is because we
 8846 // need the volatile case to be sequentially consistent but there is
 8847 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8848 // can&#39;t check the type of memory ordering here, so we always emit a
 8849 // STLXR.
 8850 
 8851 // This section is generated from aarch64_ad_cas.m4
 8852 
 8853 
 8854 
 8855 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8856   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8857   ins_cost(2 * VOLATILE_REF_COST);
 8858   effect(TEMP_DEF res, KILL cr);
 8859   format %{
 8860     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8861   %}
 8862   ins_encode %{
 8863     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8864                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8865                /*weak*/ false, $res$$Register);
 8866     __ sxtbw($res$$Register, $res$$Register);
 8867   %}
 8868   ins_pipe(pipe_slow);
 8869 %}
 8870 
 8871 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8872   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882     __ sxthw($res$$Register, $res$$Register);
 8883   %}
 8884   ins_pipe(pipe_slow);
 8885 %}
 8886 
 8887 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8888   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8889   ins_cost(2 * VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::word, /*acquire*/ false, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898   %}
 8899   ins_pipe(pipe_slow);
 8900 %}
 8901 
 8902 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8903   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8904   ins_cost(2 * VOLATILE_REF_COST);
 8905   effect(TEMP_DEF res, KILL cr);
 8906   format %{
 8907     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8908   %}
 8909   ins_encode %{
 8910     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8911                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8912                /*weak*/ false, $res$$Register);
 8913   %}
 8914   ins_pipe(pipe_slow);
 8915 %}
 8916 
 8917 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8918   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8919   ins_cost(2 * VOLATILE_REF_COST);
 8920   effect(TEMP_DEF res, KILL cr);
 8921   format %{
 8922     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8923   %}
 8924   ins_encode %{
 8925     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8926                Assembler::word, /*acquire*/ false, /*release*/ true,
 8927                /*weak*/ false, $res$$Register);
 8928   %}
 8929   ins_pipe(pipe_slow);
 8930 %}
 8931 
 8932 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8933   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8934   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8935   ins_cost(2 * VOLATILE_REF_COST);
 8936   effect(TEMP_DEF res, KILL cr);
 8937   format %{
 8938     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8939   %}
 8940   ins_encode %{
 8941     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8942                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8943                /*weak*/ false, $res$$Register);
 8944   %}
 8945   ins_pipe(pipe_slow);
 8946 %}
 8947 
 8948 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8949   predicate(needs_acquiring_load_exclusive(n));
 8950   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8951   ins_cost(VOLATILE_REF_COST);
 8952   effect(TEMP_DEF res, KILL cr);
 8953   format %{
 8954     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8955   %}
 8956   ins_encode %{
 8957     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8958                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8959                /*weak*/ false, $res$$Register);
 8960     __ sxtbw($res$$Register, $res$$Register);
 8961   %}
 8962   ins_pipe(pipe_slow);
 8963 %}
 8964 
 8965 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8966   predicate(needs_acquiring_load_exclusive(n));
 8967   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8968   ins_cost(VOLATILE_REF_COST);
 8969   effect(TEMP_DEF res, KILL cr);
 8970   format %{
 8971     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8972   %}
 8973   ins_encode %{
 8974     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8975                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8976                /*weak*/ false, $res$$Register);
 8977     __ sxthw($res$$Register, $res$$Register);
 8978   %}
 8979   ins_pipe(pipe_slow);
 8980 %}
 8981 
 8982 
 8983 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8984   predicate(needs_acquiring_load_exclusive(n));
 8985   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8986   ins_cost(VOLATILE_REF_COST);
 8987   effect(TEMP_DEF res, KILL cr);
 8988   format %{
 8989     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8990   %}
 8991   ins_encode %{
 8992     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8993                Assembler::word, /*acquire*/ true, /*release*/ true,
 8994                /*weak*/ false, $res$$Register);
 8995   %}
 8996   ins_pipe(pipe_slow);
 8997 %}
 8998 
 8999 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9000   predicate(needs_acquiring_load_exclusive(n));
 9001   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9002   ins_cost(VOLATILE_REF_COST);
 9003   effect(TEMP_DEF res, KILL cr);
 9004   format %{
 9005     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9006   %}
 9007   ins_encode %{
 9008     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9009                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9010                /*weak*/ false, $res$$Register);
 9011   %}
 9012   ins_pipe(pipe_slow);
 9013 %}
 9014 
 9015 
 9016 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9017   predicate(needs_acquiring_load_exclusive(n));
 9018   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9019   ins_cost(VOLATILE_REF_COST);
 9020   effect(TEMP_DEF res, KILL cr);
 9021   format %{
 9022     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9023   %}
 9024   ins_encode %{
 9025     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9026                Assembler::word, /*acquire*/ true, /*release*/ true,
 9027                /*weak*/ false, $res$$Register);
 9028   %}
 9029   ins_pipe(pipe_slow);
 9030 %}
 9031 
 9032 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9033   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9034   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9035   ins_cost(VOLATILE_REF_COST);
 9036   effect(TEMP_DEF res, KILL cr);
 9037   format %{
 9038     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9039   %}
 9040   ins_encode %{
 9041     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9042                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9043                /*weak*/ false, $res$$Register);
 9044   %}
 9045   ins_pipe(pipe_slow);
 9046 %}
 9047 
 9048 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9049   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9050   ins_cost(2 * VOLATILE_REF_COST);
 9051   effect(KILL cr);
 9052   format %{
 9053     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9054     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9055   %}
 9056   ins_encode %{
 9057     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9058                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9059                /*weak*/ true, noreg);
 9060     __ csetw($res$$Register, Assembler::EQ);
 9061   %}
 9062   ins_pipe(pipe_slow);
 9063 %}
 9064 
 9065 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9066   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9067   ins_cost(2 * VOLATILE_REF_COST);
 9068   effect(KILL cr);
 9069   format %{
 9070     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9071     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9072   %}
 9073   ins_encode %{
 9074     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9075                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9076                /*weak*/ true, noreg);
 9077     __ csetw($res$$Register, Assembler::EQ);
 9078   %}
 9079   ins_pipe(pipe_slow);
 9080 %}
 9081 
 9082 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9083   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9084   ins_cost(2 * VOLATILE_REF_COST);
 9085   effect(KILL cr);
 9086   format %{
 9087     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9088     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9089   %}
 9090   ins_encode %{
 9091     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9092                Assembler::word, /*acquire*/ false, /*release*/ true,
 9093                /*weak*/ true, noreg);
 9094     __ csetw($res$$Register, Assembler::EQ);
 9095   %}
 9096   ins_pipe(pipe_slow);
 9097 %}
 9098 
 9099 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9100   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9101   ins_cost(2 * VOLATILE_REF_COST);
 9102   effect(KILL cr);
 9103   format %{
 9104     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9105     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9106   %}
 9107   ins_encode %{
 9108     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9109                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9110                /*weak*/ true, noreg);
 9111     __ csetw($res$$Register, Assembler::EQ);
 9112   %}
 9113   ins_pipe(pipe_slow);
 9114 %}
 9115 
 9116 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9117   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9118   ins_cost(2 * VOLATILE_REF_COST);
 9119   effect(KILL cr);
 9120   format %{
 9121     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9122     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9123   %}
 9124   ins_encode %{
 9125     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9126                Assembler::word, /*acquire*/ false, /*release*/ true,
 9127                /*weak*/ true, noreg);
 9128     __ csetw($res$$Register, Assembler::EQ);
 9129   %}
 9130   ins_pipe(pipe_slow);
 9131 %}
 9132 
 9133 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9134   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9135   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9136   ins_cost(2 * VOLATILE_REF_COST);
 9137   effect(KILL cr);
 9138   format %{
 9139     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9140     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9141   %}
 9142   ins_encode %{
 9143     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9144                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9145                /*weak*/ true, noreg);
 9146     __ csetw($res$$Register, Assembler::EQ);
 9147   %}
 9148   ins_pipe(pipe_slow);
 9149 %}
 9150 
 9151 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9152   predicate(needs_acquiring_load_exclusive(n));
 9153   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9154   ins_cost(VOLATILE_REF_COST);
 9155   effect(KILL cr);
 9156   format %{
 9157     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9158     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9159   %}
 9160   ins_encode %{
 9161     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9162                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9163                /*weak*/ true, noreg);
 9164     __ csetw($res$$Register, Assembler::EQ);
 9165   %}
 9166   ins_pipe(pipe_slow);
 9167 %}
 9168 
 9169 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9170   predicate(needs_acquiring_load_exclusive(n));
 9171   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9172   ins_cost(VOLATILE_REF_COST);
 9173   effect(KILL cr);
 9174   format %{
 9175     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9176     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9177   %}
 9178   ins_encode %{
 9179     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9180                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9181                /*weak*/ true, noreg);
 9182     __ csetw($res$$Register, Assembler::EQ);
 9183   %}
 9184   ins_pipe(pipe_slow);
 9185 %}
 9186 
 9187 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9188   predicate(needs_acquiring_load_exclusive(n));
 9189   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9190   ins_cost(VOLATILE_REF_COST);
 9191   effect(KILL cr);
 9192   format %{
 9193     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9194     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9195   %}
 9196   ins_encode %{
 9197     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9198                Assembler::word, /*acquire*/ true, /*release*/ true,
 9199                /*weak*/ true, noreg);
 9200     __ csetw($res$$Register, Assembler::EQ);
 9201   %}
 9202   ins_pipe(pipe_slow);
 9203 %}
 9204 
 9205 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9206   predicate(needs_acquiring_load_exclusive(n));
 9207   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9208   ins_cost(VOLATILE_REF_COST);
 9209   effect(KILL cr);
 9210   format %{
 9211     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9212     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9213   %}
 9214   ins_encode %{
 9215     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9216                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9217                /*weak*/ true, noreg);
 9218     __ csetw($res$$Register, Assembler::EQ);
 9219   %}
 9220   ins_pipe(pipe_slow);
 9221 %}
 9222 
 9223 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9224   predicate(needs_acquiring_load_exclusive(n));
 9225   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9226   ins_cost(VOLATILE_REF_COST);
 9227   effect(KILL cr);
 9228   format %{
 9229     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9230     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9231   %}
 9232   ins_encode %{
 9233     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9234                Assembler::word, /*acquire*/ true, /*release*/ true,
 9235                /*weak*/ true, noreg);
 9236     __ csetw($res$$Register, Assembler::EQ);
 9237   %}
 9238   ins_pipe(pipe_slow);
 9239 %}
 9240 
 9241 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9242   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9243   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9244   ins_cost(VOLATILE_REF_COST);
 9245   effect(KILL cr);
 9246   format %{
 9247     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9248     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9249   %}
 9250   ins_encode %{
 9251     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9252                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9253                /*weak*/ true, noreg);
 9254     __ csetw($res$$Register, Assembler::EQ);
 9255   %}
 9256   ins_pipe(pipe_slow);
 9257 %}
 9258 
 9259 // END This section of the file is automatically generated. Do not edit --------------
 9260 // ---------------------------------------------------------------------
 9261 
 9262 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9263   match(Set prev (GetAndSetI mem newv));
 9264   ins_cost(2 * VOLATILE_REF_COST);
 9265   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9266   ins_encode %{
 9267     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9268   %}
 9269   ins_pipe(pipe_serial);
 9270 %}
 9271 
 9272 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9273   match(Set prev (GetAndSetL mem newv));
 9274   ins_cost(2 * VOLATILE_REF_COST);
 9275   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9276   ins_encode %{
 9277     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9278   %}
 9279   ins_pipe(pipe_serial);
 9280 %}
 9281 
 9282 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9283   match(Set prev (GetAndSetN mem newv));
 9284   ins_cost(2 * VOLATILE_REF_COST);
 9285   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9286   ins_encode %{
 9287     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9288   %}
 9289   ins_pipe(pipe_serial);
 9290 %}
 9291 
 9292 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9293   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9294   match(Set prev (GetAndSetP mem newv));
 9295   ins_cost(2 * VOLATILE_REF_COST);
 9296   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9297   ins_encode %{
 9298     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9299   %}
 9300   ins_pipe(pipe_serial);
 9301 %}
 9302 
 9303 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9304   predicate(needs_acquiring_load_exclusive(n));
 9305   match(Set prev (GetAndSetI mem newv));
 9306   ins_cost(VOLATILE_REF_COST);
 9307   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9308   ins_encode %{
 9309     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9310   %}
 9311   ins_pipe(pipe_serial);
 9312 %}
 9313 
 9314 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9315   predicate(needs_acquiring_load_exclusive(n));
 9316   match(Set prev (GetAndSetL mem newv));
 9317   ins_cost(VOLATILE_REF_COST);
 9318   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9319   ins_encode %{
 9320     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9321   %}
 9322   ins_pipe(pipe_serial);
 9323 %}
 9324 
 9325 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9326   predicate(needs_acquiring_load_exclusive(n));
 9327   match(Set prev (GetAndSetN mem newv));
 9328   ins_cost(VOLATILE_REF_COST);
 9329   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9330   ins_encode %{
 9331     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9332   %}
 9333   ins_pipe(pipe_serial);
 9334 %}
 9335 
 9336 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9337   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9338   match(Set prev (GetAndSetP mem newv));
 9339   ins_cost(VOLATILE_REF_COST);
 9340   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9341   ins_encode %{
 9342     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9343   %}
 9344   ins_pipe(pipe_serial);
 9345 %}
 9346 
 9347 
 9348 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9349   match(Set newval (GetAndAddL mem incr));
 9350   ins_cost(2 * VOLATILE_REF_COST + 1);
 9351   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9352   ins_encode %{
 9353     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9354   %}
 9355   ins_pipe(pipe_serial);
 9356 %}
 9357 
 9358 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9359   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9360   match(Set dummy (GetAndAddL mem incr));
 9361   ins_cost(2 * VOLATILE_REF_COST);
 9362   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9363   ins_encode %{
 9364     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9365   %}
 9366   ins_pipe(pipe_serial);
 9367 %}
 9368 
 9369 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9370   match(Set newval (GetAndAddL mem incr));
 9371   ins_cost(2 * VOLATILE_REF_COST + 1);
 9372   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9373   ins_encode %{
 9374     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9375   %}
 9376   ins_pipe(pipe_serial);
 9377 %}
 9378 
 9379 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9380   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9381   match(Set dummy (GetAndAddL mem incr));
 9382   ins_cost(2 * VOLATILE_REF_COST);
 9383   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9384   ins_encode %{
 9385     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9386   %}
 9387   ins_pipe(pipe_serial);
 9388 %}
 9389 
 9390 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9391   match(Set newval (GetAndAddI mem incr));
 9392   ins_cost(2 * VOLATILE_REF_COST + 1);
 9393   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9394   ins_encode %{
 9395     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9396   %}
 9397   ins_pipe(pipe_serial);
 9398 %}
 9399 
 9400 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9401   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9402   match(Set dummy (GetAndAddI mem incr));
 9403   ins_cost(2 * VOLATILE_REF_COST);
 9404   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9405   ins_encode %{
 9406     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9407   %}
 9408   ins_pipe(pipe_serial);
 9409 %}
 9410 
 9411 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9412   match(Set newval (GetAndAddI mem incr));
 9413   ins_cost(2 * VOLATILE_REF_COST + 1);
 9414   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9415   ins_encode %{
 9416     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9417   %}
 9418   ins_pipe(pipe_serial);
 9419 %}
 9420 
 9421 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9422   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9423   match(Set dummy (GetAndAddI mem incr));
 9424   ins_cost(2 * VOLATILE_REF_COST);
 9425   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9426   ins_encode %{
 9427     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9428   %}
 9429   ins_pipe(pipe_serial);
 9430 %}
 9431 
 9432 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9433   predicate(needs_acquiring_load_exclusive(n));
 9434   match(Set newval (GetAndAddL mem incr));
 9435   ins_cost(VOLATILE_REF_COST + 1);
 9436   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9437   ins_encode %{
 9438     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9439   %}
 9440   ins_pipe(pipe_serial);
 9441 %}
 9442 
 9443 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9444   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9445   match(Set dummy (GetAndAddL mem incr));
 9446   ins_cost(VOLATILE_REF_COST);
 9447   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9448   ins_encode %{
 9449     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9450   %}
 9451   ins_pipe(pipe_serial);
 9452 %}
 9453 
 9454 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9455   predicate(needs_acquiring_load_exclusive(n));
 9456   match(Set newval (GetAndAddL mem incr));
 9457   ins_cost(VOLATILE_REF_COST + 1);
 9458   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9459   ins_encode %{
 9460     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9461   %}
 9462   ins_pipe(pipe_serial);
 9463 %}
 9464 
 9465 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9466   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9467   match(Set dummy (GetAndAddL mem incr));
 9468   ins_cost(VOLATILE_REF_COST);
 9469   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9470   ins_encode %{
 9471     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9472   %}
 9473   ins_pipe(pipe_serial);
 9474 %}
 9475 
 9476 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9477   predicate(needs_acquiring_load_exclusive(n));
 9478   match(Set newval (GetAndAddI mem incr));
 9479   ins_cost(VOLATILE_REF_COST + 1);
 9480   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9481   ins_encode %{
 9482     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9483   %}
 9484   ins_pipe(pipe_serial);
 9485 %}
 9486 
 9487 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9488   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9489   match(Set dummy (GetAndAddI mem incr));
 9490   ins_cost(VOLATILE_REF_COST);
 9491   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9492   ins_encode %{
 9493     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9494   %}
 9495   ins_pipe(pipe_serial);
 9496 %}
 9497 
 9498 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9499   predicate(needs_acquiring_load_exclusive(n));
 9500   match(Set newval (GetAndAddI mem incr));
 9501   ins_cost(VOLATILE_REF_COST + 1);
 9502   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9503   ins_encode %{
 9504     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9505   %}
 9506   ins_pipe(pipe_serial);
 9507 %}
 9508 
 9509 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9510   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9511   match(Set dummy (GetAndAddI mem incr));
 9512   ins_cost(VOLATILE_REF_COST);
 9513   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9514   ins_encode %{
 9515     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9516   %}
 9517   ins_pipe(pipe_serial);
 9518 %}
 9519 
 9520 // Manifest a CmpL result in an integer register.
 9521 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9522 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9523 %{
 9524   match(Set dst (CmpL3 src1 src2));
 9525   effect(KILL flags);
 9526 
 9527   ins_cost(INSN_COST * 6);
 9528   format %{
 9529       &quot;cmp $src1, $src2&quot;
 9530       &quot;csetw $dst, ne&quot;
 9531       &quot;cnegw $dst, lt&quot;
 9532   %}
 9533   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9534   ins_encode %{
 9535     __ cmp($src1$$Register, $src2$$Register);
 9536     __ csetw($dst$$Register, Assembler::NE);
 9537     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9538   %}
 9539 
 9540   ins_pipe(pipe_class_default);
 9541 %}
 9542 
 9543 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9544 %{
 9545   match(Set dst (CmpL3 src1 src2));
 9546   effect(KILL flags);
 9547 
 9548   ins_cost(INSN_COST * 6);
 9549   format %{
 9550       &quot;cmp $src1, $src2&quot;
 9551       &quot;csetw $dst, ne&quot;
 9552       &quot;cnegw $dst, lt&quot;
 9553   %}
 9554   ins_encode %{
 9555     int32_t con = (int32_t)$src2$$constant;
 9556      if (con &lt; 0) {
 9557       __ adds(zr, $src1$$Register, -con);
 9558     } else {
 9559       __ subs(zr, $src1$$Register, con);
 9560     }
 9561     __ csetw($dst$$Register, Assembler::NE);
 9562     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9563   %}
 9564 
 9565   ins_pipe(pipe_class_default);
 9566 %}
 9567 
 9568 // ============================================================================
 9569 // Conditional Move Instructions
 9570 
 9571 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9572 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9573 // define an op class which merged both inputs and use it to type the
 9574 // argument to a single rule. unfortunatelyt his fails because the
 9575 // opclass does not live up to the COND_INTER interface of its
 9576 // component operands. When the generic code tries to negate the
 9577 // operand it ends up running the generci Machoper::negate method
 9578 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9579 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9580 
 9581 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9582   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9583 
 9584   ins_cost(INSN_COST * 2);
 9585   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9586 
 9587   ins_encode %{
 9588     __ cselw(as_Register($dst$$reg),
 9589              as_Register($src2$$reg),
 9590              as_Register($src1$$reg),
 9591              (Assembler::Condition)$cmp$$cmpcode);
 9592   %}
 9593 
 9594   ins_pipe(icond_reg_reg);
 9595 %}
 9596 
 9597 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9598   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9599 
 9600   ins_cost(INSN_COST * 2);
 9601   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9602 
 9603   ins_encode %{
 9604     __ cselw(as_Register($dst$$reg),
 9605              as_Register($src2$$reg),
 9606              as_Register($src1$$reg),
 9607              (Assembler::Condition)$cmp$$cmpcode);
 9608   %}
 9609 
 9610   ins_pipe(icond_reg_reg);
 9611 %}
 9612 
 9613 // special cases where one arg is zero
 9614 
 9615 // n.b. this is selected in preference to the rule above because it
 9616 // avoids loading constant 0 into a source register
 9617 
 9618 // TODO
 9619 // we ought only to be able to cull one of these variants as the ideal
 9620 // transforms ought always to order the zero consistently (to left/right?)
 9621 
 9622 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9623   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9624 
 9625   ins_cost(INSN_COST * 2);
 9626   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9627 
 9628   ins_encode %{
 9629     __ cselw(as_Register($dst$$reg),
 9630              as_Register($src$$reg),
 9631              zr,
 9632              (Assembler::Condition)$cmp$$cmpcode);
 9633   %}
 9634 
 9635   ins_pipe(icond_reg);
 9636 %}
 9637 
 9638 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9639   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9640 
 9641   ins_cost(INSN_COST * 2);
 9642   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9643 
 9644   ins_encode %{
 9645     __ cselw(as_Register($dst$$reg),
 9646              as_Register($src$$reg),
 9647              zr,
 9648              (Assembler::Condition)$cmp$$cmpcode);
 9649   %}
 9650 
 9651   ins_pipe(icond_reg);
 9652 %}
 9653 
 9654 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9655   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9656 
 9657   ins_cost(INSN_COST * 2);
 9658   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9659 
 9660   ins_encode %{
 9661     __ cselw(as_Register($dst$$reg),
 9662              zr,
 9663              as_Register($src$$reg),
 9664              (Assembler::Condition)$cmp$$cmpcode);
 9665   %}
 9666 
 9667   ins_pipe(icond_reg);
 9668 %}
 9669 
 9670 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9671   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9672 
 9673   ins_cost(INSN_COST * 2);
 9674   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9675 
 9676   ins_encode %{
 9677     __ cselw(as_Register($dst$$reg),
 9678              zr,
 9679              as_Register($src$$reg),
 9680              (Assembler::Condition)$cmp$$cmpcode);
 9681   %}
 9682 
 9683   ins_pipe(icond_reg);
 9684 %}
 9685 
 9686 // special case for creating a boolean 0 or 1
 9687 
 9688 // n.b. this is selected in preference to the rule above because it
 9689 // avoids loading constants 0 and 1 into a source register
 9690 
 9691 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9692   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9693 
 9694   ins_cost(INSN_COST * 2);
 9695   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9696 
 9697   ins_encode %{
 9698     // equivalently
 9699     // cset(as_Register($dst$$reg),
 9700     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9701     __ csincw(as_Register($dst$$reg),
 9702              zr,
 9703              zr,
 9704              (Assembler::Condition)$cmp$$cmpcode);
 9705   %}
 9706 
 9707   ins_pipe(icond_none);
 9708 %}
 9709 
 9710 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9711   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9712 
 9713   ins_cost(INSN_COST * 2);
 9714   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9715 
 9716   ins_encode %{
 9717     // equivalently
 9718     // cset(as_Register($dst$$reg),
 9719     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9720     __ csincw(as_Register($dst$$reg),
 9721              zr,
 9722              zr,
 9723              (Assembler::Condition)$cmp$$cmpcode);
 9724   %}
 9725 
 9726   ins_pipe(icond_none);
 9727 %}
 9728 
 9729 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9730   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9731 
 9732   ins_cost(INSN_COST * 2);
 9733   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9734 
 9735   ins_encode %{
 9736     __ csel(as_Register($dst$$reg),
 9737             as_Register($src2$$reg),
 9738             as_Register($src1$$reg),
 9739             (Assembler::Condition)$cmp$$cmpcode);
 9740   %}
 9741 
 9742   ins_pipe(icond_reg_reg);
 9743 %}
 9744 
 9745 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9746   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9747 
 9748   ins_cost(INSN_COST * 2);
 9749   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9750 
 9751   ins_encode %{
 9752     __ csel(as_Register($dst$$reg),
 9753             as_Register($src2$$reg),
 9754             as_Register($src1$$reg),
 9755             (Assembler::Condition)$cmp$$cmpcode);
 9756   %}
 9757 
 9758   ins_pipe(icond_reg_reg);
 9759 %}
 9760 
 9761 // special cases where one arg is zero
 9762 
 9763 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9764   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9765 
 9766   ins_cost(INSN_COST * 2);
 9767   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9768 
 9769   ins_encode %{
 9770     __ csel(as_Register($dst$$reg),
 9771             zr,
 9772             as_Register($src$$reg),
 9773             (Assembler::Condition)$cmp$$cmpcode);
 9774   %}
 9775 
 9776   ins_pipe(icond_reg);
 9777 %}
 9778 
 9779 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9780   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9781 
 9782   ins_cost(INSN_COST * 2);
 9783   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9784 
 9785   ins_encode %{
 9786     __ csel(as_Register($dst$$reg),
 9787             zr,
 9788             as_Register($src$$reg),
 9789             (Assembler::Condition)$cmp$$cmpcode);
 9790   %}
 9791 
 9792   ins_pipe(icond_reg);
 9793 %}
 9794 
 9795 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9796   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9797 
 9798   ins_cost(INSN_COST * 2);
 9799   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9800 
 9801   ins_encode %{
 9802     __ csel(as_Register($dst$$reg),
 9803             as_Register($src$$reg),
 9804             zr,
 9805             (Assembler::Condition)$cmp$$cmpcode);
 9806   %}
 9807 
 9808   ins_pipe(icond_reg);
 9809 %}
 9810 
 9811 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9812   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9813 
 9814   ins_cost(INSN_COST * 2);
 9815   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9816 
 9817   ins_encode %{
 9818     __ csel(as_Register($dst$$reg),
 9819             as_Register($src$$reg),
 9820             zr,
 9821             (Assembler::Condition)$cmp$$cmpcode);
 9822   %}
 9823 
 9824   ins_pipe(icond_reg);
 9825 %}
 9826 
 9827 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9828   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9829 
 9830   ins_cost(INSN_COST * 2);
 9831   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9832 
 9833   ins_encode %{
 9834     __ csel(as_Register($dst$$reg),
 9835             as_Register($src2$$reg),
 9836             as_Register($src1$$reg),
 9837             (Assembler::Condition)$cmp$$cmpcode);
 9838   %}
 9839 
 9840   ins_pipe(icond_reg_reg);
 9841 %}
 9842 
 9843 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9844   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9845 
 9846   ins_cost(INSN_COST * 2);
 9847   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9848 
 9849   ins_encode %{
 9850     __ csel(as_Register($dst$$reg),
 9851             as_Register($src2$$reg),
 9852             as_Register($src1$$reg),
 9853             (Assembler::Condition)$cmp$$cmpcode);
 9854   %}
 9855 
 9856   ins_pipe(icond_reg_reg);
 9857 %}
 9858 
 9859 // special cases where one arg is zero
 9860 
 9861 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9862   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9863 
 9864   ins_cost(INSN_COST * 2);
 9865   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9866 
 9867   ins_encode %{
 9868     __ csel(as_Register($dst$$reg),
 9869             zr,
 9870             as_Register($src$$reg),
 9871             (Assembler::Condition)$cmp$$cmpcode);
 9872   %}
 9873 
 9874   ins_pipe(icond_reg);
 9875 %}
 9876 
 9877 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9878   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9879 
 9880   ins_cost(INSN_COST * 2);
 9881   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9882 
 9883   ins_encode %{
 9884     __ csel(as_Register($dst$$reg),
 9885             zr,
 9886             as_Register($src$$reg),
 9887             (Assembler::Condition)$cmp$$cmpcode);
 9888   %}
 9889 
 9890   ins_pipe(icond_reg);
 9891 %}
 9892 
 9893 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9894   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9895 
 9896   ins_cost(INSN_COST * 2);
 9897   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9898 
 9899   ins_encode %{
 9900     __ csel(as_Register($dst$$reg),
 9901             as_Register($src$$reg),
 9902             zr,
 9903             (Assembler::Condition)$cmp$$cmpcode);
 9904   %}
 9905 
 9906   ins_pipe(icond_reg);
 9907 %}
 9908 
 9909 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9910   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9911 
 9912   ins_cost(INSN_COST * 2);
 9913   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9914 
 9915   ins_encode %{
 9916     __ csel(as_Register($dst$$reg),
 9917             as_Register($src$$reg),
 9918             zr,
 9919             (Assembler::Condition)$cmp$$cmpcode);
 9920   %}
 9921 
 9922   ins_pipe(icond_reg);
 9923 %}
 9924 
 9925 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9926   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9927 
 9928   ins_cost(INSN_COST * 2);
 9929   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9930 
 9931   ins_encode %{
 9932     __ cselw(as_Register($dst$$reg),
 9933              as_Register($src2$$reg),
 9934              as_Register($src1$$reg),
 9935              (Assembler::Condition)$cmp$$cmpcode);
 9936   %}
 9937 
 9938   ins_pipe(icond_reg_reg);
 9939 %}
 9940 
 9941 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9942   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9943 
 9944   ins_cost(INSN_COST * 2);
 9945   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9946 
 9947   ins_encode %{
 9948     __ cselw(as_Register($dst$$reg),
 9949              as_Register($src2$$reg),
 9950              as_Register($src1$$reg),
 9951              (Assembler::Condition)$cmp$$cmpcode);
 9952   %}
 9953 
 9954   ins_pipe(icond_reg_reg);
 9955 %}
 9956 
 9957 // special cases where one arg is zero
 9958 
 9959 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9960   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9961 
 9962   ins_cost(INSN_COST * 2);
 9963   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9964 
 9965   ins_encode %{
 9966     __ cselw(as_Register($dst$$reg),
 9967              zr,
 9968              as_Register($src$$reg),
 9969              (Assembler::Condition)$cmp$$cmpcode);
 9970   %}
 9971 
 9972   ins_pipe(icond_reg);
 9973 %}
 9974 
 9975 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9976   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9977 
 9978   ins_cost(INSN_COST * 2);
 9979   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9980 
 9981   ins_encode %{
 9982     __ cselw(as_Register($dst$$reg),
 9983              zr,
 9984              as_Register($src$$reg),
 9985              (Assembler::Condition)$cmp$$cmpcode);
 9986   %}
 9987 
 9988   ins_pipe(icond_reg);
 9989 %}
 9990 
 9991 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9992   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9993 
 9994   ins_cost(INSN_COST * 2);
 9995   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9996 
 9997   ins_encode %{
 9998     __ cselw(as_Register($dst$$reg),
 9999              as_Register($src$$reg),
10000              zr,
10001              (Assembler::Condition)$cmp$$cmpcode);
10002   %}
10003 
10004   ins_pipe(icond_reg);
10005 %}
10006 
10007 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10008   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10009 
10010   ins_cost(INSN_COST * 2);
10011   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10012 
10013   ins_encode %{
10014     __ cselw(as_Register($dst$$reg),
10015              as_Register($src$$reg),
10016              zr,
10017              (Assembler::Condition)$cmp$$cmpcode);
10018   %}
10019 
10020   ins_pipe(icond_reg);
10021 %}
10022 
10023 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10024 %{
10025   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10026 
10027   ins_cost(INSN_COST * 3);
10028 
10029   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10030   ins_encode %{
10031     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10032     __ fcsels(as_FloatRegister($dst$$reg),
10033               as_FloatRegister($src2$$reg),
10034               as_FloatRegister($src1$$reg),
10035               cond);
10036   %}
10037 
10038   ins_pipe(fp_cond_reg_reg_s);
10039 %}
10040 
10041 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10042 %{
10043   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10044 
10045   ins_cost(INSN_COST * 3);
10046 
10047   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10048   ins_encode %{
10049     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10050     __ fcsels(as_FloatRegister($dst$$reg),
10051               as_FloatRegister($src2$$reg),
10052               as_FloatRegister($src1$$reg),
10053               cond);
10054   %}
10055 
10056   ins_pipe(fp_cond_reg_reg_s);
10057 %}
10058 
10059 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10060 %{
10061   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10062 
10063   ins_cost(INSN_COST * 3);
10064 
10065   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10066   ins_encode %{
10067     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10068     __ fcseld(as_FloatRegister($dst$$reg),
10069               as_FloatRegister($src2$$reg),
10070               as_FloatRegister($src1$$reg),
10071               cond);
10072   %}
10073 
10074   ins_pipe(fp_cond_reg_reg_d);
10075 %}
10076 
10077 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10078 %{
10079   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10080 
10081   ins_cost(INSN_COST * 3);
10082 
10083   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10084   ins_encode %{
10085     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10086     __ fcseld(as_FloatRegister($dst$$reg),
10087               as_FloatRegister($src2$$reg),
10088               as_FloatRegister($src1$$reg),
10089               cond);
10090   %}
10091 
10092   ins_pipe(fp_cond_reg_reg_d);
10093 %}
10094 
10095 // ============================================================================
10096 // Arithmetic Instructions
10097 //
10098 
10099 // Integer Addition
10100 
10101 // TODO
10102 // these currently employ operations which do not set CR and hence are
10103 // not flagged as killing CR but we would like to isolate the cases
10104 // where we want to set flags from those where we don&#39;t. need to work
10105 // out how to do that.
10106 
10107 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10108   match(Set dst (AddI src1 src2));
10109 
10110   ins_cost(INSN_COST);
10111   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10112 
10113   ins_encode %{
10114     __ addw(as_Register($dst$$reg),
10115             as_Register($src1$$reg),
10116             as_Register($src2$$reg));
10117   %}
10118 
10119   ins_pipe(ialu_reg_reg);
10120 %}
10121 
10122 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10123   match(Set dst (AddI src1 src2));
10124 
10125   ins_cost(INSN_COST);
10126   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10127 
10128   // use opcode to indicate that this is an add not a sub
10129   opcode(0x0);
10130 
10131   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10132 
10133   ins_pipe(ialu_reg_imm);
10134 %}
10135 
10136 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10137   match(Set dst (AddI (ConvL2I src1) src2));
10138 
10139   ins_cost(INSN_COST);
10140   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10141 
10142   // use opcode to indicate that this is an add not a sub
10143   opcode(0x0);
10144 
10145   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10146 
10147   ins_pipe(ialu_reg_imm);
10148 %}
10149 
10150 // Pointer Addition
10151 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10152   match(Set dst (AddP src1 src2));
10153 
10154   ins_cost(INSN_COST);
10155   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10156 
10157   ins_encode %{
10158     __ add(as_Register($dst$$reg),
10159            as_Register($src1$$reg),
10160            as_Register($src2$$reg));
10161   %}
10162 
10163   ins_pipe(ialu_reg_reg);
10164 %}
10165 
10166 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10167   match(Set dst (AddP src1 (ConvI2L src2)));
10168 
10169   ins_cost(1.9 * INSN_COST);
10170   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10171 
10172   ins_encode %{
10173     __ add(as_Register($dst$$reg),
10174            as_Register($src1$$reg),
10175            as_Register($src2$$reg), ext::sxtw);
10176   %}
10177 
10178   ins_pipe(ialu_reg_reg);
10179 %}
10180 
10181 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10182   match(Set dst (AddP src1 (LShiftL src2 scale)));
10183 
10184   ins_cost(1.9 * INSN_COST);
10185   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10186 
10187   ins_encode %{
10188     __ lea(as_Register($dst$$reg),
10189            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10190                    Address::lsl($scale$$constant)));
10191   %}
10192 
10193   ins_pipe(ialu_reg_reg_shift);
10194 %}
10195 
10196 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10197   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10198 
10199   ins_cost(1.9 * INSN_COST);
10200   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10201 
10202   ins_encode %{
10203     __ lea(as_Register($dst$$reg),
10204            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10205                    Address::sxtw($scale$$constant)));
10206   %}
10207 
10208   ins_pipe(ialu_reg_reg_shift);
10209 %}
10210 
10211 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10212   match(Set dst (LShiftL (ConvI2L src) scale));
10213 
10214   ins_cost(INSN_COST);
10215   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10216 
10217   ins_encode %{
10218     __ sbfiz(as_Register($dst$$reg),
10219           as_Register($src$$reg),
10220           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10221   %}
10222 
10223   ins_pipe(ialu_reg_shift);
10224 %}
10225 
10226 // Pointer Immediate Addition
10227 // n.b. this needs to be more expensive than using an indirect memory
10228 // operand
10229 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10230   match(Set dst (AddP src1 src2));
10231 
10232   ins_cost(INSN_COST);
10233   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10234 
10235   // use opcode to indicate that this is an add not a sub
10236   opcode(0x0);
10237 
10238   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10239 
10240   ins_pipe(ialu_reg_imm);
10241 %}
10242 
10243 // Long Addition
10244 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10245 
10246   match(Set dst (AddL src1 src2));
10247 
10248   ins_cost(INSN_COST);
10249   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10250 
10251   ins_encode %{
10252     __ add(as_Register($dst$$reg),
10253            as_Register($src1$$reg),
10254            as_Register($src2$$reg));
10255   %}
10256 
10257   ins_pipe(ialu_reg_reg);
10258 %}
10259 
10260 // No constant pool entries requiredLong Immediate Addition.
10261 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10262   match(Set dst (AddL src1 src2));
10263 
10264   ins_cost(INSN_COST);
10265   format %{ &quot;add $dst, $src1, $src2&quot; %}
10266 
10267   // use opcode to indicate that this is an add not a sub
10268   opcode(0x0);
10269 
10270   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10271 
10272   ins_pipe(ialu_reg_imm);
10273 %}
10274 
10275 // Integer Subtraction
10276 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10277   match(Set dst (SubI src1 src2));
10278 
10279   ins_cost(INSN_COST);
10280   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10281 
10282   ins_encode %{
10283     __ subw(as_Register($dst$$reg),
10284             as_Register($src1$$reg),
10285             as_Register($src2$$reg));
10286   %}
10287 
10288   ins_pipe(ialu_reg_reg);
10289 %}
10290 
10291 // Immediate Subtraction
10292 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10293   match(Set dst (SubI src1 src2));
10294 
10295   ins_cost(INSN_COST);
10296   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10297 
10298   // use opcode to indicate that this is a sub not an add
10299   opcode(0x1);
10300 
10301   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10302 
10303   ins_pipe(ialu_reg_imm);
10304 %}
10305 
10306 // Long Subtraction
10307 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10308 
10309   match(Set dst (SubL src1 src2));
10310 
10311   ins_cost(INSN_COST);
10312   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10313 
10314   ins_encode %{
10315     __ sub(as_Register($dst$$reg),
10316            as_Register($src1$$reg),
10317            as_Register($src2$$reg));
10318   %}
10319 
10320   ins_pipe(ialu_reg_reg);
10321 %}
10322 
10323 // No constant pool entries requiredLong Immediate Subtraction.
10324 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10325   match(Set dst (SubL src1 src2));
10326 
10327   ins_cost(INSN_COST);
10328   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10329 
10330   // use opcode to indicate that this is a sub not an add
10331   opcode(0x1);
10332 
10333   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10334 
10335   ins_pipe(ialu_reg_imm);
10336 %}
10337 
10338 // Integer Negation (special case for sub)
10339 
10340 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10341   match(Set dst (SubI zero src));
10342 
10343   ins_cost(INSN_COST);
10344   format %{ &quot;negw $dst, $src\t# int&quot; %}
10345 
10346   ins_encode %{
10347     __ negw(as_Register($dst$$reg),
10348             as_Register($src$$reg));
10349   %}
10350 
10351   ins_pipe(ialu_reg);
10352 %}
10353 
10354 // Long Negation
10355 
10356 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10357   match(Set dst (SubL zero src));
10358 
10359   ins_cost(INSN_COST);
10360   format %{ &quot;neg $dst, $src\t# long&quot; %}
10361 
10362   ins_encode %{
10363     __ neg(as_Register($dst$$reg),
10364            as_Register($src$$reg));
10365   %}
10366 
10367   ins_pipe(ialu_reg);
10368 %}
10369 
10370 // Integer Multiply
10371 
10372 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10373   match(Set dst (MulI src1 src2));
10374 
10375   ins_cost(INSN_COST * 3);
10376   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10377 
10378   ins_encode %{
10379     __ mulw(as_Register($dst$$reg),
10380             as_Register($src1$$reg),
10381             as_Register($src2$$reg));
10382   %}
10383 
10384   ins_pipe(imul_reg_reg);
10385 %}
10386 
10387 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10388   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10389 
10390   ins_cost(INSN_COST * 3);
10391   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10392 
10393   ins_encode %{
10394     __ smull(as_Register($dst$$reg),
10395              as_Register($src1$$reg),
10396              as_Register($src2$$reg));
10397   %}
10398 
10399   ins_pipe(imul_reg_reg);
10400 %}
10401 
10402 // Long Multiply
10403 
10404 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10405   match(Set dst (MulL src1 src2));
10406 
10407   ins_cost(INSN_COST * 5);
10408   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10409 
10410   ins_encode %{
10411     __ mul(as_Register($dst$$reg),
10412            as_Register($src1$$reg),
10413            as_Register($src2$$reg));
10414   %}
10415 
10416   ins_pipe(lmul_reg_reg);
10417 %}
10418 
10419 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10420 %{
10421   match(Set dst (MulHiL src1 src2));
10422 
10423   ins_cost(INSN_COST * 7);
10424   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10425 
10426   ins_encode %{
10427     __ smulh(as_Register($dst$$reg),
10428              as_Register($src1$$reg),
10429              as_Register($src2$$reg));
10430   %}
10431 
10432   ins_pipe(lmul_reg_reg);
10433 %}
10434 
10435 // Combined Integer Multiply &amp; Add/Sub
10436 
10437 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10438   match(Set dst (AddI src3 (MulI src1 src2)));
10439 
10440   ins_cost(INSN_COST * 3);
10441   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10442 
10443   ins_encode %{
10444     __ maddw(as_Register($dst$$reg),
10445              as_Register($src1$$reg),
10446              as_Register($src2$$reg),
10447              as_Register($src3$$reg));
10448   %}
10449 
10450   ins_pipe(imac_reg_reg);
10451 %}
10452 
10453 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10454   match(Set dst (SubI src3 (MulI src1 src2)));
10455 
10456   ins_cost(INSN_COST * 3);
10457   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10458 
10459   ins_encode %{
10460     __ msubw(as_Register($dst$$reg),
10461              as_Register($src1$$reg),
10462              as_Register($src2$$reg),
10463              as_Register($src3$$reg));
10464   %}
10465 
10466   ins_pipe(imac_reg_reg);
10467 %}
10468 
10469 // Combined Integer Multiply &amp; Neg
10470 
10471 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10472   match(Set dst (MulI (SubI zero src1) src2));
10473   match(Set dst (MulI src1 (SubI zero src2)));
10474 
10475   ins_cost(INSN_COST * 3);
10476   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10477 
10478   ins_encode %{
10479     __ mnegw(as_Register($dst$$reg),
10480              as_Register($src1$$reg),
10481              as_Register($src2$$reg));
10482   %}
10483 
10484   ins_pipe(imac_reg_reg);
10485 %}
10486 
10487 // Combined Long Multiply &amp; Add/Sub
10488 
10489 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10490   match(Set dst (AddL src3 (MulL src1 src2)));
10491 
10492   ins_cost(INSN_COST * 5);
10493   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10494 
10495   ins_encode %{
10496     __ madd(as_Register($dst$$reg),
10497             as_Register($src1$$reg),
10498             as_Register($src2$$reg),
10499             as_Register($src3$$reg));
10500   %}
10501 
10502   ins_pipe(lmac_reg_reg);
10503 %}
10504 
10505 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10506   match(Set dst (SubL src3 (MulL src1 src2)));
10507 
10508   ins_cost(INSN_COST * 5);
10509   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10510 
10511   ins_encode %{
10512     __ msub(as_Register($dst$$reg),
10513             as_Register($src1$$reg),
10514             as_Register($src2$$reg),
10515             as_Register($src3$$reg));
10516   %}
10517 
10518   ins_pipe(lmac_reg_reg);
10519 %}
10520 
10521 // Combined Long Multiply &amp; Neg
10522 
10523 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10524   match(Set dst (MulL (SubL zero src1) src2));
10525   match(Set dst (MulL src1 (SubL zero src2)));
10526 
10527   ins_cost(INSN_COST * 5);
10528   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10529 
10530   ins_encode %{
10531     __ mneg(as_Register($dst$$reg),
10532             as_Register($src1$$reg),
10533             as_Register($src2$$reg));
10534   %}
10535 
10536   ins_pipe(lmac_reg_reg);
10537 %}
10538 
10539 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10540 
10541 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10542   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10543 
10544   ins_cost(INSN_COST * 3);
10545   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10546 
10547   ins_encode %{
10548     __ smaddl(as_Register($dst$$reg),
10549               as_Register($src1$$reg),
10550               as_Register($src2$$reg),
10551               as_Register($src3$$reg));
10552   %}
10553 
10554   ins_pipe(imac_reg_reg);
10555 %}
10556 
10557 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10558   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10559 
10560   ins_cost(INSN_COST * 3);
10561   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10562 
10563   ins_encode %{
10564     __ smsubl(as_Register($dst$$reg),
10565               as_Register($src1$$reg),
10566               as_Register($src2$$reg),
10567               as_Register($src3$$reg));
10568   %}
10569 
10570   ins_pipe(imac_reg_reg);
10571 %}
10572 
10573 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10574   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10575   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10576 
10577   ins_cost(INSN_COST * 3);
10578   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10579 
10580   ins_encode %{
10581     __ smnegl(as_Register($dst$$reg),
10582               as_Register($src1$$reg),
10583               as_Register($src2$$reg));
10584   %}
10585 
10586   ins_pipe(imac_reg_reg);
10587 %}
10588 
10589 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10590 
10591 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10592   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10593 
10594   ins_cost(INSN_COST * 5);
10595   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10596             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10597 
10598   ins_encode %{
10599     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10600     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10601 
10602   ins_pipe(imac_reg_reg);
10603 %}
10604 
10605 // Integer Divide
10606 
10607 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10608   match(Set dst (DivI src1 src2));
10609 
10610   ins_cost(INSN_COST * 19);
10611   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10612 
10613   ins_encode(aarch64_enc_divw(dst, src1, src2));
10614   ins_pipe(idiv_reg_reg);
10615 %}
10616 
10617 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10618   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10619   ins_cost(INSN_COST);
10620   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10621   ins_encode %{
10622     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10623   %}
10624   ins_pipe(ialu_reg_shift);
10625 %}
10626 
10627 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10628   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10629   ins_cost(INSN_COST);
10630   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10631 
10632   ins_encode %{
10633     __ addw(as_Register($dst$$reg),
10634               as_Register($src$$reg),
10635               as_Register($src$$reg),
10636               Assembler::LSR, 31);
10637   %}
10638   ins_pipe(ialu_reg);
10639 %}
10640 
10641 // Long Divide
10642 
10643 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10644   match(Set dst (DivL src1 src2));
10645 
10646   ins_cost(INSN_COST * 35);
10647   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10648 
10649   ins_encode(aarch64_enc_div(dst, src1, src2));
10650   ins_pipe(ldiv_reg_reg);
10651 %}
10652 
10653 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10654   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10655   ins_cost(INSN_COST);
10656   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10657   ins_encode %{
10658     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10659   %}
10660   ins_pipe(ialu_reg_shift);
10661 %}
10662 
10663 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10664   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10665   ins_cost(INSN_COST);
10666   format %{ &quot;add $dst, $src, $div1&quot; %}
10667 
10668   ins_encode %{
10669     __ add(as_Register($dst$$reg),
10670               as_Register($src$$reg),
10671               as_Register($src$$reg),
10672               Assembler::LSR, 63);
10673   %}
10674   ins_pipe(ialu_reg);
10675 %}
10676 
10677 // Integer Remainder
10678 
10679 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10680   match(Set dst (ModI src1 src2));
10681 
10682   ins_cost(INSN_COST * 22);
10683   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10684             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10685 
10686   ins_encode(aarch64_enc_modw(dst, src1, src2));
10687   ins_pipe(idiv_reg_reg);
10688 %}
10689 
10690 // Long Remainder
10691 
10692 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10693   match(Set dst (ModL src1 src2));
10694 
10695   ins_cost(INSN_COST * 38);
10696   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10697             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10698 
10699   ins_encode(aarch64_enc_mod(dst, src1, src2));
10700   ins_pipe(ldiv_reg_reg);
10701 %}
10702 
10703 // Integer Shifts
10704 
10705 // Shift Left Register
10706 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10707   match(Set dst (LShiftI src1 src2));
10708 
10709   ins_cost(INSN_COST * 2);
10710   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10711 
10712   ins_encode %{
10713     __ lslvw(as_Register($dst$$reg),
10714              as_Register($src1$$reg),
10715              as_Register($src2$$reg));
10716   %}
10717 
10718   ins_pipe(ialu_reg_reg_vshift);
10719 %}
10720 
10721 // Shift Left Immediate
10722 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10723   match(Set dst (LShiftI src1 src2));
10724 
10725   ins_cost(INSN_COST);
10726   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10727 
10728   ins_encode %{
10729     __ lslw(as_Register($dst$$reg),
10730             as_Register($src1$$reg),
10731             $src2$$constant &amp; 0x1f);
10732   %}
10733 
10734   ins_pipe(ialu_reg_shift);
10735 %}
10736 
10737 // Shift Right Logical Register
10738 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10739   match(Set dst (URShiftI src1 src2));
10740 
10741   ins_cost(INSN_COST * 2);
10742   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10743 
10744   ins_encode %{
10745     __ lsrvw(as_Register($dst$$reg),
10746              as_Register($src1$$reg),
10747              as_Register($src2$$reg));
10748   %}
10749 
10750   ins_pipe(ialu_reg_reg_vshift);
10751 %}
10752 
10753 // Shift Right Logical Immediate
10754 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10755   match(Set dst (URShiftI src1 src2));
10756 
10757   ins_cost(INSN_COST);
10758   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10759 
10760   ins_encode %{
10761     __ lsrw(as_Register($dst$$reg),
10762             as_Register($src1$$reg),
10763             $src2$$constant &amp; 0x1f);
10764   %}
10765 
10766   ins_pipe(ialu_reg_shift);
10767 %}
10768 
10769 // Shift Right Arithmetic Register
10770 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10771   match(Set dst (RShiftI src1 src2));
10772 
10773   ins_cost(INSN_COST * 2);
10774   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10775 
10776   ins_encode %{
10777     __ asrvw(as_Register($dst$$reg),
10778              as_Register($src1$$reg),
10779              as_Register($src2$$reg));
10780   %}
10781 
10782   ins_pipe(ialu_reg_reg_vshift);
10783 %}
10784 
10785 // Shift Right Arithmetic Immediate
10786 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10787   match(Set dst (RShiftI src1 src2));
10788 
10789   ins_cost(INSN_COST);
10790   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10791 
10792   ins_encode %{
10793     __ asrw(as_Register($dst$$reg),
10794             as_Register($src1$$reg),
10795             $src2$$constant &amp; 0x1f);
10796   %}
10797 
10798   ins_pipe(ialu_reg_shift);
10799 %}
10800 
10801 // Combined Int Mask and Right Shift (using UBFM)
10802 // TODO
10803 
10804 // Long Shifts
10805 
10806 // Shift Left Register
10807 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10808   match(Set dst (LShiftL src1 src2));
10809 
10810   ins_cost(INSN_COST * 2);
10811   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10812 
10813   ins_encode %{
10814     __ lslv(as_Register($dst$$reg),
10815             as_Register($src1$$reg),
10816             as_Register($src2$$reg));
10817   %}
10818 
10819   ins_pipe(ialu_reg_reg_vshift);
10820 %}
10821 
10822 // Shift Left Immediate
10823 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10824   match(Set dst (LShiftL src1 src2));
10825 
10826   ins_cost(INSN_COST);
10827   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10828 
10829   ins_encode %{
10830     __ lsl(as_Register($dst$$reg),
10831             as_Register($src1$$reg),
10832             $src2$$constant &amp; 0x3f);
10833   %}
10834 
10835   ins_pipe(ialu_reg_shift);
10836 %}
10837 
10838 // Shift Right Logical Register
10839 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10840   match(Set dst (URShiftL src1 src2));
10841 
10842   ins_cost(INSN_COST * 2);
10843   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10844 
10845   ins_encode %{
10846     __ lsrv(as_Register($dst$$reg),
10847             as_Register($src1$$reg),
10848             as_Register($src2$$reg));
10849   %}
10850 
10851   ins_pipe(ialu_reg_reg_vshift);
10852 %}
10853 
10854 // Shift Right Logical Immediate
10855 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10856   match(Set dst (URShiftL src1 src2));
10857 
10858   ins_cost(INSN_COST);
10859   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10860 
10861   ins_encode %{
10862     __ lsr(as_Register($dst$$reg),
10863            as_Register($src1$$reg),
10864            $src2$$constant &amp; 0x3f);
10865   %}
10866 
10867   ins_pipe(ialu_reg_shift);
10868 %}
10869 
10870 // A special-case pattern for card table stores.
10871 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10872   match(Set dst (URShiftL (CastP2X src1) src2));
10873 
10874   ins_cost(INSN_COST);
10875   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10876 
10877   ins_encode %{
10878     __ lsr(as_Register($dst$$reg),
10879            as_Register($src1$$reg),
10880            $src2$$constant &amp; 0x3f);
10881   %}
10882 
10883   ins_pipe(ialu_reg_shift);
10884 %}
10885 
10886 // Shift Right Arithmetic Register
10887 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10888   match(Set dst (RShiftL src1 src2));
10889 
10890   ins_cost(INSN_COST * 2);
10891   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10892 
10893   ins_encode %{
10894     __ asrv(as_Register($dst$$reg),
10895             as_Register($src1$$reg),
10896             as_Register($src2$$reg));
10897   %}
10898 
10899   ins_pipe(ialu_reg_reg_vshift);
10900 %}
10901 
10902 // Shift Right Arithmetic Immediate
10903 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10904   match(Set dst (RShiftL src1 src2));
10905 
10906   ins_cost(INSN_COST);
10907   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10908 
10909   ins_encode %{
10910     __ asr(as_Register($dst$$reg),
10911            as_Register($src1$$reg),
10912            $src2$$constant &amp; 0x3f);
10913   %}
10914 
10915   ins_pipe(ialu_reg_shift);
10916 %}
10917 
10918 // BEGIN This section of the file is automatically generated. Do not edit --------------
10919 
10920 instruct regL_not_reg(iRegLNoSp dst,
10921                          iRegL src1, immL_M1 m1,
10922                          rFlagsReg cr) %{
10923   match(Set dst (XorL src1 m1));
10924   ins_cost(INSN_COST);
10925   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10926 
10927   ins_encode %{
10928     __ eon(as_Register($dst$$reg),
10929               as_Register($src1$$reg),
10930               zr,
10931               Assembler::LSL, 0);
10932   %}
10933 
10934   ins_pipe(ialu_reg);
10935 %}
10936 instruct regI_not_reg(iRegINoSp dst,
10937                          iRegIorL2I src1, immI_M1 m1,
10938                          rFlagsReg cr) %{
10939   match(Set dst (XorI src1 m1));
10940   ins_cost(INSN_COST);
10941   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10942 
10943   ins_encode %{
10944     __ eonw(as_Register($dst$$reg),
10945               as_Register($src1$$reg),
10946               zr,
10947               Assembler::LSL, 0);
10948   %}
10949 
10950   ins_pipe(ialu_reg);
10951 %}
10952 
10953 instruct AndI_reg_not_reg(iRegINoSp dst,
10954                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10955                          rFlagsReg cr) %{
10956   match(Set dst (AndI src1 (XorI src2 m1)));
10957   ins_cost(INSN_COST);
10958   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10959 
10960   ins_encode %{
10961     __ bicw(as_Register($dst$$reg),
10962               as_Register($src1$$reg),
10963               as_Register($src2$$reg),
10964               Assembler::LSL, 0);
10965   %}
10966 
10967   ins_pipe(ialu_reg_reg);
10968 %}
10969 
10970 instruct AndL_reg_not_reg(iRegLNoSp dst,
10971                          iRegL src1, iRegL src2, immL_M1 m1,
10972                          rFlagsReg cr) %{
10973   match(Set dst (AndL src1 (XorL src2 m1)));
10974   ins_cost(INSN_COST);
10975   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10976 
10977   ins_encode %{
10978     __ bic(as_Register($dst$$reg),
10979               as_Register($src1$$reg),
10980               as_Register($src2$$reg),
10981               Assembler::LSL, 0);
10982   %}
10983 
10984   ins_pipe(ialu_reg_reg);
10985 %}
10986 
10987 instruct OrI_reg_not_reg(iRegINoSp dst,
10988                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10989                          rFlagsReg cr) %{
10990   match(Set dst (OrI src1 (XorI src2 m1)));
10991   ins_cost(INSN_COST);
10992   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10993 
10994   ins_encode %{
10995     __ ornw(as_Register($dst$$reg),
10996               as_Register($src1$$reg),
10997               as_Register($src2$$reg),
10998               Assembler::LSL, 0);
10999   %}
11000 
11001   ins_pipe(ialu_reg_reg);
11002 %}
11003 
11004 instruct OrL_reg_not_reg(iRegLNoSp dst,
11005                          iRegL src1, iRegL src2, immL_M1 m1,
11006                          rFlagsReg cr) %{
11007   match(Set dst (OrL src1 (XorL src2 m1)));
11008   ins_cost(INSN_COST);
11009   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
11010 
11011   ins_encode %{
11012     __ orn(as_Register($dst$$reg),
11013               as_Register($src1$$reg),
11014               as_Register($src2$$reg),
11015               Assembler::LSL, 0);
11016   %}
11017 
11018   ins_pipe(ialu_reg_reg);
11019 %}
11020 
11021 instruct XorI_reg_not_reg(iRegINoSp dst,
11022                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11023                          rFlagsReg cr) %{
11024   match(Set dst (XorI m1 (XorI src2 src1)));
11025   ins_cost(INSN_COST);
11026   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
11027 
11028   ins_encode %{
11029     __ eonw(as_Register($dst$$reg),
11030               as_Register($src1$$reg),
11031               as_Register($src2$$reg),
11032               Assembler::LSL, 0);
11033   %}
11034 
11035   ins_pipe(ialu_reg_reg);
11036 %}
11037 
11038 instruct XorL_reg_not_reg(iRegLNoSp dst,
11039                          iRegL src1, iRegL src2, immL_M1 m1,
11040                          rFlagsReg cr) %{
11041   match(Set dst (XorL m1 (XorL src2 src1)));
11042   ins_cost(INSN_COST);
11043   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11044 
11045   ins_encode %{
11046     __ eon(as_Register($dst$$reg),
11047               as_Register($src1$$reg),
11048               as_Register($src2$$reg),
11049               Assembler::LSL, 0);
11050   %}
11051 
11052   ins_pipe(ialu_reg_reg);
11053 %}
11054 
11055 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11056                          iRegIorL2I src1, iRegIorL2I src2,
11057                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11058   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11059   ins_cost(1.9 * INSN_COST);
11060   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11061 
11062   ins_encode %{
11063     __ bicw(as_Register($dst$$reg),
11064               as_Register($src1$$reg),
11065               as_Register($src2$$reg),
11066               Assembler::LSR,
11067               $src3$$constant &amp; 0x1f);
11068   %}
11069 
11070   ins_pipe(ialu_reg_reg_shift);
11071 %}
11072 
11073 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11074                          iRegL src1, iRegL src2,
11075                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11076   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11077   ins_cost(1.9 * INSN_COST);
11078   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11079 
11080   ins_encode %{
11081     __ bic(as_Register($dst$$reg),
11082               as_Register($src1$$reg),
11083               as_Register($src2$$reg),
11084               Assembler::LSR,
11085               $src3$$constant &amp; 0x3f);
11086   %}
11087 
11088   ins_pipe(ialu_reg_reg_shift);
11089 %}
11090 
11091 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11092                          iRegIorL2I src1, iRegIorL2I src2,
11093                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11094   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11095   ins_cost(1.9 * INSN_COST);
11096   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11097 
11098   ins_encode %{
11099     __ bicw(as_Register($dst$$reg),
11100               as_Register($src1$$reg),
11101               as_Register($src2$$reg),
11102               Assembler::ASR,
11103               $src3$$constant &amp; 0x1f);
11104   %}
11105 
11106   ins_pipe(ialu_reg_reg_shift);
11107 %}
11108 
11109 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11110                          iRegL src1, iRegL src2,
11111                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11112   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11113   ins_cost(1.9 * INSN_COST);
11114   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11115 
11116   ins_encode %{
11117     __ bic(as_Register($dst$$reg),
11118               as_Register($src1$$reg),
11119               as_Register($src2$$reg),
11120               Assembler::ASR,
11121               $src3$$constant &amp; 0x3f);
11122   %}
11123 
11124   ins_pipe(ialu_reg_reg_shift);
11125 %}
11126 
11127 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11128                          iRegIorL2I src1, iRegIorL2I src2,
11129                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11130   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11131   ins_cost(1.9 * INSN_COST);
11132   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11133 
11134   ins_encode %{
11135     __ bicw(as_Register($dst$$reg),
11136               as_Register($src1$$reg),
11137               as_Register($src2$$reg),
11138               Assembler::LSL,
11139               $src3$$constant &amp; 0x1f);
11140   %}
11141 
11142   ins_pipe(ialu_reg_reg_shift);
11143 %}
11144 
11145 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11146                          iRegL src1, iRegL src2,
11147                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11148   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11149   ins_cost(1.9 * INSN_COST);
11150   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11151 
11152   ins_encode %{
11153     __ bic(as_Register($dst$$reg),
11154               as_Register($src1$$reg),
11155               as_Register($src2$$reg),
11156               Assembler::LSL,
11157               $src3$$constant &amp; 0x3f);
11158   %}
11159 
11160   ins_pipe(ialu_reg_reg_shift);
11161 %}
11162 
11163 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11164                          iRegIorL2I src1, iRegIorL2I src2,
11165                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11166   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11167   ins_cost(1.9 * INSN_COST);
11168   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11169 
11170   ins_encode %{
11171     __ eonw(as_Register($dst$$reg),
11172               as_Register($src1$$reg),
11173               as_Register($src2$$reg),
11174               Assembler::LSR,
11175               $src3$$constant &amp; 0x1f);
11176   %}
11177 
11178   ins_pipe(ialu_reg_reg_shift);
11179 %}
11180 
11181 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11182                          iRegL src1, iRegL src2,
11183                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11184   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11185   ins_cost(1.9 * INSN_COST);
11186   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11187 
11188   ins_encode %{
11189     __ eon(as_Register($dst$$reg),
11190               as_Register($src1$$reg),
11191               as_Register($src2$$reg),
11192               Assembler::LSR,
11193               $src3$$constant &amp; 0x3f);
11194   %}
11195 
11196   ins_pipe(ialu_reg_reg_shift);
11197 %}
11198 
11199 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11200                          iRegIorL2I src1, iRegIorL2I src2,
11201                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11202   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11203   ins_cost(1.9 * INSN_COST);
11204   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11205 
11206   ins_encode %{
11207     __ eonw(as_Register($dst$$reg),
11208               as_Register($src1$$reg),
11209               as_Register($src2$$reg),
11210               Assembler::ASR,
11211               $src3$$constant &amp; 0x1f);
11212   %}
11213 
11214   ins_pipe(ialu_reg_reg_shift);
11215 %}
11216 
11217 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11218                          iRegL src1, iRegL src2,
11219                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11220   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11221   ins_cost(1.9 * INSN_COST);
11222   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11223 
11224   ins_encode %{
11225     __ eon(as_Register($dst$$reg),
11226               as_Register($src1$$reg),
11227               as_Register($src2$$reg),
11228               Assembler::ASR,
11229               $src3$$constant &amp; 0x3f);
11230   %}
11231 
11232   ins_pipe(ialu_reg_reg_shift);
11233 %}
11234 
11235 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11236                          iRegIorL2I src1, iRegIorL2I src2,
11237                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11238   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11239   ins_cost(1.9 * INSN_COST);
11240   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11241 
11242   ins_encode %{
11243     __ eonw(as_Register($dst$$reg),
11244               as_Register($src1$$reg),
11245               as_Register($src2$$reg),
11246               Assembler::LSL,
11247               $src3$$constant &amp; 0x1f);
11248   %}
11249 
11250   ins_pipe(ialu_reg_reg_shift);
11251 %}
11252 
11253 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11254                          iRegL src1, iRegL src2,
11255                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11256   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11257   ins_cost(1.9 * INSN_COST);
11258   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11259 
11260   ins_encode %{
11261     __ eon(as_Register($dst$$reg),
11262               as_Register($src1$$reg),
11263               as_Register($src2$$reg),
11264               Assembler::LSL,
11265               $src3$$constant &amp; 0x3f);
11266   %}
11267 
11268   ins_pipe(ialu_reg_reg_shift);
11269 %}
11270 
11271 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11272                          iRegIorL2I src1, iRegIorL2I src2,
11273                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11274   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11275   ins_cost(1.9 * INSN_COST);
11276   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11277 
11278   ins_encode %{
11279     __ ornw(as_Register($dst$$reg),
11280               as_Register($src1$$reg),
11281               as_Register($src2$$reg),
11282               Assembler::LSR,
11283               $src3$$constant &amp; 0x1f);
11284   %}
11285 
11286   ins_pipe(ialu_reg_reg_shift);
11287 %}
11288 
11289 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11290                          iRegL src1, iRegL src2,
11291                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11292   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11293   ins_cost(1.9 * INSN_COST);
11294   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11295 
11296   ins_encode %{
11297     __ orn(as_Register($dst$$reg),
11298               as_Register($src1$$reg),
11299               as_Register($src2$$reg),
11300               Assembler::LSR,
11301               $src3$$constant &amp; 0x3f);
11302   %}
11303 
11304   ins_pipe(ialu_reg_reg_shift);
11305 %}
11306 
11307 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11308                          iRegIorL2I src1, iRegIorL2I src2,
11309                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11310   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11311   ins_cost(1.9 * INSN_COST);
11312   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11313 
11314   ins_encode %{
11315     __ ornw(as_Register($dst$$reg),
11316               as_Register($src1$$reg),
11317               as_Register($src2$$reg),
11318               Assembler::ASR,
11319               $src3$$constant &amp; 0x1f);
11320   %}
11321 
11322   ins_pipe(ialu_reg_reg_shift);
11323 %}
11324 
11325 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11326                          iRegL src1, iRegL src2,
11327                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11328   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11329   ins_cost(1.9 * INSN_COST);
11330   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11331 
11332   ins_encode %{
11333     __ orn(as_Register($dst$$reg),
11334               as_Register($src1$$reg),
11335               as_Register($src2$$reg),
11336               Assembler::ASR,
11337               $src3$$constant &amp; 0x3f);
11338   %}
11339 
11340   ins_pipe(ialu_reg_reg_shift);
11341 %}
11342 
11343 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11344                          iRegIorL2I src1, iRegIorL2I src2,
11345                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11346   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11347   ins_cost(1.9 * INSN_COST);
11348   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11349 
11350   ins_encode %{
11351     __ ornw(as_Register($dst$$reg),
11352               as_Register($src1$$reg),
11353               as_Register($src2$$reg),
11354               Assembler::LSL,
11355               $src3$$constant &amp; 0x1f);
11356   %}
11357 
11358   ins_pipe(ialu_reg_reg_shift);
11359 %}
11360 
11361 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11362                          iRegL src1, iRegL src2,
11363                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11364   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11365   ins_cost(1.9 * INSN_COST);
11366   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11367 
11368   ins_encode %{
11369     __ orn(as_Register($dst$$reg),
11370               as_Register($src1$$reg),
11371               as_Register($src2$$reg),
11372               Assembler::LSL,
11373               $src3$$constant &amp; 0x3f);
11374   %}
11375 
11376   ins_pipe(ialu_reg_reg_shift);
11377 %}
11378 
11379 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11380                          iRegIorL2I src1, iRegIorL2I src2,
11381                          immI src3, rFlagsReg cr) %{
11382   match(Set dst (AndI src1 (URShiftI src2 src3)));
11383 
11384   ins_cost(1.9 * INSN_COST);
11385   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11386 
11387   ins_encode %{
11388     __ andw(as_Register($dst$$reg),
11389               as_Register($src1$$reg),
11390               as_Register($src2$$reg),
11391               Assembler::LSR,
11392               $src3$$constant &amp; 0x1f);
11393   %}
11394 
11395   ins_pipe(ialu_reg_reg_shift);
11396 %}
11397 
11398 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11399                          iRegL src1, iRegL src2,
11400                          immI src3, rFlagsReg cr) %{
11401   match(Set dst (AndL src1 (URShiftL src2 src3)));
11402 
11403   ins_cost(1.9 * INSN_COST);
11404   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11405 
11406   ins_encode %{
11407     __ andr(as_Register($dst$$reg),
11408               as_Register($src1$$reg),
11409               as_Register($src2$$reg),
11410               Assembler::LSR,
11411               $src3$$constant &amp; 0x3f);
11412   %}
11413 
11414   ins_pipe(ialu_reg_reg_shift);
11415 %}
11416 
11417 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11418                          iRegIorL2I src1, iRegIorL2I src2,
11419                          immI src3, rFlagsReg cr) %{
11420   match(Set dst (AndI src1 (RShiftI src2 src3)));
11421 
11422   ins_cost(1.9 * INSN_COST);
11423   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11424 
11425   ins_encode %{
11426     __ andw(as_Register($dst$$reg),
11427               as_Register($src1$$reg),
11428               as_Register($src2$$reg),
11429               Assembler::ASR,
11430               $src3$$constant &amp; 0x1f);
11431   %}
11432 
11433   ins_pipe(ialu_reg_reg_shift);
11434 %}
11435 
11436 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11437                          iRegL src1, iRegL src2,
11438                          immI src3, rFlagsReg cr) %{
11439   match(Set dst (AndL src1 (RShiftL src2 src3)));
11440 
11441   ins_cost(1.9 * INSN_COST);
11442   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11443 
11444   ins_encode %{
11445     __ andr(as_Register($dst$$reg),
11446               as_Register($src1$$reg),
11447               as_Register($src2$$reg),
11448               Assembler::ASR,
11449               $src3$$constant &amp; 0x3f);
11450   %}
11451 
11452   ins_pipe(ialu_reg_reg_shift);
11453 %}
11454 
11455 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11456                          iRegIorL2I src1, iRegIorL2I src2,
11457                          immI src3, rFlagsReg cr) %{
11458   match(Set dst (AndI src1 (LShiftI src2 src3)));
11459 
11460   ins_cost(1.9 * INSN_COST);
11461   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11462 
11463   ins_encode %{
11464     __ andw(as_Register($dst$$reg),
11465               as_Register($src1$$reg),
11466               as_Register($src2$$reg),
11467               Assembler::LSL,
11468               $src3$$constant &amp; 0x1f);
11469   %}
11470 
11471   ins_pipe(ialu_reg_reg_shift);
11472 %}
11473 
11474 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11475                          iRegL src1, iRegL src2,
11476                          immI src3, rFlagsReg cr) %{
11477   match(Set dst (AndL src1 (LShiftL src2 src3)));
11478 
11479   ins_cost(1.9 * INSN_COST);
11480   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11481 
11482   ins_encode %{
11483     __ andr(as_Register($dst$$reg),
11484               as_Register($src1$$reg),
11485               as_Register($src2$$reg),
11486               Assembler::LSL,
11487               $src3$$constant &amp; 0x3f);
11488   %}
11489 
11490   ins_pipe(ialu_reg_reg_shift);
11491 %}
11492 
11493 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11494                          iRegIorL2I src1, iRegIorL2I src2,
11495                          immI src3, rFlagsReg cr) %{
11496   match(Set dst (XorI src1 (URShiftI src2 src3)));
11497 
11498   ins_cost(1.9 * INSN_COST);
11499   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11500 
11501   ins_encode %{
11502     __ eorw(as_Register($dst$$reg),
11503               as_Register($src1$$reg),
11504               as_Register($src2$$reg),
11505               Assembler::LSR,
11506               $src3$$constant &amp; 0x1f);
11507   %}
11508 
11509   ins_pipe(ialu_reg_reg_shift);
11510 %}
11511 
11512 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11513                          iRegL src1, iRegL src2,
11514                          immI src3, rFlagsReg cr) %{
11515   match(Set dst (XorL src1 (URShiftL src2 src3)));
11516 
11517   ins_cost(1.9 * INSN_COST);
11518   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11519 
11520   ins_encode %{
11521     __ eor(as_Register($dst$$reg),
11522               as_Register($src1$$reg),
11523               as_Register($src2$$reg),
11524               Assembler::LSR,
11525               $src3$$constant &amp; 0x3f);
11526   %}
11527 
11528   ins_pipe(ialu_reg_reg_shift);
11529 %}
11530 
11531 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11532                          iRegIorL2I src1, iRegIorL2I src2,
11533                          immI src3, rFlagsReg cr) %{
11534   match(Set dst (XorI src1 (RShiftI src2 src3)));
11535 
11536   ins_cost(1.9 * INSN_COST);
11537   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11538 
11539   ins_encode %{
11540     __ eorw(as_Register($dst$$reg),
11541               as_Register($src1$$reg),
11542               as_Register($src2$$reg),
11543               Assembler::ASR,
11544               $src3$$constant &amp; 0x1f);
11545   %}
11546 
11547   ins_pipe(ialu_reg_reg_shift);
11548 %}
11549 
11550 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11551                          iRegL src1, iRegL src2,
11552                          immI src3, rFlagsReg cr) %{
11553   match(Set dst (XorL src1 (RShiftL src2 src3)));
11554 
11555   ins_cost(1.9 * INSN_COST);
11556   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11557 
11558   ins_encode %{
11559     __ eor(as_Register($dst$$reg),
11560               as_Register($src1$$reg),
11561               as_Register($src2$$reg),
11562               Assembler::ASR,
11563               $src3$$constant &amp; 0x3f);
11564   %}
11565 
11566   ins_pipe(ialu_reg_reg_shift);
11567 %}
11568 
11569 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11570                          iRegIorL2I src1, iRegIorL2I src2,
11571                          immI src3, rFlagsReg cr) %{
11572   match(Set dst (XorI src1 (LShiftI src2 src3)));
11573 
11574   ins_cost(1.9 * INSN_COST);
11575   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11576 
11577   ins_encode %{
11578     __ eorw(as_Register($dst$$reg),
11579               as_Register($src1$$reg),
11580               as_Register($src2$$reg),
11581               Assembler::LSL,
11582               $src3$$constant &amp; 0x1f);
11583   %}
11584 
11585   ins_pipe(ialu_reg_reg_shift);
11586 %}
11587 
11588 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11589                          iRegL src1, iRegL src2,
11590                          immI src3, rFlagsReg cr) %{
11591   match(Set dst (XorL src1 (LShiftL src2 src3)));
11592 
11593   ins_cost(1.9 * INSN_COST);
11594   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11595 
11596   ins_encode %{
11597     __ eor(as_Register($dst$$reg),
11598               as_Register($src1$$reg),
11599               as_Register($src2$$reg),
11600               Assembler::LSL,
11601               $src3$$constant &amp; 0x3f);
11602   %}
11603 
11604   ins_pipe(ialu_reg_reg_shift);
11605 %}
11606 
11607 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11608                          iRegIorL2I src1, iRegIorL2I src2,
11609                          immI src3, rFlagsReg cr) %{
11610   match(Set dst (OrI src1 (URShiftI src2 src3)));
11611 
11612   ins_cost(1.9 * INSN_COST);
11613   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11614 
11615   ins_encode %{
11616     __ orrw(as_Register($dst$$reg),
11617               as_Register($src1$$reg),
11618               as_Register($src2$$reg),
11619               Assembler::LSR,
11620               $src3$$constant &amp; 0x1f);
11621   %}
11622 
11623   ins_pipe(ialu_reg_reg_shift);
11624 %}
11625 
11626 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11627                          iRegL src1, iRegL src2,
11628                          immI src3, rFlagsReg cr) %{
11629   match(Set dst (OrL src1 (URShiftL src2 src3)));
11630 
11631   ins_cost(1.9 * INSN_COST);
11632   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11633 
11634   ins_encode %{
11635     __ orr(as_Register($dst$$reg),
11636               as_Register($src1$$reg),
11637               as_Register($src2$$reg),
11638               Assembler::LSR,
11639               $src3$$constant &amp; 0x3f);
11640   %}
11641 
11642   ins_pipe(ialu_reg_reg_shift);
11643 %}
11644 
11645 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11646                          iRegIorL2I src1, iRegIorL2I src2,
11647                          immI src3, rFlagsReg cr) %{
11648   match(Set dst (OrI src1 (RShiftI src2 src3)));
11649 
11650   ins_cost(1.9 * INSN_COST);
11651   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11652 
11653   ins_encode %{
11654     __ orrw(as_Register($dst$$reg),
11655               as_Register($src1$$reg),
11656               as_Register($src2$$reg),
11657               Assembler::ASR,
11658               $src3$$constant &amp; 0x1f);
11659   %}
11660 
11661   ins_pipe(ialu_reg_reg_shift);
11662 %}
11663 
11664 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11665                          iRegL src1, iRegL src2,
11666                          immI src3, rFlagsReg cr) %{
11667   match(Set dst (OrL src1 (RShiftL src2 src3)));
11668 
11669   ins_cost(1.9 * INSN_COST);
11670   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11671 
11672   ins_encode %{
11673     __ orr(as_Register($dst$$reg),
11674               as_Register($src1$$reg),
11675               as_Register($src2$$reg),
11676               Assembler::ASR,
11677               $src3$$constant &amp; 0x3f);
11678   %}
11679 
11680   ins_pipe(ialu_reg_reg_shift);
11681 %}
11682 
11683 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11684                          iRegIorL2I src1, iRegIorL2I src2,
11685                          immI src3, rFlagsReg cr) %{
11686   match(Set dst (OrI src1 (LShiftI src2 src3)));
11687 
11688   ins_cost(1.9 * INSN_COST);
11689   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11690 
11691   ins_encode %{
11692     __ orrw(as_Register($dst$$reg),
11693               as_Register($src1$$reg),
11694               as_Register($src2$$reg),
11695               Assembler::LSL,
11696               $src3$$constant &amp; 0x1f);
11697   %}
11698 
11699   ins_pipe(ialu_reg_reg_shift);
11700 %}
11701 
11702 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11703                          iRegL src1, iRegL src2,
11704                          immI src3, rFlagsReg cr) %{
11705   match(Set dst (OrL src1 (LShiftL src2 src3)));
11706 
11707   ins_cost(1.9 * INSN_COST);
11708   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11709 
11710   ins_encode %{
11711     __ orr(as_Register($dst$$reg),
11712               as_Register($src1$$reg),
11713               as_Register($src2$$reg),
11714               Assembler::LSL,
11715               $src3$$constant &amp; 0x3f);
11716   %}
11717 
11718   ins_pipe(ialu_reg_reg_shift);
11719 %}
11720 
11721 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11722                          iRegIorL2I src1, iRegIorL2I src2,
11723                          immI src3, rFlagsReg cr) %{
11724   match(Set dst (AddI src1 (URShiftI src2 src3)));
11725 
11726   ins_cost(1.9 * INSN_COST);
11727   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11728 
11729   ins_encode %{
11730     __ addw(as_Register($dst$$reg),
11731               as_Register($src1$$reg),
11732               as_Register($src2$$reg),
11733               Assembler::LSR,
11734               $src3$$constant &amp; 0x1f);
11735   %}
11736 
11737   ins_pipe(ialu_reg_reg_shift);
11738 %}
11739 
11740 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11741                          iRegL src1, iRegL src2,
11742                          immI src3, rFlagsReg cr) %{
11743   match(Set dst (AddL src1 (URShiftL src2 src3)));
11744 
11745   ins_cost(1.9 * INSN_COST);
11746   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11747 
11748   ins_encode %{
11749     __ add(as_Register($dst$$reg),
11750               as_Register($src1$$reg),
11751               as_Register($src2$$reg),
11752               Assembler::LSR,
11753               $src3$$constant &amp; 0x3f);
11754   %}
11755 
11756   ins_pipe(ialu_reg_reg_shift);
11757 %}
11758 
11759 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11760                          iRegIorL2I src1, iRegIorL2I src2,
11761                          immI src3, rFlagsReg cr) %{
11762   match(Set dst (AddI src1 (RShiftI src2 src3)));
11763 
11764   ins_cost(1.9 * INSN_COST);
11765   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11766 
11767   ins_encode %{
11768     __ addw(as_Register($dst$$reg),
11769               as_Register($src1$$reg),
11770               as_Register($src2$$reg),
11771               Assembler::ASR,
11772               $src3$$constant &amp; 0x1f);
11773   %}
11774 
11775   ins_pipe(ialu_reg_reg_shift);
11776 %}
11777 
11778 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11779                          iRegL src1, iRegL src2,
11780                          immI src3, rFlagsReg cr) %{
11781   match(Set dst (AddL src1 (RShiftL src2 src3)));
11782 
11783   ins_cost(1.9 * INSN_COST);
11784   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11785 
11786   ins_encode %{
11787     __ add(as_Register($dst$$reg),
11788               as_Register($src1$$reg),
11789               as_Register($src2$$reg),
11790               Assembler::ASR,
11791               $src3$$constant &amp; 0x3f);
11792   %}
11793 
11794   ins_pipe(ialu_reg_reg_shift);
11795 %}
11796 
11797 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11798                          iRegIorL2I src1, iRegIorL2I src2,
11799                          immI src3, rFlagsReg cr) %{
11800   match(Set dst (AddI src1 (LShiftI src2 src3)));
11801 
11802   ins_cost(1.9 * INSN_COST);
11803   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11804 
11805   ins_encode %{
11806     __ addw(as_Register($dst$$reg),
11807               as_Register($src1$$reg),
11808               as_Register($src2$$reg),
11809               Assembler::LSL,
11810               $src3$$constant &amp; 0x1f);
11811   %}
11812 
11813   ins_pipe(ialu_reg_reg_shift);
11814 %}
11815 
11816 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11817                          iRegL src1, iRegL src2,
11818                          immI src3, rFlagsReg cr) %{
11819   match(Set dst (AddL src1 (LShiftL src2 src3)));
11820 
11821   ins_cost(1.9 * INSN_COST);
11822   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11823 
11824   ins_encode %{
11825     __ add(as_Register($dst$$reg),
11826               as_Register($src1$$reg),
11827               as_Register($src2$$reg),
11828               Assembler::LSL,
11829               $src3$$constant &amp; 0x3f);
11830   %}
11831 
11832   ins_pipe(ialu_reg_reg_shift);
11833 %}
11834 
11835 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11836                          iRegIorL2I src1, iRegIorL2I src2,
11837                          immI src3, rFlagsReg cr) %{
11838   match(Set dst (SubI src1 (URShiftI src2 src3)));
11839 
11840   ins_cost(1.9 * INSN_COST);
11841   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11842 
11843   ins_encode %{
11844     __ subw(as_Register($dst$$reg),
11845               as_Register($src1$$reg),
11846               as_Register($src2$$reg),
11847               Assembler::LSR,
11848               $src3$$constant &amp; 0x1f);
11849   %}
11850 
11851   ins_pipe(ialu_reg_reg_shift);
11852 %}
11853 
11854 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11855                          iRegL src1, iRegL src2,
11856                          immI src3, rFlagsReg cr) %{
11857   match(Set dst (SubL src1 (URShiftL src2 src3)));
11858 
11859   ins_cost(1.9 * INSN_COST);
11860   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11861 
11862   ins_encode %{
11863     __ sub(as_Register($dst$$reg),
11864               as_Register($src1$$reg),
11865               as_Register($src2$$reg),
11866               Assembler::LSR,
11867               $src3$$constant &amp; 0x3f);
11868   %}
11869 
11870   ins_pipe(ialu_reg_reg_shift);
11871 %}
11872 
11873 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11874                          iRegIorL2I src1, iRegIorL2I src2,
11875                          immI src3, rFlagsReg cr) %{
11876   match(Set dst (SubI src1 (RShiftI src2 src3)));
11877 
11878   ins_cost(1.9 * INSN_COST);
11879   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11880 
11881   ins_encode %{
11882     __ subw(as_Register($dst$$reg),
11883               as_Register($src1$$reg),
11884               as_Register($src2$$reg),
11885               Assembler::ASR,
11886               $src3$$constant &amp; 0x1f);
11887   %}
11888 
11889   ins_pipe(ialu_reg_reg_shift);
11890 %}
11891 
11892 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11893                          iRegL src1, iRegL src2,
11894                          immI src3, rFlagsReg cr) %{
11895   match(Set dst (SubL src1 (RShiftL src2 src3)));
11896 
11897   ins_cost(1.9 * INSN_COST);
11898   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11899 
11900   ins_encode %{
11901     __ sub(as_Register($dst$$reg),
11902               as_Register($src1$$reg),
11903               as_Register($src2$$reg),
11904               Assembler::ASR,
11905               $src3$$constant &amp; 0x3f);
11906   %}
11907 
11908   ins_pipe(ialu_reg_reg_shift);
11909 %}
11910 
11911 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11912                          iRegIorL2I src1, iRegIorL2I src2,
11913                          immI src3, rFlagsReg cr) %{
11914   match(Set dst (SubI src1 (LShiftI src2 src3)));
11915 
11916   ins_cost(1.9 * INSN_COST);
11917   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11918 
11919   ins_encode %{
11920     __ subw(as_Register($dst$$reg),
11921               as_Register($src1$$reg),
11922               as_Register($src2$$reg),
11923               Assembler::LSL,
11924               $src3$$constant &amp; 0x1f);
11925   %}
11926 
11927   ins_pipe(ialu_reg_reg_shift);
11928 %}
11929 
11930 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11931                          iRegL src1, iRegL src2,
11932                          immI src3, rFlagsReg cr) %{
11933   match(Set dst (SubL src1 (LShiftL src2 src3)));
11934 
11935   ins_cost(1.9 * INSN_COST);
11936   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11937 
11938   ins_encode %{
11939     __ sub(as_Register($dst$$reg),
11940               as_Register($src1$$reg),
11941               as_Register($src2$$reg),
11942               Assembler::LSL,
11943               $src3$$constant &amp; 0x3f);
11944   %}
11945 
11946   ins_pipe(ialu_reg_reg_shift);
11947 %}
11948 
11949 
11950 
11951 // Shift Left followed by Shift Right.
11952 // This idiom is used by the compiler for the i2b bytecode etc.
11953 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11954 %{
11955   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11956   ins_cost(INSN_COST * 2);
11957   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11958   ins_encode %{
11959     int lshift = $lshift_count$$constant &amp; 63;
11960     int rshift = $rshift_count$$constant &amp; 63;
11961     int s = 63 - lshift;
11962     int r = (rshift - lshift) &amp; 63;
11963     __ sbfm(as_Register($dst$$reg),
11964             as_Register($src$$reg),
11965             r, s);
11966   %}
11967 
11968   ins_pipe(ialu_reg_shift);
11969 %}
11970 
11971 // Shift Left followed by Shift Right.
11972 // This idiom is used by the compiler for the i2b bytecode etc.
11973 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11974 %{
11975   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11976   ins_cost(INSN_COST * 2);
11977   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11978   ins_encode %{
11979     int lshift = $lshift_count$$constant &amp; 31;
11980     int rshift = $rshift_count$$constant &amp; 31;
11981     int s = 31 - lshift;
11982     int r = (rshift - lshift) &amp; 31;
11983     __ sbfmw(as_Register($dst$$reg),
11984             as_Register($src$$reg),
11985             r, s);
11986   %}
11987 
11988   ins_pipe(ialu_reg_shift);
11989 %}
11990 
11991 // Shift Left followed by Shift Right.
11992 // This idiom is used by the compiler for the i2b bytecode etc.
11993 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11994 %{
11995   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11996   ins_cost(INSN_COST * 2);
11997   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11998   ins_encode %{
11999     int lshift = $lshift_count$$constant &amp; 63;
12000     int rshift = $rshift_count$$constant &amp; 63;
12001     int s = 63 - lshift;
12002     int r = (rshift - lshift) &amp; 63;
12003     __ ubfm(as_Register($dst$$reg),
12004             as_Register($src$$reg),
12005             r, s);
12006   %}
12007 
12008   ins_pipe(ialu_reg_shift);
12009 %}
12010 
12011 // Shift Left followed by Shift Right.
12012 // This idiom is used by the compiler for the i2b bytecode etc.
12013 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12014 %{
12015   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12016   ins_cost(INSN_COST * 2);
12017   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12018   ins_encode %{
12019     int lshift = $lshift_count$$constant &amp; 31;
12020     int rshift = $rshift_count$$constant &amp; 31;
12021     int s = 31 - lshift;
12022     int r = (rshift - lshift) &amp; 31;
12023     __ ubfmw(as_Register($dst$$reg),
12024             as_Register($src$$reg),
12025             r, s);
12026   %}
12027 
12028   ins_pipe(ialu_reg_shift);
12029 %}
12030 // Bitfield extract with shift &amp; mask
12031 
12032 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12033 %{
12034   match(Set dst (AndI (URShiftI src rshift) mask));
12035   // Make sure we are not going to exceed what ubfxw can do.
12036   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12037 
12038   ins_cost(INSN_COST);
12039   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12040   ins_encode %{
12041     int rshift = $rshift$$constant &amp; 31;
12042     long mask = $mask$$constant;
12043     int width = exact_log2(mask+1);
12044     __ ubfxw(as_Register($dst$$reg),
12045             as_Register($src$$reg), rshift, width);
12046   %}
12047   ins_pipe(ialu_reg_shift);
12048 %}
12049 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12050 %{
12051   match(Set dst (AndL (URShiftL src rshift) mask));
12052   // Make sure we are not going to exceed what ubfx can do.
12053   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12054 
12055   ins_cost(INSN_COST);
12056   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12057   ins_encode %{
12058     int rshift = $rshift$$constant &amp; 63;
12059     long mask = $mask$$constant;
12060     int width = exact_log2_long(mask+1);
12061     __ ubfx(as_Register($dst$$reg),
12062             as_Register($src$$reg), rshift, width);
12063   %}
12064   ins_pipe(ialu_reg_shift);
12065 %}
12066 
12067 // We can use ubfx when extending an And with a mask when we know mask
12068 // is positive.  We know that because immI_bitmask guarantees it.
12069 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12070 %{
12071   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12072   // Make sure we are not going to exceed what ubfxw can do.
12073   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12074 
12075   ins_cost(INSN_COST * 2);
12076   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12077   ins_encode %{
12078     int rshift = $rshift$$constant &amp; 31;
12079     long mask = $mask$$constant;
12080     int width = exact_log2(mask+1);
12081     __ ubfx(as_Register($dst$$reg),
12082             as_Register($src$$reg), rshift, width);
12083   %}
12084   ins_pipe(ialu_reg_shift);
12085 %}
12086 
12087 // We can use ubfiz when masking by a positive number and then left shifting the result.
12088 // We know that the mask is positive because immI_bitmask guarantees it.
12089 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12090 %{
12091   match(Set dst (LShiftI (AndI src mask) lshift));
12092   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12093 
12094   ins_cost(INSN_COST);
12095   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12096   ins_encode %{
12097     int lshift = $lshift$$constant &amp; 31;
12098     long mask = $mask$$constant;
12099     int width = exact_log2(mask+1);
12100     __ ubfizw(as_Register($dst$$reg),
12101           as_Register($src$$reg), lshift, width);
12102   %}
12103   ins_pipe(ialu_reg_shift);
12104 %}
12105 // We can use ubfiz when masking by a positive number and then left shifting the result.
12106 // We know that the mask is positive because immL_bitmask guarantees it.
12107 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12108 %{
12109   match(Set dst (LShiftL (AndL src mask) lshift));
12110   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12111 
12112   ins_cost(INSN_COST);
12113   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12114   ins_encode %{
12115     int lshift = $lshift$$constant &amp; 63;
12116     long mask = $mask$$constant;
12117     int width = exact_log2_long(mask+1);
12118     __ ubfiz(as_Register($dst$$reg),
12119           as_Register($src$$reg), lshift, width);
12120   %}
12121   ins_pipe(ialu_reg_shift);
12122 %}
12123 
12124 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12125 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12126 %{
12127   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12128   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12129 
12130   ins_cost(INSN_COST);
12131   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12132   ins_encode %{
12133     int lshift = $lshift$$constant &amp; 63;
12134     long mask = $mask$$constant;
12135     int width = exact_log2(mask+1);
12136     __ ubfiz(as_Register($dst$$reg),
12137              as_Register($src$$reg), lshift, width);
12138   %}
12139   ins_pipe(ialu_reg_shift);
12140 %}
12141 
12142 // Rotations
12143 
12144 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12145 %{
12146   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12147   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12148 
12149   ins_cost(INSN_COST);
12150   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12151 
12152   ins_encode %{
12153     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12154             $rshift$$constant &amp; 63);
12155   %}
12156   ins_pipe(ialu_reg_reg_extr);
12157 %}
12158 
12159 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12160 %{
12161   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12162   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12163 
12164   ins_cost(INSN_COST);
12165   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12166 
12167   ins_encode %{
12168     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12169             $rshift$$constant &amp; 31);
12170   %}
12171   ins_pipe(ialu_reg_reg_extr);
12172 %}
12173 
12174 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12175 %{
12176   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12177   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12178 
12179   ins_cost(INSN_COST);
12180   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12181 
12182   ins_encode %{
12183     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12184             $rshift$$constant &amp; 63);
12185   %}
12186   ins_pipe(ialu_reg_reg_extr);
12187 %}
12188 
12189 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12190 %{
12191   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12192   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12193 
12194   ins_cost(INSN_COST);
12195   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12196 
12197   ins_encode %{
12198     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12199             $rshift$$constant &amp; 31);
12200   %}
12201   ins_pipe(ialu_reg_reg_extr);
12202 %}
12203 
12204 
12205 // rol expander
12206 
12207 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12208 %{
12209   effect(DEF dst, USE src, USE shift);
12210 
12211   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12212   ins_cost(INSN_COST * 3);
12213   ins_encode %{
12214     __ subw(rscratch1, zr, as_Register($shift$$reg));
12215     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12216             rscratch1);
12217     %}
12218   ins_pipe(ialu_reg_reg_vshift);
12219 %}
12220 
12221 // rol expander
12222 
12223 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12224 %{
12225   effect(DEF dst, USE src, USE shift);
12226 
12227   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12228   ins_cost(INSN_COST * 3);
12229   ins_encode %{
12230     __ subw(rscratch1, zr, as_Register($shift$$reg));
12231     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12232             rscratch1);
12233     %}
12234   ins_pipe(ialu_reg_reg_vshift);
12235 %}
12236 
12237 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12238 %{
12239   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12240 
12241   expand %{
12242     rolL_rReg(dst, src, shift, cr);
12243   %}
12244 %}
12245 
12246 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12247 %{
12248   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12249 
12250   expand %{
12251     rolL_rReg(dst, src, shift, cr);
12252   %}
12253 %}
12254 
12255 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12256 %{
12257   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12258 
12259   expand %{
12260     rolI_rReg(dst, src, shift, cr);
12261   %}
12262 %}
12263 
12264 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12265 %{
12266   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12267 
12268   expand %{
12269     rolI_rReg(dst, src, shift, cr);
12270   %}
12271 %}
12272 
12273 // ror expander
12274 
12275 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12276 %{
12277   effect(DEF dst, USE src, USE shift);
12278 
12279   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12280   ins_cost(INSN_COST);
12281   ins_encode %{
12282     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12283             as_Register($shift$$reg));
12284     %}
12285   ins_pipe(ialu_reg_reg_vshift);
12286 %}
12287 
12288 // ror expander
12289 
12290 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12291 %{
12292   effect(DEF dst, USE src, USE shift);
12293 
12294   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12295   ins_cost(INSN_COST);
12296   ins_encode %{
12297     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12298             as_Register($shift$$reg));
12299     %}
12300   ins_pipe(ialu_reg_reg_vshift);
12301 %}
12302 
12303 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12304 %{
12305   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12306 
12307   expand %{
12308     rorL_rReg(dst, src, shift, cr);
12309   %}
12310 %}
12311 
12312 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12313 %{
12314   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12315 
12316   expand %{
12317     rorL_rReg(dst, src, shift, cr);
12318   %}
12319 %}
12320 
12321 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12322 %{
12323   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12324 
12325   expand %{
12326     rorI_rReg(dst, src, shift, cr);
12327   %}
12328 %}
12329 
12330 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12331 %{
12332   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12333 
12334   expand %{
12335     rorI_rReg(dst, src, shift, cr);
12336   %}
12337 %}
12338 
12339 // Add/subtract (extended)
12340 
12341 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12342 %{
12343   match(Set dst (AddL src1 (ConvI2L src2)));
12344   ins_cost(INSN_COST);
12345   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12346 
12347    ins_encode %{
12348      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12349             as_Register($src2$$reg), ext::sxtw);
12350    %}
12351   ins_pipe(ialu_reg_reg);
12352 %};
12353 
12354 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12355 %{
12356   match(Set dst (SubL src1 (ConvI2L src2)));
12357   ins_cost(INSN_COST);
12358   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12359 
12360    ins_encode %{
12361      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12362             as_Register($src2$$reg), ext::sxtw);
12363    %}
12364   ins_pipe(ialu_reg_reg);
12365 %};
12366 
12367 
12368 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12369 %{
12370   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12371   ins_cost(INSN_COST);
12372   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12373 
12374    ins_encode %{
12375      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12376             as_Register($src2$$reg), ext::sxth);
12377    %}
12378   ins_pipe(ialu_reg_reg);
12379 %}
12380 
12381 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12382 %{
12383   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12384   ins_cost(INSN_COST);
12385   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12386 
12387    ins_encode %{
12388      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12389             as_Register($src2$$reg), ext::sxtb);
12390    %}
12391   ins_pipe(ialu_reg_reg);
12392 %}
12393 
12394 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12395 %{
12396   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12397   ins_cost(INSN_COST);
12398   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12399 
12400    ins_encode %{
12401      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12402             as_Register($src2$$reg), ext::uxtb);
12403    %}
12404   ins_pipe(ialu_reg_reg);
12405 %}
12406 
12407 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12408 %{
12409   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12410   ins_cost(INSN_COST);
12411   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12412 
12413    ins_encode %{
12414      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12415             as_Register($src2$$reg), ext::sxth);
12416    %}
12417   ins_pipe(ialu_reg_reg);
12418 %}
12419 
12420 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12421 %{
12422   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12423   ins_cost(INSN_COST);
12424   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12425 
12426    ins_encode %{
12427      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12428             as_Register($src2$$reg), ext::sxtw);
12429    %}
12430   ins_pipe(ialu_reg_reg);
12431 %}
12432 
12433 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12434 %{
12435   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12436   ins_cost(INSN_COST);
12437   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12438 
12439    ins_encode %{
12440      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12441             as_Register($src2$$reg), ext::sxtb);
12442    %}
12443   ins_pipe(ialu_reg_reg);
12444 %}
12445 
12446 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12447 %{
12448   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12449   ins_cost(INSN_COST);
12450   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12451 
12452    ins_encode %{
12453      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12454             as_Register($src2$$reg), ext::uxtb);
12455    %}
12456   ins_pipe(ialu_reg_reg);
12457 %}
12458 
12459 
12460 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12461 %{
12462   match(Set dst (AddI src1 (AndI src2 mask)));
12463   ins_cost(INSN_COST);
12464   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12465 
12466    ins_encode %{
12467      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12468             as_Register($src2$$reg), ext::uxtb);
12469    %}
12470   ins_pipe(ialu_reg_reg);
12471 %}
12472 
12473 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12474 %{
12475   match(Set dst (AddI src1 (AndI src2 mask)));
12476   ins_cost(INSN_COST);
12477   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12478 
12479    ins_encode %{
12480      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12481             as_Register($src2$$reg), ext::uxth);
12482    %}
12483   ins_pipe(ialu_reg_reg);
12484 %}
12485 
12486 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12487 %{
12488   match(Set dst (AddL src1 (AndL src2 mask)));
12489   ins_cost(INSN_COST);
12490   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12491 
12492    ins_encode %{
12493      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12494             as_Register($src2$$reg), ext::uxtb);
12495    %}
12496   ins_pipe(ialu_reg_reg);
12497 %}
12498 
12499 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12500 %{
12501   match(Set dst (AddL src1 (AndL src2 mask)));
12502   ins_cost(INSN_COST);
12503   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12504 
12505    ins_encode %{
12506      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12507             as_Register($src2$$reg), ext::uxth);
12508    %}
12509   ins_pipe(ialu_reg_reg);
12510 %}
12511 
12512 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12513 %{
12514   match(Set dst (AddL src1 (AndL src2 mask)));
12515   ins_cost(INSN_COST);
12516   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12517 
12518    ins_encode %{
12519      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12520             as_Register($src2$$reg), ext::uxtw);
12521    %}
12522   ins_pipe(ialu_reg_reg);
12523 %}
12524 
12525 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12526 %{
12527   match(Set dst (SubI src1 (AndI src2 mask)));
12528   ins_cost(INSN_COST);
12529   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12530 
12531    ins_encode %{
12532      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12533             as_Register($src2$$reg), ext::uxtb);
12534    %}
12535   ins_pipe(ialu_reg_reg);
12536 %}
12537 
12538 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12539 %{
12540   match(Set dst (SubI src1 (AndI src2 mask)));
12541   ins_cost(INSN_COST);
12542   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12543 
12544    ins_encode %{
12545      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12546             as_Register($src2$$reg), ext::uxth);
12547    %}
12548   ins_pipe(ialu_reg_reg);
12549 %}
12550 
12551 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12552 %{
12553   match(Set dst (SubL src1 (AndL src2 mask)));
12554   ins_cost(INSN_COST);
12555   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12556 
12557    ins_encode %{
12558      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12559             as_Register($src2$$reg), ext::uxtb);
12560    %}
12561   ins_pipe(ialu_reg_reg);
12562 %}
12563 
12564 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12565 %{
12566   match(Set dst (SubL src1 (AndL src2 mask)));
12567   ins_cost(INSN_COST);
12568   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12569 
12570    ins_encode %{
12571      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12572             as_Register($src2$$reg), ext::uxth);
12573    %}
12574   ins_pipe(ialu_reg_reg);
12575 %}
12576 
12577 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12578 %{
12579   match(Set dst (SubL src1 (AndL src2 mask)));
12580   ins_cost(INSN_COST);
12581   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12582 
12583    ins_encode %{
12584      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12585             as_Register($src2$$reg), ext::uxtw);
12586    %}
12587   ins_pipe(ialu_reg_reg);
12588 %}
12589 
12590 
12591 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12592 %{
12593   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12594   ins_cost(1.9 * INSN_COST);
12595   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12596 
12597    ins_encode %{
12598      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12599             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12600    %}
12601   ins_pipe(ialu_reg_reg_shift);
12602 %}
12603 
12604 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12605 %{
12606   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12607   ins_cost(1.9 * INSN_COST);
12608   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12609 
12610    ins_encode %{
12611      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12612             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12613    %}
12614   ins_pipe(ialu_reg_reg_shift);
12615 %}
12616 
12617 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12618 %{
12619   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12620   ins_cost(1.9 * INSN_COST);
12621   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12622 
12623    ins_encode %{
12624      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12625             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12626    %}
12627   ins_pipe(ialu_reg_reg_shift);
12628 %}
12629 
12630 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12631 %{
12632   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12633   ins_cost(1.9 * INSN_COST);
12634   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12635 
12636    ins_encode %{
12637      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12638             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12639    %}
12640   ins_pipe(ialu_reg_reg_shift);
12641 %}
12642 
12643 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12644 %{
12645   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12646   ins_cost(1.9 * INSN_COST);
12647   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12648 
12649    ins_encode %{
12650      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12651             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12652    %}
12653   ins_pipe(ialu_reg_reg_shift);
12654 %}
12655 
12656 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12657 %{
12658   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12659   ins_cost(1.9 * INSN_COST);
12660   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12661 
12662    ins_encode %{
12663      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12664             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12665    %}
12666   ins_pipe(ialu_reg_reg_shift);
12667 %}
12668 
12669 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12670 %{
12671   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12672   ins_cost(1.9 * INSN_COST);
12673   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12674 
12675    ins_encode %{
12676      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12677             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12678    %}
12679   ins_pipe(ialu_reg_reg_shift);
12680 %}
12681 
12682 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12683 %{
12684   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12685   ins_cost(1.9 * INSN_COST);
12686   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12687 
12688    ins_encode %{
12689      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12690             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12691    %}
12692   ins_pipe(ialu_reg_reg_shift);
12693 %}
12694 
12695 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12696 %{
12697   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12698   ins_cost(1.9 * INSN_COST);
12699   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12700 
12701    ins_encode %{
12702      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12703             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12704    %}
12705   ins_pipe(ialu_reg_reg_shift);
12706 %}
12707 
12708 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12709 %{
12710   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12711   ins_cost(1.9 * INSN_COST);
12712   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12713 
12714    ins_encode %{
12715      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12716             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12717    %}
12718   ins_pipe(ialu_reg_reg_shift);
12719 %}
12720 
12721 
12722 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12723 %{
12724   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12725   ins_cost(1.9 * INSN_COST);
12726   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12727 
12728    ins_encode %{
12729      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12730             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12731    %}
12732   ins_pipe(ialu_reg_reg_shift);
12733 %};
12734 
12735 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12736 %{
12737   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12738   ins_cost(1.9 * INSN_COST);
12739   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12740 
12741    ins_encode %{
12742      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12743             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12744    %}
12745   ins_pipe(ialu_reg_reg_shift);
12746 %};
12747 
12748 
12749 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12750 %{
12751   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12752   ins_cost(1.9 * INSN_COST);
12753   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12754 
12755    ins_encode %{
12756      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12757             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12758    %}
12759   ins_pipe(ialu_reg_reg_shift);
12760 %}
12761 
12762 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12763 %{
12764   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12765   ins_cost(1.9 * INSN_COST);
12766   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12767 
12768    ins_encode %{
12769      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12770             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12771    %}
12772   ins_pipe(ialu_reg_reg_shift);
12773 %}
12774 
12775 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12776 %{
12777   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12778   ins_cost(1.9 * INSN_COST);
12779   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12780 
12781    ins_encode %{
12782      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12783             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12784    %}
12785   ins_pipe(ialu_reg_reg_shift);
12786 %}
12787 
12788 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12789 %{
12790   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12791   ins_cost(1.9 * INSN_COST);
12792   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12793 
12794    ins_encode %{
12795      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12796             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12797    %}
12798   ins_pipe(ialu_reg_reg_shift);
12799 %}
12800 
12801 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12802 %{
12803   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12804   ins_cost(1.9 * INSN_COST);
12805   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12806 
12807    ins_encode %{
12808      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12809             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12810    %}
12811   ins_pipe(ialu_reg_reg_shift);
12812 %}
12813 
12814 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12815 %{
12816   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12817   ins_cost(1.9 * INSN_COST);
12818   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12819 
12820    ins_encode %{
12821      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12822             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12823    %}
12824   ins_pipe(ialu_reg_reg_shift);
12825 %}
12826 
12827 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12828 %{
12829   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12830   ins_cost(1.9 * INSN_COST);
12831   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12832 
12833    ins_encode %{
12834      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12835             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12836    %}
12837   ins_pipe(ialu_reg_reg_shift);
12838 %}
12839 
12840 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12841 %{
12842   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12843   ins_cost(1.9 * INSN_COST);
12844   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12845 
12846    ins_encode %{
12847      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12848             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12849    %}
12850   ins_pipe(ialu_reg_reg_shift);
12851 %}
12852 
12853 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12854 %{
12855   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12856   ins_cost(1.9 * INSN_COST);
12857   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12858 
12859    ins_encode %{
12860      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12861             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12862    %}
12863   ins_pipe(ialu_reg_reg_shift);
12864 %}
12865 
12866 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12867 %{
12868   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12869   ins_cost(1.9 * INSN_COST);
12870   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12871 
12872    ins_encode %{
12873      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12874             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12875    %}
12876   ins_pipe(ialu_reg_reg_shift);
12877 %}
12878 // END This section of the file is automatically generated. Do not edit --------------
12879 
12880 // ============================================================================
12881 // Floating Point Arithmetic Instructions
12882 
12883 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12884   match(Set dst (AddF src1 src2));
12885 
12886   ins_cost(INSN_COST * 5);
12887   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12888 
12889   ins_encode %{
12890     __ fadds(as_FloatRegister($dst$$reg),
12891              as_FloatRegister($src1$$reg),
12892              as_FloatRegister($src2$$reg));
12893   %}
12894 
12895   ins_pipe(fp_dop_reg_reg_s);
12896 %}
12897 
12898 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12899   match(Set dst (AddD src1 src2));
12900 
12901   ins_cost(INSN_COST * 5);
12902   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12903 
12904   ins_encode %{
12905     __ faddd(as_FloatRegister($dst$$reg),
12906              as_FloatRegister($src1$$reg),
12907              as_FloatRegister($src2$$reg));
12908   %}
12909 
12910   ins_pipe(fp_dop_reg_reg_d);
12911 %}
12912 
12913 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12914   match(Set dst (SubF src1 src2));
12915 
12916   ins_cost(INSN_COST * 5);
12917   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12918 
12919   ins_encode %{
12920     __ fsubs(as_FloatRegister($dst$$reg),
12921              as_FloatRegister($src1$$reg),
12922              as_FloatRegister($src2$$reg));
12923   %}
12924 
12925   ins_pipe(fp_dop_reg_reg_s);
12926 %}
12927 
12928 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12929   match(Set dst (SubD src1 src2));
12930 
12931   ins_cost(INSN_COST * 5);
12932   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12933 
12934   ins_encode %{
12935     __ fsubd(as_FloatRegister($dst$$reg),
12936              as_FloatRegister($src1$$reg),
12937              as_FloatRegister($src2$$reg));
12938   %}
12939 
12940   ins_pipe(fp_dop_reg_reg_d);
12941 %}
12942 
12943 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12944   match(Set dst (MulF src1 src2));
12945 
12946   ins_cost(INSN_COST * 6);
12947   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12948 
12949   ins_encode %{
12950     __ fmuls(as_FloatRegister($dst$$reg),
12951              as_FloatRegister($src1$$reg),
12952              as_FloatRegister($src2$$reg));
12953   %}
12954 
12955   ins_pipe(fp_dop_reg_reg_s);
12956 %}
12957 
12958 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12959   match(Set dst (MulD src1 src2));
12960 
12961   ins_cost(INSN_COST * 6);
12962   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12963 
12964   ins_encode %{
12965     __ fmuld(as_FloatRegister($dst$$reg),
12966              as_FloatRegister($src1$$reg),
12967              as_FloatRegister($src2$$reg));
12968   %}
12969 
12970   ins_pipe(fp_dop_reg_reg_d);
12971 %}
12972 
12973 // src1 * src2 + src3
12974 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12975   predicate(UseFMA);
12976   match(Set dst (FmaF src3 (Binary src1 src2)));
12977 
12978   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12979 
12980   ins_encode %{
12981     __ fmadds(as_FloatRegister($dst$$reg),
12982              as_FloatRegister($src1$$reg),
12983              as_FloatRegister($src2$$reg),
12984              as_FloatRegister($src3$$reg));
12985   %}
12986 
12987   ins_pipe(pipe_class_default);
12988 %}
12989 
12990 // src1 * src2 + src3
12991 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12992   predicate(UseFMA);
12993   match(Set dst (FmaD src3 (Binary src1 src2)));
12994 
12995   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12996 
12997   ins_encode %{
12998     __ fmaddd(as_FloatRegister($dst$$reg),
12999              as_FloatRegister($src1$$reg),
13000              as_FloatRegister($src2$$reg),
13001              as_FloatRegister($src3$$reg));
13002   %}
13003 
13004   ins_pipe(pipe_class_default);
13005 %}
13006 
13007 // -src1 * src2 + src3
13008 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13009   predicate(UseFMA);
13010   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13011   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13012 
13013   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13014 
13015   ins_encode %{
13016     __ fmsubs(as_FloatRegister($dst$$reg),
13017               as_FloatRegister($src1$$reg),
13018               as_FloatRegister($src2$$reg),
13019               as_FloatRegister($src3$$reg));
13020   %}
13021 
13022   ins_pipe(pipe_class_default);
13023 %}
13024 
13025 // -src1 * src2 + src3
13026 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13027   predicate(UseFMA);
13028   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13029   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13030 
13031   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13032 
13033   ins_encode %{
13034     __ fmsubd(as_FloatRegister($dst$$reg),
13035               as_FloatRegister($src1$$reg),
13036               as_FloatRegister($src2$$reg),
13037               as_FloatRegister($src3$$reg));
13038   %}
13039 
13040   ins_pipe(pipe_class_default);
13041 %}
13042 
13043 // -src1 * src2 - src3
13044 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13045   predicate(UseFMA);
13046   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13047   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13048 
13049   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13050 
13051   ins_encode %{
13052     __ fnmadds(as_FloatRegister($dst$$reg),
13053                as_FloatRegister($src1$$reg),
13054                as_FloatRegister($src2$$reg),
13055                as_FloatRegister($src3$$reg));
13056   %}
13057 
13058   ins_pipe(pipe_class_default);
13059 %}
13060 
13061 // -src1 * src2 - src3
13062 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13063   predicate(UseFMA);
13064   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13065   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13066 
13067   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13068 
13069   ins_encode %{
13070     __ fnmaddd(as_FloatRegister($dst$$reg),
13071                as_FloatRegister($src1$$reg),
13072                as_FloatRegister($src2$$reg),
13073                as_FloatRegister($src3$$reg));
13074   %}
13075 
13076   ins_pipe(pipe_class_default);
13077 %}
13078 
13079 // src1 * src2 - src3
13080 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13081   predicate(UseFMA);
13082   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13083 
13084   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13085 
13086   ins_encode %{
13087     __ fnmsubs(as_FloatRegister($dst$$reg),
13088                as_FloatRegister($src1$$reg),
13089                as_FloatRegister($src2$$reg),
13090                as_FloatRegister($src3$$reg));
13091   %}
13092 
13093   ins_pipe(pipe_class_default);
13094 %}
13095 
13096 // src1 * src2 - src3
13097 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13098   predicate(UseFMA);
13099   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13100 
13101   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13102 
13103   ins_encode %{
13104   // n.b. insn name should be fnmsubd
13105     __ fnmsub(as_FloatRegister($dst$$reg),
13106               as_FloatRegister($src1$$reg),
13107               as_FloatRegister($src2$$reg),
13108               as_FloatRegister($src3$$reg));
13109   %}
13110 
13111   ins_pipe(pipe_class_default);
13112 %}
13113 
13114 
13115 // Math.max(FF)F
13116 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13117   match(Set dst (MaxF src1 src2));
13118 
13119   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13120   ins_encode %{
13121     __ fmaxs(as_FloatRegister($dst$$reg),
13122              as_FloatRegister($src1$$reg),
13123              as_FloatRegister($src2$$reg));
13124   %}
13125 
13126   ins_pipe(fp_dop_reg_reg_s);
13127 %}
13128 
13129 // Math.min(FF)F
13130 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13131   match(Set dst (MinF src1 src2));
13132 
13133   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13134   ins_encode %{
13135     __ fmins(as_FloatRegister($dst$$reg),
13136              as_FloatRegister($src1$$reg),
13137              as_FloatRegister($src2$$reg));
13138   %}
13139 
13140   ins_pipe(fp_dop_reg_reg_s);
13141 %}
13142 
13143 // Math.max(DD)D
13144 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13145   match(Set dst (MaxD src1 src2));
13146 
13147   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13148   ins_encode %{
13149     __ fmaxd(as_FloatRegister($dst$$reg),
13150              as_FloatRegister($src1$$reg),
13151              as_FloatRegister($src2$$reg));
13152   %}
13153 
13154   ins_pipe(fp_dop_reg_reg_d);
13155 %}
13156 
13157 // Math.min(DD)D
13158 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13159   match(Set dst (MinD src1 src2));
13160 
13161   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13162   ins_encode %{
13163     __ fmind(as_FloatRegister($dst$$reg),
13164              as_FloatRegister($src1$$reg),
13165              as_FloatRegister($src2$$reg));
13166   %}
13167 
13168   ins_pipe(fp_dop_reg_reg_d);
13169 %}
13170 
13171 
13172 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13173   match(Set dst (DivF src1  src2));
13174 
13175   ins_cost(INSN_COST * 18);
13176   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13177 
13178   ins_encode %{
13179     __ fdivs(as_FloatRegister($dst$$reg),
13180              as_FloatRegister($src1$$reg),
13181              as_FloatRegister($src2$$reg));
13182   %}
13183 
13184   ins_pipe(fp_div_s);
13185 %}
13186 
13187 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13188   match(Set dst (DivD src1  src2));
13189 
13190   ins_cost(INSN_COST * 32);
13191   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13192 
13193   ins_encode %{
13194     __ fdivd(as_FloatRegister($dst$$reg),
13195              as_FloatRegister($src1$$reg),
13196              as_FloatRegister($src2$$reg));
13197   %}
13198 
13199   ins_pipe(fp_div_d);
13200 %}
13201 
13202 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13203   match(Set dst (NegF src));
13204 
13205   ins_cost(INSN_COST * 3);
13206   format %{ &quot;fneg   $dst, $src&quot; %}
13207 
13208   ins_encode %{
13209     __ fnegs(as_FloatRegister($dst$$reg),
13210              as_FloatRegister($src$$reg));
13211   %}
13212 
13213   ins_pipe(fp_uop_s);
13214 %}
13215 
13216 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13217   match(Set dst (NegD src));
13218 
13219   ins_cost(INSN_COST * 3);
13220   format %{ &quot;fnegd   $dst, $src&quot; %}
13221 
13222   ins_encode %{
13223     __ fnegd(as_FloatRegister($dst$$reg),
13224              as_FloatRegister($src$$reg));
13225   %}
13226 
13227   ins_pipe(fp_uop_d);
13228 %}
13229 
13230 instruct absF_reg(vRegF dst, vRegF src) %{
13231   match(Set dst (AbsF src));
13232 
13233   ins_cost(INSN_COST * 3);
13234   format %{ &quot;fabss   $dst, $src&quot; %}
13235   ins_encode %{
13236     __ fabss(as_FloatRegister($dst$$reg),
13237              as_FloatRegister($src$$reg));
13238   %}
13239 
13240   ins_pipe(fp_uop_s);
13241 %}
13242 
13243 instruct absD_reg(vRegD dst, vRegD src) %{
13244   match(Set dst (AbsD src));
13245 
13246   ins_cost(INSN_COST * 3);
13247   format %{ &quot;fabsd   $dst, $src&quot; %}
13248   ins_encode %{
13249     __ fabsd(as_FloatRegister($dst$$reg),
13250              as_FloatRegister($src$$reg));
13251   %}
13252 
13253   ins_pipe(fp_uop_d);
13254 %}
13255 
13256 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13257   match(Set dst (SqrtD src));
13258 
13259   ins_cost(INSN_COST * 50);
13260   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13261   ins_encode %{
13262     __ fsqrtd(as_FloatRegister($dst$$reg),
13263              as_FloatRegister($src$$reg));
13264   %}
13265 
13266   ins_pipe(fp_div_s);
13267 %}
13268 
13269 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13270   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13271 
13272   ins_cost(INSN_COST * 50);
13273   format %{ &quot;fsqrts  $dst, $src&quot; %}
13274   ins_encode %{
13275     __ fsqrts(as_FloatRegister($dst$$reg),
13276              as_FloatRegister($src$$reg));
13277   %}
13278 
13279   ins_pipe(fp_div_d);
13280 %}
13281 
13282 // Math.rint, floor, ceil
13283 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13284   match(Set dst (RoundDoubleMode src rmode));
13285   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13286   ins_encode %{
13287     switch ($rmode$$constant) {
13288       case RoundDoubleModeNode::rmode_rint:
13289         __ frintnd(as_FloatRegister($dst$$reg),
13290                    as_FloatRegister($src$$reg));
13291         break;
13292       case RoundDoubleModeNode::rmode_floor:
13293         __ frintmd(as_FloatRegister($dst$$reg),
13294                    as_FloatRegister($src$$reg));
13295         break;
13296       case RoundDoubleModeNode::rmode_ceil:
13297         __ frintpd(as_FloatRegister($dst$$reg),
13298                    as_FloatRegister($src$$reg));
13299         break;
13300     }
13301   %}
13302   ins_pipe(fp_uop_d);
13303 %}
13304 
13305 // ============================================================================
13306 // Logical Instructions
13307 
13308 // Integer Logical Instructions
13309 
13310 // And Instructions
13311 
13312 
13313 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13314   match(Set dst (AndI src1 src2));
13315 
13316   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13317 
13318   ins_cost(INSN_COST);
13319   ins_encode %{
13320     __ andw(as_Register($dst$$reg),
13321             as_Register($src1$$reg),
13322             as_Register($src2$$reg));
13323   %}
13324 
13325   ins_pipe(ialu_reg_reg);
13326 %}
13327 
13328 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13329   match(Set dst (AndI src1 src2));
13330 
13331   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13332 
13333   ins_cost(INSN_COST);
13334   ins_encode %{
13335     __ andw(as_Register($dst$$reg),
13336             as_Register($src1$$reg),
13337             (unsigned long)($src2$$constant));
13338   %}
13339 
13340   ins_pipe(ialu_reg_imm);
13341 %}
13342 
13343 // Or Instructions
13344 
13345 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13346   match(Set dst (OrI src1 src2));
13347 
13348   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13349 
13350   ins_cost(INSN_COST);
13351   ins_encode %{
13352     __ orrw(as_Register($dst$$reg),
13353             as_Register($src1$$reg),
13354             as_Register($src2$$reg));
13355   %}
13356 
13357   ins_pipe(ialu_reg_reg);
13358 %}
13359 
13360 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13361   match(Set dst (OrI src1 src2));
13362 
13363   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13364 
13365   ins_cost(INSN_COST);
13366   ins_encode %{
13367     __ orrw(as_Register($dst$$reg),
13368             as_Register($src1$$reg),
13369             (unsigned long)($src2$$constant));
13370   %}
13371 
13372   ins_pipe(ialu_reg_imm);
13373 %}
13374 
13375 // Xor Instructions
13376 
13377 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13378   match(Set dst (XorI src1 src2));
13379 
13380   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13381 
13382   ins_cost(INSN_COST);
13383   ins_encode %{
13384     __ eorw(as_Register($dst$$reg),
13385             as_Register($src1$$reg),
13386             as_Register($src2$$reg));
13387   %}
13388 
13389   ins_pipe(ialu_reg_reg);
13390 %}
13391 
13392 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13393   match(Set dst (XorI src1 src2));
13394 
13395   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13396 
13397   ins_cost(INSN_COST);
13398   ins_encode %{
13399     __ eorw(as_Register($dst$$reg),
13400             as_Register($src1$$reg),
13401             (unsigned long)($src2$$constant));
13402   %}
13403 
13404   ins_pipe(ialu_reg_imm);
13405 %}
13406 
13407 // Long Logical Instructions
13408 // TODO
13409 
13410 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13411   match(Set dst (AndL src1 src2));
13412 
13413   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13414 
13415   ins_cost(INSN_COST);
13416   ins_encode %{
13417     __ andr(as_Register($dst$$reg),
13418             as_Register($src1$$reg),
13419             as_Register($src2$$reg));
13420   %}
13421 
13422   ins_pipe(ialu_reg_reg);
13423 %}
13424 
13425 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13426   match(Set dst (AndL src1 src2));
13427 
13428   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13429 
13430   ins_cost(INSN_COST);
13431   ins_encode %{
13432     __ andr(as_Register($dst$$reg),
13433             as_Register($src1$$reg),
13434             (unsigned long)($src2$$constant));
13435   %}
13436 
13437   ins_pipe(ialu_reg_imm);
13438 %}
13439 
13440 // Or Instructions
13441 
13442 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13443   match(Set dst (OrL src1 src2));
13444 
13445   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13446 
13447   ins_cost(INSN_COST);
13448   ins_encode %{
13449     __ orr(as_Register($dst$$reg),
13450            as_Register($src1$$reg),
13451            as_Register($src2$$reg));
13452   %}
13453 
13454   ins_pipe(ialu_reg_reg);
13455 %}
13456 
13457 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13458   match(Set dst (OrL src1 src2));
13459 
13460   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13461 
13462   ins_cost(INSN_COST);
13463   ins_encode %{
13464     __ orr(as_Register($dst$$reg),
13465            as_Register($src1$$reg),
13466            (unsigned long)($src2$$constant));
13467   %}
13468 
13469   ins_pipe(ialu_reg_imm);
13470 %}
13471 
13472 // Xor Instructions
13473 
13474 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13475   match(Set dst (XorL src1 src2));
13476 
13477   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13478 
13479   ins_cost(INSN_COST);
13480   ins_encode %{
13481     __ eor(as_Register($dst$$reg),
13482            as_Register($src1$$reg),
13483            as_Register($src2$$reg));
13484   %}
13485 
13486   ins_pipe(ialu_reg_reg);
13487 %}
13488 
13489 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13490   match(Set dst (XorL src1 src2));
13491 
13492   ins_cost(INSN_COST);
13493   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13494 
13495   ins_encode %{
13496     __ eor(as_Register($dst$$reg),
13497            as_Register($src1$$reg),
13498            (unsigned long)($src2$$constant));
13499   %}
13500 
13501   ins_pipe(ialu_reg_imm);
13502 %}
13503 
13504 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13505 %{
13506   match(Set dst (ConvI2L src));
13507 
13508   ins_cost(INSN_COST);
13509   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13510   ins_encode %{
13511     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13512   %}
13513   ins_pipe(ialu_reg_shift);
13514 %}
13515 
13516 // this pattern occurs in bigmath arithmetic
13517 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13518 %{
13519   match(Set dst (AndL (ConvI2L src) mask));
13520 
13521   ins_cost(INSN_COST);
13522   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13523   ins_encode %{
13524     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13525   %}
13526 
13527   ins_pipe(ialu_reg_shift);
13528 %}
13529 
13530 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13531   match(Set dst (ConvL2I src));
13532 
13533   ins_cost(INSN_COST);
13534   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13535 
13536   ins_encode %{
13537     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13538   %}
13539 
13540   ins_pipe(ialu_reg);
13541 %}
13542 
13543 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13544 %{
13545   match(Set dst (Conv2B src));
13546   effect(KILL cr);
13547 
13548   format %{
13549     &quot;cmpw $src, zr\n\t&quot;
13550     &quot;cset $dst, ne&quot;
13551   %}
13552 
13553   ins_encode %{
13554     __ cmpw(as_Register($src$$reg), zr);
13555     __ cset(as_Register($dst$$reg), Assembler::NE);
13556   %}
13557 
13558   ins_pipe(ialu_reg);
13559 %}
13560 
13561 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13562 %{
13563   match(Set dst (Conv2B src));
13564   effect(KILL cr);
13565 
13566   format %{
13567     &quot;cmp  $src, zr\n\t&quot;
13568     &quot;cset $dst, ne&quot;
13569   %}
13570 
13571   ins_encode %{
13572     __ cmp(as_Register($src$$reg), zr);
13573     __ cset(as_Register($dst$$reg), Assembler::NE);
13574   %}
13575 
13576   ins_pipe(ialu_reg);
13577 %}
13578 
13579 instruct convD2F_reg(vRegF dst, vRegD src) %{
13580   match(Set dst (ConvD2F src));
13581 
13582   ins_cost(INSN_COST * 5);
13583   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13584 
13585   ins_encode %{
13586     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13587   %}
13588 
13589   ins_pipe(fp_d2f);
13590 %}
13591 
13592 instruct convF2D_reg(vRegD dst, vRegF src) %{
13593   match(Set dst (ConvF2D src));
13594 
13595   ins_cost(INSN_COST * 5);
13596   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13597 
13598   ins_encode %{
13599     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13600   %}
13601 
13602   ins_pipe(fp_f2d);
13603 %}
13604 
13605 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13606   match(Set dst (ConvF2I src));
13607 
13608   ins_cost(INSN_COST * 5);
13609   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13610 
13611   ins_encode %{
13612     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13613   %}
13614 
13615   ins_pipe(fp_f2i);
13616 %}
13617 
13618 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13619   match(Set dst (ConvF2L src));
13620 
13621   ins_cost(INSN_COST * 5);
13622   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13623 
13624   ins_encode %{
13625     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13626   %}
13627 
13628   ins_pipe(fp_f2l);
13629 %}
13630 
13631 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13632   match(Set dst (ConvI2F src));
13633 
13634   ins_cost(INSN_COST * 5);
13635   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13636 
13637   ins_encode %{
13638     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13639   %}
13640 
13641   ins_pipe(fp_i2f);
13642 %}
13643 
13644 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13645   match(Set dst (ConvL2F src));
13646 
13647   ins_cost(INSN_COST * 5);
13648   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13649 
13650   ins_encode %{
13651     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13652   %}
13653 
13654   ins_pipe(fp_l2f);
13655 %}
13656 
13657 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13658   match(Set dst (ConvD2I src));
13659 
13660   ins_cost(INSN_COST * 5);
13661   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13662 
13663   ins_encode %{
13664     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13665   %}
13666 
13667   ins_pipe(fp_d2i);
13668 %}
13669 
13670 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13671   match(Set dst (ConvD2L src));
13672 
13673   ins_cost(INSN_COST * 5);
13674   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13675 
13676   ins_encode %{
13677     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13678   %}
13679 
13680   ins_pipe(fp_d2l);
13681 %}
13682 
13683 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13684   match(Set dst (ConvI2D src));
13685 
13686   ins_cost(INSN_COST * 5);
13687   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13688 
13689   ins_encode %{
13690     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13691   %}
13692 
13693   ins_pipe(fp_i2d);
13694 %}
13695 
13696 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13697   match(Set dst (ConvL2D src));
13698 
13699   ins_cost(INSN_COST * 5);
13700   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13701 
13702   ins_encode %{
13703     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13704   %}
13705 
13706   ins_pipe(fp_l2d);
13707 %}
13708 
13709 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13710 
13711 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13712 
13713   match(Set dst (MoveF2I src));
13714 
13715   effect(DEF dst, USE src);
13716 
13717   ins_cost(4 * INSN_COST);
13718 
13719   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13720 
13721   ins_encode %{
13722     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13723   %}
13724 
13725   ins_pipe(iload_reg_reg);
13726 
13727 %}
13728 
13729 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13730 
13731   match(Set dst (MoveI2F src));
13732 
13733   effect(DEF dst, USE src);
13734 
13735   ins_cost(4 * INSN_COST);
13736 
13737   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13738 
13739   ins_encode %{
13740     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13741   %}
13742 
13743   ins_pipe(pipe_class_memory);
13744 
13745 %}
13746 
13747 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13748 
13749   match(Set dst (MoveD2L src));
13750 
13751   effect(DEF dst, USE src);
13752 
13753   ins_cost(4 * INSN_COST);
13754 
13755   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13756 
13757   ins_encode %{
13758     __ ldr($dst$$Register, Address(sp, $src$$disp));
13759   %}
13760 
13761   ins_pipe(iload_reg_reg);
13762 
13763 %}
13764 
13765 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13766 
13767   match(Set dst (MoveL2D src));
13768 
13769   effect(DEF dst, USE src);
13770 
13771   ins_cost(4 * INSN_COST);
13772 
13773   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13774 
13775   ins_encode %{
13776     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13777   %}
13778 
13779   ins_pipe(pipe_class_memory);
13780 
13781 %}
13782 
13783 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13784 
13785   match(Set dst (MoveF2I src));
13786 
13787   effect(DEF dst, USE src);
13788 
13789   ins_cost(INSN_COST);
13790 
13791   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13792 
13793   ins_encode %{
13794     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13795   %}
13796 
13797   ins_pipe(pipe_class_memory);
13798 
13799 %}
13800 
13801 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13802 
13803   match(Set dst (MoveI2F src));
13804 
13805   effect(DEF dst, USE src);
13806 
13807   ins_cost(INSN_COST);
13808 
13809   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13810 
13811   ins_encode %{
13812     __ strw($src$$Register, Address(sp, $dst$$disp));
13813   %}
13814 
13815   ins_pipe(istore_reg_reg);
13816 
13817 %}
13818 
13819 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13820 
13821   match(Set dst (MoveD2L src));
13822 
13823   effect(DEF dst, USE src);
13824 
13825   ins_cost(INSN_COST);
13826 
13827   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13828 
13829   ins_encode %{
13830     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13831   %}
13832 
13833   ins_pipe(pipe_class_memory);
13834 
13835 %}
13836 
13837 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13838 
13839   match(Set dst (MoveL2D src));
13840 
13841   effect(DEF dst, USE src);
13842 
13843   ins_cost(INSN_COST);
13844 
13845   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13846 
13847   ins_encode %{
13848     __ str($src$$Register, Address(sp, $dst$$disp));
13849   %}
13850 
13851   ins_pipe(istore_reg_reg);
13852 
13853 %}
13854 
13855 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13856 
13857   match(Set dst (MoveF2I src));
13858 
13859   effect(DEF dst, USE src);
13860 
13861   ins_cost(INSN_COST);
13862 
13863   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13864 
13865   ins_encode %{
13866     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13867   %}
13868 
13869   ins_pipe(fp_f2i);
13870 
13871 %}
13872 
13873 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13874 
13875   match(Set dst (MoveI2F src));
13876 
13877   effect(DEF dst, USE src);
13878 
13879   ins_cost(INSN_COST);
13880 
13881   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13882 
13883   ins_encode %{
13884     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13885   %}
13886 
13887   ins_pipe(fp_i2f);
13888 
13889 %}
13890 
13891 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13892 
13893   match(Set dst (MoveD2L src));
13894 
13895   effect(DEF dst, USE src);
13896 
13897   ins_cost(INSN_COST);
13898 
13899   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13900 
13901   ins_encode %{
13902     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13903   %}
13904 
13905   ins_pipe(fp_d2l);
13906 
13907 %}
13908 
13909 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13910 
13911   match(Set dst (MoveL2D src));
13912 
13913   effect(DEF dst, USE src);
13914 
13915   ins_cost(INSN_COST);
13916 
13917   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13918 
13919   ins_encode %{
13920     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13921   %}
13922 
13923   ins_pipe(fp_l2d);
13924 
13925 %}
13926 
13927 // ============================================================================
13928 // clearing of an array
13929 
<a name="10" id="anc10"></a><span class="line-modified">13930 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)</span>
13931 %{
<a name="11" id="anc11"></a><span class="line-modified">13932   match(Set dummy (ClearArray (Binary cnt base) val));</span>
13933   effect(USE_KILL cnt, USE_KILL base);
13934 
13935   ins_cost(4 * INSN_COST);
<a name="12" id="anc12"></a><span class="line-modified">13936   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}</span>

















13937 
13938   ins_encode %{
<a name="13" id="anc13"></a><span class="line-modified">13939     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);</span>
13940   %}
13941 
13942   ins_pipe(pipe_class_memory);
13943 %}
13944 
13945 // ============================================================================
13946 // Overflow Math Instructions
13947 
13948 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13949 %{
13950   match(Set cr (OverflowAddI op1 op2));
13951 
13952   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13953   ins_cost(INSN_COST);
13954   ins_encode %{
13955     __ cmnw($op1$$Register, $op2$$Register);
13956   %}
13957 
13958   ins_pipe(icmp_reg_reg);
13959 %}
13960 
13961 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13962 %{
13963   match(Set cr (OverflowAddI op1 op2));
13964 
13965   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13966   ins_cost(INSN_COST);
13967   ins_encode %{
13968     __ cmnw($op1$$Register, $op2$$constant);
13969   %}
13970 
13971   ins_pipe(icmp_reg_imm);
13972 %}
13973 
13974 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13975 %{
13976   match(Set cr (OverflowAddL op1 op2));
13977 
13978   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13979   ins_cost(INSN_COST);
13980   ins_encode %{
13981     __ cmn($op1$$Register, $op2$$Register);
13982   %}
13983 
13984   ins_pipe(icmp_reg_reg);
13985 %}
13986 
13987 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13988 %{
13989   match(Set cr (OverflowAddL op1 op2));
13990 
13991   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13992   ins_cost(INSN_COST);
13993   ins_encode %{
13994     __ cmn($op1$$Register, $op2$$constant);
13995   %}
13996 
13997   ins_pipe(icmp_reg_imm);
13998 %}
13999 
14000 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14001 %{
14002   match(Set cr (OverflowSubI op1 op2));
14003 
14004   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14005   ins_cost(INSN_COST);
14006   ins_encode %{
14007     __ cmpw($op1$$Register, $op2$$Register);
14008   %}
14009 
14010   ins_pipe(icmp_reg_reg);
14011 %}
14012 
14013 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14014 %{
14015   match(Set cr (OverflowSubI op1 op2));
14016 
14017   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14018   ins_cost(INSN_COST);
14019   ins_encode %{
14020     __ cmpw($op1$$Register, $op2$$constant);
14021   %}
14022 
14023   ins_pipe(icmp_reg_imm);
14024 %}
14025 
14026 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14027 %{
14028   match(Set cr (OverflowSubL op1 op2));
14029 
14030   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14031   ins_cost(INSN_COST);
14032   ins_encode %{
14033     __ cmp($op1$$Register, $op2$$Register);
14034   %}
14035 
14036   ins_pipe(icmp_reg_reg);
14037 %}
14038 
14039 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14040 %{
14041   match(Set cr (OverflowSubL op1 op2));
14042 
14043   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14044   ins_cost(INSN_COST);
14045   ins_encode %{
14046     __ subs(zr, $op1$$Register, $op2$$constant);
14047   %}
14048 
14049   ins_pipe(icmp_reg_imm);
14050 %}
14051 
14052 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14053 %{
14054   match(Set cr (OverflowSubI zero op1));
14055 
14056   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14057   ins_cost(INSN_COST);
14058   ins_encode %{
14059     __ cmpw(zr, $op1$$Register);
14060   %}
14061 
14062   ins_pipe(icmp_reg_imm);
14063 %}
14064 
14065 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14066 %{
14067   match(Set cr (OverflowSubL zero op1));
14068 
14069   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14070   ins_cost(INSN_COST);
14071   ins_encode %{
14072     __ cmp(zr, $op1$$Register);
14073   %}
14074 
14075   ins_pipe(icmp_reg_imm);
14076 %}
14077 
14078 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14079 %{
14080   match(Set cr (OverflowMulI op1 op2));
14081 
14082   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14083             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14084             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14085             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14086             &quot;cmpw  rscratch1, #1&quot; %}
14087   ins_cost(5 * INSN_COST);
14088   ins_encode %{
14089     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14090     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14091     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14092     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14093     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14094   %}
14095 
14096   ins_pipe(pipe_slow);
14097 %}
14098 
14099 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14100 %{
14101   match(If cmp (OverflowMulI op1 op2));
14102   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14103             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14104   effect(USE labl, KILL cr);
14105 
14106   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14107             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14108             &quot;b$cmp   $labl&quot; %}
14109   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14110   ins_encode %{
14111     Label* L = $labl$$label;
14112     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14113     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14114     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14115     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14116   %}
14117 
14118   ins_pipe(pipe_serial);
14119 %}
14120 
14121 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14122 %{
14123   match(Set cr (OverflowMulL op1 op2));
14124 
14125   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14126             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14127             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14128             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14129             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14130             &quot;cmpw  rscratch1, #1&quot; %}
14131   ins_cost(6 * INSN_COST);
14132   ins_encode %{
14133     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14134     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14135     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14136     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14137     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14138     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14139   %}
14140 
14141   ins_pipe(pipe_slow);
14142 %}
14143 
14144 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14145 %{
14146   match(If cmp (OverflowMulL op1 op2));
14147   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14148             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14149   effect(USE labl, KILL cr);
14150 
14151   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14152             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14153             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14154             &quot;b$cmp $labl&quot; %}
14155   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14156   ins_encode %{
14157     Label* L = $labl$$label;
14158     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14159     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14160     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14161     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14162     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14163   %}
14164 
14165   ins_pipe(pipe_serial);
14166 %}
14167 
14168 // ============================================================================
14169 // Compare Instructions
14170 
14171 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14172 %{
14173   match(Set cr (CmpI op1 op2));
14174 
14175   effect(DEF cr, USE op1, USE op2);
14176 
14177   ins_cost(INSN_COST);
14178   format %{ &quot;cmpw  $op1, $op2&quot; %}
14179 
14180   ins_encode(aarch64_enc_cmpw(op1, op2));
14181 
14182   ins_pipe(icmp_reg_reg);
14183 %}
14184 
14185 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14186 %{
14187   match(Set cr (CmpI op1 zero));
14188 
14189   effect(DEF cr, USE op1);
14190 
14191   ins_cost(INSN_COST);
14192   format %{ &quot;cmpw $op1, 0&quot; %}
14193 
14194   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14195 
14196   ins_pipe(icmp_reg_imm);
14197 %}
14198 
14199 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14200 %{
14201   match(Set cr (CmpI op1 op2));
14202 
14203   effect(DEF cr, USE op1);
14204 
14205   ins_cost(INSN_COST);
14206   format %{ &quot;cmpw  $op1, $op2&quot; %}
14207 
14208   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14209 
14210   ins_pipe(icmp_reg_imm);
14211 %}
14212 
14213 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14214 %{
14215   match(Set cr (CmpI op1 op2));
14216 
14217   effect(DEF cr, USE op1);
14218 
14219   ins_cost(INSN_COST * 2);
14220   format %{ &quot;cmpw  $op1, $op2&quot; %}
14221 
14222   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14223 
14224   ins_pipe(icmp_reg_imm);
14225 %}
14226 
14227 // Unsigned compare Instructions; really, same as signed compare
14228 // except it should only be used to feed an If or a CMovI which takes a
14229 // cmpOpU.
14230 
14231 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14232 %{
14233   match(Set cr (CmpU op1 op2));
14234 
14235   effect(DEF cr, USE op1, USE op2);
14236 
14237   ins_cost(INSN_COST);
14238   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14239 
14240   ins_encode(aarch64_enc_cmpw(op1, op2));
14241 
14242   ins_pipe(icmp_reg_reg);
14243 %}
14244 
14245 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14246 %{
14247   match(Set cr (CmpU op1 zero));
14248 
14249   effect(DEF cr, USE op1);
14250 
14251   ins_cost(INSN_COST);
14252   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14253 
14254   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14255 
14256   ins_pipe(icmp_reg_imm);
14257 %}
14258 
14259 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14260 %{
14261   match(Set cr (CmpU op1 op2));
14262 
14263   effect(DEF cr, USE op1);
14264 
14265   ins_cost(INSN_COST);
14266   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14267 
14268   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14269 
14270   ins_pipe(icmp_reg_imm);
14271 %}
14272 
14273 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14274 %{
14275   match(Set cr (CmpU op1 op2));
14276 
14277   effect(DEF cr, USE op1);
14278 
14279   ins_cost(INSN_COST * 2);
14280   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14281 
14282   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14283 
14284   ins_pipe(icmp_reg_imm);
14285 %}
14286 
14287 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14288 %{
14289   match(Set cr (CmpL op1 op2));
14290 
14291   effect(DEF cr, USE op1, USE op2);
14292 
14293   ins_cost(INSN_COST);
14294   format %{ &quot;cmp  $op1, $op2&quot; %}
14295 
14296   ins_encode(aarch64_enc_cmp(op1, op2));
14297 
14298   ins_pipe(icmp_reg_reg);
14299 %}
14300 
14301 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14302 %{
14303   match(Set cr (CmpL op1 zero));
14304 
14305   effect(DEF cr, USE op1);
14306 
14307   ins_cost(INSN_COST);
14308   format %{ &quot;tst  $op1&quot; %}
14309 
14310   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14311 
14312   ins_pipe(icmp_reg_imm);
14313 %}
14314 
14315 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14316 %{
14317   match(Set cr (CmpL op1 op2));
14318 
14319   effect(DEF cr, USE op1);
14320 
14321   ins_cost(INSN_COST);
14322   format %{ &quot;cmp  $op1, $op2&quot; %}
14323 
14324   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14325 
14326   ins_pipe(icmp_reg_imm);
14327 %}
14328 
14329 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14330 %{
14331   match(Set cr (CmpL op1 op2));
14332 
14333   effect(DEF cr, USE op1);
14334 
14335   ins_cost(INSN_COST * 2);
14336   format %{ &quot;cmp  $op1, $op2&quot; %}
14337 
14338   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14339 
14340   ins_pipe(icmp_reg_imm);
14341 %}
14342 
14343 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14344 %{
14345   match(Set cr (CmpUL op1 op2));
14346 
14347   effect(DEF cr, USE op1, USE op2);
14348 
14349   ins_cost(INSN_COST);
14350   format %{ &quot;cmp  $op1, $op2&quot; %}
14351 
14352   ins_encode(aarch64_enc_cmp(op1, op2));
14353 
14354   ins_pipe(icmp_reg_reg);
14355 %}
14356 
14357 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14358 %{
14359   match(Set cr (CmpUL op1 zero));
14360 
14361   effect(DEF cr, USE op1);
14362 
14363   ins_cost(INSN_COST);
14364   format %{ &quot;tst  $op1&quot; %}
14365 
14366   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14367 
14368   ins_pipe(icmp_reg_imm);
14369 %}
14370 
14371 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14372 %{
14373   match(Set cr (CmpUL op1 op2));
14374 
14375   effect(DEF cr, USE op1);
14376 
14377   ins_cost(INSN_COST);
14378   format %{ &quot;cmp  $op1, $op2&quot; %}
14379 
14380   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14381 
14382   ins_pipe(icmp_reg_imm);
14383 %}
14384 
14385 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14386 %{
14387   match(Set cr (CmpUL op1 op2));
14388 
14389   effect(DEF cr, USE op1);
14390 
14391   ins_cost(INSN_COST * 2);
14392   format %{ &quot;cmp  $op1, $op2&quot; %}
14393 
14394   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14395 
14396   ins_pipe(icmp_reg_imm);
14397 %}
14398 
14399 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14400 %{
14401   match(Set cr (CmpP op1 op2));
14402 
14403   effect(DEF cr, USE op1, USE op2);
14404 
14405   ins_cost(INSN_COST);
14406   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14407 
14408   ins_encode(aarch64_enc_cmpp(op1, op2));
14409 
14410   ins_pipe(icmp_reg_reg);
14411 %}
14412 
14413 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14414 %{
14415   match(Set cr (CmpN op1 op2));
14416 
14417   effect(DEF cr, USE op1, USE op2);
14418 
14419   ins_cost(INSN_COST);
14420   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14421 
14422   ins_encode(aarch64_enc_cmpn(op1, op2));
14423 
14424   ins_pipe(icmp_reg_reg);
14425 %}
14426 
14427 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14428 %{
14429   match(Set cr (CmpP op1 zero));
14430 
14431   effect(DEF cr, USE op1, USE zero);
14432 
14433   ins_cost(INSN_COST);
14434   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14435 
14436   ins_encode(aarch64_enc_testp(op1));
14437 
14438   ins_pipe(icmp_reg_imm);
14439 %}
14440 
14441 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14442 %{
14443   match(Set cr (CmpN op1 zero));
14444 
14445   effect(DEF cr, USE op1, USE zero);
14446 
14447   ins_cost(INSN_COST);
14448   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14449 
14450   ins_encode(aarch64_enc_testn(op1));
14451 
14452   ins_pipe(icmp_reg_imm);
14453 %}
14454 
14455 // FP comparisons
14456 //
14457 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14458 // using normal cmpOp. See declaration of rFlagsReg for details.
14459 
14460 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14461 %{
14462   match(Set cr (CmpF src1 src2));
14463 
14464   ins_cost(3 * INSN_COST);
14465   format %{ &quot;fcmps $src1, $src2&quot; %}
14466 
14467   ins_encode %{
14468     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14469   %}
14470 
14471   ins_pipe(pipe_class_compare);
14472 %}
14473 
14474 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14475 %{
14476   match(Set cr (CmpF src1 src2));
14477 
14478   ins_cost(3 * INSN_COST);
14479   format %{ &quot;fcmps $src1, 0.0&quot; %}
14480 
14481   ins_encode %{
14482     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14483   %}
14484 
14485   ins_pipe(pipe_class_compare);
14486 %}
14487 // FROM HERE
14488 
14489 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14490 %{
14491   match(Set cr (CmpD src1 src2));
14492 
14493   ins_cost(3 * INSN_COST);
14494   format %{ &quot;fcmpd $src1, $src2&quot; %}
14495 
14496   ins_encode %{
14497     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14498   %}
14499 
14500   ins_pipe(pipe_class_compare);
14501 %}
14502 
14503 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14504 %{
14505   match(Set cr (CmpD src1 src2));
14506 
14507   ins_cost(3 * INSN_COST);
14508   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14509 
14510   ins_encode %{
14511     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14512   %}
14513 
14514   ins_pipe(pipe_class_compare);
14515 %}
14516 
14517 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14518 %{
14519   match(Set dst (CmpF3 src1 src2));
14520   effect(KILL cr);
14521 
14522   ins_cost(5 * INSN_COST);
14523   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14524             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14525             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14526   %}
14527 
14528   ins_encode %{
14529     Label done;
14530     FloatRegister s1 = as_FloatRegister($src1$$reg);
14531     FloatRegister s2 = as_FloatRegister($src2$$reg);
14532     Register d = as_Register($dst$$reg);
14533     __ fcmps(s1, s2);
14534     // installs 0 if EQ else -1
14535     __ csinvw(d, zr, zr, Assembler::EQ);
14536     // keeps -1 if less or unordered else installs 1
14537     __ csnegw(d, d, d, Assembler::LT);
14538     __ bind(done);
14539   %}
14540 
14541   ins_pipe(pipe_class_default);
14542 
14543 %}
14544 
14545 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14546 %{
14547   match(Set dst (CmpD3 src1 src2));
14548   effect(KILL cr);
14549 
14550   ins_cost(5 * INSN_COST);
14551   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14552             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14553             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14554   %}
14555 
14556   ins_encode %{
14557     Label done;
14558     FloatRegister s1 = as_FloatRegister($src1$$reg);
14559     FloatRegister s2 = as_FloatRegister($src2$$reg);
14560     Register d = as_Register($dst$$reg);
14561     __ fcmpd(s1, s2);
14562     // installs 0 if EQ else -1
14563     __ csinvw(d, zr, zr, Assembler::EQ);
14564     // keeps -1 if less or unordered else installs 1
14565     __ csnegw(d, d, d, Assembler::LT);
14566     __ bind(done);
14567   %}
14568   ins_pipe(pipe_class_default);
14569 
14570 %}
14571 
14572 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14573 %{
14574   match(Set dst (CmpF3 src1 zero));
14575   effect(KILL cr);
14576 
14577   ins_cost(5 * INSN_COST);
14578   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14579             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14580             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14581   %}
14582 
14583   ins_encode %{
14584     Label done;
14585     FloatRegister s1 = as_FloatRegister($src1$$reg);
14586     Register d = as_Register($dst$$reg);
14587     __ fcmps(s1, 0.0);
14588     // installs 0 if EQ else -1
14589     __ csinvw(d, zr, zr, Assembler::EQ);
14590     // keeps -1 if less or unordered else installs 1
14591     __ csnegw(d, d, d, Assembler::LT);
14592     __ bind(done);
14593   %}
14594 
14595   ins_pipe(pipe_class_default);
14596 
14597 %}
14598 
14599 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14600 %{
14601   match(Set dst (CmpD3 src1 zero));
14602   effect(KILL cr);
14603 
14604   ins_cost(5 * INSN_COST);
14605   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14606             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14607             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14608   %}
14609 
14610   ins_encode %{
14611     Label done;
14612     FloatRegister s1 = as_FloatRegister($src1$$reg);
14613     Register d = as_Register($dst$$reg);
14614     __ fcmpd(s1, 0.0);
14615     // installs 0 if EQ else -1
14616     __ csinvw(d, zr, zr, Assembler::EQ);
14617     // keeps -1 if less or unordered else installs 1
14618     __ csnegw(d, d, d, Assembler::LT);
14619     __ bind(done);
14620   %}
14621   ins_pipe(pipe_class_default);
14622 
14623 %}
14624 
14625 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14626 %{
14627   match(Set dst (CmpLTMask p q));
14628   effect(KILL cr);
14629 
14630   ins_cost(3 * INSN_COST);
14631 
14632   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14633             &quot;csetw $dst, lt\n\t&quot;
14634             &quot;subw $dst, zr, $dst&quot;
14635   %}
14636 
14637   ins_encode %{
14638     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14639     __ csetw(as_Register($dst$$reg), Assembler::LT);
14640     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14641   %}
14642 
14643   ins_pipe(ialu_reg_reg);
14644 %}
14645 
14646 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14647 %{
14648   match(Set dst (CmpLTMask src zero));
14649   effect(KILL cr);
14650 
14651   ins_cost(INSN_COST);
14652 
14653   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14654 
14655   ins_encode %{
14656     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14657   %}
14658 
14659   ins_pipe(ialu_reg_shift);
14660 %}
14661 
14662 // ============================================================================
14663 // Max and Min
14664 
14665 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14666 %{
14667   effect( DEF dst, USE src1, USE src2, USE cr );
14668 
14669   ins_cost(INSN_COST * 2);
14670   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14671 
14672   ins_encode %{
14673     __ cselw(as_Register($dst$$reg),
14674              as_Register($src1$$reg),
14675              as_Register($src2$$reg),
14676              Assembler::LT);
14677   %}
14678 
14679   ins_pipe(icond_reg_reg);
14680 %}
14681 
14682 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14683 %{
14684   match(Set dst (MinI src1 src2));
14685   ins_cost(INSN_COST * 3);
14686 
14687   expand %{
14688     rFlagsReg cr;
14689     compI_reg_reg(cr, src1, src2);
14690     cmovI_reg_reg_lt(dst, src1, src2, cr);
14691   %}
14692 
14693 %}
14694 // FROM HERE
14695 
14696 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14697 %{
14698   effect( DEF dst, USE src1, USE src2, USE cr );
14699 
14700   ins_cost(INSN_COST * 2);
14701   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14702 
14703   ins_encode %{
14704     __ cselw(as_Register($dst$$reg),
14705              as_Register($src1$$reg),
14706              as_Register($src2$$reg),
14707              Assembler::GT);
14708   %}
14709 
14710   ins_pipe(icond_reg_reg);
14711 %}
14712 
14713 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14714 %{
14715   match(Set dst (MaxI src1 src2));
14716   ins_cost(INSN_COST * 3);
14717   expand %{
14718     rFlagsReg cr;
14719     compI_reg_reg(cr, src1, src2);
14720     cmovI_reg_reg_gt(dst, src1, src2, cr);
14721   %}
14722 %}
14723 
14724 // ============================================================================
14725 // Branch Instructions
14726 
14727 // Direct Branch.
14728 instruct branch(label lbl)
14729 %{
14730   match(Goto);
14731 
14732   effect(USE lbl);
14733 
14734   ins_cost(BRANCH_COST);
14735   format %{ &quot;b  $lbl&quot; %}
14736 
14737   ins_encode(aarch64_enc_b(lbl));
14738 
14739   ins_pipe(pipe_branch);
14740 %}
14741 
14742 // Conditional Near Branch
14743 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14744 %{
14745   // Same match rule as `branchConFar&#39;.
14746   match(If cmp cr);
14747 
14748   effect(USE lbl);
14749 
14750   ins_cost(BRANCH_COST);
14751   // If set to 1 this indicates that the current instruction is a
14752   // short variant of a long branch. This avoids using this
14753   // instruction in first-pass matching. It will then only be used in
14754   // the `Shorten_branches&#39; pass.
14755   // ins_short_branch(1);
14756   format %{ &quot;b$cmp  $lbl&quot; %}
14757 
14758   ins_encode(aarch64_enc_br_con(cmp, lbl));
14759 
14760   ins_pipe(pipe_branch_cond);
14761 %}
14762 
14763 // Conditional Near Branch Unsigned
14764 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14765 %{
14766   // Same match rule as `branchConFar&#39;.
14767   match(If cmp cr);
14768 
14769   effect(USE lbl);
14770 
14771   ins_cost(BRANCH_COST);
14772   // If set to 1 this indicates that the current instruction is a
14773   // short variant of a long branch. This avoids using this
14774   // instruction in first-pass matching. It will then only be used in
14775   // the `Shorten_branches&#39; pass.
14776   // ins_short_branch(1);
14777   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14778 
14779   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14780 
14781   ins_pipe(pipe_branch_cond);
14782 %}
14783 
14784 // Make use of CBZ and CBNZ.  These instructions, as well as being
14785 // shorter than (cmp; branch), have the additional benefit of not
14786 // killing the flags.
14787 
14788 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14789   match(If cmp (CmpI op1 op2));
14790   effect(USE labl);
14791 
14792   ins_cost(BRANCH_COST);
14793   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14794   ins_encode %{
14795     Label* L = $labl$$label;
14796     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14797     if (cond == Assembler::EQ)
14798       __ cbzw($op1$$Register, *L);
14799     else
14800       __ cbnzw($op1$$Register, *L);
14801   %}
14802   ins_pipe(pipe_cmp_branch);
14803 %}
14804 
14805 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14806   match(If cmp (CmpL op1 op2));
14807   effect(USE labl);
14808 
14809   ins_cost(BRANCH_COST);
14810   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14811   ins_encode %{
14812     Label* L = $labl$$label;
14813     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14814     if (cond == Assembler::EQ)
14815       __ cbz($op1$$Register, *L);
14816     else
14817       __ cbnz($op1$$Register, *L);
14818   %}
14819   ins_pipe(pipe_cmp_branch);
14820 %}
14821 
14822 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14823   match(If cmp (CmpP op1 op2));
14824   effect(USE labl);
14825 
14826   ins_cost(BRANCH_COST);
14827   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14828   ins_encode %{
14829     Label* L = $labl$$label;
14830     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14831     if (cond == Assembler::EQ)
14832       __ cbz($op1$$Register, *L);
14833     else
14834       __ cbnz($op1$$Register, *L);
14835   %}
14836   ins_pipe(pipe_cmp_branch);
14837 %}
14838 
14839 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14840   match(If cmp (CmpN op1 op2));
14841   effect(USE labl);
14842 
14843   ins_cost(BRANCH_COST);
14844   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14845   ins_encode %{
14846     Label* L = $labl$$label;
14847     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14848     if (cond == Assembler::EQ)
14849       __ cbzw($op1$$Register, *L);
14850     else
14851       __ cbnzw($op1$$Register, *L);
14852   %}
14853   ins_pipe(pipe_cmp_branch);
14854 %}
14855 
14856 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14857   match(If cmp (CmpP (DecodeN oop) zero));
14858   effect(USE labl);
14859 
14860   ins_cost(BRANCH_COST);
14861   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14862   ins_encode %{
14863     Label* L = $labl$$label;
14864     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14865     if (cond == Assembler::EQ)
14866       __ cbzw($oop$$Register, *L);
14867     else
14868       __ cbnzw($oop$$Register, *L);
14869   %}
14870   ins_pipe(pipe_cmp_branch);
14871 %}
14872 
14873 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14874   match(If cmp (CmpU op1 op2));
14875   effect(USE labl);
14876 
14877   ins_cost(BRANCH_COST);
14878   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14879   ins_encode %{
14880     Label* L = $labl$$label;
14881     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14882     if (cond == Assembler::EQ || cond == Assembler::LS)
14883       __ cbzw($op1$$Register, *L);
14884     else
14885       __ cbnzw($op1$$Register, *L);
14886   %}
14887   ins_pipe(pipe_cmp_branch);
14888 %}
14889 
14890 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14891   match(If cmp (CmpUL op1 op2));
14892   effect(USE labl);
14893 
14894   ins_cost(BRANCH_COST);
14895   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14896   ins_encode %{
14897     Label* L = $labl$$label;
14898     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14899     if (cond == Assembler::EQ || cond == Assembler::LS)
14900       __ cbz($op1$$Register, *L);
14901     else
14902       __ cbnz($op1$$Register, *L);
14903   %}
14904   ins_pipe(pipe_cmp_branch);
14905 %}
14906 
14907 // Test bit and Branch
14908 
14909 // Patterns for short (&lt; 32KiB) variants
14910 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14911   match(If cmp (CmpL op1 op2));
14912   effect(USE labl);
14913 
14914   ins_cost(BRANCH_COST);
14915   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14916   ins_encode %{
14917     Label* L = $labl$$label;
14918     Assembler::Condition cond =
14919       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14920     __ tbr(cond, $op1$$Register, 63, *L);
14921   %}
14922   ins_pipe(pipe_cmp_branch);
14923   ins_short_branch(1);
14924 %}
14925 
14926 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14927   match(If cmp (CmpI op1 op2));
14928   effect(USE labl);
14929 
14930   ins_cost(BRANCH_COST);
14931   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14932   ins_encode %{
14933     Label* L = $labl$$label;
14934     Assembler::Condition cond =
14935       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14936     __ tbr(cond, $op1$$Register, 31, *L);
14937   %}
14938   ins_pipe(pipe_cmp_branch);
14939   ins_short_branch(1);
14940 %}
14941 
14942 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14943   match(If cmp (CmpL (AndL op1 op2) op3));
14944   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14945   effect(USE labl);
14946 
14947   ins_cost(BRANCH_COST);
14948   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14949   ins_encode %{
14950     Label* L = $labl$$label;
14951     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14952     int bit = exact_log2_long($op2$$constant);
14953     __ tbr(cond, $op1$$Register, bit, *L);
14954   %}
14955   ins_pipe(pipe_cmp_branch);
14956   ins_short_branch(1);
14957 %}
14958 
14959 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14960   match(If cmp (CmpI (AndI op1 op2) op3));
14961   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14962   effect(USE labl);
14963 
14964   ins_cost(BRANCH_COST);
14965   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14966   ins_encode %{
14967     Label* L = $labl$$label;
14968     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14969     int bit = exact_log2((juint)$op2$$constant);
14970     __ tbr(cond, $op1$$Register, bit, *L);
14971   %}
14972   ins_pipe(pipe_cmp_branch);
14973   ins_short_branch(1);
14974 %}
14975 
14976 // And far variants
14977 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14978   match(If cmp (CmpL op1 op2));
14979   effect(USE labl);
14980 
14981   ins_cost(BRANCH_COST);
14982   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14983   ins_encode %{
14984     Label* L = $labl$$label;
14985     Assembler::Condition cond =
14986       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14987     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14988   %}
14989   ins_pipe(pipe_cmp_branch);
14990 %}
14991 
14992 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14993   match(If cmp (CmpI op1 op2));
14994   effect(USE labl);
14995 
14996   ins_cost(BRANCH_COST);
14997   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14998   ins_encode %{
14999     Label* L = $labl$$label;
15000     Assembler::Condition cond =
15001       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15002     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15003   %}
15004   ins_pipe(pipe_cmp_branch);
15005 %}
15006 
15007 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15008   match(If cmp (CmpL (AndL op1 op2) op3));
15009   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15010   effect(USE labl);
15011 
15012   ins_cost(BRANCH_COST);
15013   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15014   ins_encode %{
15015     Label* L = $labl$$label;
15016     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15017     int bit = exact_log2_long($op2$$constant);
15018     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15019   %}
15020   ins_pipe(pipe_cmp_branch);
15021 %}
15022 
15023 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15024   match(If cmp (CmpI (AndI op1 op2) op3));
15025   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15026   effect(USE labl);
15027 
15028   ins_cost(BRANCH_COST);
15029   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15030   ins_encode %{
15031     Label* L = $labl$$label;
15032     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15033     int bit = exact_log2((juint)$op2$$constant);
15034     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15035   %}
15036   ins_pipe(pipe_cmp_branch);
15037 %}
15038 
15039 // Test bits
15040 
15041 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15042   match(Set cr (CmpL (AndL op1 op2) op3));
15043   predicate(Assembler::operand_valid_for_logical_immediate
15044             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15045 
15046   ins_cost(INSN_COST);
15047   format %{ &quot;tst $op1, $op2 # long&quot; %}
15048   ins_encode %{
15049     __ tst($op1$$Register, $op2$$constant);
15050   %}
15051   ins_pipe(ialu_reg_reg);
15052 %}
15053 
15054 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15055   match(Set cr (CmpI (AndI op1 op2) op3));
15056   predicate(Assembler::operand_valid_for_logical_immediate
15057             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15058 
15059   ins_cost(INSN_COST);
15060   format %{ &quot;tst $op1, $op2 # int&quot; %}
15061   ins_encode %{
15062     __ tstw($op1$$Register, $op2$$constant);
15063   %}
15064   ins_pipe(ialu_reg_reg);
15065 %}
15066 
15067 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15068   match(Set cr (CmpL (AndL op1 op2) op3));
15069 
15070   ins_cost(INSN_COST);
15071   format %{ &quot;tst $op1, $op2 # long&quot; %}
15072   ins_encode %{
15073     __ tst($op1$$Register, $op2$$Register);
15074   %}
15075   ins_pipe(ialu_reg_reg);
15076 %}
15077 
15078 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15079   match(Set cr (CmpI (AndI op1 op2) op3));
15080 
15081   ins_cost(INSN_COST);
15082   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15083   ins_encode %{
15084     __ tstw($op1$$Register, $op2$$Register);
15085   %}
15086   ins_pipe(ialu_reg_reg);
15087 %}
15088 
15089 
15090 // Conditional Far Branch
15091 // Conditional Far Branch Unsigned
15092 // TODO: fixme
15093 
15094 // counted loop end branch near
15095 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15096 %{
15097   match(CountedLoopEnd cmp cr);
15098 
15099   effect(USE lbl);
15100 
15101   ins_cost(BRANCH_COST);
15102   // short variant.
15103   // ins_short_branch(1);
15104   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15105 
15106   ins_encode(aarch64_enc_br_con(cmp, lbl));
15107 
15108   ins_pipe(pipe_branch);
15109 %}
15110 
15111 // counted loop end branch near Unsigned
15112 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15113 %{
15114   match(CountedLoopEnd cmp cr);
15115 
15116   effect(USE lbl);
15117 
15118   ins_cost(BRANCH_COST);
15119   // short variant.
15120   // ins_short_branch(1);
15121   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15122 
15123   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15124 
15125   ins_pipe(pipe_branch);
15126 %}
15127 
15128 // counted loop end branch far
15129 // counted loop end branch far unsigned
15130 // TODO: fixme
15131 
15132 // ============================================================================
15133 // inlined locking and unlocking
15134 
15135 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15136 %{
15137   match(Set cr (FastLock object box));
15138   effect(TEMP tmp, TEMP tmp2);
15139 
15140   // TODO
15141   // identify correct cost
15142   ins_cost(5 * INSN_COST);
15143   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15144 
15145   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15146 
15147   ins_pipe(pipe_serial);
15148 %}
15149 
15150 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15151 %{
15152   match(Set cr (FastUnlock object box));
15153   effect(TEMP tmp, TEMP tmp2);
15154 
15155   ins_cost(5 * INSN_COST);
15156   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15157 
15158   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15159 
15160   ins_pipe(pipe_serial);
15161 %}
15162 
15163 
15164 // ============================================================================
15165 // Safepoint Instructions
15166 
15167 // TODO
15168 // provide a near and far version of this code
15169 
15170 instruct safePoint(rFlagsReg cr, iRegP poll)
15171 %{
15172   match(SafePoint poll);
15173   effect(KILL cr);
15174 
15175   format %{
15176     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15177   %}
15178   ins_encode %{
15179     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15180   %}
15181   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15182 %}
15183 
15184 
15185 // ============================================================================
15186 // Procedure Call/Return Instructions
15187 
15188 // Call Java Static Instruction
15189 
15190 instruct CallStaticJavaDirect(method meth)
15191 %{
15192   match(CallStaticJava);
15193 
15194   effect(USE meth);
15195 
15196   ins_cost(CALL_COST);
15197 
15198   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15199 
15200   ins_encode( aarch64_enc_java_static_call(meth),
15201               aarch64_enc_call_epilog );
15202 
15203   ins_pipe(pipe_class_call);
15204 %}
15205 
15206 // TO HERE
15207 
15208 // Call Java Dynamic Instruction
15209 instruct CallDynamicJavaDirect(method meth)
15210 %{
15211   match(CallDynamicJava);
15212 
15213   effect(USE meth);
15214 
15215   ins_cost(CALL_COST);
15216 
15217   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15218 
15219   ins_encode( aarch64_enc_java_dynamic_call(meth),
15220                aarch64_enc_call_epilog );
15221 
15222   ins_pipe(pipe_class_call);
15223 %}
15224 
15225 // Call Runtime Instruction
15226 
15227 instruct CallRuntimeDirect(method meth)
15228 %{
15229   match(CallRuntime);
15230 
15231   effect(USE meth);
15232 
15233   ins_cost(CALL_COST);
15234 
15235   format %{ &quot;CALL, runtime $meth&quot; %}
15236 
15237   ins_encode( aarch64_enc_java_to_runtime(meth) );
15238 
15239   ins_pipe(pipe_class_call);
15240 %}
15241 
15242 // Call Runtime Instruction
15243 
15244 instruct CallLeafDirect(method meth)
15245 %{
15246   match(CallLeaf);
15247 
15248   effect(USE meth);
15249 
15250   ins_cost(CALL_COST);
15251 
15252   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15253 
15254   ins_encode( aarch64_enc_java_to_runtime(meth) );
15255 
15256   ins_pipe(pipe_class_call);
15257 %}
15258 
15259 // Call Runtime Instruction
15260 
15261 instruct CallLeafNoFPDirect(method meth)
15262 %{
15263   match(CallLeafNoFP);
15264 
15265   effect(USE meth);
15266 
15267   ins_cost(CALL_COST);
15268 
15269   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15270 
15271   ins_encode( aarch64_enc_java_to_runtime(meth) );
15272 
15273   ins_pipe(pipe_class_call);
15274 %}
15275 
15276 // Tail Call; Jump from runtime stub to Java code.
15277 // Also known as an &#39;interprocedural jump&#39;.
15278 // Target of jump will eventually return to caller.
15279 // TailJump below removes the return address.
15280 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15281 %{
15282   match(TailCall jump_target method_oop);
15283 
15284   ins_cost(CALL_COST);
15285 
15286   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15287 
15288   ins_encode(aarch64_enc_tail_call(jump_target));
15289 
15290   ins_pipe(pipe_class_call);
15291 %}
15292 
15293 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15294 %{
15295   match(TailJump jump_target ex_oop);
15296 
15297   ins_cost(CALL_COST);
15298 
15299   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15300 
15301   ins_encode(aarch64_enc_tail_jmp(jump_target));
15302 
15303   ins_pipe(pipe_class_call);
15304 %}
15305 
15306 // Create exception oop: created by stack-crawling runtime code.
15307 // Created exception is now available to this handler, and is setup
15308 // just prior to jumping to this handler. No code emitted.
15309 // TODO check
15310 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15311 instruct CreateException(iRegP_R0 ex_oop)
15312 %{
15313   match(Set ex_oop (CreateEx));
15314 
15315   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15316 
15317   size(0);
15318 
15319   ins_encode( /*empty*/ );
15320 
15321   ins_pipe(pipe_class_empty);
15322 %}
15323 
15324 // Rethrow exception: The exception oop will come in the first
15325 // argument position. Then JUMP (not call) to the rethrow stub code.
15326 instruct RethrowException() %{
15327   match(Rethrow);
15328   ins_cost(CALL_COST);
15329 
15330   format %{ &quot;b rethrow_stub&quot; %}
15331 
15332   ins_encode( aarch64_enc_rethrow() );
15333 
15334   ins_pipe(pipe_class_call);
15335 %}
15336 
15337 
15338 // Return Instruction
15339 // epilog node loads ret address into lr as part of frame pop
15340 instruct Ret()
15341 %{
15342   match(Return);
15343 
15344   format %{ &quot;ret\t// return register&quot; %}
15345 
15346   ins_encode( aarch64_enc_ret() );
15347 
15348   ins_pipe(pipe_branch);
15349 %}
15350 
15351 // Die now.
15352 instruct ShouldNotReachHere() %{
15353   match(Halt);
15354 
15355   ins_cost(CALL_COST);
15356   format %{ &quot;ShouldNotReachHere&quot; %}
15357 
15358   ins_encode %{
15359     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15360     // return true
15361     __ dpcs1(0xdead + 1);
15362   %}
15363 
15364   ins_pipe(pipe_class_default);
15365 %}
15366 
15367 // ============================================================================
15368 // Partial Subtype Check
15369 //
15370 // superklass array for an instance of the superklass.  Set a hidden
15371 // internal cache on a hit (cache is checked with exposed code in
15372 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15373 // encoding ALSO sets flags.
15374 
15375 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15376 %{
15377   match(Set result (PartialSubtypeCheck sub super));
15378   effect(KILL cr, KILL temp);
15379 
15380   ins_cost(1100);  // slightly larger than the next version
15381   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15382 
15383   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15384 
15385   opcode(0x1); // Force zero of result reg on hit
15386 
15387   ins_pipe(pipe_class_memory);
15388 %}
15389 
15390 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15391 %{
15392   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15393   effect(KILL temp, KILL result);
15394 
15395   ins_cost(1100);  // slightly larger than the next version
15396   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15397 
15398   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15399 
15400   opcode(0x0); // Don&#39;t zero result reg on hit
15401 
15402   ins_pipe(pipe_class_memory);
15403 %}
15404 
15405 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15406                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15407 %{
15408   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15409   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15410   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15411 
15412   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15413   ins_encode %{
15414     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15415     __ string_compare($str1$$Register, $str2$$Register,
15416                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15417                       $tmp1$$Register, $tmp2$$Register,
15418                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15419   %}
15420   ins_pipe(pipe_class_memory);
15421 %}
15422 
15423 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15424                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15425 %{
15426   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15427   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15428   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15429 
15430   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15431   ins_encode %{
15432     __ string_compare($str1$$Register, $str2$$Register,
15433                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15434                       $tmp1$$Register, $tmp2$$Register,
15435                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15436   %}
15437   ins_pipe(pipe_class_memory);
15438 %}
15439 
15440 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15441                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15442                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15443 %{
15444   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15445   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15446   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15447          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15448 
15449   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15450   ins_encode %{
15451     __ string_compare($str1$$Register, $str2$$Register,
15452                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15453                       $tmp1$$Register, $tmp2$$Register,
15454                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15455                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15456   %}
15457   ins_pipe(pipe_class_memory);
15458 %}
15459 
15460 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15461                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15462                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15463 %{
15464   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15465   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15466   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15467          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15468 
15469   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15470   ins_encode %{
15471     __ string_compare($str1$$Register, $str2$$Register,
15472                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15473                       $tmp1$$Register, $tmp2$$Register,
15474                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15475                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15476   %}
15477   ins_pipe(pipe_class_memory);
15478 %}
15479 
15480 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15481        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15482        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15483 %{
15484   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15485   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15486   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15487          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15488   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15489 
15490   ins_encode %{
15491     __ string_indexof($str1$$Register, $str2$$Register,
15492                       $cnt1$$Register, $cnt2$$Register,
15493                       $tmp1$$Register, $tmp2$$Register,
15494                       $tmp3$$Register, $tmp4$$Register,
15495                       $tmp5$$Register, $tmp6$$Register,
15496                       -1, $result$$Register, StrIntrinsicNode::UU);
15497   %}
15498   ins_pipe(pipe_class_memory);
15499 %}
15500 
15501 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15502        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15503        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15504 %{
15505   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15506   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15507   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15508          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15509   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15510 
15511   ins_encode %{
15512     __ string_indexof($str1$$Register, $str2$$Register,
15513                       $cnt1$$Register, $cnt2$$Register,
15514                       $tmp1$$Register, $tmp2$$Register,
15515                       $tmp3$$Register, $tmp4$$Register,
15516                       $tmp5$$Register, $tmp6$$Register,
15517                       -1, $result$$Register, StrIntrinsicNode::LL);
15518   %}
15519   ins_pipe(pipe_class_memory);
15520 %}
15521 
15522 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15523        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15524        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15525 %{
15526   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15527   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15528   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15529          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15530   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15531 
15532   ins_encode %{
15533     __ string_indexof($str1$$Register, $str2$$Register,
15534                       $cnt1$$Register, $cnt2$$Register,
15535                       $tmp1$$Register, $tmp2$$Register,
15536                       $tmp3$$Register, $tmp4$$Register,
15537                       $tmp5$$Register, $tmp6$$Register,
15538                       -1, $result$$Register, StrIntrinsicNode::UL);
15539   %}
15540   ins_pipe(pipe_class_memory);
15541 %}
15542 
15543 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15544                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15545                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15546 %{
15547   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15548   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15549   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15550          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15551   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15552 
15553   ins_encode %{
15554     int icnt2 = (int)$int_cnt2$$constant;
15555     __ string_indexof($str1$$Register, $str2$$Register,
15556                       $cnt1$$Register, zr,
15557                       $tmp1$$Register, $tmp2$$Register,
15558                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15559                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15560   %}
15561   ins_pipe(pipe_class_memory);
15562 %}
15563 
15564 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15565                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15566                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15567 %{
15568   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15569   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15570   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15571          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15572   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15573 
15574   ins_encode %{
15575     int icnt2 = (int)$int_cnt2$$constant;
15576     __ string_indexof($str1$$Register, $str2$$Register,
15577                       $cnt1$$Register, zr,
15578                       $tmp1$$Register, $tmp2$$Register,
15579                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15580                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15581   %}
15582   ins_pipe(pipe_class_memory);
15583 %}
15584 
15585 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15586                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15587                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15588 %{
15589   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15590   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15591   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15592          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15593   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15594 
15595   ins_encode %{
15596     int icnt2 = (int)$int_cnt2$$constant;
15597     __ string_indexof($str1$$Register, $str2$$Register,
15598                       $cnt1$$Register, zr,
15599                       $tmp1$$Register, $tmp2$$Register,
15600                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15601                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15602   %}
15603   ins_pipe(pipe_class_memory);
15604 %}
15605 
15606 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15607                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15608                               iRegINoSp tmp3, rFlagsReg cr)
15609 %{
15610   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15611   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15612          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15613 
15614   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15615 
15616   ins_encode %{
15617     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15618                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15619                            $tmp3$$Register);
15620   %}
15621   ins_pipe(pipe_class_memory);
15622 %}
15623 
15624 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15625                         iRegI_R0 result, rFlagsReg cr)
15626 %{
15627   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15628   match(Set result (StrEquals (Binary str1 str2) cnt));
15629   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15630 
15631   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15632   ins_encode %{
15633     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15634     __ string_equals($str1$$Register, $str2$$Register,
15635                      $result$$Register, $cnt$$Register, 1);
15636   %}
15637   ins_pipe(pipe_class_memory);
15638 %}
15639 
15640 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15641                         iRegI_R0 result, rFlagsReg cr)
15642 %{
15643   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15644   match(Set result (StrEquals (Binary str1 str2) cnt));
15645   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15646 
15647   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15648   ins_encode %{
15649     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15650     __ string_equals($str1$$Register, $str2$$Register,
15651                      $result$$Register, $cnt$$Register, 2);
15652   %}
15653   ins_pipe(pipe_class_memory);
15654 %}
15655 
15656 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15657                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15658                        iRegP_R10 tmp, rFlagsReg cr)
15659 %{
15660   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15661   match(Set result (AryEq ary1 ary2));
15662   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15663 
15664   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15665   ins_encode %{
15666     __ arrays_equals($ary1$$Register, $ary2$$Register,
15667                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15668                      $result$$Register, $tmp$$Register, 1);
15669     %}
15670   ins_pipe(pipe_class_memory);
15671 %}
15672 
15673 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15674                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15675                        iRegP_R10 tmp, rFlagsReg cr)
15676 %{
15677   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15678   match(Set result (AryEq ary1 ary2));
15679   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15680 
15681   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15682   ins_encode %{
15683     __ arrays_equals($ary1$$Register, $ary2$$Register,
15684                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15685                      $result$$Register, $tmp$$Register, 2);
15686   %}
15687   ins_pipe(pipe_class_memory);
15688 %}
15689 
15690 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15691 %{
15692   match(Set result (HasNegatives ary1 len));
15693   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15694   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15695   ins_encode %{
15696     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15697   %}
15698   ins_pipe( pipe_slow );
15699 %}
15700 
15701 // fast char[] to byte[] compression
15702 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15703                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15704                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15705                          iRegI_R0 result, rFlagsReg cr)
15706 %{
15707   match(Set result (StrCompressedCopy src (Binary dst len)));
15708   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15709 
15710   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15711   ins_encode %{
15712     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15713                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15714                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15715                            $result$$Register);
15716   %}
15717   ins_pipe( pipe_slow );
15718 %}
15719 
15720 // fast byte[] to char[] inflation
15721 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15722                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15723 %{
15724   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15725   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15726 
15727   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15728   ins_encode %{
15729     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15730                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15731   %}
15732   ins_pipe(pipe_class_memory);
15733 %}
15734 
15735 // encode char[] to byte[] in ISO_8859_1
15736 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15737                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15738                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15739                           iRegI_R0 result, rFlagsReg cr)
15740 %{
15741   match(Set result (EncodeISOArray src (Binary dst len)));
15742   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15743          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15744 
15745   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15746   ins_encode %{
15747     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15748          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15749          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15750   %}
15751   ins_pipe( pipe_class_memory );
15752 %}
15753 
15754 // ============================================================================
15755 // This name is KNOWN by the ADLC and cannot be changed.
15756 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15757 // for this guy.
15758 instruct tlsLoadP(thread_RegP dst)
15759 %{
15760   match(Set dst (ThreadLocal));
15761 
15762   ins_cost(0);
15763 
15764   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15765 
15766   size(0);
15767 
15768   ins_encode( /*empty*/ );
15769 
15770   ins_pipe(pipe_class_empty);
15771 %}
15772 
15773 // ====================VECTOR INSTRUCTIONS=====================================
15774 
15775 // Load vector (32 bits)
15776 instruct loadV4(vecD dst, vmem4 mem)
15777 %{
15778   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15779   match(Set dst (LoadVector mem));
15780   ins_cost(4 * INSN_COST);
15781   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15782   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15783   ins_pipe(vload_reg_mem64);
15784 %}
15785 
15786 // Load vector (64 bits)
15787 instruct loadV8(vecD dst, vmem8 mem)
15788 %{
15789   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15790   match(Set dst (LoadVector mem));
15791   ins_cost(4 * INSN_COST);
15792   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15793   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15794   ins_pipe(vload_reg_mem64);
15795 %}
15796 
15797 // Load Vector (128 bits)
15798 instruct loadV16(vecX dst, vmem16 mem)
15799 %{
15800   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15801   match(Set dst (LoadVector mem));
15802   ins_cost(4 * INSN_COST);
15803   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15804   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15805   ins_pipe(vload_reg_mem128);
15806 %}
15807 
15808 // Store Vector (32 bits)
15809 instruct storeV4(vecD src, vmem4 mem)
15810 %{
15811   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15812   match(Set mem (StoreVector mem src));
15813   ins_cost(4 * INSN_COST);
15814   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15815   ins_encode( aarch64_enc_strvS(src, mem) );
15816   ins_pipe(vstore_reg_mem64);
15817 %}
15818 
15819 // Store Vector (64 bits)
15820 instruct storeV8(vecD src, vmem8 mem)
15821 %{
15822   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15823   match(Set mem (StoreVector mem src));
15824   ins_cost(4 * INSN_COST);
15825   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15826   ins_encode( aarch64_enc_strvD(src, mem) );
15827   ins_pipe(vstore_reg_mem64);
15828 %}
15829 
15830 // Store Vector (128 bits)
15831 instruct storeV16(vecX src, vmem16 mem)
15832 %{
15833   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15834   match(Set mem (StoreVector mem src));
15835   ins_cost(4 * INSN_COST);
15836   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15837   ins_encode( aarch64_enc_strvQ(src, mem) );
15838   ins_pipe(vstore_reg_mem128);
15839 %}
15840 
15841 instruct replicate8B(vecD dst, iRegIorL2I src)
15842 %{
15843   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15844             n-&gt;as_Vector()-&gt;length() == 8);
15845   match(Set dst (ReplicateB src));
15846   ins_cost(INSN_COST);
15847   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15848   ins_encode %{
15849     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15850   %}
15851   ins_pipe(vdup_reg_reg64);
15852 %}
15853 
15854 instruct replicate16B(vecX dst, iRegIorL2I src)
15855 %{
15856   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15857   match(Set dst (ReplicateB src));
15858   ins_cost(INSN_COST);
15859   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15860   ins_encode %{
15861     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15862   %}
15863   ins_pipe(vdup_reg_reg128);
15864 %}
15865 
15866 instruct replicate8B_imm(vecD dst, immI con)
15867 %{
15868   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15869             n-&gt;as_Vector()-&gt;length() == 8);
15870   match(Set dst (ReplicateB con));
15871   ins_cost(INSN_COST);
15872   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15873   ins_encode %{
15874     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15875   %}
15876   ins_pipe(vmovi_reg_imm64);
15877 %}
15878 
15879 instruct replicate16B_imm(vecX dst, immI con)
15880 %{
15881   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15882   match(Set dst (ReplicateB con));
15883   ins_cost(INSN_COST);
15884   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15885   ins_encode %{
15886     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15887   %}
15888   ins_pipe(vmovi_reg_imm128);
15889 %}
15890 
15891 instruct replicate4S(vecD dst, iRegIorL2I src)
15892 %{
15893   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15894             n-&gt;as_Vector()-&gt;length() == 4);
15895   match(Set dst (ReplicateS src));
15896   ins_cost(INSN_COST);
15897   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15898   ins_encode %{
15899     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15900   %}
15901   ins_pipe(vdup_reg_reg64);
15902 %}
15903 
15904 instruct replicate8S(vecX dst, iRegIorL2I src)
15905 %{
15906   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15907   match(Set dst (ReplicateS src));
15908   ins_cost(INSN_COST);
15909   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15910   ins_encode %{
15911     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15912   %}
15913   ins_pipe(vdup_reg_reg128);
15914 %}
15915 
15916 instruct replicate4S_imm(vecD dst, immI con)
15917 %{
15918   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15919             n-&gt;as_Vector()-&gt;length() == 4);
15920   match(Set dst (ReplicateS con));
15921   ins_cost(INSN_COST);
15922   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15923   ins_encode %{
15924     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15925   %}
15926   ins_pipe(vmovi_reg_imm64);
15927 %}
15928 
15929 instruct replicate8S_imm(vecX dst, immI con)
15930 %{
15931   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15932   match(Set dst (ReplicateS con));
15933   ins_cost(INSN_COST);
15934   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15935   ins_encode %{
15936     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15937   %}
15938   ins_pipe(vmovi_reg_imm128);
15939 %}
15940 
15941 instruct replicate2I(vecD dst, iRegIorL2I src)
15942 %{
15943   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15944   match(Set dst (ReplicateI src));
15945   ins_cost(INSN_COST);
15946   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15947   ins_encode %{
15948     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15949   %}
15950   ins_pipe(vdup_reg_reg64);
15951 %}
15952 
15953 instruct replicate4I(vecX dst, iRegIorL2I src)
15954 %{
15955   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15956   match(Set dst (ReplicateI src));
15957   ins_cost(INSN_COST);
15958   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15959   ins_encode %{
15960     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15961   %}
15962   ins_pipe(vdup_reg_reg128);
15963 %}
15964 
15965 instruct replicate2I_imm(vecD dst, immI con)
15966 %{
15967   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15968   match(Set dst (ReplicateI con));
15969   ins_cost(INSN_COST);
15970   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15971   ins_encode %{
15972     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15973   %}
15974   ins_pipe(vmovi_reg_imm64);
15975 %}
15976 
15977 instruct replicate4I_imm(vecX dst, immI con)
15978 %{
15979   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15980   match(Set dst (ReplicateI con));
15981   ins_cost(INSN_COST);
15982   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15983   ins_encode %{
15984     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15985   %}
15986   ins_pipe(vmovi_reg_imm128);
15987 %}
15988 
15989 instruct replicate2L(vecX dst, iRegL src)
15990 %{
15991   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15992   match(Set dst (ReplicateL src));
15993   ins_cost(INSN_COST);
15994   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15995   ins_encode %{
15996     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15997   %}
15998   ins_pipe(vdup_reg_reg128);
15999 %}
16000 
16001 instruct replicate2L_zero(vecX dst, immI0 zero)
16002 %{
16003   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16004   match(Set dst (ReplicateI zero));
16005   ins_cost(INSN_COST);
16006   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16007   ins_encode %{
16008     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16009            as_FloatRegister($dst$$reg),
16010            as_FloatRegister($dst$$reg));
16011   %}
16012   ins_pipe(vmovi_reg_imm128);
16013 %}
16014 
16015 instruct replicate2F(vecD dst, vRegF src)
16016 %{
16017   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16018   match(Set dst (ReplicateF src));
16019   ins_cost(INSN_COST);
16020   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16021   ins_encode %{
16022     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16023            as_FloatRegister($src$$reg));
16024   %}
16025   ins_pipe(vdup_reg_freg64);
16026 %}
16027 
16028 instruct replicate4F(vecX dst, vRegF src)
16029 %{
16030   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16031   match(Set dst (ReplicateF src));
16032   ins_cost(INSN_COST);
16033   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16034   ins_encode %{
16035     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16036            as_FloatRegister($src$$reg));
16037   %}
16038   ins_pipe(vdup_reg_freg128);
16039 %}
16040 
16041 instruct replicate2D(vecX dst, vRegD src)
16042 %{
16043   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16044   match(Set dst (ReplicateD src));
16045   ins_cost(INSN_COST);
16046   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16047   ins_encode %{
16048     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16049            as_FloatRegister($src$$reg));
16050   %}
16051   ins_pipe(vdup_reg_dreg128);
16052 %}
16053 
16054 // ====================REDUCTION ARITHMETIC====================================
16055 
16056 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16057 %{
16058   match(Set dst (AddReductionVI isrc vsrc));
16059   ins_cost(INSN_COST);
16060   effect(TEMP tmp, TEMP tmp2);
16061   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16062             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16063             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16064             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16065   %}
16066   ins_encode %{
16067     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16068     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16069     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16070     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16071   %}
16072   ins_pipe(pipe_class_default);
16073 %}
16074 
16075 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16076 %{
16077   match(Set dst (AddReductionVI isrc vsrc));
16078   ins_cost(INSN_COST);
16079   effect(TEMP vtmp, TEMP itmp);
16080   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16081             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16082             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16083   %}
16084   ins_encode %{
16085     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16086             as_FloatRegister($vsrc$$reg));
16087     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16088     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16089   %}
16090   ins_pipe(pipe_class_default);
16091 %}
16092 
16093 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16094 %{
16095   match(Set dst (MulReductionVI isrc vsrc));
16096   ins_cost(INSN_COST);
16097   effect(TEMP tmp, TEMP dst);
16098   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16099             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16100             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16101             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16102   %}
16103   ins_encode %{
16104     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16105     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16106     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16107     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16108   %}
16109   ins_pipe(pipe_class_default);
16110 %}
16111 
16112 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16113 %{
16114   match(Set dst (MulReductionVI isrc vsrc));
16115   ins_cost(INSN_COST);
16116   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16117   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16118             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16119             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16120             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16121             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16122             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16123   %}
16124   ins_encode %{
16125     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16126            as_FloatRegister($vsrc$$reg), 0, 1);
16127     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16128             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16129     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16130     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16131     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16132     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16133   %}
16134   ins_pipe(pipe_class_default);
16135 %}
16136 
16137 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16138 %{
16139   match(Set dst (AddReductionVF fsrc vsrc));
16140   ins_cost(INSN_COST);
16141   effect(TEMP tmp, TEMP dst);
16142   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16143             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16144             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16145   %}
16146   ins_encode %{
16147     __ fadds(as_FloatRegister($dst$$reg),
16148              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16149     __ ins(as_FloatRegister($tmp$$reg), __ S,
16150            as_FloatRegister($vsrc$$reg), 0, 1);
16151     __ fadds(as_FloatRegister($dst$$reg),
16152              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16153   %}
16154   ins_pipe(pipe_class_default);
16155 %}
16156 
16157 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16158 %{
16159   match(Set dst (AddReductionVF fsrc vsrc));
16160   ins_cost(INSN_COST);
16161   effect(TEMP tmp, TEMP dst);
16162   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16163             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16164             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16165             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16166             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16167             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16168             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16169   %}
16170   ins_encode %{
16171     __ fadds(as_FloatRegister($dst$$reg),
16172              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16173     __ ins(as_FloatRegister($tmp$$reg), __ S,
16174            as_FloatRegister($vsrc$$reg), 0, 1);
16175     __ fadds(as_FloatRegister($dst$$reg),
16176              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16177     __ ins(as_FloatRegister($tmp$$reg), __ S,
16178            as_FloatRegister($vsrc$$reg), 0, 2);
16179     __ fadds(as_FloatRegister($dst$$reg),
16180              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16181     __ ins(as_FloatRegister($tmp$$reg), __ S,
16182            as_FloatRegister($vsrc$$reg), 0, 3);
16183     __ fadds(as_FloatRegister($dst$$reg),
16184              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16185   %}
16186   ins_pipe(pipe_class_default);
16187 %}
16188 
16189 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16190 %{
16191   match(Set dst (MulReductionVF fsrc vsrc));
16192   ins_cost(INSN_COST);
16193   effect(TEMP tmp, TEMP dst);
16194   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16195             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16196             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16197   %}
16198   ins_encode %{
16199     __ fmuls(as_FloatRegister($dst$$reg),
16200              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16201     __ ins(as_FloatRegister($tmp$$reg), __ S,
16202            as_FloatRegister($vsrc$$reg), 0, 1);
16203     __ fmuls(as_FloatRegister($dst$$reg),
16204              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16205   %}
16206   ins_pipe(pipe_class_default);
16207 %}
16208 
16209 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16210 %{
16211   match(Set dst (MulReductionVF fsrc vsrc));
16212   ins_cost(INSN_COST);
16213   effect(TEMP tmp, TEMP dst);
16214   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16215             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16216             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16217             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16218             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16219             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16220             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16221   %}
16222   ins_encode %{
16223     __ fmuls(as_FloatRegister($dst$$reg),
16224              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16225     __ ins(as_FloatRegister($tmp$$reg), __ S,
16226            as_FloatRegister($vsrc$$reg), 0, 1);
16227     __ fmuls(as_FloatRegister($dst$$reg),
16228              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16229     __ ins(as_FloatRegister($tmp$$reg), __ S,
16230            as_FloatRegister($vsrc$$reg), 0, 2);
16231     __ fmuls(as_FloatRegister($dst$$reg),
16232              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16233     __ ins(as_FloatRegister($tmp$$reg), __ S,
16234            as_FloatRegister($vsrc$$reg), 0, 3);
16235     __ fmuls(as_FloatRegister($dst$$reg),
16236              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16237   %}
16238   ins_pipe(pipe_class_default);
16239 %}
16240 
16241 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16242 %{
16243   match(Set dst (AddReductionVD dsrc vsrc));
16244   ins_cost(INSN_COST);
16245   effect(TEMP tmp, TEMP dst);
16246   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16247             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16248             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16249   %}
16250   ins_encode %{
16251     __ faddd(as_FloatRegister($dst$$reg),
16252              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16253     __ ins(as_FloatRegister($tmp$$reg), __ D,
16254            as_FloatRegister($vsrc$$reg), 0, 1);
16255     __ faddd(as_FloatRegister($dst$$reg),
16256              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16257   %}
16258   ins_pipe(pipe_class_default);
16259 %}
16260 
16261 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16262 %{
16263   match(Set dst (MulReductionVD dsrc vsrc));
16264   ins_cost(INSN_COST);
16265   effect(TEMP tmp, TEMP dst);
16266   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16267             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16268             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16269   %}
16270   ins_encode %{
16271     __ fmuld(as_FloatRegister($dst$$reg),
16272              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16273     __ ins(as_FloatRegister($tmp$$reg), __ D,
16274            as_FloatRegister($vsrc$$reg), 0, 1);
16275     __ fmuld(as_FloatRegister($dst$$reg),
16276              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16277   %}
16278   ins_pipe(pipe_class_default);
16279 %}
16280 
16281 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16282   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16283   match(Set dst (MaxReductionV fsrc vsrc));
16284   ins_cost(INSN_COST);
16285   effect(TEMP_DEF dst, TEMP tmp);
16286   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16287             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16288             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16289   ins_encode %{
16290     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16291     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16292     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16293   %}
16294   ins_pipe(pipe_class_default);
16295 %}
16296 
16297 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16298   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16299   match(Set dst (MaxReductionV fsrc vsrc));
16300   ins_cost(INSN_COST);
16301   effect(TEMP_DEF dst);
16302   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16303             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16304   ins_encode %{
16305     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16306     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16307   %}
16308   ins_pipe(pipe_class_default);
16309 %}
16310 
16311 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16312   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16313   match(Set dst (MaxReductionV dsrc vsrc));
16314   ins_cost(INSN_COST);
16315   effect(TEMP_DEF dst, TEMP tmp);
16316   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16317             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16318             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16319   ins_encode %{
16320     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16321     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16322     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16323   %}
16324   ins_pipe(pipe_class_default);
16325 %}
16326 
16327 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16328   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16329   match(Set dst (MinReductionV fsrc vsrc));
16330   ins_cost(INSN_COST);
16331   effect(TEMP_DEF dst, TEMP tmp);
16332   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16333             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16334             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16335   ins_encode %{
16336     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16337     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16338     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16339   %}
16340   ins_pipe(pipe_class_default);
16341 %}
16342 
16343 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16344   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16345   match(Set dst (MinReductionV fsrc vsrc));
16346   ins_cost(INSN_COST);
16347   effect(TEMP_DEF dst);
16348   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16349             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16350   ins_encode %{
16351     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16352     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16353   %}
16354   ins_pipe(pipe_class_default);
16355 %}
16356 
16357 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16358   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16359   match(Set dst (MinReductionV dsrc vsrc));
16360   ins_cost(INSN_COST);
16361   effect(TEMP_DEF dst, TEMP tmp);
16362   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16363             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16364             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16365   ins_encode %{
16366     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16367     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16368     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16369   %}
16370   ins_pipe(pipe_class_default);
16371 %}
16372 
16373 // ====================VECTOR ARITHMETIC=======================================
16374 
16375 // --------------------------------- ADD --------------------------------------
16376 
16377 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16378 %{
16379   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16380             n-&gt;as_Vector()-&gt;length() == 8);
16381   match(Set dst (AddVB src1 src2));
16382   ins_cost(INSN_COST);
16383   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16384   ins_encode %{
16385     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16386             as_FloatRegister($src1$$reg),
16387             as_FloatRegister($src2$$reg));
16388   %}
16389   ins_pipe(vdop64);
16390 %}
16391 
16392 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16393 %{
16394   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16395   match(Set dst (AddVB src1 src2));
16396   ins_cost(INSN_COST);
16397   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16398   ins_encode %{
16399     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16400             as_FloatRegister($src1$$reg),
16401             as_FloatRegister($src2$$reg));
16402   %}
16403   ins_pipe(vdop128);
16404 %}
16405 
16406 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16407 %{
16408   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16409             n-&gt;as_Vector()-&gt;length() == 4);
16410   match(Set dst (AddVS src1 src2));
16411   ins_cost(INSN_COST);
16412   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16413   ins_encode %{
16414     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16415             as_FloatRegister($src1$$reg),
16416             as_FloatRegister($src2$$reg));
16417   %}
16418   ins_pipe(vdop64);
16419 %}
16420 
16421 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16422 %{
16423   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16424   match(Set dst (AddVS src1 src2));
16425   ins_cost(INSN_COST);
16426   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16427   ins_encode %{
16428     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16429             as_FloatRegister($src1$$reg),
16430             as_FloatRegister($src2$$reg));
16431   %}
16432   ins_pipe(vdop128);
16433 %}
16434 
16435 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16436 %{
16437   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16438   match(Set dst (AddVI src1 src2));
16439   ins_cost(INSN_COST);
16440   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16441   ins_encode %{
16442     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16443             as_FloatRegister($src1$$reg),
16444             as_FloatRegister($src2$$reg));
16445   %}
16446   ins_pipe(vdop64);
16447 %}
16448 
16449 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16450 %{
16451   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16452   match(Set dst (AddVI src1 src2));
16453   ins_cost(INSN_COST);
16454   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16455   ins_encode %{
16456     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16457             as_FloatRegister($src1$$reg),
16458             as_FloatRegister($src2$$reg));
16459   %}
16460   ins_pipe(vdop128);
16461 %}
16462 
16463 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16464 %{
16465   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16466   match(Set dst (AddVL src1 src2));
16467   ins_cost(INSN_COST);
16468   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16469   ins_encode %{
16470     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16471             as_FloatRegister($src1$$reg),
16472             as_FloatRegister($src2$$reg));
16473   %}
16474   ins_pipe(vdop128);
16475 %}
16476 
16477 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16478 %{
16479   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16480   match(Set dst (AddVF src1 src2));
16481   ins_cost(INSN_COST);
16482   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16483   ins_encode %{
16484     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16485             as_FloatRegister($src1$$reg),
16486             as_FloatRegister($src2$$reg));
16487   %}
16488   ins_pipe(vdop_fp64);
16489 %}
16490 
16491 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16492 %{
16493   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16494   match(Set dst (AddVF src1 src2));
16495   ins_cost(INSN_COST);
16496   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16497   ins_encode %{
16498     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16499             as_FloatRegister($src1$$reg),
16500             as_FloatRegister($src2$$reg));
16501   %}
16502   ins_pipe(vdop_fp128);
16503 %}
16504 
16505 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16506 %{
16507   match(Set dst (AddVD src1 src2));
16508   ins_cost(INSN_COST);
16509   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16510   ins_encode %{
16511     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16512             as_FloatRegister($src1$$reg),
16513             as_FloatRegister($src2$$reg));
16514   %}
16515   ins_pipe(vdop_fp128);
16516 %}
16517 
16518 // --------------------------------- SUB --------------------------------------
16519 
16520 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16521 %{
16522   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16523             n-&gt;as_Vector()-&gt;length() == 8);
16524   match(Set dst (SubVB src1 src2));
16525   ins_cost(INSN_COST);
16526   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16527   ins_encode %{
16528     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16529             as_FloatRegister($src1$$reg),
16530             as_FloatRegister($src2$$reg));
16531   %}
16532   ins_pipe(vdop64);
16533 %}
16534 
16535 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16536 %{
16537   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16538   match(Set dst (SubVB src1 src2));
16539   ins_cost(INSN_COST);
16540   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16541   ins_encode %{
16542     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16543             as_FloatRegister($src1$$reg),
16544             as_FloatRegister($src2$$reg));
16545   %}
16546   ins_pipe(vdop128);
16547 %}
16548 
16549 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16550 %{
16551   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16552             n-&gt;as_Vector()-&gt;length() == 4);
16553   match(Set dst (SubVS src1 src2));
16554   ins_cost(INSN_COST);
16555   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16556   ins_encode %{
16557     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16558             as_FloatRegister($src1$$reg),
16559             as_FloatRegister($src2$$reg));
16560   %}
16561   ins_pipe(vdop64);
16562 %}
16563 
16564 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16565 %{
16566   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16567   match(Set dst (SubVS src1 src2));
16568   ins_cost(INSN_COST);
16569   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16570   ins_encode %{
16571     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16572             as_FloatRegister($src1$$reg),
16573             as_FloatRegister($src2$$reg));
16574   %}
16575   ins_pipe(vdop128);
16576 %}
16577 
16578 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16579 %{
16580   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16581   match(Set dst (SubVI src1 src2));
16582   ins_cost(INSN_COST);
16583   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16584   ins_encode %{
16585     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16586             as_FloatRegister($src1$$reg),
16587             as_FloatRegister($src2$$reg));
16588   %}
16589   ins_pipe(vdop64);
16590 %}
16591 
16592 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16593 %{
16594   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16595   match(Set dst (SubVI src1 src2));
16596   ins_cost(INSN_COST);
16597   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16598   ins_encode %{
16599     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16600             as_FloatRegister($src1$$reg),
16601             as_FloatRegister($src2$$reg));
16602   %}
16603   ins_pipe(vdop128);
16604 %}
16605 
16606 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16607 %{
16608   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16609   match(Set dst (SubVL src1 src2));
16610   ins_cost(INSN_COST);
16611   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16612   ins_encode %{
16613     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16614             as_FloatRegister($src1$$reg),
16615             as_FloatRegister($src2$$reg));
16616   %}
16617   ins_pipe(vdop128);
16618 %}
16619 
16620 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16621 %{
16622   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16623   match(Set dst (SubVF src1 src2));
16624   ins_cost(INSN_COST);
16625   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16626   ins_encode %{
16627     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16628             as_FloatRegister($src1$$reg),
16629             as_FloatRegister($src2$$reg));
16630   %}
16631   ins_pipe(vdop_fp64);
16632 %}
16633 
16634 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16635 %{
16636   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16637   match(Set dst (SubVF src1 src2));
16638   ins_cost(INSN_COST);
16639   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16640   ins_encode %{
16641     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16642             as_FloatRegister($src1$$reg),
16643             as_FloatRegister($src2$$reg));
16644   %}
16645   ins_pipe(vdop_fp128);
16646 %}
16647 
16648 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16649 %{
16650   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16651   match(Set dst (SubVD src1 src2));
16652   ins_cost(INSN_COST);
16653   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16654   ins_encode %{
16655     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16656             as_FloatRegister($src1$$reg),
16657             as_FloatRegister($src2$$reg));
16658   %}
16659   ins_pipe(vdop_fp128);
16660 %}
16661 
16662 // --------------------------------- MUL --------------------------------------
16663 
16664 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16665 %{
16666   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16667             n-&gt;as_Vector()-&gt;length() == 4);
16668   match(Set dst (MulVS src1 src2));
16669   ins_cost(INSN_COST);
16670   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16671   ins_encode %{
16672     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16673             as_FloatRegister($src1$$reg),
16674             as_FloatRegister($src2$$reg));
16675   %}
16676   ins_pipe(vmul64);
16677 %}
16678 
16679 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16680 %{
16681   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16682   match(Set dst (MulVS src1 src2));
16683   ins_cost(INSN_COST);
16684   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16685   ins_encode %{
16686     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16687             as_FloatRegister($src1$$reg),
16688             as_FloatRegister($src2$$reg));
16689   %}
16690   ins_pipe(vmul128);
16691 %}
16692 
16693 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16694 %{
16695   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16696   match(Set dst (MulVI src1 src2));
16697   ins_cost(INSN_COST);
16698   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16699   ins_encode %{
16700     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16701             as_FloatRegister($src1$$reg),
16702             as_FloatRegister($src2$$reg));
16703   %}
16704   ins_pipe(vmul64);
16705 %}
16706 
16707 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16708 %{
16709   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16710   match(Set dst (MulVI src1 src2));
16711   ins_cost(INSN_COST);
16712   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16713   ins_encode %{
16714     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16715             as_FloatRegister($src1$$reg),
16716             as_FloatRegister($src2$$reg));
16717   %}
16718   ins_pipe(vmul128);
16719 %}
16720 
16721 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16722 %{
16723   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16724   match(Set dst (MulVF src1 src2));
16725   ins_cost(INSN_COST);
16726   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16727   ins_encode %{
16728     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16729             as_FloatRegister($src1$$reg),
16730             as_FloatRegister($src2$$reg));
16731   %}
16732   ins_pipe(vmuldiv_fp64);
16733 %}
16734 
16735 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16736 %{
16737   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16738   match(Set dst (MulVF src1 src2));
16739   ins_cost(INSN_COST);
16740   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16741   ins_encode %{
16742     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16743             as_FloatRegister($src1$$reg),
16744             as_FloatRegister($src2$$reg));
16745   %}
16746   ins_pipe(vmuldiv_fp128);
16747 %}
16748 
16749 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16750 %{
16751   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16752   match(Set dst (MulVD src1 src2));
16753   ins_cost(INSN_COST);
16754   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16755   ins_encode %{
16756     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16757             as_FloatRegister($src1$$reg),
16758             as_FloatRegister($src2$$reg));
16759   %}
16760   ins_pipe(vmuldiv_fp128);
16761 %}
16762 
16763 // --------------------------------- MLA --------------------------------------
16764 
16765 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16766 %{
16767   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16768             n-&gt;as_Vector()-&gt;length() == 4);
16769   match(Set dst (AddVS dst (MulVS src1 src2)));
16770   ins_cost(INSN_COST);
16771   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16772   ins_encode %{
16773     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16774             as_FloatRegister($src1$$reg),
16775             as_FloatRegister($src2$$reg));
16776   %}
16777   ins_pipe(vmla64);
16778 %}
16779 
16780 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16781 %{
16782   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16783   match(Set dst (AddVS dst (MulVS src1 src2)));
16784   ins_cost(INSN_COST);
16785   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16786   ins_encode %{
16787     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16788             as_FloatRegister($src1$$reg),
16789             as_FloatRegister($src2$$reg));
16790   %}
16791   ins_pipe(vmla128);
16792 %}
16793 
16794 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16795 %{
16796   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16797   match(Set dst (AddVI dst (MulVI src1 src2)));
16798   ins_cost(INSN_COST);
16799   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16800   ins_encode %{
16801     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16802             as_FloatRegister($src1$$reg),
16803             as_FloatRegister($src2$$reg));
16804   %}
16805   ins_pipe(vmla64);
16806 %}
16807 
16808 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16809 %{
16810   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16811   match(Set dst (AddVI dst (MulVI src1 src2)));
16812   ins_cost(INSN_COST);
16813   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16814   ins_encode %{
16815     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16816             as_FloatRegister($src1$$reg),
16817             as_FloatRegister($src2$$reg));
16818   %}
16819   ins_pipe(vmla128);
16820 %}
16821 
16822 // dst + src1 * src2
16823 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16824   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16825   match(Set dst (FmaVF  dst (Binary src1 src2)));
16826   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16827   ins_cost(INSN_COST);
16828   ins_encode %{
16829     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16830             as_FloatRegister($src1$$reg),
16831             as_FloatRegister($src2$$reg));
16832   %}
16833   ins_pipe(vmuldiv_fp64);
16834 %}
16835 
16836 // dst + src1 * src2
16837 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16838   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16839   match(Set dst (FmaVF  dst (Binary src1 src2)));
16840   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16841   ins_cost(INSN_COST);
16842   ins_encode %{
16843     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16844             as_FloatRegister($src1$$reg),
16845             as_FloatRegister($src2$$reg));
16846   %}
16847   ins_pipe(vmuldiv_fp128);
16848 %}
16849 
16850 // dst + src1 * src2
16851 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16852   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16853   match(Set dst (FmaVD  dst (Binary src1 src2)));
16854   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16855   ins_cost(INSN_COST);
16856   ins_encode %{
16857     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16858             as_FloatRegister($src1$$reg),
16859             as_FloatRegister($src2$$reg));
16860   %}
16861   ins_pipe(vmuldiv_fp128);
16862 %}
16863 
16864 // --------------------------------- MLS --------------------------------------
16865 
16866 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16867 %{
16868   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16869             n-&gt;as_Vector()-&gt;length() == 4);
16870   match(Set dst (SubVS dst (MulVS src1 src2)));
16871   ins_cost(INSN_COST);
16872   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16873   ins_encode %{
16874     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16875             as_FloatRegister($src1$$reg),
16876             as_FloatRegister($src2$$reg));
16877   %}
16878   ins_pipe(vmla64);
16879 %}
16880 
16881 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16882 %{
16883   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16884   match(Set dst (SubVS dst (MulVS src1 src2)));
16885   ins_cost(INSN_COST);
16886   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16887   ins_encode %{
16888     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16889             as_FloatRegister($src1$$reg),
16890             as_FloatRegister($src2$$reg));
16891   %}
16892   ins_pipe(vmla128);
16893 %}
16894 
16895 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16896 %{
16897   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16898   match(Set dst (SubVI dst (MulVI src1 src2)));
16899   ins_cost(INSN_COST);
16900   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16901   ins_encode %{
16902     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16903             as_FloatRegister($src1$$reg),
16904             as_FloatRegister($src2$$reg));
16905   %}
16906   ins_pipe(vmla64);
16907 %}
16908 
16909 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16910 %{
16911   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16912   match(Set dst (SubVI dst (MulVI src1 src2)));
16913   ins_cost(INSN_COST);
16914   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16915   ins_encode %{
16916     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16917             as_FloatRegister($src1$$reg),
16918             as_FloatRegister($src2$$reg));
16919   %}
16920   ins_pipe(vmla128);
16921 %}
16922 
16923 // dst - src1 * src2
16924 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16925   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16926   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16927   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16928   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16929   ins_cost(INSN_COST);
16930   ins_encode %{
16931     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16932             as_FloatRegister($src1$$reg),
16933             as_FloatRegister($src2$$reg));
16934   %}
16935   ins_pipe(vmuldiv_fp64);
16936 %}
16937 
16938 // dst - src1 * src2
16939 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16940   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16941   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16942   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16943   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16944   ins_cost(INSN_COST);
16945   ins_encode %{
16946     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16947             as_FloatRegister($src1$$reg),
16948             as_FloatRegister($src2$$reg));
16949   %}
16950   ins_pipe(vmuldiv_fp128);
16951 %}
16952 
16953 // dst - src1 * src2
16954 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16955   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16956   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16957   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16958   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16959   ins_cost(INSN_COST);
16960   ins_encode %{
16961     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16962             as_FloatRegister($src1$$reg),
16963             as_FloatRegister($src2$$reg));
16964   %}
16965   ins_pipe(vmuldiv_fp128);
16966 %}
16967 
16968 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16969 
16970 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16971   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16972   match(Set dst (MulAddVS2VI src1 src2));
16973   ins_cost(INSN_COST);
16974   effect(TEMP_DEF dst, TEMP tmp);
16975   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16976             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16977             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16978   ins_encode %{
16979     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16980               as_FloatRegister($src1$$reg),
16981               as_FloatRegister($src2$$reg));
16982     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16983               as_FloatRegister($src1$$reg),
16984               as_FloatRegister($src2$$reg));
16985     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16986              as_FloatRegister($tmp$$reg),
16987              as_FloatRegister($dst$$reg));
16988   %}
16989   ins_pipe(vmuldiv_fp128);
16990 %}
16991 
16992 // --------------------------------- DIV --------------------------------------
16993 
16994 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16995 %{
16996   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16997   match(Set dst (DivVF src1 src2));
16998   ins_cost(INSN_COST);
16999   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17000   ins_encode %{
17001     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17002             as_FloatRegister($src1$$reg),
17003             as_FloatRegister($src2$$reg));
17004   %}
17005   ins_pipe(vmuldiv_fp64);
17006 %}
17007 
17008 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17009 %{
17010   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17011   match(Set dst (DivVF src1 src2));
17012   ins_cost(INSN_COST);
17013   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17014   ins_encode %{
17015     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17016             as_FloatRegister($src1$$reg),
17017             as_FloatRegister($src2$$reg));
17018   %}
17019   ins_pipe(vmuldiv_fp128);
17020 %}
17021 
17022 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17023 %{
17024   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17025   match(Set dst (DivVD src1 src2));
17026   ins_cost(INSN_COST);
17027   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17028   ins_encode %{
17029     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17030             as_FloatRegister($src1$$reg),
17031             as_FloatRegister($src2$$reg));
17032   %}
17033   ins_pipe(vmuldiv_fp128);
17034 %}
17035 
17036 // --------------------------------- SQRT -------------------------------------
17037 
17038 instruct vsqrt2D(vecX dst, vecX src)
17039 %{
17040   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17041   match(Set dst (SqrtVD src));
17042   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17043   ins_encode %{
17044     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17045              as_FloatRegister($src$$reg));
17046   %}
17047   ins_pipe(vsqrt_fp128);
17048 %}
17049 
17050 // --------------------------------- ABS --------------------------------------
17051 
17052 instruct vabs2F(vecD dst, vecD src)
17053 %{
17054   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17055   match(Set dst (AbsVF src));
17056   ins_cost(INSN_COST * 3);
17057   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17058   ins_encode %{
17059     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17060             as_FloatRegister($src$$reg));
17061   %}
17062   ins_pipe(vunop_fp64);
17063 %}
17064 
17065 instruct vabs4F(vecX dst, vecX src)
17066 %{
17067   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17068   match(Set dst (AbsVF src));
17069   ins_cost(INSN_COST * 3);
17070   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17071   ins_encode %{
17072     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17073             as_FloatRegister($src$$reg));
17074   %}
17075   ins_pipe(vunop_fp128);
17076 %}
17077 
17078 instruct vabs2D(vecX dst, vecX src)
17079 %{
17080   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17081   match(Set dst (AbsVD src));
17082   ins_cost(INSN_COST * 3);
17083   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17084   ins_encode %{
17085     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17086             as_FloatRegister($src$$reg));
17087   %}
17088   ins_pipe(vunop_fp128);
17089 %}
17090 
17091 // --------------------------------- NEG --------------------------------------
17092 
17093 instruct vneg2F(vecD dst, vecD src)
17094 %{
17095   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17096   match(Set dst (NegVF src));
17097   ins_cost(INSN_COST * 3);
17098   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17099   ins_encode %{
17100     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17101             as_FloatRegister($src$$reg));
17102   %}
17103   ins_pipe(vunop_fp64);
17104 %}
17105 
17106 instruct vneg4F(vecX dst, vecX src)
17107 %{
17108   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17109   match(Set dst (NegVF src));
17110   ins_cost(INSN_COST * 3);
17111   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17112   ins_encode %{
17113     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17114             as_FloatRegister($src$$reg));
17115   %}
17116   ins_pipe(vunop_fp128);
17117 %}
17118 
17119 instruct vneg2D(vecX dst, vecX src)
17120 %{
17121   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17122   match(Set dst (NegVD src));
17123   ins_cost(INSN_COST * 3);
17124   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17125   ins_encode %{
17126     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17127             as_FloatRegister($src$$reg));
17128   %}
17129   ins_pipe(vunop_fp128);
17130 %}
17131 
17132 // --------------------------------- AND --------------------------------------
17133 
17134 instruct vand8B(vecD dst, vecD src1, vecD src2)
17135 %{
17136   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17137             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17138   match(Set dst (AndV src1 src2));
17139   ins_cost(INSN_COST);
17140   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17141   ins_encode %{
17142     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17143             as_FloatRegister($src1$$reg),
17144             as_FloatRegister($src2$$reg));
17145   %}
17146   ins_pipe(vlogical64);
17147 %}
17148 
17149 instruct vand16B(vecX dst, vecX src1, vecX src2)
17150 %{
17151   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17152   match(Set dst (AndV src1 src2));
17153   ins_cost(INSN_COST);
17154   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17155   ins_encode %{
17156     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17157             as_FloatRegister($src1$$reg),
17158             as_FloatRegister($src2$$reg));
17159   %}
17160   ins_pipe(vlogical128);
17161 %}
17162 
17163 // --------------------------------- OR ---------------------------------------
17164 
17165 instruct vor8B(vecD dst, vecD src1, vecD src2)
17166 %{
17167   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17168             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17169   match(Set dst (OrV src1 src2));
17170   ins_cost(INSN_COST);
17171   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17172   ins_encode %{
17173     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17174             as_FloatRegister($src1$$reg),
17175             as_FloatRegister($src2$$reg));
17176   %}
17177   ins_pipe(vlogical64);
17178 %}
17179 
17180 instruct vor16B(vecX dst, vecX src1, vecX src2)
17181 %{
17182   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17183   match(Set dst (OrV src1 src2));
17184   ins_cost(INSN_COST);
17185   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17186   ins_encode %{
17187     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17188             as_FloatRegister($src1$$reg),
17189             as_FloatRegister($src2$$reg));
17190   %}
17191   ins_pipe(vlogical128);
17192 %}
17193 
17194 // --------------------------------- XOR --------------------------------------
17195 
17196 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17197 %{
17198   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17199             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17200   match(Set dst (XorV src1 src2));
17201   ins_cost(INSN_COST);
17202   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17203   ins_encode %{
17204     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17205             as_FloatRegister($src1$$reg),
17206             as_FloatRegister($src2$$reg));
17207   %}
17208   ins_pipe(vlogical64);
17209 %}
17210 
17211 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17212 %{
17213   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17214   match(Set dst (XorV src1 src2));
17215   ins_cost(INSN_COST);
17216   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17217   ins_encode %{
17218     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17219             as_FloatRegister($src1$$reg),
17220             as_FloatRegister($src2$$reg));
17221   %}
17222   ins_pipe(vlogical128);
17223 %}
17224 
17225 // ------------------------------ Shift ---------------------------------------
17226 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17227   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17228   match(Set dst (LShiftCntV cnt));
17229   match(Set dst (RShiftCntV cnt));
17230   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17231   ins_encode %{
17232     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17233   %}
17234   ins_pipe(vdup_reg_reg64);
17235 %}
17236 
17237 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17238   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17239   match(Set dst (LShiftCntV cnt));
17240   match(Set dst (RShiftCntV cnt));
17241   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17242   ins_encode %{
17243     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17244   %}
17245   ins_pipe(vdup_reg_reg128);
17246 %}
17247 
17248 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17249   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17250             n-&gt;as_Vector()-&gt;length() == 8);
17251   match(Set dst (LShiftVB src shift));
17252   ins_cost(INSN_COST);
17253   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17254   ins_encode %{
17255     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17256             as_FloatRegister($src$$reg),
17257             as_FloatRegister($shift$$reg));
17258   %}
17259   ins_pipe(vshift64);
17260 %}
17261 
17262 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17263   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17264   match(Set dst (LShiftVB src shift));
17265   ins_cost(INSN_COST);
17266   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17267   ins_encode %{
17268     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17269             as_FloatRegister($src$$reg),
17270             as_FloatRegister($shift$$reg));
17271   %}
17272   ins_pipe(vshift128);
17273 %}
17274 
17275 // Right shifts with vector shift count on aarch64 SIMD are implemented
17276 // as left shift by negative shift count.
17277 // There are two cases for vector shift count.
17278 //
17279 // Case 1: The vector shift count is from replication.
17280 //        |            |
17281 //    LoadVector  RShiftCntV
17282 //        |       /
17283 //     RShiftVI
17284 // Note: In inner loop, multiple neg instructions are used, which can be
17285 // moved to outer loop and merge into one neg instruction.
17286 //
17287 // Case 2: The vector shift count is from loading.
17288 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17289 // panama/vectorIntrinsics(JEP 338: Vector API).
17290 //        |            |
17291 //    LoadVector  LoadVector
17292 //        |       /
17293 //     RShiftVI
17294 //
17295 
17296 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17297   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17298             n-&gt;as_Vector()-&gt;length() == 8);
17299   match(Set dst (RShiftVB src shift));
17300   ins_cost(INSN_COST);
17301   effect(TEMP tmp);
17302   format %{ &quot;negr  $tmp,$shift\t&quot;
17303             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17304   ins_encode %{
17305     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17306             as_FloatRegister($shift$$reg));
17307     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17308             as_FloatRegister($src$$reg),
17309             as_FloatRegister($tmp$$reg));
17310   %}
17311   ins_pipe(vshift64);
17312 %}
17313 
17314 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17315   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17316   match(Set dst (RShiftVB src shift));
17317   ins_cost(INSN_COST);
17318   effect(TEMP tmp);
17319   format %{ &quot;negr  $tmp,$shift\t&quot;
17320             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17321   ins_encode %{
17322     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17323             as_FloatRegister($shift$$reg));
17324     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17325             as_FloatRegister($src$$reg),
17326             as_FloatRegister($tmp$$reg));
17327   %}
17328   ins_pipe(vshift128);
17329 %}
17330 
17331 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17332   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17333             n-&gt;as_Vector()-&gt;length() == 8);
17334   match(Set dst (URShiftVB src shift));
17335   ins_cost(INSN_COST);
17336   effect(TEMP tmp);
17337   format %{ &quot;negr  $tmp,$shift\t&quot;
17338             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17339   ins_encode %{
17340     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17341             as_FloatRegister($shift$$reg));
17342     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17343             as_FloatRegister($src$$reg),
17344             as_FloatRegister($tmp$$reg));
17345   %}
17346   ins_pipe(vshift64);
17347 %}
17348 
17349 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17350   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17351   match(Set dst (URShiftVB src shift));
17352   ins_cost(INSN_COST);
17353   effect(TEMP tmp);
17354   format %{ &quot;negr  $tmp,$shift\t&quot;
17355             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17356   ins_encode %{
17357     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17358             as_FloatRegister($shift$$reg));
17359     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17360             as_FloatRegister($src$$reg),
17361             as_FloatRegister($tmp$$reg));
17362   %}
17363   ins_pipe(vshift128);
17364 %}
17365 
17366 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17367   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17368             n-&gt;as_Vector()-&gt;length() == 8);
17369   match(Set dst (LShiftVB src (LShiftCntV shift)));
17370   ins_cost(INSN_COST);
17371   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17372   ins_encode %{
17373     int sh = (int)$shift$$constant;
17374     if (sh &gt;= 8) {
17375       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17376              as_FloatRegister($src$$reg),
17377              as_FloatRegister($src$$reg));
17378     } else {
17379       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17380              as_FloatRegister($src$$reg), sh);
17381     }
17382   %}
17383   ins_pipe(vshift64_imm);
17384 %}
17385 
17386 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17387   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17388   match(Set dst (LShiftVB src (LShiftCntV shift)));
17389   ins_cost(INSN_COST);
17390   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17391   ins_encode %{
17392     int sh = (int)$shift$$constant;
17393     if (sh &gt;= 8) {
17394       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17395              as_FloatRegister($src$$reg),
17396              as_FloatRegister($src$$reg));
17397     } else {
17398       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17399              as_FloatRegister($src$$reg), sh);
17400     }
17401   %}
17402   ins_pipe(vshift128_imm);
17403 %}
17404 
17405 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17406   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17407             n-&gt;as_Vector()-&gt;length() == 8);
17408   match(Set dst (RShiftVB src (RShiftCntV shift)));
17409   ins_cost(INSN_COST);
17410   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17411   ins_encode %{
17412     int sh = (int)$shift$$constant;
17413     if (sh &gt;= 8) sh = 7;
17414     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17415            as_FloatRegister($src$$reg), sh);
17416   %}
17417   ins_pipe(vshift64_imm);
17418 %}
17419 
17420 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17421   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17422   match(Set dst (RShiftVB src (RShiftCntV shift)));
17423   ins_cost(INSN_COST);
17424   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17425   ins_encode %{
17426     int sh = (int)$shift$$constant;
17427     if (sh &gt;= 8) sh = 7;
17428     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17429            as_FloatRegister($src$$reg), sh);
17430   %}
17431   ins_pipe(vshift128_imm);
17432 %}
17433 
17434 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17435   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17436             n-&gt;as_Vector()-&gt;length() == 8);
17437   match(Set dst (URShiftVB src (RShiftCntV shift)));
17438   ins_cost(INSN_COST);
17439   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17440   ins_encode %{
17441     int sh = (int)$shift$$constant;
17442     if (sh &gt;= 8) {
17443       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17444              as_FloatRegister($src$$reg),
17445              as_FloatRegister($src$$reg));
17446     } else {
17447       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17448              as_FloatRegister($src$$reg), sh);
17449     }
17450   %}
17451   ins_pipe(vshift64_imm);
17452 %}
17453 
17454 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17455   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17456   match(Set dst (URShiftVB src (RShiftCntV shift)));
17457   ins_cost(INSN_COST);
17458   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17459   ins_encode %{
17460     int sh = (int)$shift$$constant;
17461     if (sh &gt;= 8) {
17462       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17463              as_FloatRegister($src$$reg),
17464              as_FloatRegister($src$$reg));
17465     } else {
17466       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17467              as_FloatRegister($src$$reg), sh);
17468     }
17469   %}
17470   ins_pipe(vshift128_imm);
17471 %}
17472 
17473 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17474   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17475             n-&gt;as_Vector()-&gt;length() == 4);
17476   match(Set dst (LShiftVS src shift));
17477   ins_cost(INSN_COST);
17478   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17479   ins_encode %{
17480     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17481             as_FloatRegister($src$$reg),
17482             as_FloatRegister($shift$$reg));
17483   %}
17484   ins_pipe(vshift64);
17485 %}
17486 
17487 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17488   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17489   match(Set dst (LShiftVS src shift));
17490   ins_cost(INSN_COST);
17491   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17492   ins_encode %{
17493     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17494             as_FloatRegister($src$$reg),
17495             as_FloatRegister($shift$$reg));
17496   %}
17497   ins_pipe(vshift128);
17498 %}
17499 
17500 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17501   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17502             n-&gt;as_Vector()-&gt;length() == 4);
17503   match(Set dst (RShiftVS src shift));
17504   ins_cost(INSN_COST);
17505   effect(TEMP tmp);
17506   format %{ &quot;negr  $tmp,$shift\t&quot;
17507             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17508   ins_encode %{
17509     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17510             as_FloatRegister($shift$$reg));
17511     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17512             as_FloatRegister($src$$reg),
17513             as_FloatRegister($tmp$$reg));
17514   %}
17515   ins_pipe(vshift64);
17516 %}
17517 
17518 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17519   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17520   match(Set dst (RShiftVS src shift));
17521   ins_cost(INSN_COST);
17522   effect(TEMP tmp);
17523   format %{ &quot;negr  $tmp,$shift\t&quot;
17524             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17525   ins_encode %{
17526     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17527             as_FloatRegister($shift$$reg));
17528     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17529             as_FloatRegister($src$$reg),
17530             as_FloatRegister($tmp$$reg));
17531   %}
17532   ins_pipe(vshift128);
17533 %}
17534 
17535 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17536   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17537             n-&gt;as_Vector()-&gt;length() == 4);
17538   match(Set dst (URShiftVS src shift));
17539   ins_cost(INSN_COST);
17540   effect(TEMP tmp);
17541   format %{ &quot;negr  $tmp,$shift\t&quot;
17542             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17543   ins_encode %{
17544     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17545             as_FloatRegister($shift$$reg));
17546     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17547             as_FloatRegister($src$$reg),
17548             as_FloatRegister($tmp$$reg));
17549   %}
17550   ins_pipe(vshift64);
17551 %}
17552 
17553 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17554   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17555   match(Set dst (URShiftVS src shift));
17556   ins_cost(INSN_COST);
17557   effect(TEMP tmp);
17558   format %{ &quot;negr  $tmp,$shift\t&quot;
17559             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17560   ins_encode %{
17561     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17562             as_FloatRegister($shift$$reg));
17563     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17564             as_FloatRegister($src$$reg),
17565             as_FloatRegister($tmp$$reg));
17566   %}
17567   ins_pipe(vshift128);
17568 %}
17569 
17570 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17571   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17572             n-&gt;as_Vector()-&gt;length() == 4);
17573   match(Set dst (LShiftVS src (LShiftCntV shift)));
17574   ins_cost(INSN_COST);
17575   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17576   ins_encode %{
17577     int sh = (int)$shift$$constant;
17578     if (sh &gt;= 16) {
17579       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17580              as_FloatRegister($src$$reg),
17581              as_FloatRegister($src$$reg));
17582     } else {
17583       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17584              as_FloatRegister($src$$reg), sh);
17585     }
17586   %}
17587   ins_pipe(vshift64_imm);
17588 %}
17589 
17590 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17591   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17592   match(Set dst (LShiftVS src (LShiftCntV shift)));
17593   ins_cost(INSN_COST);
17594   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17595   ins_encode %{
17596     int sh = (int)$shift$$constant;
17597     if (sh &gt;= 16) {
17598       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17599              as_FloatRegister($src$$reg),
17600              as_FloatRegister($src$$reg));
17601     } else {
17602       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17603              as_FloatRegister($src$$reg), sh);
17604     }
17605   %}
17606   ins_pipe(vshift128_imm);
17607 %}
17608 
17609 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17610   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17611             n-&gt;as_Vector()-&gt;length() == 4);
17612   match(Set dst (RShiftVS src (RShiftCntV shift)));
17613   ins_cost(INSN_COST);
17614   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17615   ins_encode %{
17616     int sh = (int)$shift$$constant;
17617     if (sh &gt;= 16) sh = 15;
17618     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17619            as_FloatRegister($src$$reg), sh);
17620   %}
17621   ins_pipe(vshift64_imm);
17622 %}
17623 
17624 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17625   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17626   match(Set dst (RShiftVS src (RShiftCntV shift)));
17627   ins_cost(INSN_COST);
17628   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17629   ins_encode %{
17630     int sh = (int)$shift$$constant;
17631     if (sh &gt;= 16) sh = 15;
17632     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17633            as_FloatRegister($src$$reg), sh);
17634   %}
17635   ins_pipe(vshift128_imm);
17636 %}
17637 
17638 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17639   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17640             n-&gt;as_Vector()-&gt;length() == 4);
17641   match(Set dst (URShiftVS src (RShiftCntV shift)));
17642   ins_cost(INSN_COST);
17643   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17644   ins_encode %{
17645     int sh = (int)$shift$$constant;
17646     if (sh &gt;= 16) {
17647       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17648              as_FloatRegister($src$$reg),
17649              as_FloatRegister($src$$reg));
17650     } else {
17651       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17652              as_FloatRegister($src$$reg), sh);
17653     }
17654   %}
17655   ins_pipe(vshift64_imm);
17656 %}
17657 
17658 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17659   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17660   match(Set dst (URShiftVS src (RShiftCntV shift)));
17661   ins_cost(INSN_COST);
17662   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17663   ins_encode %{
17664     int sh = (int)$shift$$constant;
17665     if (sh &gt;= 16) {
17666       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17667              as_FloatRegister($src$$reg),
17668              as_FloatRegister($src$$reg));
17669     } else {
17670       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17671              as_FloatRegister($src$$reg), sh);
17672     }
17673   %}
17674   ins_pipe(vshift128_imm);
17675 %}
17676 
17677 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17678   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17679   match(Set dst (LShiftVI src shift));
17680   ins_cost(INSN_COST);
17681   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17682   ins_encode %{
17683     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17684             as_FloatRegister($src$$reg),
17685             as_FloatRegister($shift$$reg));
17686   %}
17687   ins_pipe(vshift64);
17688 %}
17689 
17690 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17691   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17692   match(Set dst (LShiftVI src shift));
17693   ins_cost(INSN_COST);
17694   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17695   ins_encode %{
17696     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17697             as_FloatRegister($src$$reg),
17698             as_FloatRegister($shift$$reg));
17699   %}
17700   ins_pipe(vshift128);
17701 %}
17702 
17703 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17704   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17705   match(Set dst (RShiftVI src shift));
17706   ins_cost(INSN_COST);
17707   effect(TEMP tmp);
17708   format %{ &quot;negr  $tmp,$shift\t&quot;
17709             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17710   ins_encode %{
17711     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17712             as_FloatRegister($shift$$reg));
17713     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17714             as_FloatRegister($src$$reg),
17715             as_FloatRegister($tmp$$reg));
17716   %}
17717   ins_pipe(vshift64);
17718 %}
17719 
17720 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17721   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17722   match(Set dst (RShiftVI src shift));
17723   ins_cost(INSN_COST);
17724   effect(TEMP tmp);
17725   format %{ &quot;negr  $tmp,$shift\t&quot;
17726             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17727   ins_encode %{
17728     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17729             as_FloatRegister($shift$$reg));
17730     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17731             as_FloatRegister($src$$reg),
17732             as_FloatRegister($tmp$$reg));
17733   %}
17734   ins_pipe(vshift128);
17735 %}
17736 
17737 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17738   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17739   match(Set dst (URShiftVI src shift));
17740   ins_cost(INSN_COST);
17741   effect(TEMP tmp);
17742   format %{ &quot;negr  $tmp,$shift\t&quot;
17743             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17744   ins_encode %{
17745     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17746             as_FloatRegister($shift$$reg));
17747     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17748             as_FloatRegister($src$$reg),
17749             as_FloatRegister($tmp$$reg));
17750   %}
17751   ins_pipe(vshift64);
17752 %}
17753 
17754 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17755   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17756   match(Set dst (URShiftVI src shift));
17757   ins_cost(INSN_COST);
17758   effect(TEMP tmp);
17759   format %{ &quot;negr  $tmp,$shift\t&quot;
17760             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17761   ins_encode %{
17762     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17763             as_FloatRegister($shift$$reg));
17764     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17765             as_FloatRegister($src$$reg),
17766             as_FloatRegister($tmp$$reg));
17767   %}
17768   ins_pipe(vshift128);
17769 %}
17770 
17771 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17772   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17773   match(Set dst (LShiftVI src (LShiftCntV shift)));
17774   ins_cost(INSN_COST);
17775   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17776   ins_encode %{
17777     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17778            as_FloatRegister($src$$reg),
17779            (int)$shift$$constant);
17780   %}
17781   ins_pipe(vshift64_imm);
17782 %}
17783 
17784 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17785   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17786   match(Set dst (LShiftVI src (LShiftCntV shift)));
17787   ins_cost(INSN_COST);
17788   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17789   ins_encode %{
17790     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17791            as_FloatRegister($src$$reg),
17792            (int)$shift$$constant);
17793   %}
17794   ins_pipe(vshift128_imm);
17795 %}
17796 
17797 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17798   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17799   match(Set dst (RShiftVI src (RShiftCntV shift)));
17800   ins_cost(INSN_COST);
17801   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17802   ins_encode %{
17803     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17804             as_FloatRegister($src$$reg),
17805             (int)$shift$$constant);
17806   %}
17807   ins_pipe(vshift64_imm);
17808 %}
17809 
17810 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17811   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17812   match(Set dst (RShiftVI src (RShiftCntV shift)));
17813   ins_cost(INSN_COST);
17814   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17815   ins_encode %{
17816     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17817             as_FloatRegister($src$$reg),
17818             (int)$shift$$constant);
17819   %}
17820   ins_pipe(vshift128_imm);
17821 %}
17822 
17823 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17824   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17825   match(Set dst (URShiftVI src (RShiftCntV shift)));
17826   ins_cost(INSN_COST);
17827   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17828   ins_encode %{
17829     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17830             as_FloatRegister($src$$reg),
17831             (int)$shift$$constant);
17832   %}
17833   ins_pipe(vshift64_imm);
17834 %}
17835 
17836 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17837   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17838   match(Set dst (URShiftVI src (RShiftCntV shift)));
17839   ins_cost(INSN_COST);
17840   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17841   ins_encode %{
17842     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17843             as_FloatRegister($src$$reg),
17844             (int)$shift$$constant);
17845   %}
17846   ins_pipe(vshift128_imm);
17847 %}
17848 
17849 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17850   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17851   match(Set dst (LShiftVL src shift));
17852   ins_cost(INSN_COST);
17853   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17854   ins_encode %{
17855     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17856             as_FloatRegister($src$$reg),
17857             as_FloatRegister($shift$$reg));
17858   %}
17859   ins_pipe(vshift128);
17860 %}
17861 
17862 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17864   match(Set dst (RShiftVL src shift));
17865   ins_cost(INSN_COST);
17866   effect(TEMP tmp);
17867   format %{ &quot;negr  $tmp,$shift\t&quot;
17868             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17869   ins_encode %{
17870     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17871             as_FloatRegister($shift$$reg));
17872     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17873             as_FloatRegister($src$$reg),
17874             as_FloatRegister($tmp$$reg));
17875   %}
17876   ins_pipe(vshift128);
17877 %}
17878 
17879 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17880   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17881   match(Set dst (URShiftVL src shift));
17882   ins_cost(INSN_COST);
17883   effect(TEMP tmp);
17884   format %{ &quot;negr  $tmp,$shift\t&quot;
17885             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17886   ins_encode %{
17887     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17888             as_FloatRegister($shift$$reg));
17889     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17890             as_FloatRegister($src$$reg),
17891             as_FloatRegister($tmp$$reg));
17892   %}
17893   ins_pipe(vshift128);
17894 %}
17895 
17896 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17897   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17898   match(Set dst (LShiftVL src (LShiftCntV shift)));
17899   ins_cost(INSN_COST);
17900   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17901   ins_encode %{
17902     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17903            as_FloatRegister($src$$reg),
17904            (int)$shift$$constant);
17905   %}
17906   ins_pipe(vshift128_imm);
17907 %}
17908 
17909 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17910   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17911   match(Set dst (RShiftVL src (RShiftCntV shift)));
17912   ins_cost(INSN_COST);
17913   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17914   ins_encode %{
17915     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17916             as_FloatRegister($src$$reg),
17917             (int)$shift$$constant);
17918   %}
17919   ins_pipe(vshift128_imm);
17920 %}
17921 
17922 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17923   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17924   match(Set dst (URShiftVL src (RShiftCntV shift)));
17925   ins_cost(INSN_COST);
17926   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17927   ins_encode %{
17928     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17929             as_FloatRegister($src$$reg),
17930             (int)$shift$$constant);
17931   %}
17932   ins_pipe(vshift128_imm);
17933 %}
17934 
17935 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17936 %{
17937   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17938   match(Set dst (MaxV src1 src2));
17939   ins_cost(INSN_COST);
17940   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17941   ins_encode %{
17942     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17943             as_FloatRegister($src1$$reg),
17944             as_FloatRegister($src2$$reg));
17945   %}
17946   ins_pipe(vdop_fp64);
17947 %}
17948 
17949 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17950 %{
17951   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17952   match(Set dst (MaxV src1 src2));
17953   ins_cost(INSN_COST);
17954   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17955   ins_encode %{
17956     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17957             as_FloatRegister($src1$$reg),
17958             as_FloatRegister($src2$$reg));
17959   %}
17960   ins_pipe(vdop_fp128);
17961 %}
17962 
17963 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17964 %{
17965   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17966   match(Set dst (MaxV src1 src2));
17967   ins_cost(INSN_COST);
17968   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17969   ins_encode %{
17970     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17971             as_FloatRegister($src1$$reg),
17972             as_FloatRegister($src2$$reg));
17973   %}
17974   ins_pipe(vdop_fp128);
17975 %}
17976 
17977 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17978 %{
17979   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17980   match(Set dst (MinV src1 src2));
17981   ins_cost(INSN_COST);
17982   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17983   ins_encode %{
17984     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17985             as_FloatRegister($src1$$reg),
17986             as_FloatRegister($src2$$reg));
17987   %}
17988   ins_pipe(vdop_fp64);
17989 %}
17990 
17991 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17992 %{
17993   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17994   match(Set dst (MinV src1 src2));
17995   ins_cost(INSN_COST);
17996   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17997   ins_encode %{
17998     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17999             as_FloatRegister($src1$$reg),
18000             as_FloatRegister($src2$$reg));
18001   %}
18002   ins_pipe(vdop_fp128);
18003 %}
18004 
18005 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18006 %{
18007   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18008   match(Set dst (MinV src1 src2));
18009   ins_cost(INSN_COST);
18010   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18011   ins_encode %{
18012     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18013             as_FloatRegister($src1$$reg),
18014             as_FloatRegister($src2$$reg));
18015   %}
18016   ins_pipe(vdop_fp128);
18017 %}
18018 
18019 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18020   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18021   match(Set dst (RoundDoubleModeV src rmode));
18022   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18023   ins_encode %{
18024     switch ($rmode$$constant) {
18025       case RoundDoubleModeNode::rmode_rint:
18026         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18027                   as_FloatRegister($src$$reg));
18028         break;
18029       case RoundDoubleModeNode::rmode_floor:
18030         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18031                   as_FloatRegister($src$$reg));
18032         break;
18033       case RoundDoubleModeNode::rmode_ceil:
18034         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18035                   as_FloatRegister($src$$reg));
18036         break;
18037     }
18038   %}
18039   ins_pipe(vdop_fp128);
18040 %}
18041 
18042 instruct vpopcount4I(vecX dst, vecX src) %{
18043   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18044   match(Set dst (PopCountVI src));
18045   format %{
18046     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18047     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18048     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18049   %}
18050   ins_encode %{
18051      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18052             as_FloatRegister($src$$reg));
18053      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18054                as_FloatRegister($dst$$reg));
18055      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18056                as_FloatRegister($dst$$reg));
18057   %}
18058   ins_pipe(pipe_class_default);
18059 %}
18060 
18061 instruct vpopcount2I(vecD dst, vecD src) %{
18062   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18063   match(Set dst (PopCountVI src));
18064   format %{
18065     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18066     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18067     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18068   %}
18069   ins_encode %{
18070      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18071             as_FloatRegister($src$$reg));
18072      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18073                as_FloatRegister($dst$$reg));
18074      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18075                as_FloatRegister($dst$$reg));
18076   %}
18077   ins_pipe(pipe_class_default);
18078 %}
18079 
18080 //----------PEEPHOLE RULES-----------------------------------------------------
18081 // These must follow all instruction definitions as they use the names
18082 // defined in the instructions definitions.
18083 //
18084 // peepmatch ( root_instr_name [preceding_instruction]* );
18085 //
18086 // peepconstraint %{
18087 // (instruction_number.operand_name relational_op instruction_number.operand_name
18088 //  [, ...] );
18089 // // instruction numbers are zero-based using left to right order in peepmatch
18090 //
18091 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18092 // // provide an instruction_number.operand_name for each operand that appears
18093 // // in the replacement instruction&#39;s match rule
18094 //
18095 // ---------VM FLAGS---------------------------------------------------------
18096 //
18097 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18098 //
18099 // Each peephole rule is given an identifying number starting with zero and
18100 // increasing by one in the order seen by the parser.  An individual peephole
18101 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18102 // on the command-line.
18103 //
18104 // ---------CURRENT LIMITATIONS----------------------------------------------
18105 //
18106 // Only match adjacent instructions in same basic block
18107 // Only equality constraints
18108 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18109 // Only one replacement instruction
18110 //
18111 // ---------EXAMPLE----------------------------------------------------------
18112 //
18113 // // pertinent parts of existing instructions in architecture description
18114 // instruct movI(iRegINoSp dst, iRegI src)
18115 // %{
18116 //   match(Set dst (CopyI src));
18117 // %}
18118 //
18119 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18120 // %{
18121 //   match(Set dst (AddI dst src));
18122 //   effect(KILL cr);
18123 // %}
18124 //
18125 // // Change (inc mov) to lea
18126 // peephole %{
18127 //   // increment preceeded by register-register move
18128 //   peepmatch ( incI_iReg movI );
18129 //   // require that the destination register of the increment
18130 //   // match the destination register of the move
18131 //   peepconstraint ( 0.dst == 1.dst );
18132 //   // construct a replacement instruction that sets
18133 //   // the destination to ( move&#39;s source register + one )
18134 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18135 // %}
18136 //
18137 
18138 // Implementation no longer uses movX instructions since
18139 // machine-independent system no longer uses CopyX nodes.
18140 //
18141 // peephole
18142 // %{
18143 //   peepmatch (incI_iReg movI);
18144 //   peepconstraint (0.dst == 1.dst);
18145 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18146 // %}
18147 
18148 // peephole
18149 // %{
18150 //   peepmatch (decI_iReg movI);
18151 //   peepconstraint (0.dst == 1.dst);
18152 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18153 // %}
18154 
18155 // peephole
18156 // %{
18157 //   peepmatch (addI_iReg_imm movI);
18158 //   peepconstraint (0.dst == 1.dst);
18159 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18160 // %}
18161 
18162 // peephole
18163 // %{
18164 //   peepmatch (incL_iReg movL);
18165 //   peepconstraint (0.dst == 1.dst);
18166 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18167 // %}
18168 
18169 // peephole
18170 // %{
18171 //   peepmatch (decL_iReg movL);
18172 //   peepconstraint (0.dst == 1.dst);
18173 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18174 // %}
18175 
18176 // peephole
18177 // %{
18178 //   peepmatch (addL_iReg_imm movL);
18179 //   peepconstraint (0.dst == 1.dst);
18180 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18181 // %}
18182 
18183 // peephole
18184 // %{
18185 //   peepmatch (addP_iReg_imm movP);
18186 //   peepconstraint (0.dst == 1.dst);
18187 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18188 // %}
18189 
18190 // // Change load of spilled value to only a spill
18191 // instruct storeI(memory mem, iRegI src)
18192 // %{
18193 //   match(Set mem (StoreI mem src));
18194 // %}
18195 //
18196 // instruct loadI(iRegINoSp dst, memory mem)
18197 // %{
18198 //   match(Set dst (LoadI mem));
18199 // %}
18200 //
18201 
18202 //----------SMARTSPILL RULES---------------------------------------------------
18203 // These must follow all instruction definitions as they use the names
18204 // defined in the instructions definitions.
18205 
18206 // Local Variables:
18207 // mode: c++
18208 // End:
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>