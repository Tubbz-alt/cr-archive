<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
 1643   C2_MacroAssembler _masm(&amp;cbuf);
 1644 
<a name="1" id="anc1"></a><span class="line-modified"> 1645   // n.b. frame size includes space for return pc and rfp</span>
<span class="line-modified"> 1646   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-removed"> 1647   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);</span>
<span class="line-removed"> 1648 </span>
<span class="line-removed"> 1649   // insert a nop at the start of the prolog so we can patch in a</span>
<span class="line-removed"> 1650   // branch if we need to invalidate the method later</span>
<span class="line-removed"> 1651   __ nop();</span>
<span class="line-removed"> 1652 </span>
<span class="line-removed"> 1653   if (C-&gt;clinit_barrier_on_entry()) {</span>
<span class="line-removed"> 1654     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);</span>
<span class="line-removed"> 1655 </span>
<span class="line-removed"> 1656     Label L_skip_barrier;</span>
<span class="line-removed"> 1657 </span>
<span class="line-removed"> 1658     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());</span>
<span class="line-removed"> 1659     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);</span>
<span class="line-removed"> 1660     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));</span>
<span class="line-removed"> 1661     __ bind(L_skip_barrier);</span>
<span class="line-removed"> 1662   }</span>
<span class="line-removed"> 1663 </span>
<span class="line-removed"> 1664   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-removed"> 1665   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
<span class="line-removed"> 1666     __ generate_stack_overflow_check(bangsize);</span>
<span class="line-removed"> 1667 </span>
<span class="line-removed"> 1668   __ build_frame(framesize);</span>
<span class="line-removed"> 1669 </span>
<span class="line-removed"> 1670   if (VerifyStackAtCalls) {</span>
<span class="line-removed"> 1671     Unimplemented();</span>
<span class="line-removed"> 1672   }</span>
 1673 
 1674   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1675 
 1676   if (C-&gt;has_mach_constant_base_node()) {
 1677     // NOTE: We set the table base offset here because users might be
 1678     // emitted before MachConstantBaseNode.
 1679     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1680     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1681   }
 1682 }
 1683 
 1684 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1685 {
 1686   return MachNode::size(ra_); // too many variables; just compute it
 1687                               // the hard way
 1688 }
 1689 
 1690 int MachPrologNode::reloc() const
 1691 {
 1692   return 0;
 1693 }
 1694 
 1695 //=============================================================================
 1696 
 1697 #ifndef PRODUCT
 1698 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1699   Compile* C = ra_-&gt;C;
 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1701 
 1702   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1703 
 1704   if (framesize == 0) {
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1707     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1708     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1709   } else {
 1710     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1711     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1712     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1713   }
 1714 
 1715   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1716     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1717     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1718     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1719   }
 1720 }
 1721 #endif
 1722 
 1723 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1724   Compile* C = ra_-&gt;C;
 1725   C2_MacroAssembler _masm(&amp;cbuf);
 1726   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1727 
 1728   __ remove_frame(framesize);
 1729 
 1730   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1731     __ reserved_stack_check();
 1732   }
 1733 
 1734   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1735     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1736   }
 1737 }
 1738 
 1739 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1740   // Variable size. Determine dynamically.
 1741   return MachNode::size(ra_);
 1742 }
 1743 
 1744 int MachEpilogNode::reloc() const {
 1745   // Return number of relocatable values contained in this instruction.
 1746   return 1; // 1 for polling page.
 1747 }
 1748 
 1749 const Pipeline * MachEpilogNode::pipeline() const {
 1750   return MachNode::pipeline_class();
 1751 }
 1752 
 1753 //=============================================================================
 1754 
 1755 // Figure out which register class each belongs in: rc_int, rc_float or
 1756 // rc_stack.
 1757 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1758 
 1759 static enum RC rc_class(OptoReg::Name reg) {
 1760 
 1761   if (reg == OptoReg::Bad) {
 1762     return rc_bad;
 1763   }
 1764 
 1765   // we have 30 int registers * 2 halves
 1766   // (rscratch1 and rscratch2 are omitted)
 1767   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1768 
 1769   if (reg &lt; slots_of_int_registers) {
 1770     return rc_int;
 1771   }
 1772 
 1773   // we have 32 float register * 4 halves
 1774   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1775     return rc_float;
 1776   }
 1777 
 1778   // Between float regs &amp; stack is the flags regs.
 1779   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1780 
 1781   return rc_stack;
 1782 }
 1783 
 1784 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1785   Compile* C = ra_-&gt;C;
 1786 
 1787   // Get registers to move.
 1788   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1789   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1790   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1791   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1792 
 1793   enum RC src_hi_rc = rc_class(src_hi);
 1794   enum RC src_lo_rc = rc_class(src_lo);
 1795   enum RC dst_hi_rc = rc_class(dst_hi);
 1796   enum RC dst_lo_rc = rc_class(dst_lo);
 1797 
 1798   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1799 
 1800   if (src_hi != OptoReg::Bad) {
 1801     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1802            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1803            &quot;expected aligned-adjacent pairs&quot;);
 1804   }
 1805 
 1806   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1807     return 0;            // Self copy, no move.
 1808   }
 1809 
 1810   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1811               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1812   int src_offset = ra_-&gt;reg2offset(src_lo);
 1813   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1814 
 1815   if (bottom_type()-&gt;isa_vect() != NULL) {
 1816     uint ireg = ideal_reg();
 1817     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1818     if (cbuf) {
 1819       C2_MacroAssembler _masm(cbuf);
 1820       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1821       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1822         // stack-&gt;stack
 1823         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1824         if (ireg == Op_VecD) {
 1825           __ unspill(rscratch1, true, src_offset);
 1826           __ spill(rscratch1, true, dst_offset);
 1827         } else {
 1828           __ spill_copy128(src_offset, dst_offset);
 1829         }
 1830       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1831         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1832                ireg == Op_VecD ? __ T8B : __ T16B,
 1833                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1834       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1835         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1836                        ireg == Op_VecD ? __ D : __ Q,
 1837                        ra_-&gt;reg2offset(dst_lo));
 1838       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1839         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1840                        ireg == Op_VecD ? __ D : __ Q,
 1841                        ra_-&gt;reg2offset(src_lo));
 1842       } else {
 1843         ShouldNotReachHere();
 1844       }
 1845     }
 1846   } else if (cbuf) {
 1847     C2_MacroAssembler _masm(cbuf);
 1848     switch (src_lo_rc) {
 1849     case rc_int:
 1850       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1851         if (is64) {
 1852             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1853                    as_Register(Matcher::_regEncode[src_lo]));
 1854         } else {
 1855             C2_MacroAssembler _masm(cbuf);
 1856             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1857                     as_Register(Matcher::_regEncode[src_lo]));
 1858         }
 1859       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1860         if (is64) {
 1861             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1862                      as_Register(Matcher::_regEncode[src_lo]));
 1863         } else {
 1864             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1865                      as_Register(Matcher::_regEncode[src_lo]));
 1866         }
 1867       } else {                    // gpr --&gt; stack spill
 1868         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1869         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1870       }
 1871       break;
 1872     case rc_float:
 1873       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1874         if (is64) {
 1875             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1876                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1877         } else {
 1878             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1879                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1880         }
 1881       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1882           if (cbuf) {
 1883             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1884                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1885         } else {
 1886             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1887                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1888         }
 1889       } else {                    // fpr --&gt; stack spill
 1890         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1891         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1892                  is64 ? __ D : __ S, dst_offset);
 1893       }
 1894       break;
 1895     case rc_stack:
 1896       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1897         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1898       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1899         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1900                    is64 ? __ D : __ S, src_offset);
 1901       } else {                    // stack --&gt; stack copy
 1902         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1903         __ unspill(rscratch1, is64, src_offset);
 1904         __ spill(rscratch1, is64, dst_offset);
 1905       }
 1906       break;
 1907     default:
 1908       assert(false, &quot;bad rc_class for spill&quot;);
 1909       ShouldNotReachHere();
 1910     }
 1911   }
 1912 
 1913   if (st) {
 1914     st-&gt;print(&quot;spill &quot;);
 1915     if (src_lo_rc == rc_stack) {
 1916       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1917     } else {
 1918       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1919     }
 1920     if (dst_lo_rc == rc_stack) {
 1921       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1922     } else {
 1923       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1924     }
 1925     if (bottom_type()-&gt;isa_vect() != NULL) {
 1926       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1927     } else {
 1928       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1929     }
 1930   }
 1931 
 1932   return 0;
 1933 
 1934 }
 1935 
 1936 #ifndef PRODUCT
 1937 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1938   if (!ra_)
 1939     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1940   else
 1941     implementation(NULL, ra_, false, st);
 1942 }
 1943 #endif
 1944 
 1945 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1946   implementation(&amp;cbuf, ra_, false, NULL);
 1947 }
 1948 
 1949 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1950   return MachNode::size(ra_);
 1951 }
 1952 
 1953 //=============================================================================
 1954 
 1955 #ifndef PRODUCT
 1956 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg = ra_-&gt;get_reg_first(this);
 1959   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1960             Matcher::regName[reg], offset);
 1961 }
 1962 #endif
 1963 
 1964 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1965   C2_MacroAssembler _masm(&amp;cbuf);
 1966 
 1967   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1968   int reg    = ra_-&gt;get_encode(this);
 1969 
 1970   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1971     __ add(as_Register(reg), sp, offset);
 1972   } else {
 1973     ShouldNotReachHere();
 1974   }
 1975 }
 1976 
 1977 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1978   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1979   return 4;
 1980 }
 1981 
<a name="2" id="anc2"></a><span class="line-modified"> 1982 //=============================================================================</span>





































 1983 
<a name="3" id="anc3"></a>
 1984 #ifndef PRODUCT
 1985 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1986 {
 1987   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1988   if (UseCompressedClassPointers) {
 1989     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1990     if (CompressedKlassPointers::shift() != 0) {
 1991       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1992     }
 1993   } else {
 1994    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1995   }
 1996   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1997   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1998 }
 1999 #endif
 2000 
 2001 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2002 {
 2003   // This is the unverified entry point.
 2004   C2_MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a>
 2005 
<a name="5" id="anc5"></a>
 2006   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
<a name="6" id="anc6"></a><span class="line-modified"> 2007   Label skip;</span>
 2008   // TODO
 2009   // can we avoid this skip and still use a reloc?
 2010   __ br(Assembler::EQ, skip);
 2011   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2012   __ bind(skip);
 2013 }
 2014 
 2015 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2016 {
 2017   return MachNode::size(ra_);
 2018 }
 2019 
 2020 // REQUIRED EMIT CODE
 2021 
 2022 //=============================================================================
 2023 
 2024 // Emit exception handler code.
 2025 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2026 {
 2027   // mov rscratch1 #exception_blob_entry_point
 2028   // br rscratch1
 2029   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2030   // That&#39;s why we must use the macroassembler to generate a handler.
 2031   C2_MacroAssembler _masm(&amp;cbuf);
 2032   address base = __ start_a_stub(size_exception_handler());
 2033   if (base == NULL) {
 2034     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2035     return 0;  // CodeBuffer::expand failed
 2036   }
 2037   int offset = __ offset();
 2038   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2039   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2040   __ end_a_stub();
 2041   return offset;
 2042 }
 2043 
 2044 // Emit deopt handler code.
 2045 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2046 {
 2047   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2048   // That&#39;s why we must use the macroassembler to generate a handler.
 2049   C2_MacroAssembler _masm(&amp;cbuf);
 2050   address base = __ start_a_stub(size_deopt_handler());
 2051   if (base == NULL) {
 2052     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2053     return 0;  // CodeBuffer::expand failed
 2054   }
 2055   int offset = __ offset();
 2056 
 2057   __ adr(lr, __ pc());
 2058   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2059 
 2060   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2061   __ end_a_stub();
 2062   return offset;
 2063 }
 2064 
 2065 // REQUIRED MATCHER CODE
 2066 
 2067 //=============================================================================
 2068 
 2069 const bool Matcher::match_rule_supported(int opcode) {
 2070   if (!has_match_rule(opcode))
 2071     return false;
 2072 
 2073   bool ret_value = true;
 2074   switch (opcode) {
 2075     case Op_CacheWB:
 2076     case Op_CacheWBPreSync:
 2077     case Op_CacheWBPostSync:
 2078       if (!VM_Version::supports_data_cache_line_flush()) {
 2079         ret_value = false;
 2080       }
 2081       break;
 2082   }
 2083 
 2084   return ret_value; // Per default match rules are supported.
 2085 }
 2086 
 2087 // Identify extra cases that we might want to provide match rules for vector nodes and
 2088 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2089 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2090   if (!match_rule_supported(opcode)) {
 2091     return false;
 2092   }
 2093 
 2094   // Special cases which require vector length
 2095   switch (opcode) {
 2096     case Op_MulAddVS2VI: {
 2097       if (vlen != 4) {
 2098         return false;
 2099       }
 2100       break;
 2101     }
 2102   }
 2103 
 2104   return true; // Per default match rules are supported.
 2105 }
 2106 
 2107 const bool Matcher::has_predicated_vectors(void) {
 2108   return false;
 2109 }
 2110 
 2111 const int Matcher::float_pressure(int default_pressure_threshold) {
 2112   return default_pressure_threshold;
 2113 }
 2114 
 2115 int Matcher::regnum_to_fpu_offset(int regnum)
 2116 {
 2117   Unimplemented();
 2118   return 0;
 2119 }
 2120 
 2121 // Is this branch offset short enough that a short branch can be used?
 2122 //
 2123 // NOTE: If the platform does not provide any short branch variants, then
 2124 //       this method should return false for offset 0.
 2125 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2126   // The passed offset is relative to address of the branch.
 2127 
 2128   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2129 }
 2130 
 2131 const bool Matcher::isSimpleConstant64(jlong value) {
 2132   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2133   // Probably always true, even if a temp register is required.
 2134   return true;
 2135 }
 2136 
 2137 // true just means we have fast l2f conversion
 2138 const bool Matcher::convL2FSupported(void) {
 2139   return true;
 2140 }
 2141 
 2142 // Vector width in bytes.
 2143 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2144   int size = MIN2(16,(int)MaxVectorSize);
 2145   // Minimum 2 values in vector
 2146   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2147   // But never &lt; 4
 2148   if (size &lt; 4) size = 0;
 2149   return size;
 2150 }
 2151 
 2152 // Limits on vector size (number of elements) loaded into vector.
 2153 const int Matcher::max_vector_size(const BasicType bt) {
 2154   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2155 }
 2156 const int Matcher::min_vector_size(const BasicType bt) {
 2157 //  For the moment limit the vector size to 8 bytes
 2158     int size = 8 / type2aelembytes(bt);
 2159     if (size &lt; 2) size = 2;
 2160     return size;
 2161 }
 2162 
 2163 // Vector ideal reg.
 2164 const uint Matcher::vector_ideal_reg(int len) {
 2165   switch(len) {
 2166     case  8: return Op_VecD;
 2167     case 16: return Op_VecX;
 2168   }
 2169   ShouldNotReachHere();
 2170   return 0;
 2171 }
 2172 
 2173 // AES support not yet implemented
 2174 const bool Matcher::pass_original_key_for_aes() {
 2175   return false;
 2176 }
 2177 
 2178 // aarch64 supports misaligned vectors store/load.
 2179 const bool Matcher::misaligned_vectors_ok() {
 2180   return true;
 2181 }
 2182 
 2183 // false =&gt; size gets scaled to BytesPerLong, ok.
 2184 const bool Matcher::init_array_count_is_in_bytes = false;
 2185 
 2186 // Use conditional move (CMOVL)
 2187 const int Matcher::long_cmove_cost() {
 2188   // long cmoves are no more expensive than int cmoves
 2189   return 0;
 2190 }
 2191 
 2192 const int Matcher::float_cmove_cost() {
 2193   // float cmoves are no more expensive than int cmoves
 2194   return 0;
 2195 }
 2196 
 2197 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2198 const bool Matcher::require_postalloc_expand = false;
 2199 
 2200 // Do we need to mask the count passed to shift instructions or does
 2201 // the cpu only look at the lower 5/6 bits anyway?
 2202 const bool Matcher::need_masked_shift_count = false;
 2203 
 2204 // No support for generic vector operands.
 2205 const bool Matcher::supports_generic_vector_operands  = false;
 2206 
 2207 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2208   ShouldNotReachHere(); // generic vector operands not supported
 2209   return NULL;
 2210 }
 2211 
 2212 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2213   ShouldNotReachHere();  // generic vector operands not supported
 2214   return false;
 2215 }
 2216 
 2217 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2218   ShouldNotReachHere();  // generic vector operands not supported
 2219   return false;
 2220 }
 2221 
 2222 // This affects two different things:
 2223 //  - how Decode nodes are matched
 2224 //  - how ImplicitNullCheck opportunities are recognized
 2225 // If true, the matcher will try to remove all Decodes and match them
 2226 // (as operands) into nodes. NullChecks are not prepared to deal with
 2227 // Decodes by final_graph_reshaping().
 2228 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2229 // for a NullCheck. The matcher matches the Decode node into a register.
 2230 // Implicit_null_check optimization moves the Decode along with the
 2231 // memory operation back up before the NullCheck.
 2232 bool Matcher::narrow_oop_use_complex_address() {
 2233   return CompressedOops::shift() == 0;
 2234 }
 2235 
 2236 bool Matcher::narrow_klass_use_complex_address() {
 2237 // TODO
 2238 // decide whether we need to set this to true
 2239   return false;
 2240 }
 2241 
 2242 bool Matcher::const_oop_prefer_decode() {
 2243   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2244   return CompressedOops::base() == NULL;
 2245 }
 2246 
 2247 bool Matcher::const_klass_prefer_decode() {
 2248   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2249   return CompressedKlassPointers::base() == NULL;
 2250 }
 2251 
 2252 // Is it better to copy float constants, or load them directly from
 2253 // memory?  Intel can load a float constant from a direct address,
 2254 // requiring no extra registers.  Most RISCs will have to materialize
 2255 // an address into a register first, so they would do better to copy
 2256 // the constant from stack.
 2257 const bool Matcher::rematerialize_float_constants = false;
 2258 
 2259 // If CPU can load and store mis-aligned doubles directly then no
 2260 // fixup is needed.  Else we split the double into 2 integer pieces
 2261 // and move it piece-by-piece.  Only happens when passing doubles into
 2262 // C code as the Java calling convention forces doubles to be aligned.
 2263 const bool Matcher::misaligned_doubles_ok = true;
 2264 
 2265 // No-op on amd64
 2266 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2267   Unimplemented();
 2268 }
 2269 
 2270 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2271 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2272 
 2273 // Are floats converted to double when stored to stack during
 2274 // deoptimization?
 2275 bool Matcher::float_in_double() { return false; }
 2276 
 2277 // Do ints take an entire long register or just half?
 2278 // The relevant question is how the int is callee-saved:
 2279 // the whole long is written but de-opt&#39;ing will have to extract
 2280 // the relevant 32 bits.
 2281 const bool Matcher::int_in_long = true;
 2282 
 2283 // Return whether or not this register is ever used as an argument.
 2284 // This function is used on startup to build the trampoline stubs in
 2285 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2286 // call in the trampoline, and arguments in those registers not be
 2287 // available to the callee.
 2288 bool Matcher::can_be_java_arg(int reg)
 2289 {
 2290   return
 2291     reg ==  R0_num || reg == R0_H_num ||
 2292     reg ==  R1_num || reg == R1_H_num ||
 2293     reg ==  R2_num || reg == R2_H_num ||
 2294     reg ==  R3_num || reg == R3_H_num ||
 2295     reg ==  R4_num || reg == R4_H_num ||
 2296     reg ==  R5_num || reg == R5_H_num ||
 2297     reg ==  R6_num || reg == R6_H_num ||
 2298     reg ==  R7_num || reg == R7_H_num ||
 2299     reg ==  V0_num || reg == V0_H_num ||
 2300     reg ==  V1_num || reg == V1_H_num ||
 2301     reg ==  V2_num || reg == V2_H_num ||
 2302     reg ==  V3_num || reg == V3_H_num ||
 2303     reg ==  V4_num || reg == V4_H_num ||
 2304     reg ==  V5_num || reg == V5_H_num ||
 2305     reg ==  V6_num || reg == V6_H_num ||
 2306     reg ==  V7_num || reg == V7_H_num;
 2307 }
 2308 
 2309 bool Matcher::is_spillable_arg(int reg)
 2310 {
 2311   return can_be_java_arg(reg);
 2312 }
 2313 
 2314 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2315   return false;
 2316 }
 2317 
 2318 RegMask Matcher::divI_proj_mask() {
 2319   ShouldNotReachHere();
 2320   return RegMask();
 2321 }
 2322 
 2323 // Register for MODI projection of divmodI.
 2324 RegMask Matcher::modI_proj_mask() {
 2325   ShouldNotReachHere();
 2326   return RegMask();
 2327 }
 2328 
 2329 // Register for DIVL projection of divmodL.
 2330 RegMask Matcher::divL_proj_mask() {
 2331   ShouldNotReachHere();
 2332   return RegMask();
 2333 }
 2334 
 2335 // Register for MODL projection of divmodL.
 2336 RegMask Matcher::modL_proj_mask() {
 2337   ShouldNotReachHere();
 2338   return RegMask();
 2339 }
 2340 
 2341 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2342   return FP_REG_mask();
 2343 }
 2344 
 2345 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2346   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2347     Node* u = addp-&gt;fast_out(i);
 2348     if (u-&gt;is_Mem()) {
 2349       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2350       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2351       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2352         return false;
 2353       }
 2354     }
 2355   }
 2356   return true;
 2357 }
 2358 
 2359 const bool Matcher::convi2l_type_required = false;
 2360 
 2361 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2362 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2363   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2364     mstack.push(m, Visit);           // m = ShiftCntV
 2365     return true;
 2366   }
 2367   return false;
 2368 }
 2369 
 2370 // Should the Matcher clone shifts on addressing modes, expecting them
 2371 // to be subsumed into complex addressing expressions or compute them
 2372 // into registers?
 2373 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2374   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2375     return true;
 2376   }
 2377 
 2378   Node *off = m-&gt;in(AddPNode::Offset);
 2379   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2380       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2381       // Are there other uses besides address expressions?
 2382       !is_visited(off)) {
 2383     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2384     mstack.push(off-&gt;in(2), Visit);
 2385     Node *conv = off-&gt;in(1);
 2386     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2387         // Are there other uses besides address expressions?
 2388         !is_visited(conv)) {
 2389       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2390       mstack.push(conv-&gt;in(1), Pre_Visit);
 2391     } else {
 2392       mstack.push(conv, Pre_Visit);
 2393     }
 2394     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2395     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2396     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2397     return true;
 2398   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2399              // Are there other uses besides address expressions?
 2400              !is_visited(off)) {
 2401     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2402     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2403     mstack.push(off-&gt;in(1), Pre_Visit);
 2404     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2405     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2406     return true;
 2407   }
 2408   return false;
 2409 }
 2410 
 2411 void Compile::reshape_address(AddPNode* addp) {
 2412 }
 2413 
<a name="7" id="anc7"></a><span class="line-removed"> 2414 </span>
 2415 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2416   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2417   {                                                                     \
 2418     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2419     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2420     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2421     __ INSN(REG, as_Register(BASE));                                    \
 2422   }
 2423 
 2424 
 2425 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2426   {
 2427     Address::extend scale;
 2428 
 2429     // Hooboy, this is fugly.  We need a way to communicate to the
 2430     // encoder that the index needs to be sign extended, so we have to
 2431     // enumerate all the cases.
 2432     switch (opcode) {
 2433     case INDINDEXSCALEDI2L:
 2434     case INDINDEXSCALEDI2LN:
 2435     case INDINDEXI2L:
 2436     case INDINDEXI2LN:
 2437       scale = Address::sxtw(size);
 2438       break;
 2439     default:
 2440       scale = Address::lsl(size);
 2441     }
 2442 
 2443     if (index == -1) {
 2444       return Address(base, disp);
 2445     } else {
 2446       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2447       return Address(base, as_Register(index), scale);
 2448     }
 2449   }
 2450 
 2451 
 2452 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2453 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2454 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2455 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2456                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2457 
 2458   // Used for all non-volatile memory accesses.  The use of
 2459   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2460   // offsets is something of a kludge.
 2461   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2462                         Register reg, int opcode,
 2463                         Register base, int index, int scale, int disp,
 2464                         int size_in_memory)
 2465   {
 2466     Address addr = mem2address(opcode, base, index, scale, disp);
 2467     if (addr.getMode() == Address::base_plus_offset) {
 2468       /* If we get an out-of-range offset it is a bug in the compiler,
 2469          so we assert here. */
 2470       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2471              &quot;c2 compiler bug&quot;);
 2472       /* Fix up any out-of-range offsets. */
 2473       assert_different_registers(rscratch1, base);
 2474       assert_different_registers(rscratch1, reg);
 2475       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2476     }
 2477     (masm.*insn)(reg, addr);
 2478   }
 2479 
 2480   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2481                         FloatRegister reg, int opcode,
 2482                         Register base, int index, int size, int disp,
 2483                         int size_in_memory)
 2484   {
 2485     Address::extend scale;
 2486 
 2487     switch (opcode) {
 2488     case INDINDEXSCALEDI2L:
 2489     case INDINDEXSCALEDI2LN:
 2490       scale = Address::sxtw(size);
 2491       break;
 2492     default:
 2493       scale = Address::lsl(size);
 2494     }
 2495 
 2496     if (index == -1) {
 2497       /* If we get an out-of-range offset it is a bug in the compiler,
 2498          so we assert here. */
 2499       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2500       /* Fix up any out-of-range offsets. */
 2501       assert_different_registers(rscratch1, base);
 2502       Address addr = Address(base, disp);
 2503       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2504       (masm.*insn)(reg, addr);
 2505     } else {
 2506       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2507       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2508     }
 2509   }
 2510 
 2511   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2512                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2513                         int opcode, Register base, int index, int size, int disp)
 2514   {
 2515     if (index == -1) {
 2516       (masm.*insn)(reg, T, Address(base, disp));
 2517     } else {
 2518       assert(disp == 0, &quot;unsupported address mode&quot;);
 2519       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2520     }
 2521   }
 2522 
 2523 %}
 2524 
 2525 
 2526 
 2527 //----------ENCODING BLOCK-----------------------------------------------------
 2528 // This block specifies the encoding classes used by the compiler to
 2529 // output byte streams.  Encoding classes are parameterized macros
 2530 // used by Machine Instruction Nodes in order to generate the bit
 2531 // encoding of the instruction.  Operands specify their base encoding
 2532 // interface with the interface keyword.  There are currently
 2533 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2534 // COND_INTER.  REG_INTER causes an operand to generate a function
 2535 // which returns its register number when queried.  CONST_INTER causes
 2536 // an operand to generate a function which returns the value of the
 2537 // constant when queried.  MEMORY_INTER causes an operand to generate
 2538 // four functions which return the Base Register, the Index Register,
 2539 // the Scale Value, and the Offset Value of the operand when queried.
 2540 // COND_INTER causes an operand to generate six functions which return
 2541 // the encoding code (ie - encoding bits for the instruction)
 2542 // associated with each basic boolean condition for a conditional
 2543 // instruction.
 2544 //
 2545 // Instructions specify two basic values for encoding.  Again, a
 2546 // function is available to check if the constant displacement is an
 2547 // oop. They use the ins_encode keyword to specify their encoding
 2548 // classes (which must be a sequence of enc_class names, and their
 2549 // parameters, specified in the encoding block), and they use the
 2550 // opcode keyword to specify, in order, their primary, secondary, and
 2551 // tertiary opcode.  Only the opcode sections which a particular
 2552 // instruction needs for encoding need to be specified.
 2553 encode %{
 2554   // Build emit functions for each basic byte or larger field in the
 2555   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2556   // from C++ code in the enc_class source block.  Emit functions will
 2557   // live in the main source block for now.  In future, we can
 2558   // generalize this by adding a syntax that specifies the sizes of
 2559   // fields in an order, so that the adlc can build the emit functions
 2560   // automagically
 2561 
 2562   // catch all for unimplemented encodings
 2563   enc_class enc_unimplemented %{
 2564     C2_MacroAssembler _masm(&amp;cbuf);
 2565     __ unimplemented(&quot;C2 catch all&quot;);
 2566   %}
 2567 
 2568   // BEGIN Non-volatile memory access
 2569 
 2570   // This encoding class is generated automatically from ad_encode.m4.
 2571   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2572   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2573     Register dst_reg = as_Register($dst$$reg);
 2574     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2575                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2576   %}
 2577 
 2578   // This encoding class is generated automatically from ad_encode.m4.
 2579   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2580   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2581     Register dst_reg = as_Register($dst$$reg);
 2582     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2583                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2584   %}
 2585 
 2586   // This encoding class is generated automatically from ad_encode.m4.
 2587   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2588   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2589     Register dst_reg = as_Register($dst$$reg);
 2590     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2591                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2592   %}
 2593 
 2594   // This encoding class is generated automatically from ad_encode.m4.
 2595   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2596   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2597     Register dst_reg = as_Register($dst$$reg);
 2598     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2599                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2600   %}
 2601 
 2602   // This encoding class is generated automatically from ad_encode.m4.
 2603   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2604   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2605     Register dst_reg = as_Register($dst$$reg);
 2606     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2607                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2608   %}
 2609 
 2610   // This encoding class is generated automatically from ad_encode.m4.
 2611   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2612   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2613     Register dst_reg = as_Register($dst$$reg);
 2614     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2615                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2616   %}
 2617 
 2618   // This encoding class is generated automatically from ad_encode.m4.
 2619   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2620   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2621     Register dst_reg = as_Register($dst$$reg);
 2622     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2623                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2624   %}
 2625 
 2626   // This encoding class is generated automatically from ad_encode.m4.
 2627   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2628   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2629     Register dst_reg = as_Register($dst$$reg);
 2630     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2631                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2632   %}
 2633 
 2634   // This encoding class is generated automatically from ad_encode.m4.
 2635   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2636   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2637     Register dst_reg = as_Register($dst$$reg);
 2638     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2639                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2640   %}
 2641 
 2642   // This encoding class is generated automatically from ad_encode.m4.
 2643   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2644   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2645     Register dst_reg = as_Register($dst$$reg);
 2646     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2647                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2648   %}
 2649 
 2650   // This encoding class is generated automatically from ad_encode.m4.
 2651   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2652   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2653     Register dst_reg = as_Register($dst$$reg);
 2654     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2655                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2656   %}
 2657 
 2658   // This encoding class is generated automatically from ad_encode.m4.
 2659   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2660   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2661     Register dst_reg = as_Register($dst$$reg);
 2662     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2663                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2664   %}
 2665 
 2666   // This encoding class is generated automatically from ad_encode.m4.
 2667   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2668   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2669     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2670     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2671                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2672   %}
 2673 
 2674   // This encoding class is generated automatically from ad_encode.m4.
 2675   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2676   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2677     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2678     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2679                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2680   %}
 2681 
 2682   // This encoding class is generated automatically from ad_encode.m4.
 2683   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2684   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2685     Register src_reg = as_Register($src$$reg);
 2686     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2687                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2688   %}
 2689 
 2690   // This encoding class is generated automatically from ad_encode.m4.
 2691   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2692   enc_class aarch64_enc_strb0(memory1 mem) %{
 2693     C2_MacroAssembler _masm(&amp;cbuf);
 2694     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2695                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2696   %}
 2697 
 2698   // This encoding class is generated automatically from ad_encode.m4.
 2699   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2700   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2701     Register src_reg = as_Register($src$$reg);
 2702     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2703                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2704   %}
 2705 
 2706   // This encoding class is generated automatically from ad_encode.m4.
 2707   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2708   enc_class aarch64_enc_strh0(memory2 mem) %{
 2709     C2_MacroAssembler _masm(&amp;cbuf);
 2710     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2711                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2712   %}
 2713 
 2714   // This encoding class is generated automatically from ad_encode.m4.
 2715   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2716   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2717     Register src_reg = as_Register($src$$reg);
 2718     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2719                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2720   %}
 2721 
 2722   // This encoding class is generated automatically from ad_encode.m4.
 2723   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2724   enc_class aarch64_enc_strw0(memory4 mem) %{
 2725     C2_MacroAssembler _masm(&amp;cbuf);
 2726     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2727                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2728   %}
 2729 
 2730   // This encoding class is generated automatically from ad_encode.m4.
 2731   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2732   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2733     Register src_reg = as_Register($src$$reg);
 2734     // we sometimes get asked to store the stack pointer into the
 2735     // current thread -- we cannot do that directly on AArch64
 2736     if (src_reg == r31_sp) {
 2737       C2_MacroAssembler _masm(&amp;cbuf);
 2738       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2739       __ mov(rscratch2, sp);
 2740       src_reg = rscratch2;
 2741     }
 2742     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2743                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2744   %}
 2745 
 2746   // This encoding class is generated automatically from ad_encode.m4.
 2747   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2748   enc_class aarch64_enc_str0(memory8 mem) %{
 2749     C2_MacroAssembler _masm(&amp;cbuf);
 2750     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2751                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2752   %}
 2753 
 2754   // This encoding class is generated automatically from ad_encode.m4.
 2755   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2756   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2757     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2758     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2759                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2760   %}
 2761 
 2762   // This encoding class is generated automatically from ad_encode.m4.
 2763   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2764   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2765     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2766     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2767                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2768   %}
 2769 
 2770   // This encoding class is generated automatically from ad_encode.m4.
 2771   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2772   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2773     C2_MacroAssembler _masm(&amp;cbuf);
 2774     address con = (address)$src$$constant;
 2775     // need to do this the hard way until we can manage relocs
 2776     // for 32 bit constants
 2777     __ movoop(rscratch2, (jobject)con);
 2778     if (con) __ encode_heap_oop_not_null(rscratch2);
 2779     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2786     C2_MacroAssembler _masm(&amp;cbuf);
 2787     address con = (address)$src$$constant;
 2788     // need to do this the hard way until we can manage relocs
 2789     // for 32 bit constants
 2790     __ movoop(rscratch2, (jobject)con);
 2791     __ encode_klass_not_null(rscratch2);
 2792     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2793                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2794   %}
 2795 
 2796   // This encoding class is generated automatically from ad_encode.m4.
 2797   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2798   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2799       C2_MacroAssembler _masm(&amp;cbuf);
 2800       __ membar(Assembler::StoreStore);
 2801       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2802                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2803   %}
 2804 
 2805   // END Non-volatile memory access
 2806 
 2807   // Vector loads and stores
 2808   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2809     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2810     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2811        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2812   %}
 2813 
 2814   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2815     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2816     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2817        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2818   %}
 2819 
 2820   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2821     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2822     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2823        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2824   %}
 2825 
 2826   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2827     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2828     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2829        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2830   %}
 2831 
 2832   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2833     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2834     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2835        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2836   %}
 2837 
 2838   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2839     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2840     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2841        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2842   %}
 2843 
 2844   // volatile loads and stores
 2845 
 2846   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2847     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2848                  rscratch1, stlrb);
 2849   %}
 2850 
 2851   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2852     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2853                  rscratch1, stlrh);
 2854   %}
 2855 
 2856   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2857     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2858                  rscratch1, stlrw);
 2859   %}
 2860 
 2861 
 2862   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2863     Register dst_reg = as_Register($dst$$reg);
 2864     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2865              rscratch1, ldarb);
 2866     __ sxtbw(dst_reg, dst_reg);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2870     Register dst_reg = as_Register($dst$$reg);
 2871     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2872              rscratch1, ldarb);
 2873     __ sxtb(dst_reg, dst_reg);
 2874   %}
 2875 
 2876   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2877     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2878              rscratch1, ldarb);
 2879   %}
 2880 
 2881   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2882     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2883              rscratch1, ldarb);
 2884   %}
 2885 
 2886   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2887     Register dst_reg = as_Register($dst$$reg);
 2888     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2889              rscratch1, ldarh);
 2890     __ sxthw(dst_reg, dst_reg);
 2891   %}
 2892 
 2893   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2894     Register dst_reg = as_Register($dst$$reg);
 2895     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2896              rscratch1, ldarh);
 2897     __ sxth(dst_reg, dst_reg);
 2898   %}
 2899 
 2900   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2901     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2902              rscratch1, ldarh);
 2903   %}
 2904 
 2905   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2906     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2907              rscratch1, ldarh);
 2908   %}
 2909 
 2910   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2911     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2912              rscratch1, ldarw);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2916     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2917              rscratch1, ldarw);
 2918   %}
 2919 
 2920   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2921     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2922              rscratch1, ldar);
 2923   %}
 2924 
 2925   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2926     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2927              rscratch1, ldarw);
 2928     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2929   %}
 2930 
 2931   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2932     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2933              rscratch1, ldar);
 2934     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2935   %}
 2936 
 2937   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2938     Register src_reg = as_Register($src$$reg);
 2939     // we sometimes get asked to store the stack pointer into the
 2940     // current thread -- we cannot do that directly on AArch64
 2941     if (src_reg == r31_sp) {
 2942       C2_MacroAssembler _masm(&amp;cbuf);
 2943       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2944       __ mov(rscratch2, sp);
 2945       src_reg = rscratch2;
 2946     }
 2947     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2948                  rscratch1, stlr);
 2949   %}
 2950 
 2951   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2952     {
 2953       C2_MacroAssembler _masm(&amp;cbuf);
 2954       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2955       __ fmovs(rscratch2, src_reg);
 2956     }
 2957     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2958                  rscratch1, stlrw);
 2959   %}
 2960 
 2961   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2962     {
 2963       C2_MacroAssembler _masm(&amp;cbuf);
 2964       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2965       __ fmovd(rscratch2, src_reg);
 2966     }
 2967     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2968                  rscratch1, stlr);
 2969   %}
 2970 
 2971   // synchronized read/update encodings
 2972 
 2973   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2974     C2_MacroAssembler _masm(&amp;cbuf);
 2975     Register dst_reg = as_Register($dst$$reg);
 2976     Register base = as_Register($mem$$base);
 2977     int index = $mem$$index;
 2978     int scale = $mem$$scale;
 2979     int disp = $mem$$disp;
 2980     if (index == -1) {
 2981        if (disp != 0) {
 2982         __ lea(rscratch1, Address(base, disp));
 2983         __ ldaxr(dst_reg, rscratch1);
 2984       } else {
 2985         // TODO
 2986         // should we ever get anything other than this case?
 2987         __ ldaxr(dst_reg, base);
 2988       }
 2989     } else {
 2990       Register index_reg = as_Register(index);
 2991       if (disp == 0) {
 2992         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2993         __ ldaxr(dst_reg, rscratch1);
 2994       } else {
 2995         __ lea(rscratch1, Address(base, disp));
 2996         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2997         __ ldaxr(dst_reg, rscratch1);
 2998       }
 2999     }
 3000   %}
 3001 
 3002   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3003     C2_MacroAssembler _masm(&amp;cbuf);
 3004     Register src_reg = as_Register($src$$reg);
 3005     Register base = as_Register($mem$$base);
 3006     int index = $mem$$index;
 3007     int scale = $mem$$scale;
 3008     int disp = $mem$$disp;
 3009     if (index == -1) {
 3010        if (disp != 0) {
 3011         __ lea(rscratch2, Address(base, disp));
 3012         __ stlxr(rscratch1, src_reg, rscratch2);
 3013       } else {
 3014         // TODO
 3015         // should we ever get anything other than this case?
 3016         __ stlxr(rscratch1, src_reg, base);
 3017       }
 3018     } else {
 3019       Register index_reg = as_Register(index);
 3020       if (disp == 0) {
 3021         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3022         __ stlxr(rscratch1, src_reg, rscratch2);
 3023       } else {
 3024         __ lea(rscratch2, Address(base, disp));
 3025         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3026         __ stlxr(rscratch1, src_reg, rscratch2);
 3027       }
 3028     }
 3029     __ cmpw(rscratch1, zr);
 3030   %}
 3031 
 3032   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3033     C2_MacroAssembler _masm(&amp;cbuf);
 3034     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3035     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3036                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3037                /*weak*/ false, noreg);
 3038   %}
 3039 
 3040   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3041     C2_MacroAssembler _masm(&amp;cbuf);
 3042     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3043     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3044                Assembler::word, /*acquire*/ false, /*release*/ true,
 3045                /*weak*/ false, noreg);
 3046   %}
 3047 
 3048   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3049     C2_MacroAssembler _masm(&amp;cbuf);
 3050     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3051     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3052                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3053                /*weak*/ false, noreg);
 3054   %}
 3055 
 3056   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3057     C2_MacroAssembler _masm(&amp;cbuf);
 3058     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3059     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3060                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3061                /*weak*/ false, noreg);
 3062   %}
 3063 
 3064 
 3065   // The only difference between aarch64_enc_cmpxchg and
 3066   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3067   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3068   // lock.
 3069   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3078     C2_MacroAssembler _masm(&amp;cbuf);
 3079     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3080     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3081                Assembler::word, /*acquire*/ true, /*release*/ true,
 3082                /*weak*/ false, noreg);
 3083   %}
 3084 
 3085   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3086     C2_MacroAssembler _masm(&amp;cbuf);
 3087     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3088     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3089                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3090                /*weak*/ false, noreg);
 3091   %}
 3092 
 3093   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3094     C2_MacroAssembler _masm(&amp;cbuf);
 3095     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3096     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3097                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3098                /*weak*/ false, noreg);
 3099   %}
 3100 
 3101   // auxiliary used for CompareAndSwapX to set result register
 3102   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3103     C2_MacroAssembler _masm(&amp;cbuf);
 3104     Register res_reg = as_Register($res$$reg);
 3105     __ cset(res_reg, Assembler::EQ);
 3106   %}
 3107 
 3108   // prefetch encodings
 3109 
 3110   enc_class aarch64_enc_prefetchw(memory mem) %{
 3111     C2_MacroAssembler _masm(&amp;cbuf);
 3112     Register base = as_Register($mem$$base);
 3113     int index = $mem$$index;
 3114     int scale = $mem$$scale;
 3115     int disp = $mem$$disp;
 3116     if (index == -1) {
 3117       __ prfm(Address(base, disp), PSTL1KEEP);
 3118     } else {
 3119       Register index_reg = as_Register(index);
 3120       if (disp == 0) {
 3121         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3122       } else {
 3123         __ lea(rscratch1, Address(base, disp));
 3124 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3125       }
 3126     }
 3127   %}
 3128 
 3129   /// mov envcodings
 3130 
 3131   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3132     C2_MacroAssembler _masm(&amp;cbuf);
 3133     u_int32_t con = (u_int32_t)$src$$constant;
 3134     Register dst_reg = as_Register($dst$$reg);
 3135     if (con == 0) {
 3136       __ movw(dst_reg, zr);
 3137     } else {
 3138       __ movw(dst_reg, con);
 3139     }
 3140   %}
 3141 
 3142   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3143     C2_MacroAssembler _masm(&amp;cbuf);
 3144     Register dst_reg = as_Register($dst$$reg);
 3145     u_int64_t con = (u_int64_t)$src$$constant;
 3146     if (con == 0) {
 3147       __ mov(dst_reg, zr);
 3148     } else {
 3149       __ mov(dst_reg, con);
 3150     }
 3151   %}
 3152 
 3153   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3154     C2_MacroAssembler _masm(&amp;cbuf);
 3155     Register dst_reg = as_Register($dst$$reg);
 3156     address con = (address)$src$$constant;
 3157     if (con == NULL || con == (address)1) {
 3158       ShouldNotReachHere();
 3159     } else {
 3160       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3161       if (rtype == relocInfo::oop_type) {
 3162         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3163       } else if (rtype == relocInfo::metadata_type) {
 3164         __ mov_metadata(dst_reg, (Metadata*)con);
 3165       } else {
 3166         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3167         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3168           __ mov(dst_reg, con);
 3169         } else {
 3170           unsigned long offset;
 3171           __ adrp(dst_reg, con, offset);
 3172           __ add(dst_reg, dst_reg, offset);
 3173         }
 3174       }
 3175     }
 3176   %}
 3177 
 3178   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3179     C2_MacroAssembler _masm(&amp;cbuf);
 3180     Register dst_reg = as_Register($dst$$reg);
 3181     __ mov(dst_reg, zr);
 3182   %}
 3183 
 3184   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3185     C2_MacroAssembler _masm(&amp;cbuf);
 3186     Register dst_reg = as_Register($dst$$reg);
 3187     __ mov(dst_reg, (u_int64_t)1);
 3188   %}
 3189 
 3190   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3191     C2_MacroAssembler _masm(&amp;cbuf);
 3192     __ load_byte_map_base($dst$$Register);
 3193   %}
 3194 
 3195   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3196     C2_MacroAssembler _masm(&amp;cbuf);
 3197     Register dst_reg = as_Register($dst$$reg);
 3198     address con = (address)$src$$constant;
 3199     if (con == NULL) {
 3200       ShouldNotReachHere();
 3201     } else {
 3202       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3203       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3204       __ set_narrow_oop(dst_reg, (jobject)con);
 3205     }
 3206   %}
 3207 
 3208   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3209     C2_MacroAssembler _masm(&amp;cbuf);
 3210     Register dst_reg = as_Register($dst$$reg);
 3211     __ mov(dst_reg, zr);
 3212   %}
 3213 
 3214   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3215     C2_MacroAssembler _masm(&amp;cbuf);
 3216     Register dst_reg = as_Register($dst$$reg);
 3217     address con = (address)$src$$constant;
 3218     if (con == NULL) {
 3219       ShouldNotReachHere();
 3220     } else {
 3221       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3222       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3223       __ set_narrow_klass(dst_reg, (Klass *)con);
 3224     }
 3225   %}
 3226 
 3227   // arithmetic encodings
 3228 
 3229   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3230     C2_MacroAssembler _masm(&amp;cbuf);
 3231     Register dst_reg = as_Register($dst$$reg);
 3232     Register src_reg = as_Register($src1$$reg);
 3233     int32_t con = (int32_t)$src2$$constant;
 3234     // add has primary == 0, subtract has primary == 1
 3235     if ($primary) { con = -con; }
 3236     if (con &lt; 0) {
 3237       __ subw(dst_reg, src_reg, -con);
 3238     } else {
 3239       __ addw(dst_reg, src_reg, con);
 3240     }
 3241   %}
 3242 
 3243   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3244     C2_MacroAssembler _masm(&amp;cbuf);
 3245     Register dst_reg = as_Register($dst$$reg);
 3246     Register src_reg = as_Register($src1$$reg);
 3247     int32_t con = (int32_t)$src2$$constant;
 3248     // add has primary == 0, subtract has primary == 1
 3249     if ($primary) { con = -con; }
 3250     if (con &lt; 0) {
 3251       __ sub(dst_reg, src_reg, -con);
 3252     } else {
 3253       __ add(dst_reg, src_reg, con);
 3254     }
 3255   %}
 3256 
 3257   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3258     C2_MacroAssembler _masm(&amp;cbuf);
 3259    Register dst_reg = as_Register($dst$$reg);
 3260    Register src1_reg = as_Register($src1$$reg);
 3261    Register src2_reg = as_Register($src2$$reg);
 3262     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3263   %}
 3264 
 3265   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3266     C2_MacroAssembler _masm(&amp;cbuf);
 3267    Register dst_reg = as_Register($dst$$reg);
 3268    Register src1_reg = as_Register($src1$$reg);
 3269    Register src2_reg = as_Register($src2$$reg);
 3270     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3271   %}
 3272 
 3273   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3274     C2_MacroAssembler _masm(&amp;cbuf);
 3275    Register dst_reg = as_Register($dst$$reg);
 3276    Register src1_reg = as_Register($src1$$reg);
 3277    Register src2_reg = as_Register($src2$$reg);
 3278     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3279   %}
 3280 
 3281   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3282     C2_MacroAssembler _masm(&amp;cbuf);
 3283    Register dst_reg = as_Register($dst$$reg);
 3284    Register src1_reg = as_Register($src1$$reg);
 3285    Register src2_reg = as_Register($src2$$reg);
 3286     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3287   %}
 3288 
 3289   // compare instruction encodings
 3290 
 3291   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3292     C2_MacroAssembler _masm(&amp;cbuf);
 3293     Register reg1 = as_Register($src1$$reg);
 3294     Register reg2 = as_Register($src2$$reg);
 3295     __ cmpw(reg1, reg2);
 3296   %}
 3297 
 3298   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3299     C2_MacroAssembler _masm(&amp;cbuf);
 3300     Register reg = as_Register($src1$$reg);
 3301     int32_t val = $src2$$constant;
 3302     if (val &gt;= 0) {
 3303       __ subsw(zr, reg, val);
 3304     } else {
 3305       __ addsw(zr, reg, -val);
 3306     }
 3307   %}
 3308 
 3309   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3310     C2_MacroAssembler _masm(&amp;cbuf);
 3311     Register reg1 = as_Register($src1$$reg);
 3312     u_int32_t val = (u_int32_t)$src2$$constant;
 3313     __ movw(rscratch1, val);
 3314     __ cmpw(reg1, rscratch1);
 3315   %}
 3316 
 3317   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3318     C2_MacroAssembler _masm(&amp;cbuf);
 3319     Register reg1 = as_Register($src1$$reg);
 3320     Register reg2 = as_Register($src2$$reg);
 3321     __ cmp(reg1, reg2);
 3322   %}
 3323 
 3324   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3325     C2_MacroAssembler _masm(&amp;cbuf);
 3326     Register reg = as_Register($src1$$reg);
 3327     int64_t val = $src2$$constant;
 3328     if (val &gt;= 0) {
 3329       __ subs(zr, reg, val);
 3330     } else if (val != -val) {
 3331       __ adds(zr, reg, -val);
 3332     } else {
 3333     // aargh, Long.MIN_VALUE is a special case
 3334       __ orr(rscratch1, zr, (u_int64_t)val);
 3335       __ subs(zr, reg, rscratch1);
 3336     }
 3337   %}
 3338 
 3339   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3340     C2_MacroAssembler _masm(&amp;cbuf);
 3341     Register reg1 = as_Register($src1$$reg);
 3342     u_int64_t val = (u_int64_t)$src2$$constant;
 3343     __ mov(rscratch1, val);
 3344     __ cmp(reg1, rscratch1);
 3345   %}
 3346 
 3347   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3348     C2_MacroAssembler _masm(&amp;cbuf);
 3349     Register reg1 = as_Register($src1$$reg);
 3350     Register reg2 = as_Register($src2$$reg);
 3351     __ cmp(reg1, reg2);
 3352   %}
 3353 
 3354   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3355     C2_MacroAssembler _masm(&amp;cbuf);
 3356     Register reg1 = as_Register($src1$$reg);
 3357     Register reg2 = as_Register($src2$$reg);
 3358     __ cmpw(reg1, reg2);
 3359   %}
 3360 
 3361   enc_class aarch64_enc_testp(iRegP src) %{
 3362     C2_MacroAssembler _masm(&amp;cbuf);
 3363     Register reg = as_Register($src$$reg);
 3364     __ cmp(reg, zr);
 3365   %}
 3366 
 3367   enc_class aarch64_enc_testn(iRegN src) %{
 3368     C2_MacroAssembler _masm(&amp;cbuf);
 3369     Register reg = as_Register($src$$reg);
 3370     __ cmpw(reg, zr);
 3371   %}
 3372 
 3373   enc_class aarch64_enc_b(label lbl) %{
 3374     C2_MacroAssembler _masm(&amp;cbuf);
 3375     Label *L = $lbl$$label;
 3376     __ b(*L);
 3377   %}
 3378 
 3379   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3380     C2_MacroAssembler _masm(&amp;cbuf);
 3381     Label *L = $lbl$$label;
 3382     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3383   %}
 3384 
 3385   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3386     C2_MacroAssembler _masm(&amp;cbuf);
 3387     Label *L = $lbl$$label;
 3388     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3389   %}
 3390 
 3391   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3392   %{
 3393      Register sub_reg = as_Register($sub$$reg);
 3394      Register super_reg = as_Register($super$$reg);
 3395      Register temp_reg = as_Register($temp$$reg);
 3396      Register result_reg = as_Register($result$$reg);
 3397 
 3398      Label miss;
 3399      C2_MacroAssembler _masm(&amp;cbuf);
 3400      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3401                                      NULL, &amp;miss,
 3402                                      /*set_cond_codes:*/ true);
 3403      if ($primary) {
 3404        __ mov(result_reg, zr);
 3405      }
 3406      __ bind(miss);
 3407   %}
 3408 
 3409   enc_class aarch64_enc_java_static_call(method meth) %{
 3410     C2_MacroAssembler _masm(&amp;cbuf);
 3411 
 3412     address addr = (address)$meth$$method;
 3413     address call;
 3414     if (!_method) {
 3415       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3416       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3417     } else {
 3418       int method_index = resolved_method_index(cbuf);
 3419       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3420                                                   : static_call_Relocation::spec(method_index);
 3421       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3422 
 3423       // Emit stub for static call
 3424       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3425       if (stub == NULL) {
 3426         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3427         return;
 3428       }
 3429     }
 3430     if (call == NULL) {
 3431       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3432       return;
 3433     }
 3434   %}
 3435 
 3436   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3437     C2_MacroAssembler _masm(&amp;cbuf);
 3438     int method_index = resolved_method_index(cbuf);
 3439     address call = __ ic_call((address)$meth$$method, method_index);
 3440     if (call == NULL) {
 3441       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3442       return;
 3443     }
 3444   %}
 3445 
 3446   enc_class aarch64_enc_call_epilog() %{
 3447     C2_MacroAssembler _masm(&amp;cbuf);
 3448     if (VerifyStackAtCalls) {
 3449       // Check that stack depth is unchanged: find majik cookie on stack
 3450       __ call_Unimplemented();
 3451     }
 3452   %}
 3453 
 3454   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3455     C2_MacroAssembler _masm(&amp;cbuf);
 3456 
 3457     // some calls to generated routines (arraycopy code) are scheduled
 3458     // by C2 as runtime calls. if so we can call them using a br (they
 3459     // will be in a reachable segment) otherwise we have to use a blr
 3460     // which loads the absolute address into a register.
 3461     address entry = (address)$meth$$method;
 3462     CodeBlob *cb = CodeCache::find_blob(entry);
 3463     if (cb) {
 3464       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3465       if (call == NULL) {
 3466         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3467         return;
 3468       }
 3469     } else {
 3470       Label retaddr;
 3471       __ adr(rscratch2, retaddr);
 3472       __ lea(rscratch1, RuntimeAddress(entry));
 3473       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3474       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3475       __ blr(rscratch1);
 3476       __ bind(retaddr);
 3477       __ add(sp, sp, 2 * wordSize);
 3478     }
 3479   %}
 3480 
 3481   enc_class aarch64_enc_rethrow() %{
 3482     C2_MacroAssembler _masm(&amp;cbuf);
 3483     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3484   %}
 3485 
 3486   enc_class aarch64_enc_ret() %{
 3487     C2_MacroAssembler _masm(&amp;cbuf);
 3488     __ ret(lr);
 3489   %}
 3490 
 3491   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3492     C2_MacroAssembler _masm(&amp;cbuf);
 3493     Register target_reg = as_Register($jump_target$$reg);
 3494     __ br(target_reg);
 3495   %}
 3496 
 3497   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3498     C2_MacroAssembler _masm(&amp;cbuf);
 3499     Register target_reg = as_Register($jump_target$$reg);
 3500     // exception oop should be in r0
 3501     // ret addr has been popped into lr
 3502     // callee expects it in r3
 3503     __ mov(r3, lr);
 3504     __ br(target_reg);
 3505   %}
 3506 
 3507   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3508     C2_MacroAssembler _masm(&amp;cbuf);
 3509     Register oop = as_Register($object$$reg);
 3510     Register box = as_Register($box$$reg);
 3511     Register disp_hdr = as_Register($tmp$$reg);
 3512     Register tmp = as_Register($tmp2$$reg);
 3513     Label cont;
 3514     Label object_has_monitor;
 3515     Label cas_failed;
 3516 
 3517     assert_different_registers(oop, box, tmp, disp_hdr);
 3518 
 3519     // Load markWord from object into displaced_header.
 3520     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3521 
 3522     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3523       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3524     }
 3525 
 3526     // Check for existing monitor
 3527     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3528 
 3529     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3530     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3531 
 3532     // Initialize the box. (Must happen before we update the object mark!)
 3533     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3534 
 3535     // Compare object markWord with an unlocked value (tmp) and if
 3536     // equal exchange the stack address of our box with object markWord.
 3537     // On failure disp_hdr contains the possibly locked markWord.
 3538     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3539                /*release*/ true, /*weak*/ false, disp_hdr);
 3540     __ br(Assembler::EQ, cont);
 3541 
 3542     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3543 
 3544     // If the compare-and-exchange succeeded, then we found an unlocked
 3545     // object, will have now locked it will continue at label cont
 3546 
 3547     __ bind(cas_failed);
 3548     // We did not see an unlocked object so try the fast recursive case.
 3549 
 3550     // Check if the owner is self by comparing the value in the
 3551     // markWord of object (disp_hdr) with the stack pointer.
 3552     __ mov(rscratch1, sp);
 3553     __ sub(disp_hdr, disp_hdr, rscratch1);
 3554     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3555     // If condition is true we are cont and hence we can store 0 as the
 3556     // displaced header in the box, which indicates that it is a recursive lock.
 3557     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3558     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3559 
 3560     __ b(cont);
 3561 
 3562     // Handle existing monitor.
 3563     __ bind(object_has_monitor);
 3564 
 3565     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3566     // otherwise m-&gt;owner may contain a thread or a stack address.
 3567     //
 3568     // Try to CAS m-&gt;owner from NULL to current thread.
 3569     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3570     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3571                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3572 
 3573     // Store a non-null value into the box to avoid looking like a re-entrant
 3574     // lock. The fast-path monitor unlock code checks for
 3575     // markWord::monitor_value so use markWord::unused_mark which has the
 3576     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3577     __ mov(tmp, (address)markWord::unused_mark().value());
 3578     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3579 
 3580     __ bind(cont);
 3581     // flag == EQ indicates success
 3582     // flag == NE indicates failure
 3583   %}
 3584 
 3585   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3586     C2_MacroAssembler _masm(&amp;cbuf);
 3587     Register oop = as_Register($object$$reg);
 3588     Register box = as_Register($box$$reg);
 3589     Register disp_hdr = as_Register($tmp$$reg);
 3590     Register tmp = as_Register($tmp2$$reg);
 3591     Label cont;
 3592     Label object_has_monitor;
 3593 
 3594     assert_different_registers(oop, box, tmp, disp_hdr);
 3595 
 3596     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3597       __ biased_locking_exit(oop, tmp, cont);
 3598     }
 3599 
 3600     // Find the lock address and load the displaced header from the stack.
 3601     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3602 
 3603     // If the displaced header is 0, we have a recursive unlock.
 3604     __ cmp(disp_hdr, zr);
 3605     __ br(Assembler::EQ, cont);
 3606 
 3607     // Handle existing monitor.
 3608     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3609     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3610 
 3611     // Check if it is still a light weight lock, this is is true if we
 3612     // see the stack address of the basicLock in the markWord of the
 3613     // object.
 3614 
 3615     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3616                /*release*/ true, /*weak*/ false, tmp);
 3617     __ b(cont);
 3618 
 3619     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3620 
 3621     // Handle existing monitor.
 3622     __ bind(object_has_monitor);
 3623     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3624     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3625     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3626     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3627     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3628     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3629     __ cmp(rscratch1, zr); // Sets flags for result
 3630     __ br(Assembler::NE, cont);
 3631 
 3632     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3633     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3634     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3635     __ cmp(rscratch1, zr); // Sets flags for result
 3636     __ cbnz(rscratch1, cont);
 3637     // need a release store here
 3638     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3639     __ stlr(zr, tmp); // set unowned
 3640 
 3641     __ bind(cont);
 3642     // flag == EQ indicates success
 3643     // flag == NE indicates failure
 3644   %}
 3645 
 3646 %}
 3647 
 3648 //----------FRAME--------------------------------------------------------------
 3649 // Definition of frame structure and management information.
 3650 //
 3651 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3652 //                             |   (to get allocators register number
 3653 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3654 //  r   CALLER     |        |
 3655 //  o     |        +--------+      pad to even-align allocators stack-slot
 3656 //  w     V        |  pad0  |        numbers; owned by CALLER
 3657 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3658 //  h     ^        |   in   |  5
 3659 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3660 //  |     |        |        |  3
 3661 //  |     |        +--------+
 3662 //  V     |        | old out|      Empty on Intel, window on Sparc
 3663 //        |    old |preserve|      Must be even aligned.
 3664 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3665 //        |        |   in   |  3   area for Intel ret address
 3666 //     Owned by    |preserve|      Empty on Sparc.
 3667 //       SELF      +--------+
 3668 //        |        |  pad2  |  2   pad to align old SP
 3669 //        |        +--------+  1
 3670 //        |        | locks  |  0
 3671 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3672 //        |        |  pad1  | 11   pad to align new SP
 3673 //        |        +--------+
 3674 //        |        |        | 10
 3675 //        |        | spills |  9   spills
 3676 //        V        |        |  8   (pad0 slot for callee)
 3677 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3678 //        ^        |  out   |  7
 3679 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3680 //     Owned by    +--------+
 3681 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3682 //        |    new |preserve|      Must be even-aligned.
 3683 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3684 //        |        |        |
 3685 //
 3686 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3687 //         known from SELF&#39;s arguments and the Java calling convention.
 3688 //         Region 6-7 is determined per call site.
 3689 // Note 2: If the calling convention leaves holes in the incoming argument
 3690 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3691 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3692 //         incoming area, as the Java calling convention is completely under
 3693 //         the control of the AD file.  Doubles can be sorted and packed to
 3694 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3695 //         varargs C calling conventions.
 3696 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3697 //         even aligned with pad0 as needed.
 3698 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3699 //           (the latter is true on Intel but is it false on AArch64?)
 3700 //         region 6-11 is even aligned; it may be padded out more so that
 3701 //         the region from SP to FP meets the minimum stack alignment.
 3702 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3703 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3704 //         SP meets the minimum alignment.
 3705 
 3706 frame %{
 3707   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3708   stack_direction(TOWARDS_LOW);
 3709 
 3710   // These three registers define part of the calling convention
 3711   // between compiled code and the interpreter.
 3712 
 3713   // Inline Cache Register or methodOop for I2C.
 3714   inline_cache_reg(R12);
 3715 
 3716   // Method Oop Register when calling interpreter.
 3717   interpreter_method_oop_reg(R12);
 3718 
 3719   // Number of stack slots consumed by locking an object
 3720   sync_stack_slots(2);
 3721 
 3722   // Compiled code&#39;s Frame Pointer
 3723   frame_pointer(R31);
 3724 
 3725   // Interpreter stores its frame pointer in a register which is
 3726   // stored to the stack by I2CAdaptors.
 3727   // I2CAdaptors convert from interpreted java to compiled java.
 3728   interpreter_frame_pointer(R29);
 3729 
 3730   // Stack alignment requirement
 3731   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3732 
 3733   // Number of stack slots between incoming argument block and the start of
 3734   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3735   // EPILOG must remove this many slots. aarch64 needs two slots for
 3736   // return address and fp.
 3737   // TODO think this is correct but check
 3738   in_preserve_stack_slots(4);
 3739 
 3740   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3741   // for calls to C.  Supports the var-args backing area for register parms.
 3742   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3743 
 3744   // The after-PROLOG location of the return address.  Location of
 3745   // return address specifies a type (REG or STACK) and a number
 3746   // representing the register number (i.e. - use a register name) or
 3747   // stack slot.
 3748   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3749   // Otherwise, it is above the locks and verification slot and alignment word
 3750   // TODO this may well be correct but need to check why that - 2 is there
 3751   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3752   // which folds in the space used for monitors
 3753   return_addr(STACK - 2 +
 3754               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3755                         Compile::current()-&gt;fixed_slots()),
 3756                        stack_alignment_in_slots()));
 3757 
 3758   // Body of function which returns an integer array locating
 3759   // arguments either in registers or in stack slots.  Passed an array
 3760   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3761   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3762   // arguments for a CALLEE.  Incoming stack arguments are
 3763   // automatically biased by the preserve_stack_slots field above.
 3764 
 3765   calling_convention
 3766   %{
 3767     // No difference between ingoing/outgoing just pass false
 3768     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3769   %}
 3770 
 3771   c_calling_convention
 3772   %{
 3773     // This is obviously always outgoing
 3774     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3775   %}
 3776 
 3777   // Location of compiled Java return values.  Same as C for now.
 3778   return_value
 3779   %{
 3780     // TODO do we allow ideal_reg == Op_RegN???
 3781     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3782            &quot;only return normal values&quot;);
 3783 
 3784     static const int lo[Op_RegL + 1] = { // enum name
 3785       0,                                 // Op_Node
 3786       0,                                 // Op_Set
 3787       R0_num,                            // Op_RegN
 3788       R0_num,                            // Op_RegI
 3789       R0_num,                            // Op_RegP
 3790       V0_num,                            // Op_RegF
 3791       V0_num,                            // Op_RegD
 3792       R0_num                             // Op_RegL
 3793     };
 3794 
 3795     static const int hi[Op_RegL + 1] = { // enum name
 3796       0,                                 // Op_Node
 3797       0,                                 // Op_Set
 3798       OptoReg::Bad,                      // Op_RegN
 3799       OptoReg::Bad,                      // Op_RegI
 3800       R0_H_num,                          // Op_RegP
 3801       OptoReg::Bad,                      // Op_RegF
 3802       V0_H_num,                          // Op_RegD
 3803       R0_H_num                           // Op_RegL
 3804     };
 3805 
 3806     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3807   %}
 3808 %}
 3809 
 3810 //----------ATTRIBUTES---------------------------------------------------------
 3811 //----------Operand Attributes-------------------------------------------------
 3812 op_attrib op_cost(1);        // Required cost attribute
 3813 
 3814 //----------Instruction Attributes---------------------------------------------
 3815 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3816 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3817 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3818                                 // a non-matching short branch variant
 3819                                 // of some long branch?
 3820 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3821                                 // be a power of 2) specifies the
 3822                                 // alignment that some part of the
 3823                                 // instruction (not necessarily the
 3824                                 // start) requires.  If &gt; 1, a
 3825                                 // compute_padding() function must be
 3826                                 // provided for the instruction
 3827 
 3828 //----------OPERANDS-----------------------------------------------------------
 3829 // Operand definitions must precede instruction definitions for correct parsing
 3830 // in the ADLC because operands constitute user defined types which are used in
 3831 // instruction definitions.
 3832 
 3833 //----------Simple Operands----------------------------------------------------
 3834 
 3835 // Integer operands 32 bit
 3836 // 32 bit immediate
 3837 operand immI()
 3838 %{
 3839   match(ConI);
 3840 
 3841   op_cost(0);
 3842   format %{ %}
 3843   interface(CONST_INTER);
 3844 %}
 3845 
 3846 // 32 bit zero
 3847 operand immI0()
 3848 %{
 3849   predicate(n-&gt;get_int() == 0);
 3850   match(ConI);
 3851 
 3852   op_cost(0);
 3853   format %{ %}
 3854   interface(CONST_INTER);
 3855 %}
 3856 
 3857 // 32 bit unit increment
 3858 operand immI_1()
 3859 %{
 3860   predicate(n-&gt;get_int() == 1);
 3861   match(ConI);
 3862 
 3863   op_cost(0);
 3864   format %{ %}
 3865   interface(CONST_INTER);
 3866 %}
 3867 
 3868 // 32 bit unit decrement
 3869 operand immI_M1()
 3870 %{
 3871   predicate(n-&gt;get_int() == -1);
 3872   match(ConI);
 3873 
 3874   op_cost(0);
 3875   format %{ %}
 3876   interface(CONST_INTER);
 3877 %}
 3878 
 3879 // Shift values for add/sub extension shift
 3880 operand immIExt()
 3881 %{
 3882   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3883   match(ConI);
 3884 
 3885   op_cost(0);
 3886   format %{ %}
 3887   interface(CONST_INTER);
 3888 %}
 3889 
 3890 operand immI_le_4()
 3891 %{
 3892   predicate(n-&gt;get_int() &lt;= 4);
 3893   match(ConI);
 3894 
 3895   op_cost(0);
 3896   format %{ %}
 3897   interface(CONST_INTER);
 3898 %}
 3899 
 3900 operand immI_31()
 3901 %{
 3902   predicate(n-&gt;get_int() == 31);
 3903   match(ConI);
 3904 
 3905   op_cost(0);
 3906   format %{ %}
 3907   interface(CONST_INTER);
 3908 %}
 3909 
 3910 operand immI_8()
 3911 %{
 3912   predicate(n-&gt;get_int() == 8);
 3913   match(ConI);
 3914 
 3915   op_cost(0);
 3916   format %{ %}
 3917   interface(CONST_INTER);
 3918 %}
 3919 
 3920 operand immI_16()
 3921 %{
 3922   predicate(n-&gt;get_int() == 16);
 3923   match(ConI);
 3924 
 3925   op_cost(0);
 3926   format %{ %}
 3927   interface(CONST_INTER);
 3928 %}
 3929 
 3930 operand immI_24()
 3931 %{
 3932   predicate(n-&gt;get_int() == 24);
 3933   match(ConI);
 3934 
 3935   op_cost(0);
 3936   format %{ %}
 3937   interface(CONST_INTER);
 3938 %}
 3939 
 3940 operand immI_32()
 3941 %{
 3942   predicate(n-&gt;get_int() == 32);
 3943   match(ConI);
 3944 
 3945   op_cost(0);
 3946   format %{ %}
 3947   interface(CONST_INTER);
 3948 %}
 3949 
 3950 operand immI_48()
 3951 %{
 3952   predicate(n-&gt;get_int() == 48);
 3953   match(ConI);
 3954 
 3955   op_cost(0);
 3956   format %{ %}
 3957   interface(CONST_INTER);
 3958 %}
 3959 
 3960 operand immI_56()
 3961 %{
 3962   predicate(n-&gt;get_int() == 56);
 3963   match(ConI);
 3964 
 3965   op_cost(0);
 3966   format %{ %}
 3967   interface(CONST_INTER);
 3968 %}
 3969 
 3970 operand immI_63()
 3971 %{
 3972   predicate(n-&gt;get_int() == 63);
 3973   match(ConI);
 3974 
 3975   op_cost(0);
 3976   format %{ %}
 3977   interface(CONST_INTER);
 3978 %}
 3979 
 3980 operand immI_64()
 3981 %{
 3982   predicate(n-&gt;get_int() == 64);
 3983   match(ConI);
 3984 
 3985   op_cost(0);
 3986   format %{ %}
 3987   interface(CONST_INTER);
 3988 %}
 3989 
 3990 operand immI_255()
 3991 %{
 3992   predicate(n-&gt;get_int() == 255);
 3993   match(ConI);
 3994 
 3995   op_cost(0);
 3996   format %{ %}
 3997   interface(CONST_INTER);
 3998 %}
 3999 
 4000 operand immI_65535()
 4001 %{
 4002   predicate(n-&gt;get_int() == 65535);
 4003   match(ConI);
 4004 
 4005   op_cost(0);
 4006   format %{ %}
 4007   interface(CONST_INTER);
 4008 %}
 4009 
 4010 operand immL_255()
 4011 %{
 4012   predicate(n-&gt;get_long() == 255L);
 4013   match(ConL);
 4014 
 4015   op_cost(0);
 4016   format %{ %}
 4017   interface(CONST_INTER);
 4018 %}
 4019 
 4020 operand immL_65535()
 4021 %{
 4022   predicate(n-&gt;get_long() == 65535L);
 4023   match(ConL);
 4024 
 4025   op_cost(0);
 4026   format %{ %}
 4027   interface(CONST_INTER);
 4028 %}
 4029 
 4030 operand immL_4294967295()
 4031 %{
 4032   predicate(n-&gt;get_long() == 4294967295L);
 4033   match(ConL);
 4034 
 4035   op_cost(0);
 4036   format %{ %}
 4037   interface(CONST_INTER);
 4038 %}
 4039 
 4040 operand immL_bitmask()
 4041 %{
 4042   predicate((n-&gt;get_long() != 0)
 4043             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4044             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4045   match(ConL);
 4046 
 4047   op_cost(0);
 4048   format %{ %}
 4049   interface(CONST_INTER);
 4050 %}
 4051 
 4052 operand immI_bitmask()
 4053 %{
 4054   predicate((n-&gt;get_int() != 0)
 4055             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4056             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4057   match(ConI);
 4058 
 4059   op_cost(0);
 4060   format %{ %}
 4061   interface(CONST_INTER);
 4062 %}
 4063 
 4064 // Scale values for scaled offset addressing modes (up to long but not quad)
 4065 operand immIScale()
 4066 %{
 4067   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4068   match(ConI);
 4069 
 4070   op_cost(0);
 4071   format %{ %}
 4072   interface(CONST_INTER);
 4073 %}
 4074 
 4075 // 26 bit signed offset -- for pc-relative branches
 4076 operand immI26()
 4077 %{
 4078   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4079   match(ConI);
 4080 
 4081   op_cost(0);
 4082   format %{ %}
 4083   interface(CONST_INTER);
 4084 %}
 4085 
 4086 // 19 bit signed offset -- for pc-relative loads
 4087 operand immI19()
 4088 %{
 4089   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4090   match(ConI);
 4091 
 4092   op_cost(0);
 4093   format %{ %}
 4094   interface(CONST_INTER);
 4095 %}
 4096 
 4097 // 12 bit unsigned offset -- for base plus immediate loads
 4098 operand immIU12()
 4099 %{
 4100   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4101   match(ConI);
 4102 
 4103   op_cost(0);
 4104   format %{ %}
 4105   interface(CONST_INTER);
 4106 %}
 4107 
 4108 operand immLU12()
 4109 %{
 4110   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4111   match(ConL);
 4112 
 4113   op_cost(0);
 4114   format %{ %}
 4115   interface(CONST_INTER);
 4116 %}
 4117 
 4118 // Offset for scaled or unscaled immediate loads and stores
 4119 operand immIOffset()
 4120 %{
 4121   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4122   match(ConI);
 4123 
 4124   op_cost(0);
 4125   format %{ %}
 4126   interface(CONST_INTER);
 4127 %}
 4128 
 4129 operand immIOffset1()
 4130 %{
 4131   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4132   match(ConI);
 4133 
 4134   op_cost(0);
 4135   format %{ %}
 4136   interface(CONST_INTER);
 4137 %}
 4138 
 4139 operand immIOffset2()
 4140 %{
 4141   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4142   match(ConI);
 4143 
 4144   op_cost(0);
 4145   format %{ %}
 4146   interface(CONST_INTER);
 4147 %}
 4148 
 4149 operand immIOffset4()
 4150 %{
 4151   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4152   match(ConI);
 4153 
 4154   op_cost(0);
 4155   format %{ %}
 4156   interface(CONST_INTER);
 4157 %}
 4158 
 4159 operand immIOffset8()
 4160 %{
 4161   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4162   match(ConI);
 4163 
 4164   op_cost(0);
 4165   format %{ %}
 4166   interface(CONST_INTER);
 4167 %}
 4168 
 4169 operand immIOffset16()
 4170 %{
 4171   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4172   match(ConI);
 4173 
 4174   op_cost(0);
 4175   format %{ %}
 4176   interface(CONST_INTER);
 4177 %}
 4178 
 4179 operand immLoffset()
 4180 %{
 4181   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4182   match(ConL);
 4183 
 4184   op_cost(0);
 4185   format %{ %}
 4186   interface(CONST_INTER);
 4187 %}
 4188 
 4189 operand immLoffset1()
 4190 %{
 4191   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4192   match(ConL);
 4193 
 4194   op_cost(0);
 4195   format %{ %}
 4196   interface(CONST_INTER);
 4197 %}
 4198 
 4199 operand immLoffset2()
 4200 %{
 4201   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4202   match(ConL);
 4203 
 4204   op_cost(0);
 4205   format %{ %}
 4206   interface(CONST_INTER);
 4207 %}
 4208 
 4209 operand immLoffset4()
 4210 %{
 4211   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4212   match(ConL);
 4213 
 4214   op_cost(0);
 4215   format %{ %}
 4216   interface(CONST_INTER);
 4217 %}
 4218 
 4219 operand immLoffset8()
 4220 %{
 4221   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4222   match(ConL);
 4223 
 4224   op_cost(0);
 4225   format %{ %}
 4226   interface(CONST_INTER);
 4227 %}
 4228 
 4229 operand immLoffset16()
 4230 %{
 4231   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4232   match(ConL);
 4233 
 4234   op_cost(0);
 4235   format %{ %}
 4236   interface(CONST_INTER);
 4237 %}
 4238 
 4239 // 32 bit integer valid for add sub immediate
 4240 operand immIAddSub()
 4241 %{
 4242   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4243   match(ConI);
 4244   op_cost(0);
 4245   format %{ %}
 4246   interface(CONST_INTER);
 4247 %}
 4248 
 4249 // 32 bit unsigned integer valid for logical immediate
 4250 // TODO -- check this is right when e.g the mask is 0x80000000
 4251 operand immILog()
 4252 %{
 4253   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4254   match(ConI);
 4255 
 4256   op_cost(0);
 4257   format %{ %}
 4258   interface(CONST_INTER);
 4259 %}
 4260 
 4261 // Integer operands 64 bit
 4262 // 64 bit immediate
 4263 operand immL()
 4264 %{
 4265   match(ConL);
 4266 
 4267   op_cost(0);
 4268   format %{ %}
 4269   interface(CONST_INTER);
 4270 %}
 4271 
 4272 // 64 bit zero
 4273 operand immL0()
 4274 %{
 4275   predicate(n-&gt;get_long() == 0);
 4276   match(ConL);
 4277 
 4278   op_cost(0);
 4279   format %{ %}
 4280   interface(CONST_INTER);
 4281 %}
 4282 
 4283 // 64 bit unit increment
 4284 operand immL_1()
 4285 %{
 4286   predicate(n-&gt;get_long() == 1);
 4287   match(ConL);
 4288 
 4289   op_cost(0);
 4290   format %{ %}
 4291   interface(CONST_INTER);
 4292 %}
 4293 
 4294 // 64 bit unit decrement
 4295 operand immL_M1()
 4296 %{
 4297   predicate(n-&gt;get_long() == -1);
 4298   match(ConL);
 4299 
 4300   op_cost(0);
 4301   format %{ %}
 4302   interface(CONST_INTER);
 4303 %}
 4304 
 4305 // 32 bit offset of pc in thread anchor
 4306 
 4307 operand immL_pc_off()
 4308 %{
 4309   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4310                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4311   match(ConL);
 4312 
 4313   op_cost(0);
 4314   format %{ %}
 4315   interface(CONST_INTER);
 4316 %}
 4317 
 4318 // 64 bit integer valid for add sub immediate
 4319 operand immLAddSub()
 4320 %{
 4321   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4322   match(ConL);
 4323   op_cost(0);
 4324   format %{ %}
 4325   interface(CONST_INTER);
 4326 %}
 4327 
 4328 // 64 bit integer valid for logical immediate
 4329 operand immLLog()
 4330 %{
 4331   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4332   match(ConL);
 4333   op_cost(0);
 4334   format %{ %}
 4335   interface(CONST_INTER);
 4336 %}
 4337 
 4338 // Long Immediate: low 32-bit mask
 4339 operand immL_32bits()
 4340 %{
 4341   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4342   match(ConL);
 4343   op_cost(0);
 4344   format %{ %}
 4345   interface(CONST_INTER);
 4346 %}
 4347 
 4348 // Pointer operands
 4349 // Pointer Immediate
 4350 operand immP()
 4351 %{
 4352   match(ConP);
 4353 
 4354   op_cost(0);
 4355   format %{ %}
 4356   interface(CONST_INTER);
 4357 %}
 4358 
 4359 // NULL Pointer Immediate
 4360 operand immP0()
 4361 %{
 4362   predicate(n-&gt;get_ptr() == 0);
 4363   match(ConP);
 4364 
 4365   op_cost(0);
 4366   format %{ %}
 4367   interface(CONST_INTER);
 4368 %}
 4369 
 4370 // Pointer Immediate One
 4371 // this is used in object initialization (initial object header)
 4372 operand immP_1()
 4373 %{
 4374   predicate(n-&gt;get_ptr() == 1);
 4375   match(ConP);
 4376 
 4377   op_cost(0);
 4378   format %{ %}
 4379   interface(CONST_INTER);
 4380 %}
 4381 
 4382 // Card Table Byte Map Base
 4383 operand immByteMapBase()
 4384 %{
 4385   // Get base of card map
 4386   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4387             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4388   match(ConP);
 4389 
 4390   op_cost(0);
 4391   format %{ %}
 4392   interface(CONST_INTER);
 4393 %}
 4394 
 4395 // Pointer Immediate Minus One
 4396 // this is used when we want to write the current PC to the thread anchor
 4397 operand immP_M1()
 4398 %{
 4399   predicate(n-&gt;get_ptr() == -1);
 4400   match(ConP);
 4401 
 4402   op_cost(0);
 4403   format %{ %}
 4404   interface(CONST_INTER);
 4405 %}
 4406 
 4407 // Pointer Immediate Minus Two
 4408 // this is used when we want to write the current PC to the thread anchor
 4409 operand immP_M2()
 4410 %{
 4411   predicate(n-&gt;get_ptr() == -2);
 4412   match(ConP);
 4413 
 4414   op_cost(0);
 4415   format %{ %}
 4416   interface(CONST_INTER);
 4417 %}
 4418 
 4419 // Float and Double operands
 4420 // Double Immediate
 4421 operand immD()
 4422 %{
 4423   match(ConD);
 4424   op_cost(0);
 4425   format %{ %}
 4426   interface(CONST_INTER);
 4427 %}
 4428 
 4429 // Double Immediate: +0.0d
 4430 operand immD0()
 4431 %{
 4432   predicate(jlong_cast(n-&gt;getd()) == 0);
 4433   match(ConD);
 4434 
 4435   op_cost(0);
 4436   format %{ %}
 4437   interface(CONST_INTER);
 4438 %}
 4439 
 4440 // constant &#39;double +0.0&#39;.
 4441 operand immDPacked()
 4442 %{
 4443   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4444   match(ConD);
 4445   op_cost(0);
 4446   format %{ %}
 4447   interface(CONST_INTER);
 4448 %}
 4449 
 4450 // Float Immediate
 4451 operand immF()
 4452 %{
 4453   match(ConF);
 4454   op_cost(0);
 4455   format %{ %}
 4456   interface(CONST_INTER);
 4457 %}
 4458 
 4459 // Float Immediate: +0.0f.
 4460 operand immF0()
 4461 %{
 4462   predicate(jint_cast(n-&gt;getf()) == 0);
 4463   match(ConF);
 4464 
 4465   op_cost(0);
 4466   format %{ %}
 4467   interface(CONST_INTER);
 4468 %}
 4469 
 4470 //
 4471 operand immFPacked()
 4472 %{
 4473   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4474   match(ConF);
 4475   op_cost(0);
 4476   format %{ %}
 4477   interface(CONST_INTER);
 4478 %}
 4479 
 4480 // Narrow pointer operands
 4481 // Narrow Pointer Immediate
 4482 operand immN()
 4483 %{
 4484   match(ConN);
 4485 
 4486   op_cost(0);
 4487   format %{ %}
 4488   interface(CONST_INTER);
 4489 %}
 4490 
 4491 // Narrow NULL Pointer Immediate
 4492 operand immN0()
 4493 %{
 4494   predicate(n-&gt;get_narrowcon() == 0);
 4495   match(ConN);
 4496 
 4497   op_cost(0);
 4498   format %{ %}
 4499   interface(CONST_INTER);
 4500 %}
 4501 
 4502 operand immNKlass()
 4503 %{
 4504   match(ConNKlass);
 4505 
 4506   op_cost(0);
 4507   format %{ %}
 4508   interface(CONST_INTER);
 4509 %}
 4510 
 4511 // Integer 32 bit Register Operands
 4512 // Integer 32 bitRegister (excludes SP)
 4513 operand iRegI()
 4514 %{
 4515   constraint(ALLOC_IN_RC(any_reg32));
 4516   match(RegI);
 4517   match(iRegINoSp);
 4518   op_cost(0);
 4519   format %{ %}
 4520   interface(REG_INTER);
 4521 %}
 4522 
 4523 // Integer 32 bit Register not Special
 4524 operand iRegINoSp()
 4525 %{
 4526   constraint(ALLOC_IN_RC(no_special_reg32));
 4527   match(RegI);
 4528   op_cost(0);
 4529   format %{ %}
 4530   interface(REG_INTER);
 4531 %}
 4532 
 4533 // Integer 64 bit Register Operands
 4534 // Integer 64 bit Register (includes SP)
 4535 operand iRegL()
 4536 %{
 4537   constraint(ALLOC_IN_RC(any_reg));
 4538   match(RegL);
 4539   match(iRegLNoSp);
 4540   op_cost(0);
 4541   format %{ %}
 4542   interface(REG_INTER);
 4543 %}
 4544 
 4545 // Integer 64 bit Register not Special
 4546 operand iRegLNoSp()
 4547 %{
 4548   constraint(ALLOC_IN_RC(no_special_reg));
 4549   match(RegL);
 4550   match(iRegL_R0);
 4551   format %{ %}
 4552   interface(REG_INTER);
 4553 %}
 4554 
 4555 // Pointer Register Operands
 4556 // Pointer Register
 4557 operand iRegP()
 4558 %{
 4559   constraint(ALLOC_IN_RC(ptr_reg));
 4560   match(RegP);
 4561   match(iRegPNoSp);
 4562   match(iRegP_R0);
 4563   //match(iRegP_R2);
 4564   //match(iRegP_R4);
 4565   //match(iRegP_R5);
 4566   match(thread_RegP);
 4567   op_cost(0);
 4568   format %{ %}
 4569   interface(REG_INTER);
 4570 %}
 4571 
 4572 // Pointer 64 bit Register not Special
 4573 operand iRegPNoSp()
 4574 %{
 4575   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4576   match(RegP);
 4577   // match(iRegP);
 4578   // match(iRegP_R0);
 4579   // match(iRegP_R2);
 4580   // match(iRegP_R4);
 4581   // match(iRegP_R5);
 4582   // match(thread_RegP);
 4583   op_cost(0);
 4584   format %{ %}
 4585   interface(REG_INTER);
 4586 %}
 4587 
 4588 // Pointer 64 bit Register R0 only
 4589 operand iRegP_R0()
 4590 %{
 4591   constraint(ALLOC_IN_RC(r0_reg));
 4592   match(RegP);
 4593   // match(iRegP);
 4594   match(iRegPNoSp);
 4595   op_cost(0);
 4596   format %{ %}
 4597   interface(REG_INTER);
 4598 %}
 4599 
 4600 // Pointer 64 bit Register R1 only
 4601 operand iRegP_R1()
 4602 %{
 4603   constraint(ALLOC_IN_RC(r1_reg));
 4604   match(RegP);
 4605   // match(iRegP);
 4606   match(iRegPNoSp);
 4607   op_cost(0);
 4608   format %{ %}
 4609   interface(REG_INTER);
 4610 %}
 4611 
 4612 // Pointer 64 bit Register R2 only
 4613 operand iRegP_R2()
 4614 %{
 4615   constraint(ALLOC_IN_RC(r2_reg));
 4616   match(RegP);
 4617   // match(iRegP);
 4618   match(iRegPNoSp);
 4619   op_cost(0);
 4620   format %{ %}
 4621   interface(REG_INTER);
 4622 %}
 4623 
 4624 // Pointer 64 bit Register R3 only
 4625 operand iRegP_R3()
 4626 %{
 4627   constraint(ALLOC_IN_RC(r3_reg));
 4628   match(RegP);
 4629   // match(iRegP);
 4630   match(iRegPNoSp);
 4631   op_cost(0);
 4632   format %{ %}
 4633   interface(REG_INTER);
 4634 %}
 4635 
 4636 // Pointer 64 bit Register R4 only
 4637 operand iRegP_R4()
 4638 %{
 4639   constraint(ALLOC_IN_RC(r4_reg));
 4640   match(RegP);
 4641   // match(iRegP);
 4642   match(iRegPNoSp);
 4643   op_cost(0);
 4644   format %{ %}
 4645   interface(REG_INTER);
 4646 %}
 4647 
 4648 // Pointer 64 bit Register R5 only
 4649 operand iRegP_R5()
 4650 %{
 4651   constraint(ALLOC_IN_RC(r5_reg));
 4652   match(RegP);
 4653   // match(iRegP);
 4654   match(iRegPNoSp);
 4655   op_cost(0);
 4656   format %{ %}
 4657   interface(REG_INTER);
 4658 %}
 4659 
 4660 // Pointer 64 bit Register R10 only
 4661 operand iRegP_R10()
 4662 %{
 4663   constraint(ALLOC_IN_RC(r10_reg));
 4664   match(RegP);
 4665   // match(iRegP);
 4666   match(iRegPNoSp);
 4667   op_cost(0);
 4668   format %{ %}
 4669   interface(REG_INTER);
 4670 %}
 4671 
 4672 // Long 64 bit Register R0 only
 4673 operand iRegL_R0()
 4674 %{
 4675   constraint(ALLOC_IN_RC(r0_reg));
 4676   match(RegL);
 4677   match(iRegLNoSp);
 4678   op_cost(0);
 4679   format %{ %}
 4680   interface(REG_INTER);
 4681 %}
 4682 
 4683 // Long 64 bit Register R2 only
 4684 operand iRegL_R2()
 4685 %{
 4686   constraint(ALLOC_IN_RC(r2_reg));
 4687   match(RegL);
 4688   match(iRegLNoSp);
 4689   op_cost(0);
 4690   format %{ %}
 4691   interface(REG_INTER);
 4692 %}
 4693 
 4694 // Long 64 bit Register R3 only
 4695 operand iRegL_R3()
 4696 %{
 4697   constraint(ALLOC_IN_RC(r3_reg));
 4698   match(RegL);
 4699   match(iRegLNoSp);
 4700   op_cost(0);
 4701   format %{ %}
 4702   interface(REG_INTER);
 4703 %}
 4704 
 4705 // Long 64 bit Register R11 only
 4706 operand iRegL_R11()
 4707 %{
 4708   constraint(ALLOC_IN_RC(r11_reg));
 4709   match(RegL);
 4710   match(iRegLNoSp);
 4711   op_cost(0);
 4712   format %{ %}
 4713   interface(REG_INTER);
 4714 %}
 4715 
 4716 // Pointer 64 bit Register FP only
 4717 operand iRegP_FP()
 4718 %{
 4719   constraint(ALLOC_IN_RC(fp_reg));
 4720   match(RegP);
 4721   // match(iRegP);
 4722   op_cost(0);
 4723   format %{ %}
 4724   interface(REG_INTER);
 4725 %}
 4726 
 4727 // Register R0 only
 4728 operand iRegI_R0()
 4729 %{
 4730   constraint(ALLOC_IN_RC(int_r0_reg));
 4731   match(RegI);
 4732   match(iRegINoSp);
 4733   op_cost(0);
 4734   format %{ %}
 4735   interface(REG_INTER);
 4736 %}
 4737 
 4738 // Register R2 only
 4739 operand iRegI_R2()
 4740 %{
 4741   constraint(ALLOC_IN_RC(int_r2_reg));
 4742   match(RegI);
 4743   match(iRegINoSp);
 4744   op_cost(0);
 4745   format %{ %}
 4746   interface(REG_INTER);
 4747 %}
 4748 
 4749 // Register R3 only
 4750 operand iRegI_R3()
 4751 %{
 4752   constraint(ALLOC_IN_RC(int_r3_reg));
 4753   match(RegI);
 4754   match(iRegINoSp);
 4755   op_cost(0);
 4756   format %{ %}
 4757   interface(REG_INTER);
 4758 %}
 4759 
 4760 
 4761 // Register R4 only
 4762 operand iRegI_R4()
 4763 %{
 4764   constraint(ALLOC_IN_RC(int_r4_reg));
 4765   match(RegI);
 4766   match(iRegINoSp);
 4767   op_cost(0);
 4768   format %{ %}
 4769   interface(REG_INTER);
 4770 %}
 4771 
 4772 
 4773 // Pointer Register Operands
 4774 // Narrow Pointer Register
 4775 operand iRegN()
 4776 %{
 4777   constraint(ALLOC_IN_RC(any_reg32));
 4778   match(RegN);
 4779   match(iRegNNoSp);
 4780   op_cost(0);
 4781   format %{ %}
 4782   interface(REG_INTER);
 4783 %}
 4784 
 4785 operand iRegN_R0()
 4786 %{
 4787   constraint(ALLOC_IN_RC(r0_reg));
 4788   match(iRegN);
 4789   op_cost(0);
 4790   format %{ %}
 4791   interface(REG_INTER);
 4792 %}
 4793 
 4794 operand iRegN_R2()
 4795 %{
 4796   constraint(ALLOC_IN_RC(r2_reg));
 4797   match(iRegN);
 4798   op_cost(0);
 4799   format %{ %}
 4800   interface(REG_INTER);
 4801 %}
 4802 
 4803 operand iRegN_R3()
 4804 %{
 4805   constraint(ALLOC_IN_RC(r3_reg));
 4806   match(iRegN);
 4807   op_cost(0);
 4808   format %{ %}
 4809   interface(REG_INTER);
 4810 %}
 4811 
 4812 // Integer 64 bit Register not Special
 4813 operand iRegNNoSp()
 4814 %{
 4815   constraint(ALLOC_IN_RC(no_special_reg32));
 4816   match(RegN);
 4817   op_cost(0);
 4818   format %{ %}
 4819   interface(REG_INTER);
 4820 %}
 4821 
 4822 // heap base register -- used for encoding immN0
 4823 
 4824 operand iRegIHeapbase()
 4825 %{
 4826   constraint(ALLOC_IN_RC(heapbase_reg));
 4827   match(RegI);
 4828   op_cost(0);
 4829   format %{ %}
 4830   interface(REG_INTER);
 4831 %}
 4832 
 4833 // Float Register
 4834 // Float register operands
 4835 operand vRegF()
 4836 %{
 4837   constraint(ALLOC_IN_RC(float_reg));
 4838   match(RegF);
 4839 
 4840   op_cost(0);
 4841   format %{ %}
 4842   interface(REG_INTER);
 4843 %}
 4844 
 4845 // Double Register
 4846 // Double register operands
 4847 operand vRegD()
 4848 %{
 4849   constraint(ALLOC_IN_RC(double_reg));
 4850   match(RegD);
 4851 
 4852   op_cost(0);
 4853   format %{ %}
 4854   interface(REG_INTER);
 4855 %}
 4856 
 4857 operand vecD()
 4858 %{
 4859   constraint(ALLOC_IN_RC(vectord_reg));
 4860   match(VecD);
 4861 
 4862   op_cost(0);
 4863   format %{ %}
 4864   interface(REG_INTER);
 4865 %}
 4866 
 4867 operand vecX()
 4868 %{
 4869   constraint(ALLOC_IN_RC(vectorx_reg));
 4870   match(VecX);
 4871 
 4872   op_cost(0);
 4873   format %{ %}
 4874   interface(REG_INTER);
 4875 %}
 4876 
 4877 operand vRegD_V0()
 4878 %{
 4879   constraint(ALLOC_IN_RC(v0_reg));
 4880   match(RegD);
 4881   op_cost(0);
 4882   format %{ %}
 4883   interface(REG_INTER);
 4884 %}
 4885 
 4886 operand vRegD_V1()
 4887 %{
 4888   constraint(ALLOC_IN_RC(v1_reg));
 4889   match(RegD);
 4890   op_cost(0);
 4891   format %{ %}
 4892   interface(REG_INTER);
 4893 %}
 4894 
 4895 operand vRegD_V2()
 4896 %{
 4897   constraint(ALLOC_IN_RC(v2_reg));
 4898   match(RegD);
 4899   op_cost(0);
 4900   format %{ %}
 4901   interface(REG_INTER);
 4902 %}
 4903 
 4904 operand vRegD_V3()
 4905 %{
 4906   constraint(ALLOC_IN_RC(v3_reg));
 4907   match(RegD);
 4908   op_cost(0);
 4909   format %{ %}
 4910   interface(REG_INTER);
 4911 %}
 4912 
 4913 operand vRegD_V4()
 4914 %{
 4915   constraint(ALLOC_IN_RC(v4_reg));
 4916   match(RegD);
 4917   op_cost(0);
 4918   format %{ %}
 4919   interface(REG_INTER);
 4920 %}
 4921 
 4922 operand vRegD_V5()
 4923 %{
 4924   constraint(ALLOC_IN_RC(v5_reg));
 4925   match(RegD);
 4926   op_cost(0);
 4927   format %{ %}
 4928   interface(REG_INTER);
 4929 %}
 4930 
 4931 operand vRegD_V6()
 4932 %{
 4933   constraint(ALLOC_IN_RC(v6_reg));
 4934   match(RegD);
 4935   op_cost(0);
 4936   format %{ %}
 4937   interface(REG_INTER);
 4938 %}
 4939 
 4940 operand vRegD_V7()
 4941 %{
 4942   constraint(ALLOC_IN_RC(v7_reg));
 4943   match(RegD);
 4944   op_cost(0);
 4945   format %{ %}
 4946   interface(REG_INTER);
 4947 %}
 4948 
 4949 operand vRegD_V8()
 4950 %{
 4951   constraint(ALLOC_IN_RC(v8_reg));
 4952   match(RegD);
 4953   op_cost(0);
 4954   format %{ %}
 4955   interface(REG_INTER);
 4956 %}
 4957 
 4958 operand vRegD_V9()
 4959 %{
 4960   constraint(ALLOC_IN_RC(v9_reg));
 4961   match(RegD);
 4962   op_cost(0);
 4963   format %{ %}
 4964   interface(REG_INTER);
 4965 %}
 4966 
 4967 operand vRegD_V10()
 4968 %{
 4969   constraint(ALLOC_IN_RC(v10_reg));
 4970   match(RegD);
 4971   op_cost(0);
 4972   format %{ %}
 4973   interface(REG_INTER);
 4974 %}
 4975 
 4976 operand vRegD_V11()
 4977 %{
 4978   constraint(ALLOC_IN_RC(v11_reg));
 4979   match(RegD);
 4980   op_cost(0);
 4981   format %{ %}
 4982   interface(REG_INTER);
 4983 %}
 4984 
 4985 operand vRegD_V12()
 4986 %{
 4987   constraint(ALLOC_IN_RC(v12_reg));
 4988   match(RegD);
 4989   op_cost(0);
 4990   format %{ %}
 4991   interface(REG_INTER);
 4992 %}
 4993 
 4994 operand vRegD_V13()
 4995 %{
 4996   constraint(ALLOC_IN_RC(v13_reg));
 4997   match(RegD);
 4998   op_cost(0);
 4999   format %{ %}
 5000   interface(REG_INTER);
 5001 %}
 5002 
 5003 operand vRegD_V14()
 5004 %{
 5005   constraint(ALLOC_IN_RC(v14_reg));
 5006   match(RegD);
 5007   op_cost(0);
 5008   format %{ %}
 5009   interface(REG_INTER);
 5010 %}
 5011 
 5012 operand vRegD_V15()
 5013 %{
 5014   constraint(ALLOC_IN_RC(v15_reg));
 5015   match(RegD);
 5016   op_cost(0);
 5017   format %{ %}
 5018   interface(REG_INTER);
 5019 %}
 5020 
 5021 operand vRegD_V16()
 5022 %{
 5023   constraint(ALLOC_IN_RC(v16_reg));
 5024   match(RegD);
 5025   op_cost(0);
 5026   format %{ %}
 5027   interface(REG_INTER);
 5028 %}
 5029 
 5030 operand vRegD_V17()
 5031 %{
 5032   constraint(ALLOC_IN_RC(v17_reg));
 5033   match(RegD);
 5034   op_cost(0);
 5035   format %{ %}
 5036   interface(REG_INTER);
 5037 %}
 5038 
 5039 operand vRegD_V18()
 5040 %{
 5041   constraint(ALLOC_IN_RC(v18_reg));
 5042   match(RegD);
 5043   op_cost(0);
 5044   format %{ %}
 5045   interface(REG_INTER);
 5046 %}
 5047 
 5048 operand vRegD_V19()
 5049 %{
 5050   constraint(ALLOC_IN_RC(v19_reg));
 5051   match(RegD);
 5052   op_cost(0);
 5053   format %{ %}
 5054   interface(REG_INTER);
 5055 %}
 5056 
 5057 operand vRegD_V20()
 5058 %{
 5059   constraint(ALLOC_IN_RC(v20_reg));
 5060   match(RegD);
 5061   op_cost(0);
 5062   format %{ %}
 5063   interface(REG_INTER);
 5064 %}
 5065 
 5066 operand vRegD_V21()
 5067 %{
 5068   constraint(ALLOC_IN_RC(v21_reg));
 5069   match(RegD);
 5070   op_cost(0);
 5071   format %{ %}
 5072   interface(REG_INTER);
 5073 %}
 5074 
 5075 operand vRegD_V22()
 5076 %{
 5077   constraint(ALLOC_IN_RC(v22_reg));
 5078   match(RegD);
 5079   op_cost(0);
 5080   format %{ %}
 5081   interface(REG_INTER);
 5082 %}
 5083 
 5084 operand vRegD_V23()
 5085 %{
 5086   constraint(ALLOC_IN_RC(v23_reg));
 5087   match(RegD);
 5088   op_cost(0);
 5089   format %{ %}
 5090   interface(REG_INTER);
 5091 %}
 5092 
 5093 operand vRegD_V24()
 5094 %{
 5095   constraint(ALLOC_IN_RC(v24_reg));
 5096   match(RegD);
 5097   op_cost(0);
 5098   format %{ %}
 5099   interface(REG_INTER);
 5100 %}
 5101 
 5102 operand vRegD_V25()
 5103 %{
 5104   constraint(ALLOC_IN_RC(v25_reg));
 5105   match(RegD);
 5106   op_cost(0);
 5107   format %{ %}
 5108   interface(REG_INTER);
 5109 %}
 5110 
 5111 operand vRegD_V26()
 5112 %{
 5113   constraint(ALLOC_IN_RC(v26_reg));
 5114   match(RegD);
 5115   op_cost(0);
 5116   format %{ %}
 5117   interface(REG_INTER);
 5118 %}
 5119 
 5120 operand vRegD_V27()
 5121 %{
 5122   constraint(ALLOC_IN_RC(v27_reg));
 5123   match(RegD);
 5124   op_cost(0);
 5125   format %{ %}
 5126   interface(REG_INTER);
 5127 %}
 5128 
 5129 operand vRegD_V28()
 5130 %{
 5131   constraint(ALLOC_IN_RC(v28_reg));
 5132   match(RegD);
 5133   op_cost(0);
 5134   format %{ %}
 5135   interface(REG_INTER);
 5136 %}
 5137 
 5138 operand vRegD_V29()
 5139 %{
 5140   constraint(ALLOC_IN_RC(v29_reg));
 5141   match(RegD);
 5142   op_cost(0);
 5143   format %{ %}
 5144   interface(REG_INTER);
 5145 %}
 5146 
 5147 operand vRegD_V30()
 5148 %{
 5149   constraint(ALLOC_IN_RC(v30_reg));
 5150   match(RegD);
 5151   op_cost(0);
 5152   format %{ %}
 5153   interface(REG_INTER);
 5154 %}
 5155 
 5156 operand vRegD_V31()
 5157 %{
 5158   constraint(ALLOC_IN_RC(v31_reg));
 5159   match(RegD);
 5160   op_cost(0);
 5161   format %{ %}
 5162   interface(REG_INTER);
 5163 %}
 5164 
 5165 // Flags register, used as output of signed compare instructions
 5166 
 5167 // note that on AArch64 we also use this register as the output for
 5168 // for floating point compare instructions (CmpF CmpD). this ensures
 5169 // that ordered inequality tests use GT, GE, LT or LE none of which
 5170 // pass through cases where the result is unordered i.e. one or both
 5171 // inputs to the compare is a NaN. this means that the ideal code can
 5172 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5173 // (where the comparison should always fail). EQ and NE tests are
 5174 // always generated in ideal code so that unordered folds into the NE
 5175 // case, matching the behaviour of AArch64 NE.
 5176 //
 5177 // This differs from x86 where the outputs of FP compares use a
 5178 // special FP flags registers and where compares based on this
 5179 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5180 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5181 // to explicitly handle the unordered case in branches. x86 also has
 5182 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5183 
 5184 operand rFlagsReg()
 5185 %{
 5186   constraint(ALLOC_IN_RC(int_flags));
 5187   match(RegFlags);
 5188 
 5189   op_cost(0);
 5190   format %{ &quot;RFLAGS&quot; %}
 5191   interface(REG_INTER);
 5192 %}
 5193 
 5194 // Flags register, used as output of unsigned compare instructions
 5195 operand rFlagsRegU()
 5196 %{
 5197   constraint(ALLOC_IN_RC(int_flags));
 5198   match(RegFlags);
 5199 
 5200   op_cost(0);
 5201   format %{ &quot;RFLAGSU&quot; %}
 5202   interface(REG_INTER);
 5203 %}
 5204 
 5205 // Special Registers
 5206 
 5207 // Method Register
 5208 operand inline_cache_RegP(iRegP reg)
 5209 %{
 5210   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5211   match(reg);
 5212   match(iRegPNoSp);
 5213   op_cost(0);
 5214   format %{ %}
 5215   interface(REG_INTER);
 5216 %}
 5217 
 5218 operand interpreter_method_oop_RegP(iRegP reg)
 5219 %{
 5220   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5221   match(reg);
 5222   match(iRegPNoSp);
 5223   op_cost(0);
 5224   format %{ %}
 5225   interface(REG_INTER);
 5226 %}
 5227 
 5228 // Thread Register
 5229 operand thread_RegP(iRegP reg)
 5230 %{
 5231   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5232   match(reg);
 5233   op_cost(0);
 5234   format %{ %}
 5235   interface(REG_INTER);
 5236 %}
 5237 
 5238 operand lr_RegP(iRegP reg)
 5239 %{
 5240   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5241   match(reg);
 5242   op_cost(0);
 5243   format %{ %}
 5244   interface(REG_INTER);
 5245 %}
 5246 
 5247 //----------Memory Operands----------------------------------------------------
 5248 
 5249 operand indirect(iRegP reg)
 5250 %{
 5251   constraint(ALLOC_IN_RC(ptr_reg));
 5252   match(reg);
 5253   op_cost(0);
 5254   format %{ &quot;[$reg]&quot; %}
 5255   interface(MEMORY_INTER) %{
 5256     base($reg);
 5257     index(0xffffffff);
 5258     scale(0x0);
 5259     disp(0x0);
 5260   %}
 5261 %}
 5262 
 5263 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5264 %{
 5265   constraint(ALLOC_IN_RC(ptr_reg));
 5266   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5267   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5268   op_cost(0);
 5269   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5270   interface(MEMORY_INTER) %{
 5271     base($reg);
 5272     index($ireg);
 5273     scale($scale);
 5274     disp(0x0);
 5275   %}
 5276 %}
 5277 
 5278 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5279 %{
 5280   constraint(ALLOC_IN_RC(ptr_reg));
 5281   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5282   match(AddP reg (LShiftL lreg scale));
 5283   op_cost(0);
 5284   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5285   interface(MEMORY_INTER) %{
 5286     base($reg);
 5287     index($lreg);
 5288     scale($scale);
 5289     disp(0x0);
 5290   %}
 5291 %}
 5292 
 5293 operand indIndexI2L(iRegP reg, iRegI ireg)
 5294 %{
 5295   constraint(ALLOC_IN_RC(ptr_reg));
 5296   match(AddP reg (ConvI2L ireg));
 5297   op_cost(0);
 5298   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5299   interface(MEMORY_INTER) %{
 5300     base($reg);
 5301     index($ireg);
 5302     scale(0x0);
 5303     disp(0x0);
 5304   %}
 5305 %}
 5306 
 5307 operand indIndex(iRegP reg, iRegL lreg)
 5308 %{
 5309   constraint(ALLOC_IN_RC(ptr_reg));
 5310   match(AddP reg lreg);
 5311   op_cost(0);
 5312   format %{ &quot;$reg, $lreg&quot; %}
 5313   interface(MEMORY_INTER) %{
 5314     base($reg);
 5315     index($lreg);
 5316     scale(0x0);
 5317     disp(0x0);
 5318   %}
 5319 %}
 5320 
 5321 operand indOffI(iRegP reg, immIOffset off)
 5322 %{
 5323   constraint(ALLOC_IN_RC(ptr_reg));
 5324   match(AddP reg off);
 5325   op_cost(0);
 5326   format %{ &quot;[$reg, $off]&quot; %}
 5327   interface(MEMORY_INTER) %{
 5328     base($reg);
 5329     index(0xffffffff);
 5330     scale(0x0);
 5331     disp($off);
 5332   %}
 5333 %}
 5334 
 5335 operand indOffI1(iRegP reg, immIOffset1 off)
 5336 %{
 5337   constraint(ALLOC_IN_RC(ptr_reg));
 5338   match(AddP reg off);
 5339   op_cost(0);
 5340   format %{ &quot;[$reg, $off]&quot; %}
 5341   interface(MEMORY_INTER) %{
 5342     base($reg);
 5343     index(0xffffffff);
 5344     scale(0x0);
 5345     disp($off);
 5346   %}
 5347 %}
 5348 
 5349 operand indOffI2(iRegP reg, immIOffset2 off)
 5350 %{
 5351   constraint(ALLOC_IN_RC(ptr_reg));
 5352   match(AddP reg off);
 5353   op_cost(0);
 5354   format %{ &quot;[$reg, $off]&quot; %}
 5355   interface(MEMORY_INTER) %{
 5356     base($reg);
 5357     index(0xffffffff);
 5358     scale(0x0);
 5359     disp($off);
 5360   %}
 5361 %}
 5362 
 5363 operand indOffI4(iRegP reg, immIOffset4 off)
 5364 %{
 5365   constraint(ALLOC_IN_RC(ptr_reg));
 5366   match(AddP reg off);
 5367   op_cost(0);
 5368   format %{ &quot;[$reg, $off]&quot; %}
 5369   interface(MEMORY_INTER) %{
 5370     base($reg);
 5371     index(0xffffffff);
 5372     scale(0x0);
 5373     disp($off);
 5374   %}
 5375 %}
 5376 
 5377 operand indOffI8(iRegP reg, immIOffset8 off)
 5378 %{
 5379   constraint(ALLOC_IN_RC(ptr_reg));
 5380   match(AddP reg off);
 5381   op_cost(0);
 5382   format %{ &quot;[$reg, $off]&quot; %}
 5383   interface(MEMORY_INTER) %{
 5384     base($reg);
 5385     index(0xffffffff);
 5386     scale(0x0);
 5387     disp($off);
 5388   %}
 5389 %}
 5390 
 5391 operand indOffI16(iRegP reg, immIOffset16 off)
 5392 %{
 5393   constraint(ALLOC_IN_RC(ptr_reg));
 5394   match(AddP reg off);
 5395   op_cost(0);
 5396   format %{ &quot;[$reg, $off]&quot; %}
 5397   interface(MEMORY_INTER) %{
 5398     base($reg);
 5399     index(0xffffffff);
 5400     scale(0x0);
 5401     disp($off);
 5402   %}
 5403 %}
 5404 
 5405 operand indOffL(iRegP reg, immLoffset off)
 5406 %{
 5407   constraint(ALLOC_IN_RC(ptr_reg));
 5408   match(AddP reg off);
 5409   op_cost(0);
 5410   format %{ &quot;[$reg, $off]&quot; %}
 5411   interface(MEMORY_INTER) %{
 5412     base($reg);
 5413     index(0xffffffff);
 5414     scale(0x0);
 5415     disp($off);
 5416   %}
 5417 %}
 5418 
 5419 operand indOffL1(iRegP reg, immLoffset1 off)
 5420 %{
 5421   constraint(ALLOC_IN_RC(ptr_reg));
 5422   match(AddP reg off);
 5423   op_cost(0);
 5424   format %{ &quot;[$reg, $off]&quot; %}
 5425   interface(MEMORY_INTER) %{
 5426     base($reg);
 5427     index(0xffffffff);
 5428     scale(0x0);
 5429     disp($off);
 5430   %}
 5431 %}
 5432 
 5433 operand indOffL2(iRegP reg, immLoffset2 off)
 5434 %{
 5435   constraint(ALLOC_IN_RC(ptr_reg));
 5436   match(AddP reg off);
 5437   op_cost(0);
 5438   format %{ &quot;[$reg, $off]&quot; %}
 5439   interface(MEMORY_INTER) %{
 5440     base($reg);
 5441     index(0xffffffff);
 5442     scale(0x0);
 5443     disp($off);
 5444   %}
 5445 %}
 5446 
 5447 operand indOffL4(iRegP reg, immLoffset4 off)
 5448 %{
 5449   constraint(ALLOC_IN_RC(ptr_reg));
 5450   match(AddP reg off);
 5451   op_cost(0);
 5452   format %{ &quot;[$reg, $off]&quot; %}
 5453   interface(MEMORY_INTER) %{
 5454     base($reg);
 5455     index(0xffffffff);
 5456     scale(0x0);
 5457     disp($off);
 5458   %}
 5459 %}
 5460 
 5461 operand indOffL8(iRegP reg, immLoffset8 off)
 5462 %{
 5463   constraint(ALLOC_IN_RC(ptr_reg));
 5464   match(AddP reg off);
 5465   op_cost(0);
 5466   format %{ &quot;[$reg, $off]&quot; %}
 5467   interface(MEMORY_INTER) %{
 5468     base($reg);
 5469     index(0xffffffff);
 5470     scale(0x0);
 5471     disp($off);
 5472   %}
 5473 %}
 5474 
 5475 operand indOffL16(iRegP reg, immLoffset16 off)
 5476 %{
 5477   constraint(ALLOC_IN_RC(ptr_reg));
 5478   match(AddP reg off);
 5479   op_cost(0);
 5480   format %{ &quot;[$reg, $off]&quot; %}
 5481   interface(MEMORY_INTER) %{
 5482     base($reg);
 5483     index(0xffffffff);
 5484     scale(0x0);
 5485     disp($off);
 5486   %}
 5487 %}
 5488 
 5489 operand indirectN(iRegN reg)
 5490 %{
 5491   predicate(CompressedOops::shift() == 0);
 5492   constraint(ALLOC_IN_RC(ptr_reg));
 5493   match(DecodeN reg);
 5494   op_cost(0);
 5495   format %{ &quot;[$reg]\t# narrow&quot; %}
 5496   interface(MEMORY_INTER) %{
 5497     base($reg);
 5498     index(0xffffffff);
 5499     scale(0x0);
 5500     disp(0x0);
 5501   %}
 5502 %}
 5503 
 5504 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5505 %{
 5506   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5507   constraint(ALLOC_IN_RC(ptr_reg));
 5508   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5509   op_cost(0);
 5510   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5511   interface(MEMORY_INTER) %{
 5512     base($reg);
 5513     index($ireg);
 5514     scale($scale);
 5515     disp(0x0);
 5516   %}
 5517 %}
 5518 
 5519 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5520 %{
 5521   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5522   constraint(ALLOC_IN_RC(ptr_reg));
 5523   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5524   op_cost(0);
 5525   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5526   interface(MEMORY_INTER) %{
 5527     base($reg);
 5528     index($lreg);
 5529     scale($scale);
 5530     disp(0x0);
 5531   %}
 5532 %}
 5533 
 5534 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5535 %{
 5536   predicate(CompressedOops::shift() == 0);
 5537   constraint(ALLOC_IN_RC(ptr_reg));
 5538   match(AddP (DecodeN reg) (ConvI2L ireg));
 5539   op_cost(0);
 5540   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5541   interface(MEMORY_INTER) %{
 5542     base($reg);
 5543     index($ireg);
 5544     scale(0x0);
 5545     disp(0x0);
 5546   %}
 5547 %}
 5548 
 5549 operand indIndexN(iRegN reg, iRegL lreg)
 5550 %{
 5551   predicate(CompressedOops::shift() == 0);
 5552   constraint(ALLOC_IN_RC(ptr_reg));
 5553   match(AddP (DecodeN reg) lreg);
 5554   op_cost(0);
 5555   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5556   interface(MEMORY_INTER) %{
 5557     base($reg);
 5558     index($lreg);
 5559     scale(0x0);
 5560     disp(0x0);
 5561   %}
 5562 %}
 5563 
 5564 operand indOffIN(iRegN reg, immIOffset off)
 5565 %{
 5566   predicate(CompressedOops::shift() == 0);
 5567   constraint(ALLOC_IN_RC(ptr_reg));
 5568   match(AddP (DecodeN reg) off);
 5569   op_cost(0);
 5570   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5571   interface(MEMORY_INTER) %{
 5572     base($reg);
 5573     index(0xffffffff);
 5574     scale(0x0);
 5575     disp($off);
 5576   %}
 5577 %}
 5578 
 5579 operand indOffLN(iRegN reg, immLoffset off)
 5580 %{
 5581   predicate(CompressedOops::shift() == 0);
 5582   constraint(ALLOC_IN_RC(ptr_reg));
 5583   match(AddP (DecodeN reg) off);
 5584   op_cost(0);
 5585   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5586   interface(MEMORY_INTER) %{
 5587     base($reg);
 5588     index(0xffffffff);
 5589     scale(0x0);
 5590     disp($off);
 5591   %}
 5592 %}
 5593 
 5594 
 5595 
 5596 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5597 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5598 %{
 5599   constraint(ALLOC_IN_RC(ptr_reg));
 5600   match(AddP reg off);
 5601   op_cost(0);
 5602   format %{ &quot;[$reg, $off]&quot; %}
 5603   interface(MEMORY_INTER) %{
 5604     base($reg);
 5605     index(0xffffffff);
 5606     scale(0x0);
 5607     disp($off);
 5608   %}
 5609 %}
 5610 
 5611 //----------Special Memory Operands--------------------------------------------
 5612 // Stack Slot Operand - This operand is used for loading and storing temporary
 5613 //                      values on the stack where a match requires a value to
 5614 //                      flow through memory.
 5615 operand stackSlotP(sRegP reg)
 5616 %{
 5617   constraint(ALLOC_IN_RC(stack_slots));
 5618   op_cost(100);
 5619   // No match rule because this operand is only generated in matching
 5620   // match(RegP);
 5621   format %{ &quot;[$reg]&quot; %}
 5622   interface(MEMORY_INTER) %{
 5623     base(0x1e);  // RSP
 5624     index(0x0);  // No Index
 5625     scale(0x0);  // No Scale
 5626     disp($reg);  // Stack Offset
 5627   %}
 5628 %}
 5629 
 5630 operand stackSlotI(sRegI reg)
 5631 %{
 5632   constraint(ALLOC_IN_RC(stack_slots));
 5633   // No match rule because this operand is only generated in matching
 5634   // match(RegI);
 5635   format %{ &quot;[$reg]&quot; %}
 5636   interface(MEMORY_INTER) %{
 5637     base(0x1e);  // RSP
 5638     index(0x0);  // No Index
 5639     scale(0x0);  // No Scale
 5640     disp($reg);  // Stack Offset
 5641   %}
 5642 %}
 5643 
 5644 operand stackSlotF(sRegF reg)
 5645 %{
 5646   constraint(ALLOC_IN_RC(stack_slots));
 5647   // No match rule because this operand is only generated in matching
 5648   // match(RegF);
 5649   format %{ &quot;[$reg]&quot; %}
 5650   interface(MEMORY_INTER) %{
 5651     base(0x1e);  // RSP
 5652     index(0x0);  // No Index
 5653     scale(0x0);  // No Scale
 5654     disp($reg);  // Stack Offset
 5655   %}
 5656 %}
 5657 
 5658 operand stackSlotD(sRegD reg)
 5659 %{
 5660   constraint(ALLOC_IN_RC(stack_slots));
 5661   // No match rule because this operand is only generated in matching
 5662   // match(RegD);
 5663   format %{ &quot;[$reg]&quot; %}
 5664   interface(MEMORY_INTER) %{
 5665     base(0x1e);  // RSP
 5666     index(0x0);  // No Index
 5667     scale(0x0);  // No Scale
 5668     disp($reg);  // Stack Offset
 5669   %}
 5670 %}
 5671 
 5672 operand stackSlotL(sRegL reg)
 5673 %{
 5674   constraint(ALLOC_IN_RC(stack_slots));
 5675   // No match rule because this operand is only generated in matching
 5676   // match(RegL);
 5677   format %{ &quot;[$reg]&quot; %}
 5678   interface(MEMORY_INTER) %{
 5679     base(0x1e);  // RSP
 5680     index(0x0);  // No Index
 5681     scale(0x0);  // No Scale
 5682     disp($reg);  // Stack Offset
 5683   %}
 5684 %}
 5685 
 5686 // Operands for expressing Control Flow
 5687 // NOTE: Label is a predefined operand which should not be redefined in
 5688 //       the AD file. It is generically handled within the ADLC.
 5689 
 5690 //----------Conditional Branch Operands----------------------------------------
 5691 // Comparison Op  - This is the operation of the comparison, and is limited to
 5692 //                  the following set of codes:
 5693 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5694 //
 5695 // Other attributes of the comparison, such as unsignedness, are specified
 5696 // by the comparison instruction that sets a condition code flags register.
 5697 // That result is represented by a flags operand whose subtype is appropriate
 5698 // to the unsignedness (etc.) of the comparison.
 5699 //
 5700 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5701 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5702 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5703 
 5704 // used for signed integral comparisons and fp comparisons
 5705 
 5706 operand cmpOp()
 5707 %{
 5708   match(Bool);
 5709 
 5710   format %{ &quot;&quot; %}
 5711   interface(COND_INTER) %{
 5712     equal(0x0, &quot;eq&quot;);
 5713     not_equal(0x1, &quot;ne&quot;);
 5714     less(0xb, &quot;lt&quot;);
 5715     greater_equal(0xa, &quot;ge&quot;);
 5716     less_equal(0xd, &quot;le&quot;);
 5717     greater(0xc, &quot;gt&quot;);
 5718     overflow(0x6, &quot;vs&quot;);
 5719     no_overflow(0x7, &quot;vc&quot;);
 5720   %}
 5721 %}
 5722 
 5723 // used for unsigned integral comparisons
 5724 
 5725 operand cmpOpU()
 5726 %{
 5727   match(Bool);
 5728 
 5729   format %{ &quot;&quot; %}
 5730   interface(COND_INTER) %{
 5731     equal(0x0, &quot;eq&quot;);
 5732     not_equal(0x1, &quot;ne&quot;);
 5733     less(0x3, &quot;lo&quot;);
 5734     greater_equal(0x2, &quot;hs&quot;);
 5735     less_equal(0x9, &quot;ls&quot;);
 5736     greater(0x8, &quot;hi&quot;);
 5737     overflow(0x6, &quot;vs&quot;);
 5738     no_overflow(0x7, &quot;vc&quot;);
 5739   %}
 5740 %}
 5741 
 5742 // used for certain integral comparisons which can be
 5743 // converted to cbxx or tbxx instructions
 5744 
 5745 operand cmpOpEqNe()
 5746 %{
 5747   match(Bool);
 5748   op_cost(0);
 5749   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5750             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5751 
 5752   format %{ &quot;&quot; %}
 5753   interface(COND_INTER) %{
 5754     equal(0x0, &quot;eq&quot;);
 5755     not_equal(0x1, &quot;ne&quot;);
 5756     less(0xb, &quot;lt&quot;);
 5757     greater_equal(0xa, &quot;ge&quot;);
 5758     less_equal(0xd, &quot;le&quot;);
 5759     greater(0xc, &quot;gt&quot;);
 5760     overflow(0x6, &quot;vs&quot;);
 5761     no_overflow(0x7, &quot;vc&quot;);
 5762   %}
 5763 %}
 5764 
 5765 // used for certain integral comparisons which can be
 5766 // converted to cbxx or tbxx instructions
 5767 
 5768 operand cmpOpLtGe()
 5769 %{
 5770   match(Bool);
 5771   op_cost(0);
 5772 
 5773   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5774             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5775 
 5776   format %{ &quot;&quot; %}
 5777   interface(COND_INTER) %{
 5778     equal(0x0, &quot;eq&quot;);
 5779     not_equal(0x1, &quot;ne&quot;);
 5780     less(0xb, &quot;lt&quot;);
 5781     greater_equal(0xa, &quot;ge&quot;);
 5782     less_equal(0xd, &quot;le&quot;);
 5783     greater(0xc, &quot;gt&quot;);
 5784     overflow(0x6, &quot;vs&quot;);
 5785     no_overflow(0x7, &quot;vc&quot;);
 5786   %}
 5787 %}
 5788 
 5789 // used for certain unsigned integral comparisons which can be
 5790 // converted to cbxx or tbxx instructions
 5791 
 5792 operand cmpOpUEqNeLtGe()
 5793 %{
 5794   match(Bool);
 5795   op_cost(0);
 5796 
 5797   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5798             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5799             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5800             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5801 
 5802   format %{ &quot;&quot; %}
 5803   interface(COND_INTER) %{
 5804     equal(0x0, &quot;eq&quot;);
 5805     not_equal(0x1, &quot;ne&quot;);
 5806     less(0xb, &quot;lt&quot;);
 5807     greater_equal(0xa, &quot;ge&quot;);
 5808     less_equal(0xd, &quot;le&quot;);
 5809     greater(0xc, &quot;gt&quot;);
 5810     overflow(0x6, &quot;vs&quot;);
 5811     no_overflow(0x7, &quot;vc&quot;);
 5812   %}
 5813 %}
 5814 
 5815 // Special operand allowing long args to int ops to be truncated for free
 5816 
 5817 operand iRegL2I(iRegL reg) %{
 5818 
 5819   op_cost(0);
 5820 
 5821   match(ConvL2I reg);
 5822 
 5823   format %{ &quot;l2i($reg)&quot; %}
 5824 
 5825   interface(REG_INTER)
 5826 %}
 5827 
 5828 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5829 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5830 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5831 
 5832 //----------OPERAND CLASSES----------------------------------------------------
 5833 // Operand Classes are groups of operands that are used as to simplify
 5834 // instruction definitions by not requiring the AD writer to specify
 5835 // separate instructions for every form of operand when the
 5836 // instruction accepts multiple operand types with the same basic
 5837 // encoding and format. The classic case of this is memory operands.
 5838 
 5839 // memory is used to define read/write location for load/store
 5840 // instruction defs. we can turn a memory op into an Address
 5841 
 5842 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5843                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5844 
 5845 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5846                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5847 
 5848 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5849                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5850 
 5851 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5852                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5853 
 5854 // All of the memory operands. For the pipeline description.
 5855 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5856                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5857                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5858 
 5859 
 5860 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5861 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5862 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5863 // can be elided because the 32-bit instruction will just employ the
 5864 // lower 32 bits anyway.
 5865 //
 5866 // n.b. this does not elide all L2I conversions. if the truncated
 5867 // value is consumed by more than one operation then the ConvL2I
 5868 // cannot be bundled into the consuming nodes so an l2i gets planted
 5869 // (actually a movw $dst $src) and the downstream instructions consume
 5870 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5871 // movw is actually redundant but its not too costly.
 5872 
 5873 opclass iRegIorL2I(iRegI, iRegL2I);
 5874 
 5875 //----------PIPELINE-----------------------------------------------------------
 5876 // Rules which define the behavior of the target architectures pipeline.
 5877 
 5878 // For specific pipelines, eg A53, define the stages of that pipeline
 5879 //pipe_desc(ISS, EX1, EX2, WR);
 5880 #define ISS S0
 5881 #define EX1 S1
 5882 #define EX2 S2
 5883 #define WR  S3
 5884 
 5885 // Integer ALU reg operation
 5886 pipeline %{
 5887 
 5888 attributes %{
 5889   // ARM instructions are of fixed length
 5890   fixed_size_instructions;        // Fixed size instructions TODO does
 5891   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5892   // ARM instructions come in 32-bit word units
 5893   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5894   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5895   instruction_fetch_units = 1;       // of 64 bytes
 5896 
 5897   // List of nop instructions
 5898   nops( MachNop );
 5899 %}
 5900 
 5901 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5902 // or description. we do use pipeline classes to introduce fixed
 5903 // latencies
 5904 
 5905 //----------RESOURCES----------------------------------------------------------
 5906 // Resources are the functional units available to the machine
 5907 
 5908 resources( INS0, INS1, INS01 = INS0 | INS1,
 5909            ALU0, ALU1, ALU = ALU0 | ALU1,
 5910            MAC,
 5911            DIV,
 5912            BRANCH,
 5913            LDST,
 5914            NEON_FP);
 5915 
 5916 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5917 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5918 
 5919 // Define the pipeline as a generic 6 stage pipeline
 5920 pipe_desc(S0, S1, S2, S3, S4, S5);
 5921 
 5922 //----------PIPELINE CLASSES---------------------------------------------------
 5923 // Pipeline Classes describe the stages in which input and output are
 5924 // referenced by the hardware pipeline.
 5925 
 5926 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5927 %{
 5928   single_instruction;
 5929   src1   : S1(read);
 5930   src2   : S2(read);
 5931   dst    : S5(write);
 5932   INS01  : ISS;
 5933   NEON_FP : S5;
 5934 %}
 5935 
 5936 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5937 %{
 5938   single_instruction;
 5939   src1   : S1(read);
 5940   src2   : S2(read);
 5941   dst    : S5(write);
 5942   INS01  : ISS;
 5943   NEON_FP : S5;
 5944 %}
 5945 
 5946 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5947 %{
 5948   single_instruction;
 5949   src    : S1(read);
 5950   dst    : S5(write);
 5951   INS01  : ISS;
 5952   NEON_FP : S5;
 5953 %}
 5954 
 5955 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5956 %{
 5957   single_instruction;
 5958   src    : S1(read);
 5959   dst    : S5(write);
 5960   INS01  : ISS;
 5961   NEON_FP : S5;
 5962 %}
 5963 
 5964 pipe_class fp_d2f(vRegF dst, vRegD src)
 5965 %{
 5966   single_instruction;
 5967   src    : S1(read);
 5968   dst    : S5(write);
 5969   INS01  : ISS;
 5970   NEON_FP : S5;
 5971 %}
 5972 
 5973 pipe_class fp_f2d(vRegD dst, vRegF src)
 5974 %{
 5975   single_instruction;
 5976   src    : S1(read);
 5977   dst    : S5(write);
 5978   INS01  : ISS;
 5979   NEON_FP : S5;
 5980 %}
 5981 
 5982 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5983 %{
 5984   single_instruction;
 5985   src    : S1(read);
 5986   dst    : S5(write);
 5987   INS01  : ISS;
 5988   NEON_FP : S5;
 5989 %}
 5990 
 5991 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5992 %{
 5993   single_instruction;
 5994   src    : S1(read);
 5995   dst    : S5(write);
 5996   INS01  : ISS;
 5997   NEON_FP : S5;
 5998 %}
 5999 
 6000 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6001 %{
 6002   single_instruction;
 6003   src    : S1(read);
 6004   dst    : S5(write);
 6005   INS01  : ISS;
 6006   NEON_FP : S5;
 6007 %}
 6008 
 6009 pipe_class fp_l2f(vRegF dst, iRegL src)
 6010 %{
 6011   single_instruction;
 6012   src    : S1(read);
 6013   dst    : S5(write);
 6014   INS01  : ISS;
 6015   NEON_FP : S5;
 6016 %}
 6017 
 6018 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6019 %{
 6020   single_instruction;
 6021   src    : S1(read);
 6022   dst    : S5(write);
 6023   INS01  : ISS;
 6024   NEON_FP : S5;
 6025 %}
 6026 
 6027 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6028 %{
 6029   single_instruction;
 6030   src    : S1(read);
 6031   dst    : S5(write);
 6032   INS01  : ISS;
 6033   NEON_FP : S5;
 6034 %}
 6035 
 6036 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6037 %{
 6038   single_instruction;
 6039   src    : S1(read);
 6040   dst    : S5(write);
 6041   INS01  : ISS;
 6042   NEON_FP : S5;
 6043 %}
 6044 
 6045 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6046 %{
 6047   single_instruction;
 6048   src    : S1(read);
 6049   dst    : S5(write);
 6050   INS01  : ISS;
 6051   NEON_FP : S5;
 6052 %}
 6053 
 6054 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6055 %{
 6056   single_instruction;
 6057   src1   : S1(read);
 6058   src2   : S2(read);
 6059   dst    : S5(write);
 6060   INS0   : ISS;
 6061   NEON_FP : S5;
 6062 %}
 6063 
 6064 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6065 %{
 6066   single_instruction;
 6067   src1   : S1(read);
 6068   src2   : S2(read);
 6069   dst    : S5(write);
 6070   INS0   : ISS;
 6071   NEON_FP : S5;
 6072 %}
 6073 
 6074 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6075 %{
 6076   single_instruction;
 6077   cr     : S1(read);
 6078   src1   : S1(read);
 6079   src2   : S1(read);
 6080   dst    : S3(write);
 6081   INS01  : ISS;
 6082   NEON_FP : S3;
 6083 %}
 6084 
 6085 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6086 %{
 6087   single_instruction;
 6088   cr     : S1(read);
 6089   src1   : S1(read);
 6090   src2   : S1(read);
 6091   dst    : S3(write);
 6092   INS01  : ISS;
 6093   NEON_FP : S3;
 6094 %}
 6095 
 6096 pipe_class fp_imm_s(vRegF dst)
 6097 %{
 6098   single_instruction;
 6099   dst    : S3(write);
 6100   INS01  : ISS;
 6101   NEON_FP : S3;
 6102 %}
 6103 
 6104 pipe_class fp_imm_d(vRegD dst)
 6105 %{
 6106   single_instruction;
 6107   dst    : S3(write);
 6108   INS01  : ISS;
 6109   NEON_FP : S3;
 6110 %}
 6111 
 6112 pipe_class fp_load_constant_s(vRegF dst)
 6113 %{
 6114   single_instruction;
 6115   dst    : S4(write);
 6116   INS01  : ISS;
 6117   NEON_FP : S4;
 6118 %}
 6119 
 6120 pipe_class fp_load_constant_d(vRegD dst)
 6121 %{
 6122   single_instruction;
 6123   dst    : S4(write);
 6124   INS01  : ISS;
 6125   NEON_FP : S4;
 6126 %}
 6127 
 6128 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6129 %{
 6130   single_instruction;
 6131   dst    : S5(write);
 6132   src1   : S1(read);
 6133   src2   : S1(read);
 6134   INS01  : ISS;
 6135   NEON_FP : S5;
 6136 %}
 6137 
 6138 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6139 %{
 6140   single_instruction;
 6141   dst    : S5(write);
 6142   src1   : S1(read);
 6143   src2   : S1(read);
 6144   INS0   : ISS;
 6145   NEON_FP : S5;
 6146 %}
 6147 
 6148 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6149 %{
 6150   single_instruction;
 6151   dst    : S5(write);
 6152   src1   : S1(read);
 6153   src2   : S1(read);
 6154   dst    : S1(read);
 6155   INS01  : ISS;
 6156   NEON_FP : S5;
 6157 %}
 6158 
 6159 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6160 %{
 6161   single_instruction;
 6162   dst    : S5(write);
 6163   src1   : S1(read);
 6164   src2   : S1(read);
 6165   dst    : S1(read);
 6166   INS0   : ISS;
 6167   NEON_FP : S5;
 6168 %}
 6169 
 6170 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6171 %{
 6172   single_instruction;
 6173   dst    : S4(write);
 6174   src1   : S2(read);
 6175   src2   : S2(read);
 6176   INS01  : ISS;
 6177   NEON_FP : S4;
 6178 %}
 6179 
 6180 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6181 %{
 6182   single_instruction;
 6183   dst    : S4(write);
 6184   src1   : S2(read);
 6185   src2   : S2(read);
 6186   INS0   : ISS;
 6187   NEON_FP : S4;
 6188 %}
 6189 
 6190 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6191 %{
 6192   single_instruction;
 6193   dst    : S3(write);
 6194   src1   : S2(read);
 6195   src2   : S2(read);
 6196   INS01  : ISS;
 6197   NEON_FP : S3;
 6198 %}
 6199 
 6200 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6201 %{
 6202   single_instruction;
 6203   dst    : S3(write);
 6204   src1   : S2(read);
 6205   src2   : S2(read);
 6206   INS0   : ISS;
 6207   NEON_FP : S3;
 6208 %}
 6209 
 6210 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6211 %{
 6212   single_instruction;
 6213   dst    : S3(write);
 6214   src    : S1(read);
 6215   shift  : S1(read);
 6216   INS01  : ISS;
 6217   NEON_FP : S3;
 6218 %}
 6219 
 6220 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6221 %{
 6222   single_instruction;
 6223   dst    : S3(write);
 6224   src    : S1(read);
 6225   shift  : S1(read);
 6226   INS0   : ISS;
 6227   NEON_FP : S3;
 6228 %}
 6229 
 6230 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6231 %{
 6232   single_instruction;
 6233   dst    : S3(write);
 6234   src    : S1(read);
 6235   INS01  : ISS;
 6236   NEON_FP : S3;
 6237 %}
 6238 
 6239 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6240 %{
 6241   single_instruction;
 6242   dst    : S3(write);
 6243   src    : S1(read);
 6244   INS0   : ISS;
 6245   NEON_FP : S3;
 6246 %}
 6247 
 6248 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6249 %{
 6250   single_instruction;
 6251   dst    : S5(write);
 6252   src1   : S1(read);
 6253   src2   : S1(read);
 6254   INS01  : ISS;
 6255   NEON_FP : S5;
 6256 %}
 6257 
 6258 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6259 %{
 6260   single_instruction;
 6261   dst    : S5(write);
 6262   src1   : S1(read);
 6263   src2   : S1(read);
 6264   INS0   : ISS;
 6265   NEON_FP : S5;
 6266 %}
 6267 
 6268 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6269 %{
 6270   single_instruction;
 6271   dst    : S5(write);
 6272   src1   : S1(read);
 6273   src2   : S1(read);
 6274   INS0   : ISS;
 6275   NEON_FP : S5;
 6276 %}
 6277 
 6278 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6279 %{
 6280   single_instruction;
 6281   dst    : S5(write);
 6282   src1   : S1(read);
 6283   src2   : S1(read);
 6284   INS0   : ISS;
 6285   NEON_FP : S5;
 6286 %}
 6287 
 6288 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6289 %{
 6290   single_instruction;
 6291   dst    : S5(write);
 6292   src    : S1(read);
 6293   INS0   : ISS;
 6294   NEON_FP : S5;
 6295 %}
 6296 
 6297 pipe_class vunop_fp64(vecD dst, vecD src)
 6298 %{
 6299   single_instruction;
 6300   dst    : S5(write);
 6301   src    : S1(read);
 6302   INS01  : ISS;
 6303   NEON_FP : S5;
 6304 %}
 6305 
 6306 pipe_class vunop_fp128(vecX dst, vecX src)
 6307 %{
 6308   single_instruction;
 6309   dst    : S5(write);
 6310   src    : S1(read);
 6311   INS0   : ISS;
 6312   NEON_FP : S5;
 6313 %}
 6314 
 6315 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6316 %{
 6317   single_instruction;
 6318   dst    : S3(write);
 6319   src    : S1(read);
 6320   INS01  : ISS;
 6321   NEON_FP : S3;
 6322 %}
 6323 
 6324 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6325 %{
 6326   single_instruction;
 6327   dst    : S3(write);
 6328   src    : S1(read);
 6329   INS01  : ISS;
 6330   NEON_FP : S3;
 6331 %}
 6332 
 6333 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6334 %{
 6335   single_instruction;
 6336   dst    : S3(write);
 6337   src    : S1(read);
 6338   INS01  : ISS;
 6339   NEON_FP : S3;
 6340 %}
 6341 
 6342 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6343 %{
 6344   single_instruction;
 6345   dst    : S3(write);
 6346   src    : S1(read);
 6347   INS01  : ISS;
 6348   NEON_FP : S3;
 6349 %}
 6350 
 6351 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6352 %{
 6353   single_instruction;
 6354   dst    : S3(write);
 6355   src    : S1(read);
 6356   INS01  : ISS;
 6357   NEON_FP : S3;
 6358 %}
 6359 
 6360 pipe_class vmovi_reg_imm64(vecD dst)
 6361 %{
 6362   single_instruction;
 6363   dst    : S3(write);
 6364   INS01  : ISS;
 6365   NEON_FP : S3;
 6366 %}
 6367 
 6368 pipe_class vmovi_reg_imm128(vecX dst)
 6369 %{
 6370   single_instruction;
 6371   dst    : S3(write);
 6372   INS0   : ISS;
 6373   NEON_FP : S3;
 6374 %}
 6375 
 6376 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6377 %{
 6378   single_instruction;
 6379   dst    : S5(write);
 6380   mem    : ISS(read);
 6381   INS01  : ISS;
 6382   NEON_FP : S3;
 6383 %}
 6384 
 6385 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6386 %{
 6387   single_instruction;
 6388   dst    : S5(write);
 6389   mem    : ISS(read);
 6390   INS01  : ISS;
 6391   NEON_FP : S3;
 6392 %}
 6393 
 6394 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6395 %{
 6396   single_instruction;
 6397   mem    : ISS(read);
 6398   src    : S2(read);
 6399   INS01  : ISS;
 6400   NEON_FP : S3;
 6401 %}
 6402 
 6403 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6404 %{
 6405   single_instruction;
 6406   mem    : ISS(read);
 6407   src    : S2(read);
 6408   INS01  : ISS;
 6409   NEON_FP : S3;
 6410 %}
 6411 
 6412 //------- Integer ALU operations --------------------------
 6413 
 6414 // Integer ALU reg-reg operation
 6415 // Operands needed in EX1, result generated in EX2
 6416 // Eg.  ADD     x0, x1, x2
 6417 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6418 %{
 6419   single_instruction;
 6420   dst    : EX2(write);
 6421   src1   : EX1(read);
 6422   src2   : EX1(read);
 6423   INS01  : ISS; // Dual issue as instruction 0 or 1
 6424   ALU    : EX2;
 6425 %}
 6426 
 6427 // Integer ALU reg-reg operation with constant shift
 6428 // Shifted register must be available in LATE_ISS instead of EX1
 6429 // Eg.  ADD     x0, x1, x2, LSL #2
 6430 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6431 %{
 6432   single_instruction;
 6433   dst    : EX2(write);
 6434   src1   : EX1(read);
 6435   src2   : ISS(read);
 6436   INS01  : ISS;
 6437   ALU    : EX2;
 6438 %}
 6439 
 6440 // Integer ALU reg operation with constant shift
 6441 // Eg.  LSL     x0, x1, #shift
 6442 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6443 %{
 6444   single_instruction;
 6445   dst    : EX2(write);
 6446   src1   : ISS(read);
 6447   INS01  : ISS;
 6448   ALU    : EX2;
 6449 %}
 6450 
 6451 // Integer ALU reg-reg operation with variable shift
 6452 // Both operands must be available in LATE_ISS instead of EX1
 6453 // Result is available in EX1 instead of EX2
 6454 // Eg.  LSLV    x0, x1, x2
 6455 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6456 %{
 6457   single_instruction;
 6458   dst    : EX1(write);
 6459   src1   : ISS(read);
 6460   src2   : ISS(read);
 6461   INS01  : ISS;
 6462   ALU    : EX1;
 6463 %}
 6464 
 6465 // Integer ALU reg-reg operation with extract
 6466 // As for _vshift above, but result generated in EX2
 6467 // Eg.  EXTR    x0, x1, x2, #N
 6468 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6469 %{
 6470   single_instruction;
 6471   dst    : EX2(write);
 6472   src1   : ISS(read);
 6473   src2   : ISS(read);
 6474   INS1   : ISS; // Can only dual issue as Instruction 1
 6475   ALU    : EX1;
 6476 %}
 6477 
 6478 // Integer ALU reg operation
 6479 // Eg.  NEG     x0, x1
 6480 pipe_class ialu_reg(iRegI dst, iRegI src)
 6481 %{
 6482   single_instruction;
 6483   dst    : EX2(write);
 6484   src    : EX1(read);
 6485   INS01  : ISS;
 6486   ALU    : EX2;
 6487 %}
 6488 
 6489 // Integer ALU reg mmediate operation
 6490 // Eg.  ADD     x0, x1, #N
 6491 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6492 %{
 6493   single_instruction;
 6494   dst    : EX2(write);
 6495   src1   : EX1(read);
 6496   INS01  : ISS;
 6497   ALU    : EX2;
 6498 %}
 6499 
 6500 // Integer ALU immediate operation (no source operands)
 6501 // Eg.  MOV     x0, #N
 6502 pipe_class ialu_imm(iRegI dst)
 6503 %{
 6504   single_instruction;
 6505   dst    : EX1(write);
 6506   INS01  : ISS;
 6507   ALU    : EX1;
 6508 %}
 6509 
 6510 //------- Compare operation -------------------------------
 6511 
 6512 // Compare reg-reg
 6513 // Eg.  CMP     x0, x1
 6514 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6515 %{
 6516   single_instruction;
 6517 //  fixed_latency(16);
 6518   cr     : EX2(write);
 6519   op1    : EX1(read);
 6520   op2    : EX1(read);
 6521   INS01  : ISS;
 6522   ALU    : EX2;
 6523 %}
 6524 
 6525 // Compare reg-reg
 6526 // Eg.  CMP     x0, #N
 6527 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6528 %{
 6529   single_instruction;
 6530 //  fixed_latency(16);
 6531   cr     : EX2(write);
 6532   op1    : EX1(read);
 6533   INS01  : ISS;
 6534   ALU    : EX2;
 6535 %}
 6536 
 6537 //------- Conditional instructions ------------------------
 6538 
 6539 // Conditional no operands
 6540 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6541 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6542 %{
 6543   single_instruction;
 6544   cr     : EX1(read);
 6545   dst    : EX2(write);
 6546   INS01  : ISS;
 6547   ALU    : EX2;
 6548 %}
 6549 
 6550 // Conditional 2 operand
 6551 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6552 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6553 %{
 6554   single_instruction;
 6555   cr     : EX1(read);
 6556   src1   : EX1(read);
 6557   src2   : EX1(read);
 6558   dst    : EX2(write);
 6559   INS01  : ISS;
 6560   ALU    : EX2;
 6561 %}
 6562 
 6563 // Conditional 2 operand
 6564 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6565 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6566 %{
 6567   single_instruction;
 6568   cr     : EX1(read);
 6569   src    : EX1(read);
 6570   dst    : EX2(write);
 6571   INS01  : ISS;
 6572   ALU    : EX2;
 6573 %}
 6574 
 6575 //------- Multiply pipeline operations --------------------
 6576 
 6577 // Multiply reg-reg
 6578 // Eg.  MUL     w0, w1, w2
 6579 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6580 %{
 6581   single_instruction;
 6582   dst    : WR(write);
 6583   src1   : ISS(read);
 6584   src2   : ISS(read);
 6585   INS01  : ISS;
 6586   MAC    : WR;
 6587 %}
 6588 
 6589 // Multiply accumulate
 6590 // Eg.  MADD    w0, w1, w2, w3
 6591 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6592 %{
 6593   single_instruction;
 6594   dst    : WR(write);
 6595   src1   : ISS(read);
 6596   src2   : ISS(read);
 6597   src3   : ISS(read);
 6598   INS01  : ISS;
 6599   MAC    : WR;
 6600 %}
 6601 
 6602 // Eg.  MUL     w0, w1, w2
 6603 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6604 %{
 6605   single_instruction;
 6606   fixed_latency(3); // Maximum latency for 64 bit mul
 6607   dst    : WR(write);
 6608   src1   : ISS(read);
 6609   src2   : ISS(read);
 6610   INS01  : ISS;
 6611   MAC    : WR;
 6612 %}
 6613 
 6614 // Multiply accumulate
 6615 // Eg.  MADD    w0, w1, w2, w3
 6616 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6617 %{
 6618   single_instruction;
 6619   fixed_latency(3); // Maximum latency for 64 bit mul
 6620   dst    : WR(write);
 6621   src1   : ISS(read);
 6622   src2   : ISS(read);
 6623   src3   : ISS(read);
 6624   INS01  : ISS;
 6625   MAC    : WR;
 6626 %}
 6627 
 6628 //------- Divide pipeline operations --------------------
 6629 
 6630 // Eg.  SDIV    w0, w1, w2
 6631 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6632 %{
 6633   single_instruction;
 6634   fixed_latency(8); // Maximum latency for 32 bit divide
 6635   dst    : WR(write);
 6636   src1   : ISS(read);
 6637   src2   : ISS(read);
 6638   INS0   : ISS; // Can only dual issue as instruction 0
 6639   DIV    : WR;
 6640 %}
 6641 
 6642 // Eg.  SDIV    x0, x1, x2
 6643 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6644 %{
 6645   single_instruction;
 6646   fixed_latency(16); // Maximum latency for 64 bit divide
 6647   dst    : WR(write);
 6648   src1   : ISS(read);
 6649   src2   : ISS(read);
 6650   INS0   : ISS; // Can only dual issue as instruction 0
 6651   DIV    : WR;
 6652 %}
 6653 
 6654 //------- Load pipeline operations ------------------------
 6655 
 6656 // Load - prefetch
 6657 // Eg.  PFRM    &lt;mem&gt;
 6658 pipe_class iload_prefetch(memory mem)
 6659 %{
 6660   single_instruction;
 6661   mem    : ISS(read);
 6662   INS01  : ISS;
 6663   LDST   : WR;
 6664 %}
 6665 
 6666 // Load - reg, mem
 6667 // Eg.  LDR     x0, &lt;mem&gt;
 6668 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6669 %{
 6670   single_instruction;
 6671   dst    : WR(write);
 6672   mem    : ISS(read);
 6673   INS01  : ISS;
 6674   LDST   : WR;
 6675 %}
 6676 
 6677 // Load - reg, reg
 6678 // Eg.  LDR     x0, [sp, x1]
 6679 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6680 %{
 6681   single_instruction;
 6682   dst    : WR(write);
 6683   src    : ISS(read);
 6684   INS01  : ISS;
 6685   LDST   : WR;
 6686 %}
 6687 
 6688 //------- Store pipeline operations -----------------------
 6689 
 6690 // Store - zr, mem
 6691 // Eg.  STR     zr, &lt;mem&gt;
 6692 pipe_class istore_mem(memory mem)
 6693 %{
 6694   single_instruction;
 6695   mem    : ISS(read);
 6696   INS01  : ISS;
 6697   LDST   : WR;
 6698 %}
 6699 
 6700 // Store - reg, mem
 6701 // Eg.  STR     x0, &lt;mem&gt;
 6702 pipe_class istore_reg_mem(iRegI src, memory mem)
 6703 %{
 6704   single_instruction;
 6705   mem    : ISS(read);
 6706   src    : EX2(read);
 6707   INS01  : ISS;
 6708   LDST   : WR;
 6709 %}
 6710 
 6711 // Store - reg, reg
 6712 // Eg. STR      x0, [sp, x1]
 6713 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6714 %{
 6715   single_instruction;
 6716   dst    : ISS(read);
 6717   src    : EX2(read);
 6718   INS01  : ISS;
 6719   LDST   : WR;
 6720 %}
 6721 
 6722 //------- Store pipeline operations -----------------------
 6723 
 6724 // Branch
 6725 pipe_class pipe_branch()
 6726 %{
 6727   single_instruction;
 6728   INS01  : ISS;
 6729   BRANCH : EX1;
 6730 %}
 6731 
 6732 // Conditional branch
 6733 pipe_class pipe_branch_cond(rFlagsReg cr)
 6734 %{
 6735   single_instruction;
 6736   cr     : EX1(read);
 6737   INS01  : ISS;
 6738   BRANCH : EX1;
 6739 %}
 6740 
 6741 // Compare &amp; Branch
 6742 // EG.  CBZ/CBNZ
 6743 pipe_class pipe_cmp_branch(iRegI op1)
 6744 %{
 6745   single_instruction;
 6746   op1    : EX1(read);
 6747   INS01  : ISS;
 6748   BRANCH : EX1;
 6749 %}
 6750 
 6751 //------- Synchronisation operations ----------------------
 6752 
 6753 // Any operation requiring serialization.
 6754 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6755 pipe_class pipe_serial()
 6756 %{
 6757   single_instruction;
 6758   force_serialization;
 6759   fixed_latency(16);
 6760   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6761   LDST   : WR;
 6762 %}
 6763 
 6764 // Generic big/slow expanded idiom - also serialized
 6765 pipe_class pipe_slow()
 6766 %{
 6767   instruction_count(10);
 6768   multiple_bundles;
 6769   force_serialization;
 6770   fixed_latency(16);
 6771   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6772   LDST   : WR;
 6773 %}
 6774 
 6775 // Empty pipeline class
 6776 pipe_class pipe_class_empty()
 6777 %{
 6778   single_instruction;
 6779   fixed_latency(0);
 6780 %}
 6781 
 6782 // Default pipeline class.
 6783 pipe_class pipe_class_default()
 6784 %{
 6785   single_instruction;
 6786   fixed_latency(2);
 6787 %}
 6788 
 6789 // Pipeline class for compares.
 6790 pipe_class pipe_class_compare()
 6791 %{
 6792   single_instruction;
 6793   fixed_latency(16);
 6794 %}
 6795 
 6796 // Pipeline class for memory operations.
 6797 pipe_class pipe_class_memory()
 6798 %{
 6799   single_instruction;
 6800   fixed_latency(16);
 6801 %}
 6802 
 6803 // Pipeline class for call.
 6804 pipe_class pipe_class_call()
 6805 %{
 6806   single_instruction;
 6807   fixed_latency(100);
 6808 %}
 6809 
 6810 // Define the class for the Nop node.
 6811 define %{
 6812    MachNop = pipe_class_empty;
 6813 %}
 6814 
 6815 %}
 6816 //----------INSTRUCTIONS-------------------------------------------------------
 6817 //
 6818 // match      -- States which machine-independent subtree may be replaced
 6819 //               by this instruction.
 6820 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6821 //               selection to identify a minimum cost tree of machine
 6822 //               instructions that matches a tree of machine-independent
 6823 //               instructions.
 6824 // format     -- A string providing the disassembly for this instruction.
 6825 //               The value of an instruction&#39;s operand may be inserted
 6826 //               by referring to it with a &#39;$&#39; prefix.
 6827 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6828 //               to within an encode class as $primary, $secondary, and $tertiary
 6829 //               rrspectively.  The primary opcode is commonly used to
 6830 //               indicate the type of machine instruction, while secondary
 6831 //               and tertiary are often used for prefix options or addressing
 6832 //               modes.
 6833 // ins_encode -- A list of encode classes with parameters. The encode class
 6834 //               name must have been defined in an &#39;enc_class&#39; specification
 6835 //               in the encode section of the architecture description.
 6836 
 6837 // ============================================================================
 6838 // Memory (Load/Store) Instructions
 6839 
 6840 // Load Instructions
 6841 
 6842 // Load Byte (8 bit signed)
 6843 instruct loadB(iRegINoSp dst, memory1 mem)
 6844 %{
 6845   match(Set dst (LoadB mem));
 6846   predicate(!needs_acquiring_load(n));
 6847 
 6848   ins_cost(4 * INSN_COST);
 6849   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6850 
 6851   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6852 
 6853   ins_pipe(iload_reg_mem);
 6854 %}
 6855 
 6856 // Load Byte (8 bit signed) into long
 6857 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6858 %{
 6859   match(Set dst (ConvI2L (LoadB mem)));
 6860   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6861 
 6862   ins_cost(4 * INSN_COST);
 6863   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6864 
 6865   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6866 
 6867   ins_pipe(iload_reg_mem);
 6868 %}
 6869 
 6870 // Load Byte (8 bit unsigned)
 6871 instruct loadUB(iRegINoSp dst, memory1 mem)
 6872 %{
 6873   match(Set dst (LoadUB mem));
 6874   predicate(!needs_acquiring_load(n));
 6875 
 6876   ins_cost(4 * INSN_COST);
 6877   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6878 
 6879   ins_encode(aarch64_enc_ldrb(dst, mem));
 6880 
 6881   ins_pipe(iload_reg_mem);
 6882 %}
 6883 
 6884 // Load Byte (8 bit unsigned) into long
 6885 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6886 %{
 6887   match(Set dst (ConvI2L (LoadUB mem)));
 6888   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6889 
 6890   ins_cost(4 * INSN_COST);
 6891   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6892 
 6893   ins_encode(aarch64_enc_ldrb(dst, mem));
 6894 
 6895   ins_pipe(iload_reg_mem);
 6896 %}
 6897 
 6898 // Load Short (16 bit signed)
 6899 instruct loadS(iRegINoSp dst, memory2 mem)
 6900 %{
 6901   match(Set dst (LoadS mem));
 6902   predicate(!needs_acquiring_load(n));
 6903 
 6904   ins_cost(4 * INSN_COST);
 6905   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6906 
 6907   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6908 
 6909   ins_pipe(iload_reg_mem);
 6910 %}
 6911 
 6912 // Load Short (16 bit signed) into long
 6913 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6914 %{
 6915   match(Set dst (ConvI2L (LoadS mem)));
 6916   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6917 
 6918   ins_cost(4 * INSN_COST);
 6919   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6920 
 6921   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6922 
 6923   ins_pipe(iload_reg_mem);
 6924 %}
 6925 
 6926 // Load Char (16 bit unsigned)
 6927 instruct loadUS(iRegINoSp dst, memory2 mem)
 6928 %{
 6929   match(Set dst (LoadUS mem));
 6930   predicate(!needs_acquiring_load(n));
 6931 
 6932   ins_cost(4 * INSN_COST);
 6933   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6934 
 6935   ins_encode(aarch64_enc_ldrh(dst, mem));
 6936 
 6937   ins_pipe(iload_reg_mem);
 6938 %}
 6939 
 6940 // Load Short/Char (16 bit unsigned) into long
 6941 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6942 %{
 6943   match(Set dst (ConvI2L (LoadUS mem)));
 6944   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6945 
 6946   ins_cost(4 * INSN_COST);
 6947   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6948 
 6949   ins_encode(aarch64_enc_ldrh(dst, mem));
 6950 
 6951   ins_pipe(iload_reg_mem);
 6952 %}
 6953 
 6954 // Load Integer (32 bit signed)
 6955 instruct loadI(iRegINoSp dst, memory4 mem)
 6956 %{
 6957   match(Set dst (LoadI mem));
 6958   predicate(!needs_acquiring_load(n));
 6959 
 6960   ins_cost(4 * INSN_COST);
 6961   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6962 
 6963   ins_encode(aarch64_enc_ldrw(dst, mem));
 6964 
 6965   ins_pipe(iload_reg_mem);
 6966 %}
 6967 
 6968 // Load Integer (32 bit signed) into long
 6969 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6970 %{
 6971   match(Set dst (ConvI2L (LoadI mem)));
 6972   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6973 
 6974   ins_cost(4 * INSN_COST);
 6975   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6976 
 6977   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6978 
 6979   ins_pipe(iload_reg_mem);
 6980 %}
 6981 
 6982 // Load Integer (32 bit unsigned) into long
 6983 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6984 %{
 6985   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6986   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6987 
 6988   ins_cost(4 * INSN_COST);
 6989   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6990 
 6991   ins_encode(aarch64_enc_ldrw(dst, mem));
 6992 
 6993   ins_pipe(iload_reg_mem);
 6994 %}
 6995 
 6996 // Load Long (64 bit signed)
 6997 instruct loadL(iRegLNoSp dst, memory8 mem)
 6998 %{
 6999   match(Set dst (LoadL mem));
 7000   predicate(!needs_acquiring_load(n));
 7001 
 7002   ins_cost(4 * INSN_COST);
 7003   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7004 
 7005   ins_encode(aarch64_enc_ldr(dst, mem));
 7006 
 7007   ins_pipe(iload_reg_mem);
 7008 %}
 7009 
 7010 // Load Range
 7011 instruct loadRange(iRegINoSp dst, memory4 mem)
 7012 %{
 7013   match(Set dst (LoadRange mem));
 7014 
 7015   ins_cost(4 * INSN_COST);
 7016   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7017 
 7018   ins_encode(aarch64_enc_ldrw(dst, mem));
 7019 
 7020   ins_pipe(iload_reg_mem);
 7021 %}
 7022 
 7023 // Load Pointer
 7024 instruct loadP(iRegPNoSp dst, memory8 mem)
 7025 %{
 7026   match(Set dst (LoadP mem));
 7027   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7028 
 7029   ins_cost(4 * INSN_COST);
 7030   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7031 
 7032   ins_encode(aarch64_enc_ldr(dst, mem));
 7033 
 7034   ins_pipe(iload_reg_mem);
 7035 %}
 7036 
 7037 // Load Compressed Pointer
 7038 instruct loadN(iRegNNoSp dst, memory4 mem)
 7039 %{
 7040   match(Set dst (LoadN mem));
 7041   predicate(!needs_acquiring_load(n));
 7042 
 7043   ins_cost(4 * INSN_COST);
 7044   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7045 
 7046   ins_encode(aarch64_enc_ldrw(dst, mem));
 7047 
 7048   ins_pipe(iload_reg_mem);
 7049 %}
 7050 
 7051 // Load Klass Pointer
 7052 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7053 %{
 7054   match(Set dst (LoadKlass mem));
 7055   predicate(!needs_acquiring_load(n));
 7056 
 7057   ins_cost(4 * INSN_COST);
 7058   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7059 
 7060   ins_encode(aarch64_enc_ldr(dst, mem));
 7061 
 7062   ins_pipe(iload_reg_mem);
 7063 %}
 7064 
 7065 // Load Narrow Klass Pointer
 7066 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7067 %{
 7068   match(Set dst (LoadNKlass mem));
 7069   predicate(!needs_acquiring_load(n));
 7070 
 7071   ins_cost(4 * INSN_COST);
 7072   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7073 
 7074   ins_encode(aarch64_enc_ldrw(dst, mem));
 7075 
 7076   ins_pipe(iload_reg_mem);
 7077 %}
 7078 
 7079 // Load Float
 7080 instruct loadF(vRegF dst, memory4 mem)
 7081 %{
 7082   match(Set dst (LoadF mem));
 7083   predicate(!needs_acquiring_load(n));
 7084 
 7085   ins_cost(4 * INSN_COST);
 7086   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7087 
 7088   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7089 
 7090   ins_pipe(pipe_class_memory);
 7091 %}
 7092 
 7093 // Load Double
 7094 instruct loadD(vRegD dst, memory8 mem)
 7095 %{
 7096   match(Set dst (LoadD mem));
 7097   predicate(!needs_acquiring_load(n));
 7098 
 7099   ins_cost(4 * INSN_COST);
 7100   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7101 
 7102   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7103 
 7104   ins_pipe(pipe_class_memory);
 7105 %}
 7106 
 7107 
 7108 // Load Int Constant
 7109 instruct loadConI(iRegINoSp dst, immI src)
 7110 %{
 7111   match(Set dst src);
 7112 
 7113   ins_cost(INSN_COST);
 7114   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7115 
 7116   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7117 
 7118   ins_pipe(ialu_imm);
 7119 %}
 7120 
 7121 // Load Long Constant
 7122 instruct loadConL(iRegLNoSp dst, immL src)
 7123 %{
 7124   match(Set dst src);
 7125 
 7126   ins_cost(INSN_COST);
 7127   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7128 
 7129   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7130 
 7131   ins_pipe(ialu_imm);
 7132 %}
 7133 
 7134 // Load Pointer Constant
 7135 
 7136 instruct loadConP(iRegPNoSp dst, immP con)
 7137 %{
 7138   match(Set dst con);
 7139 
 7140   ins_cost(INSN_COST * 4);
 7141   format %{
 7142     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7143   %}
 7144 
 7145   ins_encode(aarch64_enc_mov_p(dst, con));
 7146 
 7147   ins_pipe(ialu_imm);
 7148 %}
 7149 
 7150 // Load Null Pointer Constant
 7151 
 7152 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7153 %{
 7154   match(Set dst con);
 7155 
 7156   ins_cost(INSN_COST);
 7157   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7158 
 7159   ins_encode(aarch64_enc_mov_p0(dst, con));
 7160 
 7161   ins_pipe(ialu_imm);
 7162 %}
 7163 
 7164 // Load Pointer Constant One
 7165 
 7166 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7167 %{
 7168   match(Set dst con);
 7169 
 7170   ins_cost(INSN_COST);
 7171   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7172 
 7173   ins_encode(aarch64_enc_mov_p1(dst, con));
 7174 
 7175   ins_pipe(ialu_imm);
 7176 %}
 7177 
 7178 // Load Byte Map Base Constant
 7179 
 7180 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7181 %{
 7182   match(Set dst con);
 7183 
 7184   ins_cost(INSN_COST);
 7185   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7186 
 7187   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7188 
 7189   ins_pipe(ialu_imm);
 7190 %}
 7191 
 7192 // Load Narrow Pointer Constant
 7193 
 7194 instruct loadConN(iRegNNoSp dst, immN con)
 7195 %{
 7196   match(Set dst con);
 7197 
 7198   ins_cost(INSN_COST * 4);
 7199   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7200 
 7201   ins_encode(aarch64_enc_mov_n(dst, con));
 7202 
 7203   ins_pipe(ialu_imm);
 7204 %}
 7205 
 7206 // Load Narrow Null Pointer Constant
 7207 
 7208 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7209 %{
 7210   match(Set dst con);
 7211 
 7212   ins_cost(INSN_COST);
 7213   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7214 
 7215   ins_encode(aarch64_enc_mov_n0(dst, con));
 7216 
 7217   ins_pipe(ialu_imm);
 7218 %}
 7219 
 7220 // Load Narrow Klass Constant
 7221 
 7222 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7223 %{
 7224   match(Set dst con);
 7225 
 7226   ins_cost(INSN_COST);
 7227   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7228 
 7229   ins_encode(aarch64_enc_mov_nk(dst, con));
 7230 
 7231   ins_pipe(ialu_imm);
 7232 %}
 7233 
 7234 // Load Packed Float Constant
 7235 
 7236 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7237   match(Set dst con);
 7238   ins_cost(INSN_COST * 4);
 7239   format %{ &quot;fmovs  $dst, $con&quot;%}
 7240   ins_encode %{
 7241     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7242   %}
 7243 
 7244   ins_pipe(fp_imm_s);
 7245 %}
 7246 
 7247 // Load Float Constant
 7248 
 7249 instruct loadConF(vRegF dst, immF con) %{
 7250   match(Set dst con);
 7251 
 7252   ins_cost(INSN_COST * 4);
 7253 
 7254   format %{
 7255     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7256   %}
 7257 
 7258   ins_encode %{
 7259     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7260   %}
 7261 
 7262   ins_pipe(fp_load_constant_s);
 7263 %}
 7264 
 7265 // Load Packed Double Constant
 7266 
 7267 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7268   match(Set dst con);
 7269   ins_cost(INSN_COST);
 7270   format %{ &quot;fmovd  $dst, $con&quot;%}
 7271   ins_encode %{
 7272     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7273   %}
 7274 
 7275   ins_pipe(fp_imm_d);
 7276 %}
 7277 
 7278 // Load Double Constant
 7279 
 7280 instruct loadConD(vRegD dst, immD con) %{
 7281   match(Set dst con);
 7282 
 7283   ins_cost(INSN_COST * 5);
 7284   format %{
 7285     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7286   %}
 7287 
 7288   ins_encode %{
 7289     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7290   %}
 7291 
 7292   ins_pipe(fp_load_constant_d);
 7293 %}
 7294 
 7295 // Store Instructions
 7296 
 7297 // Store CMS card-mark Immediate
 7298 instruct storeimmCM0(immI0 zero, memory1 mem)
 7299 %{
 7300   match(Set mem (StoreCM mem zero));
 7301 
 7302   ins_cost(INSN_COST);
 7303   format %{ &quot;storestore (elided)\n\t&quot;
 7304             &quot;strb zr, $mem\t# byte&quot; %}
 7305 
 7306   ins_encode(aarch64_enc_strb0(mem));
 7307 
 7308   ins_pipe(istore_mem);
 7309 %}
 7310 
 7311 // Store CMS card-mark Immediate with intervening StoreStore
 7312 // needed when using CMS with no conditional card marking
 7313 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7314 %{
 7315   match(Set mem (StoreCM mem zero));
 7316 
 7317   ins_cost(INSN_COST * 2);
 7318   format %{ &quot;storestore\n\t&quot;
 7319             &quot;dmb ishst&quot;
 7320             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7321 
 7322   ins_encode(aarch64_enc_strb0_ordered(mem));
 7323 
 7324   ins_pipe(istore_mem);
 7325 %}
 7326 
 7327 // Store Byte
 7328 instruct storeB(iRegIorL2I src, memory1 mem)
 7329 %{
 7330   match(Set mem (StoreB mem src));
 7331   predicate(!needs_releasing_store(n));
 7332 
 7333   ins_cost(INSN_COST);
 7334   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7335 
 7336   ins_encode(aarch64_enc_strb(src, mem));
 7337 
 7338   ins_pipe(istore_reg_mem);
 7339 %}
 7340 
 7341 
 7342 instruct storeimmB0(immI0 zero, memory1 mem)
 7343 %{
 7344   match(Set mem (StoreB mem zero));
 7345   predicate(!needs_releasing_store(n));
 7346 
 7347   ins_cost(INSN_COST);
 7348   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7349 
 7350   ins_encode(aarch64_enc_strb0(mem));
 7351 
 7352   ins_pipe(istore_mem);
 7353 %}
 7354 
 7355 // Store Char/Short
 7356 instruct storeC(iRegIorL2I src, memory2 mem)
 7357 %{
 7358   match(Set mem (StoreC mem src));
 7359   predicate(!needs_releasing_store(n));
 7360 
 7361   ins_cost(INSN_COST);
 7362   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7363 
 7364   ins_encode(aarch64_enc_strh(src, mem));
 7365 
 7366   ins_pipe(istore_reg_mem);
 7367 %}
 7368 
 7369 instruct storeimmC0(immI0 zero, memory2 mem)
 7370 %{
 7371   match(Set mem (StoreC mem zero));
 7372   predicate(!needs_releasing_store(n));
 7373 
 7374   ins_cost(INSN_COST);
 7375   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7376 
 7377   ins_encode(aarch64_enc_strh0(mem));
 7378 
 7379   ins_pipe(istore_mem);
 7380 %}
 7381 
 7382 // Store Integer
 7383 
 7384 instruct storeI(iRegIorL2I src, memory4 mem)
 7385 %{
 7386   match(Set mem(StoreI mem src));
 7387   predicate(!needs_releasing_store(n));
 7388 
 7389   ins_cost(INSN_COST);
 7390   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7391 
 7392   ins_encode(aarch64_enc_strw(src, mem));
 7393 
 7394   ins_pipe(istore_reg_mem);
 7395 %}
 7396 
 7397 instruct storeimmI0(immI0 zero, memory4 mem)
 7398 %{
 7399   match(Set mem(StoreI mem zero));
 7400   predicate(!needs_releasing_store(n));
 7401 
 7402   ins_cost(INSN_COST);
 7403   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7404 
 7405   ins_encode(aarch64_enc_strw0(mem));
 7406 
 7407   ins_pipe(istore_mem);
 7408 %}
 7409 
 7410 // Store Long (64 bit signed)
 7411 instruct storeL(iRegL src, memory8 mem)
 7412 %{
 7413   match(Set mem (StoreL mem src));
 7414   predicate(!needs_releasing_store(n));
 7415 
 7416   ins_cost(INSN_COST);
 7417   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7418 
 7419   ins_encode(aarch64_enc_str(src, mem));
 7420 
 7421   ins_pipe(istore_reg_mem);
 7422 %}
 7423 
 7424 // Store Long (64 bit signed)
 7425 instruct storeimmL0(immL0 zero, memory8 mem)
 7426 %{
 7427   match(Set mem (StoreL mem zero));
 7428   predicate(!needs_releasing_store(n));
 7429 
 7430   ins_cost(INSN_COST);
 7431   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7432 
 7433   ins_encode(aarch64_enc_str0(mem));
 7434 
 7435   ins_pipe(istore_mem);
 7436 %}
 7437 
 7438 // Store Pointer
 7439 instruct storeP(iRegP src, memory8 mem)
 7440 %{
 7441   match(Set mem (StoreP mem src));
 7442   predicate(!needs_releasing_store(n));
 7443 
 7444   ins_cost(INSN_COST);
 7445   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7446 
 7447   ins_encode(aarch64_enc_str(src, mem));
 7448 
 7449   ins_pipe(istore_reg_mem);
 7450 %}
 7451 
 7452 // Store Pointer
 7453 instruct storeimmP0(immP0 zero, memory8 mem)
 7454 %{
 7455   match(Set mem (StoreP mem zero));
 7456   predicate(!needs_releasing_store(n));
 7457 
 7458   ins_cost(INSN_COST);
 7459   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7460 
 7461   ins_encode(aarch64_enc_str0(mem));
 7462 
 7463   ins_pipe(istore_mem);
 7464 %}
 7465 
 7466 // Store Compressed Pointer
 7467 instruct storeN(iRegN src, memory4 mem)
 7468 %{
 7469   match(Set mem (StoreN mem src));
 7470   predicate(!needs_releasing_store(n));
 7471 
 7472   ins_cost(INSN_COST);
 7473   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7474 
 7475   ins_encode(aarch64_enc_strw(src, mem));
 7476 
 7477   ins_pipe(istore_reg_mem);
 7478 %}
 7479 
 7480 instruct storeImmN0(immN0 zero, memory4 mem)
 7481 %{
 7482   match(Set mem (StoreN mem zero));
 7483   predicate(!needs_releasing_store(n));
 7484 
 7485   ins_cost(INSN_COST);
 7486   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7487 
 7488   ins_encode(aarch64_enc_strw0(mem));
 7489 
 7490   ins_pipe(istore_mem);
 7491 %}
 7492 
 7493 // Store Float
 7494 instruct storeF(vRegF src, memory4 mem)
 7495 %{
 7496   match(Set mem (StoreF mem src));
 7497   predicate(!needs_releasing_store(n));
 7498 
 7499   ins_cost(INSN_COST);
 7500   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7501 
 7502   ins_encode( aarch64_enc_strs(src, mem) );
 7503 
 7504   ins_pipe(pipe_class_memory);
 7505 %}
 7506 
 7507 // TODO
 7508 // implement storeImmF0 and storeFImmPacked
 7509 
 7510 // Store Double
 7511 instruct storeD(vRegD src, memory8 mem)
 7512 %{
 7513   match(Set mem (StoreD mem src));
 7514   predicate(!needs_releasing_store(n));
 7515 
 7516   ins_cost(INSN_COST);
 7517   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7518 
 7519   ins_encode( aarch64_enc_strd(src, mem) );
 7520 
 7521   ins_pipe(pipe_class_memory);
 7522 %}
 7523 
 7524 // Store Compressed Klass Pointer
 7525 instruct storeNKlass(iRegN src, memory4 mem)
 7526 %{
 7527   predicate(!needs_releasing_store(n));
 7528   match(Set mem (StoreNKlass mem src));
 7529 
 7530   ins_cost(INSN_COST);
 7531   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7532 
 7533   ins_encode(aarch64_enc_strw(src, mem));
 7534 
 7535   ins_pipe(istore_reg_mem);
 7536 %}
 7537 
 7538 // TODO
 7539 // implement storeImmD0 and storeDImmPacked
 7540 
 7541 // prefetch instructions
 7542 // Must be safe to execute with invalid address (cannot fault).
 7543 
 7544 instruct prefetchalloc( memory8 mem ) %{
 7545   match(PrefetchAllocation mem);
 7546 
 7547   ins_cost(INSN_COST);
 7548   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7549 
 7550   ins_encode( aarch64_enc_prefetchw(mem) );
 7551 
 7552   ins_pipe(iload_prefetch);
 7553 %}
 7554 
 7555 //  ---------------- volatile loads and stores ----------------
 7556 
 7557 // Load Byte (8 bit signed)
 7558 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7559 %{
 7560   match(Set dst (LoadB mem));
 7561 
 7562   ins_cost(VOLATILE_REF_COST);
 7563   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7564 
 7565   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7566 
 7567   ins_pipe(pipe_serial);
 7568 %}
 7569 
 7570 // Load Byte (8 bit signed) into long
 7571 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7572 %{
 7573   match(Set dst (ConvI2L (LoadB mem)));
 7574 
 7575   ins_cost(VOLATILE_REF_COST);
 7576   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7577 
 7578   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7579 
 7580   ins_pipe(pipe_serial);
 7581 %}
 7582 
 7583 // Load Byte (8 bit unsigned)
 7584 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7585 %{
 7586   match(Set dst (LoadUB mem));
 7587 
 7588   ins_cost(VOLATILE_REF_COST);
 7589   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7590 
 7591   ins_encode(aarch64_enc_ldarb(dst, mem));
 7592 
 7593   ins_pipe(pipe_serial);
 7594 %}
 7595 
 7596 // Load Byte (8 bit unsigned) into long
 7597 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7598 %{
 7599   match(Set dst (ConvI2L (LoadUB mem)));
 7600 
 7601   ins_cost(VOLATILE_REF_COST);
 7602   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7603 
 7604   ins_encode(aarch64_enc_ldarb(dst, mem));
 7605 
 7606   ins_pipe(pipe_serial);
 7607 %}
 7608 
 7609 // Load Short (16 bit signed)
 7610 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7611 %{
 7612   match(Set dst (LoadS mem));
 7613 
 7614   ins_cost(VOLATILE_REF_COST);
 7615   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7616 
 7617   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7618 
 7619   ins_pipe(pipe_serial);
 7620 %}
 7621 
 7622 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7623 %{
 7624   match(Set dst (LoadUS mem));
 7625 
 7626   ins_cost(VOLATILE_REF_COST);
 7627   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7628 
 7629   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7630 
 7631   ins_pipe(pipe_serial);
 7632 %}
 7633 
 7634 // Load Short/Char (16 bit unsigned) into long
 7635 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7636 %{
 7637   match(Set dst (ConvI2L (LoadUS mem)));
 7638 
 7639   ins_cost(VOLATILE_REF_COST);
 7640   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7641 
 7642   ins_encode(aarch64_enc_ldarh(dst, mem));
 7643 
 7644   ins_pipe(pipe_serial);
 7645 %}
 7646 
 7647 // Load Short/Char (16 bit signed) into long
 7648 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7649 %{
 7650   match(Set dst (ConvI2L (LoadS mem)));
 7651 
 7652   ins_cost(VOLATILE_REF_COST);
 7653   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7654 
 7655   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7656 
 7657   ins_pipe(pipe_serial);
 7658 %}
 7659 
 7660 // Load Integer (32 bit signed)
 7661 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7662 %{
 7663   match(Set dst (LoadI mem));
 7664 
 7665   ins_cost(VOLATILE_REF_COST);
 7666   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7667 
 7668   ins_encode(aarch64_enc_ldarw(dst, mem));
 7669 
 7670   ins_pipe(pipe_serial);
 7671 %}
 7672 
 7673 // Load Integer (32 bit unsigned) into long
 7674 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7675 %{
 7676   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7677 
 7678   ins_cost(VOLATILE_REF_COST);
 7679   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7680 
 7681   ins_encode(aarch64_enc_ldarw(dst, mem));
 7682 
 7683   ins_pipe(pipe_serial);
 7684 %}
 7685 
 7686 // Load Long (64 bit signed)
 7687 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7688 %{
 7689   match(Set dst (LoadL mem));
 7690 
 7691   ins_cost(VOLATILE_REF_COST);
 7692   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7693 
 7694   ins_encode(aarch64_enc_ldar(dst, mem));
 7695 
 7696   ins_pipe(pipe_serial);
 7697 %}
 7698 
 7699 // Load Pointer
 7700 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7701 %{
 7702   match(Set dst (LoadP mem));
 7703   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7704 
 7705   ins_cost(VOLATILE_REF_COST);
 7706   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7707 
 7708   ins_encode(aarch64_enc_ldar(dst, mem));
 7709 
 7710   ins_pipe(pipe_serial);
 7711 %}
 7712 
 7713 // Load Compressed Pointer
 7714 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7715 %{
 7716   match(Set dst (LoadN mem));
 7717 
 7718   ins_cost(VOLATILE_REF_COST);
 7719   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7720 
 7721   ins_encode(aarch64_enc_ldarw(dst, mem));
 7722 
 7723   ins_pipe(pipe_serial);
 7724 %}
 7725 
 7726 // Load Float
 7727 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7728 %{
 7729   match(Set dst (LoadF mem));
 7730 
 7731   ins_cost(VOLATILE_REF_COST);
 7732   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7733 
 7734   ins_encode( aarch64_enc_fldars(dst, mem) );
 7735 
 7736   ins_pipe(pipe_serial);
 7737 %}
 7738 
 7739 // Load Double
 7740 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7741 %{
 7742   match(Set dst (LoadD mem));
 7743 
 7744   ins_cost(VOLATILE_REF_COST);
 7745   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7746 
 7747   ins_encode( aarch64_enc_fldard(dst, mem) );
 7748 
 7749   ins_pipe(pipe_serial);
 7750 %}
 7751 
 7752 // Store Byte
 7753 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7754 %{
 7755   match(Set mem (StoreB mem src));
 7756 
 7757   ins_cost(VOLATILE_REF_COST);
 7758   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7759 
 7760   ins_encode(aarch64_enc_stlrb(src, mem));
 7761 
 7762   ins_pipe(pipe_class_memory);
 7763 %}
 7764 
 7765 // Store Char/Short
 7766 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7767 %{
 7768   match(Set mem (StoreC mem src));
 7769 
 7770   ins_cost(VOLATILE_REF_COST);
 7771   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7772 
 7773   ins_encode(aarch64_enc_stlrh(src, mem));
 7774 
 7775   ins_pipe(pipe_class_memory);
 7776 %}
 7777 
 7778 // Store Integer
 7779 
 7780 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7781 %{
 7782   match(Set mem(StoreI mem src));
 7783 
 7784   ins_cost(VOLATILE_REF_COST);
 7785   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7786 
 7787   ins_encode(aarch64_enc_stlrw(src, mem));
 7788 
 7789   ins_pipe(pipe_class_memory);
 7790 %}
 7791 
 7792 // Store Long (64 bit signed)
 7793 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7794 %{
 7795   match(Set mem (StoreL mem src));
 7796 
 7797   ins_cost(VOLATILE_REF_COST);
 7798   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7799 
 7800   ins_encode(aarch64_enc_stlr(src, mem));
 7801 
 7802   ins_pipe(pipe_class_memory);
 7803 %}
 7804 
 7805 // Store Pointer
 7806 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7807 %{
 7808   match(Set mem (StoreP mem src));
 7809 
 7810   ins_cost(VOLATILE_REF_COST);
 7811   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7812 
 7813   ins_encode(aarch64_enc_stlr(src, mem));
 7814 
 7815   ins_pipe(pipe_class_memory);
 7816 %}
 7817 
 7818 // Store Compressed Pointer
 7819 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7820 %{
 7821   match(Set mem (StoreN mem src));
 7822 
 7823   ins_cost(VOLATILE_REF_COST);
 7824   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7825 
 7826   ins_encode(aarch64_enc_stlrw(src, mem));
 7827 
 7828   ins_pipe(pipe_class_memory);
 7829 %}
 7830 
 7831 // Store Float
 7832 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7833 %{
 7834   match(Set mem (StoreF mem src));
 7835 
 7836   ins_cost(VOLATILE_REF_COST);
 7837   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7838 
 7839   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7840 
 7841   ins_pipe(pipe_class_memory);
 7842 %}
 7843 
 7844 // TODO
 7845 // implement storeImmF0 and storeFImmPacked
 7846 
 7847 // Store Double
 7848 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7849 %{
 7850   match(Set mem (StoreD mem src));
 7851 
 7852   ins_cost(VOLATILE_REF_COST);
 7853   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7854 
 7855   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7856 
 7857   ins_pipe(pipe_class_memory);
 7858 %}
 7859 
 7860 //  ---------------- end of volatile loads and stores ----------------
 7861 
 7862 instruct cacheWB(indirect addr)
 7863 %{
 7864   predicate(VM_Version::supports_data_cache_line_flush());
 7865   match(CacheWB addr);
 7866 
 7867   ins_cost(100);
 7868   format %{&quot;cache wb $addr&quot; %}
 7869   ins_encode %{
 7870     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7871     assert($addr$$disp == 0, &quot;should be&quot;);
 7872     __ cache_wb(Address($addr$$base$$Register, 0));
 7873   %}
 7874   ins_pipe(pipe_slow); // XXX
 7875 %}
 7876 
 7877 instruct cacheWBPreSync()
 7878 %{
 7879   predicate(VM_Version::supports_data_cache_line_flush());
 7880   match(CacheWBPreSync);
 7881 
 7882   ins_cost(100);
 7883   format %{&quot;cache wb presync&quot; %}
 7884   ins_encode %{
 7885     __ cache_wbsync(true);
 7886   %}
 7887   ins_pipe(pipe_slow); // XXX
 7888 %}
 7889 
 7890 instruct cacheWBPostSync()
 7891 %{
 7892   predicate(VM_Version::supports_data_cache_line_flush());
 7893   match(CacheWBPostSync);
 7894 
 7895   ins_cost(100);
 7896   format %{&quot;cache wb postsync&quot; %}
 7897   ins_encode %{
 7898     __ cache_wbsync(false);
 7899   %}
 7900   ins_pipe(pipe_slow); // XXX
 7901 %}
 7902 
 7903 // ============================================================================
 7904 // BSWAP Instructions
 7905 
 7906 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7907   match(Set dst (ReverseBytesI src));
 7908 
 7909   ins_cost(INSN_COST);
 7910   format %{ &quot;revw  $dst, $src&quot; %}
 7911 
 7912   ins_encode %{
 7913     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7914   %}
 7915 
 7916   ins_pipe(ialu_reg);
 7917 %}
 7918 
 7919 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7920   match(Set dst (ReverseBytesL src));
 7921 
 7922   ins_cost(INSN_COST);
 7923   format %{ &quot;rev  $dst, $src&quot; %}
 7924 
 7925   ins_encode %{
 7926     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7927   %}
 7928 
 7929   ins_pipe(ialu_reg);
 7930 %}
 7931 
 7932 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7933   match(Set dst (ReverseBytesUS src));
 7934 
 7935   ins_cost(INSN_COST);
 7936   format %{ &quot;rev16w  $dst, $src&quot; %}
 7937 
 7938   ins_encode %{
 7939     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7940   %}
 7941 
 7942   ins_pipe(ialu_reg);
 7943 %}
 7944 
 7945 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7946   match(Set dst (ReverseBytesS src));
 7947 
 7948   ins_cost(INSN_COST);
 7949   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7950             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7951 
 7952   ins_encode %{
 7953     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7954     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7955   %}
 7956 
 7957   ins_pipe(ialu_reg);
 7958 %}
 7959 
 7960 // ============================================================================
 7961 // Zero Count Instructions
 7962 
 7963 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7964   match(Set dst (CountLeadingZerosI src));
 7965 
 7966   ins_cost(INSN_COST);
 7967   format %{ &quot;clzw  $dst, $src&quot; %}
 7968   ins_encode %{
 7969     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7970   %}
 7971 
 7972   ins_pipe(ialu_reg);
 7973 %}
 7974 
 7975 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7976   match(Set dst (CountLeadingZerosL src));
 7977 
 7978   ins_cost(INSN_COST);
 7979   format %{ &quot;clz   $dst, $src&quot; %}
 7980   ins_encode %{
 7981     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7982   %}
 7983 
 7984   ins_pipe(ialu_reg);
 7985 %}
 7986 
 7987 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7988   match(Set dst (CountTrailingZerosI src));
 7989 
 7990   ins_cost(INSN_COST * 2);
 7991   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7992             &quot;clzw   $dst, $dst&quot; %}
 7993   ins_encode %{
 7994     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7995     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7996   %}
 7997 
 7998   ins_pipe(ialu_reg);
 7999 %}
 8000 
 8001 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8002   match(Set dst (CountTrailingZerosL src));
 8003 
 8004   ins_cost(INSN_COST * 2);
 8005   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8006             &quot;clz    $dst, $dst&quot; %}
 8007   ins_encode %{
 8008     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8009     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8010   %}
 8011 
 8012   ins_pipe(ialu_reg);
 8013 %}
 8014 
 8015 //---------- Population Count Instructions -------------------------------------
 8016 //
 8017 
 8018 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8019   predicate(UsePopCountInstruction);
 8020   match(Set dst (PopCountI src));
 8021   effect(TEMP tmp);
 8022   ins_cost(INSN_COST * 13);
 8023 
 8024   format %{ &quot;movw   $src, $src\n\t&quot;
 8025             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8026             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8027             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8028             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8029   ins_encode %{
 8030     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8031     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8032     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8033     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8034     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8035   %}
 8036 
 8037   ins_pipe(pipe_class_default);
 8038 %}
 8039 
 8040 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8041   predicate(UsePopCountInstruction);
 8042   match(Set dst (PopCountI (LoadI mem)));
 8043   effect(TEMP tmp);
 8044   ins_cost(INSN_COST * 13);
 8045 
 8046   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8047             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8048             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8049             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8050   ins_encode %{
 8051     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8052     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8053               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8054     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8055     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8056     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8057   %}
 8058 
 8059   ins_pipe(pipe_class_default);
 8060 %}
 8061 
 8062 // Note: Long.bitCount(long) returns an int.
 8063 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8064   predicate(UsePopCountInstruction);
 8065   match(Set dst (PopCountL src));
 8066   effect(TEMP tmp);
 8067   ins_cost(INSN_COST * 13);
 8068 
 8069   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8070             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8071             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8072             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8073   ins_encode %{
 8074     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8075     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8076     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8077     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8078   %}
 8079 
 8080   ins_pipe(pipe_class_default);
 8081 %}
 8082 
 8083 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8084   predicate(UsePopCountInstruction);
 8085   match(Set dst (PopCountL (LoadL mem)));
 8086   effect(TEMP tmp);
 8087   ins_cost(INSN_COST * 13);
 8088 
 8089   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8090             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8091             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8092             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8093   ins_encode %{
 8094     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8095     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8096               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8097     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8098     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8099     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8100   %}
 8101 
 8102   ins_pipe(pipe_class_default);
 8103 %}
 8104 
 8105 // ============================================================================
 8106 // MemBar Instruction
 8107 
 8108 instruct load_fence() %{
 8109   match(LoadFence);
 8110   ins_cost(VOLATILE_REF_COST);
 8111 
 8112   format %{ &quot;load_fence&quot; %}
 8113 
 8114   ins_encode %{
 8115     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8116   %}
 8117   ins_pipe(pipe_serial);
 8118 %}
 8119 
 8120 instruct unnecessary_membar_acquire() %{
 8121   predicate(unnecessary_acquire(n));
 8122   match(MemBarAcquire);
 8123   ins_cost(0);
 8124 
 8125   format %{ &quot;membar_acquire (elided)&quot; %}
 8126 
 8127   ins_encode %{
 8128     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8129   %}
 8130 
 8131   ins_pipe(pipe_class_empty);
 8132 %}
 8133 
 8134 instruct membar_acquire() %{
 8135   match(MemBarAcquire);
 8136   ins_cost(VOLATILE_REF_COST);
 8137 
 8138   format %{ &quot;membar_acquire\n\t&quot;
 8139             &quot;dmb ish&quot; %}
 8140 
 8141   ins_encode %{
 8142     __ block_comment(&quot;membar_acquire&quot;);
 8143     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8144   %}
 8145 
 8146   ins_pipe(pipe_serial);
 8147 %}
 8148 
 8149 
 8150 instruct membar_acquire_lock() %{
 8151   match(MemBarAcquireLock);
 8152   ins_cost(VOLATILE_REF_COST);
 8153 
 8154   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8155 
 8156   ins_encode %{
 8157     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8158   %}
 8159 
 8160   ins_pipe(pipe_serial);
 8161 %}
 8162 
 8163 instruct store_fence() %{
 8164   match(StoreFence);
 8165   ins_cost(VOLATILE_REF_COST);
 8166 
 8167   format %{ &quot;store_fence&quot; %}
 8168 
 8169   ins_encode %{
 8170     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8171   %}
 8172   ins_pipe(pipe_serial);
 8173 %}
 8174 
 8175 instruct unnecessary_membar_release() %{
 8176   predicate(unnecessary_release(n));
 8177   match(MemBarRelease);
 8178   ins_cost(0);
 8179 
 8180   format %{ &quot;membar_release (elided)&quot; %}
 8181 
 8182   ins_encode %{
 8183     __ block_comment(&quot;membar_release (elided)&quot;);
 8184   %}
 8185   ins_pipe(pipe_serial);
 8186 %}
 8187 
 8188 instruct membar_release() %{
 8189   match(MemBarRelease);
 8190   ins_cost(VOLATILE_REF_COST);
 8191 
 8192   format %{ &quot;membar_release\n\t&quot;
 8193             &quot;dmb ish&quot; %}
 8194 
 8195   ins_encode %{
 8196     __ block_comment(&quot;membar_release&quot;);
 8197     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8198   %}
 8199   ins_pipe(pipe_serial);
 8200 %}
 8201 
 8202 instruct membar_storestore() %{
 8203   match(MemBarStoreStore);
 8204   ins_cost(VOLATILE_REF_COST);
 8205 
 8206   format %{ &quot;MEMBAR-store-store&quot; %}
 8207 
 8208   ins_encode %{
 8209     __ membar(Assembler::StoreStore);
 8210   %}
 8211   ins_pipe(pipe_serial);
 8212 %}
 8213 
 8214 instruct membar_release_lock() %{
 8215   match(MemBarReleaseLock);
 8216   ins_cost(VOLATILE_REF_COST);
 8217 
 8218   format %{ &quot;membar_release_lock (elided)&quot; %}
 8219 
 8220   ins_encode %{
 8221     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8222   %}
 8223 
 8224   ins_pipe(pipe_serial);
 8225 %}
 8226 
 8227 instruct unnecessary_membar_volatile() %{
 8228   predicate(unnecessary_volatile(n));
 8229   match(MemBarVolatile);
 8230   ins_cost(0);
 8231 
 8232   format %{ &quot;membar_volatile (elided)&quot; %}
 8233 
 8234   ins_encode %{
 8235     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8236   %}
 8237 
 8238   ins_pipe(pipe_serial);
 8239 %}
 8240 
 8241 instruct membar_volatile() %{
 8242   match(MemBarVolatile);
 8243   ins_cost(VOLATILE_REF_COST*100);
 8244 
 8245   format %{ &quot;membar_volatile\n\t&quot;
 8246              &quot;dmb ish&quot;%}
 8247 
 8248   ins_encode %{
 8249     __ block_comment(&quot;membar_volatile&quot;);
 8250     __ membar(Assembler::StoreLoad);
 8251   %}
 8252 
 8253   ins_pipe(pipe_serial);
 8254 %}
 8255 
 8256 // ============================================================================
 8257 // Cast/Convert Instructions
 8258 
 8259 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8260   match(Set dst (CastX2P src));
 8261 
 8262   ins_cost(INSN_COST);
 8263   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8264 
 8265   ins_encode %{
 8266     if ($dst$$reg != $src$$reg) {
 8267       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8268     }
 8269   %}
 8270 
 8271   ins_pipe(ialu_reg);
 8272 %}
 8273 
<a name="8" id="anc8"></a>














 8274 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8275   match(Set dst (CastP2X src));
 8276 
 8277   ins_cost(INSN_COST);
 8278   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8279 
 8280   ins_encode %{
 8281     if ($dst$$reg != $src$$reg) {
 8282       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8283     }
 8284   %}
 8285 
 8286   ins_pipe(ialu_reg);
 8287 %}
 8288 
<a name="9" id="anc9"></a>






























 8289 // Convert oop into int for vectors alignment masking
 8290 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8291   match(Set dst (ConvL2I (CastP2X src)));
 8292 
 8293   ins_cost(INSN_COST);
 8294   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8295   ins_encode %{
 8296     __ movw($dst$$Register, $src$$Register);
 8297   %}
 8298 
 8299   ins_pipe(ialu_reg);
 8300 %}
 8301 
 8302 // Convert compressed oop into int for vectors alignment masking
 8303 // in case of 32bit oops (heap &lt; 4Gb).
 8304 instruct convN2I(iRegINoSp dst, iRegN src)
 8305 %{
 8306   predicate(CompressedOops::shift() == 0);
 8307   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8308 
 8309   ins_cost(INSN_COST);
 8310   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8311   ins_encode %{
 8312     __ movw($dst$$Register, $src$$Register);
 8313   %}
 8314 
 8315   ins_pipe(ialu_reg);
 8316 %}
 8317 
 8318 
 8319 // Convert oop pointer into compressed form
 8320 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8321   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8322   match(Set dst (EncodeP src));
 8323   effect(KILL cr);
 8324   ins_cost(INSN_COST * 3);
 8325   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8326   ins_encode %{
 8327     Register s = $src$$Register;
 8328     Register d = $dst$$Register;
 8329     __ encode_heap_oop(d, s);
 8330   %}
 8331   ins_pipe(ialu_reg);
 8332 %}
 8333 
 8334 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8335   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8336   match(Set dst (EncodeP src));
 8337   ins_cost(INSN_COST * 3);
 8338   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8339   ins_encode %{
 8340     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8341   %}
 8342   ins_pipe(ialu_reg);
 8343 %}
 8344 
 8345 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8346   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8347             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8348   match(Set dst (DecodeN src));
 8349   ins_cost(INSN_COST * 3);
 8350   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8351   ins_encode %{
 8352     Register s = $src$$Register;
 8353     Register d = $dst$$Register;
 8354     __ decode_heap_oop(d, s);
 8355   %}
 8356   ins_pipe(ialu_reg);
 8357 %}
 8358 
 8359 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8360   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8361             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8362   match(Set dst (DecodeN src));
 8363   ins_cost(INSN_COST * 3);
 8364   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8365   ins_encode %{
 8366     Register s = $src$$Register;
 8367     Register d = $dst$$Register;
 8368     __ decode_heap_oop_not_null(d, s);
 8369   %}
 8370   ins_pipe(ialu_reg);
 8371 %}
 8372 
 8373 // n.b. AArch64 implementations of encode_klass_not_null and
 8374 // decode_klass_not_null do not modify the flags register so, unlike
 8375 // Intel, we don&#39;t kill CR as a side effect here
 8376 
 8377 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8378   match(Set dst (EncodePKlass src));
 8379 
 8380   ins_cost(INSN_COST * 3);
 8381   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8382 
 8383   ins_encode %{
 8384     Register src_reg = as_Register($src$$reg);
 8385     Register dst_reg = as_Register($dst$$reg);
 8386     __ encode_klass_not_null(dst_reg, src_reg);
 8387   %}
 8388 
 8389    ins_pipe(ialu_reg);
 8390 %}
 8391 
 8392 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8393   match(Set dst (DecodeNKlass src));
 8394 
 8395   ins_cost(INSN_COST * 3);
 8396   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8397 
 8398   ins_encode %{
 8399     Register src_reg = as_Register($src$$reg);
 8400     Register dst_reg = as_Register($dst$$reg);
 8401     if (dst_reg != src_reg) {
 8402       __ decode_klass_not_null(dst_reg, src_reg);
 8403     } else {
 8404       __ decode_klass_not_null(dst_reg);
 8405     }
 8406   %}
 8407 
 8408    ins_pipe(ialu_reg);
 8409 %}
 8410 
 8411 instruct checkCastPP(iRegPNoSp dst)
 8412 %{
 8413   match(Set dst (CheckCastPP dst));
 8414 
 8415   size(0);
 8416   format %{ &quot;# checkcastPP of $dst&quot; %}
 8417   ins_encode(/* empty encoding */);
 8418   ins_pipe(pipe_class_empty);
 8419 %}
 8420 
 8421 instruct castPP(iRegPNoSp dst)
 8422 %{
 8423   match(Set dst (CastPP dst));
 8424 
 8425   size(0);
 8426   format %{ &quot;# castPP of $dst&quot; %}
 8427   ins_encode(/* empty encoding */);
 8428   ins_pipe(pipe_class_empty);
 8429 %}
 8430 
 8431 instruct castII(iRegI dst)
 8432 %{
 8433   match(Set dst (CastII dst));
 8434 
 8435   size(0);
 8436   format %{ &quot;# castII of $dst&quot; %}
 8437   ins_encode(/* empty encoding */);
 8438   ins_cost(0);
 8439   ins_pipe(pipe_class_empty);
 8440 %}
 8441 
 8442 // ============================================================================
 8443 // Atomic operation instructions
 8444 //
 8445 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8446 // Store{PIL}Conditional instructions using a normal load for the
 8447 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8448 //
 8449 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8450 // pair to lock object allocations from Eden space when not using
 8451 // TLABs.
 8452 //
 8453 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8454 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8455 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8456 // only for 64-bit.
 8457 //
 8458 // We implement LoadPLocked and StorePLocked instructions using,
 8459 // respectively the AArch64 hw load-exclusive and store-conditional
 8460 // instructions. Whereas we must implement each of
 8461 // Store{IL}Conditional using a CAS which employs a pair of
 8462 // instructions comprising a load-exclusive followed by a
 8463 // store-conditional.
 8464 
 8465 
 8466 // Locked-load (linked load) of the current heap-top
 8467 // used when updating the eden heap top
 8468 // implemented using ldaxr on AArch64
 8469 
 8470 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8471 %{
 8472   match(Set dst (LoadPLocked mem));
 8473 
 8474   ins_cost(VOLATILE_REF_COST);
 8475 
 8476   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8477 
 8478   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8479 
 8480   ins_pipe(pipe_serial);
 8481 %}
 8482 
 8483 // Conditional-store of the updated heap-top.
 8484 // Used during allocation of the shared heap.
 8485 // Sets flag (EQ) on success.
 8486 // implemented using stlxr on AArch64.
 8487 
 8488 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8489 %{
 8490   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8491 
 8492   ins_cost(VOLATILE_REF_COST);
 8493 
 8494  // TODO
 8495  // do we need to do a store-conditional release or can we just use a
 8496  // plain store-conditional?
 8497 
 8498   format %{
 8499     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8500     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8501   %}
 8502 
 8503   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8504 
 8505   ins_pipe(pipe_serial);
 8506 %}
 8507 
 8508 
 8509 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8510 // when attempting to rebias a lock towards the current thread.  We
 8511 // must use the acquire form of cmpxchg in order to guarantee acquire
 8512 // semantics in this case.
 8513 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8514 %{
 8515   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8516 
 8517   ins_cost(VOLATILE_REF_COST);
 8518 
 8519   format %{
 8520     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8521     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8522   %}
 8523 
 8524   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8525 
 8526   ins_pipe(pipe_slow);
 8527 %}
 8528 
 8529 // storeIConditional also has acquire semantics, for no better reason
 8530 // than matching storeLConditional.  At the time of writing this
 8531 // comment storeIConditional was not used anywhere by AArch64.
 8532 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8533 %{
 8534   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8535 
 8536   ins_cost(VOLATILE_REF_COST);
 8537 
 8538   format %{
 8539     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8540     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8541   %}
 8542 
 8543   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8544 
 8545   ins_pipe(pipe_slow);
 8546 %}
 8547 
 8548 // standard CompareAndSwapX when we are using barriers
 8549 // these have higher priority than the rules selected by a predicate
 8550 
 8551 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8552 // can&#39;t match them
 8553 
 8554 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8555 
 8556   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8557   ins_cost(2 * VOLATILE_REF_COST);
 8558 
 8559   effect(KILL cr);
 8560 
 8561   format %{
 8562     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8563     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8564   %}
 8565 
 8566   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8567             aarch64_enc_cset_eq(res));
 8568 
 8569   ins_pipe(pipe_slow);
 8570 %}
 8571 
 8572 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8573 
 8574   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8575   ins_cost(2 * VOLATILE_REF_COST);
 8576 
 8577   effect(KILL cr);
 8578 
 8579   format %{
 8580     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8581     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8582   %}
 8583 
 8584   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8585             aarch64_enc_cset_eq(res));
 8586 
 8587   ins_pipe(pipe_slow);
 8588 %}
 8589 
 8590 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8591 
 8592   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8593   ins_cost(2 * VOLATILE_REF_COST);
 8594 
 8595   effect(KILL cr);
 8596 
 8597  format %{
 8598     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8599     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8600  %}
 8601 
 8602  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8603             aarch64_enc_cset_eq(res));
 8604 
 8605   ins_pipe(pipe_slow);
 8606 %}
 8607 
 8608 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8609 
 8610   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8611   ins_cost(2 * VOLATILE_REF_COST);
 8612 
 8613   effect(KILL cr);
 8614 
 8615  format %{
 8616     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8617     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8618  %}
 8619 
 8620  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8621             aarch64_enc_cset_eq(res));
 8622 
 8623   ins_pipe(pipe_slow);
 8624 %}
 8625 
 8626 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8627 
 8628   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8629   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8630   ins_cost(2 * VOLATILE_REF_COST);
 8631 
 8632   effect(KILL cr);
 8633 
 8634  format %{
 8635     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8636     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8637  %}
 8638 
 8639  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8640             aarch64_enc_cset_eq(res));
 8641 
 8642   ins_pipe(pipe_slow);
 8643 %}
 8644 
 8645 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8646 
 8647   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8648   ins_cost(2 * VOLATILE_REF_COST);
 8649 
 8650   effect(KILL cr);
 8651 
 8652  format %{
 8653     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8654     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8655  %}
 8656 
 8657  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8658             aarch64_enc_cset_eq(res));
 8659 
 8660   ins_pipe(pipe_slow);
 8661 %}
 8662 
 8663 // alternative CompareAndSwapX when we are eliding barriers
 8664 
 8665 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8666 
 8667   predicate(needs_acquiring_load_exclusive(n));
 8668   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8669   ins_cost(VOLATILE_REF_COST);
 8670 
 8671   effect(KILL cr);
 8672 
 8673   format %{
 8674     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8675     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8676   %}
 8677 
 8678   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8679             aarch64_enc_cset_eq(res));
 8680 
 8681   ins_pipe(pipe_slow);
 8682 %}
 8683 
 8684 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8685 
 8686   predicate(needs_acquiring_load_exclusive(n));
 8687   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8688   ins_cost(VOLATILE_REF_COST);
 8689 
 8690   effect(KILL cr);
 8691 
 8692   format %{
 8693     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8694     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8695   %}
 8696 
 8697   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8698             aarch64_enc_cset_eq(res));
 8699 
 8700   ins_pipe(pipe_slow);
 8701 %}
 8702 
 8703 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8704 
 8705   predicate(needs_acquiring_load_exclusive(n));
 8706   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8707   ins_cost(VOLATILE_REF_COST);
 8708 
 8709   effect(KILL cr);
 8710 
 8711  format %{
 8712     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8713     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8714  %}
 8715 
 8716  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8717             aarch64_enc_cset_eq(res));
 8718 
 8719   ins_pipe(pipe_slow);
 8720 %}
 8721 
 8722 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8723 
 8724   predicate(needs_acquiring_load_exclusive(n));
 8725   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8726   ins_cost(VOLATILE_REF_COST);
 8727 
 8728   effect(KILL cr);
 8729 
 8730  format %{
 8731     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8732     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8733  %}
 8734 
 8735  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8736             aarch64_enc_cset_eq(res));
 8737 
 8738   ins_pipe(pipe_slow);
 8739 %}
 8740 
 8741 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8742 
 8743   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8744   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8745   ins_cost(VOLATILE_REF_COST);
 8746 
 8747   effect(KILL cr);
 8748 
 8749  format %{
 8750     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8751     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8752  %}
 8753 
 8754  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8755             aarch64_enc_cset_eq(res));
 8756 
 8757   ins_pipe(pipe_slow);
 8758 %}
 8759 
 8760 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8761 
 8762   predicate(needs_acquiring_load_exclusive(n));
 8763   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8764   ins_cost(VOLATILE_REF_COST);
 8765 
 8766   effect(KILL cr);
 8767 
 8768  format %{
 8769     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8770     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8771  %}
 8772 
 8773  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8774             aarch64_enc_cset_eq(res));
 8775 
 8776   ins_pipe(pipe_slow);
 8777 %}
 8778 
 8779 
 8780 // ---------------------------------------------------------------------
 8781 
 8782 
 8783 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8784 
 8785 // Sundry CAS operations.  Note that release is always true,
 8786 // regardless of the memory ordering of the CAS.  This is because we
 8787 // need the volatile case to be sequentially consistent but there is
 8788 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8789 // can&#39;t check the type of memory ordering here, so we always emit a
 8790 // STLXR.
 8791 
 8792 // This section is generated from aarch64_ad_cas.m4
 8793 
 8794 
 8795 
 8796 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8797   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8798   ins_cost(2 * VOLATILE_REF_COST);
 8799   effect(TEMP_DEF res, KILL cr);
 8800   format %{
 8801     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8802   %}
 8803   ins_encode %{
 8804     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8805                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8806                /*weak*/ false, $res$$Register);
 8807     __ sxtbw($res$$Register, $res$$Register);
 8808   %}
 8809   ins_pipe(pipe_slow);
 8810 %}
 8811 
 8812 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8813   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8814   ins_cost(2 * VOLATILE_REF_COST);
 8815   effect(TEMP_DEF res, KILL cr);
 8816   format %{
 8817     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8818   %}
 8819   ins_encode %{
 8820     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8821                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8822                /*weak*/ false, $res$$Register);
 8823     __ sxthw($res$$Register, $res$$Register);
 8824   %}
 8825   ins_pipe(pipe_slow);
 8826 %}
 8827 
 8828 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8829   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8830   ins_cost(2 * VOLATILE_REF_COST);
 8831   effect(TEMP_DEF res, KILL cr);
 8832   format %{
 8833     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8834   %}
 8835   ins_encode %{
 8836     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8837                Assembler::word, /*acquire*/ false, /*release*/ true,
 8838                /*weak*/ false, $res$$Register);
 8839   %}
 8840   ins_pipe(pipe_slow);
 8841 %}
 8842 
 8843 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8844   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8845   ins_cost(2 * VOLATILE_REF_COST);
 8846   effect(TEMP_DEF res, KILL cr);
 8847   format %{
 8848     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8849   %}
 8850   ins_encode %{
 8851     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8852                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8853                /*weak*/ false, $res$$Register);
 8854   %}
 8855   ins_pipe(pipe_slow);
 8856 %}
 8857 
 8858 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8859   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8860   ins_cost(2 * VOLATILE_REF_COST);
 8861   effect(TEMP_DEF res, KILL cr);
 8862   format %{
 8863     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8864   %}
 8865   ins_encode %{
 8866     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8867                Assembler::word, /*acquire*/ false, /*release*/ true,
 8868                /*weak*/ false, $res$$Register);
 8869   %}
 8870   ins_pipe(pipe_slow);
 8871 %}
 8872 
 8873 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8874   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8875   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8876   ins_cost(2 * VOLATILE_REF_COST);
 8877   effect(TEMP_DEF res, KILL cr);
 8878   format %{
 8879     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8880   %}
 8881   ins_encode %{
 8882     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8883                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8884                /*weak*/ false, $res$$Register);
 8885   %}
 8886   ins_pipe(pipe_slow);
 8887 %}
 8888 
 8889 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8890   predicate(needs_acquiring_load_exclusive(n));
 8891   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8892   ins_cost(VOLATILE_REF_COST);
 8893   effect(TEMP_DEF res, KILL cr);
 8894   format %{
 8895     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8896   %}
 8897   ins_encode %{
 8898     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8899                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8900                /*weak*/ false, $res$$Register);
 8901     __ sxtbw($res$$Register, $res$$Register);
 8902   %}
 8903   ins_pipe(pipe_slow);
 8904 %}
 8905 
 8906 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8907   predicate(needs_acquiring_load_exclusive(n));
 8908   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8909   ins_cost(VOLATILE_REF_COST);
 8910   effect(TEMP_DEF res, KILL cr);
 8911   format %{
 8912     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8913   %}
 8914   ins_encode %{
 8915     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8916                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8917                /*weak*/ false, $res$$Register);
 8918     __ sxthw($res$$Register, $res$$Register);
 8919   %}
 8920   ins_pipe(pipe_slow);
 8921 %}
 8922 
 8923 
 8924 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8925   predicate(needs_acquiring_load_exclusive(n));
 8926   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8927   ins_cost(VOLATILE_REF_COST);
 8928   effect(TEMP_DEF res, KILL cr);
 8929   format %{
 8930     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8931   %}
 8932   ins_encode %{
 8933     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8934                Assembler::word, /*acquire*/ true, /*release*/ true,
 8935                /*weak*/ false, $res$$Register);
 8936   %}
 8937   ins_pipe(pipe_slow);
 8938 %}
 8939 
 8940 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8941   predicate(needs_acquiring_load_exclusive(n));
 8942   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8943   ins_cost(VOLATILE_REF_COST);
 8944   effect(TEMP_DEF res, KILL cr);
 8945   format %{
 8946     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8947   %}
 8948   ins_encode %{
 8949     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8950                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8951                /*weak*/ false, $res$$Register);
 8952   %}
 8953   ins_pipe(pipe_slow);
 8954 %}
 8955 
 8956 
 8957 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8958   predicate(needs_acquiring_load_exclusive(n));
 8959   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8960   ins_cost(VOLATILE_REF_COST);
 8961   effect(TEMP_DEF res, KILL cr);
 8962   format %{
 8963     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8964   %}
 8965   ins_encode %{
 8966     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8967                Assembler::word, /*acquire*/ true, /*release*/ true,
 8968                /*weak*/ false, $res$$Register);
 8969   %}
 8970   ins_pipe(pipe_slow);
 8971 %}
 8972 
 8973 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8974   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8975   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8976   ins_cost(VOLATILE_REF_COST);
 8977   effect(TEMP_DEF res, KILL cr);
 8978   format %{
 8979     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8980   %}
 8981   ins_encode %{
 8982     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8983                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8984                /*weak*/ false, $res$$Register);
 8985   %}
 8986   ins_pipe(pipe_slow);
 8987 %}
 8988 
 8989 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8990   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 8991   ins_cost(2 * VOLATILE_REF_COST);
 8992   effect(KILL cr);
 8993   format %{
 8994     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8995     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8996   %}
 8997   ins_encode %{
 8998     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8999                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9000                /*weak*/ true, noreg);
 9001     __ csetw($res$$Register, Assembler::EQ);
 9002   %}
 9003   ins_pipe(pipe_slow);
 9004 %}
 9005 
 9006 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9007   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9008   ins_cost(2 * VOLATILE_REF_COST);
 9009   effect(KILL cr);
 9010   format %{
 9011     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9012     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9013   %}
 9014   ins_encode %{
 9015     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9016                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9017                /*weak*/ true, noreg);
 9018     __ csetw($res$$Register, Assembler::EQ);
 9019   %}
 9020   ins_pipe(pipe_slow);
 9021 %}
 9022 
 9023 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9024   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9025   ins_cost(2 * VOLATILE_REF_COST);
 9026   effect(KILL cr);
 9027   format %{
 9028     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9029     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9030   %}
 9031   ins_encode %{
 9032     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9033                Assembler::word, /*acquire*/ false, /*release*/ true,
 9034                /*weak*/ true, noreg);
 9035     __ csetw($res$$Register, Assembler::EQ);
 9036   %}
 9037   ins_pipe(pipe_slow);
 9038 %}
 9039 
 9040 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9041   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9042   ins_cost(2 * VOLATILE_REF_COST);
 9043   effect(KILL cr);
 9044   format %{
 9045     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9046     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9047   %}
 9048   ins_encode %{
 9049     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9050                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9051                /*weak*/ true, noreg);
 9052     __ csetw($res$$Register, Assembler::EQ);
 9053   %}
 9054   ins_pipe(pipe_slow);
 9055 %}
 9056 
 9057 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9058   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9059   ins_cost(2 * VOLATILE_REF_COST);
 9060   effect(KILL cr);
 9061   format %{
 9062     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9063     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9064   %}
 9065   ins_encode %{
 9066     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9067                Assembler::word, /*acquire*/ false, /*release*/ true,
 9068                /*weak*/ true, noreg);
 9069     __ csetw($res$$Register, Assembler::EQ);
 9070   %}
 9071   ins_pipe(pipe_slow);
 9072 %}
 9073 
 9074 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9075   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9076   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9077   ins_cost(2 * VOLATILE_REF_COST);
 9078   effect(KILL cr);
 9079   format %{
 9080     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9081     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9082   %}
 9083   ins_encode %{
 9084     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9085                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9086                /*weak*/ true, noreg);
 9087     __ csetw($res$$Register, Assembler::EQ);
 9088   %}
 9089   ins_pipe(pipe_slow);
 9090 %}
 9091 
 9092 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9093   predicate(needs_acquiring_load_exclusive(n));
 9094   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9095   ins_cost(VOLATILE_REF_COST);
 9096   effect(KILL cr);
 9097   format %{
 9098     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9099     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9100   %}
 9101   ins_encode %{
 9102     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9103                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9104                /*weak*/ true, noreg);
 9105     __ csetw($res$$Register, Assembler::EQ);
 9106   %}
 9107   ins_pipe(pipe_slow);
 9108 %}
 9109 
 9110 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9111   predicate(needs_acquiring_load_exclusive(n));
 9112   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9113   ins_cost(VOLATILE_REF_COST);
 9114   effect(KILL cr);
 9115   format %{
 9116     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9117     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9118   %}
 9119   ins_encode %{
 9120     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9121                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9122                /*weak*/ true, noreg);
 9123     __ csetw($res$$Register, Assembler::EQ);
 9124   %}
 9125   ins_pipe(pipe_slow);
 9126 %}
 9127 
 9128 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9129   predicate(needs_acquiring_load_exclusive(n));
 9130   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9131   ins_cost(VOLATILE_REF_COST);
 9132   effect(KILL cr);
 9133   format %{
 9134     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9135     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9136   %}
 9137   ins_encode %{
 9138     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9139                Assembler::word, /*acquire*/ true, /*release*/ true,
 9140                /*weak*/ true, noreg);
 9141     __ csetw($res$$Register, Assembler::EQ);
 9142   %}
 9143   ins_pipe(pipe_slow);
 9144 %}
 9145 
 9146 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9147   predicate(needs_acquiring_load_exclusive(n));
 9148   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9149   ins_cost(VOLATILE_REF_COST);
 9150   effect(KILL cr);
 9151   format %{
 9152     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9153     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9154   %}
 9155   ins_encode %{
 9156     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9157                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9158                /*weak*/ true, noreg);
 9159     __ csetw($res$$Register, Assembler::EQ);
 9160   %}
 9161   ins_pipe(pipe_slow);
 9162 %}
 9163 
 9164 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9165   predicate(needs_acquiring_load_exclusive(n));
 9166   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9167   ins_cost(VOLATILE_REF_COST);
 9168   effect(KILL cr);
 9169   format %{
 9170     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9171     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9172   %}
 9173   ins_encode %{
 9174     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9175                Assembler::word, /*acquire*/ true, /*release*/ true,
 9176                /*weak*/ true, noreg);
 9177     __ csetw($res$$Register, Assembler::EQ);
 9178   %}
 9179   ins_pipe(pipe_slow);
 9180 %}
 9181 
 9182 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9183   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9184   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9185   ins_cost(VOLATILE_REF_COST);
 9186   effect(KILL cr);
 9187   format %{
 9188     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9189     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9190   %}
 9191   ins_encode %{
 9192     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9193                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9194                /*weak*/ true, noreg);
 9195     __ csetw($res$$Register, Assembler::EQ);
 9196   %}
 9197   ins_pipe(pipe_slow);
 9198 %}
 9199 
 9200 // END This section of the file is automatically generated. Do not edit --------------
 9201 // ---------------------------------------------------------------------
 9202 
 9203 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9204   match(Set prev (GetAndSetI mem newv));
 9205   ins_cost(2 * VOLATILE_REF_COST);
 9206   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9207   ins_encode %{
 9208     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9209   %}
 9210   ins_pipe(pipe_serial);
 9211 %}
 9212 
 9213 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9214   match(Set prev (GetAndSetL mem newv));
 9215   ins_cost(2 * VOLATILE_REF_COST);
 9216   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9217   ins_encode %{
 9218     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9219   %}
 9220   ins_pipe(pipe_serial);
 9221 %}
 9222 
 9223 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9224   match(Set prev (GetAndSetN mem newv));
 9225   ins_cost(2 * VOLATILE_REF_COST);
 9226   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9227   ins_encode %{
 9228     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9229   %}
 9230   ins_pipe(pipe_serial);
 9231 %}
 9232 
 9233 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9234   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9235   match(Set prev (GetAndSetP mem newv));
 9236   ins_cost(2 * VOLATILE_REF_COST);
 9237   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9238   ins_encode %{
 9239     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9240   %}
 9241   ins_pipe(pipe_serial);
 9242 %}
 9243 
 9244 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9245   predicate(needs_acquiring_load_exclusive(n));
 9246   match(Set prev (GetAndSetI mem newv));
 9247   ins_cost(VOLATILE_REF_COST);
 9248   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9249   ins_encode %{
 9250     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9251   %}
 9252   ins_pipe(pipe_serial);
 9253 %}
 9254 
 9255 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9256   predicate(needs_acquiring_load_exclusive(n));
 9257   match(Set prev (GetAndSetL mem newv));
 9258   ins_cost(VOLATILE_REF_COST);
 9259   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9260   ins_encode %{
 9261     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9262   %}
 9263   ins_pipe(pipe_serial);
 9264 %}
 9265 
 9266 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9267   predicate(needs_acquiring_load_exclusive(n));
 9268   match(Set prev (GetAndSetN mem newv));
 9269   ins_cost(VOLATILE_REF_COST);
 9270   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9271   ins_encode %{
 9272     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9273   %}
 9274   ins_pipe(pipe_serial);
 9275 %}
 9276 
 9277 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9278   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9279   match(Set prev (GetAndSetP mem newv));
 9280   ins_cost(VOLATILE_REF_COST);
 9281   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9282   ins_encode %{
 9283     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9284   %}
 9285   ins_pipe(pipe_serial);
 9286 %}
 9287 
 9288 
 9289 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9290   match(Set newval (GetAndAddL mem incr));
 9291   ins_cost(2 * VOLATILE_REF_COST + 1);
 9292   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9293   ins_encode %{
 9294     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9295   %}
 9296   ins_pipe(pipe_serial);
 9297 %}
 9298 
 9299 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9300   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9301   match(Set dummy (GetAndAddL mem incr));
 9302   ins_cost(2 * VOLATILE_REF_COST);
 9303   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9304   ins_encode %{
 9305     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9306   %}
 9307   ins_pipe(pipe_serial);
 9308 %}
 9309 
 9310 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9311   match(Set newval (GetAndAddL mem incr));
 9312   ins_cost(2 * VOLATILE_REF_COST + 1);
 9313   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9314   ins_encode %{
 9315     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9316   %}
 9317   ins_pipe(pipe_serial);
 9318 %}
 9319 
 9320 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9321   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9322   match(Set dummy (GetAndAddL mem incr));
 9323   ins_cost(2 * VOLATILE_REF_COST);
 9324   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9325   ins_encode %{
 9326     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9327   %}
 9328   ins_pipe(pipe_serial);
 9329 %}
 9330 
 9331 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9332   match(Set newval (GetAndAddI mem incr));
 9333   ins_cost(2 * VOLATILE_REF_COST + 1);
 9334   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9335   ins_encode %{
 9336     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9337   %}
 9338   ins_pipe(pipe_serial);
 9339 %}
 9340 
 9341 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9342   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9343   match(Set dummy (GetAndAddI mem incr));
 9344   ins_cost(2 * VOLATILE_REF_COST);
 9345   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9346   ins_encode %{
 9347     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9348   %}
 9349   ins_pipe(pipe_serial);
 9350 %}
 9351 
 9352 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9353   match(Set newval (GetAndAddI mem incr));
 9354   ins_cost(2 * VOLATILE_REF_COST + 1);
 9355   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9356   ins_encode %{
 9357     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9358   %}
 9359   ins_pipe(pipe_serial);
 9360 %}
 9361 
 9362 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9363   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9364   match(Set dummy (GetAndAddI mem incr));
 9365   ins_cost(2 * VOLATILE_REF_COST);
 9366   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9367   ins_encode %{
 9368     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9369   %}
 9370   ins_pipe(pipe_serial);
 9371 %}
 9372 
 9373 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9374   predicate(needs_acquiring_load_exclusive(n));
 9375   match(Set newval (GetAndAddL mem incr));
 9376   ins_cost(VOLATILE_REF_COST + 1);
 9377   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9378   ins_encode %{
 9379     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9380   %}
 9381   ins_pipe(pipe_serial);
 9382 %}
 9383 
 9384 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9385   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9386   match(Set dummy (GetAndAddL mem incr));
 9387   ins_cost(VOLATILE_REF_COST);
 9388   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9389   ins_encode %{
 9390     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9391   %}
 9392   ins_pipe(pipe_serial);
 9393 %}
 9394 
 9395 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9396   predicate(needs_acquiring_load_exclusive(n));
 9397   match(Set newval (GetAndAddL mem incr));
 9398   ins_cost(VOLATILE_REF_COST + 1);
 9399   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9400   ins_encode %{
 9401     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9402   %}
 9403   ins_pipe(pipe_serial);
 9404 %}
 9405 
 9406 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9407   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9408   match(Set dummy (GetAndAddL mem incr));
 9409   ins_cost(VOLATILE_REF_COST);
 9410   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9411   ins_encode %{
 9412     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9413   %}
 9414   ins_pipe(pipe_serial);
 9415 %}
 9416 
 9417 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9418   predicate(needs_acquiring_load_exclusive(n));
 9419   match(Set newval (GetAndAddI mem incr));
 9420   ins_cost(VOLATILE_REF_COST + 1);
 9421   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9422   ins_encode %{
 9423     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9424   %}
 9425   ins_pipe(pipe_serial);
 9426 %}
 9427 
 9428 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9429   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9430   match(Set dummy (GetAndAddI mem incr));
 9431   ins_cost(VOLATILE_REF_COST);
 9432   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9433   ins_encode %{
 9434     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9435   %}
 9436   ins_pipe(pipe_serial);
 9437 %}
 9438 
 9439 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9440   predicate(needs_acquiring_load_exclusive(n));
 9441   match(Set newval (GetAndAddI mem incr));
 9442   ins_cost(VOLATILE_REF_COST + 1);
 9443   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9444   ins_encode %{
 9445     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9446   %}
 9447   ins_pipe(pipe_serial);
 9448 %}
 9449 
 9450 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9451   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9452   match(Set dummy (GetAndAddI mem incr));
 9453   ins_cost(VOLATILE_REF_COST);
 9454   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9455   ins_encode %{
 9456     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9457   %}
 9458   ins_pipe(pipe_serial);
 9459 %}
 9460 
 9461 // Manifest a CmpL result in an integer register.
 9462 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9463 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9464 %{
 9465   match(Set dst (CmpL3 src1 src2));
 9466   effect(KILL flags);
 9467 
 9468   ins_cost(INSN_COST * 6);
 9469   format %{
 9470       &quot;cmp $src1, $src2&quot;
 9471       &quot;csetw $dst, ne&quot;
 9472       &quot;cnegw $dst, lt&quot;
 9473   %}
 9474   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9475   ins_encode %{
 9476     __ cmp($src1$$Register, $src2$$Register);
 9477     __ csetw($dst$$Register, Assembler::NE);
 9478     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9479   %}
 9480 
 9481   ins_pipe(pipe_class_default);
 9482 %}
 9483 
 9484 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9485 %{
 9486   match(Set dst (CmpL3 src1 src2));
 9487   effect(KILL flags);
 9488 
 9489   ins_cost(INSN_COST * 6);
 9490   format %{
 9491       &quot;cmp $src1, $src2&quot;
 9492       &quot;csetw $dst, ne&quot;
 9493       &quot;cnegw $dst, lt&quot;
 9494   %}
 9495   ins_encode %{
 9496     int32_t con = (int32_t)$src2$$constant;
 9497      if (con &lt; 0) {
 9498       __ adds(zr, $src1$$Register, -con);
 9499     } else {
 9500       __ subs(zr, $src1$$Register, con);
 9501     }
 9502     __ csetw($dst$$Register, Assembler::NE);
 9503     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9504   %}
 9505 
 9506   ins_pipe(pipe_class_default);
 9507 %}
 9508 
 9509 // ============================================================================
 9510 // Conditional Move Instructions
 9511 
 9512 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9513 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9514 // define an op class which merged both inputs and use it to type the
 9515 // argument to a single rule. unfortunatelyt his fails because the
 9516 // opclass does not live up to the COND_INTER interface of its
 9517 // component operands. When the generic code tries to negate the
 9518 // operand it ends up running the generci Machoper::negate method
 9519 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9520 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9521 
 9522 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9523   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9524 
 9525   ins_cost(INSN_COST * 2);
 9526   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9527 
 9528   ins_encode %{
 9529     __ cselw(as_Register($dst$$reg),
 9530              as_Register($src2$$reg),
 9531              as_Register($src1$$reg),
 9532              (Assembler::Condition)$cmp$$cmpcode);
 9533   %}
 9534 
 9535   ins_pipe(icond_reg_reg);
 9536 %}
 9537 
 9538 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9539   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9540 
 9541   ins_cost(INSN_COST * 2);
 9542   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9543 
 9544   ins_encode %{
 9545     __ cselw(as_Register($dst$$reg),
 9546              as_Register($src2$$reg),
 9547              as_Register($src1$$reg),
 9548              (Assembler::Condition)$cmp$$cmpcode);
 9549   %}
 9550 
 9551   ins_pipe(icond_reg_reg);
 9552 %}
 9553 
 9554 // special cases where one arg is zero
 9555 
 9556 // n.b. this is selected in preference to the rule above because it
 9557 // avoids loading constant 0 into a source register
 9558 
 9559 // TODO
 9560 // we ought only to be able to cull one of these variants as the ideal
 9561 // transforms ought always to order the zero consistently (to left/right?)
 9562 
 9563 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9564   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9565 
 9566   ins_cost(INSN_COST * 2);
 9567   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9568 
 9569   ins_encode %{
 9570     __ cselw(as_Register($dst$$reg),
 9571              as_Register($src$$reg),
 9572              zr,
 9573              (Assembler::Condition)$cmp$$cmpcode);
 9574   %}
 9575 
 9576   ins_pipe(icond_reg);
 9577 %}
 9578 
 9579 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9580   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9581 
 9582   ins_cost(INSN_COST * 2);
 9583   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9584 
 9585   ins_encode %{
 9586     __ cselw(as_Register($dst$$reg),
 9587              as_Register($src$$reg),
 9588              zr,
 9589              (Assembler::Condition)$cmp$$cmpcode);
 9590   %}
 9591 
 9592   ins_pipe(icond_reg);
 9593 %}
 9594 
 9595 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9596   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9597 
 9598   ins_cost(INSN_COST * 2);
 9599   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9600 
 9601   ins_encode %{
 9602     __ cselw(as_Register($dst$$reg),
 9603              zr,
 9604              as_Register($src$$reg),
 9605              (Assembler::Condition)$cmp$$cmpcode);
 9606   %}
 9607 
 9608   ins_pipe(icond_reg);
 9609 %}
 9610 
 9611 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9612   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9613 
 9614   ins_cost(INSN_COST * 2);
 9615   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9616 
 9617   ins_encode %{
 9618     __ cselw(as_Register($dst$$reg),
 9619              zr,
 9620              as_Register($src$$reg),
 9621              (Assembler::Condition)$cmp$$cmpcode);
 9622   %}
 9623 
 9624   ins_pipe(icond_reg);
 9625 %}
 9626 
 9627 // special case for creating a boolean 0 or 1
 9628 
 9629 // n.b. this is selected in preference to the rule above because it
 9630 // avoids loading constants 0 and 1 into a source register
 9631 
 9632 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9633   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9634 
 9635   ins_cost(INSN_COST * 2);
 9636   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9637 
 9638   ins_encode %{
 9639     // equivalently
 9640     // cset(as_Register($dst$$reg),
 9641     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9642     __ csincw(as_Register($dst$$reg),
 9643              zr,
 9644              zr,
 9645              (Assembler::Condition)$cmp$$cmpcode);
 9646   %}
 9647 
 9648   ins_pipe(icond_none);
 9649 %}
 9650 
 9651 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9652   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9653 
 9654   ins_cost(INSN_COST * 2);
 9655   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9656 
 9657   ins_encode %{
 9658     // equivalently
 9659     // cset(as_Register($dst$$reg),
 9660     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9661     __ csincw(as_Register($dst$$reg),
 9662              zr,
 9663              zr,
 9664              (Assembler::Condition)$cmp$$cmpcode);
 9665   %}
 9666 
 9667   ins_pipe(icond_none);
 9668 %}
 9669 
 9670 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9671   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9672 
 9673   ins_cost(INSN_COST * 2);
 9674   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9675 
 9676   ins_encode %{
 9677     __ csel(as_Register($dst$$reg),
 9678             as_Register($src2$$reg),
 9679             as_Register($src1$$reg),
 9680             (Assembler::Condition)$cmp$$cmpcode);
 9681   %}
 9682 
 9683   ins_pipe(icond_reg_reg);
 9684 %}
 9685 
 9686 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9687   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9688 
 9689   ins_cost(INSN_COST * 2);
 9690   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9691 
 9692   ins_encode %{
 9693     __ csel(as_Register($dst$$reg),
 9694             as_Register($src2$$reg),
 9695             as_Register($src1$$reg),
 9696             (Assembler::Condition)$cmp$$cmpcode);
 9697   %}
 9698 
 9699   ins_pipe(icond_reg_reg);
 9700 %}
 9701 
 9702 // special cases where one arg is zero
 9703 
 9704 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9705   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9706 
 9707   ins_cost(INSN_COST * 2);
 9708   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9709 
 9710   ins_encode %{
 9711     __ csel(as_Register($dst$$reg),
 9712             zr,
 9713             as_Register($src$$reg),
 9714             (Assembler::Condition)$cmp$$cmpcode);
 9715   %}
 9716 
 9717   ins_pipe(icond_reg);
 9718 %}
 9719 
 9720 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9721   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9722 
 9723   ins_cost(INSN_COST * 2);
 9724   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9725 
 9726   ins_encode %{
 9727     __ csel(as_Register($dst$$reg),
 9728             zr,
 9729             as_Register($src$$reg),
 9730             (Assembler::Condition)$cmp$$cmpcode);
 9731   %}
 9732 
 9733   ins_pipe(icond_reg);
 9734 %}
 9735 
 9736 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9737   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9738 
 9739   ins_cost(INSN_COST * 2);
 9740   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9741 
 9742   ins_encode %{
 9743     __ csel(as_Register($dst$$reg),
 9744             as_Register($src$$reg),
 9745             zr,
 9746             (Assembler::Condition)$cmp$$cmpcode);
 9747   %}
 9748 
 9749   ins_pipe(icond_reg);
 9750 %}
 9751 
 9752 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9753   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9754 
 9755   ins_cost(INSN_COST * 2);
 9756   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9757 
 9758   ins_encode %{
 9759     __ csel(as_Register($dst$$reg),
 9760             as_Register($src$$reg),
 9761             zr,
 9762             (Assembler::Condition)$cmp$$cmpcode);
 9763   %}
 9764 
 9765   ins_pipe(icond_reg);
 9766 %}
 9767 
 9768 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9769   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9770 
 9771   ins_cost(INSN_COST * 2);
 9772   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9773 
 9774   ins_encode %{
 9775     __ csel(as_Register($dst$$reg),
 9776             as_Register($src2$$reg),
 9777             as_Register($src1$$reg),
 9778             (Assembler::Condition)$cmp$$cmpcode);
 9779   %}
 9780 
 9781   ins_pipe(icond_reg_reg);
 9782 %}
 9783 
 9784 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9785   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9786 
 9787   ins_cost(INSN_COST * 2);
 9788   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9789 
 9790   ins_encode %{
 9791     __ csel(as_Register($dst$$reg),
 9792             as_Register($src2$$reg),
 9793             as_Register($src1$$reg),
 9794             (Assembler::Condition)$cmp$$cmpcode);
 9795   %}
 9796 
 9797   ins_pipe(icond_reg_reg);
 9798 %}
 9799 
 9800 // special cases where one arg is zero
 9801 
 9802 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9803   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9804 
 9805   ins_cost(INSN_COST * 2);
 9806   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9807 
 9808   ins_encode %{
 9809     __ csel(as_Register($dst$$reg),
 9810             zr,
 9811             as_Register($src$$reg),
 9812             (Assembler::Condition)$cmp$$cmpcode);
 9813   %}
 9814 
 9815   ins_pipe(icond_reg);
 9816 %}
 9817 
 9818 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9819   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9820 
 9821   ins_cost(INSN_COST * 2);
 9822   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9823 
 9824   ins_encode %{
 9825     __ csel(as_Register($dst$$reg),
 9826             zr,
 9827             as_Register($src$$reg),
 9828             (Assembler::Condition)$cmp$$cmpcode);
 9829   %}
 9830 
 9831   ins_pipe(icond_reg);
 9832 %}
 9833 
 9834 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9835   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9836 
 9837   ins_cost(INSN_COST * 2);
 9838   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9839 
 9840   ins_encode %{
 9841     __ csel(as_Register($dst$$reg),
 9842             as_Register($src$$reg),
 9843             zr,
 9844             (Assembler::Condition)$cmp$$cmpcode);
 9845   %}
 9846 
 9847   ins_pipe(icond_reg);
 9848 %}
 9849 
 9850 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9851   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9852 
 9853   ins_cost(INSN_COST * 2);
 9854   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9855 
 9856   ins_encode %{
 9857     __ csel(as_Register($dst$$reg),
 9858             as_Register($src$$reg),
 9859             zr,
 9860             (Assembler::Condition)$cmp$$cmpcode);
 9861   %}
 9862 
 9863   ins_pipe(icond_reg);
 9864 %}
 9865 
 9866 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9867   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9868 
 9869   ins_cost(INSN_COST * 2);
 9870   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9871 
 9872   ins_encode %{
 9873     __ cselw(as_Register($dst$$reg),
 9874              as_Register($src2$$reg),
 9875              as_Register($src1$$reg),
 9876              (Assembler::Condition)$cmp$$cmpcode);
 9877   %}
 9878 
 9879   ins_pipe(icond_reg_reg);
 9880 %}
 9881 
 9882 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9883   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9884 
 9885   ins_cost(INSN_COST * 2);
 9886   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9887 
 9888   ins_encode %{
 9889     __ cselw(as_Register($dst$$reg),
 9890              as_Register($src2$$reg),
 9891              as_Register($src1$$reg),
 9892              (Assembler::Condition)$cmp$$cmpcode);
 9893   %}
 9894 
 9895   ins_pipe(icond_reg_reg);
 9896 %}
 9897 
 9898 // special cases where one arg is zero
 9899 
 9900 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9901   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9902 
 9903   ins_cost(INSN_COST * 2);
 9904   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9905 
 9906   ins_encode %{
 9907     __ cselw(as_Register($dst$$reg),
 9908              zr,
 9909              as_Register($src$$reg),
 9910              (Assembler::Condition)$cmp$$cmpcode);
 9911   %}
 9912 
 9913   ins_pipe(icond_reg);
 9914 %}
 9915 
 9916 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9917   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9918 
 9919   ins_cost(INSN_COST * 2);
 9920   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9921 
 9922   ins_encode %{
 9923     __ cselw(as_Register($dst$$reg),
 9924              zr,
 9925              as_Register($src$$reg),
 9926              (Assembler::Condition)$cmp$$cmpcode);
 9927   %}
 9928 
 9929   ins_pipe(icond_reg);
 9930 %}
 9931 
 9932 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9933   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9934 
 9935   ins_cost(INSN_COST * 2);
 9936   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9937 
 9938   ins_encode %{
 9939     __ cselw(as_Register($dst$$reg),
 9940              as_Register($src$$reg),
 9941              zr,
 9942              (Assembler::Condition)$cmp$$cmpcode);
 9943   %}
 9944 
 9945   ins_pipe(icond_reg);
 9946 %}
 9947 
 9948 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9949   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9950 
 9951   ins_cost(INSN_COST * 2);
 9952   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9953 
 9954   ins_encode %{
 9955     __ cselw(as_Register($dst$$reg),
 9956              as_Register($src$$reg),
 9957              zr,
 9958              (Assembler::Condition)$cmp$$cmpcode);
 9959   %}
 9960 
 9961   ins_pipe(icond_reg);
 9962 %}
 9963 
 9964 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9965 %{
 9966   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9967 
 9968   ins_cost(INSN_COST * 3);
 9969 
 9970   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9971   ins_encode %{
 9972     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9973     __ fcsels(as_FloatRegister($dst$$reg),
 9974               as_FloatRegister($src2$$reg),
 9975               as_FloatRegister($src1$$reg),
 9976               cond);
 9977   %}
 9978 
 9979   ins_pipe(fp_cond_reg_reg_s);
 9980 %}
 9981 
 9982 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9983 %{
 9984   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9985 
 9986   ins_cost(INSN_COST * 3);
 9987 
 9988   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9989   ins_encode %{
 9990     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9991     __ fcsels(as_FloatRegister($dst$$reg),
 9992               as_FloatRegister($src2$$reg),
 9993               as_FloatRegister($src1$$reg),
 9994               cond);
 9995   %}
 9996 
 9997   ins_pipe(fp_cond_reg_reg_s);
 9998 %}
 9999 
10000 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10001 %{
10002   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10003 
10004   ins_cost(INSN_COST * 3);
10005 
10006   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10007   ins_encode %{
10008     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10009     __ fcseld(as_FloatRegister($dst$$reg),
10010               as_FloatRegister($src2$$reg),
10011               as_FloatRegister($src1$$reg),
10012               cond);
10013   %}
10014 
10015   ins_pipe(fp_cond_reg_reg_d);
10016 %}
10017 
10018 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10019 %{
10020   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10021 
10022   ins_cost(INSN_COST * 3);
10023 
10024   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10025   ins_encode %{
10026     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10027     __ fcseld(as_FloatRegister($dst$$reg),
10028               as_FloatRegister($src2$$reg),
10029               as_FloatRegister($src1$$reg),
10030               cond);
10031   %}
10032 
10033   ins_pipe(fp_cond_reg_reg_d);
10034 %}
10035 
10036 // ============================================================================
10037 // Arithmetic Instructions
10038 //
10039 
10040 // Integer Addition
10041 
10042 // TODO
10043 // these currently employ operations which do not set CR and hence are
10044 // not flagged as killing CR but we would like to isolate the cases
10045 // where we want to set flags from those where we don&#39;t. need to work
10046 // out how to do that.
10047 
10048 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10049   match(Set dst (AddI src1 src2));
10050 
10051   ins_cost(INSN_COST);
10052   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10053 
10054   ins_encode %{
10055     __ addw(as_Register($dst$$reg),
10056             as_Register($src1$$reg),
10057             as_Register($src2$$reg));
10058   %}
10059 
10060   ins_pipe(ialu_reg_reg);
10061 %}
10062 
10063 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10064   match(Set dst (AddI src1 src2));
10065 
10066   ins_cost(INSN_COST);
10067   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10068 
10069   // use opcode to indicate that this is an add not a sub
10070   opcode(0x0);
10071 
10072   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10073 
10074   ins_pipe(ialu_reg_imm);
10075 %}
10076 
10077 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10078   match(Set dst (AddI (ConvL2I src1) src2));
10079 
10080   ins_cost(INSN_COST);
10081   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10082 
10083   // use opcode to indicate that this is an add not a sub
10084   opcode(0x0);
10085 
10086   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10087 
10088   ins_pipe(ialu_reg_imm);
10089 %}
10090 
10091 // Pointer Addition
10092 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10093   match(Set dst (AddP src1 src2));
10094 
10095   ins_cost(INSN_COST);
10096   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10097 
10098   ins_encode %{
10099     __ add(as_Register($dst$$reg),
10100            as_Register($src1$$reg),
10101            as_Register($src2$$reg));
10102   %}
10103 
10104   ins_pipe(ialu_reg_reg);
10105 %}
10106 
10107 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10108   match(Set dst (AddP src1 (ConvI2L src2)));
10109 
10110   ins_cost(1.9 * INSN_COST);
10111   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10112 
10113   ins_encode %{
10114     __ add(as_Register($dst$$reg),
10115            as_Register($src1$$reg),
10116            as_Register($src2$$reg), ext::sxtw);
10117   %}
10118 
10119   ins_pipe(ialu_reg_reg);
10120 %}
10121 
10122 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10123   match(Set dst (AddP src1 (LShiftL src2 scale)));
10124 
10125   ins_cost(1.9 * INSN_COST);
10126   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10127 
10128   ins_encode %{
10129     __ lea(as_Register($dst$$reg),
10130            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10131                    Address::lsl($scale$$constant)));
10132   %}
10133 
10134   ins_pipe(ialu_reg_reg_shift);
10135 %}
10136 
10137 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10138   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10139 
10140   ins_cost(1.9 * INSN_COST);
10141   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10142 
10143   ins_encode %{
10144     __ lea(as_Register($dst$$reg),
10145            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10146                    Address::sxtw($scale$$constant)));
10147   %}
10148 
10149   ins_pipe(ialu_reg_reg_shift);
10150 %}
10151 
10152 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10153   match(Set dst (LShiftL (ConvI2L src) scale));
10154 
10155   ins_cost(INSN_COST);
10156   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10157 
10158   ins_encode %{
10159     __ sbfiz(as_Register($dst$$reg),
10160           as_Register($src$$reg),
10161           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10162   %}
10163 
10164   ins_pipe(ialu_reg_shift);
10165 %}
10166 
10167 // Pointer Immediate Addition
10168 // n.b. this needs to be more expensive than using an indirect memory
10169 // operand
10170 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10171   match(Set dst (AddP src1 src2));
10172 
10173   ins_cost(INSN_COST);
10174   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10175 
10176   // use opcode to indicate that this is an add not a sub
10177   opcode(0x0);
10178 
10179   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10180 
10181   ins_pipe(ialu_reg_imm);
10182 %}
10183 
10184 // Long Addition
10185 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10186 
10187   match(Set dst (AddL src1 src2));
10188 
10189   ins_cost(INSN_COST);
10190   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10191 
10192   ins_encode %{
10193     __ add(as_Register($dst$$reg),
10194            as_Register($src1$$reg),
10195            as_Register($src2$$reg));
10196   %}
10197 
10198   ins_pipe(ialu_reg_reg);
10199 %}
10200 
10201 // No constant pool entries requiredLong Immediate Addition.
10202 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10203   match(Set dst (AddL src1 src2));
10204 
10205   ins_cost(INSN_COST);
10206   format %{ &quot;add $dst, $src1, $src2&quot; %}
10207 
10208   // use opcode to indicate that this is an add not a sub
10209   opcode(0x0);
10210 
10211   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10212 
10213   ins_pipe(ialu_reg_imm);
10214 %}
10215 
10216 // Integer Subtraction
10217 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10218   match(Set dst (SubI src1 src2));
10219 
10220   ins_cost(INSN_COST);
10221   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10222 
10223   ins_encode %{
10224     __ subw(as_Register($dst$$reg),
10225             as_Register($src1$$reg),
10226             as_Register($src2$$reg));
10227   %}
10228 
10229   ins_pipe(ialu_reg_reg);
10230 %}
10231 
10232 // Immediate Subtraction
10233 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10234   match(Set dst (SubI src1 src2));
10235 
10236   ins_cost(INSN_COST);
10237   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10238 
10239   // use opcode to indicate that this is a sub not an add
10240   opcode(0x1);
10241 
10242   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10243 
10244   ins_pipe(ialu_reg_imm);
10245 %}
10246 
10247 // Long Subtraction
10248 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10249 
10250   match(Set dst (SubL src1 src2));
10251 
10252   ins_cost(INSN_COST);
10253   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10254 
10255   ins_encode %{
10256     __ sub(as_Register($dst$$reg),
10257            as_Register($src1$$reg),
10258            as_Register($src2$$reg));
10259   %}
10260 
10261   ins_pipe(ialu_reg_reg);
10262 %}
10263 
10264 // No constant pool entries requiredLong Immediate Subtraction.
10265 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10266   match(Set dst (SubL src1 src2));
10267 
10268   ins_cost(INSN_COST);
10269   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10270 
10271   // use opcode to indicate that this is a sub not an add
10272   opcode(0x1);
10273 
10274   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10275 
10276   ins_pipe(ialu_reg_imm);
10277 %}
10278 
10279 // Integer Negation (special case for sub)
10280 
10281 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10282   match(Set dst (SubI zero src));
10283 
10284   ins_cost(INSN_COST);
10285   format %{ &quot;negw $dst, $src\t# int&quot; %}
10286 
10287   ins_encode %{
10288     __ negw(as_Register($dst$$reg),
10289             as_Register($src$$reg));
10290   %}
10291 
10292   ins_pipe(ialu_reg);
10293 %}
10294 
10295 // Long Negation
10296 
10297 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10298   match(Set dst (SubL zero src));
10299 
10300   ins_cost(INSN_COST);
10301   format %{ &quot;neg $dst, $src\t# long&quot; %}
10302 
10303   ins_encode %{
10304     __ neg(as_Register($dst$$reg),
10305            as_Register($src$$reg));
10306   %}
10307 
10308   ins_pipe(ialu_reg);
10309 %}
10310 
10311 // Integer Multiply
10312 
10313 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10314   match(Set dst (MulI src1 src2));
10315 
10316   ins_cost(INSN_COST * 3);
10317   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10318 
10319   ins_encode %{
10320     __ mulw(as_Register($dst$$reg),
10321             as_Register($src1$$reg),
10322             as_Register($src2$$reg));
10323   %}
10324 
10325   ins_pipe(imul_reg_reg);
10326 %}
10327 
10328 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10329   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10330 
10331   ins_cost(INSN_COST * 3);
10332   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10333 
10334   ins_encode %{
10335     __ smull(as_Register($dst$$reg),
10336              as_Register($src1$$reg),
10337              as_Register($src2$$reg));
10338   %}
10339 
10340   ins_pipe(imul_reg_reg);
10341 %}
10342 
10343 // Long Multiply
10344 
10345 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10346   match(Set dst (MulL src1 src2));
10347 
10348   ins_cost(INSN_COST * 5);
10349   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10350 
10351   ins_encode %{
10352     __ mul(as_Register($dst$$reg),
10353            as_Register($src1$$reg),
10354            as_Register($src2$$reg));
10355   %}
10356 
10357   ins_pipe(lmul_reg_reg);
10358 %}
10359 
10360 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10361 %{
10362   match(Set dst (MulHiL src1 src2));
10363 
10364   ins_cost(INSN_COST * 7);
10365   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10366 
10367   ins_encode %{
10368     __ smulh(as_Register($dst$$reg),
10369              as_Register($src1$$reg),
10370              as_Register($src2$$reg));
10371   %}
10372 
10373   ins_pipe(lmul_reg_reg);
10374 %}
10375 
10376 // Combined Integer Multiply &amp; Add/Sub
10377 
10378 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10379   match(Set dst (AddI src3 (MulI src1 src2)));
10380 
10381   ins_cost(INSN_COST * 3);
10382   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10383 
10384   ins_encode %{
10385     __ maddw(as_Register($dst$$reg),
10386              as_Register($src1$$reg),
10387              as_Register($src2$$reg),
10388              as_Register($src3$$reg));
10389   %}
10390 
10391   ins_pipe(imac_reg_reg);
10392 %}
10393 
10394 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10395   match(Set dst (SubI src3 (MulI src1 src2)));
10396 
10397   ins_cost(INSN_COST * 3);
10398   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10399 
10400   ins_encode %{
10401     __ msubw(as_Register($dst$$reg),
10402              as_Register($src1$$reg),
10403              as_Register($src2$$reg),
10404              as_Register($src3$$reg));
10405   %}
10406 
10407   ins_pipe(imac_reg_reg);
10408 %}
10409 
10410 // Combined Integer Multiply &amp; Neg
10411 
10412 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10413   match(Set dst (MulI (SubI zero src1) src2));
10414   match(Set dst (MulI src1 (SubI zero src2)));
10415 
10416   ins_cost(INSN_COST * 3);
10417   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10418 
10419   ins_encode %{
10420     __ mnegw(as_Register($dst$$reg),
10421              as_Register($src1$$reg),
10422              as_Register($src2$$reg));
10423   %}
10424 
10425   ins_pipe(imac_reg_reg);
10426 %}
10427 
10428 // Combined Long Multiply &amp; Add/Sub
10429 
10430 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10431   match(Set dst (AddL src3 (MulL src1 src2)));
10432 
10433   ins_cost(INSN_COST * 5);
10434   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10435 
10436   ins_encode %{
10437     __ madd(as_Register($dst$$reg),
10438             as_Register($src1$$reg),
10439             as_Register($src2$$reg),
10440             as_Register($src3$$reg));
10441   %}
10442 
10443   ins_pipe(lmac_reg_reg);
10444 %}
10445 
10446 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10447   match(Set dst (SubL src3 (MulL src1 src2)));
10448 
10449   ins_cost(INSN_COST * 5);
10450   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10451 
10452   ins_encode %{
10453     __ msub(as_Register($dst$$reg),
10454             as_Register($src1$$reg),
10455             as_Register($src2$$reg),
10456             as_Register($src3$$reg));
10457   %}
10458 
10459   ins_pipe(lmac_reg_reg);
10460 %}
10461 
10462 // Combined Long Multiply &amp; Neg
10463 
10464 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10465   match(Set dst (MulL (SubL zero src1) src2));
10466   match(Set dst (MulL src1 (SubL zero src2)));
10467 
10468   ins_cost(INSN_COST * 5);
10469   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10470 
10471   ins_encode %{
10472     __ mneg(as_Register($dst$$reg),
10473             as_Register($src1$$reg),
10474             as_Register($src2$$reg));
10475   %}
10476 
10477   ins_pipe(lmac_reg_reg);
10478 %}
10479 
10480 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10481 
10482 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10483   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10484 
10485   ins_cost(INSN_COST * 3);
10486   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10487 
10488   ins_encode %{
10489     __ smaddl(as_Register($dst$$reg),
10490               as_Register($src1$$reg),
10491               as_Register($src2$$reg),
10492               as_Register($src3$$reg));
10493   %}
10494 
10495   ins_pipe(imac_reg_reg);
10496 %}
10497 
10498 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10499   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10500 
10501   ins_cost(INSN_COST * 3);
10502   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10503 
10504   ins_encode %{
10505     __ smsubl(as_Register($dst$$reg),
10506               as_Register($src1$$reg),
10507               as_Register($src2$$reg),
10508               as_Register($src3$$reg));
10509   %}
10510 
10511   ins_pipe(imac_reg_reg);
10512 %}
10513 
10514 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10515   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10516   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10517 
10518   ins_cost(INSN_COST * 3);
10519   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10520 
10521   ins_encode %{
10522     __ smnegl(as_Register($dst$$reg),
10523               as_Register($src1$$reg),
10524               as_Register($src2$$reg));
10525   %}
10526 
10527   ins_pipe(imac_reg_reg);
10528 %}
10529 
10530 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10531 
10532 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10533   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10534 
10535   ins_cost(INSN_COST * 5);
10536   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10537             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10538 
10539   ins_encode %{
10540     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10541     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10542 
10543   ins_pipe(imac_reg_reg);
10544 %}
10545 
10546 // Integer Divide
10547 
10548 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10549   match(Set dst (DivI src1 src2));
10550 
10551   ins_cost(INSN_COST * 19);
10552   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10553 
10554   ins_encode(aarch64_enc_divw(dst, src1, src2));
10555   ins_pipe(idiv_reg_reg);
10556 %}
10557 
10558 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10559   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10560   ins_cost(INSN_COST);
10561   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10562   ins_encode %{
10563     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10564   %}
10565   ins_pipe(ialu_reg_shift);
10566 %}
10567 
10568 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10569   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10570   ins_cost(INSN_COST);
10571   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10572 
10573   ins_encode %{
10574     __ addw(as_Register($dst$$reg),
10575               as_Register($src$$reg),
10576               as_Register($src$$reg),
10577               Assembler::LSR, 31);
10578   %}
10579   ins_pipe(ialu_reg);
10580 %}
10581 
10582 // Long Divide
10583 
10584 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10585   match(Set dst (DivL src1 src2));
10586 
10587   ins_cost(INSN_COST * 35);
10588   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10589 
10590   ins_encode(aarch64_enc_div(dst, src1, src2));
10591   ins_pipe(ldiv_reg_reg);
10592 %}
10593 
10594 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10595   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10596   ins_cost(INSN_COST);
10597   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10598   ins_encode %{
10599     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10600   %}
10601   ins_pipe(ialu_reg_shift);
10602 %}
10603 
10604 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10605   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10606   ins_cost(INSN_COST);
10607   format %{ &quot;add $dst, $src, $div1&quot; %}
10608 
10609   ins_encode %{
10610     __ add(as_Register($dst$$reg),
10611               as_Register($src$$reg),
10612               as_Register($src$$reg),
10613               Assembler::LSR, 63);
10614   %}
10615   ins_pipe(ialu_reg);
10616 %}
10617 
10618 // Integer Remainder
10619 
10620 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10621   match(Set dst (ModI src1 src2));
10622 
10623   ins_cost(INSN_COST * 22);
10624   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10625             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10626 
10627   ins_encode(aarch64_enc_modw(dst, src1, src2));
10628   ins_pipe(idiv_reg_reg);
10629 %}
10630 
10631 // Long Remainder
10632 
10633 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10634   match(Set dst (ModL src1 src2));
10635 
10636   ins_cost(INSN_COST * 38);
10637   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10638             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10639 
10640   ins_encode(aarch64_enc_mod(dst, src1, src2));
10641   ins_pipe(ldiv_reg_reg);
10642 %}
10643 
10644 // Integer Shifts
10645 
10646 // Shift Left Register
10647 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10648   match(Set dst (LShiftI src1 src2));
10649 
10650   ins_cost(INSN_COST * 2);
10651   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10652 
10653   ins_encode %{
10654     __ lslvw(as_Register($dst$$reg),
10655              as_Register($src1$$reg),
10656              as_Register($src2$$reg));
10657   %}
10658 
10659   ins_pipe(ialu_reg_reg_vshift);
10660 %}
10661 
10662 // Shift Left Immediate
10663 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10664   match(Set dst (LShiftI src1 src2));
10665 
10666   ins_cost(INSN_COST);
10667   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10668 
10669   ins_encode %{
10670     __ lslw(as_Register($dst$$reg),
10671             as_Register($src1$$reg),
10672             $src2$$constant &amp; 0x1f);
10673   %}
10674 
10675   ins_pipe(ialu_reg_shift);
10676 %}
10677 
10678 // Shift Right Logical Register
10679 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10680   match(Set dst (URShiftI src1 src2));
10681 
10682   ins_cost(INSN_COST * 2);
10683   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10684 
10685   ins_encode %{
10686     __ lsrvw(as_Register($dst$$reg),
10687              as_Register($src1$$reg),
10688              as_Register($src2$$reg));
10689   %}
10690 
10691   ins_pipe(ialu_reg_reg_vshift);
10692 %}
10693 
10694 // Shift Right Logical Immediate
10695 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10696   match(Set dst (URShiftI src1 src2));
10697 
10698   ins_cost(INSN_COST);
10699   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10700 
10701   ins_encode %{
10702     __ lsrw(as_Register($dst$$reg),
10703             as_Register($src1$$reg),
10704             $src2$$constant &amp; 0x1f);
10705   %}
10706 
10707   ins_pipe(ialu_reg_shift);
10708 %}
10709 
10710 // Shift Right Arithmetic Register
10711 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10712   match(Set dst (RShiftI src1 src2));
10713 
10714   ins_cost(INSN_COST * 2);
10715   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10716 
10717   ins_encode %{
10718     __ asrvw(as_Register($dst$$reg),
10719              as_Register($src1$$reg),
10720              as_Register($src2$$reg));
10721   %}
10722 
10723   ins_pipe(ialu_reg_reg_vshift);
10724 %}
10725 
10726 // Shift Right Arithmetic Immediate
10727 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10728   match(Set dst (RShiftI src1 src2));
10729 
10730   ins_cost(INSN_COST);
10731   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10732 
10733   ins_encode %{
10734     __ asrw(as_Register($dst$$reg),
10735             as_Register($src1$$reg),
10736             $src2$$constant &amp; 0x1f);
10737   %}
10738 
10739   ins_pipe(ialu_reg_shift);
10740 %}
10741 
10742 // Combined Int Mask and Right Shift (using UBFM)
10743 // TODO
10744 
10745 // Long Shifts
10746 
10747 // Shift Left Register
10748 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10749   match(Set dst (LShiftL src1 src2));
10750 
10751   ins_cost(INSN_COST * 2);
10752   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10753 
10754   ins_encode %{
10755     __ lslv(as_Register($dst$$reg),
10756             as_Register($src1$$reg),
10757             as_Register($src2$$reg));
10758   %}
10759 
10760   ins_pipe(ialu_reg_reg_vshift);
10761 %}
10762 
10763 // Shift Left Immediate
10764 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10765   match(Set dst (LShiftL src1 src2));
10766 
10767   ins_cost(INSN_COST);
10768   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10769 
10770   ins_encode %{
10771     __ lsl(as_Register($dst$$reg),
10772             as_Register($src1$$reg),
10773             $src2$$constant &amp; 0x3f);
10774   %}
10775 
10776   ins_pipe(ialu_reg_shift);
10777 %}
10778 
10779 // Shift Right Logical Register
10780 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10781   match(Set dst (URShiftL src1 src2));
10782 
10783   ins_cost(INSN_COST * 2);
10784   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10785 
10786   ins_encode %{
10787     __ lsrv(as_Register($dst$$reg),
10788             as_Register($src1$$reg),
10789             as_Register($src2$$reg));
10790   %}
10791 
10792   ins_pipe(ialu_reg_reg_vshift);
10793 %}
10794 
10795 // Shift Right Logical Immediate
10796 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10797   match(Set dst (URShiftL src1 src2));
10798 
10799   ins_cost(INSN_COST);
10800   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10801 
10802   ins_encode %{
10803     __ lsr(as_Register($dst$$reg),
10804            as_Register($src1$$reg),
10805            $src2$$constant &amp; 0x3f);
10806   %}
10807 
10808   ins_pipe(ialu_reg_shift);
10809 %}
10810 
10811 // A special-case pattern for card table stores.
10812 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10813   match(Set dst (URShiftL (CastP2X src1) src2));
10814 
10815   ins_cost(INSN_COST);
10816   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10817 
10818   ins_encode %{
10819     __ lsr(as_Register($dst$$reg),
10820            as_Register($src1$$reg),
10821            $src2$$constant &amp; 0x3f);
10822   %}
10823 
10824   ins_pipe(ialu_reg_shift);
10825 %}
10826 
10827 // Shift Right Arithmetic Register
10828 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10829   match(Set dst (RShiftL src1 src2));
10830 
10831   ins_cost(INSN_COST * 2);
10832   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10833 
10834   ins_encode %{
10835     __ asrv(as_Register($dst$$reg),
10836             as_Register($src1$$reg),
10837             as_Register($src2$$reg));
10838   %}
10839 
10840   ins_pipe(ialu_reg_reg_vshift);
10841 %}
10842 
10843 // Shift Right Arithmetic Immediate
10844 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10845   match(Set dst (RShiftL src1 src2));
10846 
10847   ins_cost(INSN_COST);
10848   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10849 
10850   ins_encode %{
10851     __ asr(as_Register($dst$$reg),
10852            as_Register($src1$$reg),
10853            $src2$$constant &amp; 0x3f);
10854   %}
10855 
10856   ins_pipe(ialu_reg_shift);
10857 %}
10858 
10859 // BEGIN This section of the file is automatically generated. Do not edit --------------
10860 
10861 instruct regL_not_reg(iRegLNoSp dst,
10862                          iRegL src1, immL_M1 m1,
10863                          rFlagsReg cr) %{
10864   match(Set dst (XorL src1 m1));
10865   ins_cost(INSN_COST);
10866   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10867 
10868   ins_encode %{
10869     __ eon(as_Register($dst$$reg),
10870               as_Register($src1$$reg),
10871               zr,
10872               Assembler::LSL, 0);
10873   %}
10874 
10875   ins_pipe(ialu_reg);
10876 %}
10877 instruct regI_not_reg(iRegINoSp dst,
10878                          iRegIorL2I src1, immI_M1 m1,
10879                          rFlagsReg cr) %{
10880   match(Set dst (XorI src1 m1));
10881   ins_cost(INSN_COST);
10882   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10883 
10884   ins_encode %{
10885     __ eonw(as_Register($dst$$reg),
10886               as_Register($src1$$reg),
10887               zr,
10888               Assembler::LSL, 0);
10889   %}
10890 
10891   ins_pipe(ialu_reg);
10892 %}
10893 
10894 instruct AndI_reg_not_reg(iRegINoSp dst,
10895                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10896                          rFlagsReg cr) %{
10897   match(Set dst (AndI src1 (XorI src2 m1)));
10898   ins_cost(INSN_COST);
10899   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10900 
10901   ins_encode %{
10902     __ bicw(as_Register($dst$$reg),
10903               as_Register($src1$$reg),
10904               as_Register($src2$$reg),
10905               Assembler::LSL, 0);
10906   %}
10907 
10908   ins_pipe(ialu_reg_reg);
10909 %}
10910 
10911 instruct AndL_reg_not_reg(iRegLNoSp dst,
10912                          iRegL src1, iRegL src2, immL_M1 m1,
10913                          rFlagsReg cr) %{
10914   match(Set dst (AndL src1 (XorL src2 m1)));
10915   ins_cost(INSN_COST);
10916   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10917 
10918   ins_encode %{
10919     __ bic(as_Register($dst$$reg),
10920               as_Register($src1$$reg),
10921               as_Register($src2$$reg),
10922               Assembler::LSL, 0);
10923   %}
10924 
10925   ins_pipe(ialu_reg_reg);
10926 %}
10927 
10928 instruct OrI_reg_not_reg(iRegINoSp dst,
10929                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10930                          rFlagsReg cr) %{
10931   match(Set dst (OrI src1 (XorI src2 m1)));
10932   ins_cost(INSN_COST);
10933   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10934 
10935   ins_encode %{
10936     __ ornw(as_Register($dst$$reg),
10937               as_Register($src1$$reg),
10938               as_Register($src2$$reg),
10939               Assembler::LSL, 0);
10940   %}
10941 
10942   ins_pipe(ialu_reg_reg);
10943 %}
10944 
10945 instruct OrL_reg_not_reg(iRegLNoSp dst,
10946                          iRegL src1, iRegL src2, immL_M1 m1,
10947                          rFlagsReg cr) %{
10948   match(Set dst (OrL src1 (XorL src2 m1)));
10949   ins_cost(INSN_COST);
10950   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10951 
10952   ins_encode %{
10953     __ orn(as_Register($dst$$reg),
10954               as_Register($src1$$reg),
10955               as_Register($src2$$reg),
10956               Assembler::LSL, 0);
10957   %}
10958 
10959   ins_pipe(ialu_reg_reg);
10960 %}
10961 
10962 instruct XorI_reg_not_reg(iRegINoSp dst,
10963                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10964                          rFlagsReg cr) %{
10965   match(Set dst (XorI m1 (XorI src2 src1)));
10966   ins_cost(INSN_COST);
10967   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10968 
10969   ins_encode %{
10970     __ eonw(as_Register($dst$$reg),
10971               as_Register($src1$$reg),
10972               as_Register($src2$$reg),
10973               Assembler::LSL, 0);
10974   %}
10975 
10976   ins_pipe(ialu_reg_reg);
10977 %}
10978 
10979 instruct XorL_reg_not_reg(iRegLNoSp dst,
10980                          iRegL src1, iRegL src2, immL_M1 m1,
10981                          rFlagsReg cr) %{
10982   match(Set dst (XorL m1 (XorL src2 src1)));
10983   ins_cost(INSN_COST);
10984   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10985 
10986   ins_encode %{
10987     __ eon(as_Register($dst$$reg),
10988               as_Register($src1$$reg),
10989               as_Register($src2$$reg),
10990               Assembler::LSL, 0);
10991   %}
10992 
10993   ins_pipe(ialu_reg_reg);
10994 %}
10995 
10996 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10997                          iRegIorL2I src1, iRegIorL2I src2,
10998                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10999   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11000   ins_cost(1.9 * INSN_COST);
11001   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11002 
11003   ins_encode %{
11004     __ bicw(as_Register($dst$$reg),
11005               as_Register($src1$$reg),
11006               as_Register($src2$$reg),
11007               Assembler::LSR,
11008               $src3$$constant &amp; 0x1f);
11009   %}
11010 
11011   ins_pipe(ialu_reg_reg_shift);
11012 %}
11013 
11014 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11015                          iRegL src1, iRegL src2,
11016                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11017   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11018   ins_cost(1.9 * INSN_COST);
11019   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11020 
11021   ins_encode %{
11022     __ bic(as_Register($dst$$reg),
11023               as_Register($src1$$reg),
11024               as_Register($src2$$reg),
11025               Assembler::LSR,
11026               $src3$$constant &amp; 0x3f);
11027   %}
11028 
11029   ins_pipe(ialu_reg_reg_shift);
11030 %}
11031 
11032 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11033                          iRegIorL2I src1, iRegIorL2I src2,
11034                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11035   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11036   ins_cost(1.9 * INSN_COST);
11037   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11038 
11039   ins_encode %{
11040     __ bicw(as_Register($dst$$reg),
11041               as_Register($src1$$reg),
11042               as_Register($src2$$reg),
11043               Assembler::ASR,
11044               $src3$$constant &amp; 0x1f);
11045   %}
11046 
11047   ins_pipe(ialu_reg_reg_shift);
11048 %}
11049 
11050 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11051                          iRegL src1, iRegL src2,
11052                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11053   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11054   ins_cost(1.9 * INSN_COST);
11055   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11056 
11057   ins_encode %{
11058     __ bic(as_Register($dst$$reg),
11059               as_Register($src1$$reg),
11060               as_Register($src2$$reg),
11061               Assembler::ASR,
11062               $src3$$constant &amp; 0x3f);
11063   %}
11064 
11065   ins_pipe(ialu_reg_reg_shift);
11066 %}
11067 
11068 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11069                          iRegIorL2I src1, iRegIorL2I src2,
11070                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11071   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11072   ins_cost(1.9 * INSN_COST);
11073   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11074 
11075   ins_encode %{
11076     __ bicw(as_Register($dst$$reg),
11077               as_Register($src1$$reg),
11078               as_Register($src2$$reg),
11079               Assembler::LSL,
11080               $src3$$constant &amp; 0x1f);
11081   %}
11082 
11083   ins_pipe(ialu_reg_reg_shift);
11084 %}
11085 
11086 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11087                          iRegL src1, iRegL src2,
11088                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11089   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11090   ins_cost(1.9 * INSN_COST);
11091   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11092 
11093   ins_encode %{
11094     __ bic(as_Register($dst$$reg),
11095               as_Register($src1$$reg),
11096               as_Register($src2$$reg),
11097               Assembler::LSL,
11098               $src3$$constant &amp; 0x3f);
11099   %}
11100 
11101   ins_pipe(ialu_reg_reg_shift);
11102 %}
11103 
11104 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11105                          iRegIorL2I src1, iRegIorL2I src2,
11106                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11107   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11108   ins_cost(1.9 * INSN_COST);
11109   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11110 
11111   ins_encode %{
11112     __ eonw(as_Register($dst$$reg),
11113               as_Register($src1$$reg),
11114               as_Register($src2$$reg),
11115               Assembler::LSR,
11116               $src3$$constant &amp; 0x1f);
11117   %}
11118 
11119   ins_pipe(ialu_reg_reg_shift);
11120 %}
11121 
11122 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11123                          iRegL src1, iRegL src2,
11124                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11125   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11126   ins_cost(1.9 * INSN_COST);
11127   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11128 
11129   ins_encode %{
11130     __ eon(as_Register($dst$$reg),
11131               as_Register($src1$$reg),
11132               as_Register($src2$$reg),
11133               Assembler::LSR,
11134               $src3$$constant &amp; 0x3f);
11135   %}
11136 
11137   ins_pipe(ialu_reg_reg_shift);
11138 %}
11139 
11140 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11141                          iRegIorL2I src1, iRegIorL2I src2,
11142                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11143   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11144   ins_cost(1.9 * INSN_COST);
11145   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11146 
11147   ins_encode %{
11148     __ eonw(as_Register($dst$$reg),
11149               as_Register($src1$$reg),
11150               as_Register($src2$$reg),
11151               Assembler::ASR,
11152               $src3$$constant &amp; 0x1f);
11153   %}
11154 
11155   ins_pipe(ialu_reg_reg_shift);
11156 %}
11157 
11158 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11159                          iRegL src1, iRegL src2,
11160                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11161   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11162   ins_cost(1.9 * INSN_COST);
11163   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11164 
11165   ins_encode %{
11166     __ eon(as_Register($dst$$reg),
11167               as_Register($src1$$reg),
11168               as_Register($src2$$reg),
11169               Assembler::ASR,
11170               $src3$$constant &amp; 0x3f);
11171   %}
11172 
11173   ins_pipe(ialu_reg_reg_shift);
11174 %}
11175 
11176 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11177                          iRegIorL2I src1, iRegIorL2I src2,
11178                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11179   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11180   ins_cost(1.9 * INSN_COST);
11181   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11182 
11183   ins_encode %{
11184     __ eonw(as_Register($dst$$reg),
11185               as_Register($src1$$reg),
11186               as_Register($src2$$reg),
11187               Assembler::LSL,
11188               $src3$$constant &amp; 0x1f);
11189   %}
11190 
11191   ins_pipe(ialu_reg_reg_shift);
11192 %}
11193 
11194 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11195                          iRegL src1, iRegL src2,
11196                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11197   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11198   ins_cost(1.9 * INSN_COST);
11199   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11200 
11201   ins_encode %{
11202     __ eon(as_Register($dst$$reg),
11203               as_Register($src1$$reg),
11204               as_Register($src2$$reg),
11205               Assembler::LSL,
11206               $src3$$constant &amp; 0x3f);
11207   %}
11208 
11209   ins_pipe(ialu_reg_reg_shift);
11210 %}
11211 
11212 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11213                          iRegIorL2I src1, iRegIorL2I src2,
11214                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11215   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11216   ins_cost(1.9 * INSN_COST);
11217   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11218 
11219   ins_encode %{
11220     __ ornw(as_Register($dst$$reg),
11221               as_Register($src1$$reg),
11222               as_Register($src2$$reg),
11223               Assembler::LSR,
11224               $src3$$constant &amp; 0x1f);
11225   %}
11226 
11227   ins_pipe(ialu_reg_reg_shift);
11228 %}
11229 
11230 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11231                          iRegL src1, iRegL src2,
11232                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11233   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11234   ins_cost(1.9 * INSN_COST);
11235   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11236 
11237   ins_encode %{
11238     __ orn(as_Register($dst$$reg),
11239               as_Register($src1$$reg),
11240               as_Register($src2$$reg),
11241               Assembler::LSR,
11242               $src3$$constant &amp; 0x3f);
11243   %}
11244 
11245   ins_pipe(ialu_reg_reg_shift);
11246 %}
11247 
11248 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11249                          iRegIorL2I src1, iRegIorL2I src2,
11250                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11251   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11252   ins_cost(1.9 * INSN_COST);
11253   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11254 
11255   ins_encode %{
11256     __ ornw(as_Register($dst$$reg),
11257               as_Register($src1$$reg),
11258               as_Register($src2$$reg),
11259               Assembler::ASR,
11260               $src3$$constant &amp; 0x1f);
11261   %}
11262 
11263   ins_pipe(ialu_reg_reg_shift);
11264 %}
11265 
11266 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11267                          iRegL src1, iRegL src2,
11268                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11269   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11270   ins_cost(1.9 * INSN_COST);
11271   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11272 
11273   ins_encode %{
11274     __ orn(as_Register($dst$$reg),
11275               as_Register($src1$$reg),
11276               as_Register($src2$$reg),
11277               Assembler::ASR,
11278               $src3$$constant &amp; 0x3f);
11279   %}
11280 
11281   ins_pipe(ialu_reg_reg_shift);
11282 %}
11283 
11284 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11285                          iRegIorL2I src1, iRegIorL2I src2,
11286                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11287   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11288   ins_cost(1.9 * INSN_COST);
11289   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11290 
11291   ins_encode %{
11292     __ ornw(as_Register($dst$$reg),
11293               as_Register($src1$$reg),
11294               as_Register($src2$$reg),
11295               Assembler::LSL,
11296               $src3$$constant &amp; 0x1f);
11297   %}
11298 
11299   ins_pipe(ialu_reg_reg_shift);
11300 %}
11301 
11302 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11303                          iRegL src1, iRegL src2,
11304                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11305   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11306   ins_cost(1.9 * INSN_COST);
11307   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11308 
11309   ins_encode %{
11310     __ orn(as_Register($dst$$reg),
11311               as_Register($src1$$reg),
11312               as_Register($src2$$reg),
11313               Assembler::LSL,
11314               $src3$$constant &amp; 0x3f);
11315   %}
11316 
11317   ins_pipe(ialu_reg_reg_shift);
11318 %}
11319 
11320 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11321                          iRegIorL2I src1, iRegIorL2I src2,
11322                          immI src3, rFlagsReg cr) %{
11323   match(Set dst (AndI src1 (URShiftI src2 src3)));
11324 
11325   ins_cost(1.9 * INSN_COST);
11326   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11327 
11328   ins_encode %{
11329     __ andw(as_Register($dst$$reg),
11330               as_Register($src1$$reg),
11331               as_Register($src2$$reg),
11332               Assembler::LSR,
11333               $src3$$constant &amp; 0x1f);
11334   %}
11335 
11336   ins_pipe(ialu_reg_reg_shift);
11337 %}
11338 
11339 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11340                          iRegL src1, iRegL src2,
11341                          immI src3, rFlagsReg cr) %{
11342   match(Set dst (AndL src1 (URShiftL src2 src3)));
11343 
11344   ins_cost(1.9 * INSN_COST);
11345   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11346 
11347   ins_encode %{
11348     __ andr(as_Register($dst$$reg),
11349               as_Register($src1$$reg),
11350               as_Register($src2$$reg),
11351               Assembler::LSR,
11352               $src3$$constant &amp; 0x3f);
11353   %}
11354 
11355   ins_pipe(ialu_reg_reg_shift);
11356 %}
11357 
11358 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11359                          iRegIorL2I src1, iRegIorL2I src2,
11360                          immI src3, rFlagsReg cr) %{
11361   match(Set dst (AndI src1 (RShiftI src2 src3)));
11362 
11363   ins_cost(1.9 * INSN_COST);
11364   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11365 
11366   ins_encode %{
11367     __ andw(as_Register($dst$$reg),
11368               as_Register($src1$$reg),
11369               as_Register($src2$$reg),
11370               Assembler::ASR,
11371               $src3$$constant &amp; 0x1f);
11372   %}
11373 
11374   ins_pipe(ialu_reg_reg_shift);
11375 %}
11376 
11377 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11378                          iRegL src1, iRegL src2,
11379                          immI src3, rFlagsReg cr) %{
11380   match(Set dst (AndL src1 (RShiftL src2 src3)));
11381 
11382   ins_cost(1.9 * INSN_COST);
11383   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11384 
11385   ins_encode %{
11386     __ andr(as_Register($dst$$reg),
11387               as_Register($src1$$reg),
11388               as_Register($src2$$reg),
11389               Assembler::ASR,
11390               $src3$$constant &amp; 0x3f);
11391   %}
11392 
11393   ins_pipe(ialu_reg_reg_shift);
11394 %}
11395 
11396 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11397                          iRegIorL2I src1, iRegIorL2I src2,
11398                          immI src3, rFlagsReg cr) %{
11399   match(Set dst (AndI src1 (LShiftI src2 src3)));
11400 
11401   ins_cost(1.9 * INSN_COST);
11402   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11403 
11404   ins_encode %{
11405     __ andw(as_Register($dst$$reg),
11406               as_Register($src1$$reg),
11407               as_Register($src2$$reg),
11408               Assembler::LSL,
11409               $src3$$constant &amp; 0x1f);
11410   %}
11411 
11412   ins_pipe(ialu_reg_reg_shift);
11413 %}
11414 
11415 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11416                          iRegL src1, iRegL src2,
11417                          immI src3, rFlagsReg cr) %{
11418   match(Set dst (AndL src1 (LShiftL src2 src3)));
11419 
11420   ins_cost(1.9 * INSN_COST);
11421   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11422 
11423   ins_encode %{
11424     __ andr(as_Register($dst$$reg),
11425               as_Register($src1$$reg),
11426               as_Register($src2$$reg),
11427               Assembler::LSL,
11428               $src3$$constant &amp; 0x3f);
11429   %}
11430 
11431   ins_pipe(ialu_reg_reg_shift);
11432 %}
11433 
11434 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11435                          iRegIorL2I src1, iRegIorL2I src2,
11436                          immI src3, rFlagsReg cr) %{
11437   match(Set dst (XorI src1 (URShiftI src2 src3)));
11438 
11439   ins_cost(1.9 * INSN_COST);
11440   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11441 
11442   ins_encode %{
11443     __ eorw(as_Register($dst$$reg),
11444               as_Register($src1$$reg),
11445               as_Register($src2$$reg),
11446               Assembler::LSR,
11447               $src3$$constant &amp; 0x1f);
11448   %}
11449 
11450   ins_pipe(ialu_reg_reg_shift);
11451 %}
11452 
11453 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11454                          iRegL src1, iRegL src2,
11455                          immI src3, rFlagsReg cr) %{
11456   match(Set dst (XorL src1 (URShiftL src2 src3)));
11457 
11458   ins_cost(1.9 * INSN_COST);
11459   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11460 
11461   ins_encode %{
11462     __ eor(as_Register($dst$$reg),
11463               as_Register($src1$$reg),
11464               as_Register($src2$$reg),
11465               Assembler::LSR,
11466               $src3$$constant &amp; 0x3f);
11467   %}
11468 
11469   ins_pipe(ialu_reg_reg_shift);
11470 %}
11471 
11472 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11473                          iRegIorL2I src1, iRegIorL2I src2,
11474                          immI src3, rFlagsReg cr) %{
11475   match(Set dst (XorI src1 (RShiftI src2 src3)));
11476 
11477   ins_cost(1.9 * INSN_COST);
11478   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11479 
11480   ins_encode %{
11481     __ eorw(as_Register($dst$$reg),
11482               as_Register($src1$$reg),
11483               as_Register($src2$$reg),
11484               Assembler::ASR,
11485               $src3$$constant &amp; 0x1f);
11486   %}
11487 
11488   ins_pipe(ialu_reg_reg_shift);
11489 %}
11490 
11491 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11492                          iRegL src1, iRegL src2,
11493                          immI src3, rFlagsReg cr) %{
11494   match(Set dst (XorL src1 (RShiftL src2 src3)));
11495 
11496   ins_cost(1.9 * INSN_COST);
11497   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11498 
11499   ins_encode %{
11500     __ eor(as_Register($dst$$reg),
11501               as_Register($src1$$reg),
11502               as_Register($src2$$reg),
11503               Assembler::ASR,
11504               $src3$$constant &amp; 0x3f);
11505   %}
11506 
11507   ins_pipe(ialu_reg_reg_shift);
11508 %}
11509 
11510 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11511                          iRegIorL2I src1, iRegIorL2I src2,
11512                          immI src3, rFlagsReg cr) %{
11513   match(Set dst (XorI src1 (LShiftI src2 src3)));
11514 
11515   ins_cost(1.9 * INSN_COST);
11516   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11517 
11518   ins_encode %{
11519     __ eorw(as_Register($dst$$reg),
11520               as_Register($src1$$reg),
11521               as_Register($src2$$reg),
11522               Assembler::LSL,
11523               $src3$$constant &amp; 0x1f);
11524   %}
11525 
11526   ins_pipe(ialu_reg_reg_shift);
11527 %}
11528 
11529 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11530                          iRegL src1, iRegL src2,
11531                          immI src3, rFlagsReg cr) %{
11532   match(Set dst (XorL src1 (LShiftL src2 src3)));
11533 
11534   ins_cost(1.9 * INSN_COST);
11535   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11536 
11537   ins_encode %{
11538     __ eor(as_Register($dst$$reg),
11539               as_Register($src1$$reg),
11540               as_Register($src2$$reg),
11541               Assembler::LSL,
11542               $src3$$constant &amp; 0x3f);
11543   %}
11544 
11545   ins_pipe(ialu_reg_reg_shift);
11546 %}
11547 
11548 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11549                          iRegIorL2I src1, iRegIorL2I src2,
11550                          immI src3, rFlagsReg cr) %{
11551   match(Set dst (OrI src1 (URShiftI src2 src3)));
11552 
11553   ins_cost(1.9 * INSN_COST);
11554   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11555 
11556   ins_encode %{
11557     __ orrw(as_Register($dst$$reg),
11558               as_Register($src1$$reg),
11559               as_Register($src2$$reg),
11560               Assembler::LSR,
11561               $src3$$constant &amp; 0x1f);
11562   %}
11563 
11564   ins_pipe(ialu_reg_reg_shift);
11565 %}
11566 
11567 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11568                          iRegL src1, iRegL src2,
11569                          immI src3, rFlagsReg cr) %{
11570   match(Set dst (OrL src1 (URShiftL src2 src3)));
11571 
11572   ins_cost(1.9 * INSN_COST);
11573   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11574 
11575   ins_encode %{
11576     __ orr(as_Register($dst$$reg),
11577               as_Register($src1$$reg),
11578               as_Register($src2$$reg),
11579               Assembler::LSR,
11580               $src3$$constant &amp; 0x3f);
11581   %}
11582 
11583   ins_pipe(ialu_reg_reg_shift);
11584 %}
11585 
11586 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11587                          iRegIorL2I src1, iRegIorL2I src2,
11588                          immI src3, rFlagsReg cr) %{
11589   match(Set dst (OrI src1 (RShiftI src2 src3)));
11590 
11591   ins_cost(1.9 * INSN_COST);
11592   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11593 
11594   ins_encode %{
11595     __ orrw(as_Register($dst$$reg),
11596               as_Register($src1$$reg),
11597               as_Register($src2$$reg),
11598               Assembler::ASR,
11599               $src3$$constant &amp; 0x1f);
11600   %}
11601 
11602   ins_pipe(ialu_reg_reg_shift);
11603 %}
11604 
11605 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11606                          iRegL src1, iRegL src2,
11607                          immI src3, rFlagsReg cr) %{
11608   match(Set dst (OrL src1 (RShiftL src2 src3)));
11609 
11610   ins_cost(1.9 * INSN_COST);
11611   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11612 
11613   ins_encode %{
11614     __ orr(as_Register($dst$$reg),
11615               as_Register($src1$$reg),
11616               as_Register($src2$$reg),
11617               Assembler::ASR,
11618               $src3$$constant &amp; 0x3f);
11619   %}
11620 
11621   ins_pipe(ialu_reg_reg_shift);
11622 %}
11623 
11624 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11625                          iRegIorL2I src1, iRegIorL2I src2,
11626                          immI src3, rFlagsReg cr) %{
11627   match(Set dst (OrI src1 (LShiftI src2 src3)));
11628 
11629   ins_cost(1.9 * INSN_COST);
11630   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11631 
11632   ins_encode %{
11633     __ orrw(as_Register($dst$$reg),
11634               as_Register($src1$$reg),
11635               as_Register($src2$$reg),
11636               Assembler::LSL,
11637               $src3$$constant &amp; 0x1f);
11638   %}
11639 
11640   ins_pipe(ialu_reg_reg_shift);
11641 %}
11642 
11643 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11644                          iRegL src1, iRegL src2,
11645                          immI src3, rFlagsReg cr) %{
11646   match(Set dst (OrL src1 (LShiftL src2 src3)));
11647 
11648   ins_cost(1.9 * INSN_COST);
11649   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11650 
11651   ins_encode %{
11652     __ orr(as_Register($dst$$reg),
11653               as_Register($src1$$reg),
11654               as_Register($src2$$reg),
11655               Assembler::LSL,
11656               $src3$$constant &amp; 0x3f);
11657   %}
11658 
11659   ins_pipe(ialu_reg_reg_shift);
11660 %}
11661 
11662 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11663                          iRegIorL2I src1, iRegIorL2I src2,
11664                          immI src3, rFlagsReg cr) %{
11665   match(Set dst (AddI src1 (URShiftI src2 src3)));
11666 
11667   ins_cost(1.9 * INSN_COST);
11668   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11669 
11670   ins_encode %{
11671     __ addw(as_Register($dst$$reg),
11672               as_Register($src1$$reg),
11673               as_Register($src2$$reg),
11674               Assembler::LSR,
11675               $src3$$constant &amp; 0x1f);
11676   %}
11677 
11678   ins_pipe(ialu_reg_reg_shift);
11679 %}
11680 
11681 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11682                          iRegL src1, iRegL src2,
11683                          immI src3, rFlagsReg cr) %{
11684   match(Set dst (AddL src1 (URShiftL src2 src3)));
11685 
11686   ins_cost(1.9 * INSN_COST);
11687   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11688 
11689   ins_encode %{
11690     __ add(as_Register($dst$$reg),
11691               as_Register($src1$$reg),
11692               as_Register($src2$$reg),
11693               Assembler::LSR,
11694               $src3$$constant &amp; 0x3f);
11695   %}
11696 
11697   ins_pipe(ialu_reg_reg_shift);
11698 %}
11699 
11700 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11701                          iRegIorL2I src1, iRegIorL2I src2,
11702                          immI src3, rFlagsReg cr) %{
11703   match(Set dst (AddI src1 (RShiftI src2 src3)));
11704 
11705   ins_cost(1.9 * INSN_COST);
11706   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11707 
11708   ins_encode %{
11709     __ addw(as_Register($dst$$reg),
11710               as_Register($src1$$reg),
11711               as_Register($src2$$reg),
11712               Assembler::ASR,
11713               $src3$$constant &amp; 0x1f);
11714   %}
11715 
11716   ins_pipe(ialu_reg_reg_shift);
11717 %}
11718 
11719 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11720                          iRegL src1, iRegL src2,
11721                          immI src3, rFlagsReg cr) %{
11722   match(Set dst (AddL src1 (RShiftL src2 src3)));
11723 
11724   ins_cost(1.9 * INSN_COST);
11725   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11726 
11727   ins_encode %{
11728     __ add(as_Register($dst$$reg),
11729               as_Register($src1$$reg),
11730               as_Register($src2$$reg),
11731               Assembler::ASR,
11732               $src3$$constant &amp; 0x3f);
11733   %}
11734 
11735   ins_pipe(ialu_reg_reg_shift);
11736 %}
11737 
11738 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11739                          iRegIorL2I src1, iRegIorL2I src2,
11740                          immI src3, rFlagsReg cr) %{
11741   match(Set dst (AddI src1 (LShiftI src2 src3)));
11742 
11743   ins_cost(1.9 * INSN_COST);
11744   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11745 
11746   ins_encode %{
11747     __ addw(as_Register($dst$$reg),
11748               as_Register($src1$$reg),
11749               as_Register($src2$$reg),
11750               Assembler::LSL,
11751               $src3$$constant &amp; 0x1f);
11752   %}
11753 
11754   ins_pipe(ialu_reg_reg_shift);
11755 %}
11756 
11757 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11758                          iRegL src1, iRegL src2,
11759                          immI src3, rFlagsReg cr) %{
11760   match(Set dst (AddL src1 (LShiftL src2 src3)));
11761 
11762   ins_cost(1.9 * INSN_COST);
11763   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11764 
11765   ins_encode %{
11766     __ add(as_Register($dst$$reg),
11767               as_Register($src1$$reg),
11768               as_Register($src2$$reg),
11769               Assembler::LSL,
11770               $src3$$constant &amp; 0x3f);
11771   %}
11772 
11773   ins_pipe(ialu_reg_reg_shift);
11774 %}
11775 
11776 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11777                          iRegIorL2I src1, iRegIorL2I src2,
11778                          immI src3, rFlagsReg cr) %{
11779   match(Set dst (SubI src1 (URShiftI src2 src3)));
11780 
11781   ins_cost(1.9 * INSN_COST);
11782   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11783 
11784   ins_encode %{
11785     __ subw(as_Register($dst$$reg),
11786               as_Register($src1$$reg),
11787               as_Register($src2$$reg),
11788               Assembler::LSR,
11789               $src3$$constant &amp; 0x1f);
11790   %}
11791 
11792   ins_pipe(ialu_reg_reg_shift);
11793 %}
11794 
11795 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11796                          iRegL src1, iRegL src2,
11797                          immI src3, rFlagsReg cr) %{
11798   match(Set dst (SubL src1 (URShiftL src2 src3)));
11799 
11800   ins_cost(1.9 * INSN_COST);
11801   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11802 
11803   ins_encode %{
11804     __ sub(as_Register($dst$$reg),
11805               as_Register($src1$$reg),
11806               as_Register($src2$$reg),
11807               Assembler::LSR,
11808               $src3$$constant &amp; 0x3f);
11809   %}
11810 
11811   ins_pipe(ialu_reg_reg_shift);
11812 %}
11813 
11814 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11815                          iRegIorL2I src1, iRegIorL2I src2,
11816                          immI src3, rFlagsReg cr) %{
11817   match(Set dst (SubI src1 (RShiftI src2 src3)));
11818 
11819   ins_cost(1.9 * INSN_COST);
11820   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11821 
11822   ins_encode %{
11823     __ subw(as_Register($dst$$reg),
11824               as_Register($src1$$reg),
11825               as_Register($src2$$reg),
11826               Assembler::ASR,
11827               $src3$$constant &amp; 0x1f);
11828   %}
11829 
11830   ins_pipe(ialu_reg_reg_shift);
11831 %}
11832 
11833 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11834                          iRegL src1, iRegL src2,
11835                          immI src3, rFlagsReg cr) %{
11836   match(Set dst (SubL src1 (RShiftL src2 src3)));
11837 
11838   ins_cost(1.9 * INSN_COST);
11839   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11840 
11841   ins_encode %{
11842     __ sub(as_Register($dst$$reg),
11843               as_Register($src1$$reg),
11844               as_Register($src2$$reg),
11845               Assembler::ASR,
11846               $src3$$constant &amp; 0x3f);
11847   %}
11848 
11849   ins_pipe(ialu_reg_reg_shift);
11850 %}
11851 
11852 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11853                          iRegIorL2I src1, iRegIorL2I src2,
11854                          immI src3, rFlagsReg cr) %{
11855   match(Set dst (SubI src1 (LShiftI src2 src3)));
11856 
11857   ins_cost(1.9 * INSN_COST);
11858   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11859 
11860   ins_encode %{
11861     __ subw(as_Register($dst$$reg),
11862               as_Register($src1$$reg),
11863               as_Register($src2$$reg),
11864               Assembler::LSL,
11865               $src3$$constant &amp; 0x1f);
11866   %}
11867 
11868   ins_pipe(ialu_reg_reg_shift);
11869 %}
11870 
11871 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11872                          iRegL src1, iRegL src2,
11873                          immI src3, rFlagsReg cr) %{
11874   match(Set dst (SubL src1 (LShiftL src2 src3)));
11875 
11876   ins_cost(1.9 * INSN_COST);
11877   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11878 
11879   ins_encode %{
11880     __ sub(as_Register($dst$$reg),
11881               as_Register($src1$$reg),
11882               as_Register($src2$$reg),
11883               Assembler::LSL,
11884               $src3$$constant &amp; 0x3f);
11885   %}
11886 
11887   ins_pipe(ialu_reg_reg_shift);
11888 %}
11889 
11890 
11891 
11892 // Shift Left followed by Shift Right.
11893 // This idiom is used by the compiler for the i2b bytecode etc.
11894 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11895 %{
11896   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11897   ins_cost(INSN_COST * 2);
11898   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11899   ins_encode %{
11900     int lshift = $lshift_count$$constant &amp; 63;
11901     int rshift = $rshift_count$$constant &amp; 63;
11902     int s = 63 - lshift;
11903     int r = (rshift - lshift) &amp; 63;
11904     __ sbfm(as_Register($dst$$reg),
11905             as_Register($src$$reg),
11906             r, s);
11907   %}
11908 
11909   ins_pipe(ialu_reg_shift);
11910 %}
11911 
11912 // Shift Left followed by Shift Right.
11913 // This idiom is used by the compiler for the i2b bytecode etc.
11914 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11915 %{
11916   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11917   ins_cost(INSN_COST * 2);
11918   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11919   ins_encode %{
11920     int lshift = $lshift_count$$constant &amp; 31;
11921     int rshift = $rshift_count$$constant &amp; 31;
11922     int s = 31 - lshift;
11923     int r = (rshift - lshift) &amp; 31;
11924     __ sbfmw(as_Register($dst$$reg),
11925             as_Register($src$$reg),
11926             r, s);
11927   %}
11928 
11929   ins_pipe(ialu_reg_shift);
11930 %}
11931 
11932 // Shift Left followed by Shift Right.
11933 // This idiom is used by the compiler for the i2b bytecode etc.
11934 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11935 %{
11936   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11937   ins_cost(INSN_COST * 2);
11938   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11939   ins_encode %{
11940     int lshift = $lshift_count$$constant &amp; 63;
11941     int rshift = $rshift_count$$constant &amp; 63;
11942     int s = 63 - lshift;
11943     int r = (rshift - lshift) &amp; 63;
11944     __ ubfm(as_Register($dst$$reg),
11945             as_Register($src$$reg),
11946             r, s);
11947   %}
11948 
11949   ins_pipe(ialu_reg_shift);
11950 %}
11951 
11952 // Shift Left followed by Shift Right.
11953 // This idiom is used by the compiler for the i2b bytecode etc.
11954 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11955 %{
11956   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11957   ins_cost(INSN_COST * 2);
11958   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11959   ins_encode %{
11960     int lshift = $lshift_count$$constant &amp; 31;
11961     int rshift = $rshift_count$$constant &amp; 31;
11962     int s = 31 - lshift;
11963     int r = (rshift - lshift) &amp; 31;
11964     __ ubfmw(as_Register($dst$$reg),
11965             as_Register($src$$reg),
11966             r, s);
11967   %}
11968 
11969   ins_pipe(ialu_reg_shift);
11970 %}
11971 // Bitfield extract with shift &amp; mask
11972 
11973 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11974 %{
11975   match(Set dst (AndI (URShiftI src rshift) mask));
11976   // Make sure we are not going to exceed what ubfxw can do.
11977   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11978 
11979   ins_cost(INSN_COST);
11980   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11981   ins_encode %{
11982     int rshift = $rshift$$constant &amp; 31;
11983     long mask = $mask$$constant;
11984     int width = exact_log2(mask+1);
11985     __ ubfxw(as_Register($dst$$reg),
11986             as_Register($src$$reg), rshift, width);
11987   %}
11988   ins_pipe(ialu_reg_shift);
11989 %}
11990 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
11991 %{
11992   match(Set dst (AndL (URShiftL src rshift) mask));
11993   // Make sure we are not going to exceed what ubfx can do.
11994   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11995 
11996   ins_cost(INSN_COST);
11997   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11998   ins_encode %{
11999     int rshift = $rshift$$constant &amp; 63;
12000     long mask = $mask$$constant;
12001     int width = exact_log2_long(mask+1);
12002     __ ubfx(as_Register($dst$$reg),
12003             as_Register($src$$reg), rshift, width);
12004   %}
12005   ins_pipe(ialu_reg_shift);
12006 %}
12007 
12008 // We can use ubfx when extending an And with a mask when we know mask
12009 // is positive.  We know that because immI_bitmask guarantees it.
12010 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12011 %{
12012   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12013   // Make sure we are not going to exceed what ubfxw can do.
12014   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12015 
12016   ins_cost(INSN_COST * 2);
12017   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12018   ins_encode %{
12019     int rshift = $rshift$$constant &amp; 31;
12020     long mask = $mask$$constant;
12021     int width = exact_log2(mask+1);
12022     __ ubfx(as_Register($dst$$reg),
12023             as_Register($src$$reg), rshift, width);
12024   %}
12025   ins_pipe(ialu_reg_shift);
12026 %}
12027 
12028 // We can use ubfiz when masking by a positive number and then left shifting the result.
12029 // We know that the mask is positive because immI_bitmask guarantees it.
12030 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12031 %{
12032   match(Set dst (LShiftI (AndI src mask) lshift));
12033   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12034 
12035   ins_cost(INSN_COST);
12036   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12037   ins_encode %{
12038     int lshift = $lshift$$constant &amp; 31;
12039     long mask = $mask$$constant;
12040     int width = exact_log2(mask+1);
12041     __ ubfizw(as_Register($dst$$reg),
12042           as_Register($src$$reg), lshift, width);
12043   %}
12044   ins_pipe(ialu_reg_shift);
12045 %}
12046 // We can use ubfiz when masking by a positive number and then left shifting the result.
12047 // We know that the mask is positive because immL_bitmask guarantees it.
12048 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12049 %{
12050   match(Set dst (LShiftL (AndL src mask) lshift));
12051   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12052 
12053   ins_cost(INSN_COST);
12054   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12055   ins_encode %{
12056     int lshift = $lshift$$constant &amp; 63;
12057     long mask = $mask$$constant;
12058     int width = exact_log2_long(mask+1);
12059     __ ubfiz(as_Register($dst$$reg),
12060           as_Register($src$$reg), lshift, width);
12061   %}
12062   ins_pipe(ialu_reg_shift);
12063 %}
12064 
12065 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12066 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12067 %{
12068   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12069   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12070 
12071   ins_cost(INSN_COST);
12072   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12073   ins_encode %{
12074     int lshift = $lshift$$constant &amp; 63;
12075     long mask = $mask$$constant;
12076     int width = exact_log2(mask+1);
12077     __ ubfiz(as_Register($dst$$reg),
12078              as_Register($src$$reg), lshift, width);
12079   %}
12080   ins_pipe(ialu_reg_shift);
12081 %}
12082 
12083 // Rotations
12084 
12085 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12086 %{
12087   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12088   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12089 
12090   ins_cost(INSN_COST);
12091   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12092 
12093   ins_encode %{
12094     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12095             $rshift$$constant &amp; 63);
12096   %}
12097   ins_pipe(ialu_reg_reg_extr);
12098 %}
12099 
12100 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12101 %{
12102   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12103   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12104 
12105   ins_cost(INSN_COST);
12106   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12107 
12108   ins_encode %{
12109     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12110             $rshift$$constant &amp; 31);
12111   %}
12112   ins_pipe(ialu_reg_reg_extr);
12113 %}
12114 
12115 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12116 %{
12117   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12118   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12119 
12120   ins_cost(INSN_COST);
12121   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12122 
12123   ins_encode %{
12124     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12125             $rshift$$constant &amp; 63);
12126   %}
12127   ins_pipe(ialu_reg_reg_extr);
12128 %}
12129 
12130 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12131 %{
12132   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12133   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12134 
12135   ins_cost(INSN_COST);
12136   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12137 
12138   ins_encode %{
12139     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12140             $rshift$$constant &amp; 31);
12141   %}
12142   ins_pipe(ialu_reg_reg_extr);
12143 %}
12144 
12145 
12146 // rol expander
12147 
12148 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12149 %{
12150   effect(DEF dst, USE src, USE shift);
12151 
12152   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12153   ins_cost(INSN_COST * 3);
12154   ins_encode %{
12155     __ subw(rscratch1, zr, as_Register($shift$$reg));
12156     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12157             rscratch1);
12158     %}
12159   ins_pipe(ialu_reg_reg_vshift);
12160 %}
12161 
12162 // rol expander
12163 
12164 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12165 %{
12166   effect(DEF dst, USE src, USE shift);
12167 
12168   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12169   ins_cost(INSN_COST * 3);
12170   ins_encode %{
12171     __ subw(rscratch1, zr, as_Register($shift$$reg));
12172     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12173             rscratch1);
12174     %}
12175   ins_pipe(ialu_reg_reg_vshift);
12176 %}
12177 
12178 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12179 %{
12180   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12181 
12182   expand %{
12183     rolL_rReg(dst, src, shift, cr);
12184   %}
12185 %}
12186 
12187 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12188 %{
12189   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12190 
12191   expand %{
12192     rolL_rReg(dst, src, shift, cr);
12193   %}
12194 %}
12195 
12196 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12197 %{
12198   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12199 
12200   expand %{
12201     rolI_rReg(dst, src, shift, cr);
12202   %}
12203 %}
12204 
12205 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12206 %{
12207   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12208 
12209   expand %{
12210     rolI_rReg(dst, src, shift, cr);
12211   %}
12212 %}
12213 
12214 // ror expander
12215 
12216 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12217 %{
12218   effect(DEF dst, USE src, USE shift);
12219 
12220   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12221   ins_cost(INSN_COST);
12222   ins_encode %{
12223     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12224             as_Register($shift$$reg));
12225     %}
12226   ins_pipe(ialu_reg_reg_vshift);
12227 %}
12228 
12229 // ror expander
12230 
12231 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12232 %{
12233   effect(DEF dst, USE src, USE shift);
12234 
12235   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12236   ins_cost(INSN_COST);
12237   ins_encode %{
12238     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12239             as_Register($shift$$reg));
12240     %}
12241   ins_pipe(ialu_reg_reg_vshift);
12242 %}
12243 
12244 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12245 %{
12246   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12247 
12248   expand %{
12249     rorL_rReg(dst, src, shift, cr);
12250   %}
12251 %}
12252 
12253 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12254 %{
12255   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12256 
12257   expand %{
12258     rorL_rReg(dst, src, shift, cr);
12259   %}
12260 %}
12261 
12262 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12263 %{
12264   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12265 
12266   expand %{
12267     rorI_rReg(dst, src, shift, cr);
12268   %}
12269 %}
12270 
12271 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12272 %{
12273   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12274 
12275   expand %{
12276     rorI_rReg(dst, src, shift, cr);
12277   %}
12278 %}
12279 
12280 // Add/subtract (extended)
12281 
12282 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12283 %{
12284   match(Set dst (AddL src1 (ConvI2L src2)));
12285   ins_cost(INSN_COST);
12286   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12287 
12288    ins_encode %{
12289      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12290             as_Register($src2$$reg), ext::sxtw);
12291    %}
12292   ins_pipe(ialu_reg_reg);
12293 %};
12294 
12295 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12296 %{
12297   match(Set dst (SubL src1 (ConvI2L src2)));
12298   ins_cost(INSN_COST);
12299   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12300 
12301    ins_encode %{
12302      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12303             as_Register($src2$$reg), ext::sxtw);
12304    %}
12305   ins_pipe(ialu_reg_reg);
12306 %};
12307 
12308 
12309 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12310 %{
12311   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12312   ins_cost(INSN_COST);
12313   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12314 
12315    ins_encode %{
12316      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12317             as_Register($src2$$reg), ext::sxth);
12318    %}
12319   ins_pipe(ialu_reg_reg);
12320 %}
12321 
12322 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12323 %{
12324   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12325   ins_cost(INSN_COST);
12326   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12327 
12328    ins_encode %{
12329      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12330             as_Register($src2$$reg), ext::sxtb);
12331    %}
12332   ins_pipe(ialu_reg_reg);
12333 %}
12334 
12335 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12336 %{
12337   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12338   ins_cost(INSN_COST);
12339   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12340 
12341    ins_encode %{
12342      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12343             as_Register($src2$$reg), ext::uxtb);
12344    %}
12345   ins_pipe(ialu_reg_reg);
12346 %}
12347 
12348 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12349 %{
12350   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12351   ins_cost(INSN_COST);
12352   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12353 
12354    ins_encode %{
12355      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12356             as_Register($src2$$reg), ext::sxth);
12357    %}
12358   ins_pipe(ialu_reg_reg);
12359 %}
12360 
12361 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12362 %{
12363   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12364   ins_cost(INSN_COST);
12365   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12366 
12367    ins_encode %{
12368      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12369             as_Register($src2$$reg), ext::sxtw);
12370    %}
12371   ins_pipe(ialu_reg_reg);
12372 %}
12373 
12374 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12375 %{
12376   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12377   ins_cost(INSN_COST);
12378   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12379 
12380    ins_encode %{
12381      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12382             as_Register($src2$$reg), ext::sxtb);
12383    %}
12384   ins_pipe(ialu_reg_reg);
12385 %}
12386 
12387 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12388 %{
12389   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12390   ins_cost(INSN_COST);
12391   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12392 
12393    ins_encode %{
12394      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12395             as_Register($src2$$reg), ext::uxtb);
12396    %}
12397   ins_pipe(ialu_reg_reg);
12398 %}
12399 
12400 
12401 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12402 %{
12403   match(Set dst (AddI src1 (AndI src2 mask)));
12404   ins_cost(INSN_COST);
12405   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12406 
12407    ins_encode %{
12408      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12409             as_Register($src2$$reg), ext::uxtb);
12410    %}
12411   ins_pipe(ialu_reg_reg);
12412 %}
12413 
12414 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12415 %{
12416   match(Set dst (AddI src1 (AndI src2 mask)));
12417   ins_cost(INSN_COST);
12418   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12419 
12420    ins_encode %{
12421      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12422             as_Register($src2$$reg), ext::uxth);
12423    %}
12424   ins_pipe(ialu_reg_reg);
12425 %}
12426 
12427 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12428 %{
12429   match(Set dst (AddL src1 (AndL src2 mask)));
12430   ins_cost(INSN_COST);
12431   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12432 
12433    ins_encode %{
12434      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12435             as_Register($src2$$reg), ext::uxtb);
12436    %}
12437   ins_pipe(ialu_reg_reg);
12438 %}
12439 
12440 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12441 %{
12442   match(Set dst (AddL src1 (AndL src2 mask)));
12443   ins_cost(INSN_COST);
12444   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12445 
12446    ins_encode %{
12447      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12448             as_Register($src2$$reg), ext::uxth);
12449    %}
12450   ins_pipe(ialu_reg_reg);
12451 %}
12452 
12453 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12454 %{
12455   match(Set dst (AddL src1 (AndL src2 mask)));
12456   ins_cost(INSN_COST);
12457   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12458 
12459    ins_encode %{
12460      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12461             as_Register($src2$$reg), ext::uxtw);
12462    %}
12463   ins_pipe(ialu_reg_reg);
12464 %}
12465 
12466 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12467 %{
12468   match(Set dst (SubI src1 (AndI src2 mask)));
12469   ins_cost(INSN_COST);
12470   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12471 
12472    ins_encode %{
12473      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12474             as_Register($src2$$reg), ext::uxtb);
12475    %}
12476   ins_pipe(ialu_reg_reg);
12477 %}
12478 
12479 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12480 %{
12481   match(Set dst (SubI src1 (AndI src2 mask)));
12482   ins_cost(INSN_COST);
12483   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12484 
12485    ins_encode %{
12486      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12487             as_Register($src2$$reg), ext::uxth);
12488    %}
12489   ins_pipe(ialu_reg_reg);
12490 %}
12491 
12492 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12493 %{
12494   match(Set dst (SubL src1 (AndL src2 mask)));
12495   ins_cost(INSN_COST);
12496   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12497 
12498    ins_encode %{
12499      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12500             as_Register($src2$$reg), ext::uxtb);
12501    %}
12502   ins_pipe(ialu_reg_reg);
12503 %}
12504 
12505 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12506 %{
12507   match(Set dst (SubL src1 (AndL src2 mask)));
12508   ins_cost(INSN_COST);
12509   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12510 
12511    ins_encode %{
12512      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12513             as_Register($src2$$reg), ext::uxth);
12514    %}
12515   ins_pipe(ialu_reg_reg);
12516 %}
12517 
12518 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12519 %{
12520   match(Set dst (SubL src1 (AndL src2 mask)));
12521   ins_cost(INSN_COST);
12522   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12523 
12524    ins_encode %{
12525      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12526             as_Register($src2$$reg), ext::uxtw);
12527    %}
12528   ins_pipe(ialu_reg_reg);
12529 %}
12530 
12531 
12532 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12533 %{
12534   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12535   ins_cost(1.9 * INSN_COST);
12536   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12537 
12538    ins_encode %{
12539      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12540             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12541    %}
12542   ins_pipe(ialu_reg_reg_shift);
12543 %}
12544 
12545 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12546 %{
12547   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12548   ins_cost(1.9 * INSN_COST);
12549   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12550 
12551    ins_encode %{
12552      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12553             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12554    %}
12555   ins_pipe(ialu_reg_reg_shift);
12556 %}
12557 
12558 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12559 %{
12560   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12561   ins_cost(1.9 * INSN_COST);
12562   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12563 
12564    ins_encode %{
12565      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12566             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12567    %}
12568   ins_pipe(ialu_reg_reg_shift);
12569 %}
12570 
12571 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12572 %{
12573   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12574   ins_cost(1.9 * INSN_COST);
12575   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12576 
12577    ins_encode %{
12578      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12579             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12580    %}
12581   ins_pipe(ialu_reg_reg_shift);
12582 %}
12583 
12584 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12585 %{
12586   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12587   ins_cost(1.9 * INSN_COST);
12588   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12589 
12590    ins_encode %{
12591      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12592             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12593    %}
12594   ins_pipe(ialu_reg_reg_shift);
12595 %}
12596 
12597 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12598 %{
12599   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12600   ins_cost(1.9 * INSN_COST);
12601   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12602 
12603    ins_encode %{
12604      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12605             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12606    %}
12607   ins_pipe(ialu_reg_reg_shift);
12608 %}
12609 
12610 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12611 %{
12612   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12613   ins_cost(1.9 * INSN_COST);
12614   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12615 
12616    ins_encode %{
12617      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12618             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12619    %}
12620   ins_pipe(ialu_reg_reg_shift);
12621 %}
12622 
12623 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12624 %{
12625   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12626   ins_cost(1.9 * INSN_COST);
12627   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12628 
12629    ins_encode %{
12630      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12631             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12632    %}
12633   ins_pipe(ialu_reg_reg_shift);
12634 %}
12635 
12636 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12637 %{
12638   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12639   ins_cost(1.9 * INSN_COST);
12640   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12641 
12642    ins_encode %{
12643      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12644             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12645    %}
12646   ins_pipe(ialu_reg_reg_shift);
12647 %}
12648 
12649 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12650 %{
12651   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12652   ins_cost(1.9 * INSN_COST);
12653   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12654 
12655    ins_encode %{
12656      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12657             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12658    %}
12659   ins_pipe(ialu_reg_reg_shift);
12660 %}
12661 
12662 
12663 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12664 %{
12665   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12666   ins_cost(1.9 * INSN_COST);
12667   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12668 
12669    ins_encode %{
12670      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12671             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12672    %}
12673   ins_pipe(ialu_reg_reg_shift);
12674 %};
12675 
12676 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12677 %{
12678   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12679   ins_cost(1.9 * INSN_COST);
12680   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12681 
12682    ins_encode %{
12683      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12684             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12685    %}
12686   ins_pipe(ialu_reg_reg_shift);
12687 %};
12688 
12689 
12690 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12691 %{
12692   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12693   ins_cost(1.9 * INSN_COST);
12694   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12695 
12696    ins_encode %{
12697      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12698             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12699    %}
12700   ins_pipe(ialu_reg_reg_shift);
12701 %}
12702 
12703 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12704 %{
12705   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12708 
12709    ins_encode %{
12710      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %}
12715 
12716 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12717 %{
12718   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12719   ins_cost(1.9 * INSN_COST);
12720   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12721 
12722    ins_encode %{
12723      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12724             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12725    %}
12726   ins_pipe(ialu_reg_reg_shift);
12727 %}
12728 
12729 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12730 %{
12731   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12732   ins_cost(1.9 * INSN_COST);
12733   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12734 
12735    ins_encode %{
12736      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12737             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12738    %}
12739   ins_pipe(ialu_reg_reg_shift);
12740 %}
12741 
12742 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12743 %{
12744   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12745   ins_cost(1.9 * INSN_COST);
12746   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12747 
12748    ins_encode %{
12749      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12750             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12751    %}
12752   ins_pipe(ialu_reg_reg_shift);
12753 %}
12754 
12755 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12756 %{
12757   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12758   ins_cost(1.9 * INSN_COST);
12759   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12760 
12761    ins_encode %{
12762      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12763             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12764    %}
12765   ins_pipe(ialu_reg_reg_shift);
12766 %}
12767 
12768 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12769 %{
12770   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12771   ins_cost(1.9 * INSN_COST);
12772   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12773 
12774    ins_encode %{
12775      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12776             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12777    %}
12778   ins_pipe(ialu_reg_reg_shift);
12779 %}
12780 
12781 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12782 %{
12783   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12784   ins_cost(1.9 * INSN_COST);
12785   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12786 
12787    ins_encode %{
12788      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12789             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12790    %}
12791   ins_pipe(ialu_reg_reg_shift);
12792 %}
12793 
12794 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12795 %{
12796   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12797   ins_cost(1.9 * INSN_COST);
12798   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12799 
12800    ins_encode %{
12801      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12802             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12803    %}
12804   ins_pipe(ialu_reg_reg_shift);
12805 %}
12806 
12807 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12808 %{
12809   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12810   ins_cost(1.9 * INSN_COST);
12811   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12812 
12813    ins_encode %{
12814      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12815             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12816    %}
12817   ins_pipe(ialu_reg_reg_shift);
12818 %}
12819 // END This section of the file is automatically generated. Do not edit --------------
12820 
12821 // ============================================================================
12822 // Floating Point Arithmetic Instructions
12823 
12824 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12825   match(Set dst (AddF src1 src2));
12826 
12827   ins_cost(INSN_COST * 5);
12828   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12829 
12830   ins_encode %{
12831     __ fadds(as_FloatRegister($dst$$reg),
12832              as_FloatRegister($src1$$reg),
12833              as_FloatRegister($src2$$reg));
12834   %}
12835 
12836   ins_pipe(fp_dop_reg_reg_s);
12837 %}
12838 
12839 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12840   match(Set dst (AddD src1 src2));
12841 
12842   ins_cost(INSN_COST * 5);
12843   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12844 
12845   ins_encode %{
12846     __ faddd(as_FloatRegister($dst$$reg),
12847              as_FloatRegister($src1$$reg),
12848              as_FloatRegister($src2$$reg));
12849   %}
12850 
12851   ins_pipe(fp_dop_reg_reg_d);
12852 %}
12853 
12854 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12855   match(Set dst (SubF src1 src2));
12856 
12857   ins_cost(INSN_COST * 5);
12858   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12859 
12860   ins_encode %{
12861     __ fsubs(as_FloatRegister($dst$$reg),
12862              as_FloatRegister($src1$$reg),
12863              as_FloatRegister($src2$$reg));
12864   %}
12865 
12866   ins_pipe(fp_dop_reg_reg_s);
12867 %}
12868 
12869 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12870   match(Set dst (SubD src1 src2));
12871 
12872   ins_cost(INSN_COST * 5);
12873   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12874 
12875   ins_encode %{
12876     __ fsubd(as_FloatRegister($dst$$reg),
12877              as_FloatRegister($src1$$reg),
12878              as_FloatRegister($src2$$reg));
12879   %}
12880 
12881   ins_pipe(fp_dop_reg_reg_d);
12882 %}
12883 
12884 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12885   match(Set dst (MulF src1 src2));
12886 
12887   ins_cost(INSN_COST * 6);
12888   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12889 
12890   ins_encode %{
12891     __ fmuls(as_FloatRegister($dst$$reg),
12892              as_FloatRegister($src1$$reg),
12893              as_FloatRegister($src2$$reg));
12894   %}
12895 
12896   ins_pipe(fp_dop_reg_reg_s);
12897 %}
12898 
12899 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12900   match(Set dst (MulD src1 src2));
12901 
12902   ins_cost(INSN_COST * 6);
12903   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12904 
12905   ins_encode %{
12906     __ fmuld(as_FloatRegister($dst$$reg),
12907              as_FloatRegister($src1$$reg),
12908              as_FloatRegister($src2$$reg));
12909   %}
12910 
12911   ins_pipe(fp_dop_reg_reg_d);
12912 %}
12913 
12914 // src1 * src2 + src3
12915 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12916   predicate(UseFMA);
12917   match(Set dst (FmaF src3 (Binary src1 src2)));
12918 
12919   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12920 
12921   ins_encode %{
12922     __ fmadds(as_FloatRegister($dst$$reg),
12923              as_FloatRegister($src1$$reg),
12924              as_FloatRegister($src2$$reg),
12925              as_FloatRegister($src3$$reg));
12926   %}
12927 
12928   ins_pipe(pipe_class_default);
12929 %}
12930 
12931 // src1 * src2 + src3
12932 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12933   predicate(UseFMA);
12934   match(Set dst (FmaD src3 (Binary src1 src2)));
12935 
12936   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12937 
12938   ins_encode %{
12939     __ fmaddd(as_FloatRegister($dst$$reg),
12940              as_FloatRegister($src1$$reg),
12941              as_FloatRegister($src2$$reg),
12942              as_FloatRegister($src3$$reg));
12943   %}
12944 
12945   ins_pipe(pipe_class_default);
12946 %}
12947 
12948 // -src1 * src2 + src3
12949 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12950   predicate(UseFMA);
12951   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12952   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12953 
12954   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12955 
12956   ins_encode %{
12957     __ fmsubs(as_FloatRegister($dst$$reg),
12958               as_FloatRegister($src1$$reg),
12959               as_FloatRegister($src2$$reg),
12960               as_FloatRegister($src3$$reg));
12961   %}
12962 
12963   ins_pipe(pipe_class_default);
12964 %}
12965 
12966 // -src1 * src2 + src3
12967 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12968   predicate(UseFMA);
12969   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12970   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12971 
12972   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12973 
12974   ins_encode %{
12975     __ fmsubd(as_FloatRegister($dst$$reg),
12976               as_FloatRegister($src1$$reg),
12977               as_FloatRegister($src2$$reg),
12978               as_FloatRegister($src3$$reg));
12979   %}
12980 
12981   ins_pipe(pipe_class_default);
12982 %}
12983 
12984 // -src1 * src2 - src3
12985 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12986   predicate(UseFMA);
12987   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
12988   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
12989 
12990   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
12991 
12992   ins_encode %{
12993     __ fnmadds(as_FloatRegister($dst$$reg),
12994                as_FloatRegister($src1$$reg),
12995                as_FloatRegister($src2$$reg),
12996                as_FloatRegister($src3$$reg));
12997   %}
12998 
12999   ins_pipe(pipe_class_default);
13000 %}
13001 
13002 // -src1 * src2 - src3
13003 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13004   predicate(UseFMA);
13005   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13006   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13007 
13008   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13009 
13010   ins_encode %{
13011     __ fnmaddd(as_FloatRegister($dst$$reg),
13012                as_FloatRegister($src1$$reg),
13013                as_FloatRegister($src2$$reg),
13014                as_FloatRegister($src3$$reg));
13015   %}
13016 
13017   ins_pipe(pipe_class_default);
13018 %}
13019 
13020 // src1 * src2 - src3
13021 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13022   predicate(UseFMA);
13023   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13024 
13025   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13026 
13027   ins_encode %{
13028     __ fnmsubs(as_FloatRegister($dst$$reg),
13029                as_FloatRegister($src1$$reg),
13030                as_FloatRegister($src2$$reg),
13031                as_FloatRegister($src3$$reg));
13032   %}
13033 
13034   ins_pipe(pipe_class_default);
13035 %}
13036 
13037 // src1 * src2 - src3
13038 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13039   predicate(UseFMA);
13040   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13041 
13042   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13043 
13044   ins_encode %{
13045   // n.b. insn name should be fnmsubd
13046     __ fnmsub(as_FloatRegister($dst$$reg),
13047               as_FloatRegister($src1$$reg),
13048               as_FloatRegister($src2$$reg),
13049               as_FloatRegister($src3$$reg));
13050   %}
13051 
13052   ins_pipe(pipe_class_default);
13053 %}
13054 
13055 
13056 // Math.max(FF)F
13057 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13058   match(Set dst (MaxF src1 src2));
13059 
13060   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13061   ins_encode %{
13062     __ fmaxs(as_FloatRegister($dst$$reg),
13063              as_FloatRegister($src1$$reg),
13064              as_FloatRegister($src2$$reg));
13065   %}
13066 
13067   ins_pipe(fp_dop_reg_reg_s);
13068 %}
13069 
13070 // Math.min(FF)F
13071 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13072   match(Set dst (MinF src1 src2));
13073 
13074   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13075   ins_encode %{
13076     __ fmins(as_FloatRegister($dst$$reg),
13077              as_FloatRegister($src1$$reg),
13078              as_FloatRegister($src2$$reg));
13079   %}
13080 
13081   ins_pipe(fp_dop_reg_reg_s);
13082 %}
13083 
13084 // Math.max(DD)D
13085 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13086   match(Set dst (MaxD src1 src2));
13087 
13088   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13089   ins_encode %{
13090     __ fmaxd(as_FloatRegister($dst$$reg),
13091              as_FloatRegister($src1$$reg),
13092              as_FloatRegister($src2$$reg));
13093   %}
13094 
13095   ins_pipe(fp_dop_reg_reg_d);
13096 %}
13097 
13098 // Math.min(DD)D
13099 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13100   match(Set dst (MinD src1 src2));
13101 
13102   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13103   ins_encode %{
13104     __ fmind(as_FloatRegister($dst$$reg),
13105              as_FloatRegister($src1$$reg),
13106              as_FloatRegister($src2$$reg));
13107   %}
13108 
13109   ins_pipe(fp_dop_reg_reg_d);
13110 %}
13111 
13112 
13113 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13114   match(Set dst (DivF src1  src2));
13115 
13116   ins_cost(INSN_COST * 18);
13117   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13118 
13119   ins_encode %{
13120     __ fdivs(as_FloatRegister($dst$$reg),
13121              as_FloatRegister($src1$$reg),
13122              as_FloatRegister($src2$$reg));
13123   %}
13124 
13125   ins_pipe(fp_div_s);
13126 %}
13127 
13128 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13129   match(Set dst (DivD src1  src2));
13130 
13131   ins_cost(INSN_COST * 32);
13132   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13133 
13134   ins_encode %{
13135     __ fdivd(as_FloatRegister($dst$$reg),
13136              as_FloatRegister($src1$$reg),
13137              as_FloatRegister($src2$$reg));
13138   %}
13139 
13140   ins_pipe(fp_div_d);
13141 %}
13142 
13143 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13144   match(Set dst (NegF src));
13145 
13146   ins_cost(INSN_COST * 3);
13147   format %{ &quot;fneg   $dst, $src&quot; %}
13148 
13149   ins_encode %{
13150     __ fnegs(as_FloatRegister($dst$$reg),
13151              as_FloatRegister($src$$reg));
13152   %}
13153 
13154   ins_pipe(fp_uop_s);
13155 %}
13156 
13157 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13158   match(Set dst (NegD src));
13159 
13160   ins_cost(INSN_COST * 3);
13161   format %{ &quot;fnegd   $dst, $src&quot; %}
13162 
13163   ins_encode %{
13164     __ fnegd(as_FloatRegister($dst$$reg),
13165              as_FloatRegister($src$$reg));
13166   %}
13167 
13168   ins_pipe(fp_uop_d);
13169 %}
13170 
13171 instruct absF_reg(vRegF dst, vRegF src) %{
13172   match(Set dst (AbsF src));
13173 
13174   ins_cost(INSN_COST * 3);
13175   format %{ &quot;fabss   $dst, $src&quot; %}
13176   ins_encode %{
13177     __ fabss(as_FloatRegister($dst$$reg),
13178              as_FloatRegister($src$$reg));
13179   %}
13180 
13181   ins_pipe(fp_uop_s);
13182 %}
13183 
13184 instruct absD_reg(vRegD dst, vRegD src) %{
13185   match(Set dst (AbsD src));
13186 
13187   ins_cost(INSN_COST * 3);
13188   format %{ &quot;fabsd   $dst, $src&quot; %}
13189   ins_encode %{
13190     __ fabsd(as_FloatRegister($dst$$reg),
13191              as_FloatRegister($src$$reg));
13192   %}
13193 
13194   ins_pipe(fp_uop_d);
13195 %}
13196 
13197 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13198   match(Set dst (SqrtD src));
13199 
13200   ins_cost(INSN_COST * 50);
13201   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13202   ins_encode %{
13203     __ fsqrtd(as_FloatRegister($dst$$reg),
13204              as_FloatRegister($src$$reg));
13205   %}
13206 
13207   ins_pipe(fp_div_s);
13208 %}
13209 
13210 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13211   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13212 
13213   ins_cost(INSN_COST * 50);
13214   format %{ &quot;fsqrts  $dst, $src&quot; %}
13215   ins_encode %{
13216     __ fsqrts(as_FloatRegister($dst$$reg),
13217              as_FloatRegister($src$$reg));
13218   %}
13219 
13220   ins_pipe(fp_div_d);
13221 %}
13222 
13223 // Math.rint, floor, ceil
13224 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13225   match(Set dst (RoundDoubleMode src rmode));
13226   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13227   ins_encode %{
13228     switch ($rmode$$constant) {
13229       case RoundDoubleModeNode::rmode_rint:
13230         __ frintnd(as_FloatRegister($dst$$reg),
13231                    as_FloatRegister($src$$reg));
13232         break;
13233       case RoundDoubleModeNode::rmode_floor:
13234         __ frintmd(as_FloatRegister($dst$$reg),
13235                    as_FloatRegister($src$$reg));
13236         break;
13237       case RoundDoubleModeNode::rmode_ceil:
13238         __ frintpd(as_FloatRegister($dst$$reg),
13239                    as_FloatRegister($src$$reg));
13240         break;
13241     }
13242   %}
13243   ins_pipe(fp_uop_d);
13244 %}
13245 
13246 // ============================================================================
13247 // Logical Instructions
13248 
13249 // Integer Logical Instructions
13250 
13251 // And Instructions
13252 
13253 
13254 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13255   match(Set dst (AndI src1 src2));
13256 
13257   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13258 
13259   ins_cost(INSN_COST);
13260   ins_encode %{
13261     __ andw(as_Register($dst$$reg),
13262             as_Register($src1$$reg),
13263             as_Register($src2$$reg));
13264   %}
13265 
13266   ins_pipe(ialu_reg_reg);
13267 %}
13268 
13269 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13270   match(Set dst (AndI src1 src2));
13271 
13272   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13273 
13274   ins_cost(INSN_COST);
13275   ins_encode %{
13276     __ andw(as_Register($dst$$reg),
13277             as_Register($src1$$reg),
13278             (unsigned long)($src2$$constant));
13279   %}
13280 
13281   ins_pipe(ialu_reg_imm);
13282 %}
13283 
13284 // Or Instructions
13285 
13286 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13287   match(Set dst (OrI src1 src2));
13288 
13289   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13290 
13291   ins_cost(INSN_COST);
13292   ins_encode %{
13293     __ orrw(as_Register($dst$$reg),
13294             as_Register($src1$$reg),
13295             as_Register($src2$$reg));
13296   %}
13297 
13298   ins_pipe(ialu_reg_reg);
13299 %}
13300 
13301 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13302   match(Set dst (OrI src1 src2));
13303 
13304   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13305 
13306   ins_cost(INSN_COST);
13307   ins_encode %{
13308     __ orrw(as_Register($dst$$reg),
13309             as_Register($src1$$reg),
13310             (unsigned long)($src2$$constant));
13311   %}
13312 
13313   ins_pipe(ialu_reg_imm);
13314 %}
13315 
13316 // Xor Instructions
13317 
13318 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13319   match(Set dst (XorI src1 src2));
13320 
13321   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13322 
13323   ins_cost(INSN_COST);
13324   ins_encode %{
13325     __ eorw(as_Register($dst$$reg),
13326             as_Register($src1$$reg),
13327             as_Register($src2$$reg));
13328   %}
13329 
13330   ins_pipe(ialu_reg_reg);
13331 %}
13332 
13333 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13334   match(Set dst (XorI src1 src2));
13335 
13336   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13337 
13338   ins_cost(INSN_COST);
13339   ins_encode %{
13340     __ eorw(as_Register($dst$$reg),
13341             as_Register($src1$$reg),
13342             (unsigned long)($src2$$constant));
13343   %}
13344 
13345   ins_pipe(ialu_reg_imm);
13346 %}
13347 
13348 // Long Logical Instructions
13349 // TODO
13350 
13351 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13352   match(Set dst (AndL src1 src2));
13353 
13354   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13355 
13356   ins_cost(INSN_COST);
13357   ins_encode %{
13358     __ andr(as_Register($dst$$reg),
13359             as_Register($src1$$reg),
13360             as_Register($src2$$reg));
13361   %}
13362 
13363   ins_pipe(ialu_reg_reg);
13364 %}
13365 
13366 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13367   match(Set dst (AndL src1 src2));
13368 
13369   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13370 
13371   ins_cost(INSN_COST);
13372   ins_encode %{
13373     __ andr(as_Register($dst$$reg),
13374             as_Register($src1$$reg),
13375             (unsigned long)($src2$$constant));
13376   %}
13377 
13378   ins_pipe(ialu_reg_imm);
13379 %}
13380 
13381 // Or Instructions
13382 
13383 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13384   match(Set dst (OrL src1 src2));
13385 
13386   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13387 
13388   ins_cost(INSN_COST);
13389   ins_encode %{
13390     __ orr(as_Register($dst$$reg),
13391            as_Register($src1$$reg),
13392            as_Register($src2$$reg));
13393   %}
13394 
13395   ins_pipe(ialu_reg_reg);
13396 %}
13397 
13398 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13399   match(Set dst (OrL src1 src2));
13400 
13401   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13402 
13403   ins_cost(INSN_COST);
13404   ins_encode %{
13405     __ orr(as_Register($dst$$reg),
13406            as_Register($src1$$reg),
13407            (unsigned long)($src2$$constant));
13408   %}
13409 
13410   ins_pipe(ialu_reg_imm);
13411 %}
13412 
13413 // Xor Instructions
13414 
13415 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13416   match(Set dst (XorL src1 src2));
13417 
13418   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13419 
13420   ins_cost(INSN_COST);
13421   ins_encode %{
13422     __ eor(as_Register($dst$$reg),
13423            as_Register($src1$$reg),
13424            as_Register($src2$$reg));
13425   %}
13426 
13427   ins_pipe(ialu_reg_reg);
13428 %}
13429 
13430 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13431   match(Set dst (XorL src1 src2));
13432 
13433   ins_cost(INSN_COST);
13434   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13435 
13436   ins_encode %{
13437     __ eor(as_Register($dst$$reg),
13438            as_Register($src1$$reg),
13439            (unsigned long)($src2$$constant));
13440   %}
13441 
13442   ins_pipe(ialu_reg_imm);
13443 %}
13444 
13445 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13446 %{
13447   match(Set dst (ConvI2L src));
13448 
13449   ins_cost(INSN_COST);
13450   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13451   ins_encode %{
13452     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13453   %}
13454   ins_pipe(ialu_reg_shift);
13455 %}
13456 
13457 // this pattern occurs in bigmath arithmetic
13458 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13459 %{
13460   match(Set dst (AndL (ConvI2L src) mask));
13461 
13462   ins_cost(INSN_COST);
13463   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13464   ins_encode %{
13465     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13466   %}
13467 
13468   ins_pipe(ialu_reg_shift);
13469 %}
13470 
13471 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13472   match(Set dst (ConvL2I src));
13473 
13474   ins_cost(INSN_COST);
13475   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13476 
13477   ins_encode %{
13478     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13479   %}
13480 
13481   ins_pipe(ialu_reg);
13482 %}
13483 
13484 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13485 %{
13486   match(Set dst (Conv2B src));
13487   effect(KILL cr);
13488 
13489   format %{
13490     &quot;cmpw $src, zr\n\t&quot;
13491     &quot;cset $dst, ne&quot;
13492   %}
13493 
13494   ins_encode %{
13495     __ cmpw(as_Register($src$$reg), zr);
13496     __ cset(as_Register($dst$$reg), Assembler::NE);
13497   %}
13498 
13499   ins_pipe(ialu_reg);
13500 %}
13501 
13502 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13503 %{
13504   match(Set dst (Conv2B src));
13505   effect(KILL cr);
13506 
13507   format %{
13508     &quot;cmp  $src, zr\n\t&quot;
13509     &quot;cset $dst, ne&quot;
13510   %}
13511 
13512   ins_encode %{
13513     __ cmp(as_Register($src$$reg), zr);
13514     __ cset(as_Register($dst$$reg), Assembler::NE);
13515   %}
13516 
13517   ins_pipe(ialu_reg);
13518 %}
13519 
13520 instruct convD2F_reg(vRegF dst, vRegD src) %{
13521   match(Set dst (ConvD2F src));
13522 
13523   ins_cost(INSN_COST * 5);
13524   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13525 
13526   ins_encode %{
13527     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13528   %}
13529 
13530   ins_pipe(fp_d2f);
13531 %}
13532 
13533 instruct convF2D_reg(vRegD dst, vRegF src) %{
13534   match(Set dst (ConvF2D src));
13535 
13536   ins_cost(INSN_COST * 5);
13537   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13538 
13539   ins_encode %{
13540     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13541   %}
13542 
13543   ins_pipe(fp_f2d);
13544 %}
13545 
13546 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13547   match(Set dst (ConvF2I src));
13548 
13549   ins_cost(INSN_COST * 5);
13550   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13551 
13552   ins_encode %{
13553     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13554   %}
13555 
13556   ins_pipe(fp_f2i);
13557 %}
13558 
13559 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13560   match(Set dst (ConvF2L src));
13561 
13562   ins_cost(INSN_COST * 5);
13563   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13564 
13565   ins_encode %{
13566     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13567   %}
13568 
13569   ins_pipe(fp_f2l);
13570 %}
13571 
13572 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13573   match(Set dst (ConvI2F src));
13574 
13575   ins_cost(INSN_COST * 5);
13576   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13577 
13578   ins_encode %{
13579     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13580   %}
13581 
13582   ins_pipe(fp_i2f);
13583 %}
13584 
13585 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13586   match(Set dst (ConvL2F src));
13587 
13588   ins_cost(INSN_COST * 5);
13589   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13590 
13591   ins_encode %{
13592     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13593   %}
13594 
13595   ins_pipe(fp_l2f);
13596 %}
13597 
13598 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13599   match(Set dst (ConvD2I src));
13600 
13601   ins_cost(INSN_COST * 5);
13602   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13603 
13604   ins_encode %{
13605     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13606   %}
13607 
13608   ins_pipe(fp_d2i);
13609 %}
13610 
13611 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13612   match(Set dst (ConvD2L src));
13613 
13614   ins_cost(INSN_COST * 5);
13615   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13616 
13617   ins_encode %{
13618     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13619   %}
13620 
13621   ins_pipe(fp_d2l);
13622 %}
13623 
13624 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13625   match(Set dst (ConvI2D src));
13626 
13627   ins_cost(INSN_COST * 5);
13628   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13629 
13630   ins_encode %{
13631     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13632   %}
13633 
13634   ins_pipe(fp_i2d);
13635 %}
13636 
13637 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13638   match(Set dst (ConvL2D src));
13639 
13640   ins_cost(INSN_COST * 5);
13641   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13642 
13643   ins_encode %{
13644     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13645   %}
13646 
13647   ins_pipe(fp_l2d);
13648 %}
13649 
13650 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13651 
13652 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13653 
13654   match(Set dst (MoveF2I src));
13655 
13656   effect(DEF dst, USE src);
13657 
13658   ins_cost(4 * INSN_COST);
13659 
13660   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13661 
13662   ins_encode %{
13663     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13664   %}
13665 
13666   ins_pipe(iload_reg_reg);
13667 
13668 %}
13669 
13670 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13671 
13672   match(Set dst (MoveI2F src));
13673 
13674   effect(DEF dst, USE src);
13675 
13676   ins_cost(4 * INSN_COST);
13677 
13678   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13679 
13680   ins_encode %{
13681     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13682   %}
13683 
13684   ins_pipe(pipe_class_memory);
13685 
13686 %}
13687 
13688 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13689 
13690   match(Set dst (MoveD2L src));
13691 
13692   effect(DEF dst, USE src);
13693 
13694   ins_cost(4 * INSN_COST);
13695 
13696   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13697 
13698   ins_encode %{
13699     __ ldr($dst$$Register, Address(sp, $src$$disp));
13700   %}
13701 
13702   ins_pipe(iload_reg_reg);
13703 
13704 %}
13705 
13706 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13707 
13708   match(Set dst (MoveL2D src));
13709 
13710   effect(DEF dst, USE src);
13711 
13712   ins_cost(4 * INSN_COST);
13713 
13714   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13715 
13716   ins_encode %{
13717     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13718   %}
13719 
13720   ins_pipe(pipe_class_memory);
13721 
13722 %}
13723 
13724 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13725 
13726   match(Set dst (MoveF2I src));
13727 
13728   effect(DEF dst, USE src);
13729 
13730   ins_cost(INSN_COST);
13731 
13732   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13733 
13734   ins_encode %{
13735     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13736   %}
13737 
13738   ins_pipe(pipe_class_memory);
13739 
13740 %}
13741 
13742 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13743 
13744   match(Set dst (MoveI2F src));
13745 
13746   effect(DEF dst, USE src);
13747 
13748   ins_cost(INSN_COST);
13749 
13750   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13751 
13752   ins_encode %{
13753     __ strw($src$$Register, Address(sp, $dst$$disp));
13754   %}
13755 
13756   ins_pipe(istore_reg_reg);
13757 
13758 %}
13759 
13760 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13761 
13762   match(Set dst (MoveD2L src));
13763 
13764   effect(DEF dst, USE src);
13765 
13766   ins_cost(INSN_COST);
13767 
13768   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13769 
13770   ins_encode %{
13771     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13772   %}
13773 
13774   ins_pipe(pipe_class_memory);
13775 
13776 %}
13777 
13778 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13779 
13780   match(Set dst (MoveL2D src));
13781 
13782   effect(DEF dst, USE src);
13783 
13784   ins_cost(INSN_COST);
13785 
13786   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13787 
13788   ins_encode %{
13789     __ str($src$$Register, Address(sp, $dst$$disp));
13790   %}
13791 
13792   ins_pipe(istore_reg_reg);
13793 
13794 %}
13795 
13796 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13797 
13798   match(Set dst (MoveF2I src));
13799 
13800   effect(DEF dst, USE src);
13801 
13802   ins_cost(INSN_COST);
13803 
13804   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13805 
13806   ins_encode %{
13807     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13808   %}
13809 
13810   ins_pipe(fp_f2i);
13811 
13812 %}
13813 
13814 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13815 
13816   match(Set dst (MoveI2F src));
13817 
13818   effect(DEF dst, USE src);
13819 
13820   ins_cost(INSN_COST);
13821 
13822   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13823 
13824   ins_encode %{
13825     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13826   %}
13827 
13828   ins_pipe(fp_i2f);
13829 
13830 %}
13831 
13832 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13833 
13834   match(Set dst (MoveD2L src));
13835 
13836   effect(DEF dst, USE src);
13837 
13838   ins_cost(INSN_COST);
13839 
13840   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13841 
13842   ins_encode %{
13843     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13844   %}
13845 
13846   ins_pipe(fp_d2l);
13847 
13848 %}
13849 
13850 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13851 
13852   match(Set dst (MoveL2D src));
13853 
13854   effect(DEF dst, USE src);
13855 
13856   ins_cost(INSN_COST);
13857 
13858   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13859 
13860   ins_encode %{
13861     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13862   %}
13863 
13864   ins_pipe(fp_l2d);
13865 
13866 %}
13867 
13868 // ============================================================================
13869 // clearing of an array
13870 
<a name="10" id="anc10"></a><span class="line-modified">13871 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)</span>
13872 %{
<a name="11" id="anc11"></a><span class="line-modified">13873   match(Set dummy (ClearArray cnt base));</span>
13874   effect(USE_KILL cnt, USE_KILL base);
13875 
13876   ins_cost(4 * INSN_COST);
<a name="12" id="anc12"></a><span class="line-modified">13877   format %{ &quot;ClearArray $cnt, $base&quot; %}</span>
<span class="line-removed">13878 </span>
<span class="line-removed">13879   ins_encode %{</span>
<span class="line-removed">13880     __ zero_words($base$$Register, $cnt$$Register);</span>
<span class="line-removed">13881   %}</span>
<span class="line-removed">13882 </span>
<span class="line-removed">13883   ins_pipe(pipe_class_memory);</span>
<span class="line-removed">13884 %}</span>
<span class="line-removed">13885 </span>
<span class="line-removed">13886 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)</span>
<span class="line-removed">13887 %{</span>
<span class="line-removed">13888   predicate((u_int64_t)n-&gt;in(2)-&gt;get_long()</span>
<span class="line-removed">13889             &lt; (u_int64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));</span>
<span class="line-removed">13890   match(Set dummy (ClearArray cnt base));</span>
<span class="line-removed">13891   effect(USE_KILL base);</span>
<span class="line-removed">13892 </span>
<span class="line-removed">13893   ins_cost(4 * INSN_COST);</span>
<span class="line-removed">13894   format %{ &quot;ClearArray $cnt, $base&quot; %}</span>
13895 
13896   ins_encode %{
<a name="13" id="anc13"></a><span class="line-modified">13897     __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);</span>
13898   %}
13899 
13900   ins_pipe(pipe_class_memory);
13901 %}
13902 
13903 // ============================================================================
13904 // Overflow Math Instructions
13905 
13906 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13907 %{
13908   match(Set cr (OverflowAddI op1 op2));
13909 
13910   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13911   ins_cost(INSN_COST);
13912   ins_encode %{
13913     __ cmnw($op1$$Register, $op2$$Register);
13914   %}
13915 
13916   ins_pipe(icmp_reg_reg);
13917 %}
13918 
13919 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13920 %{
13921   match(Set cr (OverflowAddI op1 op2));
13922 
13923   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13924   ins_cost(INSN_COST);
13925   ins_encode %{
13926     __ cmnw($op1$$Register, $op2$$constant);
13927   %}
13928 
13929   ins_pipe(icmp_reg_imm);
13930 %}
13931 
13932 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13933 %{
13934   match(Set cr (OverflowAddL op1 op2));
13935 
13936   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13937   ins_cost(INSN_COST);
13938   ins_encode %{
13939     __ cmn($op1$$Register, $op2$$Register);
13940   %}
13941 
13942   ins_pipe(icmp_reg_reg);
13943 %}
13944 
13945 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13946 %{
13947   match(Set cr (OverflowAddL op1 op2));
13948 
13949   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13950   ins_cost(INSN_COST);
13951   ins_encode %{
13952     __ cmn($op1$$Register, $op2$$constant);
13953   %}
13954 
13955   ins_pipe(icmp_reg_imm);
13956 %}
13957 
13958 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13959 %{
13960   match(Set cr (OverflowSubI op1 op2));
13961 
13962   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13963   ins_cost(INSN_COST);
13964   ins_encode %{
13965     __ cmpw($op1$$Register, $op2$$Register);
13966   %}
13967 
13968   ins_pipe(icmp_reg_reg);
13969 %}
13970 
13971 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13972 %{
13973   match(Set cr (OverflowSubI op1 op2));
13974 
13975   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13976   ins_cost(INSN_COST);
13977   ins_encode %{
13978     __ cmpw($op1$$Register, $op2$$constant);
13979   %}
13980 
13981   ins_pipe(icmp_reg_imm);
13982 %}
13983 
13984 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13985 %{
13986   match(Set cr (OverflowSubL op1 op2));
13987 
13988   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13989   ins_cost(INSN_COST);
13990   ins_encode %{
13991     __ cmp($op1$$Register, $op2$$Register);
13992   %}
13993 
13994   ins_pipe(icmp_reg_reg);
13995 %}
13996 
13997 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13998 %{
13999   match(Set cr (OverflowSubL op1 op2));
14000 
14001   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14002   ins_cost(INSN_COST);
14003   ins_encode %{
14004     __ subs(zr, $op1$$Register, $op2$$constant);
14005   %}
14006 
14007   ins_pipe(icmp_reg_imm);
14008 %}
14009 
14010 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14011 %{
14012   match(Set cr (OverflowSubI zero op1));
14013 
14014   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14015   ins_cost(INSN_COST);
14016   ins_encode %{
14017     __ cmpw(zr, $op1$$Register);
14018   %}
14019 
14020   ins_pipe(icmp_reg_imm);
14021 %}
14022 
14023 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14024 %{
14025   match(Set cr (OverflowSubL zero op1));
14026 
14027   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14028   ins_cost(INSN_COST);
14029   ins_encode %{
14030     __ cmp(zr, $op1$$Register);
14031   %}
14032 
14033   ins_pipe(icmp_reg_imm);
14034 %}
14035 
14036 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14037 %{
14038   match(Set cr (OverflowMulI op1 op2));
14039 
14040   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14041             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14042             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14043             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14044             &quot;cmpw  rscratch1, #1&quot; %}
14045   ins_cost(5 * INSN_COST);
14046   ins_encode %{
14047     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14048     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14049     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14050     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14051     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14052   %}
14053 
14054   ins_pipe(pipe_slow);
14055 %}
14056 
14057 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14058 %{
14059   match(If cmp (OverflowMulI op1 op2));
14060   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14061             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14062   effect(USE labl, KILL cr);
14063 
14064   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14065             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14066             &quot;b$cmp   $labl&quot; %}
14067   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14068   ins_encode %{
14069     Label* L = $labl$$label;
14070     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14071     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14072     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14073     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14074   %}
14075 
14076   ins_pipe(pipe_serial);
14077 %}
14078 
14079 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14080 %{
14081   match(Set cr (OverflowMulL op1 op2));
14082 
14083   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14084             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14085             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14086             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14087             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14088             &quot;cmpw  rscratch1, #1&quot; %}
14089   ins_cost(6 * INSN_COST);
14090   ins_encode %{
14091     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14092     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14093     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14094     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14095     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14096     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14097   %}
14098 
14099   ins_pipe(pipe_slow);
14100 %}
14101 
14102 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14103 %{
14104   match(If cmp (OverflowMulL op1 op2));
14105   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14106             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14107   effect(USE labl, KILL cr);
14108 
14109   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14110             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14111             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14112             &quot;b$cmp $labl&quot; %}
14113   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14114   ins_encode %{
14115     Label* L = $labl$$label;
14116     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14117     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14118     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14119     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14120     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14121   %}
14122 
14123   ins_pipe(pipe_serial);
14124 %}
14125 
14126 // ============================================================================
14127 // Compare Instructions
14128 
14129 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14130 %{
14131   match(Set cr (CmpI op1 op2));
14132 
14133   effect(DEF cr, USE op1, USE op2);
14134 
14135   ins_cost(INSN_COST);
14136   format %{ &quot;cmpw  $op1, $op2&quot; %}
14137 
14138   ins_encode(aarch64_enc_cmpw(op1, op2));
14139 
14140   ins_pipe(icmp_reg_reg);
14141 %}
14142 
14143 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14144 %{
14145   match(Set cr (CmpI op1 zero));
14146 
14147   effect(DEF cr, USE op1);
14148 
14149   ins_cost(INSN_COST);
14150   format %{ &quot;cmpw $op1, 0&quot; %}
14151 
14152   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14153 
14154   ins_pipe(icmp_reg_imm);
14155 %}
14156 
14157 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14158 %{
14159   match(Set cr (CmpI op1 op2));
14160 
14161   effect(DEF cr, USE op1);
14162 
14163   ins_cost(INSN_COST);
14164   format %{ &quot;cmpw  $op1, $op2&quot; %}
14165 
14166   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14167 
14168   ins_pipe(icmp_reg_imm);
14169 %}
14170 
14171 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14172 %{
14173   match(Set cr (CmpI op1 op2));
14174 
14175   effect(DEF cr, USE op1);
14176 
14177   ins_cost(INSN_COST * 2);
14178   format %{ &quot;cmpw  $op1, $op2&quot; %}
14179 
14180   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14181 
14182   ins_pipe(icmp_reg_imm);
14183 %}
14184 
14185 // Unsigned compare Instructions; really, same as signed compare
14186 // except it should only be used to feed an If or a CMovI which takes a
14187 // cmpOpU.
14188 
14189 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14190 %{
14191   match(Set cr (CmpU op1 op2));
14192 
14193   effect(DEF cr, USE op1, USE op2);
14194 
14195   ins_cost(INSN_COST);
14196   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14197 
14198   ins_encode(aarch64_enc_cmpw(op1, op2));
14199 
14200   ins_pipe(icmp_reg_reg);
14201 %}
14202 
14203 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14204 %{
14205   match(Set cr (CmpU op1 zero));
14206 
14207   effect(DEF cr, USE op1);
14208 
14209   ins_cost(INSN_COST);
14210   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14211 
14212   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14213 
14214   ins_pipe(icmp_reg_imm);
14215 %}
14216 
14217 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14218 %{
14219   match(Set cr (CmpU op1 op2));
14220 
14221   effect(DEF cr, USE op1);
14222 
14223   ins_cost(INSN_COST);
14224   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14225 
14226   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14227 
14228   ins_pipe(icmp_reg_imm);
14229 %}
14230 
14231 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14232 %{
14233   match(Set cr (CmpU op1 op2));
14234 
14235   effect(DEF cr, USE op1);
14236 
14237   ins_cost(INSN_COST * 2);
14238   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14239 
14240   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14241 
14242   ins_pipe(icmp_reg_imm);
14243 %}
14244 
14245 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14246 %{
14247   match(Set cr (CmpL op1 op2));
14248 
14249   effect(DEF cr, USE op1, USE op2);
14250 
14251   ins_cost(INSN_COST);
14252   format %{ &quot;cmp  $op1, $op2&quot; %}
14253 
14254   ins_encode(aarch64_enc_cmp(op1, op2));
14255 
14256   ins_pipe(icmp_reg_reg);
14257 %}
14258 
14259 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14260 %{
14261   match(Set cr (CmpL op1 zero));
14262 
14263   effect(DEF cr, USE op1);
14264 
14265   ins_cost(INSN_COST);
14266   format %{ &quot;tst  $op1&quot; %}
14267 
14268   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14269 
14270   ins_pipe(icmp_reg_imm);
14271 %}
14272 
14273 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14274 %{
14275   match(Set cr (CmpL op1 op2));
14276 
14277   effect(DEF cr, USE op1);
14278 
14279   ins_cost(INSN_COST);
14280   format %{ &quot;cmp  $op1, $op2&quot; %}
14281 
14282   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14283 
14284   ins_pipe(icmp_reg_imm);
14285 %}
14286 
14287 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14288 %{
14289   match(Set cr (CmpL op1 op2));
14290 
14291   effect(DEF cr, USE op1);
14292 
14293   ins_cost(INSN_COST * 2);
14294   format %{ &quot;cmp  $op1, $op2&quot; %}
14295 
14296   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14297 
14298   ins_pipe(icmp_reg_imm);
14299 %}
14300 
14301 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14302 %{
14303   match(Set cr (CmpUL op1 op2));
14304 
14305   effect(DEF cr, USE op1, USE op2);
14306 
14307   ins_cost(INSN_COST);
14308   format %{ &quot;cmp  $op1, $op2&quot; %}
14309 
14310   ins_encode(aarch64_enc_cmp(op1, op2));
14311 
14312   ins_pipe(icmp_reg_reg);
14313 %}
14314 
14315 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14316 %{
14317   match(Set cr (CmpUL op1 zero));
14318 
14319   effect(DEF cr, USE op1);
14320 
14321   ins_cost(INSN_COST);
14322   format %{ &quot;tst  $op1&quot; %}
14323 
14324   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14325 
14326   ins_pipe(icmp_reg_imm);
14327 %}
14328 
14329 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14330 %{
14331   match(Set cr (CmpUL op1 op2));
14332 
14333   effect(DEF cr, USE op1);
14334 
14335   ins_cost(INSN_COST);
14336   format %{ &quot;cmp  $op1, $op2&quot; %}
14337 
14338   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14339 
14340   ins_pipe(icmp_reg_imm);
14341 %}
14342 
14343 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14344 %{
14345   match(Set cr (CmpUL op1 op2));
14346 
14347   effect(DEF cr, USE op1);
14348 
14349   ins_cost(INSN_COST * 2);
14350   format %{ &quot;cmp  $op1, $op2&quot; %}
14351 
14352   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14353 
14354   ins_pipe(icmp_reg_imm);
14355 %}
14356 
14357 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14358 %{
14359   match(Set cr (CmpP op1 op2));
14360 
14361   effect(DEF cr, USE op1, USE op2);
14362 
14363   ins_cost(INSN_COST);
14364   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14365 
14366   ins_encode(aarch64_enc_cmpp(op1, op2));
14367 
14368   ins_pipe(icmp_reg_reg);
14369 %}
14370 
14371 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14372 %{
14373   match(Set cr (CmpN op1 op2));
14374 
14375   effect(DEF cr, USE op1, USE op2);
14376 
14377   ins_cost(INSN_COST);
14378   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14379 
14380   ins_encode(aarch64_enc_cmpn(op1, op2));
14381 
14382   ins_pipe(icmp_reg_reg);
14383 %}
14384 
14385 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14386 %{
14387   match(Set cr (CmpP op1 zero));
14388 
14389   effect(DEF cr, USE op1, USE zero);
14390 
14391   ins_cost(INSN_COST);
14392   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14393 
14394   ins_encode(aarch64_enc_testp(op1));
14395 
14396   ins_pipe(icmp_reg_imm);
14397 %}
14398 
14399 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14400 %{
14401   match(Set cr (CmpN op1 zero));
14402 
14403   effect(DEF cr, USE op1, USE zero);
14404 
14405   ins_cost(INSN_COST);
14406   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14407 
14408   ins_encode(aarch64_enc_testn(op1));
14409 
14410   ins_pipe(icmp_reg_imm);
14411 %}
14412 
14413 // FP comparisons
14414 //
14415 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14416 // using normal cmpOp. See declaration of rFlagsReg for details.
14417 
14418 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14419 %{
14420   match(Set cr (CmpF src1 src2));
14421 
14422   ins_cost(3 * INSN_COST);
14423   format %{ &quot;fcmps $src1, $src2&quot; %}
14424 
14425   ins_encode %{
14426     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14427   %}
14428 
14429   ins_pipe(pipe_class_compare);
14430 %}
14431 
14432 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14433 %{
14434   match(Set cr (CmpF src1 src2));
14435 
14436   ins_cost(3 * INSN_COST);
14437   format %{ &quot;fcmps $src1, 0.0&quot; %}
14438 
14439   ins_encode %{
14440     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14441   %}
14442 
14443   ins_pipe(pipe_class_compare);
14444 %}
14445 // FROM HERE
14446 
14447 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14448 %{
14449   match(Set cr (CmpD src1 src2));
14450 
14451   ins_cost(3 * INSN_COST);
14452   format %{ &quot;fcmpd $src1, $src2&quot; %}
14453 
14454   ins_encode %{
14455     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14456   %}
14457 
14458   ins_pipe(pipe_class_compare);
14459 %}
14460 
14461 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14462 %{
14463   match(Set cr (CmpD src1 src2));
14464 
14465   ins_cost(3 * INSN_COST);
14466   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14467 
14468   ins_encode %{
14469     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14470   %}
14471 
14472   ins_pipe(pipe_class_compare);
14473 %}
14474 
14475 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14476 %{
14477   match(Set dst (CmpF3 src1 src2));
14478   effect(KILL cr);
14479 
14480   ins_cost(5 * INSN_COST);
14481   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14482             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14483             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14484   %}
14485 
14486   ins_encode %{
14487     Label done;
14488     FloatRegister s1 = as_FloatRegister($src1$$reg);
14489     FloatRegister s2 = as_FloatRegister($src2$$reg);
14490     Register d = as_Register($dst$$reg);
14491     __ fcmps(s1, s2);
14492     // installs 0 if EQ else -1
14493     __ csinvw(d, zr, zr, Assembler::EQ);
14494     // keeps -1 if less or unordered else installs 1
14495     __ csnegw(d, d, d, Assembler::LT);
14496     __ bind(done);
14497   %}
14498 
14499   ins_pipe(pipe_class_default);
14500 
14501 %}
14502 
14503 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14504 %{
14505   match(Set dst (CmpD3 src1 src2));
14506   effect(KILL cr);
14507 
14508   ins_cost(5 * INSN_COST);
14509   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14510             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14511             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14512   %}
14513 
14514   ins_encode %{
14515     Label done;
14516     FloatRegister s1 = as_FloatRegister($src1$$reg);
14517     FloatRegister s2 = as_FloatRegister($src2$$reg);
14518     Register d = as_Register($dst$$reg);
14519     __ fcmpd(s1, s2);
14520     // installs 0 if EQ else -1
14521     __ csinvw(d, zr, zr, Assembler::EQ);
14522     // keeps -1 if less or unordered else installs 1
14523     __ csnegw(d, d, d, Assembler::LT);
14524     __ bind(done);
14525   %}
14526   ins_pipe(pipe_class_default);
14527 
14528 %}
14529 
14530 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14531 %{
14532   match(Set dst (CmpF3 src1 zero));
14533   effect(KILL cr);
14534 
14535   ins_cost(5 * INSN_COST);
14536   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14537             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14538             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14539   %}
14540 
14541   ins_encode %{
14542     Label done;
14543     FloatRegister s1 = as_FloatRegister($src1$$reg);
14544     Register d = as_Register($dst$$reg);
14545     __ fcmps(s1, 0.0);
14546     // installs 0 if EQ else -1
14547     __ csinvw(d, zr, zr, Assembler::EQ);
14548     // keeps -1 if less or unordered else installs 1
14549     __ csnegw(d, d, d, Assembler::LT);
14550     __ bind(done);
14551   %}
14552 
14553   ins_pipe(pipe_class_default);
14554 
14555 %}
14556 
14557 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14558 %{
14559   match(Set dst (CmpD3 src1 zero));
14560   effect(KILL cr);
14561 
14562   ins_cost(5 * INSN_COST);
14563   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14564             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14565             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14566   %}
14567 
14568   ins_encode %{
14569     Label done;
14570     FloatRegister s1 = as_FloatRegister($src1$$reg);
14571     Register d = as_Register($dst$$reg);
14572     __ fcmpd(s1, 0.0);
14573     // installs 0 if EQ else -1
14574     __ csinvw(d, zr, zr, Assembler::EQ);
14575     // keeps -1 if less or unordered else installs 1
14576     __ csnegw(d, d, d, Assembler::LT);
14577     __ bind(done);
14578   %}
14579   ins_pipe(pipe_class_default);
14580 
14581 %}
14582 
14583 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14584 %{
14585   match(Set dst (CmpLTMask p q));
14586   effect(KILL cr);
14587 
14588   ins_cost(3 * INSN_COST);
14589 
14590   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14591             &quot;csetw $dst, lt\n\t&quot;
14592             &quot;subw $dst, zr, $dst&quot;
14593   %}
14594 
14595   ins_encode %{
14596     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14597     __ csetw(as_Register($dst$$reg), Assembler::LT);
14598     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14599   %}
14600 
14601   ins_pipe(ialu_reg_reg);
14602 %}
14603 
14604 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14605 %{
14606   match(Set dst (CmpLTMask src zero));
14607   effect(KILL cr);
14608 
14609   ins_cost(INSN_COST);
14610 
14611   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14612 
14613   ins_encode %{
14614     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14615   %}
14616 
14617   ins_pipe(ialu_reg_shift);
14618 %}
14619 
14620 // ============================================================================
14621 // Max and Min
14622 
14623 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14624 %{
14625   effect( DEF dst, USE src1, USE src2, USE cr );
14626 
14627   ins_cost(INSN_COST * 2);
14628   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14629 
14630   ins_encode %{
14631     __ cselw(as_Register($dst$$reg),
14632              as_Register($src1$$reg),
14633              as_Register($src2$$reg),
14634              Assembler::LT);
14635   %}
14636 
14637   ins_pipe(icond_reg_reg);
14638 %}
14639 
14640 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14641 %{
14642   match(Set dst (MinI src1 src2));
14643   ins_cost(INSN_COST * 3);
14644 
14645   expand %{
14646     rFlagsReg cr;
14647     compI_reg_reg(cr, src1, src2);
14648     cmovI_reg_reg_lt(dst, src1, src2, cr);
14649   %}
14650 
14651 %}
14652 // FROM HERE
14653 
14654 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14655 %{
14656   effect( DEF dst, USE src1, USE src2, USE cr );
14657 
14658   ins_cost(INSN_COST * 2);
14659   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14660 
14661   ins_encode %{
14662     __ cselw(as_Register($dst$$reg),
14663              as_Register($src1$$reg),
14664              as_Register($src2$$reg),
14665              Assembler::GT);
14666   %}
14667 
14668   ins_pipe(icond_reg_reg);
14669 %}
14670 
14671 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14672 %{
14673   match(Set dst (MaxI src1 src2));
14674   ins_cost(INSN_COST * 3);
14675   expand %{
14676     rFlagsReg cr;
14677     compI_reg_reg(cr, src1, src2);
14678     cmovI_reg_reg_gt(dst, src1, src2, cr);
14679   %}
14680 %}
14681 
14682 // ============================================================================
14683 // Branch Instructions
14684 
14685 // Direct Branch.
14686 instruct branch(label lbl)
14687 %{
14688   match(Goto);
14689 
14690   effect(USE lbl);
14691 
14692   ins_cost(BRANCH_COST);
14693   format %{ &quot;b  $lbl&quot; %}
14694 
14695   ins_encode(aarch64_enc_b(lbl));
14696 
14697   ins_pipe(pipe_branch);
14698 %}
14699 
14700 // Conditional Near Branch
14701 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14702 %{
14703   // Same match rule as `branchConFar&#39;.
14704   match(If cmp cr);
14705 
14706   effect(USE lbl);
14707 
14708   ins_cost(BRANCH_COST);
14709   // If set to 1 this indicates that the current instruction is a
14710   // short variant of a long branch. This avoids using this
14711   // instruction in first-pass matching. It will then only be used in
14712   // the `Shorten_branches&#39; pass.
14713   // ins_short_branch(1);
14714   format %{ &quot;b$cmp  $lbl&quot; %}
14715 
14716   ins_encode(aarch64_enc_br_con(cmp, lbl));
14717 
14718   ins_pipe(pipe_branch_cond);
14719 %}
14720 
14721 // Conditional Near Branch Unsigned
14722 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14723 %{
14724   // Same match rule as `branchConFar&#39;.
14725   match(If cmp cr);
14726 
14727   effect(USE lbl);
14728 
14729   ins_cost(BRANCH_COST);
14730   // If set to 1 this indicates that the current instruction is a
14731   // short variant of a long branch. This avoids using this
14732   // instruction in first-pass matching. It will then only be used in
14733   // the `Shorten_branches&#39; pass.
14734   // ins_short_branch(1);
14735   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14736 
14737   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14738 
14739   ins_pipe(pipe_branch_cond);
14740 %}
14741 
14742 // Make use of CBZ and CBNZ.  These instructions, as well as being
14743 // shorter than (cmp; branch), have the additional benefit of not
14744 // killing the flags.
14745 
14746 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14747   match(If cmp (CmpI op1 op2));
14748   effect(USE labl);
14749 
14750   ins_cost(BRANCH_COST);
14751   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14752   ins_encode %{
14753     Label* L = $labl$$label;
14754     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14755     if (cond == Assembler::EQ)
14756       __ cbzw($op1$$Register, *L);
14757     else
14758       __ cbnzw($op1$$Register, *L);
14759   %}
14760   ins_pipe(pipe_cmp_branch);
14761 %}
14762 
14763 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14764   match(If cmp (CmpL op1 op2));
14765   effect(USE labl);
14766 
14767   ins_cost(BRANCH_COST);
14768   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14769   ins_encode %{
14770     Label* L = $labl$$label;
14771     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14772     if (cond == Assembler::EQ)
14773       __ cbz($op1$$Register, *L);
14774     else
14775       __ cbnz($op1$$Register, *L);
14776   %}
14777   ins_pipe(pipe_cmp_branch);
14778 %}
14779 
14780 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14781   match(If cmp (CmpP op1 op2));
14782   effect(USE labl);
14783 
14784   ins_cost(BRANCH_COST);
14785   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14786   ins_encode %{
14787     Label* L = $labl$$label;
14788     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14789     if (cond == Assembler::EQ)
14790       __ cbz($op1$$Register, *L);
14791     else
14792       __ cbnz($op1$$Register, *L);
14793   %}
14794   ins_pipe(pipe_cmp_branch);
14795 %}
14796 
14797 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14798   match(If cmp (CmpN op1 op2));
14799   effect(USE labl);
14800 
14801   ins_cost(BRANCH_COST);
14802   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14803   ins_encode %{
14804     Label* L = $labl$$label;
14805     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14806     if (cond == Assembler::EQ)
14807       __ cbzw($op1$$Register, *L);
14808     else
14809       __ cbnzw($op1$$Register, *L);
14810   %}
14811   ins_pipe(pipe_cmp_branch);
14812 %}
14813 
14814 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14815   match(If cmp (CmpP (DecodeN oop) zero));
14816   effect(USE labl);
14817 
14818   ins_cost(BRANCH_COST);
14819   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14820   ins_encode %{
14821     Label* L = $labl$$label;
14822     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14823     if (cond == Assembler::EQ)
14824       __ cbzw($oop$$Register, *L);
14825     else
14826       __ cbnzw($oop$$Register, *L);
14827   %}
14828   ins_pipe(pipe_cmp_branch);
14829 %}
14830 
14831 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14832   match(If cmp (CmpU op1 op2));
14833   effect(USE labl);
14834 
14835   ins_cost(BRANCH_COST);
14836   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14837   ins_encode %{
14838     Label* L = $labl$$label;
14839     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14840     if (cond == Assembler::EQ || cond == Assembler::LS)
14841       __ cbzw($op1$$Register, *L);
14842     else
14843       __ cbnzw($op1$$Register, *L);
14844   %}
14845   ins_pipe(pipe_cmp_branch);
14846 %}
14847 
14848 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14849   match(If cmp (CmpUL op1 op2));
14850   effect(USE labl);
14851 
14852   ins_cost(BRANCH_COST);
14853   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14854   ins_encode %{
14855     Label* L = $labl$$label;
14856     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14857     if (cond == Assembler::EQ || cond == Assembler::LS)
14858       __ cbz($op1$$Register, *L);
14859     else
14860       __ cbnz($op1$$Register, *L);
14861   %}
14862   ins_pipe(pipe_cmp_branch);
14863 %}
14864 
14865 // Test bit and Branch
14866 
14867 // Patterns for short (&lt; 32KiB) variants
14868 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14869   match(If cmp (CmpL op1 op2));
14870   effect(USE labl);
14871 
14872   ins_cost(BRANCH_COST);
14873   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14874   ins_encode %{
14875     Label* L = $labl$$label;
14876     Assembler::Condition cond =
14877       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14878     __ tbr(cond, $op1$$Register, 63, *L);
14879   %}
14880   ins_pipe(pipe_cmp_branch);
14881   ins_short_branch(1);
14882 %}
14883 
14884 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14885   match(If cmp (CmpI op1 op2));
14886   effect(USE labl);
14887 
14888   ins_cost(BRANCH_COST);
14889   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14890   ins_encode %{
14891     Label* L = $labl$$label;
14892     Assembler::Condition cond =
14893       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14894     __ tbr(cond, $op1$$Register, 31, *L);
14895   %}
14896   ins_pipe(pipe_cmp_branch);
14897   ins_short_branch(1);
14898 %}
14899 
14900 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14901   match(If cmp (CmpL (AndL op1 op2) op3));
14902   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14903   effect(USE labl);
14904 
14905   ins_cost(BRANCH_COST);
14906   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14907   ins_encode %{
14908     Label* L = $labl$$label;
14909     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14910     int bit = exact_log2_long($op2$$constant);
14911     __ tbr(cond, $op1$$Register, bit, *L);
14912   %}
14913   ins_pipe(pipe_cmp_branch);
14914   ins_short_branch(1);
14915 %}
14916 
14917 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14918   match(If cmp (CmpI (AndI op1 op2) op3));
14919   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14920   effect(USE labl);
14921 
14922   ins_cost(BRANCH_COST);
14923   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14924   ins_encode %{
14925     Label* L = $labl$$label;
14926     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14927     int bit = exact_log2((juint)$op2$$constant);
14928     __ tbr(cond, $op1$$Register, bit, *L);
14929   %}
14930   ins_pipe(pipe_cmp_branch);
14931   ins_short_branch(1);
14932 %}
14933 
14934 // And far variants
14935 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14936   match(If cmp (CmpL op1 op2));
14937   effect(USE labl);
14938 
14939   ins_cost(BRANCH_COST);
14940   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14941   ins_encode %{
14942     Label* L = $labl$$label;
14943     Assembler::Condition cond =
14944       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14945     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14946   %}
14947   ins_pipe(pipe_cmp_branch);
14948 %}
14949 
14950 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14951   match(If cmp (CmpI op1 op2));
14952   effect(USE labl);
14953 
14954   ins_cost(BRANCH_COST);
14955   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14956   ins_encode %{
14957     Label* L = $labl$$label;
14958     Assembler::Condition cond =
14959       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14960     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14961   %}
14962   ins_pipe(pipe_cmp_branch);
14963 %}
14964 
14965 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14966   match(If cmp (CmpL (AndL op1 op2) op3));
14967   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14968   effect(USE labl);
14969 
14970   ins_cost(BRANCH_COST);
14971   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14972   ins_encode %{
14973     Label* L = $labl$$label;
14974     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14975     int bit = exact_log2_long($op2$$constant);
14976     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14977   %}
14978   ins_pipe(pipe_cmp_branch);
14979 %}
14980 
14981 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14982   match(If cmp (CmpI (AndI op1 op2) op3));
14983   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14984   effect(USE labl);
14985 
14986   ins_cost(BRANCH_COST);
14987   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14988   ins_encode %{
14989     Label* L = $labl$$label;
14990     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14991     int bit = exact_log2((juint)$op2$$constant);
14992     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14993   %}
14994   ins_pipe(pipe_cmp_branch);
14995 %}
14996 
14997 // Test bits
14998 
14999 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15000   match(Set cr (CmpL (AndL op1 op2) op3));
15001   predicate(Assembler::operand_valid_for_logical_immediate
15002             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15003 
15004   ins_cost(INSN_COST);
15005   format %{ &quot;tst $op1, $op2 # long&quot; %}
15006   ins_encode %{
15007     __ tst($op1$$Register, $op2$$constant);
15008   %}
15009   ins_pipe(ialu_reg_reg);
15010 %}
15011 
15012 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15013   match(Set cr (CmpI (AndI op1 op2) op3));
15014   predicate(Assembler::operand_valid_for_logical_immediate
15015             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15016 
15017   ins_cost(INSN_COST);
15018   format %{ &quot;tst $op1, $op2 # int&quot; %}
15019   ins_encode %{
15020     __ tstw($op1$$Register, $op2$$constant);
15021   %}
15022   ins_pipe(ialu_reg_reg);
15023 %}
15024 
15025 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15026   match(Set cr (CmpL (AndL op1 op2) op3));
15027 
15028   ins_cost(INSN_COST);
15029   format %{ &quot;tst $op1, $op2 # long&quot; %}
15030   ins_encode %{
15031     __ tst($op1$$Register, $op2$$Register);
15032   %}
15033   ins_pipe(ialu_reg_reg);
15034 %}
15035 
15036 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15037   match(Set cr (CmpI (AndI op1 op2) op3));
15038 
15039   ins_cost(INSN_COST);
15040   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15041   ins_encode %{
15042     __ tstw($op1$$Register, $op2$$Register);
15043   %}
15044   ins_pipe(ialu_reg_reg);
15045 %}
15046 
15047 
15048 // Conditional Far Branch
15049 // Conditional Far Branch Unsigned
15050 // TODO: fixme
15051 
15052 // counted loop end branch near
15053 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15054 %{
15055   match(CountedLoopEnd cmp cr);
15056 
15057   effect(USE lbl);
15058 
15059   ins_cost(BRANCH_COST);
15060   // short variant.
15061   // ins_short_branch(1);
15062   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15063 
15064   ins_encode(aarch64_enc_br_con(cmp, lbl));
15065 
15066   ins_pipe(pipe_branch);
15067 %}
15068 
15069 // counted loop end branch near Unsigned
15070 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15071 %{
15072   match(CountedLoopEnd cmp cr);
15073 
15074   effect(USE lbl);
15075 
15076   ins_cost(BRANCH_COST);
15077   // short variant.
15078   // ins_short_branch(1);
15079   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15080 
15081   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15082 
15083   ins_pipe(pipe_branch);
15084 %}
15085 
15086 // counted loop end branch far
15087 // counted loop end branch far unsigned
15088 // TODO: fixme
15089 
15090 // ============================================================================
15091 // inlined locking and unlocking
15092 
15093 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15094 %{
15095   match(Set cr (FastLock object box));
15096   effect(TEMP tmp, TEMP tmp2);
15097 
15098   // TODO
15099   // identify correct cost
15100   ins_cost(5 * INSN_COST);
15101   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15102 
15103   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15104 
15105   ins_pipe(pipe_serial);
15106 %}
15107 
15108 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15109 %{
15110   match(Set cr (FastUnlock object box));
15111   effect(TEMP tmp, TEMP tmp2);
15112 
15113   ins_cost(5 * INSN_COST);
15114   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15115 
15116   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15117 
15118   ins_pipe(pipe_serial);
15119 %}
15120 
15121 
15122 // ============================================================================
15123 // Safepoint Instructions
15124 
15125 // TODO
15126 // provide a near and far version of this code
15127 
15128 instruct safePoint(rFlagsReg cr, iRegP poll)
15129 %{
15130   match(SafePoint poll);
15131   effect(KILL cr);
15132 
15133   format %{
15134     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15135   %}
15136   ins_encode %{
15137     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15138   %}
15139   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15140 %}
15141 
15142 
15143 // ============================================================================
15144 // Procedure Call/Return Instructions
15145 
15146 // Call Java Static Instruction
15147 
15148 instruct CallStaticJavaDirect(method meth)
15149 %{
15150   match(CallStaticJava);
15151 
15152   effect(USE meth);
15153 
15154   ins_cost(CALL_COST);
15155 
15156   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15157 
15158   ins_encode( aarch64_enc_java_static_call(meth),
15159               aarch64_enc_call_epilog );
15160 
15161   ins_pipe(pipe_class_call);
15162 %}
15163 
15164 // TO HERE
15165 
15166 // Call Java Dynamic Instruction
15167 instruct CallDynamicJavaDirect(method meth)
15168 %{
15169   match(CallDynamicJava);
15170 
15171   effect(USE meth);
15172 
15173   ins_cost(CALL_COST);
15174 
15175   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15176 
15177   ins_encode( aarch64_enc_java_dynamic_call(meth),
15178                aarch64_enc_call_epilog );
15179 
15180   ins_pipe(pipe_class_call);
15181 %}
15182 
15183 // Call Runtime Instruction
15184 
15185 instruct CallRuntimeDirect(method meth)
15186 %{
15187   match(CallRuntime);
15188 
15189   effect(USE meth);
15190 
15191   ins_cost(CALL_COST);
15192 
15193   format %{ &quot;CALL, runtime $meth&quot; %}
15194 
15195   ins_encode( aarch64_enc_java_to_runtime(meth) );
15196 
15197   ins_pipe(pipe_class_call);
15198 %}
15199 
15200 // Call Runtime Instruction
15201 
15202 instruct CallLeafDirect(method meth)
15203 %{
15204   match(CallLeaf);
15205 
15206   effect(USE meth);
15207 
15208   ins_cost(CALL_COST);
15209 
15210   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15211 
15212   ins_encode( aarch64_enc_java_to_runtime(meth) );
15213 
15214   ins_pipe(pipe_class_call);
15215 %}
15216 
15217 // Call Runtime Instruction
15218 
15219 instruct CallLeafNoFPDirect(method meth)
15220 %{
15221   match(CallLeafNoFP);
15222 
15223   effect(USE meth);
15224 
15225   ins_cost(CALL_COST);
15226 
15227   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15228 
15229   ins_encode( aarch64_enc_java_to_runtime(meth) );
15230 
15231   ins_pipe(pipe_class_call);
15232 %}
15233 
15234 // Tail Call; Jump from runtime stub to Java code.
15235 // Also known as an &#39;interprocedural jump&#39;.
15236 // Target of jump will eventually return to caller.
15237 // TailJump below removes the return address.
15238 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15239 %{
15240   match(TailCall jump_target method_oop);
15241 
15242   ins_cost(CALL_COST);
15243 
15244   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15245 
15246   ins_encode(aarch64_enc_tail_call(jump_target));
15247 
15248   ins_pipe(pipe_class_call);
15249 %}
15250 
15251 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15252 %{
15253   match(TailJump jump_target ex_oop);
15254 
15255   ins_cost(CALL_COST);
15256 
15257   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15258 
15259   ins_encode(aarch64_enc_tail_jmp(jump_target));
15260 
15261   ins_pipe(pipe_class_call);
15262 %}
15263 
15264 // Create exception oop: created by stack-crawling runtime code.
15265 // Created exception is now available to this handler, and is setup
15266 // just prior to jumping to this handler. No code emitted.
15267 // TODO check
15268 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15269 instruct CreateException(iRegP_R0 ex_oop)
15270 %{
15271   match(Set ex_oop (CreateEx));
15272 
15273   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15274 
15275   size(0);
15276 
15277   ins_encode( /*empty*/ );
15278 
15279   ins_pipe(pipe_class_empty);
15280 %}
15281 
15282 // Rethrow exception: The exception oop will come in the first
15283 // argument position. Then JUMP (not call) to the rethrow stub code.
15284 instruct RethrowException() %{
15285   match(Rethrow);
15286   ins_cost(CALL_COST);
15287 
15288   format %{ &quot;b rethrow_stub&quot; %}
15289 
15290   ins_encode( aarch64_enc_rethrow() );
15291 
15292   ins_pipe(pipe_class_call);
15293 %}
15294 
15295 
15296 // Return Instruction
15297 // epilog node loads ret address into lr as part of frame pop
15298 instruct Ret()
15299 %{
15300   match(Return);
15301 
15302   format %{ &quot;ret\t// return register&quot; %}
15303 
15304   ins_encode( aarch64_enc_ret() );
15305 
15306   ins_pipe(pipe_branch);
15307 %}
15308 
15309 // Die now.
15310 instruct ShouldNotReachHere() %{
15311   match(Halt);
15312 
15313   ins_cost(CALL_COST);
15314   format %{ &quot;ShouldNotReachHere&quot; %}
15315 
15316   ins_encode %{
15317     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15318     // return true
15319     __ dpcs1(0xdead + 1);
15320   %}
15321 
15322   ins_pipe(pipe_class_default);
15323 %}
15324 
15325 // ============================================================================
15326 // Partial Subtype Check
15327 //
15328 // superklass array for an instance of the superklass.  Set a hidden
15329 // internal cache on a hit (cache is checked with exposed code in
15330 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15331 // encoding ALSO sets flags.
15332 
15333 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15334 %{
15335   match(Set result (PartialSubtypeCheck sub super));
15336   effect(KILL cr, KILL temp);
15337 
15338   ins_cost(1100);  // slightly larger than the next version
15339   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15340 
15341   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15342 
15343   opcode(0x1); // Force zero of result reg on hit
15344 
15345   ins_pipe(pipe_class_memory);
15346 %}
15347 
15348 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15349 %{
15350   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15351   effect(KILL temp, KILL result);
15352 
15353   ins_cost(1100);  // slightly larger than the next version
15354   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15355 
15356   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15357 
15358   opcode(0x0); // Don&#39;t zero result reg on hit
15359 
15360   ins_pipe(pipe_class_memory);
15361 %}
15362 
15363 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15364                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15365 %{
15366   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15367   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15368   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15369 
15370   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15371   ins_encode %{
15372     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15373     __ string_compare($str1$$Register, $str2$$Register,
15374                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15375                       $tmp1$$Register, $tmp2$$Register,
15376                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15377   %}
15378   ins_pipe(pipe_class_memory);
15379 %}
15380 
15381 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15382                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15383 %{
15384   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15385   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15386   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15387 
15388   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15389   ins_encode %{
15390     __ string_compare($str1$$Register, $str2$$Register,
15391                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15392                       $tmp1$$Register, $tmp2$$Register,
15393                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15394   %}
15395   ins_pipe(pipe_class_memory);
15396 %}
15397 
15398 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15399                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15400                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15401 %{
15402   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15403   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15404   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15405          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15406 
15407   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15408   ins_encode %{
15409     __ string_compare($str1$$Register, $str2$$Register,
15410                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15411                       $tmp1$$Register, $tmp2$$Register,
15412                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15413                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15414   %}
15415   ins_pipe(pipe_class_memory);
15416 %}
15417 
15418 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15419                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15420                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15421 %{
15422   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15423   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15424   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15425          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15426 
15427   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15428   ins_encode %{
15429     __ string_compare($str1$$Register, $str2$$Register,
15430                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15431                       $tmp1$$Register, $tmp2$$Register,
15432                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15433                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15434   %}
15435   ins_pipe(pipe_class_memory);
15436 %}
15437 
15438 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15439        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15440        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15441 %{
15442   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15443   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15444   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15445          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15446   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15447 
15448   ins_encode %{
15449     __ string_indexof($str1$$Register, $str2$$Register,
15450                       $cnt1$$Register, $cnt2$$Register,
15451                       $tmp1$$Register, $tmp2$$Register,
15452                       $tmp3$$Register, $tmp4$$Register,
15453                       $tmp5$$Register, $tmp6$$Register,
15454                       -1, $result$$Register, StrIntrinsicNode::UU);
15455   %}
15456   ins_pipe(pipe_class_memory);
15457 %}
15458 
15459 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15460        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15461        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15462 %{
15463   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15464   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15465   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15466          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15467   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15468 
15469   ins_encode %{
15470     __ string_indexof($str1$$Register, $str2$$Register,
15471                       $cnt1$$Register, $cnt2$$Register,
15472                       $tmp1$$Register, $tmp2$$Register,
15473                       $tmp3$$Register, $tmp4$$Register,
15474                       $tmp5$$Register, $tmp6$$Register,
15475                       -1, $result$$Register, StrIntrinsicNode::LL);
15476   %}
15477   ins_pipe(pipe_class_memory);
15478 %}
15479 
15480 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15481        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15482        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15483 %{
15484   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15485   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15486   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15487          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15488   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15489 
15490   ins_encode %{
15491     __ string_indexof($str1$$Register, $str2$$Register,
15492                       $cnt1$$Register, $cnt2$$Register,
15493                       $tmp1$$Register, $tmp2$$Register,
15494                       $tmp3$$Register, $tmp4$$Register,
15495                       $tmp5$$Register, $tmp6$$Register,
15496                       -1, $result$$Register, StrIntrinsicNode::UL);
15497   %}
15498   ins_pipe(pipe_class_memory);
15499 %}
15500 
15501 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15502                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15503                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15504 %{
15505   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15506   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15507   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15508          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15509   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15510 
15511   ins_encode %{
15512     int icnt2 = (int)$int_cnt2$$constant;
15513     __ string_indexof($str1$$Register, $str2$$Register,
15514                       $cnt1$$Register, zr,
15515                       $tmp1$$Register, $tmp2$$Register,
15516                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15517                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15518   %}
15519   ins_pipe(pipe_class_memory);
15520 %}
15521 
15522 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15523                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15524                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15525 %{
15526   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15527   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15528   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15529          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15530   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15531 
15532   ins_encode %{
15533     int icnt2 = (int)$int_cnt2$$constant;
15534     __ string_indexof($str1$$Register, $str2$$Register,
15535                       $cnt1$$Register, zr,
15536                       $tmp1$$Register, $tmp2$$Register,
15537                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15538                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15539   %}
15540   ins_pipe(pipe_class_memory);
15541 %}
15542 
15543 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15544                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15545                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15546 %{
15547   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15548   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15549   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15550          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15551   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15552 
15553   ins_encode %{
15554     int icnt2 = (int)$int_cnt2$$constant;
15555     __ string_indexof($str1$$Register, $str2$$Register,
15556                       $cnt1$$Register, zr,
15557                       $tmp1$$Register, $tmp2$$Register,
15558                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15559                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15560   %}
15561   ins_pipe(pipe_class_memory);
15562 %}
15563 
15564 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15565                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15566                               iRegINoSp tmp3, rFlagsReg cr)
15567 %{
15568   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15569   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15570          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15571 
15572   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15573 
15574   ins_encode %{
15575     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15576                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15577                            $tmp3$$Register);
15578   %}
15579   ins_pipe(pipe_class_memory);
15580 %}
15581 
15582 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15583                         iRegI_R0 result, rFlagsReg cr)
15584 %{
15585   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15586   match(Set result (StrEquals (Binary str1 str2) cnt));
15587   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15588 
15589   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15590   ins_encode %{
15591     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15592     __ string_equals($str1$$Register, $str2$$Register,
15593                      $result$$Register, $cnt$$Register, 1);
15594   %}
15595   ins_pipe(pipe_class_memory);
15596 %}
15597 
15598 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15599                         iRegI_R0 result, rFlagsReg cr)
15600 %{
15601   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15602   match(Set result (StrEquals (Binary str1 str2) cnt));
15603   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15604 
15605   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15606   ins_encode %{
15607     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15608     __ string_equals($str1$$Register, $str2$$Register,
15609                      $result$$Register, $cnt$$Register, 2);
15610   %}
15611   ins_pipe(pipe_class_memory);
15612 %}
15613 
15614 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15615                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15616                        iRegP_R10 tmp, rFlagsReg cr)
15617 %{
15618   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15619   match(Set result (AryEq ary1 ary2));
15620   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15621 
15622   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15623   ins_encode %{
15624     __ arrays_equals($ary1$$Register, $ary2$$Register,
15625                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15626                      $result$$Register, $tmp$$Register, 1);
15627     %}
15628   ins_pipe(pipe_class_memory);
15629 %}
15630 
15631 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15632                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15633                        iRegP_R10 tmp, rFlagsReg cr)
15634 %{
15635   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15636   match(Set result (AryEq ary1 ary2));
15637   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15638 
15639   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15640   ins_encode %{
15641     __ arrays_equals($ary1$$Register, $ary2$$Register,
15642                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15643                      $result$$Register, $tmp$$Register, 2);
15644   %}
15645   ins_pipe(pipe_class_memory);
15646 %}
15647 
15648 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15649 %{
15650   match(Set result (HasNegatives ary1 len));
15651   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15652   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15653   ins_encode %{
15654     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15655   %}
15656   ins_pipe( pipe_slow );
15657 %}
15658 
15659 // fast char[] to byte[] compression
15660 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15661                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15662                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15663                          iRegI_R0 result, rFlagsReg cr)
15664 %{
15665   match(Set result (StrCompressedCopy src (Binary dst len)));
15666   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15667 
15668   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15669   ins_encode %{
15670     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15671                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15672                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15673                            $result$$Register);
15674   %}
15675   ins_pipe( pipe_slow );
15676 %}
15677 
15678 // fast byte[] to char[] inflation
15679 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15680                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15681 %{
15682   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15683   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15684 
15685   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15686   ins_encode %{
15687     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15688                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15689   %}
15690   ins_pipe(pipe_class_memory);
15691 %}
15692 
15693 // encode char[] to byte[] in ISO_8859_1
15694 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15695                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15696                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15697                           iRegI_R0 result, rFlagsReg cr)
15698 %{
15699   match(Set result (EncodeISOArray src (Binary dst len)));
15700   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15701          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15702 
15703   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15704   ins_encode %{
15705     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15706          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15707          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15708   %}
15709   ins_pipe( pipe_class_memory );
15710 %}
15711 
15712 // ============================================================================
15713 // This name is KNOWN by the ADLC and cannot be changed.
15714 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15715 // for this guy.
15716 instruct tlsLoadP(thread_RegP dst)
15717 %{
15718   match(Set dst (ThreadLocal));
15719 
15720   ins_cost(0);
15721 
15722   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15723 
15724   size(0);
15725 
15726   ins_encode( /*empty*/ );
15727 
15728   ins_pipe(pipe_class_empty);
15729 %}
15730 
15731 // ====================VECTOR INSTRUCTIONS=====================================
15732 
15733 // Load vector (32 bits)
15734 instruct loadV4(vecD dst, vmem4 mem)
15735 %{
15736   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15737   match(Set dst (LoadVector mem));
15738   ins_cost(4 * INSN_COST);
15739   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15740   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15741   ins_pipe(vload_reg_mem64);
15742 %}
15743 
15744 // Load vector (64 bits)
15745 instruct loadV8(vecD dst, vmem8 mem)
15746 %{
15747   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15748   match(Set dst (LoadVector mem));
15749   ins_cost(4 * INSN_COST);
15750   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15751   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15752   ins_pipe(vload_reg_mem64);
15753 %}
15754 
15755 // Load Vector (128 bits)
15756 instruct loadV16(vecX dst, vmem16 mem)
15757 %{
15758   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15759   match(Set dst (LoadVector mem));
15760   ins_cost(4 * INSN_COST);
15761   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15762   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15763   ins_pipe(vload_reg_mem128);
15764 %}
15765 
15766 // Store Vector (32 bits)
15767 instruct storeV4(vecD src, vmem4 mem)
15768 %{
15769   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15770   match(Set mem (StoreVector mem src));
15771   ins_cost(4 * INSN_COST);
15772   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15773   ins_encode( aarch64_enc_strvS(src, mem) );
15774   ins_pipe(vstore_reg_mem64);
15775 %}
15776 
15777 // Store Vector (64 bits)
15778 instruct storeV8(vecD src, vmem8 mem)
15779 %{
15780   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15781   match(Set mem (StoreVector mem src));
15782   ins_cost(4 * INSN_COST);
15783   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15784   ins_encode( aarch64_enc_strvD(src, mem) );
15785   ins_pipe(vstore_reg_mem64);
15786 %}
15787 
15788 // Store Vector (128 bits)
15789 instruct storeV16(vecX src, vmem16 mem)
15790 %{
15791   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15792   match(Set mem (StoreVector mem src));
15793   ins_cost(4 * INSN_COST);
15794   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15795   ins_encode( aarch64_enc_strvQ(src, mem) );
15796   ins_pipe(vstore_reg_mem128);
15797 %}
15798 
15799 instruct replicate8B(vecD dst, iRegIorL2I src)
15800 %{
15801   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15802             n-&gt;as_Vector()-&gt;length() == 8);
15803   match(Set dst (ReplicateB src));
15804   ins_cost(INSN_COST);
15805   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15806   ins_encode %{
15807     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15808   %}
15809   ins_pipe(vdup_reg_reg64);
15810 %}
15811 
15812 instruct replicate16B(vecX dst, iRegIorL2I src)
15813 %{
15814   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15815   match(Set dst (ReplicateB src));
15816   ins_cost(INSN_COST);
15817   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15818   ins_encode %{
15819     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15820   %}
15821   ins_pipe(vdup_reg_reg128);
15822 %}
15823 
15824 instruct replicate8B_imm(vecD dst, immI con)
15825 %{
15826   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15827             n-&gt;as_Vector()-&gt;length() == 8);
15828   match(Set dst (ReplicateB con));
15829   ins_cost(INSN_COST);
15830   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15831   ins_encode %{
15832     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15833   %}
15834   ins_pipe(vmovi_reg_imm64);
15835 %}
15836 
15837 instruct replicate16B_imm(vecX dst, immI con)
15838 %{
15839   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15840   match(Set dst (ReplicateB con));
15841   ins_cost(INSN_COST);
15842   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15843   ins_encode %{
15844     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15845   %}
15846   ins_pipe(vmovi_reg_imm128);
15847 %}
15848 
15849 instruct replicate4S(vecD dst, iRegIorL2I src)
15850 %{
15851   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15852             n-&gt;as_Vector()-&gt;length() == 4);
15853   match(Set dst (ReplicateS src));
15854   ins_cost(INSN_COST);
15855   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15856   ins_encode %{
15857     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15858   %}
15859   ins_pipe(vdup_reg_reg64);
15860 %}
15861 
15862 instruct replicate8S(vecX dst, iRegIorL2I src)
15863 %{
15864   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15865   match(Set dst (ReplicateS src));
15866   ins_cost(INSN_COST);
15867   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15868   ins_encode %{
15869     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15870   %}
15871   ins_pipe(vdup_reg_reg128);
15872 %}
15873 
15874 instruct replicate4S_imm(vecD dst, immI con)
15875 %{
15876   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15877             n-&gt;as_Vector()-&gt;length() == 4);
15878   match(Set dst (ReplicateS con));
15879   ins_cost(INSN_COST);
15880   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15881   ins_encode %{
15882     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15883   %}
15884   ins_pipe(vmovi_reg_imm64);
15885 %}
15886 
15887 instruct replicate8S_imm(vecX dst, immI con)
15888 %{
15889   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15890   match(Set dst (ReplicateS con));
15891   ins_cost(INSN_COST);
15892   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15893   ins_encode %{
15894     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15895   %}
15896   ins_pipe(vmovi_reg_imm128);
15897 %}
15898 
15899 instruct replicate2I(vecD dst, iRegIorL2I src)
15900 %{
15901   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15902   match(Set dst (ReplicateI src));
15903   ins_cost(INSN_COST);
15904   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15905   ins_encode %{
15906     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15907   %}
15908   ins_pipe(vdup_reg_reg64);
15909 %}
15910 
15911 instruct replicate4I(vecX dst, iRegIorL2I src)
15912 %{
15913   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15914   match(Set dst (ReplicateI src));
15915   ins_cost(INSN_COST);
15916   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15917   ins_encode %{
15918     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15919   %}
15920   ins_pipe(vdup_reg_reg128);
15921 %}
15922 
15923 instruct replicate2I_imm(vecD dst, immI con)
15924 %{
15925   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15926   match(Set dst (ReplicateI con));
15927   ins_cost(INSN_COST);
15928   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15929   ins_encode %{
15930     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15931   %}
15932   ins_pipe(vmovi_reg_imm64);
15933 %}
15934 
15935 instruct replicate4I_imm(vecX dst, immI con)
15936 %{
15937   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15938   match(Set dst (ReplicateI con));
15939   ins_cost(INSN_COST);
15940   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15941   ins_encode %{
15942     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15943   %}
15944   ins_pipe(vmovi_reg_imm128);
15945 %}
15946 
15947 instruct replicate2L(vecX dst, iRegL src)
15948 %{
15949   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15950   match(Set dst (ReplicateL src));
15951   ins_cost(INSN_COST);
15952   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15953   ins_encode %{
15954     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15955   %}
15956   ins_pipe(vdup_reg_reg128);
15957 %}
15958 
15959 instruct replicate2L_zero(vecX dst, immI0 zero)
15960 %{
15961   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15962   match(Set dst (ReplicateI zero));
15963   ins_cost(INSN_COST);
15964   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15965   ins_encode %{
15966     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15967            as_FloatRegister($dst$$reg),
15968            as_FloatRegister($dst$$reg));
15969   %}
15970   ins_pipe(vmovi_reg_imm128);
15971 %}
15972 
15973 instruct replicate2F(vecD dst, vRegF src)
15974 %{
15975   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15976   match(Set dst (ReplicateF src));
15977   ins_cost(INSN_COST);
15978   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15979   ins_encode %{
15980     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15981            as_FloatRegister($src$$reg));
15982   %}
15983   ins_pipe(vdup_reg_freg64);
15984 %}
15985 
15986 instruct replicate4F(vecX dst, vRegF src)
15987 %{
15988   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15989   match(Set dst (ReplicateF src));
15990   ins_cost(INSN_COST);
15991   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
15992   ins_encode %{
15993     __ dup(as_FloatRegister($dst$$reg), __ T4S,
15994            as_FloatRegister($src$$reg));
15995   %}
15996   ins_pipe(vdup_reg_freg128);
15997 %}
15998 
15999 instruct replicate2D(vecX dst, vRegD src)
16000 %{
16001   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16002   match(Set dst (ReplicateD src));
16003   ins_cost(INSN_COST);
16004   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16005   ins_encode %{
16006     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16007            as_FloatRegister($src$$reg));
16008   %}
16009   ins_pipe(vdup_reg_dreg128);
16010 %}
16011 
16012 // ====================REDUCTION ARITHMETIC====================================
16013 
16014 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16015 %{
16016   match(Set dst (AddReductionVI isrc vsrc));
16017   ins_cost(INSN_COST);
16018   effect(TEMP tmp, TEMP tmp2);
16019   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16020             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16021             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16022             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16023   %}
16024   ins_encode %{
16025     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16026     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16027     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16028     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16029   %}
16030   ins_pipe(pipe_class_default);
16031 %}
16032 
16033 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16034 %{
16035   match(Set dst (AddReductionVI isrc vsrc));
16036   ins_cost(INSN_COST);
16037   effect(TEMP vtmp, TEMP itmp);
16038   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16039             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16040             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16041   %}
16042   ins_encode %{
16043     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16044             as_FloatRegister($vsrc$$reg));
16045     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16046     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16047   %}
16048   ins_pipe(pipe_class_default);
16049 %}
16050 
16051 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16052 %{
16053   match(Set dst (MulReductionVI isrc vsrc));
16054   ins_cost(INSN_COST);
16055   effect(TEMP tmp, TEMP dst);
16056   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16057             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16058             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16059             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16060   %}
16061   ins_encode %{
16062     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16063     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16064     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16065     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16066   %}
16067   ins_pipe(pipe_class_default);
16068 %}
16069 
16070 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16071 %{
16072   match(Set dst (MulReductionVI isrc vsrc));
16073   ins_cost(INSN_COST);
16074   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16075   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16076             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16077             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16078             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16079             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16080             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16081   %}
16082   ins_encode %{
16083     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16084            as_FloatRegister($vsrc$$reg), 0, 1);
16085     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16086             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16087     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16088     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16089     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16090     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16091   %}
16092   ins_pipe(pipe_class_default);
16093 %}
16094 
16095 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16096 %{
16097   match(Set dst (AddReductionVF fsrc vsrc));
16098   ins_cost(INSN_COST);
16099   effect(TEMP tmp, TEMP dst);
16100   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16101             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16102             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16103   %}
16104   ins_encode %{
16105     __ fadds(as_FloatRegister($dst$$reg),
16106              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16107     __ ins(as_FloatRegister($tmp$$reg), __ S,
16108            as_FloatRegister($vsrc$$reg), 0, 1);
16109     __ fadds(as_FloatRegister($dst$$reg),
16110              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16111   %}
16112   ins_pipe(pipe_class_default);
16113 %}
16114 
16115 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16116 %{
16117   match(Set dst (AddReductionVF fsrc vsrc));
16118   ins_cost(INSN_COST);
16119   effect(TEMP tmp, TEMP dst);
16120   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16121             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16122             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16123             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16124             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16125             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16126             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16127   %}
16128   ins_encode %{
16129     __ fadds(as_FloatRegister($dst$$reg),
16130              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16131     __ ins(as_FloatRegister($tmp$$reg), __ S,
16132            as_FloatRegister($vsrc$$reg), 0, 1);
16133     __ fadds(as_FloatRegister($dst$$reg),
16134              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16135     __ ins(as_FloatRegister($tmp$$reg), __ S,
16136            as_FloatRegister($vsrc$$reg), 0, 2);
16137     __ fadds(as_FloatRegister($dst$$reg),
16138              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16139     __ ins(as_FloatRegister($tmp$$reg), __ S,
16140            as_FloatRegister($vsrc$$reg), 0, 3);
16141     __ fadds(as_FloatRegister($dst$$reg),
16142              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16143   %}
16144   ins_pipe(pipe_class_default);
16145 %}
16146 
16147 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16148 %{
16149   match(Set dst (MulReductionVF fsrc vsrc));
16150   ins_cost(INSN_COST);
16151   effect(TEMP tmp, TEMP dst);
16152   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16153             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16154             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16155   %}
16156   ins_encode %{
16157     __ fmuls(as_FloatRegister($dst$$reg),
16158              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16159     __ ins(as_FloatRegister($tmp$$reg), __ S,
16160            as_FloatRegister($vsrc$$reg), 0, 1);
16161     __ fmuls(as_FloatRegister($dst$$reg),
16162              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16163   %}
16164   ins_pipe(pipe_class_default);
16165 %}
16166 
16167 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16168 %{
16169   match(Set dst (MulReductionVF fsrc vsrc));
16170   ins_cost(INSN_COST);
16171   effect(TEMP tmp, TEMP dst);
16172   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16173             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16174             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16175             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16176             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16177             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16178             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16179   %}
16180   ins_encode %{
16181     __ fmuls(as_FloatRegister($dst$$reg),
16182              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16183     __ ins(as_FloatRegister($tmp$$reg), __ S,
16184            as_FloatRegister($vsrc$$reg), 0, 1);
16185     __ fmuls(as_FloatRegister($dst$$reg),
16186              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16187     __ ins(as_FloatRegister($tmp$$reg), __ S,
16188            as_FloatRegister($vsrc$$reg), 0, 2);
16189     __ fmuls(as_FloatRegister($dst$$reg),
16190              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16191     __ ins(as_FloatRegister($tmp$$reg), __ S,
16192            as_FloatRegister($vsrc$$reg), 0, 3);
16193     __ fmuls(as_FloatRegister($dst$$reg),
16194              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16195   %}
16196   ins_pipe(pipe_class_default);
16197 %}
16198 
16199 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16200 %{
16201   match(Set dst (AddReductionVD dsrc vsrc));
16202   ins_cost(INSN_COST);
16203   effect(TEMP tmp, TEMP dst);
16204   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16205             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16206             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16207   %}
16208   ins_encode %{
16209     __ faddd(as_FloatRegister($dst$$reg),
16210              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16211     __ ins(as_FloatRegister($tmp$$reg), __ D,
16212            as_FloatRegister($vsrc$$reg), 0, 1);
16213     __ faddd(as_FloatRegister($dst$$reg),
16214              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16215   %}
16216   ins_pipe(pipe_class_default);
16217 %}
16218 
16219 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16220 %{
16221   match(Set dst (MulReductionVD dsrc vsrc));
16222   ins_cost(INSN_COST);
16223   effect(TEMP tmp, TEMP dst);
16224   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16225             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16226             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16227   %}
16228   ins_encode %{
16229     __ fmuld(as_FloatRegister($dst$$reg),
16230              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16231     __ ins(as_FloatRegister($tmp$$reg), __ D,
16232            as_FloatRegister($vsrc$$reg), 0, 1);
16233     __ fmuld(as_FloatRegister($dst$$reg),
16234              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16235   %}
16236   ins_pipe(pipe_class_default);
16237 %}
16238 
16239 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16240   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16241   match(Set dst (MaxReductionV fsrc vsrc));
16242   ins_cost(INSN_COST);
16243   effect(TEMP_DEF dst, TEMP tmp);
16244   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16245             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16246             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16247   ins_encode %{
16248     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16249     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16250     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16251   %}
16252   ins_pipe(pipe_class_default);
16253 %}
16254 
16255 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16256   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16257   match(Set dst (MaxReductionV fsrc vsrc));
16258   ins_cost(INSN_COST);
16259   effect(TEMP_DEF dst);
16260   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16261             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16262   ins_encode %{
16263     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16264     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16265   %}
16266   ins_pipe(pipe_class_default);
16267 %}
16268 
16269 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16270   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16271   match(Set dst (MaxReductionV dsrc vsrc));
16272   ins_cost(INSN_COST);
16273   effect(TEMP_DEF dst, TEMP tmp);
16274   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16275             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16276             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16277   ins_encode %{
16278     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16279     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16280     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16281   %}
16282   ins_pipe(pipe_class_default);
16283 %}
16284 
16285 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16286   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16287   match(Set dst (MinReductionV fsrc vsrc));
16288   ins_cost(INSN_COST);
16289   effect(TEMP_DEF dst, TEMP tmp);
16290   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16291             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16292             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16293   ins_encode %{
16294     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16295     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16296     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16297   %}
16298   ins_pipe(pipe_class_default);
16299 %}
16300 
16301 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16302   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16303   match(Set dst (MinReductionV fsrc vsrc));
16304   ins_cost(INSN_COST);
16305   effect(TEMP_DEF dst);
16306   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16307             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16308   ins_encode %{
16309     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16310     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16311   %}
16312   ins_pipe(pipe_class_default);
16313 %}
16314 
16315 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16316   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16317   match(Set dst (MinReductionV dsrc vsrc));
16318   ins_cost(INSN_COST);
16319   effect(TEMP_DEF dst, TEMP tmp);
16320   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16321             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16322             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16323   ins_encode %{
16324     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16325     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16326     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16327   %}
16328   ins_pipe(pipe_class_default);
16329 %}
16330 
16331 // ====================VECTOR ARITHMETIC=======================================
16332 
16333 // --------------------------------- ADD --------------------------------------
16334 
16335 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16336 %{
16337   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16338             n-&gt;as_Vector()-&gt;length() == 8);
16339   match(Set dst (AddVB src1 src2));
16340   ins_cost(INSN_COST);
16341   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16342   ins_encode %{
16343     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16344             as_FloatRegister($src1$$reg),
16345             as_FloatRegister($src2$$reg));
16346   %}
16347   ins_pipe(vdop64);
16348 %}
16349 
16350 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16351 %{
16352   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16353   match(Set dst (AddVB src1 src2));
16354   ins_cost(INSN_COST);
16355   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16356   ins_encode %{
16357     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16358             as_FloatRegister($src1$$reg),
16359             as_FloatRegister($src2$$reg));
16360   %}
16361   ins_pipe(vdop128);
16362 %}
16363 
16364 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16365 %{
16366   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16367             n-&gt;as_Vector()-&gt;length() == 4);
16368   match(Set dst (AddVS src1 src2));
16369   ins_cost(INSN_COST);
16370   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16371   ins_encode %{
16372     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16373             as_FloatRegister($src1$$reg),
16374             as_FloatRegister($src2$$reg));
16375   %}
16376   ins_pipe(vdop64);
16377 %}
16378 
16379 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16380 %{
16381   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16382   match(Set dst (AddVS src1 src2));
16383   ins_cost(INSN_COST);
16384   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16385   ins_encode %{
16386     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16387             as_FloatRegister($src1$$reg),
16388             as_FloatRegister($src2$$reg));
16389   %}
16390   ins_pipe(vdop128);
16391 %}
16392 
16393 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16394 %{
16395   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16396   match(Set dst (AddVI src1 src2));
16397   ins_cost(INSN_COST);
16398   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16399   ins_encode %{
16400     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16401             as_FloatRegister($src1$$reg),
16402             as_FloatRegister($src2$$reg));
16403   %}
16404   ins_pipe(vdop64);
16405 %}
16406 
16407 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16408 %{
16409   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16410   match(Set dst (AddVI src1 src2));
16411   ins_cost(INSN_COST);
16412   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16413   ins_encode %{
16414     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16415             as_FloatRegister($src1$$reg),
16416             as_FloatRegister($src2$$reg));
16417   %}
16418   ins_pipe(vdop128);
16419 %}
16420 
16421 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16422 %{
16423   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16424   match(Set dst (AddVL src1 src2));
16425   ins_cost(INSN_COST);
16426   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16427   ins_encode %{
16428     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16429             as_FloatRegister($src1$$reg),
16430             as_FloatRegister($src2$$reg));
16431   %}
16432   ins_pipe(vdop128);
16433 %}
16434 
16435 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16436 %{
16437   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16438   match(Set dst (AddVF src1 src2));
16439   ins_cost(INSN_COST);
16440   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16441   ins_encode %{
16442     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16443             as_FloatRegister($src1$$reg),
16444             as_FloatRegister($src2$$reg));
16445   %}
16446   ins_pipe(vdop_fp64);
16447 %}
16448 
16449 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16450 %{
16451   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16452   match(Set dst (AddVF src1 src2));
16453   ins_cost(INSN_COST);
16454   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16455   ins_encode %{
16456     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16457             as_FloatRegister($src1$$reg),
16458             as_FloatRegister($src2$$reg));
16459   %}
16460   ins_pipe(vdop_fp128);
16461 %}
16462 
16463 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16464 %{
16465   match(Set dst (AddVD src1 src2));
16466   ins_cost(INSN_COST);
16467   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16468   ins_encode %{
16469     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16470             as_FloatRegister($src1$$reg),
16471             as_FloatRegister($src2$$reg));
16472   %}
16473   ins_pipe(vdop_fp128);
16474 %}
16475 
16476 // --------------------------------- SUB --------------------------------------
16477 
16478 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16479 %{
16480   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16481             n-&gt;as_Vector()-&gt;length() == 8);
16482   match(Set dst (SubVB src1 src2));
16483   ins_cost(INSN_COST);
16484   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16485   ins_encode %{
16486     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16487             as_FloatRegister($src1$$reg),
16488             as_FloatRegister($src2$$reg));
16489   %}
16490   ins_pipe(vdop64);
16491 %}
16492 
16493 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16494 %{
16495   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16496   match(Set dst (SubVB src1 src2));
16497   ins_cost(INSN_COST);
16498   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16499   ins_encode %{
16500     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16501             as_FloatRegister($src1$$reg),
16502             as_FloatRegister($src2$$reg));
16503   %}
16504   ins_pipe(vdop128);
16505 %}
16506 
16507 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16508 %{
16509   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16510             n-&gt;as_Vector()-&gt;length() == 4);
16511   match(Set dst (SubVS src1 src2));
16512   ins_cost(INSN_COST);
16513   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16514   ins_encode %{
16515     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16516             as_FloatRegister($src1$$reg),
16517             as_FloatRegister($src2$$reg));
16518   %}
16519   ins_pipe(vdop64);
16520 %}
16521 
16522 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16523 %{
16524   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16525   match(Set dst (SubVS src1 src2));
16526   ins_cost(INSN_COST);
16527   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16528   ins_encode %{
16529     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16530             as_FloatRegister($src1$$reg),
16531             as_FloatRegister($src2$$reg));
16532   %}
16533   ins_pipe(vdop128);
16534 %}
16535 
16536 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16537 %{
16538   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16539   match(Set dst (SubVI src1 src2));
16540   ins_cost(INSN_COST);
16541   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16542   ins_encode %{
16543     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16544             as_FloatRegister($src1$$reg),
16545             as_FloatRegister($src2$$reg));
16546   %}
16547   ins_pipe(vdop64);
16548 %}
16549 
16550 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16551 %{
16552   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16553   match(Set dst (SubVI src1 src2));
16554   ins_cost(INSN_COST);
16555   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16556   ins_encode %{
16557     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16558             as_FloatRegister($src1$$reg),
16559             as_FloatRegister($src2$$reg));
16560   %}
16561   ins_pipe(vdop128);
16562 %}
16563 
16564 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16565 %{
16566   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16567   match(Set dst (SubVL src1 src2));
16568   ins_cost(INSN_COST);
16569   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16570   ins_encode %{
16571     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16572             as_FloatRegister($src1$$reg),
16573             as_FloatRegister($src2$$reg));
16574   %}
16575   ins_pipe(vdop128);
16576 %}
16577 
16578 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16579 %{
16580   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16581   match(Set dst (SubVF src1 src2));
16582   ins_cost(INSN_COST);
16583   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16584   ins_encode %{
16585     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16586             as_FloatRegister($src1$$reg),
16587             as_FloatRegister($src2$$reg));
16588   %}
16589   ins_pipe(vdop_fp64);
16590 %}
16591 
16592 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16593 %{
16594   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16595   match(Set dst (SubVF src1 src2));
16596   ins_cost(INSN_COST);
16597   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16598   ins_encode %{
16599     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16600             as_FloatRegister($src1$$reg),
16601             as_FloatRegister($src2$$reg));
16602   %}
16603   ins_pipe(vdop_fp128);
16604 %}
16605 
16606 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16607 %{
16608   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16609   match(Set dst (SubVD src1 src2));
16610   ins_cost(INSN_COST);
16611   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16612   ins_encode %{
16613     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16614             as_FloatRegister($src1$$reg),
16615             as_FloatRegister($src2$$reg));
16616   %}
16617   ins_pipe(vdop_fp128);
16618 %}
16619 
16620 // --------------------------------- MUL --------------------------------------
16621 
16622 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16623 %{
16624   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16625             n-&gt;as_Vector()-&gt;length() == 4);
16626   match(Set dst (MulVS src1 src2));
16627   ins_cost(INSN_COST);
16628   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16629   ins_encode %{
16630     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16631             as_FloatRegister($src1$$reg),
16632             as_FloatRegister($src2$$reg));
16633   %}
16634   ins_pipe(vmul64);
16635 %}
16636 
16637 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16638 %{
16639   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16640   match(Set dst (MulVS src1 src2));
16641   ins_cost(INSN_COST);
16642   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16643   ins_encode %{
16644     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16645             as_FloatRegister($src1$$reg),
16646             as_FloatRegister($src2$$reg));
16647   %}
16648   ins_pipe(vmul128);
16649 %}
16650 
16651 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16652 %{
16653   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16654   match(Set dst (MulVI src1 src2));
16655   ins_cost(INSN_COST);
16656   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16657   ins_encode %{
16658     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16659             as_FloatRegister($src1$$reg),
16660             as_FloatRegister($src2$$reg));
16661   %}
16662   ins_pipe(vmul64);
16663 %}
16664 
16665 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16666 %{
16667   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16668   match(Set dst (MulVI src1 src2));
16669   ins_cost(INSN_COST);
16670   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16671   ins_encode %{
16672     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16673             as_FloatRegister($src1$$reg),
16674             as_FloatRegister($src2$$reg));
16675   %}
16676   ins_pipe(vmul128);
16677 %}
16678 
16679 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16680 %{
16681   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16682   match(Set dst (MulVF src1 src2));
16683   ins_cost(INSN_COST);
16684   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16685   ins_encode %{
16686     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16687             as_FloatRegister($src1$$reg),
16688             as_FloatRegister($src2$$reg));
16689   %}
16690   ins_pipe(vmuldiv_fp64);
16691 %}
16692 
16693 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16694 %{
16695   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16696   match(Set dst (MulVF src1 src2));
16697   ins_cost(INSN_COST);
16698   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16699   ins_encode %{
16700     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16701             as_FloatRegister($src1$$reg),
16702             as_FloatRegister($src2$$reg));
16703   %}
16704   ins_pipe(vmuldiv_fp128);
16705 %}
16706 
16707 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16708 %{
16709   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16710   match(Set dst (MulVD src1 src2));
16711   ins_cost(INSN_COST);
16712   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16713   ins_encode %{
16714     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16715             as_FloatRegister($src1$$reg),
16716             as_FloatRegister($src2$$reg));
16717   %}
16718   ins_pipe(vmuldiv_fp128);
16719 %}
16720 
16721 // --------------------------------- MLA --------------------------------------
16722 
16723 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16724 %{
16725   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16726             n-&gt;as_Vector()-&gt;length() == 4);
16727   match(Set dst (AddVS dst (MulVS src1 src2)));
16728   ins_cost(INSN_COST);
16729   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16730   ins_encode %{
16731     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16732             as_FloatRegister($src1$$reg),
16733             as_FloatRegister($src2$$reg));
16734   %}
16735   ins_pipe(vmla64);
16736 %}
16737 
16738 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16739 %{
16740   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16741   match(Set dst (AddVS dst (MulVS src1 src2)));
16742   ins_cost(INSN_COST);
16743   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16744   ins_encode %{
16745     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16746             as_FloatRegister($src1$$reg),
16747             as_FloatRegister($src2$$reg));
16748   %}
16749   ins_pipe(vmla128);
16750 %}
16751 
16752 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16753 %{
16754   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16755   match(Set dst (AddVI dst (MulVI src1 src2)));
16756   ins_cost(INSN_COST);
16757   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16758   ins_encode %{
16759     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16760             as_FloatRegister($src1$$reg),
16761             as_FloatRegister($src2$$reg));
16762   %}
16763   ins_pipe(vmla64);
16764 %}
16765 
16766 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16767 %{
16768   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16769   match(Set dst (AddVI dst (MulVI src1 src2)));
16770   ins_cost(INSN_COST);
16771   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16772   ins_encode %{
16773     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16774             as_FloatRegister($src1$$reg),
16775             as_FloatRegister($src2$$reg));
16776   %}
16777   ins_pipe(vmla128);
16778 %}
16779 
16780 // dst + src1 * src2
16781 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16782   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16783   match(Set dst (FmaVF  dst (Binary src1 src2)));
16784   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16785   ins_cost(INSN_COST);
16786   ins_encode %{
16787     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16788             as_FloatRegister($src1$$reg),
16789             as_FloatRegister($src2$$reg));
16790   %}
16791   ins_pipe(vmuldiv_fp64);
16792 %}
16793 
16794 // dst + src1 * src2
16795 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16796   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16797   match(Set dst (FmaVF  dst (Binary src1 src2)));
16798   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16799   ins_cost(INSN_COST);
16800   ins_encode %{
16801     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16802             as_FloatRegister($src1$$reg),
16803             as_FloatRegister($src2$$reg));
16804   %}
16805   ins_pipe(vmuldiv_fp128);
16806 %}
16807 
16808 // dst + src1 * src2
16809 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16810   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16811   match(Set dst (FmaVD  dst (Binary src1 src2)));
16812   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16813   ins_cost(INSN_COST);
16814   ins_encode %{
16815     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16816             as_FloatRegister($src1$$reg),
16817             as_FloatRegister($src2$$reg));
16818   %}
16819   ins_pipe(vmuldiv_fp128);
16820 %}
16821 
16822 // --------------------------------- MLS --------------------------------------
16823 
16824 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16825 %{
16826   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16827             n-&gt;as_Vector()-&gt;length() == 4);
16828   match(Set dst (SubVS dst (MulVS src1 src2)));
16829   ins_cost(INSN_COST);
16830   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16831   ins_encode %{
16832     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16833             as_FloatRegister($src1$$reg),
16834             as_FloatRegister($src2$$reg));
16835   %}
16836   ins_pipe(vmla64);
16837 %}
16838 
16839 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16840 %{
16841   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16842   match(Set dst (SubVS dst (MulVS src1 src2)));
16843   ins_cost(INSN_COST);
16844   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16845   ins_encode %{
16846     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16847             as_FloatRegister($src1$$reg),
16848             as_FloatRegister($src2$$reg));
16849   %}
16850   ins_pipe(vmla128);
16851 %}
16852 
16853 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16854 %{
16855   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16856   match(Set dst (SubVI dst (MulVI src1 src2)));
16857   ins_cost(INSN_COST);
16858   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16859   ins_encode %{
16860     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16861             as_FloatRegister($src1$$reg),
16862             as_FloatRegister($src2$$reg));
16863   %}
16864   ins_pipe(vmla64);
16865 %}
16866 
16867 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16868 %{
16869   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16870   match(Set dst (SubVI dst (MulVI src1 src2)));
16871   ins_cost(INSN_COST);
16872   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16873   ins_encode %{
16874     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16875             as_FloatRegister($src1$$reg),
16876             as_FloatRegister($src2$$reg));
16877   %}
16878   ins_pipe(vmla128);
16879 %}
16880 
16881 // dst - src1 * src2
16882 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16883   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16884   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16885   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16886   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16887   ins_cost(INSN_COST);
16888   ins_encode %{
16889     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16890             as_FloatRegister($src1$$reg),
16891             as_FloatRegister($src2$$reg));
16892   %}
16893   ins_pipe(vmuldiv_fp64);
16894 %}
16895 
16896 // dst - src1 * src2
16897 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16898   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16899   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16900   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16901   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16902   ins_cost(INSN_COST);
16903   ins_encode %{
16904     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16905             as_FloatRegister($src1$$reg),
16906             as_FloatRegister($src2$$reg));
16907   %}
16908   ins_pipe(vmuldiv_fp128);
16909 %}
16910 
16911 // dst - src1 * src2
16912 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16913   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16914   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16915   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16916   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16917   ins_cost(INSN_COST);
16918   ins_encode %{
16919     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16920             as_FloatRegister($src1$$reg),
16921             as_FloatRegister($src2$$reg));
16922   %}
16923   ins_pipe(vmuldiv_fp128);
16924 %}
16925 
16926 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16927 
16928 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16929   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16930   match(Set dst (MulAddVS2VI src1 src2));
16931   ins_cost(INSN_COST);
16932   effect(TEMP_DEF dst, TEMP tmp);
16933   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16934             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16935             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16936   ins_encode %{
16937     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16938               as_FloatRegister($src1$$reg),
16939               as_FloatRegister($src2$$reg));
16940     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16941               as_FloatRegister($src1$$reg),
16942               as_FloatRegister($src2$$reg));
16943     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16944              as_FloatRegister($tmp$$reg),
16945              as_FloatRegister($dst$$reg));
16946   %}
16947   ins_pipe(vmuldiv_fp128);
16948 %}
16949 
16950 // --------------------------------- DIV --------------------------------------
16951 
16952 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16953 %{
16954   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16955   match(Set dst (DivVF src1 src2));
16956   ins_cost(INSN_COST);
16957   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16958   ins_encode %{
16959     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16960             as_FloatRegister($src1$$reg),
16961             as_FloatRegister($src2$$reg));
16962   %}
16963   ins_pipe(vmuldiv_fp64);
16964 %}
16965 
16966 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16967 %{
16968   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16969   match(Set dst (DivVF src1 src2));
16970   ins_cost(INSN_COST);
16971   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16972   ins_encode %{
16973     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16974             as_FloatRegister($src1$$reg),
16975             as_FloatRegister($src2$$reg));
16976   %}
16977   ins_pipe(vmuldiv_fp128);
16978 %}
16979 
16980 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16981 %{
16982   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16983   match(Set dst (DivVD src1 src2));
16984   ins_cost(INSN_COST);
16985   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16986   ins_encode %{
16987     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16988             as_FloatRegister($src1$$reg),
16989             as_FloatRegister($src2$$reg));
16990   %}
16991   ins_pipe(vmuldiv_fp128);
16992 %}
16993 
16994 // --------------------------------- SQRT -------------------------------------
16995 
16996 instruct vsqrt2D(vecX dst, vecX src)
16997 %{
16998   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16999   match(Set dst (SqrtVD src));
17000   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17001   ins_encode %{
17002     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17003              as_FloatRegister($src$$reg));
17004   %}
17005   ins_pipe(vsqrt_fp128);
17006 %}
17007 
17008 // --------------------------------- ABS --------------------------------------
17009 
17010 instruct vabs2F(vecD dst, vecD src)
17011 %{
17012   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17013   match(Set dst (AbsVF src));
17014   ins_cost(INSN_COST * 3);
17015   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17016   ins_encode %{
17017     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17018             as_FloatRegister($src$$reg));
17019   %}
17020   ins_pipe(vunop_fp64);
17021 %}
17022 
17023 instruct vabs4F(vecX dst, vecX src)
17024 %{
17025   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17026   match(Set dst (AbsVF src));
17027   ins_cost(INSN_COST * 3);
17028   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17029   ins_encode %{
17030     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17031             as_FloatRegister($src$$reg));
17032   %}
17033   ins_pipe(vunop_fp128);
17034 %}
17035 
17036 instruct vabs2D(vecX dst, vecX src)
17037 %{
17038   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17039   match(Set dst (AbsVD src));
17040   ins_cost(INSN_COST * 3);
17041   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17042   ins_encode %{
17043     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17044             as_FloatRegister($src$$reg));
17045   %}
17046   ins_pipe(vunop_fp128);
17047 %}
17048 
17049 // --------------------------------- NEG --------------------------------------
17050 
17051 instruct vneg2F(vecD dst, vecD src)
17052 %{
17053   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17054   match(Set dst (NegVF src));
17055   ins_cost(INSN_COST * 3);
17056   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17057   ins_encode %{
17058     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17059             as_FloatRegister($src$$reg));
17060   %}
17061   ins_pipe(vunop_fp64);
17062 %}
17063 
17064 instruct vneg4F(vecX dst, vecX src)
17065 %{
17066   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17067   match(Set dst (NegVF src));
17068   ins_cost(INSN_COST * 3);
17069   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17070   ins_encode %{
17071     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17072             as_FloatRegister($src$$reg));
17073   %}
17074   ins_pipe(vunop_fp128);
17075 %}
17076 
17077 instruct vneg2D(vecX dst, vecX src)
17078 %{
17079   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17080   match(Set dst (NegVD src));
17081   ins_cost(INSN_COST * 3);
17082   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17083   ins_encode %{
17084     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17085             as_FloatRegister($src$$reg));
17086   %}
17087   ins_pipe(vunop_fp128);
17088 %}
17089 
17090 // --------------------------------- AND --------------------------------------
17091 
17092 instruct vand8B(vecD dst, vecD src1, vecD src2)
17093 %{
17094   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17095             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17096   match(Set dst (AndV src1 src2));
17097   ins_cost(INSN_COST);
17098   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17099   ins_encode %{
17100     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17101             as_FloatRegister($src1$$reg),
17102             as_FloatRegister($src2$$reg));
17103   %}
17104   ins_pipe(vlogical64);
17105 %}
17106 
17107 instruct vand16B(vecX dst, vecX src1, vecX src2)
17108 %{
17109   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17110   match(Set dst (AndV src1 src2));
17111   ins_cost(INSN_COST);
17112   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17113   ins_encode %{
17114     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17115             as_FloatRegister($src1$$reg),
17116             as_FloatRegister($src2$$reg));
17117   %}
17118   ins_pipe(vlogical128);
17119 %}
17120 
17121 // --------------------------------- OR ---------------------------------------
17122 
17123 instruct vor8B(vecD dst, vecD src1, vecD src2)
17124 %{
17125   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17126             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17127   match(Set dst (OrV src1 src2));
17128   ins_cost(INSN_COST);
17129   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17130   ins_encode %{
17131     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17132             as_FloatRegister($src1$$reg),
17133             as_FloatRegister($src2$$reg));
17134   %}
17135   ins_pipe(vlogical64);
17136 %}
17137 
17138 instruct vor16B(vecX dst, vecX src1, vecX src2)
17139 %{
17140   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17141   match(Set dst (OrV src1 src2));
17142   ins_cost(INSN_COST);
17143   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17144   ins_encode %{
17145     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17146             as_FloatRegister($src1$$reg),
17147             as_FloatRegister($src2$$reg));
17148   %}
17149   ins_pipe(vlogical128);
17150 %}
17151 
17152 // --------------------------------- XOR --------------------------------------
17153 
17154 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17155 %{
17156   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17157             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17158   match(Set dst (XorV src1 src2));
17159   ins_cost(INSN_COST);
17160   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17161   ins_encode %{
17162     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17163             as_FloatRegister($src1$$reg),
17164             as_FloatRegister($src2$$reg));
17165   %}
17166   ins_pipe(vlogical64);
17167 %}
17168 
17169 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17170 %{
17171   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17172   match(Set dst (XorV src1 src2));
17173   ins_cost(INSN_COST);
17174   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17175   ins_encode %{
17176     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17177             as_FloatRegister($src1$$reg),
17178             as_FloatRegister($src2$$reg));
17179   %}
17180   ins_pipe(vlogical128);
17181 %}
17182 
17183 // ------------------------------ Shift ---------------------------------------
17184 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17185   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17186   match(Set dst (LShiftCntV cnt));
17187   match(Set dst (RShiftCntV cnt));
17188   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17189   ins_encode %{
17190     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17191   %}
17192   ins_pipe(vdup_reg_reg64);
17193 %}
17194 
17195 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17196   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17197   match(Set dst (LShiftCntV cnt));
17198   match(Set dst (RShiftCntV cnt));
17199   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17200   ins_encode %{
17201     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17202   %}
17203   ins_pipe(vdup_reg_reg128);
17204 %}
17205 
17206 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17207   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17208             n-&gt;as_Vector()-&gt;length() == 8);
17209   match(Set dst (LShiftVB src shift));
17210   ins_cost(INSN_COST);
17211   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17212   ins_encode %{
17213     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17214             as_FloatRegister($src$$reg),
17215             as_FloatRegister($shift$$reg));
17216   %}
17217   ins_pipe(vshift64);
17218 %}
17219 
17220 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17221   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17222   match(Set dst (LShiftVB src shift));
17223   ins_cost(INSN_COST);
17224   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17225   ins_encode %{
17226     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17227             as_FloatRegister($src$$reg),
17228             as_FloatRegister($shift$$reg));
17229   %}
17230   ins_pipe(vshift128);
17231 %}
17232 
17233 // Right shifts with vector shift count on aarch64 SIMD are implemented
17234 // as left shift by negative shift count.
17235 // There are two cases for vector shift count.
17236 //
17237 // Case 1: The vector shift count is from replication.
17238 //        |            |
17239 //    LoadVector  RShiftCntV
17240 //        |       /
17241 //     RShiftVI
17242 // Note: In inner loop, multiple neg instructions are used, which can be
17243 // moved to outer loop and merge into one neg instruction.
17244 //
17245 // Case 2: The vector shift count is from loading.
17246 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17247 // panama/vectorIntrinsics(JEP 338: Vector API).
17248 //        |            |
17249 //    LoadVector  LoadVector
17250 //        |       /
17251 //     RShiftVI
17252 //
17253 
17254 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17255   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17256             n-&gt;as_Vector()-&gt;length() == 8);
17257   match(Set dst (RShiftVB src shift));
17258   ins_cost(INSN_COST);
17259   effect(TEMP tmp);
17260   format %{ &quot;negr  $tmp,$shift\t&quot;
17261             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17262   ins_encode %{
17263     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17264             as_FloatRegister($shift$$reg));
17265     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17266             as_FloatRegister($src$$reg),
17267             as_FloatRegister($tmp$$reg));
17268   %}
17269   ins_pipe(vshift64);
17270 %}
17271 
17272 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17273   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17274   match(Set dst (RShiftVB src shift));
17275   ins_cost(INSN_COST);
17276   effect(TEMP tmp);
17277   format %{ &quot;negr  $tmp,$shift\t&quot;
17278             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17279   ins_encode %{
17280     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17281             as_FloatRegister($shift$$reg));
17282     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17283             as_FloatRegister($src$$reg),
17284             as_FloatRegister($tmp$$reg));
17285   %}
17286   ins_pipe(vshift128);
17287 %}
17288 
17289 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17290   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17291             n-&gt;as_Vector()-&gt;length() == 8);
17292   match(Set dst (URShiftVB src shift));
17293   ins_cost(INSN_COST);
17294   effect(TEMP tmp);
17295   format %{ &quot;negr  $tmp,$shift\t&quot;
17296             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17297   ins_encode %{
17298     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17299             as_FloatRegister($shift$$reg));
17300     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17301             as_FloatRegister($src$$reg),
17302             as_FloatRegister($tmp$$reg));
17303   %}
17304   ins_pipe(vshift64);
17305 %}
17306 
17307 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17308   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17309   match(Set dst (URShiftVB src shift));
17310   ins_cost(INSN_COST);
17311   effect(TEMP tmp);
17312   format %{ &quot;negr  $tmp,$shift\t&quot;
17313             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17314   ins_encode %{
17315     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17316             as_FloatRegister($shift$$reg));
17317     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17318             as_FloatRegister($src$$reg),
17319             as_FloatRegister($tmp$$reg));
17320   %}
17321   ins_pipe(vshift128);
17322 %}
17323 
17324 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17325   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17326             n-&gt;as_Vector()-&gt;length() == 8);
17327   match(Set dst (LShiftVB src (LShiftCntV shift)));
17328   ins_cost(INSN_COST);
17329   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17330   ins_encode %{
17331     int sh = (int)$shift$$constant;
17332     if (sh &gt;= 8) {
17333       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17334              as_FloatRegister($src$$reg),
17335              as_FloatRegister($src$$reg));
17336     } else {
17337       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17338              as_FloatRegister($src$$reg), sh);
17339     }
17340   %}
17341   ins_pipe(vshift64_imm);
17342 %}
17343 
17344 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17345   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17346   match(Set dst (LShiftVB src (LShiftCntV shift)));
17347   ins_cost(INSN_COST);
17348   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17349   ins_encode %{
17350     int sh = (int)$shift$$constant;
17351     if (sh &gt;= 8) {
17352       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17353              as_FloatRegister($src$$reg),
17354              as_FloatRegister($src$$reg));
17355     } else {
17356       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17357              as_FloatRegister($src$$reg), sh);
17358     }
17359   %}
17360   ins_pipe(vshift128_imm);
17361 %}
17362 
17363 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17364   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17365             n-&gt;as_Vector()-&gt;length() == 8);
17366   match(Set dst (RShiftVB src (RShiftCntV shift)));
17367   ins_cost(INSN_COST);
17368   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17369   ins_encode %{
17370     int sh = (int)$shift$$constant;
17371     if (sh &gt;= 8) sh = 7;
17372     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17373            as_FloatRegister($src$$reg), sh);
17374   %}
17375   ins_pipe(vshift64_imm);
17376 %}
17377 
17378 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17379   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17380   match(Set dst (RShiftVB src (RShiftCntV shift)));
17381   ins_cost(INSN_COST);
17382   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17383   ins_encode %{
17384     int sh = (int)$shift$$constant;
17385     if (sh &gt;= 8) sh = 7;
17386     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17387            as_FloatRegister($src$$reg), sh);
17388   %}
17389   ins_pipe(vshift128_imm);
17390 %}
17391 
17392 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17393   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17394             n-&gt;as_Vector()-&gt;length() == 8);
17395   match(Set dst (URShiftVB src (RShiftCntV shift)));
17396   ins_cost(INSN_COST);
17397   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17398   ins_encode %{
17399     int sh = (int)$shift$$constant;
17400     if (sh &gt;= 8) {
17401       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17402              as_FloatRegister($src$$reg),
17403              as_FloatRegister($src$$reg));
17404     } else {
17405       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17406              as_FloatRegister($src$$reg), sh);
17407     }
17408   %}
17409   ins_pipe(vshift64_imm);
17410 %}
17411 
17412 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17413   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17414   match(Set dst (URShiftVB src (RShiftCntV shift)));
17415   ins_cost(INSN_COST);
17416   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17417   ins_encode %{
17418     int sh = (int)$shift$$constant;
17419     if (sh &gt;= 8) {
17420       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17421              as_FloatRegister($src$$reg),
17422              as_FloatRegister($src$$reg));
17423     } else {
17424       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17425              as_FloatRegister($src$$reg), sh);
17426     }
17427   %}
17428   ins_pipe(vshift128_imm);
17429 %}
17430 
17431 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17432   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17433             n-&gt;as_Vector()-&gt;length() == 4);
17434   match(Set dst (LShiftVS src shift));
17435   ins_cost(INSN_COST);
17436   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17437   ins_encode %{
17438     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17439             as_FloatRegister($src$$reg),
17440             as_FloatRegister($shift$$reg));
17441   %}
17442   ins_pipe(vshift64);
17443 %}
17444 
17445 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17446   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17447   match(Set dst (LShiftVS src shift));
17448   ins_cost(INSN_COST);
17449   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17450   ins_encode %{
17451     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17452             as_FloatRegister($src$$reg),
17453             as_FloatRegister($shift$$reg));
17454   %}
17455   ins_pipe(vshift128);
17456 %}
17457 
17458 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17459   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17460             n-&gt;as_Vector()-&gt;length() == 4);
17461   match(Set dst (RShiftVS src shift));
17462   ins_cost(INSN_COST);
17463   effect(TEMP tmp);
17464   format %{ &quot;negr  $tmp,$shift\t&quot;
17465             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17466   ins_encode %{
17467     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17468             as_FloatRegister($shift$$reg));
17469     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17470             as_FloatRegister($src$$reg),
17471             as_FloatRegister($tmp$$reg));
17472   %}
17473   ins_pipe(vshift64);
17474 %}
17475 
17476 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17477   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17478   match(Set dst (RShiftVS src shift));
17479   ins_cost(INSN_COST);
17480   effect(TEMP tmp);
17481   format %{ &quot;negr  $tmp,$shift\t&quot;
17482             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17483   ins_encode %{
17484     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17485             as_FloatRegister($shift$$reg));
17486     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17487             as_FloatRegister($src$$reg),
17488             as_FloatRegister($tmp$$reg));
17489   %}
17490   ins_pipe(vshift128);
17491 %}
17492 
17493 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17494   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17495             n-&gt;as_Vector()-&gt;length() == 4);
17496   match(Set dst (URShiftVS src shift));
17497   ins_cost(INSN_COST);
17498   effect(TEMP tmp);
17499   format %{ &quot;negr  $tmp,$shift\t&quot;
17500             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17501   ins_encode %{
17502     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17503             as_FloatRegister($shift$$reg));
17504     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17505             as_FloatRegister($src$$reg),
17506             as_FloatRegister($tmp$$reg));
17507   %}
17508   ins_pipe(vshift64);
17509 %}
17510 
17511 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17512   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17513   match(Set dst (URShiftVS src shift));
17514   ins_cost(INSN_COST);
17515   effect(TEMP tmp);
17516   format %{ &quot;negr  $tmp,$shift\t&quot;
17517             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17518   ins_encode %{
17519     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17520             as_FloatRegister($shift$$reg));
17521     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17522             as_FloatRegister($src$$reg),
17523             as_FloatRegister($tmp$$reg));
17524   %}
17525   ins_pipe(vshift128);
17526 %}
17527 
17528 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17529   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17530             n-&gt;as_Vector()-&gt;length() == 4);
17531   match(Set dst (LShiftVS src (LShiftCntV shift)));
17532   ins_cost(INSN_COST);
17533   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17534   ins_encode %{
17535     int sh = (int)$shift$$constant;
17536     if (sh &gt;= 16) {
17537       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17538              as_FloatRegister($src$$reg),
17539              as_FloatRegister($src$$reg));
17540     } else {
17541       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17542              as_FloatRegister($src$$reg), sh);
17543     }
17544   %}
17545   ins_pipe(vshift64_imm);
17546 %}
17547 
17548 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17549   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17550   match(Set dst (LShiftVS src (LShiftCntV shift)));
17551   ins_cost(INSN_COST);
17552   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17553   ins_encode %{
17554     int sh = (int)$shift$$constant;
17555     if (sh &gt;= 16) {
17556       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17557              as_FloatRegister($src$$reg),
17558              as_FloatRegister($src$$reg));
17559     } else {
17560       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17561              as_FloatRegister($src$$reg), sh);
17562     }
17563   %}
17564   ins_pipe(vshift128_imm);
17565 %}
17566 
17567 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17568   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17569             n-&gt;as_Vector()-&gt;length() == 4);
17570   match(Set dst (RShiftVS src (RShiftCntV shift)));
17571   ins_cost(INSN_COST);
17572   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17573   ins_encode %{
17574     int sh = (int)$shift$$constant;
17575     if (sh &gt;= 16) sh = 15;
17576     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17577            as_FloatRegister($src$$reg), sh);
17578   %}
17579   ins_pipe(vshift64_imm);
17580 %}
17581 
17582 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17583   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17584   match(Set dst (RShiftVS src (RShiftCntV shift)));
17585   ins_cost(INSN_COST);
17586   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17587   ins_encode %{
17588     int sh = (int)$shift$$constant;
17589     if (sh &gt;= 16) sh = 15;
17590     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17591            as_FloatRegister($src$$reg), sh);
17592   %}
17593   ins_pipe(vshift128_imm);
17594 %}
17595 
17596 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17597   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17598             n-&gt;as_Vector()-&gt;length() == 4);
17599   match(Set dst (URShiftVS src (RShiftCntV shift)));
17600   ins_cost(INSN_COST);
17601   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17602   ins_encode %{
17603     int sh = (int)$shift$$constant;
17604     if (sh &gt;= 16) {
17605       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17606              as_FloatRegister($src$$reg),
17607              as_FloatRegister($src$$reg));
17608     } else {
17609       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17610              as_FloatRegister($src$$reg), sh);
17611     }
17612   %}
17613   ins_pipe(vshift64_imm);
17614 %}
17615 
17616 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17617   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17618   match(Set dst (URShiftVS src (RShiftCntV shift)));
17619   ins_cost(INSN_COST);
17620   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17621   ins_encode %{
17622     int sh = (int)$shift$$constant;
17623     if (sh &gt;= 16) {
17624       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17625              as_FloatRegister($src$$reg),
17626              as_FloatRegister($src$$reg));
17627     } else {
17628       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17629              as_FloatRegister($src$$reg), sh);
17630     }
17631   %}
17632   ins_pipe(vshift128_imm);
17633 %}
17634 
17635 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17636   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17637   match(Set dst (LShiftVI src shift));
17638   ins_cost(INSN_COST);
17639   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17640   ins_encode %{
17641     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17642             as_FloatRegister($src$$reg),
17643             as_FloatRegister($shift$$reg));
17644   %}
17645   ins_pipe(vshift64);
17646 %}
17647 
17648 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17649   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17650   match(Set dst (LShiftVI src shift));
17651   ins_cost(INSN_COST);
17652   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17653   ins_encode %{
17654     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17655             as_FloatRegister($src$$reg),
17656             as_FloatRegister($shift$$reg));
17657   %}
17658   ins_pipe(vshift128);
17659 %}
17660 
17661 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17662   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17663   match(Set dst (RShiftVI src shift));
17664   ins_cost(INSN_COST);
17665   effect(TEMP tmp);
17666   format %{ &quot;negr  $tmp,$shift\t&quot;
17667             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17668   ins_encode %{
17669     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17670             as_FloatRegister($shift$$reg));
17671     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17672             as_FloatRegister($src$$reg),
17673             as_FloatRegister($tmp$$reg));
17674   %}
17675   ins_pipe(vshift64);
17676 %}
17677 
17678 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17679   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17680   match(Set dst (RShiftVI src shift));
17681   ins_cost(INSN_COST);
17682   effect(TEMP tmp);
17683   format %{ &quot;negr  $tmp,$shift\t&quot;
17684             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17685   ins_encode %{
17686     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17687             as_FloatRegister($shift$$reg));
17688     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17689             as_FloatRegister($src$$reg),
17690             as_FloatRegister($tmp$$reg));
17691   %}
17692   ins_pipe(vshift128);
17693 %}
17694 
17695 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17696   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17697   match(Set dst (URShiftVI src shift));
17698   ins_cost(INSN_COST);
17699   effect(TEMP tmp);
17700   format %{ &quot;negr  $tmp,$shift\t&quot;
17701             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17702   ins_encode %{
17703     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17704             as_FloatRegister($shift$$reg));
17705     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17706             as_FloatRegister($src$$reg),
17707             as_FloatRegister($tmp$$reg));
17708   %}
17709   ins_pipe(vshift64);
17710 %}
17711 
17712 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17713   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17714   match(Set dst (URShiftVI src shift));
17715   ins_cost(INSN_COST);
17716   effect(TEMP tmp);
17717   format %{ &quot;negr  $tmp,$shift\t&quot;
17718             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17719   ins_encode %{
17720     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17721             as_FloatRegister($shift$$reg));
17722     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17723             as_FloatRegister($src$$reg),
17724             as_FloatRegister($tmp$$reg));
17725   %}
17726   ins_pipe(vshift128);
17727 %}
17728 
17729 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17730   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17731   match(Set dst (LShiftVI src (LShiftCntV shift)));
17732   ins_cost(INSN_COST);
17733   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17734   ins_encode %{
17735     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17736            as_FloatRegister($src$$reg),
17737            (int)$shift$$constant);
17738   %}
17739   ins_pipe(vshift64_imm);
17740 %}
17741 
17742 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17743   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17744   match(Set dst (LShiftVI src (LShiftCntV shift)));
17745   ins_cost(INSN_COST);
17746   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17747   ins_encode %{
17748     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17749            as_FloatRegister($src$$reg),
17750            (int)$shift$$constant);
17751   %}
17752   ins_pipe(vshift128_imm);
17753 %}
17754 
17755 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17756   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17757   match(Set dst (RShiftVI src (RShiftCntV shift)));
17758   ins_cost(INSN_COST);
17759   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17760   ins_encode %{
17761     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17762             as_FloatRegister($src$$reg),
17763             (int)$shift$$constant);
17764   %}
17765   ins_pipe(vshift64_imm);
17766 %}
17767 
17768 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17769   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17770   match(Set dst (RShiftVI src (RShiftCntV shift)));
17771   ins_cost(INSN_COST);
17772   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17773   ins_encode %{
17774     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17775             as_FloatRegister($src$$reg),
17776             (int)$shift$$constant);
17777   %}
17778   ins_pipe(vshift128_imm);
17779 %}
17780 
17781 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17782   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17783   match(Set dst (URShiftVI src (RShiftCntV shift)));
17784   ins_cost(INSN_COST);
17785   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17786   ins_encode %{
17787     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17788             as_FloatRegister($src$$reg),
17789             (int)$shift$$constant);
17790   %}
17791   ins_pipe(vshift64_imm);
17792 %}
17793 
17794 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17795   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17796   match(Set dst (URShiftVI src (RShiftCntV shift)));
17797   ins_cost(INSN_COST);
17798   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17799   ins_encode %{
17800     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17801             as_FloatRegister($src$$reg),
17802             (int)$shift$$constant);
17803   %}
17804   ins_pipe(vshift128_imm);
17805 %}
17806 
17807 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17808   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17809   match(Set dst (LShiftVL src shift));
17810   ins_cost(INSN_COST);
17811   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17812   ins_encode %{
17813     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17814             as_FloatRegister($src$$reg),
17815             as_FloatRegister($shift$$reg));
17816   %}
17817   ins_pipe(vshift128);
17818 %}
17819 
17820 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17821   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17822   match(Set dst (RShiftVL src shift));
17823   ins_cost(INSN_COST);
17824   effect(TEMP tmp);
17825   format %{ &quot;negr  $tmp,$shift\t&quot;
17826             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17827   ins_encode %{
17828     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17829             as_FloatRegister($shift$$reg));
17830     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17831             as_FloatRegister($src$$reg),
17832             as_FloatRegister($tmp$$reg));
17833   %}
17834   ins_pipe(vshift128);
17835 %}
17836 
17837 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17838   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17839   match(Set dst (URShiftVL src shift));
17840   ins_cost(INSN_COST);
17841   effect(TEMP tmp);
17842   format %{ &quot;negr  $tmp,$shift\t&quot;
17843             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17844   ins_encode %{
17845     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17846             as_FloatRegister($shift$$reg));
17847     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17848             as_FloatRegister($src$$reg),
17849             as_FloatRegister($tmp$$reg));
17850   %}
17851   ins_pipe(vshift128);
17852 %}
17853 
17854 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17855   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17856   match(Set dst (LShiftVL src (LShiftCntV shift)));
17857   ins_cost(INSN_COST);
17858   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17859   ins_encode %{
17860     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17861            as_FloatRegister($src$$reg),
17862            (int)$shift$$constant);
17863   %}
17864   ins_pipe(vshift128_imm);
17865 %}
17866 
17867 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17868   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17869   match(Set dst (RShiftVL src (RShiftCntV shift)));
17870   ins_cost(INSN_COST);
17871   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17872   ins_encode %{
17873     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17874             as_FloatRegister($src$$reg),
17875             (int)$shift$$constant);
17876   %}
17877   ins_pipe(vshift128_imm);
17878 %}
17879 
17880 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17881   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17882   match(Set dst (URShiftVL src (RShiftCntV shift)));
17883   ins_cost(INSN_COST);
17884   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17885   ins_encode %{
17886     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17887             as_FloatRegister($src$$reg),
17888             (int)$shift$$constant);
17889   %}
17890   ins_pipe(vshift128_imm);
17891 %}
17892 
17893 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17894 %{
17895   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17896   match(Set dst (MaxV src1 src2));
17897   ins_cost(INSN_COST);
17898   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17899   ins_encode %{
17900     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17901             as_FloatRegister($src1$$reg),
17902             as_FloatRegister($src2$$reg));
17903   %}
17904   ins_pipe(vdop_fp64);
17905 %}
17906 
17907 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17908 %{
17909   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17910   match(Set dst (MaxV src1 src2));
17911   ins_cost(INSN_COST);
17912   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17913   ins_encode %{
17914     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17915             as_FloatRegister($src1$$reg),
17916             as_FloatRegister($src2$$reg));
17917   %}
17918   ins_pipe(vdop_fp128);
17919 %}
17920 
17921 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17922 %{
17923   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17924   match(Set dst (MaxV src1 src2));
17925   ins_cost(INSN_COST);
17926   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17927   ins_encode %{
17928     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17929             as_FloatRegister($src1$$reg),
17930             as_FloatRegister($src2$$reg));
17931   %}
17932   ins_pipe(vdop_fp128);
17933 %}
17934 
17935 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17936 %{
17937   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17938   match(Set dst (MinV src1 src2));
17939   ins_cost(INSN_COST);
17940   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17941   ins_encode %{
17942     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17943             as_FloatRegister($src1$$reg),
17944             as_FloatRegister($src2$$reg));
17945   %}
17946   ins_pipe(vdop_fp64);
17947 %}
17948 
17949 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17950 %{
17951   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17952   match(Set dst (MinV src1 src2));
17953   ins_cost(INSN_COST);
17954   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17955   ins_encode %{
17956     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17957             as_FloatRegister($src1$$reg),
17958             as_FloatRegister($src2$$reg));
17959   %}
17960   ins_pipe(vdop_fp128);
17961 %}
17962 
17963 instruct vmin2D(vecX dst, vecX src1, vecX src2)
17964 %{
17965   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17966   match(Set dst (MinV src1 src2));
17967   ins_cost(INSN_COST);
17968   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
17969   ins_encode %{
17970     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
17971             as_FloatRegister($src1$$reg),
17972             as_FloatRegister($src2$$reg));
17973   %}
17974   ins_pipe(vdop_fp128);
17975 %}
17976 
17977 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
17978   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17979   match(Set dst (RoundDoubleModeV src rmode));
17980   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
17981   ins_encode %{
17982     switch ($rmode$$constant) {
17983       case RoundDoubleModeNode::rmode_rint:
17984         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
17985                   as_FloatRegister($src$$reg));
17986         break;
17987       case RoundDoubleModeNode::rmode_floor:
17988         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
17989                   as_FloatRegister($src$$reg));
17990         break;
17991       case RoundDoubleModeNode::rmode_ceil:
17992         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
17993                   as_FloatRegister($src$$reg));
17994         break;
17995     }
17996   %}
17997   ins_pipe(vdop_fp128);
17998 %}
17999 
18000 instruct vpopcount4I(vecX dst, vecX src) %{
18001   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18002   match(Set dst (PopCountVI src));
18003   format %{
18004     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18005     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18006     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18007   %}
18008   ins_encode %{
18009      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18010             as_FloatRegister($src$$reg));
18011      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18012                as_FloatRegister($dst$$reg));
18013      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18014                as_FloatRegister($dst$$reg));
18015   %}
18016   ins_pipe(pipe_class_default);
18017 %}
18018 
18019 instruct vpopcount2I(vecD dst, vecD src) %{
18020   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18021   match(Set dst (PopCountVI src));
18022   format %{
18023     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18024     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18025     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18026   %}
18027   ins_encode %{
18028      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18029             as_FloatRegister($src$$reg));
18030      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18031                as_FloatRegister($dst$$reg));
18032      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18033                as_FloatRegister($dst$$reg));
18034   %}
18035   ins_pipe(pipe_class_default);
18036 %}
18037 
18038 //----------PEEPHOLE RULES-----------------------------------------------------
18039 // These must follow all instruction definitions as they use the names
18040 // defined in the instructions definitions.
18041 //
18042 // peepmatch ( root_instr_name [preceding_instruction]* );
18043 //
18044 // peepconstraint %{
18045 // (instruction_number.operand_name relational_op instruction_number.operand_name
18046 //  [, ...] );
18047 // // instruction numbers are zero-based using left to right order in peepmatch
18048 //
18049 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18050 // // provide an instruction_number.operand_name for each operand that appears
18051 // // in the replacement instruction&#39;s match rule
18052 //
18053 // ---------VM FLAGS---------------------------------------------------------
18054 //
18055 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18056 //
18057 // Each peephole rule is given an identifying number starting with zero and
18058 // increasing by one in the order seen by the parser.  An individual peephole
18059 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18060 // on the command-line.
18061 //
18062 // ---------CURRENT LIMITATIONS----------------------------------------------
18063 //
18064 // Only match adjacent instructions in same basic block
18065 // Only equality constraints
18066 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18067 // Only one replacement instruction
18068 //
18069 // ---------EXAMPLE----------------------------------------------------------
18070 //
18071 // // pertinent parts of existing instructions in architecture description
18072 // instruct movI(iRegINoSp dst, iRegI src)
18073 // %{
18074 //   match(Set dst (CopyI src));
18075 // %}
18076 //
18077 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18078 // %{
18079 //   match(Set dst (AddI dst src));
18080 //   effect(KILL cr);
18081 // %}
18082 //
18083 // // Change (inc mov) to lea
18084 // peephole %{
18085 //   // increment preceeded by register-register move
18086 //   peepmatch ( incI_iReg movI );
18087 //   // require that the destination register of the increment
18088 //   // match the destination register of the move
18089 //   peepconstraint ( 0.dst == 1.dst );
18090 //   // construct a replacement instruction that sets
18091 //   // the destination to ( move&#39;s source register + one )
18092 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18093 // %}
18094 //
18095 
18096 // Implementation no longer uses movX instructions since
18097 // machine-independent system no longer uses CopyX nodes.
18098 //
18099 // peephole
18100 // %{
18101 //   peepmatch (incI_iReg movI);
18102 //   peepconstraint (0.dst == 1.dst);
18103 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18104 // %}
18105 
18106 // peephole
18107 // %{
18108 //   peepmatch (decI_iReg movI);
18109 //   peepconstraint (0.dst == 1.dst);
18110 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18111 // %}
18112 
18113 // peephole
18114 // %{
18115 //   peepmatch (addI_iReg_imm movI);
18116 //   peepconstraint (0.dst == 1.dst);
18117 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18118 // %}
18119 
18120 // peephole
18121 // %{
18122 //   peepmatch (incL_iReg movL);
18123 //   peepconstraint (0.dst == 1.dst);
18124 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18125 // %}
18126 
18127 // peephole
18128 // %{
18129 //   peepmatch (decL_iReg movL);
18130 //   peepconstraint (0.dst == 1.dst);
18131 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18132 // %}
18133 
18134 // peephole
18135 // %{
18136 //   peepmatch (addL_iReg_imm movL);
18137 //   peepconstraint (0.dst == 1.dst);
18138 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18139 // %}
18140 
18141 // peephole
18142 // %{
18143 //   peepmatch (addP_iReg_imm movP);
18144 //   peepconstraint (0.dst == 1.dst);
18145 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18146 // %}
18147 
18148 // // Change load of spilled value to only a spill
18149 // instruct storeI(memory mem, iRegI src)
18150 // %{
18151 //   match(Set mem (StoreI mem src));
18152 // %}
18153 //
18154 // instruct loadI(iRegINoSp dst, memory mem)
18155 // %{
18156 //   match(Set dst (LoadI mem));
18157 // %}
18158 //
18159 
18160 //----------SMARTSPILL RULES---------------------------------------------------
18161 // These must follow all instruction definitions as they use the names
18162 // defined in the instructions definitions.
18163 
18164 // Local Variables:
18165 // mode: c++
18166 // End:
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>