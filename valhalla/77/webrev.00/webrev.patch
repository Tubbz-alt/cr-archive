diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -1505,18 +1505,18 @@
   ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));
   andr(temp_reg, temp_reg, JVM_ACC_VALUE);
   cbnz(temp_reg, is_value);
 }
 
-void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label& is_flattenable) {
+void MacroAssembler::test_field_is_inline(Register flags, Register temp_reg, Label& is_inline) {
   (void) temp_reg; // keep signature uniform with x86
-  tbnz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, is_flattenable);
+  tbnz(flags, ConstantPoolCacheEntry::is_inline_field_shift, is_inline);
 }
 
-void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label& not_flattenable) {
+void MacroAssembler::test_field_is_not_inline(Register flags, Register temp_reg, Label& not_inline) {
   (void) temp_reg; // keep signature uniform with x86
-  tbz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, not_flattenable);
+  tbz(flags, ConstantPoolCacheEntry::is_inline_field_shift, not_inline);
 }
 
 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label& is_flattened) {
   (void) temp_reg; // keep signature uniform with x86
   tbnz(flags, ConstantPoolCacheEntry::is_flattened_field_shift, is_flattened);
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
@@ -613,12 +613,12 @@
   static bool needs_explicit_null_check(intptr_t offset);
   static bool uses_implicit_null_check(void* address);
 
   void test_klass_is_value(Register klass, Register temp_reg, Label& is_value);
 
-  void test_field_is_flattenable(Register flags, Register temp_reg, Label& is_flattenable);
-  void test_field_is_not_flattenable(Register flags, Register temp_reg, Label& notFlattenable);
+  void test_field_is_inline(Register flags, Register temp_reg, Label& is_inline);
+  void test_field_is_not_inline(Register flags, Register temp_reg, Label& not_inline);
   void test_field_is_flattened(Register flags, Register temp_reg, Label& is_flattened);
 
   // Check klass/oops is flat value type array (oop->_klass->_layout_helper & vt_bit)
   void test_flattened_array_oop(Register klass, Register temp_reg, Label& is_flattened_array);
   void test_null_free_array_oop(Register oop, Register temp_reg, Label& is_null_free_array);
diff a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
@@ -2665,55 +2665,55 @@
     __ b(Done);
   } else { // Valhalla
 
     if (is_static) {
       __ load_heap_oop(r0, field);
-      Label isFlattenable, isUninitialized;
+      Label is_inline, isUninitialized;
       // Issue below if the static field has not been initialized yet
-      __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);
-        // Not flattenable case
+      __ test_field_is_inline(raw_flags, r8 /*temp*/, is_inline);
+        // Not inline case
         __ push(atos);
         __ b(Done);
-      // Flattenable case, must not return null even if uninitialized
-      __ bind(isFlattenable);
+      // Inline case, must not return null even if uninitialized
+      __ bind(is_inline);
         __ cbz(r0, isUninitialized);
           __ push(atos);
           __ b(Done);
         __ bind(isUninitialized);
           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_value_field), obj, raw_flags);
           __ verify_oop(r0);
           __ push(atos);
           __ b(Done);
     } else {
-      Label isFlattened, isInitialized, isFlattenable, rewriteFlattenable;
-        __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);
-        // Non-flattenable field case, also covers the object case
+      Label isFlattened, isInitialized, is_inline, rewrite_inline;
+        __ test_field_is_inline(raw_flags, r8 /*temp*/, is_inline);
+        // Non-inline field case
         __ load_heap_oop(r0, field);
         __ push(atos);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
         }
         __ b(Done);
-      __ bind(isFlattenable);
+      __ bind(is_inline);
         __ test_field_is_flattened(raw_flags, r8 /* temp */, isFlattened);
-         // Non-flattened field case
+         // Non-inline field case
           __ load_heap_oop(r0, field);
           __ cbnz(r0, isInitialized);
             __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
             __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), obj, raw_flags);
           __ bind(isInitialized);
           __ verify_oop(r0);
           __ push(atos);
-          __ b(rewriteFlattenable);
+          __ b(rewrite_inline);
         __ bind(isFlattened);
           __ ldr(r10, Address(cache, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
           call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10);
           __ verify_oop(r0);
           __ push(atos);
-      __ bind(rewriteFlattenable);
+      __ bind(rewrite_inline);
       if (rc == may_rewrite) {
          patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);
       }
       __ b(Done);
     }
@@ -2965,41 +2965,41 @@
       __ b(Done);
      } else { // Valhalla
 
       __ pop(atos);
       if (is_static) {
-        Label notFlattenable;
-         __ test_field_is_not_flattenable(flags2, r8 /* temp */, notFlattenable);
+        Label not_inline;
+         __ test_field_is_not_inline(flags2, r8 /* temp */, not_inline);
          __ null_check(r0);
-         __ bind(notFlattenable);
+         __ bind(not_inline);
          do_oop_store(_masm, field, r0, IN_HEAP);
          __ b(Done);
       } else {
-        Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;
-        __ test_field_is_flattenable(flags2, r8 /*temp*/, isFlattenable);
-        // Not flattenable case, covers not flattenable values and objects
+        Label is_inline, isFlattened, rewrite_not_inline, rewrite_inline;
+        __ test_field_is_inline(flags2, r8 /*temp*/, is_inline);
+        // Not inline case
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, r0, IN_HEAP);
-        __ bind(rewriteNotFlattenable);
+        __ bind(rewrite_not_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);
         }
         __ b(Done);
-        // Implementation of the flattenable semantic
-        __ bind(isFlattenable);
+        // Implementation of the inline semantic
+        __ bind(is_inline);
         __ null_check(r0);
         __ test_field_is_flattened(flags2, r8 /*temp*/, isFlattened);
-        // Not flattened case
+        // Not inline case
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, r0, IN_HEAP);
-        __ b(rewriteFlattenable);
+        __ b(rewrite_inline);
         __ bind(isFlattened);
         pop_and_check_object(obj);
         call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_flattened_value), r0, off, obj);
-        __ bind(rewriteFlattenable);
+        __ bind(rewrite_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_qputfield, bc, r19, true, byte_no);
         }
         __ b(Done);
       }
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -2635,24 +2635,24 @@
   movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));
   testl(temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());
   jcc(Assembler::notZero, is_empty_value);
 }
 
-void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label& is_flattenable) {
+void MacroAssembler::test_field_is_inline(Register flags, Register temp_reg, Label& is_inline) {
   movl(temp_reg, flags);
-  shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);
+  shrl(temp_reg, ConstantPoolCacheEntry::is_inline_field_shift);
   andl(temp_reg, 0x1);
   testl(temp_reg, temp_reg);
-  jcc(Assembler::notZero, is_flattenable);
+  jcc(Assembler::notZero, is_inline);
 }
 
-void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label& notFlattenable) {
+void MacroAssembler::test_field_is_not_inline(Register flags, Register temp_reg, Label& not_inline) {
   movl(temp_reg, flags);
-  shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);
+  shrl(temp_reg, ConstantPoolCacheEntry::is_inline_field_shift);
   andl(temp_reg, 0x1);
   testl(temp_reg, temp_reg);
-  jcc(Assembler::zero, notFlattenable);
+  jcc(Assembler::zero, not_inline);
 }
 
 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label& is_flattened) {
   movl(temp_reg, flags);
   shrl(temp_reg, ConstantPoolCacheEntry::is_flattened_field_shift);
diff a/src/hotspot/cpu/x86/macroAssembler_x86.hpp b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
@@ -109,12 +109,12 @@
   void get_default_value_oop(Register value_klass, Register temp_reg, Register obj);
   // The empty value oop, for the given ValueKlass ("empty" as in no instance fields)
   // get_default_value_oop with extra assertion for empty value klass
   void get_empty_value_oop(Register value_klass, Register temp_reg, Register obj);
 
-  void test_field_is_flattenable(Register flags, Register temp_reg, Label& is_flattenable);
-  void test_field_is_not_flattenable(Register flags, Register temp_reg, Label& notFlattenable);
+  void test_field_is_inline(Register flags, Register temp_reg, Label& is_inline);
+  void test_field_is_not_inline(Register flags, Register temp_reg, Label& not_inline);
   void test_field_is_flattened(Register flags, Register temp_reg, Label& is_flattened);
 
   // Check oops array storage properties, i.e. flattened and/or null-free
   void test_flattened_array_oop(Register oop, Register temp_reg, Label&is_flattened_array);
   void test_non_flattened_array_oop(Register oop, Register temp_reg, Label&is_non_flattened_array);
diff a/src/hotspot/cpu/x86/templateTable_x86.cpp b/src/hotspot/cpu/x86/templateTable_x86.cpp
--- a/src/hotspot/cpu/x86/templateTable_x86.cpp
+++ b/src/hotspot/cpu/x86/templateTable_x86.cpp
@@ -3066,18 +3066,18 @@
     }
     __ jmp(Done);
   } else {
     if (is_static) {
       __ load_heap_oop(rax, field);
-      Label isFlattenable, uninitialized;
+      Label is_inline, uninitialized;
       // Issue below if the static field has not been initialized yet
-      __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Not flattenable case
+      __ test_field_is_inline(flags2, rscratch1, is_inline);
+        // Not inline case
         __ push(atos);
         __ jmp(Done);
-      // Flattenable case, must not return null even if uninitialized
-      __ bind(isFlattenable);
+      // inline case, must not return null even if uninitialized
+      __ bind(is_inline);
         __ testptr(rax, rax);
         __ jcc(Assembler::zero, uninitialized);
           __ push(atos);
           __ jmp(Done);
         __ bind(uninitialized);
@@ -3097,21 +3097,21 @@
 #endif // _LP64
           __ verify_oop(rax);
           __ push(atos);
           __ jmp(Done);
     } else {
-      Label isFlattened, nonnull, isFlattenable, rewriteFlattenable;
-      __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Non-flattenable field case, also covers the object case
+      Label isFlattened, nonnull, is_inline, rewrite_inline;
+      __ test_field_is_inline(flags2, rscratch1, is_inline);
+        // Non-inline field case, also covers the object case
         pop_and_check_object(obj);
         __ load_heap_oop(rax, field);
         __ push(atos);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_agetfield, bc, rbx);
         }
         __ jmp(Done);
-      __ bind(isFlattenable);
+      __ bind(is_inline);
         __ test_field_is_flattened(flags2, rscratch1, isFlattened);
           // Non-flattened field case
           __ movptr(rax, rcx);  // small dance required to preserve the klass_holder somewhere
           pop_and_check_object(obj);
           __ push(rax);
@@ -3123,18 +3123,18 @@
             __ get_value_field_klass(rcx, flags2, rbx);
             __ get_default_value_oop(rbx, rcx, rax);
           __ bind(nonnull);
           __ verify_oop(rax);
           __ push(atos);
-          __ jmp(rewriteFlattenable);
+          __ jmp(rewrite_inline);
         __ bind(isFlattened);
           __ andl(flags2, ConstantPoolCacheEntry::field_index_mask);
           pop_and_check_object(rax);
           __ read_flattened_field(rcx, flags2, rbx, rax);
           __ verify_oop(rax);
           __ push(atos);
-      __ bind(rewriteFlattenable);
+      __ bind(rewrite_inline);
       if (rc == may_rewrite) {
         patch_bytecode(Bytecodes::_fast_qgetfield, bc, rbx);
       }
       __ jmp(Done);
     }
@@ -3445,45 +3445,45 @@
       }
       __ jmp(Done);
     } else {
       __ pop(atos);
       if (is_static) {
-        Label notFlattenable, notBuffered;
-        __ test_field_is_not_flattenable(flags2, rscratch1, notFlattenable);
+        Label is_inline;
+        __ test_field_is_not_inline(flags2, rscratch1, is_inline);
         __ null_check(rax);
-        __ bind(notFlattenable);
+        __ bind(is_inline);
         do_oop_store(_masm, field, rax);
         __ jmp(Done);
       } else {
-        Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;
-        __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Not flattenable case, covers not flattenable values and objects
+        Label is_inline, isFlattened, rewrite_not_inline, rewrite_inline;
+        __ test_field_is_inline(flags2, rscratch1, is_inline);
+        // Not inline case
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, rax);
-        __ bind(rewriteNotFlattenable);
+        __ bind(rewrite_not_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_aputfield, bc, rbx, true, byte_no);
         }
         __ jmp(Done);
-        // Implementation of the flattenable semantic
-        __ bind(isFlattenable);
+        // Implementation of the inline semantic
+        __ bind(is_inline);
         __ null_check(rax);
         __ test_field_is_flattened(flags2, rscratch1, isFlattened);
         // Not flattened case
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, rax);
-        __ jmp(rewriteFlattenable);
+        __ jmp(rewrite_inline);
         __ bind(isFlattened);
         pop_and_check_object(obj);
         assert_different_registers(rax, rdx, obj, off);
         __ load_klass(rdx, rax, rscratch1);
         __ data_for_oop(rax, rax, rdx);
         __ addptr(obj, off);
         __ access_value_copy(IN_HEAP, rax, obj, rdx);
-        __ bind(rewriteFlattenable);
+        __ bind(rewrite_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_qputfield, bc, rbx, true, byte_no);
         }
         __ jmp(Done);
       }
diff a/src/hotspot/share/ci/ciField.cpp b/src/hotspot/share/ci/ciField.cpp
--- a/src/hotspot/share/ci/ciField.cpp
+++ b/src/hotspot/share/ci/ciField.cpp
@@ -281,11 +281,11 @@
   _offset = fd->offset();
   Klass* field_holder = fd->field_holder();
   assert(field_holder != NULL, "null field_holder");
   _holder = CURRENT_ENV->get_instance_klass(field_holder);
   _is_flattened = fd->is_flattened();
-  _is_flattenable = fd->is_flattenable();
+  _is_flattenable = fd->is_inline();
 
   // Check to see if the field is constant.
   Klass* k = _holder->get_Klass();
   bool is_stable_field = FoldStableValues && is_stable();
   if ((is_final() && !has_initialized_final_update()) || is_stable_field) {
diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -1516,17 +1516,17 @@
   STATIC_OOP,           // Oops
   STATIC_BYTE,          // Boolean, Byte, char
   STATIC_SHORT,         // shorts
   STATIC_WORD,          // ints
   STATIC_DOUBLE,        // aligned long or double
-  STATIC_FLATTENABLE,   // flattenable field
+  STATIC_INLINE,        // inline field
   NONSTATIC_OOP,
   NONSTATIC_BYTE,
   NONSTATIC_SHORT,
   NONSTATIC_WORD,
   NONSTATIC_DOUBLE,
-  NONSTATIC_FLATTENABLE,
+  NONSTATIC_INLINE,
   MAX_FIELD_ALLOCATION_TYPE,
   BAD_ALLOCATION_TYPE = -1
 };
 
 static FieldAllocationType _basic_type_to_atype[2 * (T_CONFLICT + 1)] = {
@@ -1572,16 +1572,16 @@
   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
   BAD_ALLOCATION_TYPE, // T_CONFLICT    = 20
 };
 
-static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_flattenable) {
+static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline) {
   assert(type >= T_BOOLEAN && type < T_VOID, "only allowable values");
   FieldAllocationType result = _basic_type_to_atype[type + (is_static ? (T_CONFLICT + 1) : 0)];
   assert(result != BAD_ALLOCATION_TYPE, "bad type");
-  if (is_flattenable) {
-    result = is_static ? STATIC_FLATTENABLE : NONSTATIC_FLATTENABLE;
+  if (is_inline) {
+    result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;
   }
   return result;
 }
 
 class ClassFileParser::FieldAllocationCount : public ResourceObj {
@@ -1592,12 +1592,12 @@
     for (int i = 0; i < MAX_FIELD_ALLOCATION_TYPE; i++) {
       count[i] = 0;
     }
   }
 
-  FieldAllocationType update(bool is_static, BasicType type, bool is_flattenable) {
-    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_flattenable);
+  FieldAllocationType update(bool is_static, BasicType type, bool is_inline) {
+    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline);
     if (atype != BAD_ALLOCATION_TYPE) {
       // Make sure there is no overflow with injected fields.
       assert(count[atype] < 0xFFFF, "More than 65535 fields");
       count[atype]++;
     }
@@ -1689,26 +1689,10 @@
     check_property(valid_symbol_at(signature_index),
       "Invalid constant pool index %u for field signature in class file %s",
       signature_index, CHECK);
     const Symbol* const sig = cp->symbol_at(signature_index);
     verify_legal_field_signature(name, sig, CHECK);
-    assert(!access_flags.is_flattenable(), "ACC_FLATTENABLE should have been filtered out");
-    if (sig->is_Q_signature()) {
-      // assert(_major_version >= CONSTANT_CLASS_DESCRIPTORS, "Q-descriptors are only supported in recent classfiles");
-      access_flags.set_is_flattenable();
-    }
-    if (access_flags.is_flattenable()) {
-      // Array flattenability cannot be specified.  Arrays of value classes are
-      // are always flattenable.  Arrays of other classes are not flattenable.
-      if (sig->utf8_length() > 1 && sig->char_at(0) == '[') {
-        classfile_parse_error(
-            "Field \"%s\" with signature \"%s\" in class file %s is invalid."
-            " ACC_FLATTENABLE cannot be specified for an array",
-            name->as_C_string(), sig->as_klass_external_name(), CHECK);
-      }
-      _has_flattenable_fields = true;
-    }
     if (!access_flags.is_static()) instance_fields_count++;
 
     u2 constantvalue_index = 0;
     bool is_synthetic = false;
     u2 generic_signature_index = 0;
@@ -1765,11 +1749,11 @@
                       signature_index,
                       constantvalue_index);
     const BasicType type = cp->basic_type_for_signature_at(signature_index);
 
     // Remember how many oops we encountered and compute allocation type
-    const FieldAllocationType atype = fac->update(is_static, type, access_flags.is_flattenable());
+    const FieldAllocationType atype = fac->update(is_static, type, type == T_VALUETYPE);
     field->set_allocation_type(atype);
 
     // After field is initialized with type, we can augment it with aux info
     if (parsed_annotations.has_any_annotations()) {
       parsed_annotations.apply_to(field);
@@ -4324,11 +4308,11 @@
 
   // Calculate the starting byte offsets
   int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();
   // Inline types in static fields are not embedded, they are handled with oops
   int next_static_double_offset = next_static_oop_offset +
-                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_FLATTENABLE]) * heapOopSize);
+                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_INLINE]) * heapOopSize);
   if (fac->count[STATIC_DOUBLE]) {
     next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);
   }
 
   int next_static_word_offset   = next_static_double_offset +
@@ -4341,11 +4325,11 @@
   int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +
                                 nonstatic_field_size * heapOopSize;
 
   // First field of inline types is aligned on a long boundary in order to ease
   // in-lining of inline types (with header removal) in packed arrays and
-  // flatten inline types
+  // flattened inline types
   int initial_inline_type_padding = 0;
   if (is_inline_type()) {
     int old = nonstatic_fields_start;
     nonstatic_fields_start = align_up(nonstatic_fields_start, BytesPerLong);
     initial_inline_type_padding = nonstatic_fields_start - old;
@@ -4384,35 +4368,35 @@
   Klass** nonstatic_inline_type_klasses = NULL;
   unsigned int inline_type_oop_map_count = 0;
   int not_flattened_inline_types = 0;
   int not_atomic_inline_types = 0;
 
-  int max_nonstatic_inline_type = fac->count[NONSTATIC_FLATTENABLE] + 1;
+  int max_nonstatic_inline_type = fac->count[NONSTATIC_INLINE] + 1;
 
   nonstatic_inline_type_indexes = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, int,
                                                                max_nonstatic_inline_type);
   for (int i = 0; i < max_nonstatic_inline_type; i++) {
     nonstatic_inline_type_indexes[i] = -1;
   }
   nonstatic_inline_type_klasses = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, Klass*,
                                                                max_nonstatic_inline_type);
 
   for (AllFieldStream fs(_fields, _cp); !fs.done(); fs.next()) {
-    if (fs.allocation_type() == STATIC_FLATTENABLE) {
+    if (fs.allocation_type() == STATIC_INLINE) {
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       static_inline_type_count++;
-    } else if (fs.allocation_type() == NONSTATIC_FLATTENABLE) {
-      // Pre-resolve the flattenable field and check for inline type circularity issues.
+    } else if (fs.allocation_type() == NONSTATIC_INLINE) {
+      // Pre-resolve the inline field and check for inline type circularity issues.
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       Klass* klass =
-        SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+        SystemDictionary::resolve_inline_field_or_fail(&fs,
                                                             Handle(THREAD, _loader_data->class_loader()),
                                                             _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
       if (!klass->access_flags().is_inline_type()) {
         THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
@@ -4452,11 +4436,11 @@
   nonstatic_oop_count += not_flattened_inline_types;
 
   // Total non-static fields count, including every contended field
   unsigned int nonstatic_fields_count = fac->count[NONSTATIC_DOUBLE] + fac->count[NONSTATIC_WORD] +
                                         fac->count[NONSTATIC_SHORT] + fac->count[NONSTATIC_BYTE] +
-                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_FLATTENABLE];
+                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_INLINE];
 
   const bool super_has_nonstatic_fields =
           (_super_klass != NULL && _super_klass->has_nonstatic_fields());
   const bool has_nonstatic_fields =
     super_has_nonstatic_fields || (nonstatic_fields_count != 0);
@@ -4601,11 +4585,11 @@
     const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();
 
     // pack the rest of the fields
     switch (atype) {
       // Inline types in static fields are handled with oops
-      case STATIC_FLATTENABLE:   // Fallthrough
+      case STATIC_INLINE:   // Fallthrough
       case STATIC_OOP:
         real_offset = next_static_oop_offset;
         next_static_oop_offset += heapOopSize;
         break;
       case STATIC_BYTE:
@@ -4622,11 +4606,11 @@
         break;
       case STATIC_DOUBLE:
         real_offset = next_static_double_offset;
         next_static_double_offset += BytesPerLong;
         break;
-      case NONSTATIC_FLATTENABLE:
+      case NONSTATIC_INLINE:
         if (fs.is_flattened()) {
           Klass* klass = nonstatic_inline_type_klasses[next_inline_type_index];
           assert(klass != NULL, "Klass should have been loaded and resolved earlier");
           assert(klass->access_flags().is_inline_type(),"Must be an inline type");
           ValueKlass* vklass = ValueKlass::cast(klass);
@@ -4766,11 +4750,11 @@
             real_offset = next_nonstatic_padded_offset;
             next_nonstatic_padded_offset += BytesPerLong;
             break;
 
             // Inline types in static fields are handled with oops
-          case NONSTATIC_FLATTENABLE:
+          case NONSTATIC_INLINE:
             throwInlineTypeLimitation(THREAD_AND_LOCATION,
                                       "@Contended annotation not supported for inline types yet", fs.name(), fs.signature());
             return;
 
           case NONSTATIC_OOP:
@@ -4880,10 +4864,11 @@
   info->oop_map_blocks = nonstatic_oop_maps;
   info->_instance_size = instance_size;
   info->_static_field_size = static_field_size;
   info->_nonstatic_field_size = nonstatic_field_size;
   info->_has_nonstatic_fields = has_nonstatic_fields;
+  info->_has_inline_fields = nonstatic_inline_type_count > 0;
 
   // An inline type is naturally atomic if it has just one field, and
   // that field is simple enough.
   info->_is_naturally_atomic = (is_inline_type() &&
                                 !super_has_nonstatic_fields &&
@@ -6162,11 +6147,11 @@
   if (_has_injected_identityObject) {
     ik->set_has_injected_identityObject();
   }
 
   assert(_fac != NULL, "invariant");
-  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_FLATTENABLE]);
+  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_INLINE]);
 
   // this transfers ownership of a lot of arrays from
   // the parser onto the InstanceKlass*
   apply_parsed_class_metadata(ik, _java_fields_count, CHECK);
 
@@ -6327,11 +6312,11 @@
   }
 
   int nfields = ik->java_fields_count();
   if (ik->is_value()) nfields++;
   for (int i = 0; i < nfields; i++) {
-    if (ik->field_is_flattenable(i)) {
+    if (ik->field_is_inline(i)) {
       Symbol* klass_name = ik->field_signature(i)->fundamental_name(CHECK);
       // Inline classes for instance fields must have been pre-loaded
       // Inline classes for static fields might not have been loaded yet
       Klass* klass = SystemDictionary::find(klass_name,
           Handle(THREAD, ik->class_loader()),
@@ -6552,11 +6537,11 @@
   _relax_verify(false),
   _has_nonstatic_concrete_methods(false),
   _declares_nonstatic_concrete_methods(false),
   _has_final_method(false),
   _has_contended_fields(false),
-  _has_flattenable_fields(false),
+  _has_inline_fields(false),
   _has_nonstatic_fields(false),
   _is_empty_inline_type(false),
   _is_naturally_atomic(false),
   _is_declared_atomic(false),
   _invalid_inline_super(false),
@@ -7173,18 +7158,17 @@
   assert(_fac != NULL, "invariant");
   assert(_parsed_annotations != NULL, "invariant");
 
 
   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
-    if (fs.is_flattenable() && !fs.access_flags().is_static()) {
+    if (Signature::basic_type(fs.signature()) == T_VALUETYPE  && !fs.access_flags().is_static()) {
       // Pre-load value class
-      Klass* klass = SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+      Klass* klass = SystemDictionary::resolve_inline_field_or_fail(&fs,
           Handle(THREAD, _loader_data->class_loader()),
           _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
-      assert(klass->access_flags().is_inline_type(), "Inline type expected");
-      _has_flattenable_fields = true;
+      assert(klass->access_flags().is_inline_type(), "Value type expected");
     }
   }
 
   _field_info = new FieldLayoutInfo();
   if (UseNewFieldLayout) {
@@ -7198,10 +7182,11 @@
       _exact_size_in_bytes = lb.get_exact_size_in_byte();
     }
   } else {
     layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);
   }
+  _has_inline_fields = _field_info->_has_inline_fields;
 
   // Compute reference type
   _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass->reference_type();
 }
 
diff a/src/hotspot/share/classfile/classFileParser.hpp b/src/hotspot/share/classfile/classFileParser.hpp
--- a/src/hotspot/share/classfile/classFileParser.hpp
+++ b/src/hotspot/share/classfile/classFileParser.hpp
@@ -74,10 +74,11 @@
   int _instance_size;
   int _nonstatic_field_size;
   int _static_field_size;
   bool  _has_nonstatic_fields;
   bool  _is_naturally_atomic;
+  bool _has_inline_fields;
 };
 
 // Parser for for .class files
 //
 // The bytes describing the class file structure is read from a Stream object
@@ -200,11 +201,11 @@
   bool _has_nonstatic_concrete_methods;
   bool _declares_nonstatic_concrete_methods;
   bool _has_final_method;
   bool _has_contended_fields;
 
-  bool _has_flattenable_fields;
+  bool _has_inline_fields;
   bool _has_nonstatic_fields;
   bool _is_empty_inline_type;
   bool _is_naturally_atomic;
   bool _is_declared_atomic;
   bool _invalid_inline_super;   // if true, invalid super type for an inline type.
@@ -597,11 +598,11 @@
   bool is_unsafe_anonymous() const { return _unsafe_anonymous_host != NULL; }
   bool is_hidden() const { return _is_hidden; }
   bool is_interface() const { return _access_flags.is_interface(); }
   bool is_inline_type() const { return _access_flags.is_inline_type(); }
   bool is_value_capable_class() const;
-  bool has_flattenable_fields() const { return _has_flattenable_fields; }
+  bool has_inline_fields() const { return _has_inline_fields; }
   bool invalid_inline_super() const { return _invalid_inline_super; }
   void set_invalid_inline_super() { _invalid_inline_super = true; }
   bool invalid_identity_super() const { return _invalid_identity_super; }
   void set_invalid_identity_super() { _invalid_identity_super = true; }
   bool is_invalid_super_for_inline_type();
diff a/src/hotspot/share/classfile/fieldLayoutBuilder.cpp b/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
--- a/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
+++ b/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
@@ -535,10 +535,11 @@
   _nonstatic_oopmap_count(0),
   _alignment(-1),
   _first_field_offset(-1),
   _exact_size_in_bytes(-1),
   _has_nonstatic_fields(false),
+  _has_inline_fields(false),
   _is_contended(is_contended),
   _is_inline_type(is_inline_type),
   _has_flattening_information(is_inline_type),
   _has_nonatomic_values(false),
   _atomic_field_count(0)
@@ -612,22 +613,23 @@
     case T_ARRAY:
       if (group != _static_fields) _nonstatic_oopmap_count++;
       group->add_oop_field(fs);
       break;
     case T_VALUETYPE:
+//      fs.set_inline(true);
+      _has_inline_fields = true;
       if (group == _static_fields) {
         // static fields are never flattened
         group->add_oop_field(fs);
       } else {
         _has_flattening_information = true;
         // Flattening decision to be taken here
-        // This code assumes all verification have been performed before
-        // (field is a flattenable field, field's type has been loaded
-        // and it is an inline klass
+        // This code assumes all verification already have been performed
+        // (field's type has been loaded and it is an inline klass)
         Thread* THREAD = Thread::current();
         Klass* klass =
-            SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+            SystemDictionary::resolve_inline_field_or_fail(&fs,
                                                                 Handle(THREAD, _class_loader_data->class_loader()),
                                                                 _protection_domain, true, THREAD);
         assert(klass != NULL, "Sanity check");
         ValueKlass* vk = ValueKlass::cast(klass);
         bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&
@@ -713,21 +715,22 @@
         field_alignment = type2aelembytes(type); // alignment == size for oops
       }
       group->add_oop_field(fs);
       break;
     case T_VALUETYPE: {
+//      fs.set_inline(true);
+      _has_inline_fields = true;
       if (group == _static_fields) {
         // static fields are never flattened
         group->add_oop_field(fs);
       } else {
         // Flattening decision to be taken here
-        // This code assumes all verifications have been performed before
-        // (field is a flattenable field, field's type has been loaded
-        // and it is an inline klass
+        // This code assumes all verifications have already been performed
+        // (field's type has been loaded and it is an inline klass)
         Thread* THREAD = Thread::current();
         Klass* klass =
-            SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+            SystemDictionary::resolve_inline_field_or_fail(&fs,
                 Handle(THREAD, _class_loader_data->class_loader()),
                 _protection_domain, true, CHECK);
         assert(klass != NULL, "Sanity check");
         ValueKlass* vk = ValueKlass::cast(klass);
         bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&
@@ -943,10 +946,11 @@
   _info->oop_map_blocks = nonstatic_oop_maps;
   _info->_instance_size = align_object_size(instance_end / wordSize);
   _info->_static_field_size = static_fields_size;
   _info->_nonstatic_field_size = (nonstatic_field_end - instanceOopDesc::base_offset_in_bytes()) / heapOopSize;
   _info->_has_nonstatic_fields = _has_nonstatic_fields;
+  _info->_has_inline_fields = _has_inline_fields;
 
   // An inline type is naturally atomic if it has just one field, and
   // that field is simple enough.
   _info->_is_naturally_atomic = (_is_inline_type &&
                                  (_atomic_field_count <= 1) &&
diff a/src/hotspot/share/classfile/fieldLayoutBuilder.hpp b/src/hotspot/share/classfile/fieldLayoutBuilder.hpp
--- a/src/hotspot/share/classfile/fieldLayoutBuilder.hpp
+++ b/src/hotspot/share/classfile/fieldLayoutBuilder.hpp
@@ -251,10 +251,11 @@
   int _nonstatic_oopmap_count;
   int _alignment;
   int _first_field_offset;
   int _exact_size_in_bytes;
   bool _has_nonstatic_fields;
+  bool _has_inline_fields;
   bool _is_contended;
   bool _is_inline_type;
   bool _has_flattening_information;
   bool _has_nonatomic_values;
   int _atomic_field_count;
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -4489,11 +4489,11 @@
 int java_lang_reflect_RecordComponent::typeAnnotations_offset;
 int jdk_internal_vm_jni_SubElementSelector::_arrayElementType_offset;
 int jdk_internal_vm_jni_SubElementSelector::_subElementType_offset;
 int jdk_internal_vm_jni_SubElementSelector::_offset_offset;
 int jdk_internal_vm_jni_SubElementSelector::_isFlattened_offset;
-int jdk_internal_vm_jni_SubElementSelector::_isFlattenable_offset;
+int jdk_internal_vm_jni_SubElementSelector::_isInline_offset;
 
 
 
 #define STACKTRACEELEMENT_FIELDS_DO(macro) \
   macro(declaringClassObject_offset,  k, "declaringClassObject", class_signature, false); \
@@ -4800,11 +4800,11 @@
 #define SUBELEMENT_SELECTOR_FIELDS_DO(macro) \
   macro(_arrayElementType_offset,  k, "arrayElementType", class_signature, false); \
   macro(_subElementType_offset,    k, "subElementType",   class_signature, false); \
   macro(_offset_offset,            k, "offset",           int_signature,   false); \
   macro(_isFlattened_offset,       k, "isFlattened",      bool_signature,  false); \
-  macro(_isFlattenable_offset,     k, "isFlattenable",    bool_signature,  false);
+  macro(_isInline_offset,          k, "isInline",    bool_signature,  false);
 
 void jdk_internal_vm_jni_SubElementSelector::compute_offsets() {
   InstanceKlass* k = SystemDictionary::jdk_internal_vm_jni_SubElementSelector_klass();
   SUBELEMENT_SELECTOR_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -4850,16 +4850,16 @@
 
 void jdk_internal_vm_jni_SubElementSelector::setIsFlattened(oop obj, bool b) {
   obj->bool_field_put(_isFlattened_offset, b);
 }
 
-bool jdk_internal_vm_jni_SubElementSelector::getIsFlattenable(oop obj) {
-  return obj->bool_field(_isFlattenable_offset);
+bool jdk_internal_vm_jni_SubElementSelector::getIsInline(oop obj) {
+  return obj->bool_field(_isInline_offset);
 }
 
-void jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(oop obj, bool b) {
-  obj->bool_field_put(_isFlattenable_offset, b);
+void jdk_internal_vm_jni_SubElementSelector::setIsInline(oop obj, bool b) {
+  obj->bool_field_put(_isInline_offset, b);
 }
 
 jbyte java_lang_Byte::value(oop obj) {
    jvalue v;
    java_lang_boxing_object::get_value(obj, &v);
diff a/src/hotspot/share/classfile/javaClasses.hpp b/src/hotspot/share/classfile/javaClasses.hpp
--- a/src/hotspot/share/classfile/javaClasses.hpp
+++ b/src/hotspot/share/classfile/javaClasses.hpp
@@ -1667,11 +1667,11 @@
  private:
   static int _arrayElementType_offset;
   static int _subElementType_offset;
   static int _offset_offset;
   static int _isFlattened_offset;
-  static int _isFlattenable_offset;
+  static int _isInline_offset;
  public:
   static Symbol* symbol();
   static void compute_offsets();
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
@@ -1681,12 +1681,12 @@
   static void setSubElementType(oop obj, oop type);
   static int getOffset(oop obj);
   static void setOffset(oop obj, int offset);
   static bool getIsFlattened(oop obj);
   static void setIsFlattened(oop obj, bool b);
-  static bool getIsFlattenable(oop obj);
-  static void setIsFlattenable(oop obj, bool b);
+  static bool getIsInline(oop obj);
+  static void setIsInline(oop obj, bool b);
 };
 
 // Use to declare fields that need to be injected into Java classes
 // for the JVM to use.  The name_index and signature_index are
 // declared in vmSymbols.  The may_be_java flag is used to declare
diff a/src/hotspot/share/classfile/placeholders.cpp b/src/hotspot/share/classfile/placeholders.cpp
--- a/src/hotspot/share/classfile/placeholders.cpp
+++ b/src/hotspot/share/classfile/placeholders.cpp
@@ -42,11 +42,11 @@
   entry->set_havesupername(havesupername);
   entry->set_supername(supername);
   entry->set_superThreadQ(NULL);
   entry->set_loadInstanceThreadQ(NULL);
   entry->set_defineThreadQ(NULL);
-  entry->set_flattenableFieldQ(NULL);
+  entry->set_inlineFieldQ(NULL);
   entry->set_definer(NULL);
   entry->set_instance_klass(NULL);
   return entry;
 }
 
@@ -165,11 +165,11 @@
     if (probe != NULL) {
        probe->remove_seen_thread(thread, action);
        // If no other threads using this entry, and this thread is not using this entry for other states
        if ((probe->superThreadQ() == NULL) && (probe->loadInstanceThreadQ() == NULL)
           && (probe->defineThreadQ() == NULL) && (probe->definer() == NULL)
-          && (probe->flattenableFieldQ() == NULL)) {
+          && (probe->inlineFieldQ() == NULL)) {
          remove_entry(index, hash, name, loader_data);
        }
     }
   }
 
@@ -220,12 +220,12 @@
   superThreadQ()->print_action_queue(st);
   st->cr();
   st->print("defineThreadQ threads:");
   defineThreadQ()->print_action_queue(st);
   st->cr();
-  st->print("flattenableFieldQ threads:");
-  flattenableFieldQ()->print_action_queue(st);
+  st->print("inlineFieldQ threads:");
+  inlineFieldQ()->print_action_queue(st);
   st->cr();
 }
 
 void PlaceholderTable::print_on(outputStream* st) const {
   st->print_cr("Placeholder table (table_size=%d, placeholders=%d)",
diff a/src/hotspot/share/classfile/placeholders.hpp b/src/hotspot/share/classfile/placeholders.hpp
--- a/src/hotspot/share/classfile/placeholders.hpp
+++ b/src/hotspot/share/classfile/placeholders.hpp
@@ -72,16 +72,16 @@
 // LOAD_SUPER needed to check for class circularity
 // DEFINE_CLASS: ultimately define class must be single threaded
 // on a class/classloader basis
 // so the head of that queue owns the token
 // and the rest of the threads return the result the first thread gets
-// FLATTENABLE_FIELD: needed to check for value type flattenable fields circularity
+// INLINE_FIELD: needed to check for inline type fields circularity
  enum classloadAction {
     LOAD_INSTANCE = 1,             // calling load_instance_class
     LOAD_SUPER = 2,                // loading superclass for this class
     DEFINE_CLASS = 3,              // find_or_define class
-    FLATTENABLE_FIELD = 4          // flattenable value type fields
+    INLINE_FIELD = 4               // inline type fields
  };
 
   // find_and_add returns probe pointer - old or new
   // If no entry exists, add a placeholder entry and push SeenThread for classloadAction
   // If entry exists, reuse entry and push SeenThread for classloadAction
@@ -109,11 +109,11 @@
 // For bootclasssearchpath, set before calling load_instance_class.
 // Defining must be single threaded on a class/classloader basis
 // For DEFINE_CLASS, the head of the queue owns the
 // define token and the rest of the threads wait to return the
 // result the first thread gets.
-// For FLATTENABLE_FIELD, set when loading value type fields for
+// For INLINE_FIELD, set when loading inline type fields for
 // class circularity checking.
 class SeenThread: public CHeapObj<mtInternal> {
 private:
    Thread *_thread;
    SeenThread* _stnext;
@@ -162,11 +162,11 @@
 
   SeenThread*       _defineThreadQ; // queue of Threads trying to define this class
                                     // including _definer
                                     // _definer owns token
                                     // queue waits for and returns results from _definer
-  SeenThread*       _flattenableFieldQ; // queue of value types for circularity checking
+  SeenThread*       _inlineFieldQ;  // queue of inline types for circularity checking
 
  public:
   // Simple accessors, used only by SystemDictionary
   Symbol*            klassname()           const { return literal(); }
 
@@ -195,12 +195,12 @@
   void               set_loadInstanceThreadQ(SeenThread* SeenThread) { _loadInstanceThreadQ = SeenThread; }
 
   SeenThread*        defineThreadQ()        const { return _defineThreadQ; }
   void               set_defineThreadQ(SeenThread* SeenThread) { _defineThreadQ = SeenThread; }
 
-  SeenThread*        flattenableFieldQ()    const { return _flattenableFieldQ; }
-  void               set_flattenableFieldQ(SeenThread* SeenThread) { _flattenableFieldQ = SeenThread; }
+  SeenThread*        inlineFieldQ()    const { return _inlineFieldQ; }
+  void               set_inlineFieldQ(SeenThread* SeenThread) { _inlineFieldQ = SeenThread; }
 
   PlaceholderEntry* next() const {
     return (PlaceholderEntry*)HashtableEntry<Symbol*, mtClass>::next();
   }
 
@@ -224,12 +224,12 @@
          queuehead = _superThreadQ;
          break;
       case PlaceholderTable::DEFINE_CLASS:
 	 queuehead = _defineThreadQ;
 	 break;
-      case PlaceholderTable::FLATTENABLE_FIELD:
-         queuehead = _flattenableFieldQ;
+      case PlaceholderTable::INLINE_FIELD:
+         queuehead = _inlineFieldQ;
          break;
       default: Unimplemented();
     }
     return queuehead;
   }
@@ -243,12 +243,12 @@
          _superThreadQ = seenthread;
          break;
       case PlaceholderTable::DEFINE_CLASS:
          _defineThreadQ = seenthread;
          break;
-      case PlaceholderTable::FLATTENABLE_FIELD:
-         _flattenableFieldQ = seenthread;
+      case PlaceholderTable::INLINE_FIELD:
+         _inlineFieldQ = seenthread;
          break;
       default: Unimplemented();
     }
     return;
   }
@@ -263,12 +263,12 @@
 
   bool define_class_in_progress() {
     return (_defineThreadQ != NULL);
   }
 
-  bool flattenable_field_in_progress() {
-    return (_flattenableFieldQ != NULL);
+  bool inline_field_in_progress() {
+    return (_inlineFieldQ != NULL);
   }
 
 // Doubly-linked list of Threads per action for class/classloader pair
 // Class circularity support: links in thread before loading superclass
 // bootstrapsearchpath support: links in a thread before load_instance_class
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -506,11 +506,11 @@
   }
 
   return superk;
 }
 
-Klass* SystemDictionary::resolve_flattenable_field_or_fail(AllFieldStream* fs,
+Klass* SystemDictionary::resolve_inline_field_or_fail(AllFieldStream* fs,
                                                            Handle class_loader,
                                                            Handle protection_domain,
                                                            bool throw_error,
                                                            TRAPS) {
   Symbol* class_name = fs->signature()->fundamental_name(THREAD);
@@ -523,16 +523,16 @@
 
   {
     MutexLocker mu(THREAD, SystemDictionary_lock);
     oldprobe = placeholders()->get_entry(p_index, p_hash, class_name, loader_data);
     if (oldprobe != NULL &&
-      oldprobe->check_seen_thread(THREAD, PlaceholderTable::FLATTENABLE_FIELD)) {
+      oldprobe->check_seen_thread(THREAD, PlaceholderTable::INLINE_FIELD)) {
       throw_circularity_error = true;
 
     } else {
       placeholders()->find_and_add(p_index, p_hash, class_name, loader_data,
-                                   PlaceholderTable::FLATTENABLE_FIELD, NULL, THREAD);
+                                   PlaceholderTable::INLINE_FIELD, NULL, THREAD);
     }
   }
 
   Klass* klass = NULL;
   if (!throw_circularity_error) {
@@ -544,11 +544,11 @@
   }
 
   {
     MutexLocker mu(THREAD, SystemDictionary_lock);
     placeholders()->find_and_remove(p_index, p_hash, class_name, loader_data,
-                                    PlaceholderTable::FLATTENABLE_FIELD, THREAD);
+                                    PlaceholderTable::INLINE_FIELD, THREAD);
   }
 
   class_name->decrement_refcount();
   return klass;
 }
diff a/src/hotspot/share/classfile/systemDictionary.hpp b/src/hotspot/share/classfile/systemDictionary.hpp
--- a/src/hotspot/share/classfile/systemDictionary.hpp
+++ b/src/hotspot/share/classfile/systemDictionary.hpp
@@ -320,11 +320,11 @@
                                               Handle class_loader,
                                               Handle protection_domain,
                                               bool is_superclass,
                                               TRAPS);
 
-  static Klass* resolve_flattenable_field_or_fail(AllFieldStream* fs,
+  static Klass* resolve_inline_field_or_fail(AllFieldStream* fs,
                                                   Handle class_loader,
                                                   Handle protection_domain,
                                                   bool throw_error,
                                                   TRAPS);
 
diff a/src/hotspot/share/interpreter/interpreterRuntime.cpp b/src/hotspot/share/interpreter/interpreterRuntime.cpp
--- a/src/hotspot/share/interpreter/interpreterRuntime.cpp
+++ b/src/hotspot/share/interpreter/interpreterRuntime.cpp
@@ -358,11 +358,11 @@
       ValueKlass* field_vk = ValueKlass::cast(vklass->get_value_field_klass(field_index));
       assert(vt_oop != NULL && field_vk == vt_oop->klass(), "Must match");
       field_vk->write_flattened_field(new_value_h(), offset, vt_oop, CHECK_(return_offset));
     } else { // not flattened
       oop voop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
-      if (voop == NULL && cp_entry->is_flattenable()) {
+      if (voop == NULL && cp_entry->is_inline()) {
         THROW_(vmSymbols::java_lang_NullPointerException(), return_offset);
       }
       assert(voop == NULL || oopDesc::is_oop(voop),"checking argument");
       new_value_h()->obj_field_put(field_offset, voop);
     }
@@ -375,11 +375,11 @@
   thread->set_vm_result(new_value_h());
   return return_offset;
 JRT_END
 
 JRT_ENTRY(void, InterpreterRuntime::uninitialized_static_value_field(JavaThread* thread, oopDesc* mirror, int index))
-  // The interpreter tries to access a flattenable static field that has not been initialized.
+  // The interpreter tries to access an inline static field that has not been initialized.
   // This situation can happen in different scenarios:
   //   1 - if the load or initialization of the field failed during step 8 of
   //       the initialization of the holder of the field, in this case the access to the field
   //       must fail
   //   2 - it can also happen when the initialization of the holder class triggered the initialization of
@@ -990,11 +990,11 @@
     info.offset(),
     state,
     info.access_flags().is_final(),
     info.access_flags().is_volatile(),
     info.is_flattened(),
-    info.is_flattenable(),
+    info.is_inline(),
     pool->pool_holder()
   );
 }
 
 
diff a/src/hotspot/share/memory/heapInspection.cpp b/src/hotspot/share/memory/heapInspection.cpp
--- a/src/hotspot/share/memory/heapInspection.cpp
+++ b/src/hotspot/share/memory/heapInspection.cpp
@@ -526,27 +526,27 @@
   const Symbol* signature() { return _signature; }
   const int offset() { return _offset; }
   const int index() { return _index; }
   const InstanceKlass* holder() { return _holder; }
   const AccessFlags& access_flags() { return _access_flags; }
-  const bool is_flattenable() { return _access_flags.is_flattenable(); }
+  const bool is_inline() { return Signature::basic_type(_signature) == T_VALUETYPE; }
 };
 
 static int compare_offset(FieldDesc* f1, FieldDesc* f2) {
    return f1->offset() > f2->offset() ? 1 : -1;
 }
 
-static void print_field(outputStream* st, int level, int offset, FieldDesc& fd, bool flattenable, bool flattened ) {
+static void print_field(outputStream* st, int level, int offset, FieldDesc& fd, bool is_inline, bool flattened ) {
   const char* flattened_msg = "";
-  if (flattenable) {
+  if (is_inline) {
     flattened_msg = flattened ? "and flattened" : "not flattened";
   }
   st->print_cr("  @ %d %*s \"%s\" %s %s %s",
       offset, level * 3, "",
       fd.name()->as_C_string(),
       fd.signature()->as_C_string(),
-      flattenable ? " // flattenable" : "",
+      is_inline ? " // inline " : "",
       flattened_msg);
 }
 
 static void print_flattened_field(outputStream* st, int level, int offset, InstanceKlass* klass) {
   assert(klass->is_value(), "Only value classes can be flattened");
@@ -560,11 +560,11 @@
   fields->sort(compare_offset);
   for(int i = 0; i < fields->length(); i++) {
     FieldDesc fd = fields->at(i);
     int offset2 = offset + fd.offset() - vklass->first_field_offset();
     print_field(st, level, offset2, fd,
-        fd.is_flattenable(), fd.holder()->field_is_flattened(fd.index()));
+        fd.is_inline(), fd.holder()->field_is_flattened(fd.index()));
     if (fd.holder()->field_is_flattened(fd.index())) {
       print_flattened_field(st, level + 1, offset2 ,
           InstanceKlass::cast(fd.holder()->get_value_field_klass(fd.index())));
     }
   }
@@ -601,11 +601,11 @@
       }
     }
     fields->sort(compare_offset);
     for(int i = 0; i < fields->length(); i++) {
       FieldDesc fd = fields->at(i);
-      print_field(st, 0, fd.offset(), fd, fd.is_flattenable(), fd.holder()->field_is_flattened(fd.index()));
+      print_field(st, 0, fd.offset(), fd, fd.is_inline(), fd.holder()->field_is_flattened(fd.index()));
       if (fd.holder()->field_is_flattened(fd.index())) {
         print_flattened_field(st, 1, fd.offset(),
             InstanceKlass::cast(fd.holder()->get_value_field_klass(fd.index())));
       }
     }
diff a/src/hotspot/share/oops/cpCache.cpp b/src/hotspot/share/oops/cpCache.cpp
--- a/src/hotspot/share/oops/cpCache.cpp
+++ b/src/hotspot/share/oops/cpCache.cpp
@@ -132,22 +132,22 @@
                                        int field_offset,
                                        TosState field_type,
                                        bool is_final,
                                        bool is_volatile,
                                        bool is_flattened,
-                                       bool is_flattenable,
+                                       bool is_inline,
                                        Klass* root_klass) {
   set_f1(field_holder);
   set_f2(field_offset);
   assert((field_index & field_index_mask) == field_index,
          "field index does not fit in low flag bits");
-  assert(!is_flattened || is_flattenable, "Sanity check");
+  assert(!is_flattened || is_inline, "Sanity check");
   set_field_flags(field_type,
                   ((is_volatile ? 1 : 0) << is_volatile_shift) |
                   ((is_final    ? 1 : 0) << is_final_shift) |
                   ((is_flattened  ? 1 : 0) << is_flattened_field_shift) |
-                  ((is_flattenable ? 1 : 0) << is_flattenable_field_shift),
+                  ((is_inline ? 1 : 0) << is_inline_field_shift),
                   field_index);
   set_bytecode_1(get_code);
   set_bytecode_2(put_code);
   NOT_PRODUCT(verify(tty));
 }
diff a/src/hotspot/share/oops/cpCache.hpp b/src/hotspot/share/oops/cpCache.hpp
--- a/src/hotspot/share/oops/cpCache.hpp
+++ b/src/hotspot/share/oops/cpCache.hpp
@@ -49,11 +49,11 @@
 // bit length |-8--|-8--|---16----|
 // --------------------------------
 // _indices   [ b2 | b1 |  index  ]  index = constant_pool_index
 // _f1        [  entry specific   ]  metadata ptr (method or klass)
 // _f2        [  entry specific   ]  vtable or res_ref index, or vfinal method ptr
-// _flags     [tos|0|F=1|0|N|i|f|v|0 |0000|field_index] (for field entries)
+// _flags     [tos|0|F=1|0|I|i|f|v|0 |0000|field_index] (for field entries)
 // bit length [ 4 |1| 1 |1|1|1|1|1|1 |1     |-3-|----16-----]
 // _flags     [tos|0|F=0|S|A|I|f|0|vf|indy_rf|000|00000|psize] (for method entries)
 // bit length [ 4 |1| 1 |1|1|1|1|1|1 |-4--|--8--|--8--]
 
 // --------------------------------
@@ -75,11 +75,11 @@
 // vf     = virtual but final (method entries only: is_vfinal())
 // indy_rf = call site specifier method resolution failed
 //
 // The flags after TosState have the following interpretation:
 // bit 27: 0 for fields, 1 for methods
-// N  flag true if field is marked flattenable (must never be null)
+// I  flag true if field is an inline type (must never be null)
 // i  flag true if field is inlined (flattened)
 // f  flag true if field is marked final
 // v  flag true if field is volatile (only for fields)
 // f2 flag true if f2 contains an oop (e.g., virtual final method)
 // fv flag true if invokeinterface used for method in class Object
@@ -184,11 +184,11 @@
     tos_state_shift            = BitsPerInt - tos_state_bits,  // see verify_tos_state_shift below
     // misc. option bits; can be any bit position in [16..27]
     is_field_entry_shift       = 26,  // (F) is it a field or a method?
     has_local_signature_shift  = 25,  // (S) does the call site have a per-site signature (sig-poly methods)?
     has_appendix_shift         = 24,  // (A) does the call site have an appendix argument?
-    is_flattenable_field_shift = 24,  // (N) is the field flattenable (must never be null)
+    is_inline_field_shift      = 24,  // (I) is the field inline (must never be null)
     is_forced_virtual_shift    = 23,  // (I) is the interface reference forced to virtual mode?
     is_flattened_field_shift   = 23,  // (i) is the value field flattened?
     is_final_shift             = 22,  // (f) is the field or method final?
     is_volatile_shift          = 21,  // (v) is the field volatile?
     is_vfinal_shift            = 20,  // (vf) did the call resolve to a final method?
@@ -227,11 +227,11 @@
     int             field_offset,                // the field offset in words in the field holder
     TosState        field_type,                  // the (machine) field type
     bool            is_final,                    // the field is final
     bool            is_volatile,                 // the field is volatile
     bool            is_flattened,                // the field is flattened (value field)
-    bool            is_flattenable,              // the field is flattenable (must never be null)
+    bool            is_inline,                   // the field is inline (must never be null)
     Klass*          root_klass                   // needed by the GC to dirty the klass
   );
 
  private:
   void set_direct_or_vtable_call(
@@ -361,11 +361,11 @@
   bool has_local_signature() const;
   bool is_method_entry() const                   { return (_flags & (1 << is_field_entry_shift))    == 0; }
   bool is_field_entry() const                    { return (_flags & (1 << is_field_entry_shift))    != 0; }
   bool is_long() const                           { return flag_state() == ltos; }
   bool is_double() const                         { return flag_state() == dtos; }
-  bool is_flattenable() const                    { return (_flags & (1 << is_flattenable_field_shift))       != 0; }
+  bool is_inline() const                         { return (_flags & (1 << is_inline_field_shift))       != 0; }
   TosState flag_state() const                    { assert((uint)number_of_states <= (uint)tos_state_mask+1, "");
                                                    return (TosState)((_flags >> tos_state_shift) & tos_state_mask); }
   void set_indy_resolution_failed();
 
   // Code generation support
diff a/src/hotspot/share/oops/fieldInfo.hpp b/src/hotspot/share/oops/fieldInfo.hpp
--- a/src/hotspot/share/oops/fieldInfo.hpp
+++ b/src/hotspot/share/oops/fieldInfo.hpp
@@ -268,14 +268,10 @@
   void set_stable(bool z) {
     if (z) _shorts[access_flags_offset] |=  JVM_ACC_FIELD_STABLE;
     else   _shorts[access_flags_offset] &= ~JVM_ACC_FIELD_STABLE;
   }
 
-  bool is_flattenable() const {
-    return (access_flags() & JVM_ACC_FLATTENABLE) != 0;
-  }
-
   Symbol* lookup_symbol(int symbol_index) const {
     assert(is_internal(), "only internal fields");
     return vmSymbols::symbol_at((vmSymbols::SID)symbol_index);
   }
 };
diff a/src/hotspot/share/oops/fieldStreams.hpp b/src/hotspot/share/oops/fieldStreams.hpp
--- a/src/hotspot/share/oops/fieldStreams.hpp
+++ b/src/hotspot/share/oops/fieldStreams.hpp
@@ -145,16 +145,10 @@
 
   void set_flattened(bool b) {
     field()->set_flattened(b);
   }
 
-  bool is_flattenable() const {
-    AccessFlags flags;
-    flags.set_flags(field()->access_flags());
-    return flags.is_flattenable();
-  }
-
   void set_offset(int offset) {
     field()->set_offset(offset);
   }
 
   bool is_offset_set() const {
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -154,10 +154,12 @@
     }
   }
   return false;
 }
 
+bool InstanceKlass::field_is_inline(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_VALUETYPE; }
+
 // private: called to verify that k is a static member of this nest.
 // We know that k is an instance class in the same package and hence the
 // same classloader.
 bool InstanceKlass::has_nest_member(InstanceKlass* k, TRAPS) const {
   assert(!is_hidden(), "unexpected hidden class");
@@ -422,11 +424,11 @@
                                        parser.itable_size(),
                                        nonstatic_oop_map_size(parser.total_oop_map_count()),
                                        parser.is_interface(),
                                        parser.is_unsafe_anonymous(),
                                        should_store_fingerprint(is_hidden_or_anonymous),
-                                       parser.has_flattenable_fields() ? parser.java_fields_count() : 0,
+                                       parser.has_inline_fields() ? parser.java_fields_count() : 0,
                                        parser.is_inline_type());
 
   const Symbol* const class_name = parser.class_name();
   assert(class_name != NULL, "invariant");
   ClassLoaderData* loader_data = parser.loader_data();
@@ -535,11 +537,11 @@
   set_access_flags(parser.access_flags());
   if (parser.is_hidden()) set_is_hidden();
   set_is_unsafe_anonymous(parser.is_unsafe_anonymous());
   set_layout_helper(Klass::instance_layout_helper(parser.layout_size(),
                                                     false));
-    if (parser.has_flattenable_fields()) {
+    if (parser.has_inline_fields()) {
       set_has_inline_fields();
     }
     _java_fields_count = parser.java_fields_count();
 
     assert(NULL == _methods, "underlying memory not zeroed?");
@@ -920,11 +922,11 @@
   // linked (and have performed their own pre-loading) before the linking
   // of the current class.
 
 
   // Note:
-  // Inline class types used for flattenable fields are loaded during
+  // Inline class types are loaded during
   // the loading phase (see ClassFileParser::post_process_parsed_stream()).
   // Inline class types used as element types for array creation
   // are not pre-loaded. Their loading is triggered by either anewarray
   // or multianewarray bytecodes.
 
@@ -1187,18 +1189,17 @@
       THROW_OOP(e());
     }
   }
 
   // Step 8
-  // Initialize classes of flattenable fields
+  // Initialize classes of inline fields
   {
     for (AllFieldStream fs(this); !fs.done(); fs.next()) {
-      if (fs.is_flattenable()) {
+      if (Signature::basic_type(fs.signature()) == T_VALUETYPE) {
         Klass* klass = this->get_value_field_klass_or_null(fs.index());
         if (klass == NULL) {
-          assert(fs.access_flags().is_static() && fs.access_flags().is_flattenable(),
-              "Otherwise should have been pre-loaded");
+          assert(fs.access_flags().is_static(), "Otherwise should have been pre-loaded");
           klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),
               Handle(THREAD, class_loader()),
               Handle(THREAD, protection_domain()),
               true, CHECK);
           if (klass == NULL) {
diff a/src/hotspot/share/oops/instanceKlass.hpp b/src/hotspot/share/oops/instanceKlass.hpp
--- a/src/hotspot/share/oops/instanceKlass.hpp
+++ b/src/hotspot/share/oops/instanceKlass.hpp
@@ -541,11 +541,11 @@
   int     field_offset      (int index) const { return field(index)->offset(); }
   int     field_access_flags(int index) const { return field(index)->access_flags(); }
   Symbol* field_name        (int index) const { return field(index)->name(constants()); }
   Symbol* field_signature   (int index) const { return field(index)->signature(constants()); }
   bool    field_is_flattened(int index) const { return field(index)->is_flattened(); }
-  bool    field_is_flattenable(int index) const { return field(index)->is_flattenable(); }
+  bool    field_is_inline   (int index) const;
 
   // Number of Java declared fields
   int java_fields_count() const           { return (int)_java_fields_count; }
 
   Array<u2>* fields() const            { return _fields; }
diff a/src/hotspot/share/prims/jni.cpp b/src/hotspot/share/prims/jni.cpp
--- a/src/hotspot/share/prims/jni.cpp
+++ b/src/hotspot/share/prims/jni.cpp
@@ -3494,11 +3494,11 @@
   Handle ses_h(THREAD, ses);
   jdk_internal_vm_jni_SubElementSelector::setArrayElementType(ses_h(), elementKlass->java_mirror());
   jdk_internal_vm_jni_SubElementSelector::setSubElementType(ses_h(), elementKlass->java_mirror());
   jdk_internal_vm_jni_SubElementSelector::setOffset(ses_h(), 0);
   jdk_internal_vm_jni_SubElementSelector::setIsFlattened(ses_h(), true);   // by definition, top element of a flattened array is flattened
-  jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(ses_h(), true); // by definition, top element of a flattened array is flattenable
+  jdk_internal_vm_jni_SubElementSelector::setIsInline(ses_h(), true); // by definition, top element of a flattened array is an inline type
   return JNIHandles::make_local(ses_h());
 JNI_END
 
 JNI_ENTRY(jobject, jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))
   JNIWrapper("jni_GetSubElementSelector");
@@ -3540,11 +3540,11 @@
         Handle(THREAD, holder->protection_domain()), true, CHECK_NULL);
     jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(),fieldKlass->java_mirror());
   }
   jdk_internal_vm_jni_SubElementSelector::setOffset(res_h(), offset);
   jdk_internal_vm_jni_SubElementSelector::setIsFlattened(res_h(), fd.is_flattened());
-  jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(res_h(), fd.is_flattenable());
+  jdk_internal_vm_jni_SubElementSelector::setIsInline(res_h(), fd.is_inline());
   return JNIHandles::make_local(res_h());
 JNI_END
 
 JNI_ENTRY(jobject, jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))
   JNIWrapper("jni_GetObjectSubElement");
@@ -3581,11 +3581,11 @@
   if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {
     THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), "Array/Selector mismatch");
   }
   oop val = JNIHandles::resolve(value);
   if (val == NULL) {
-    if (jdk_internal_vm_jni_SubElementSelector::getIsFlattenable(slct)) {
+    if (jdk_internal_vm_jni_SubElementSelector::getIsInline(slct)) {
       THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), "null cannot be stored in a flattened array");
     }
   } else {
     if (!val->is_a(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)))) {
       THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), "type mismatch");
diff a/src/hotspot/share/prims/methodHandles.cpp b/src/hotspot/share/prims/methodHandles.cpp
--- a/src/hotspot/share/prims/methodHandles.cpp
+++ b/src/hotspot/share/prims/methodHandles.cpp
@@ -339,14 +339,11 @@
 }
 
 oop MethodHandles::init_field_MemberName(Handle mname, fieldDescriptor& fd, bool is_setter) {
   int flags = (jushort)( fd.access_flags().as_short() & JVM_RECOGNIZED_FIELD_MODIFIERS );
   flags |= IS_FIELD | ((fd.is_static() ? JVM_REF_getStatic : JVM_REF_getField) << REFERENCE_KIND_SHIFT);
-  if (fd.is_flattenable()) {
-    flags |= JVM_ACC_FIELD_FLATTENABLE;
-  }
-    if (fd.is_flattened()) {
+  if (fd.is_flattened()) {
     flags |= JVM_ACC_FIELD_FLATTENED;
   }
   if (is_setter)  flags += ((JVM_REF_putField - JVM_REF_getField) << REFERENCE_KIND_SHIFT);
   int vmindex        = fd.offset();  // determines the field uniquely when combined with static bit
 
diff a/src/hotspot/share/runtime/fieldDescriptor.hpp b/src/hotspot/share/runtime/fieldDescriptor.hpp
--- a/src/hotspot/share/runtime/fieldDescriptor.hpp
+++ b/src/hotspot/share/runtime/fieldDescriptor.hpp
@@ -92,11 +92,11 @@
   bool is_final()                 const    { return access_flags().is_final(); }
   bool is_stable()                const    { return access_flags().is_stable(); }
   bool is_volatile()              const    { return access_flags().is_volatile(); }
   bool is_transient()             const    { return access_flags().is_transient(); }
   inline bool is_flattened()      const;
-  inline bool is_flattenable()    const;
+  inline bool is_inline()         const;
 
   bool is_synthetic()             const    { return access_flags().is_synthetic(); }
 
   bool is_field_access_watched()  const    { return access_flags().is_field_access_watched(); }
   bool is_field_modification_watched() const
diff a/src/hotspot/share/runtime/fieldDescriptor.inline.hpp b/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
--- a/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
+++ b/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
@@ -78,8 +78,8 @@
 inline BasicType fieldDescriptor::field_type() const {
   return Signature::basic_type(signature());
 }
 
 inline bool fieldDescriptor::is_flattened()  const  { return field()->is_flattened(); }
-inline bool fieldDescriptor::is_flattenable() const { return field()->is_flattenable(); }
+inline bool fieldDescriptor::is_inline() const { return Signature::basic_type(field()->signature(_cp())) == T_VALUETYPE; }
 
 #endif // SHARE_RUNTIME_FIELDDESCRIPTOR_INLINE_HPP
diff a/src/hotspot/share/runtime/globals.hpp b/src/hotspot/share/runtime/globals.hpp
--- a/src/hotspot/share/runtime/globals.hpp
+++ b/src/hotspot/share/runtime/globals.hpp
@@ -2471,17 +2471,10 @@
   diagnostic(ccstrlist, ForceNonTearable, "",                               \
           "List of inline classes which are forced to be atomic "           \
           "(whitespace and commas separate names, "                         \
           "and leading and trailing stars '*' are wildcards)")              \
                                                                             \
-  product(bool, PrintNewLayout, false,                                      \
-               "Print layout compute by new algorithm")                     \
-                                                                            \
-  product(bool, PrintFlattenableLayouts, false,                             \
-                "Print layout of inline classes and classes with "          \
-                "flattenable fields")                                       \
-                                                                            \
   product(bool, UseNewFieldLayout, true,                                    \
                 "(Deprecated) Use new algorithm to compute field layouts")  \
                                                                             \
   product(bool, UseEmptySlotsInSupers, true,                                \
                 "Allow allocating fields in empty slots of super-classes")  \
diff a/src/hotspot/share/runtime/reflection.cpp b/src/hotspot/share/runtime/reflection.cpp
--- a/src/hotspot/share/runtime/reflection.cpp
+++ b/src/hotspot/share/runtime/reflection.cpp
@@ -901,15 +901,10 @@
   java_lang_reflect_Field::set_slot(rh(), fd->index());
   java_lang_reflect_Field::set_name(rh(), name());
   java_lang_reflect_Field::set_type(rh(), type());
   // Note the ACC_ANNOTATION bit, which is a per-class access flag, is never set here.
   int modifiers = fd->access_flags().as_int() & JVM_RECOGNIZED_FIELD_MODIFIERS;
-  if (fd->is_flattenable()) {
-    modifiers |= JVM_ACC_FIELD_FLATTENABLE;
-    // JVM_ACC_FLATTENABLE should not be set in LWorld.  set_is_flattenable should be re-examined.
-    modifiers &= ~JVM_ACC_FLATTENABLE;
-  }
   if (fd->is_flattened()) {
     modifiers |= JVM_ACC_FIELD_FLATTENED;
   }
   java_lang_reflect_Field::set_modifiers(rh(), modifiers);
   java_lang_reflect_Field::set_override(rh(), false);
diff a/src/hotspot/share/utilities/accessFlags.hpp b/src/hotspot/share/utilities/accessFlags.hpp
--- a/src/hotspot/share/utilities/accessFlags.hpp
+++ b/src/hotspot/share/utilities/accessFlags.hpp
@@ -84,20 +84,17 @@
   JVM_ACC_FIELD_MODIFICATION_WATCHED      = 0x00008000, // field modification is watched by JVMTI
   JVM_ACC_FIELD_INTERNAL                  = 0x00000400, // internal field, same as JVM_ACC_ABSTRACT
   JVM_ACC_FIELD_STABLE                    = 0x00000020, // @Stable field, same as JVM_ACC_SYNCHRONIZED and JVM_ACC_SUPER
   JVM_ACC_FIELD_INITIALIZED_FINAL_UPDATE  = 0x00000200, // (static) final field updated outside (class) initializer, same as JVM_ACC_NATIVE
   JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE     = 0x00000800, // field has generic signature
-  JVM_ACC_FIELD_FLATTENABLE               = 0x00004000, // flattenable field
   JVM_ACC_FIELD_FLATTENED                 = 0x00008000, // flattened field
 
   JVM_ACC_FIELD_INTERNAL_FLAGS       = JVM_ACC_FIELD_ACCESS_WATCHED |
                                        JVM_ACC_FIELD_MODIFICATION_WATCHED |
                                        JVM_ACC_FIELD_INTERNAL |
                                        JVM_ACC_FIELD_STABLE |
                                        JVM_ACC_FIELD_HAS_GENERIC_SIGNATURE |
-                                       JVM_ACC_FLATTENABLE |
-                                       JVM_ACC_FIELD_FLATTENABLE |
                                        JVM_ACC_FIELD_FLATTENED,
 
                                                     // flags accepted by set_field_flags()
   JVM_ACC_FIELD_FLAGS                = JVM_RECOGNIZED_FIELD_MODIFIERS | JVM_ACC_FIELD_INTERNAL_FLAGS
 
@@ -126,11 +123,10 @@
   bool is_native      () const         { return (_flags & JVM_ACC_NATIVE      ) != 0; }
   bool is_interface   () const         { return (_flags & JVM_ACC_INTERFACE   ) != 0; }
   bool is_abstract    () const         { return (_flags & JVM_ACC_ABSTRACT    ) != 0; }
   bool is_strict      () const         { return (_flags & JVM_ACC_STRICT      ) != 0; }
   bool is_inline_type () const         { return (_flags & JVM_ACC_VALUE       ) != 0; }
-  bool is_flattenable () const         { return (_flags & JVM_ACC_FLATTENABLE ) != 0; }
 
   // Attribute flags
   bool is_synthetic   () const         { return (_flags & JVM_ACC_SYNTHETIC   ) != 0; }
 
   // Method* flags
@@ -217,11 +213,10 @@
   void set_has_jsrs()                  { atomic_set_bits(JVM_ACC_HAS_JSRS);                }
   void set_is_old()                    { atomic_set_bits(JVM_ACC_IS_OLD);                  }
   void set_is_obsolete()               { atomic_set_bits(JVM_ACC_IS_OBSOLETE);             }
   void set_is_deleted()                { atomic_set_bits(JVM_ACC_IS_DELETED);              }
   void set_is_prefixed_native()        { atomic_set_bits(JVM_ACC_IS_PREFIXED_NATIVE);      }
-  void set_is_flattenable()            { atomic_set_bits(JVM_ACC_FLATTENABLE);             }
 
   void clear_not_c1_compilable()       { atomic_clear_bits(JVM_ACC_NOT_C1_COMPILABLE);       }
   void clear_not_c2_compilable()       { atomic_clear_bits(JVM_ACC_NOT_C2_COMPILABLE);       }
   void clear_not_c2_osr_compilable()   { atomic_clear_bits(JVM_ACC_NOT_C2_OSR_COMPILABLE);   }
   // Klass* flags
diff a/src/java.base/share/classes/jdk/internal/vm/jni/SubElementSelector.java b/src/java.base/share/classes/jdk/internal/vm/jni/SubElementSelector.java
--- a/src/java.base/share/classes/jdk/internal/vm/jni/SubElementSelector.java
+++ b/src/java.base/share/classes/jdk/internal/vm/jni/SubElementSelector.java
@@ -28,7 +28,7 @@
 public /*inline*/ class SubElementSelector {
     public final Class<?> arrayElementType = null;
     public final Class<?> subElementType = null;
     public final int offset = -1;
     public final boolean isFlattened = false;
-    public final boolean isFlattenable = false;
+    public final boolean isInline = false;
 }
diff a/src/java.base/share/native/include/classfile_constants.h.template b/src/java.base/share/native/include/classfile_constants.h.template
--- a/src/java.base/share/native/include/classfile_constants.h.template
+++ b/src/java.base/share/native/include/classfile_constants.h.template
@@ -47,11 +47,10 @@
     JVM_ACC_VOLATILE      = 0x0040,
     JVM_ACC_BRIDGE        = 0x0040,
     JVM_ACC_TRANSIENT     = 0x0080,
     JVM_ACC_VARARGS       = 0x0080,
     JVM_ACC_VALUE         = 0x0100,
-    JVM_ACC_FLATTENABLE   = 0x0100,
     JVM_ACC_NATIVE        = 0x0100,
     JVM_ACC_INTERFACE     = 0x0200,
     JVM_ACC_ABSTRACT      = 0x0400,
     JVM_ACC_STRICT        = 0x0800,
     JVM_ACC_SYNTHETIC     = 0x1000,
@@ -111,11 +110,11 @@
     JVM_CONSTANT_MethodType             = 16,  // JSR 292
     JVM_CONSTANT_Dynamic                = 17,
     JVM_CONSTANT_InvokeDynamic          = 18,
     JVM_CONSTANT_Module                 = 19,
     JVM_CONSTANT_Package                = 20,
-    JVM_CONSTANT_ExternalMax            = 20 
+    JVM_CONSTANT_ExternalMax            = 20
 };
 
 /* JVM_CONSTANT_MethodHandle subtypes */
 enum {
     JVM_REF_getField                = 1,
diff a/test/hotspot/jtreg/runtime/valhalla/valuetypes/TestJNIArrays.java b/test/hotspot/jtreg/runtime/valhalla/valuetypes/TestJNIArrays.java
--- a/test/hotspot/jtreg/runtime/valhalla/valuetypes/TestJNIArrays.java
+++ b/test/hotspot/jtreg/runtime/valhalla/valuetypes/TestJNIArrays.java
@@ -38,12 +38,12 @@
  * @modules java.base/jdk.internal.misc java.base/jdk.internal.vm.jni
  * @library /testlibrary /test/lib
  * @requires (os.simpleArch == "x64")
  * @requires (os.family == "linux" | os.family == "mac")
  * @compile -XDallowWithFieldOperator TestJNIArrays.java
- * @run main/othervm/native/timeout=3000 -XX:InlineArrayElemMaxFlatSize=128 -XX:+PrintFlattenableLayouts -XX:+UseCompressedOops TestJNIArrays
- * @run main/othervm/native/timeout=3000 -XX:InlineArrayElemMaxFlatSize=128 -XX:+PrintFlattenableLayouts -XX:-UseCompressedOops TestJNIArrays
+ * @run main/othervm/native/timeout=3000 -XX:InlineArrayElemMaxFlatSize=128 -XX:+UseCompressedOops TestJNIArrays
+ * @run main/othervm/native/timeout=3000 -XX:InlineArrayElemMaxFlatSize=128 -XX:-UseCompressedOops TestJNIArrays
  */
 public class TestJNIArrays {
 
     static final Unsafe U = Unsafe.getUnsafe();
 
