diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -1516,17 +1516,17 @@
   STATIC_OOP,           // Oops
   STATIC_BYTE,          // Boolean, Byte, char
   STATIC_SHORT,         // shorts
   STATIC_WORD,          // ints
   STATIC_DOUBLE,        // aligned long or double
-  STATIC_FLATTENABLE,   // flattenable field
+  STATIC_INLINE,        // inline field
   NONSTATIC_OOP,
   NONSTATIC_BYTE,
   NONSTATIC_SHORT,
   NONSTATIC_WORD,
   NONSTATIC_DOUBLE,
-  NONSTATIC_FLATTENABLE,
+  NONSTATIC_INLINE,
   MAX_FIELD_ALLOCATION_TYPE,
   BAD_ALLOCATION_TYPE = -1
 };
 
 static FieldAllocationType _basic_type_to_atype[2 * (T_CONFLICT + 1)] = {
@@ -1572,16 +1572,16 @@
   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
   BAD_ALLOCATION_TYPE, // T_CONFLICT    = 20
 };
 
-static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_flattenable) {
+static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline) {
   assert(type >= T_BOOLEAN && type < T_VOID, "only allowable values");
   FieldAllocationType result = _basic_type_to_atype[type + (is_static ? (T_CONFLICT + 1) : 0)];
   assert(result != BAD_ALLOCATION_TYPE, "bad type");
-  if (is_flattenable) {
-    result = is_static ? STATIC_FLATTENABLE : NONSTATIC_FLATTENABLE;
+  if (is_inline) {
+    result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;
   }
   return result;
 }
 
 class ClassFileParser::FieldAllocationCount : public ResourceObj {
@@ -1592,12 +1592,12 @@
     for (int i = 0; i < MAX_FIELD_ALLOCATION_TYPE; i++) {
       count[i] = 0;
     }
   }
 
-  FieldAllocationType update(bool is_static, BasicType type, bool is_flattenable) {
-    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_flattenable);
+  FieldAllocationType update(bool is_static, BasicType type, bool is_inline) {
+    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline);
     if (atype != BAD_ALLOCATION_TYPE) {
       // Make sure there is no overflow with injected fields.
       assert(count[atype] < 0xFFFF, "More than 65535 fields");
       count[atype]++;
     }
@@ -1689,26 +1689,10 @@
     check_property(valid_symbol_at(signature_index),
       "Invalid constant pool index %u for field signature in class file %s",
       signature_index, CHECK);
     const Symbol* const sig = cp->symbol_at(signature_index);
     verify_legal_field_signature(name, sig, CHECK);
-    assert(!access_flags.is_flattenable(), "ACC_FLATTENABLE should have been filtered out");
-    if (sig->is_Q_signature()) {
-      // assert(_major_version >= CONSTANT_CLASS_DESCRIPTORS, "Q-descriptors are only supported in recent classfiles");
-      access_flags.set_is_flattenable();
-    }
-    if (access_flags.is_flattenable()) {
-      // Array flattenability cannot be specified.  Arrays of value classes are
-      // are always flattenable.  Arrays of other classes are not flattenable.
-      if (sig->utf8_length() > 1 && sig->char_at(0) == '[') {
-        classfile_parse_error(
-            "Field \"%s\" with signature \"%s\" in class file %s is invalid."
-            " ACC_FLATTENABLE cannot be specified for an array",
-            name->as_C_string(), sig->as_klass_external_name(), CHECK);
-      }
-      _has_flattenable_fields = true;
-    }
     if (!access_flags.is_static()) instance_fields_count++;
 
     u2 constantvalue_index = 0;
     bool is_synthetic = false;
     u2 generic_signature_index = 0;
@@ -1765,11 +1749,11 @@
                       signature_index,
                       constantvalue_index);
     const BasicType type = cp->basic_type_for_signature_at(signature_index);
 
     // Remember how many oops we encountered and compute allocation type
-    const FieldAllocationType atype = fac->update(is_static, type, access_flags.is_flattenable());
+    const FieldAllocationType atype = fac->update(is_static, type, type == T_VALUETYPE);
     field->set_allocation_type(atype);
 
     // After field is initialized with type, we can augment it with aux info
     if (parsed_annotations.has_any_annotations()) {
       parsed_annotations.apply_to(field);
@@ -4324,11 +4308,11 @@
 
   // Calculate the starting byte offsets
   int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();
   // Inline types in static fields are not embedded, they are handled with oops
   int next_static_double_offset = next_static_oop_offset +
-                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_FLATTENABLE]) * heapOopSize);
+                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_INLINE]) * heapOopSize);
   if (fac->count[STATIC_DOUBLE]) {
     next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);
   }
 
   int next_static_word_offset   = next_static_double_offset +
@@ -4341,11 +4325,11 @@
   int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +
                                 nonstatic_field_size * heapOopSize;
 
   // First field of inline types is aligned on a long boundary in order to ease
   // in-lining of inline types (with header removal) in packed arrays and
-  // flatten inline types
+  // flattened inline types
   int initial_inline_type_padding = 0;
   if (is_inline_type()) {
     int old = nonstatic_fields_start;
     nonstatic_fields_start = align_up(nonstatic_fields_start, BytesPerLong);
     initial_inline_type_padding = nonstatic_fields_start - old;
@@ -4384,35 +4368,35 @@
   Klass** nonstatic_inline_type_klasses = NULL;
   unsigned int inline_type_oop_map_count = 0;
   int not_flattened_inline_types = 0;
   int not_atomic_inline_types = 0;
 
-  int max_nonstatic_inline_type = fac->count[NONSTATIC_FLATTENABLE] + 1;
+  int max_nonstatic_inline_type = fac->count[NONSTATIC_INLINE] + 1;
 
   nonstatic_inline_type_indexes = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, int,
                                                                max_nonstatic_inline_type);
   for (int i = 0; i < max_nonstatic_inline_type; i++) {
     nonstatic_inline_type_indexes[i] = -1;
   }
   nonstatic_inline_type_klasses = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, Klass*,
                                                                max_nonstatic_inline_type);
 
   for (AllFieldStream fs(_fields, _cp); !fs.done(); fs.next()) {
-    if (fs.allocation_type() == STATIC_FLATTENABLE) {
+    if (fs.allocation_type() == STATIC_INLINE) {
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       static_inline_type_count++;
-    } else if (fs.allocation_type() == NONSTATIC_FLATTENABLE) {
-      // Pre-resolve the flattenable field and check for inline type circularity issues.
+    } else if (fs.allocation_type() == NONSTATIC_INLINE) {
+      // Pre-resolve the inline field and check for inline type circularity issues.
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       Klass* klass =
-        SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+        SystemDictionary::resolve_inline_field_or_fail(&fs,
                                                             Handle(THREAD, _loader_data->class_loader()),
                                                             _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
       if (!klass->access_flags().is_inline_type()) {
         THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
@@ -4452,11 +4436,11 @@
   nonstatic_oop_count += not_flattened_inline_types;
 
   // Total non-static fields count, including every contended field
   unsigned int nonstatic_fields_count = fac->count[NONSTATIC_DOUBLE] + fac->count[NONSTATIC_WORD] +
                                         fac->count[NONSTATIC_SHORT] + fac->count[NONSTATIC_BYTE] +
-                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_FLATTENABLE];
+                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_INLINE];
 
   const bool super_has_nonstatic_fields =
           (_super_klass != NULL && _super_klass->has_nonstatic_fields());
   const bool has_nonstatic_fields =
     super_has_nonstatic_fields || (nonstatic_fields_count != 0);
@@ -4601,11 +4585,11 @@
     const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();
 
     // pack the rest of the fields
     switch (atype) {
       // Inline types in static fields are handled with oops
-      case STATIC_FLATTENABLE:   // Fallthrough
+      case STATIC_INLINE:   // Fallthrough
       case STATIC_OOP:
         real_offset = next_static_oop_offset;
         next_static_oop_offset += heapOopSize;
         break;
       case STATIC_BYTE:
@@ -4622,11 +4606,11 @@
         break;
       case STATIC_DOUBLE:
         real_offset = next_static_double_offset;
         next_static_double_offset += BytesPerLong;
         break;
-      case NONSTATIC_FLATTENABLE:
+      case NONSTATIC_INLINE:
         if (fs.is_flattened()) {
           Klass* klass = nonstatic_inline_type_klasses[next_inline_type_index];
           assert(klass != NULL, "Klass should have been loaded and resolved earlier");
           assert(klass->access_flags().is_inline_type(),"Must be an inline type");
           ValueKlass* vklass = ValueKlass::cast(klass);
@@ -4766,11 +4750,11 @@
             real_offset = next_nonstatic_padded_offset;
             next_nonstatic_padded_offset += BytesPerLong;
             break;
 
             // Inline types in static fields are handled with oops
-          case NONSTATIC_FLATTENABLE:
+          case NONSTATIC_INLINE:
             throwInlineTypeLimitation(THREAD_AND_LOCATION,
                                       "@Contended annotation not supported for inline types yet", fs.name(), fs.signature());
             return;
 
           case NONSTATIC_OOP:
@@ -4880,10 +4864,11 @@
   info->oop_map_blocks = nonstatic_oop_maps;
   info->_instance_size = instance_size;
   info->_static_field_size = static_field_size;
   info->_nonstatic_field_size = nonstatic_field_size;
   info->_has_nonstatic_fields = has_nonstatic_fields;
+  info->_has_inline_fields = nonstatic_inline_type_count > 0;
 
   // An inline type is naturally atomic if it has just one field, and
   // that field is simple enough.
   info->_is_naturally_atomic = (is_inline_type() &&
                                 !super_has_nonstatic_fields &&
@@ -6162,11 +6147,11 @@
   if (_has_injected_identityObject) {
     ik->set_has_injected_identityObject();
   }
 
   assert(_fac != NULL, "invariant");
-  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_FLATTENABLE]);
+  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_INLINE]);
 
   // this transfers ownership of a lot of arrays from
   // the parser onto the InstanceKlass*
   apply_parsed_class_metadata(ik, _java_fields_count, CHECK);
 
@@ -6327,11 +6312,11 @@
   }
 
   int nfields = ik->java_fields_count();
   if (ik->is_value()) nfields++;
   for (int i = 0; i < nfields; i++) {
-    if (ik->field_is_flattenable(i)) {
+    if (ik->field_is_inline(i)) {
       Symbol* klass_name = ik->field_signature(i)->fundamental_name(CHECK);
       // Inline classes for instance fields must have been pre-loaded
       // Inline classes for static fields might not have been loaded yet
       Klass* klass = SystemDictionary::find(klass_name,
           Handle(THREAD, ik->class_loader()),
@@ -6552,11 +6537,11 @@
   _relax_verify(false),
   _has_nonstatic_concrete_methods(false),
   _declares_nonstatic_concrete_methods(false),
   _has_final_method(false),
   _has_contended_fields(false),
-  _has_flattenable_fields(false),
+  _has_inline_fields(false),
   _has_nonstatic_fields(false),
   _is_empty_inline_type(false),
   _is_naturally_atomic(false),
   _is_declared_atomic(false),
   _invalid_inline_super(false),
@@ -7173,18 +7158,17 @@
   assert(_fac != NULL, "invariant");
   assert(_parsed_annotations != NULL, "invariant");
 
 
   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
-    if (fs.is_flattenable() && !fs.access_flags().is_static()) {
+    if (Signature::basic_type(fs.signature()) == T_VALUETYPE  && !fs.access_flags().is_static()) {
       // Pre-load value class
-      Klass* klass = SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+      Klass* klass = SystemDictionary::resolve_inline_field_or_fail(&fs,
           Handle(THREAD, _loader_data->class_loader()),
           _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
-      assert(klass->access_flags().is_inline_type(), "Inline type expected");
-      _has_flattenable_fields = true;
+      assert(klass->access_flags().is_inline_type(), "Value type expected");
     }
   }
 
   _field_info = new FieldLayoutInfo();
   if (UseNewFieldLayout) {
@@ -7198,10 +7182,11 @@
       _exact_size_in_bytes = lb.get_exact_size_in_byte();
     }
   } else {
     layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);
   }
+  _has_inline_fields = _field_info->_has_inline_fields;
 
   // Compute reference type
   _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass->reference_type();
 }
 
