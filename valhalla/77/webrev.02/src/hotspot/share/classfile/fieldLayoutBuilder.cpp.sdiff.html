<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/classfile/fieldLayoutBuilder.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="classFileParser.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="fieldLayoutBuilder.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/classfile/fieldLayoutBuilder.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 43   _alignment(1),
 44   _size(size),
 45   _field_index(-1),
 46   _is_reference(false) {
 47   assert(kind == EMPTY || kind == RESERVED || kind == PADDING || kind == INHERITED,
 48          &quot;Otherwise, should use the constructor with a field index argument&quot;);
 49   assert(size &gt; 0, &quot;Sanity check&quot;);
 50 }
 51 
 52 
 53 LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference) :
 54  _next_block(NULL),
 55  _prev_block(NULL),
 56  _value_klass(NULL),
 57  _kind(kind),
 58  _offset(-1),
 59  _alignment(alignment),
 60  _size(size),
 61  _field_index(index),
 62  _is_reference(is_reference) {
<span class="line-modified"> 63   assert(kind == REGULAR || kind == FLATTENED || kind == INHERITED,</span>
 64          &quot;Other kind do not have a field index&quot;);
 65   assert(size &gt; 0, &quot;Sanity check&quot;);
 66   assert(alignment &gt; 0, &quot;Sanity check&quot;);
 67 }
 68 
 69 bool LayoutRawBlock::fit(int size, int alignment) {
 70   int adjustment = 0;
 71   if ((_offset % alignment) != 0) {
 72     adjustment = alignment - (_offset % alignment);
 73   }
 74   return _size &gt;= size + adjustment;
 75 }
 76 
 77 FieldGroup::FieldGroup(int contended_group) :
 78   _next(NULL),
 79   _primitive_fields(NULL),
 80   _oop_fields(NULL),
<span class="line-modified"> 81   _flattened_fields(NULL),</span>
 82   _contended_group(contended_group),  // -1 means no contended group, 0 means default contended group
 83   _oop_count(0) {}
 84 
 85 void FieldGroup::add_primitive_field(AllFieldStream fs, BasicType type) {
 86   int size = type2aelembytes(type);
 87   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for primitive types */, false);
 88   if (_primitive_fields == NULL) {
 89     _primitive_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 90   }
 91   _primitive_fields-&gt;append(block);
 92 }
 93 
 94 void FieldGroup::add_oop_field(AllFieldStream fs) {
 95   int size = type2aelembytes(T_OBJECT);
 96   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for oops */, true);
 97   if (_oop_fields == NULL) {
 98     _oop_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 99   }
100   _oop_fields-&gt;append(block);
101   _oop_count++;
102 }
103 
<span class="line-modified">104 void FieldGroup::add_flattened_field(AllFieldStream fs, ValueKlass* vk) {</span>
<span class="line-modified">105   // _flattened_fields list might be merged with the _primitive_fields list in the future</span>
<span class="line-modified">106   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::FLATTENED, vk-&gt;get_exact_size_in_bytes(), vk-&gt;get_alignment(), false);</span>
107   block-&gt;set_value_klass(vk);
<span class="line-modified">108   if (_flattened_fields == NULL) {</span>
<span class="line-modified">109     _flattened_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);</span>
110   }
<span class="line-modified">111   _flattened_fields-&gt;append(block);</span>
112 }
113 
114 void FieldGroup::sort_by_size() {
115   if (_primitive_fields != NULL) {
116     _primitive_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
117   }
<span class="line-modified">118   if (_flattened_fields != NULL) {</span>
<span class="line-modified">119     _flattened_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);</span>
120   }
121 }
122 
123 FieldLayout::FieldLayout(Array&lt;u2&gt;* fields, ConstantPool* cp) :
124   _fields(fields),
125   _cp(cp),
126   _blocks(NULL),
127   _start(_blocks),
128   _last(_blocks) {}
129 
130 void FieldLayout::initialize_static_layout() {
131   _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
132   _blocks-&gt;set_offset(0);
133   _last = _blocks;
134   _start = _blocks;
135   // Note: at this stage, InstanceMirrorKlass::offset_of_static_fields() could be zero, because
136   // during bootstrapping, the size of the java.lang.Class is still not known when layout
137   // of static field is computed. Field offsets are fixed later when the size is known
138   // (see java_lang_Class::fixup_mirror())
139   if (InstanceMirrorKlass::offset_of_static_fields() &gt; 0) {
</pre>
<hr />
<pre>
149     _last = _blocks;
150     _start = _blocks;
151     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes()));
152   } else {
153     bool has_fields = reconstruct_layout(super_klass);
154     fill_holes(super_klass);
155     if ((UseEmptySlotsInSupers &amp;&amp; !super_klass-&gt;has_contended_annotations()) || !has_fields) {
156       _start = _blocks; // Setting _start to _blocks instead of _last would allow subclasses
157       // to allocate fields in empty slots of their super classes
158     } else {
159       _start = _last;    // append fields at the end of the reconstructed layout
160     }
161   }
162 }
163 
164 LayoutRawBlock* FieldLayout::first_field_block() {
165   LayoutRawBlock* block = _blocks;
166   while (block != NULL
167          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INHERITED
168          &amp;&amp; block-&gt;kind() != LayoutRawBlock::REGULAR
<span class="line-modified">169          &amp;&amp; block-&gt;kind() != LayoutRawBlock::FLATTENED) {</span>
170     block = block-&gt;next_block();
171   }
172   return block;
173 }
174 
175 // Insert a set of fields into a layout.
176 // For each field, search for an empty slot able to fit the field
177 // (satisfying both size and alignment requirements), if none is found,
178 // add the field at the end of the layout.
179 // Fields cannot be inserted before the block specified in the &quot;start&quot; argument
180 void FieldLayout::add(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
181   if (list == NULL) return;
182   if (start == NULL) start = this-&gt;_start;
183   bool last_search_success = false;
184   int last_size = 0;
185   int last_alignment = 0;
186   for (int i = 0; i &lt; list-&gt;length(); i ++) {
187     LayoutRawBlock* b = list-&gt;at(i);
188     LayoutRawBlock* cursor = NULL;
189     LayoutRawBlock* candidate = NULL;
</pre>
<hr />
<pre>
442     _start = block-&gt;prev_block();
443   }
444 }
445 
446 void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super) {
447   ResourceMark rm;
448   LayoutRawBlock* b = _blocks;
449   while(b != _last) {
450     switch(b-&gt;kind()) {
451     case LayoutRawBlock::REGULAR: {
452       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
453       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
454                        b-&gt;offset(),
455                        fi-&gt;name(_cp)-&gt;as_C_string(),
456                        fi-&gt;signature(_cp)-&gt;as_C_string(),
457                        b-&gt;size(),
458                        b-&gt;alignment(),
459                        &quot;REGULAR&quot;);
460       break;
461     }
<span class="line-modified">462     case LayoutRawBlock::FLATTENED: {</span>
463       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
464       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
465                        b-&gt;offset(),
466                        fi-&gt;name(_cp)-&gt;as_C_string(),
467                        fi-&gt;signature(_cp)-&gt;as_C_string(),
468                        b-&gt;size(),
469                        b-&gt;alignment(),
<span class="line-modified">470                        &quot;FLATTENED&quot;);</span>
471       break;
472     }
473     case LayoutRawBlock::RESERVED: {
474       output-&gt;print_cr(&quot; @%d %d/- %s&quot;,
475                        b-&gt;offset(),
476                        b-&gt;size(),
477                        &quot;RESERVED&quot;);
478       break;
479     }
480     case LayoutRawBlock::INHERITED: {
481       assert(!is_static, &quot;Static fields are not inherited in layouts&quot;);
482       assert(super != NULL, &quot;super klass must be provided to retrieve inherited fields info&quot;);
483       bool found = false;
484       const InstanceKlass* ik = super;
485       while (!found &amp;&amp; ik != NULL) {
486         for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
487           if (fs.offset() == b-&gt;offset()) {
488             output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
489                 b-&gt;offset(),
490                 fs.name()-&gt;as_C_string(),
</pre>
<hr />
<pre>
520 FieldLayoutBuilder::FieldLayoutBuilder(const Symbol* classname, const InstanceKlass* super_klass, ConstantPool* constant_pool,
521                                        Array&lt;u2&gt;* fields, bool is_contended, bool is_inline_type, ClassLoaderData* class_loader_data,
522                                        Handle protection_domain, FieldLayoutInfo* info) :
523   _classname(classname),
524   _super_klass(super_klass),
525   _constant_pool(constant_pool),
526   _fields(fields),
527   _info(info),
528   _root_group(NULL),
529   _contended_groups(GrowableArray&lt;FieldGroup*&gt;(8)),
530   _static_fields(NULL),
531   _layout(NULL),
532   _static_layout(NULL),
533   _class_loader_data(class_loader_data),
534   _protection_domain(protection_domain),
535   _nonstatic_oopmap_count(0),
536   _alignment(-1),
537   _first_field_offset(-1),
538   _exact_size_in_bytes(-1),
539   _has_nonstatic_fields(false),

540   _is_contended(is_contended),
541   _is_inline_type(is_inline_type),
542   _has_flattening_information(is_inline_type),
543   _has_nonatomic_values(false),
544   _atomic_field_count(0)
545  {}
546 
547 FieldGroup* FieldLayoutBuilder::get_or_create_contended_group(int g) {
548   assert(g &gt; 0, &quot;must only be called for named contended groups&quot;);
549   FieldGroup* fg = NULL;
550   for (int i = 0; i &lt; _contended_groups.length(); i++) {
551     fg = _contended_groups.at(i);
552     if (fg-&gt;contended_group() == g) return fg;
553   }
554   fg = new FieldGroup(g);
555   _contended_groups.append(fg);
556   return fg;
557 }
558 
559 void FieldLayoutBuilder::prologue() {
</pre>
<hr />
<pre>
597     }
598     assert(group != NULL, &quot;invariant&quot;);
599     BasicType type = Signature::basic_type(fs.signature());
600     switch(type) {
601     case T_BYTE:
602     case T_CHAR:
603     case T_DOUBLE:
604     case T_FLOAT:
605     case T_INT:
606     case T_LONG:
607     case T_SHORT:
608     case T_BOOLEAN:
609       group-&gt;add_primitive_field(fs, type);
610       break;
611     case T_OBJECT:
612     case T_ARRAY:
613       if (group != _static_fields) _nonstatic_oopmap_count++;
614       group-&gt;add_oop_field(fs);
615       break;
616     case T_VALUETYPE:


617       if (group == _static_fields) {
<span class="line-modified">618         // static fields are never flattened</span>
619         group-&gt;add_oop_field(fs);
620       } else {
621         _has_flattening_information = true;
622         // Flattening decision to be taken here
<span class="line-modified">623         // This code assumes all verification have been performed before</span>
<span class="line-modified">624         // (field is a flattenable field, field&#39;s type has been loaded</span>
<span class="line-removed">625         // and it is an inline klass</span>
626         Thread* THREAD = Thread::current();
627         Klass* klass =
<span class="line-modified">628             SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,</span>
629                                                                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
630                                                                 _protection_domain, true, THREAD);
631         assert(klass != NULL, &quot;Sanity check&quot;);
632         ValueKlass* vk = ValueKlass::cast(klass);
633         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
634                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
635         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
636         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
637         if (vk-&gt;is_naturally_atomic()) {
638           too_atomic_to_flatten = false;
639           //too_volatile_to_flatten = false; //FIXME
<span class="line-modified">640           // volatile fields are currently never flattened, this could change in the future</span>
641         }
642         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
<span class="line-modified">643           group-&gt;add_flattened_field(fs, vk);</span>
644           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
<span class="line-modified">645           fs.set_flattened(true);</span>
646           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
647             _has_nonatomic_values = true;
648             _atomic_field_count--;  // every other field is atomic but this one
649           }
650         } else {
651           _nonstatic_oopmap_count++;
652           group-&gt;add_oop_field(fs);
653         }
654       }
655       break;
656     default:
657       fatal(&quot;Something wrong?&quot;);
658     }
659   }
660   _root_group-&gt;sort_by_size();
661   _static_fields-&gt;sort_by_size();
662   if (!_contended_groups.is_empty()) {
663     for (int i = 0; i &lt; _contended_groups.length(); i++) {
664       _contended_groups.at(i)-&gt;sort_by_size();
665     }
666   }
667 }
668 
669 /* Field sorting for inline classes:
670  *   - because inline classes are immutable, the @Contended annotation is ignored
671  *     when computing their layout (with only read operation, there&#39;s no false
672  *     sharing issue)
673  *   - this method also records the alignment of the field with the most
674  *     constraining alignment, this value is then used as the alignment
675  *     constraint when flattening this inline type into another container
676  *   - field flattening decisions are taken in this method (those decisions are
<span class="line-modified">677  *     currently only based in the size of the fields to be flattened, the size</span>
678  *     of the resulting instance is not considered)
679  */
680 void FieldLayoutBuilder::inline_class_field_sorting(TRAPS) {
681   assert(_is_inline_type, &quot;Should only be used for inline classes&quot;);
682   int alignment = 1;
683   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
684     FieldGroup* group = NULL;
685     int field_alignment = 1;
686     if (fs.access_flags().is_static()) {
687       group = _static_fields;
688     } else {
689       _has_nonstatic_fields = true;
690       _atomic_field_count++;  // we might decrement this
691       group = _root_group;
692     }
693     assert(group != NULL, &quot;invariant&quot;);
694     BasicType type = Signature::basic_type(fs.signature());
695     switch(type) {
696     case T_BYTE:
697     case T_CHAR:
698     case T_DOUBLE:
699     case T_FLOAT:
700     case T_INT:
701     case T_LONG:
702     case T_SHORT:
703     case T_BOOLEAN:
704       if (group != _static_fields) {
705         field_alignment = type2aelembytes(type); // alignment == size for primitive types
706       }
707       group-&gt;add_primitive_field(fs, type);
708       break;
709     case T_OBJECT:
710     case T_ARRAY:
711       if (group != _static_fields) {
712         _nonstatic_oopmap_count++;
713         field_alignment = type2aelembytes(type); // alignment == size for oops
714       }
715       group-&gt;add_oop_field(fs);
716       break;
717     case T_VALUETYPE: {


718       if (group == _static_fields) {
<span class="line-modified">719         // static fields are never flattened</span>
720         group-&gt;add_oop_field(fs);
721       } else {
722         // Flattening decision to be taken here
<span class="line-modified">723         // This code assumes all verifications have been performed before</span>
<span class="line-modified">724         // (field is a flattenable field, field&#39;s type has been loaded</span>
<span class="line-removed">725         // and it is an inline klass</span>
726         Thread* THREAD = Thread::current();
727         Klass* klass =
<span class="line-modified">728             SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,</span>
729                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
730                 _protection_domain, true, CHECK);
731         assert(klass != NULL, &quot;Sanity check&quot;);
732         ValueKlass* vk = ValueKlass::cast(klass);
733         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
734                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
735         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
736         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
737         if (vk-&gt;is_naturally_atomic()) {
738           too_atomic_to_flatten = false;
739           //too_volatile_to_flatten = false; //FIXME
<span class="line-modified">740           // volatile fields are currently never flattened, this could change in the future</span>
741         }
742         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
<span class="line-modified">743           group-&gt;add_flattened_field(fs, vk);</span>
744           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
745           field_alignment = vk-&gt;get_alignment();
<span class="line-modified">746           fs.set_flattened(true);</span>
747           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
748             _has_nonatomic_values = true;
749             _atomic_field_count--;  // every other field is atomic but this one
750           }
751         } else {
752           _nonstatic_oopmap_count++;
753           field_alignment = type2aelembytes(T_OBJECT);
754           group-&gt;add_oop_field(fs);
755         }
756       }
757       break;
758     }
759     default:
760       fatal(&quot;Unexpected BasicType&quot;);
761     }
762     if (!fs.access_flags().is_static() &amp;&amp; field_alignment &gt; alignment) alignment = field_alignment;
763   }
764   _alignment = alignment;
765   if (!_has_nonstatic_fields) {
766     // There are a number of fixes required throughout the type system and JIT
767     Exceptions::fthrow(THREAD_AND_LOCATION,
768                        vmSymbols::java_lang_ClassFormatError(),
769                        &quot;Value Types do not support zero instance size yet&quot;);
770     return;
771   }
772 }
773 
774 void FieldLayoutBuilder::insert_contended_padding(LayoutRawBlock* slot) {
775   if (ContendedPaddingWidth &gt; 0) {
776     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
777     _layout-&gt;insert(slot, padding);
778   }
779 }
780 
781 /* Computation of regular classes layout is an evolution of the previous default layout
782  * (FieldAllocationStyle 1):
<span class="line-modified">783  *   - flattened fields are allocated first (because they have potentially the</span>
784  *     least regular shapes, and are more likely to create empty slots between them,
785  *     which can then be used to allocation primitive or oop fields). Allocation is
<span class="line-modified">786  *     performed from the biggest to the smallest flattened field.</span>
787  *   - then primitive fields (from the biggest to the smallest)
788  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
789  *     and reduce the work of the GC).
790  */
791 void FieldLayoutBuilder::compute_regular_layout() {
792   bool need_tail_padding = false;
793   prologue();
794   regular_field_sorting();
795   if (_is_contended) {
796     _layout-&gt;set_start(_layout-&gt;last_block());
797     // insertion is currently easy because the current strategy doesn&#39;t try to fill holes
798     // in super classes layouts =&gt; the _start block is by consequence the _last_block
799     insert_contended_padding(_layout-&gt;start());
800     need_tail_padding = true;
801   }
<span class="line-modified">802   _layout-&gt;add(_root_group-&gt;flattened_fields());</span>
803   _layout-&gt;add(_root_group-&gt;primitive_fields());
804   _layout-&gt;add(_root_group-&gt;oop_fields());
805 
806   if (!_contended_groups.is_empty()) {
807     for (int i = 0; i &lt; _contended_groups.length(); i++) {
808       FieldGroup* cg = _contended_groups.at(i);
809       LayoutRawBlock* start = _layout-&gt;last_block();
810       insert_contended_padding(start);
<span class="line-modified">811       _layout-&gt;add(_root_group-&gt;flattened_fields());</span>
812       _layout-&gt;add(cg-&gt;primitive_fields(), start);
813       _layout-&gt;add(cg-&gt;oop_fields(), start);
814       need_tail_padding = true;
815     }
816   }
817 
818   if (need_tail_padding) {
819     insert_contended_padding(_layout-&gt;last_block());
820   }
<span class="line-modified">821   _static_layout-&gt;add(_static_fields-&gt;flattened_fields());</span>
822   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
823   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
824 
825   epilogue();
826 }
827 
828 /* Computation of inline classes has a slightly different strategy than for
829  * regular classes. Regular classes have their oop fields allocated at the end
830  * of the layout to increase GC performances. Unfortunately, this strategy
831  * increases the number of empty slots inside an instance. Because the purpose
832  * of inline classes is to be embedded into other containers, it is critical
833  * to keep their size as small as possible. For this reason, the allocation
834  * strategy is:
<span class="line-modified">835  *   - flattened fields are allocated first (because they have potentially the</span>
836  *     least regular shapes, and are more likely to create empty slots between them,
837  *     which can then be used to allocation primitive or oop fields). Allocation is
<span class="line-modified">838  *     performed from the biggest to the smallest flattened field.</span>
839  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
840  *     and reduce the work of the GC)
841  *   - then primitive fields (from the biggest to the smallest)
842  */
843 void FieldLayoutBuilder::compute_inline_class_layout(TRAPS) {
844   prologue();
845   inline_class_field_sorting(CHECK);
846   // Inline types are not polymorphic, so they cannot inherit fields.
847   // By consequence, at this stage, the layout must be composed of a RESERVED
848   // block, followed by an EMPTY block.
849   assert(_layout-&gt;start()-&gt;kind() == LayoutRawBlock::RESERVED, &quot;Unexpected&quot;);
850   assert(_layout-&gt;start()-&gt;next_block()-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Unexpected&quot;);
851   LayoutRawBlock* first_empty = _layout-&gt;start()-&gt;next_block();
852   if (first_empty-&gt;offset() % _alignment != 0) {
853     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _alignment - (first_empty-&gt;offset() % _alignment));
854     _layout-&gt;insert(first_empty, padding);
855     _layout-&gt;set_start(padding-&gt;next_block());
856   }
857 
<span class="line-modified">858   _layout-&gt;add(_root_group-&gt;flattened_fields());</span>
859   _layout-&gt;add(_root_group-&gt;oop_fields());
860   _layout-&gt;add(_root_group-&gt;primitive_fields());
861 
862   LayoutRawBlock* first_field = _layout-&gt;first_field_block();
863    if (first_field != NULL) {
864      _first_field_offset = _layout-&gt;first_field_block()-&gt;offset();
865      _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
866    } else {
867      // special case for empty value types
868      _first_field_offset = _layout-&gt;blocks()-&gt;size();
869      _exact_size_in_bytes = 0;
870    }
871   _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
872 
<span class="line-modified">873   _static_layout-&gt;add(_static_fields-&gt;flattened_fields());</span>
874   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
875   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
876 
877 
878   epilogue();
879 }
880 
<span class="line-modified">881 void FieldLayoutBuilder::add_flattened_field_oopmap(OopMapBlocksBuilder* nonstatic_oop_maps,</span>
882                 ValueKlass* vklass, int offset) {
883   int diff = offset - vklass-&gt;first_field_offset();
884   const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
885   const OopMapBlock* last_map = map + vklass-&gt;nonstatic_oop_map_count();
886   while (map &lt; last_map) {
887     nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
888     map++;
889   }
890 }
891 
892 void FieldLayoutBuilder::epilogue() {
893   // Computing oopmaps
894   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
895   int max_oop_map_count = super_oop_map_count + _nonstatic_oopmap_count;
896 
897   OopMapBlocksBuilder* nonstatic_oop_maps =
898       new OopMapBlocksBuilder(max_oop_map_count);
899   if (super_oop_map_count &gt; 0) {
900     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
901     _super_klass-&gt;nonstatic_oop_map_count());
902   }
903 
904   if (_root_group-&gt;oop_fields() != NULL) {
905     for (int i = 0; i &lt; _root_group-&gt;oop_fields()-&gt;length(); i++) {
906       LayoutRawBlock* b = _root_group-&gt;oop_fields()-&gt;at(i);
907       nonstatic_oop_maps-&gt;add(b-&gt;offset(), 1);
908     }
909   }
910 
<span class="line-modified">911   GrowableArray&lt;LayoutRawBlock*&gt;* ff = _root_group-&gt;flattened_fields();</span>
912   if (ff != NULL) {
913     for (int i = 0; i &lt; ff-&gt;length(); i++) {
914       LayoutRawBlock* f = ff-&gt;at(i);
915       ValueKlass* vk = f-&gt;value_klass();
916       assert(vk != NULL, &quot;Should have been initialized&quot;);
917       if (vk-&gt;contains_oops()) {
<span class="line-modified">918         add_flattened_field_oopmap(nonstatic_oop_maps, vk, f-&gt;offset());</span>
919       }
920     }
921   }
922 
923   if (!_contended_groups.is_empty()) {
924     for (int i = 0; i &lt; _contended_groups.length(); i++) {
925       FieldGroup* cg = _contended_groups.at(i);
926       if (cg-&gt;oop_count() &gt; 0) {
927         assert(cg-&gt;oop_fields() != NULL &amp;&amp; cg-&gt;oop_fields()-&gt;at(0) != NULL, &quot;oop_count &gt; 0 but no oop fields found&quot;);
928         nonstatic_oop_maps-&gt;add(cg-&gt;oop_fields()-&gt;at(0)-&gt;offset(), cg-&gt;oop_count());
929       }
930     }
931   }
932 
933   nonstatic_oop_maps-&gt;compact();
934 
935   int instance_end = align_up(_layout-&gt;last_block()-&gt;offset(), wordSize);
936   int static_fields_end = align_up(_static_layout-&gt;last_block()-&gt;offset(), wordSize);
937   int static_fields_size = (static_fields_end -
938       InstanceMirrorKlass::offset_of_static_fields()) / wordSize;
939   int nonstatic_field_end = align_up(_layout-&gt;last_block()-&gt;offset(), heapOopSize);
940 
941   // Pass back information needed for InstanceKlass creation
942 
943   _info-&gt;oop_map_blocks = nonstatic_oop_maps;
944   _info-&gt;_instance_size = align_object_size(instance_end / wordSize);
945   _info-&gt;_static_field_size = static_fields_size;
946   _info-&gt;_nonstatic_field_size = (nonstatic_field_end - instanceOopDesc::base_offset_in_bytes()) / heapOopSize;
947   _info-&gt;_has_nonstatic_fields = _has_nonstatic_fields;

948 
949   // An inline type is naturally atomic if it has just one field, and
950   // that field is simple enough.
951   _info-&gt;_is_naturally_atomic = (_is_inline_type &amp;&amp;
952                                  (_atomic_field_count &lt;= 1) &amp;&amp;
953                                  !_has_nonatomic_values &amp;&amp;
954                                  _contended_groups.is_empty());
955   // This may be too restrictive, since if all the fields fit in 64
956   // bits we could make the decision to align instances of this class
957   // to 64-bit boundaries, and load and store them as single words.
958   // And on machines which supported larger atomics we could similarly
959   // allow larger values to be atomic, if properly aligned.
960 
961 
962   if (PrintFieldLayout) {
963     ResourceMark rm;
964     tty-&gt;print_cr(&quot;Layout of class %s&quot;, _classname-&gt;as_C_string());
965     tty-&gt;print_cr(&quot;Instance fields:&quot;);
966     _layout-&gt;print(tty, false, _super_klass);
967     tty-&gt;print_cr(&quot;Static fields:&quot;);
</pre>
</td>
<td>
<hr />
<pre>
 43   _alignment(1),
 44   _size(size),
 45   _field_index(-1),
 46   _is_reference(false) {
 47   assert(kind == EMPTY || kind == RESERVED || kind == PADDING || kind == INHERITED,
 48          &quot;Otherwise, should use the constructor with a field index argument&quot;);
 49   assert(size &gt; 0, &quot;Sanity check&quot;);
 50 }
 51 
 52 
 53 LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference) :
 54  _next_block(NULL),
 55  _prev_block(NULL),
 56  _value_klass(NULL),
 57  _kind(kind),
 58  _offset(-1),
 59  _alignment(alignment),
 60  _size(size),
 61  _field_index(index),
 62  _is_reference(is_reference) {
<span class="line-modified"> 63   assert(kind == REGULAR || kind == INLINED || kind == INHERITED,</span>
 64          &quot;Other kind do not have a field index&quot;);
 65   assert(size &gt; 0, &quot;Sanity check&quot;);
 66   assert(alignment &gt; 0, &quot;Sanity check&quot;);
 67 }
 68 
 69 bool LayoutRawBlock::fit(int size, int alignment) {
 70   int adjustment = 0;
 71   if ((_offset % alignment) != 0) {
 72     adjustment = alignment - (_offset % alignment);
 73   }
 74   return _size &gt;= size + adjustment;
 75 }
 76 
 77 FieldGroup::FieldGroup(int contended_group) :
 78   _next(NULL),
 79   _primitive_fields(NULL),
 80   _oop_fields(NULL),
<span class="line-modified"> 81   _inlined_fields(NULL),</span>
 82   _contended_group(contended_group),  // -1 means no contended group, 0 means default contended group
 83   _oop_count(0) {}
 84 
 85 void FieldGroup::add_primitive_field(AllFieldStream fs, BasicType type) {
 86   int size = type2aelembytes(type);
 87   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for primitive types */, false);
 88   if (_primitive_fields == NULL) {
 89     _primitive_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 90   }
 91   _primitive_fields-&gt;append(block);
 92 }
 93 
 94 void FieldGroup::add_oop_field(AllFieldStream fs) {
 95   int size = type2aelembytes(T_OBJECT);
 96   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for oops */, true);
 97   if (_oop_fields == NULL) {
 98     _oop_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 99   }
100   _oop_fields-&gt;append(block);
101   _oop_count++;
102 }
103 
<span class="line-modified">104 void FieldGroup::add_inlined_field(AllFieldStream fs, ValueKlass* vk) {</span>
<span class="line-modified">105   // _inlined_fields list might be merged with the _primitive_fields list in the future</span>
<span class="line-modified">106   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INLINED, vk-&gt;get_exact_size_in_bytes(), vk-&gt;get_alignment(), false);</span>
107   block-&gt;set_value_klass(vk);
<span class="line-modified">108   if (_inlined_fields == NULL) {</span>
<span class="line-modified">109     _inlined_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);</span>
110   }
<span class="line-modified">111   _inlined_fields-&gt;append(block);</span>
112 }
113 
114 void FieldGroup::sort_by_size() {
115   if (_primitive_fields != NULL) {
116     _primitive_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
117   }
<span class="line-modified">118   if (_inlined_fields != NULL) {</span>
<span class="line-modified">119     _inlined_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);</span>
120   }
121 }
122 
123 FieldLayout::FieldLayout(Array&lt;u2&gt;* fields, ConstantPool* cp) :
124   _fields(fields),
125   _cp(cp),
126   _blocks(NULL),
127   _start(_blocks),
128   _last(_blocks) {}
129 
130 void FieldLayout::initialize_static_layout() {
131   _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
132   _blocks-&gt;set_offset(0);
133   _last = _blocks;
134   _start = _blocks;
135   // Note: at this stage, InstanceMirrorKlass::offset_of_static_fields() could be zero, because
136   // during bootstrapping, the size of the java.lang.Class is still not known when layout
137   // of static field is computed. Field offsets are fixed later when the size is known
138   // (see java_lang_Class::fixup_mirror())
139   if (InstanceMirrorKlass::offset_of_static_fields() &gt; 0) {
</pre>
<hr />
<pre>
149     _last = _blocks;
150     _start = _blocks;
151     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes()));
152   } else {
153     bool has_fields = reconstruct_layout(super_klass);
154     fill_holes(super_klass);
155     if ((UseEmptySlotsInSupers &amp;&amp; !super_klass-&gt;has_contended_annotations()) || !has_fields) {
156       _start = _blocks; // Setting _start to _blocks instead of _last would allow subclasses
157       // to allocate fields in empty slots of their super classes
158     } else {
159       _start = _last;    // append fields at the end of the reconstructed layout
160     }
161   }
162 }
163 
164 LayoutRawBlock* FieldLayout::first_field_block() {
165   LayoutRawBlock* block = _blocks;
166   while (block != NULL
167          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INHERITED
168          &amp;&amp; block-&gt;kind() != LayoutRawBlock::REGULAR
<span class="line-modified">169          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INLINED) {</span>
170     block = block-&gt;next_block();
171   }
172   return block;
173 }
174 
175 // Insert a set of fields into a layout.
176 // For each field, search for an empty slot able to fit the field
177 // (satisfying both size and alignment requirements), if none is found,
178 // add the field at the end of the layout.
179 // Fields cannot be inserted before the block specified in the &quot;start&quot; argument
180 void FieldLayout::add(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
181   if (list == NULL) return;
182   if (start == NULL) start = this-&gt;_start;
183   bool last_search_success = false;
184   int last_size = 0;
185   int last_alignment = 0;
186   for (int i = 0; i &lt; list-&gt;length(); i ++) {
187     LayoutRawBlock* b = list-&gt;at(i);
188     LayoutRawBlock* cursor = NULL;
189     LayoutRawBlock* candidate = NULL;
</pre>
<hr />
<pre>
442     _start = block-&gt;prev_block();
443   }
444 }
445 
446 void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super) {
447   ResourceMark rm;
448   LayoutRawBlock* b = _blocks;
449   while(b != _last) {
450     switch(b-&gt;kind()) {
451     case LayoutRawBlock::REGULAR: {
452       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
453       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
454                        b-&gt;offset(),
455                        fi-&gt;name(_cp)-&gt;as_C_string(),
456                        fi-&gt;signature(_cp)-&gt;as_C_string(),
457                        b-&gt;size(),
458                        b-&gt;alignment(),
459                        &quot;REGULAR&quot;);
460       break;
461     }
<span class="line-modified">462     case LayoutRawBlock::INLINED: {</span>
463       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
464       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
465                        b-&gt;offset(),
466                        fi-&gt;name(_cp)-&gt;as_C_string(),
467                        fi-&gt;signature(_cp)-&gt;as_C_string(),
468                        b-&gt;size(),
469                        b-&gt;alignment(),
<span class="line-modified">470                        &quot;INLINED&quot;);</span>
471       break;
472     }
473     case LayoutRawBlock::RESERVED: {
474       output-&gt;print_cr(&quot; @%d %d/- %s&quot;,
475                        b-&gt;offset(),
476                        b-&gt;size(),
477                        &quot;RESERVED&quot;);
478       break;
479     }
480     case LayoutRawBlock::INHERITED: {
481       assert(!is_static, &quot;Static fields are not inherited in layouts&quot;);
482       assert(super != NULL, &quot;super klass must be provided to retrieve inherited fields info&quot;);
483       bool found = false;
484       const InstanceKlass* ik = super;
485       while (!found &amp;&amp; ik != NULL) {
486         for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
487           if (fs.offset() == b-&gt;offset()) {
488             output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
489                 b-&gt;offset(),
490                 fs.name()-&gt;as_C_string(),
</pre>
<hr />
<pre>
520 FieldLayoutBuilder::FieldLayoutBuilder(const Symbol* classname, const InstanceKlass* super_klass, ConstantPool* constant_pool,
521                                        Array&lt;u2&gt;* fields, bool is_contended, bool is_inline_type, ClassLoaderData* class_loader_data,
522                                        Handle protection_domain, FieldLayoutInfo* info) :
523   _classname(classname),
524   _super_klass(super_klass),
525   _constant_pool(constant_pool),
526   _fields(fields),
527   _info(info),
528   _root_group(NULL),
529   _contended_groups(GrowableArray&lt;FieldGroup*&gt;(8)),
530   _static_fields(NULL),
531   _layout(NULL),
532   _static_layout(NULL),
533   _class_loader_data(class_loader_data),
534   _protection_domain(protection_domain),
535   _nonstatic_oopmap_count(0),
536   _alignment(-1),
537   _first_field_offset(-1),
538   _exact_size_in_bytes(-1),
539   _has_nonstatic_fields(false),
<span class="line-added">540   _has_inline_type_fields(false),</span>
541   _is_contended(is_contended),
542   _is_inline_type(is_inline_type),
543   _has_flattening_information(is_inline_type),
544   _has_nonatomic_values(false),
545   _atomic_field_count(0)
546  {}
547 
548 FieldGroup* FieldLayoutBuilder::get_or_create_contended_group(int g) {
549   assert(g &gt; 0, &quot;must only be called for named contended groups&quot;);
550   FieldGroup* fg = NULL;
551   for (int i = 0; i &lt; _contended_groups.length(); i++) {
552     fg = _contended_groups.at(i);
553     if (fg-&gt;contended_group() == g) return fg;
554   }
555   fg = new FieldGroup(g);
556   _contended_groups.append(fg);
557   return fg;
558 }
559 
560 void FieldLayoutBuilder::prologue() {
</pre>
<hr />
<pre>
598     }
599     assert(group != NULL, &quot;invariant&quot;);
600     BasicType type = Signature::basic_type(fs.signature());
601     switch(type) {
602     case T_BYTE:
603     case T_CHAR:
604     case T_DOUBLE:
605     case T_FLOAT:
606     case T_INT:
607     case T_LONG:
608     case T_SHORT:
609     case T_BOOLEAN:
610       group-&gt;add_primitive_field(fs, type);
611       break;
612     case T_OBJECT:
613     case T_ARRAY:
614       if (group != _static_fields) _nonstatic_oopmap_count++;
615       group-&gt;add_oop_field(fs);
616       break;
617     case T_VALUETYPE:
<span class="line-added">618 //      fs.set_inline(true);</span>
<span class="line-added">619       _has_inline_type_fields = true;</span>
620       if (group == _static_fields) {
<span class="line-modified">621         // static fields are never inlined</span>
622         group-&gt;add_oop_field(fs);
623       } else {
624         _has_flattening_information = true;
625         // Flattening decision to be taken here
<span class="line-modified">626         // This code assumes all verification already have been performed</span>
<span class="line-modified">627         // (field&#39;s type has been loaded and it is an inline klass)</span>

628         Thread* THREAD = Thread::current();
629         Klass* klass =
<span class="line-modified">630             SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,</span>
631                                                                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
632                                                                 _protection_domain, true, THREAD);
633         assert(klass != NULL, &quot;Sanity check&quot;);
634         ValueKlass* vk = ValueKlass::cast(klass);
635         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
636                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
637         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
638         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
639         if (vk-&gt;is_naturally_atomic()) {
640           too_atomic_to_flatten = false;
641           //too_volatile_to_flatten = false; //FIXME
<span class="line-modified">642           // volatile fields are currently never inlined, this could change in the future</span>
643         }
644         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
<span class="line-modified">645           group-&gt;add_inlined_field(fs, vk);</span>
646           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
<span class="line-modified">647           fs.set_inlined(true);</span>
648           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
649             _has_nonatomic_values = true;
650             _atomic_field_count--;  // every other field is atomic but this one
651           }
652         } else {
653           _nonstatic_oopmap_count++;
654           group-&gt;add_oop_field(fs);
655         }
656       }
657       break;
658     default:
659       fatal(&quot;Something wrong?&quot;);
660     }
661   }
662   _root_group-&gt;sort_by_size();
663   _static_fields-&gt;sort_by_size();
664   if (!_contended_groups.is_empty()) {
665     for (int i = 0; i &lt; _contended_groups.length(); i++) {
666       _contended_groups.at(i)-&gt;sort_by_size();
667     }
668   }
669 }
670 
671 /* Field sorting for inline classes:
672  *   - because inline classes are immutable, the @Contended annotation is ignored
673  *     when computing their layout (with only read operation, there&#39;s no false
674  *     sharing issue)
675  *   - this method also records the alignment of the field with the most
676  *     constraining alignment, this value is then used as the alignment
677  *     constraint when flattening this inline type into another container
678  *   - field flattening decisions are taken in this method (those decisions are
<span class="line-modified">679  *     currently only based in the size of the fields to be inlined, the size</span>
680  *     of the resulting instance is not considered)
681  */
682 void FieldLayoutBuilder::inline_class_field_sorting(TRAPS) {
683   assert(_is_inline_type, &quot;Should only be used for inline classes&quot;);
684   int alignment = 1;
685   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
686     FieldGroup* group = NULL;
687     int field_alignment = 1;
688     if (fs.access_flags().is_static()) {
689       group = _static_fields;
690     } else {
691       _has_nonstatic_fields = true;
692       _atomic_field_count++;  // we might decrement this
693       group = _root_group;
694     }
695     assert(group != NULL, &quot;invariant&quot;);
696     BasicType type = Signature::basic_type(fs.signature());
697     switch(type) {
698     case T_BYTE:
699     case T_CHAR:
700     case T_DOUBLE:
701     case T_FLOAT:
702     case T_INT:
703     case T_LONG:
704     case T_SHORT:
705     case T_BOOLEAN:
706       if (group != _static_fields) {
707         field_alignment = type2aelembytes(type); // alignment == size for primitive types
708       }
709       group-&gt;add_primitive_field(fs, type);
710       break;
711     case T_OBJECT:
712     case T_ARRAY:
713       if (group != _static_fields) {
714         _nonstatic_oopmap_count++;
715         field_alignment = type2aelembytes(type); // alignment == size for oops
716       }
717       group-&gt;add_oop_field(fs);
718       break;
719     case T_VALUETYPE: {
<span class="line-added">720 //      fs.set_inline(true);</span>
<span class="line-added">721       _has_inline_type_fields = true;</span>
722       if (group == _static_fields) {
<span class="line-modified">723         // static fields are never inlined</span>
724         group-&gt;add_oop_field(fs);
725       } else {
726         // Flattening decision to be taken here
<span class="line-modified">727         // This code assumes all verifications have already been performed</span>
<span class="line-modified">728         // (field&#39;s type has been loaded and it is an inline klass)</span>

729         Thread* THREAD = Thread::current();
730         Klass* klass =
<span class="line-modified">731             SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,</span>
732                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
733                 _protection_domain, true, CHECK);
734         assert(klass != NULL, &quot;Sanity check&quot;);
735         ValueKlass* vk = ValueKlass::cast(klass);
736         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
737                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
738         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
739         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
740         if (vk-&gt;is_naturally_atomic()) {
741           too_atomic_to_flatten = false;
742           //too_volatile_to_flatten = false; //FIXME
<span class="line-modified">743           // volatile fields are currently never inlined, this could change in the future</span>
744         }
745         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
<span class="line-modified">746           group-&gt;add_inlined_field(fs, vk);</span>
747           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
748           field_alignment = vk-&gt;get_alignment();
<span class="line-modified">749           fs.set_inlined(true);</span>
750           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
751             _has_nonatomic_values = true;
752             _atomic_field_count--;  // every other field is atomic but this one
753           }
754         } else {
755           _nonstatic_oopmap_count++;
756           field_alignment = type2aelembytes(T_OBJECT);
757           group-&gt;add_oop_field(fs);
758         }
759       }
760       break;
761     }
762     default:
763       fatal(&quot;Unexpected BasicType&quot;);
764     }
765     if (!fs.access_flags().is_static() &amp;&amp; field_alignment &gt; alignment) alignment = field_alignment;
766   }
767   _alignment = alignment;
768   if (!_has_nonstatic_fields) {
769     // There are a number of fixes required throughout the type system and JIT
770     Exceptions::fthrow(THREAD_AND_LOCATION,
771                        vmSymbols::java_lang_ClassFormatError(),
772                        &quot;Value Types do not support zero instance size yet&quot;);
773     return;
774   }
775 }
776 
777 void FieldLayoutBuilder::insert_contended_padding(LayoutRawBlock* slot) {
778   if (ContendedPaddingWidth &gt; 0) {
779     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
780     _layout-&gt;insert(slot, padding);
781   }
782 }
783 
784 /* Computation of regular classes layout is an evolution of the previous default layout
785  * (FieldAllocationStyle 1):
<span class="line-modified">786  *   - inlined fields are allocated first (because they have potentially the</span>
787  *     least regular shapes, and are more likely to create empty slots between them,
788  *     which can then be used to allocation primitive or oop fields). Allocation is
<span class="line-modified">789  *     performed from the biggest to the smallest field.</span>
790  *   - then primitive fields (from the biggest to the smallest)
791  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
792  *     and reduce the work of the GC).
793  */
794 void FieldLayoutBuilder::compute_regular_layout() {
795   bool need_tail_padding = false;
796   prologue();
797   regular_field_sorting();
798   if (_is_contended) {
799     _layout-&gt;set_start(_layout-&gt;last_block());
800     // insertion is currently easy because the current strategy doesn&#39;t try to fill holes
801     // in super classes layouts =&gt; the _start block is by consequence the _last_block
802     insert_contended_padding(_layout-&gt;start());
803     need_tail_padding = true;
804   }
<span class="line-modified">805   _layout-&gt;add(_root_group-&gt;inlined_fields());</span>
806   _layout-&gt;add(_root_group-&gt;primitive_fields());
807   _layout-&gt;add(_root_group-&gt;oop_fields());
808 
809   if (!_contended_groups.is_empty()) {
810     for (int i = 0; i &lt; _contended_groups.length(); i++) {
811       FieldGroup* cg = _contended_groups.at(i);
812       LayoutRawBlock* start = _layout-&gt;last_block();
813       insert_contended_padding(start);
<span class="line-modified">814       _layout-&gt;add(_root_group-&gt;inlined_fields());</span>
815       _layout-&gt;add(cg-&gt;primitive_fields(), start);
816       _layout-&gt;add(cg-&gt;oop_fields(), start);
817       need_tail_padding = true;
818     }
819   }
820 
821   if (need_tail_padding) {
822     insert_contended_padding(_layout-&gt;last_block());
823   }
<span class="line-modified">824   _static_layout-&gt;add(_static_fields-&gt;inlined_fields());</span>
825   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
826   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
827 
828   epilogue();
829 }
830 
831 /* Computation of inline classes has a slightly different strategy than for
832  * regular classes. Regular classes have their oop fields allocated at the end
833  * of the layout to increase GC performances. Unfortunately, this strategy
834  * increases the number of empty slots inside an instance. Because the purpose
835  * of inline classes is to be embedded into other containers, it is critical
836  * to keep their size as small as possible. For this reason, the allocation
837  * strategy is:
<span class="line-modified">838  *   - inlined fields are allocated first (because they have potentially the</span>
839  *     least regular shapes, and are more likely to create empty slots between them,
840  *     which can then be used to allocation primitive or oop fields). Allocation is
<span class="line-modified">841  *     performed from the biggest to the smallest field.</span>
842  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
843  *     and reduce the work of the GC)
844  *   - then primitive fields (from the biggest to the smallest)
845  */
846 void FieldLayoutBuilder::compute_inline_class_layout(TRAPS) {
847   prologue();
848   inline_class_field_sorting(CHECK);
849   // Inline types are not polymorphic, so they cannot inherit fields.
850   // By consequence, at this stage, the layout must be composed of a RESERVED
851   // block, followed by an EMPTY block.
852   assert(_layout-&gt;start()-&gt;kind() == LayoutRawBlock::RESERVED, &quot;Unexpected&quot;);
853   assert(_layout-&gt;start()-&gt;next_block()-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Unexpected&quot;);
854   LayoutRawBlock* first_empty = _layout-&gt;start()-&gt;next_block();
855   if (first_empty-&gt;offset() % _alignment != 0) {
856     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _alignment - (first_empty-&gt;offset() % _alignment));
857     _layout-&gt;insert(first_empty, padding);
858     _layout-&gt;set_start(padding-&gt;next_block());
859   }
860 
<span class="line-modified">861   _layout-&gt;add(_root_group-&gt;inlined_fields());</span>
862   _layout-&gt;add(_root_group-&gt;oop_fields());
863   _layout-&gt;add(_root_group-&gt;primitive_fields());
864 
865   LayoutRawBlock* first_field = _layout-&gt;first_field_block();
866    if (first_field != NULL) {
867      _first_field_offset = _layout-&gt;first_field_block()-&gt;offset();
868      _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
869    } else {
870      // special case for empty value types
871      _first_field_offset = _layout-&gt;blocks()-&gt;size();
872      _exact_size_in_bytes = 0;
873    }
874   _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
875 
<span class="line-modified">876   _static_layout-&gt;add(_static_fields-&gt;inlined_fields());</span>
877   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
878   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
879 
880 
881   epilogue();
882 }
883 
<span class="line-modified">884 void FieldLayoutBuilder::add_inlined_field_oopmap(OopMapBlocksBuilder* nonstatic_oop_maps,</span>
885                 ValueKlass* vklass, int offset) {
886   int diff = offset - vklass-&gt;first_field_offset();
887   const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
888   const OopMapBlock* last_map = map + vklass-&gt;nonstatic_oop_map_count();
889   while (map &lt; last_map) {
890     nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
891     map++;
892   }
893 }
894 
895 void FieldLayoutBuilder::epilogue() {
896   // Computing oopmaps
897   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
898   int max_oop_map_count = super_oop_map_count + _nonstatic_oopmap_count;
899 
900   OopMapBlocksBuilder* nonstatic_oop_maps =
901       new OopMapBlocksBuilder(max_oop_map_count);
902   if (super_oop_map_count &gt; 0) {
903     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
904     _super_klass-&gt;nonstatic_oop_map_count());
905   }
906 
907   if (_root_group-&gt;oop_fields() != NULL) {
908     for (int i = 0; i &lt; _root_group-&gt;oop_fields()-&gt;length(); i++) {
909       LayoutRawBlock* b = _root_group-&gt;oop_fields()-&gt;at(i);
910       nonstatic_oop_maps-&gt;add(b-&gt;offset(), 1);
911     }
912   }
913 
<span class="line-modified">914   GrowableArray&lt;LayoutRawBlock*&gt;* ff = _root_group-&gt;inlined_fields();</span>
915   if (ff != NULL) {
916     for (int i = 0; i &lt; ff-&gt;length(); i++) {
917       LayoutRawBlock* f = ff-&gt;at(i);
918       ValueKlass* vk = f-&gt;value_klass();
919       assert(vk != NULL, &quot;Should have been initialized&quot;);
920       if (vk-&gt;contains_oops()) {
<span class="line-modified">921         add_inlined_field_oopmap(nonstatic_oop_maps, vk, f-&gt;offset());</span>
922       }
923     }
924   }
925 
926   if (!_contended_groups.is_empty()) {
927     for (int i = 0; i &lt; _contended_groups.length(); i++) {
928       FieldGroup* cg = _contended_groups.at(i);
929       if (cg-&gt;oop_count() &gt; 0) {
930         assert(cg-&gt;oop_fields() != NULL &amp;&amp; cg-&gt;oop_fields()-&gt;at(0) != NULL, &quot;oop_count &gt; 0 but no oop fields found&quot;);
931         nonstatic_oop_maps-&gt;add(cg-&gt;oop_fields()-&gt;at(0)-&gt;offset(), cg-&gt;oop_count());
932       }
933     }
934   }
935 
936   nonstatic_oop_maps-&gt;compact();
937 
938   int instance_end = align_up(_layout-&gt;last_block()-&gt;offset(), wordSize);
939   int static_fields_end = align_up(_static_layout-&gt;last_block()-&gt;offset(), wordSize);
940   int static_fields_size = (static_fields_end -
941       InstanceMirrorKlass::offset_of_static_fields()) / wordSize;
942   int nonstatic_field_end = align_up(_layout-&gt;last_block()-&gt;offset(), heapOopSize);
943 
944   // Pass back information needed for InstanceKlass creation
945 
946   _info-&gt;oop_map_blocks = nonstatic_oop_maps;
947   _info-&gt;_instance_size = align_object_size(instance_end / wordSize);
948   _info-&gt;_static_field_size = static_fields_size;
949   _info-&gt;_nonstatic_field_size = (nonstatic_field_end - instanceOopDesc::base_offset_in_bytes()) / heapOopSize;
950   _info-&gt;_has_nonstatic_fields = _has_nonstatic_fields;
<span class="line-added">951   _info-&gt;_has_inline_fields = _has_inline_type_fields;</span>
952 
953   // An inline type is naturally atomic if it has just one field, and
954   // that field is simple enough.
955   _info-&gt;_is_naturally_atomic = (_is_inline_type &amp;&amp;
956                                  (_atomic_field_count &lt;= 1) &amp;&amp;
957                                  !_has_nonatomic_values &amp;&amp;
958                                  _contended_groups.is_empty());
959   // This may be too restrictive, since if all the fields fit in 64
960   // bits we could make the decision to align instances of this class
961   // to 64-bit boundaries, and load and store them as single words.
962   // And on machines which supported larger atomics we could similarly
963   // allow larger values to be atomic, if properly aligned.
964 
965 
966   if (PrintFieldLayout) {
967     ResourceMark rm;
968     tty-&gt;print_cr(&quot;Layout of class %s&quot;, _classname-&gt;as_C_string());
969     tty-&gt;print_cr(&quot;Instance fields:&quot;);
970     _layout-&gt;print(tty, false, _super_klass);
971     tty-&gt;print_cr(&quot;Static fields:&quot;);
</pre>
</td>
</tr>
</table>
<center><a href="classFileParser.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="fieldLayoutBuilder.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>