diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -1516,17 +1516,17 @@
   STATIC_OOP,           // Oops
   STATIC_BYTE,          // Boolean, Byte, char
   STATIC_SHORT,         // shorts
   STATIC_WORD,          // ints
   STATIC_DOUBLE,        // aligned long or double
-  STATIC_FLATTENABLE,   // flattenable field
+  STATIC_INLINE,        // inline type field
   NONSTATIC_OOP,
   NONSTATIC_BYTE,
   NONSTATIC_SHORT,
   NONSTATIC_WORD,
   NONSTATIC_DOUBLE,
-  NONSTATIC_FLATTENABLE,
+  NONSTATIC_INLINE,
   MAX_FIELD_ALLOCATION_TYPE,
   BAD_ALLOCATION_TYPE = -1
 };
 
 static FieldAllocationType _basic_type_to_atype[2 * (T_CONFLICT + 1)] = {
@@ -1572,16 +1572,16 @@
   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
   BAD_ALLOCATION_TYPE, // T_CONFLICT    = 20
 };
 
-static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_flattenable) {
+static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline_type) {
   assert(type >= T_BOOLEAN && type < T_VOID, "only allowable values");
   FieldAllocationType result = _basic_type_to_atype[type + (is_static ? (T_CONFLICT + 1) : 0)];
   assert(result != BAD_ALLOCATION_TYPE, "bad type");
-  if (is_flattenable) {
-    result = is_static ? STATIC_FLATTENABLE : NONSTATIC_FLATTENABLE;
+  if (is_inline_type) {
+    result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;
   }
   return result;
 }
 
 class ClassFileParser::FieldAllocationCount : public ResourceObj {
@@ -1592,12 +1592,12 @@
     for (int i = 0; i < MAX_FIELD_ALLOCATION_TYPE; i++) {
       count[i] = 0;
     }
   }
 
-  FieldAllocationType update(bool is_static, BasicType type, bool is_flattenable) {
-    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_flattenable);
+  FieldAllocationType update(bool is_static, BasicType type, bool is_inline_type) {
+    FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline_type);
     if (atype != BAD_ALLOCATION_TYPE) {
       // Make sure there is no overflow with injected fields.
       assert(count[atype] < 0xFFFF, "More than 65535 fields");
       count[atype]++;
     }
@@ -1689,26 +1689,10 @@
     check_property(valid_symbol_at(signature_index),
       "Invalid constant pool index %u for field signature in class file %s",
       signature_index, CHECK);
     const Symbol* const sig = cp->symbol_at(signature_index);
     verify_legal_field_signature(name, sig, CHECK);
-    assert(!access_flags.is_flattenable(), "ACC_FLATTENABLE should have been filtered out");
-    if (sig->is_Q_signature()) {
-      // assert(_major_version >= CONSTANT_CLASS_DESCRIPTORS, "Q-descriptors are only supported in recent classfiles");
-      access_flags.set_is_flattenable();
-    }
-    if (access_flags.is_flattenable()) {
-      // Array flattenability cannot be specified.  Arrays of value classes are
-      // are always flattenable.  Arrays of other classes are not flattenable.
-      if (sig->utf8_length() > 1 && sig->char_at(0) == '[') {
-        classfile_parse_error(
-            "Field \"%s\" with signature \"%s\" in class file %s is invalid."
-            " ACC_FLATTENABLE cannot be specified for an array",
-            name->as_C_string(), sig->as_klass_external_name(), CHECK);
-      }
-      _has_flattenable_fields = true;
-    }
     if (!access_flags.is_static()) instance_fields_count++;
 
     u2 constantvalue_index = 0;
     bool is_synthetic = false;
     u2 generic_signature_index = 0;
@@ -1765,11 +1749,11 @@
                       signature_index,
                       constantvalue_index);
     const BasicType type = cp->basic_type_for_signature_at(signature_index);
 
     // Remember how many oops we encountered and compute allocation type
-    const FieldAllocationType atype = fac->update(is_static, type, access_flags.is_flattenable());
+    const FieldAllocationType atype = fac->update(is_static, type, type == T_VALUETYPE);
     field->set_allocation_type(atype);
 
     // After field is initialized with type, we can augment it with aux info
     if (parsed_annotations.has_any_annotations()) {
       parsed_annotations.apply_to(field);
@@ -4403,11 +4387,11 @@
 
   // Calculate the starting byte offsets
   int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();
   // Inline types in static fields are not embedded, they are handled with oops
   int next_static_double_offset = next_static_oop_offset +
-                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_FLATTENABLE]) * heapOopSize);
+                                  ((fac->count[STATIC_OOP] + fac->count[STATIC_INLINE]) * heapOopSize);
   if (fac->count[STATIC_DOUBLE]) {
     next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);
   }
 
   int next_static_word_offset   = next_static_double_offset +
@@ -4420,11 +4404,11 @@
   int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +
                                 nonstatic_field_size * heapOopSize;
 
   // First field of inline types is aligned on a long boundary in order to ease
   // in-lining of inline types (with header removal) in packed arrays and
-  // flatten inline types
+  // inlined fields
   int initial_inline_type_padding = 0;
   if (is_inline_type()) {
     int old = nonstatic_fields_start;
     nonstatic_fields_start = align_up(nonstatic_fields_start, BytesPerLong);
     initial_inline_type_padding = nonstatic_fields_start - old;
@@ -4460,82 +4444,82 @@
   int static_inline_type_count = 0;
   int nonstatic_inline_type_count = 0;
   int* nonstatic_inline_type_indexes = NULL;
   Klass** nonstatic_inline_type_klasses = NULL;
   unsigned int inline_type_oop_map_count = 0;
-  int not_flattened_inline_types = 0;
+  int inline_types_not_inlined = 0;
   int not_atomic_inline_types = 0;
 
-  int max_nonstatic_inline_type = fac->count[NONSTATIC_FLATTENABLE] + 1;
+  int max_nonstatic_inline_type = fac->count[NONSTATIC_INLINE] + 1;
 
   nonstatic_inline_type_indexes = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, int,
                                                                max_nonstatic_inline_type);
   for (int i = 0; i < max_nonstatic_inline_type; i++) {
     nonstatic_inline_type_indexes[i] = -1;
   }
   nonstatic_inline_type_klasses = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, Klass*,
                                                                max_nonstatic_inline_type);
 
   for (AllFieldStream fs(_fields, _cp); !fs.done(); fs.next()) {
-    if (fs.allocation_type() == STATIC_FLATTENABLE) {
+    if (fs.allocation_type() == STATIC_INLINE) {
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       static_inline_type_count++;
-    } else if (fs.allocation_type() == NONSTATIC_FLATTENABLE) {
-      // Pre-resolve the flattenable field and check for inline type circularity issues.
+    } else if (fs.allocation_type() == NONSTATIC_INLINE) {
+      // Pre-resolve the inline field and check for inline type circularity issues.
       ResourceMark rm;
       if (!fs.signature()->is_Q_signature()) {
         THROW(vmSymbols::java_lang_ClassFormatError());
       }
       Klass* klass =
-        SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+        SystemDictionary::resolve_inline_type_field_or_fail(&fs,
                                                             Handle(THREAD, _loader_data->class_loader()),
                                                             _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
       if (!klass->access_flags().is_inline_type()) {
         THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
       }
       ValueKlass* vk = ValueKlass::cast(klass);
       // Conditions to apply flattening or not should be defined in a single place
-      bool too_big_to_flatten = (InlineFieldMaxFlatSize >= 0 &&
+      bool too_big_to_allocate_inline = (InlineFieldMaxFlatSize >= 0 &&
                                  (vk->size_helper() * HeapWordSize) > InlineFieldMaxFlatSize);
-      bool too_atomic_to_flatten = vk->is_declared_atomic();
-      bool too_volatile_to_flatten = fs.access_flags().is_volatile();
+      bool too_atomic_to_allocate_inline = vk->is_declared_atomic();
+      bool too_volatile_to_allocate_inline = fs.access_flags().is_volatile();
       if (vk->is_naturally_atomic()) {
-        too_atomic_to_flatten = false;
-        //too_volatile_to_flatten = false; //FIXME
-        // volatile fields are currently never flattened, this could change in the future
+        too_atomic_to_allocate_inline = false;
+        // too_volatile_to_allocate_inline = false; //FIXME
+        // volatile fields are currently never inlined, this could change in the future
       }
-      if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
+      if (!(too_big_to_allocate_inline | too_atomic_to_allocate_inline | too_volatile_to_allocate_inline)) {
         nonstatic_inline_type_indexes[nonstatic_inline_type_count] = fs.index();
         nonstatic_inline_type_klasses[nonstatic_inline_type_count] = klass;
         nonstatic_inline_type_count++;
 
         ValueKlass* vklass = ValueKlass::cast(klass);
         if (vklass->contains_oops()) {
           inline_type_oop_map_count += vklass->nonstatic_oop_map_count();
         }
-        fs.set_flattened(true);
+        fs.set_inlined(true);
         if (!vk->is_atomic()) {  // flat and non-atomic: take note
           not_atomic_inline_types++;
         }
       } else {
-        not_flattened_inline_types++;
-        fs.set_flattened(false);
+        inline_types_not_inlined++;
+        fs.set_inlined(false);
       }
     }
   }
 
-  // Adjusting non_static_oop_count to take into account not flattened inline types;
-  nonstatic_oop_count += not_flattened_inline_types;
+  // Adjusting non_static_oop_count to take into account inline types fields not inlined;
+  nonstatic_oop_count += inline_types_not_inlined;
 
   // Total non-static fields count, including every contended field
   unsigned int nonstatic_fields_count = fac->count[NONSTATIC_DOUBLE] + fac->count[NONSTATIC_WORD] +
                                         fac->count[NONSTATIC_SHORT] + fac->count[NONSTATIC_BYTE] +
-                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_FLATTENABLE];
+                                        fac->count[NONSTATIC_OOP] + fac->count[NONSTATIC_INLINE];
 
   const bool super_has_nonstatic_fields =
           (_super_klass != NULL && _super_klass->has_nonstatic_fields());
   const bool has_nonstatic_fields =
     super_has_nonstatic_fields || (nonstatic_fields_count != 0);
@@ -4558,11 +4542,11 @@
   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass->nonstatic_oop_map_count();
   int max_oop_map_count =
       super_oop_map_count +
       fac->count[NONSTATIC_OOP] +
       inline_type_oop_map_count +
-      not_flattened_inline_types;
+      inline_types_not_inlined;
 
   OopMapBlocksBuilder* nonstatic_oop_maps = new OopMapBlocksBuilder(max_oop_map_count);
   if (super_oop_map_count > 0) {
     nonstatic_oop_maps->initialize_inherited_blocks(_super_klass->start_of_nonstatic_oop_maps(),
                                                     _super_klass->nonstatic_oop_map_count());
@@ -4680,11 +4664,11 @@
     const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();
 
     // pack the rest of the fields
     switch (atype) {
       // Inline types in static fields are handled with oops
-      case STATIC_FLATTENABLE:   // Fallthrough
+      case STATIC_INLINE:   // Fallthrough
       case STATIC_OOP:
         real_offset = next_static_oop_offset;
         next_static_oop_offset += heapOopSize;
         break;
       case STATIC_BYTE:
@@ -4701,12 +4685,12 @@
         break;
       case STATIC_DOUBLE:
         real_offset = next_static_double_offset;
         next_static_double_offset += BytesPerLong;
         break;
-      case NONSTATIC_FLATTENABLE:
-        if (fs.is_flattened()) {
+      case NONSTATIC_INLINE:
+        if (fs.is_inlined()) {
           Klass* klass = nonstatic_inline_type_klasses[next_inline_type_index];
           assert(klass != NULL, "Klass should have been loaded and resolved earlier");
           assert(klass->access_flags().is_inline_type(),"Must be an inline type");
           ValueKlass* vklass = ValueKlass::cast(klass);
           real_offset = next_nonstatic_inline_type_offset;
@@ -4845,11 +4829,11 @@
             real_offset = next_nonstatic_padded_offset;
             next_nonstatic_padded_offset += BytesPerLong;
             break;
 
             // Inline types in static fields are handled with oops
-          case NONSTATIC_FLATTENABLE:
+          case NONSTATIC_INLINE:
             throwInlineTypeLimitation(THREAD_AND_LOCATION,
                                       "@Contended annotation not supported for inline types yet", fs.name(), fs.signature());
             return;
 
           case NONSTATIC_OOP:
@@ -4959,10 +4943,11 @@
   info->oop_map_blocks = nonstatic_oop_maps;
   info->_instance_size = instance_size;
   info->_static_field_size = static_field_size;
   info->_nonstatic_field_size = nonstatic_field_size;
   info->_has_nonstatic_fields = has_nonstatic_fields;
+  info->_has_inline_fields = nonstatic_inline_type_count > 0;
 
   // An inline type is naturally atomic if it has just one field, and
   // that field is simple enough.
   info->_is_naturally_atomic = (is_inline_type() &&
                                 !super_has_nonstatic_fields &&
@@ -6276,11 +6261,11 @@
   if (_has_injected_identityObject) {
     ik->set_has_injected_identityObject();
   }
 
   assert(_fac != NULL, "invariant");
-  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_FLATTENABLE]);
+  ik->set_static_oop_field_count(_fac->count[STATIC_OOP] + _fac->count[STATIC_INLINE]);
 
   // this transfers ownership of a lot of arrays from
   // the parser onto the InstanceKlass*
   apply_parsed_class_metadata(ik, _java_fields_count, CHECK);
 
@@ -6443,11 +6428,11 @@
   }
 
   int nfields = ik->java_fields_count();
   if (ik->is_value()) nfields++;
   for (int i = 0; i < nfields; i++) {
-    if (ik->field_is_flattenable(i)) {
+    if (ik->field_is_inline_type(i)) {
       Symbol* klass_name = ik->field_signature(i)->fundamental_name(CHECK);
       // Inline classes for instance fields must have been pre-loaded
       // Inline classes for static fields might not have been loaded yet
       Klass* klass = SystemDictionary::find(klass_name,
           Handle(THREAD, ik->class_loader()),
@@ -6669,11 +6654,11 @@
   _relax_verify(false),
   _has_nonstatic_concrete_methods(false),
   _declares_nonstatic_concrete_methods(false),
   _has_final_method(false),
   _has_contended_fields(false),
-  _has_flattenable_fields(false),
+  _has_inline_type_fields(false),
   _has_nonstatic_fields(false),
   _is_empty_inline_type(false),
   _is_naturally_atomic(false),
   _is_declared_atomic(false),
   _invalid_inline_super(false),
@@ -7290,18 +7275,17 @@
   assert(_fac != NULL, "invariant");
   assert(_parsed_annotations != NULL, "invariant");
 
 
   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
-    if (fs.is_flattenable() && !fs.access_flags().is_static()) {
+    if (Signature::basic_type(fs.signature()) == T_VALUETYPE  && !fs.access_flags().is_static()) {
       // Pre-load value class
-      Klass* klass = SystemDictionary::resolve_flattenable_field_or_fail(&fs,
+      Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&fs,
           Handle(THREAD, _loader_data->class_loader()),
           _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
-      assert(klass->access_flags().is_inline_type(), "Inline type expected");
-      _has_flattenable_fields = true;
+      assert(klass->access_flags().is_inline_type(), "Value type expected");
     }
   }
 
   _field_info = new FieldLayoutInfo();
   if (UseNewFieldLayout) {
@@ -7315,10 +7299,11 @@
       _exact_size_in_bytes = lb.get_exact_size_in_byte();
     }
   } else {
     layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);
   }
+  _has_inline_type_fields = _field_info->_has_inline_fields;
 
   // Compute reference type
   _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass->reference_type();
 }
 
