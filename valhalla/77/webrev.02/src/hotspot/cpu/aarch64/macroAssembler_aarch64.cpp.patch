diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -1503,21 +1503,21 @@
   ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));
   andr(temp_reg, temp_reg, JVM_ACC_VALUE);
   cbnz(temp_reg, is_value);
 }
 
-void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label& is_flattenable) {
+void MacroAssembler::test_field_is_inline_type(Register flags, Register temp_reg, Label& is_inline) {
   (void) temp_reg; // keep signature uniform with x86
-  tbnz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, is_flattenable);
+  tbnz(flags, ConstantPoolCacheEntry::is_inline_field_shift, is_inline);
 }
 
-void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label& not_flattenable) {
+void MacroAssembler::test_field_is_not_inline_type(Register flags, Register temp_reg, Label& not_inline) {
   (void) temp_reg; // keep signature uniform with x86
-  tbz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, not_flattenable);
+  tbz(flags, ConstantPoolCacheEntry::is_inline_field_shift, not_inline);
 }
 
-void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label& is_flattened) {
+void MacroAssembler::test_field_is_inlined(Register flags, Register temp_reg, Label& is_flattened) {
   (void) temp_reg; // keep signature uniform with x86
   tbnz(flags, ConstantPoolCacheEntry::is_flattened_field_shift, is_flattened);
 }
 
 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label& is_flattened_array) {
