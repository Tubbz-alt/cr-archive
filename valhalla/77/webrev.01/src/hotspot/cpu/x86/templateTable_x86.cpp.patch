diff a/src/hotspot/cpu/x86/templateTable_x86.cpp b/src/hotspot/cpu/x86/templateTable_x86.cpp
--- a/src/hotspot/cpu/x86/templateTable_x86.cpp
+++ b/src/hotspot/cpu/x86/templateTable_x86.cpp
@@ -3066,18 +3066,18 @@
     }
     __ jmp(Done);
   } else {
     if (is_static) {
       __ load_heap_oop(rax, field);
-      Label isFlattenable, uninitialized;
+      Label is_inline_type, uninitialized;
       // Issue below if the static field has not been initialized yet
-      __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Not flattenable case
+      __ test_field_is_inline_type(flags2, rscratch1, is_inline_type);
+        // field is not an inline type
         __ push(atos);
         __ jmp(Done);
-      // Flattenable case, must not return null even if uninitialized
-      __ bind(isFlattenable);
+      // field is an inline type, must not return null even if uninitialized
+      __ bind(is_inline_type);
         __ testptr(rax, rax);
         __ jcc(Assembler::zero, uninitialized);
           __ push(atos);
           __ jmp(Done);
         __ bind(uninitialized);
@@ -3097,23 +3097,23 @@
 #endif // _LP64
           __ verify_oop(rax);
           __ push(atos);
           __ jmp(Done);
     } else {
-      Label isFlattened, nonnull, isFlattenable, rewriteFlattenable;
-      __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Non-flattenable field case, also covers the object case
+      Label is_allocated_inline, nonnull, is_inline_type, rewrite_inline;
+      __ test_field_is_inline_type(flags2, rscratch1, is_inline_type);
+        // field is not an inline type
         pop_and_check_object(obj);
         __ load_heap_oop(rax, field);
         __ push(atos);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_agetfield, bc, rbx);
         }
         __ jmp(Done);
-      __ bind(isFlattenable);
-        __ test_field_is_flattened(flags2, rscratch1, isFlattened);
-          // Non-flattened field case
+      __ bind(is_inline_type);
+        __ test_field_is_allocated_inline(flags2, rscratch1, is_allocated_inline);
+          // field is not allocated inline
           __ movptr(rax, rcx);  // small dance required to preserve the klass_holder somewhere
           pop_and_check_object(obj);
           __ push(rax);
           __ load_heap_oop(rax, field);
           __ pop(rcx);
@@ -3123,18 +3123,19 @@
             __ get_value_field_klass(rcx, flags2, rbx);
             __ get_default_value_oop(rbx, rcx, rax);
           __ bind(nonnull);
           __ verify_oop(rax);
           __ push(atos);
-          __ jmp(rewriteFlattenable);
-        __ bind(isFlattened);
+          __ jmp(rewrite_inline);
+        __ bind(is_allocated_inline);
+        // field is allocated inline
           __ andl(flags2, ConstantPoolCacheEntry::field_index_mask);
           pop_and_check_object(rax);
-          __ read_flattened_field(rcx, flags2, rbx, rax);
+          __ read_field_allocated_inline(rcx, flags2, rbx, rax);
           __ verify_oop(rax);
           __ push(atos);
-      __ bind(rewriteFlattenable);
+      __ bind(rewrite_inline);
       if (rc == may_rewrite) {
         patch_bytecode(Bytecodes::_fast_qgetfield, bc, rbx);
       }
       __ jmp(Done);
     }
@@ -3445,45 +3446,46 @@
       }
       __ jmp(Done);
     } else {
       __ pop(atos);
       if (is_static) {
-        Label notFlattenable, notBuffered;
-        __ test_field_is_not_flattenable(flags2, rscratch1, notFlattenable);
+        Label is_inline_type;
+        __ test_field_is_not_inline_type(flags2, rscratch1, is_inline_type);
         __ null_check(rax);
-        __ bind(notFlattenable);
+        __ bind(is_inline_type);
         do_oop_store(_masm, field, rax);
         __ jmp(Done);
       } else {
-        Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;
-        __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);
-        // Not flattenable case, covers not flattenable values and objects
+        Label is_inline_type, is_allocated_inline, rewrite_not_inline, rewrite_inline;
+        __ test_field_is_inline_type(flags2, rscratch1, is_inline_type);
+        // Not an inline type
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, rax);
-        __ bind(rewriteNotFlattenable);
+        __ bind(rewrite_not_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_aputfield, bc, rbx, true, byte_no);
         }
         __ jmp(Done);
-        // Implementation of the flattenable semantic
-        __ bind(isFlattenable);
+        // Implementation of the inline type semantic
+        __ bind(is_inline_type);
         __ null_check(rax);
-        __ test_field_is_flattened(flags2, rscratch1, isFlattened);
-        // Not flattened case
+        __ test_field_is_allocated_inline(flags2, rscratch1, is_allocated_inline);
+        // field is not allocated inline
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, rax);
-        __ jmp(rewriteFlattenable);
-        __ bind(isFlattened);
+        __ jmp(rewrite_inline);
+        __ bind(is_allocated_inline);
+        // field is allocated inline
         pop_and_check_object(obj);
         assert_different_registers(rax, rdx, obj, off);
         __ load_klass(rdx, rax, rscratch1);
         __ data_for_oop(rax, rax, rdx);
         __ addptr(obj, off);
         __ access_value_copy(IN_HEAP, rax, obj, rdx);
-        __ bind(rewriteFlattenable);
+        __ bind(rewrite_inline);
         if (rc == may_rewrite) {
           patch_bytecode(Bytecodes::_fast_qputfield, bc, rbx, true, byte_no);
         }
         __ jmp(Done);
       }
@@ -3691,11 +3693,11 @@
   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadStore |
   //                                              Assembler::StoreStore));
 
   Label notVolatile, Done;
   if (bytecode() == Bytecodes::_fast_qputfield) {
-    __ movl(rscratch2, rdx);  // saving flags for isFlattened test
+    __ movl(rscratch2, rdx);  // saving flags for is_allocated_inline test
   }
 
   __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
   __ andl(rdx, 0x1);
 
@@ -3708,20 +3710,20 @@
   // Check for volatile store
   __ testl(rdx, rdx);
   __ jcc(Assembler::zero, notVolatile);
 
   if (bytecode() == Bytecodes::_fast_qputfield) {
-    __ movl(rdx, rscratch2);  // restoring flags for isFlattened test
+    __ movl(rdx, rscratch2);  // restoring flags for is_allocated_inline test
   }
   fast_storefield_helper(field, rax, rdx);
   volatile_barrier(Assembler::Membar_mask_bits(Assembler::StoreLoad |
                                                Assembler::StoreStore));
   __ jmp(Done);
   __ bind(notVolatile);
 
   if (bytecode() == Bytecodes::_fast_qputfield) {
-    __ movl(rdx, rscratch2);  // restoring flags for isFlattened test
+    __ movl(rdx, rscratch2);  // restoring flags for is_allocated_inline test
   }
   fast_storefield_helper(field, rax, rdx);
 
   __ bind(Done);
 }
@@ -3730,18 +3732,18 @@
 
   // access field
   switch (bytecode()) {
   case Bytecodes::_fast_qputfield:
     {
-      Label isFlattened, done;
+      Label is_allocated_inline, done;
       __ null_check(rax);
-      __ test_field_is_flattened(flags, rscratch1, isFlattened);
-      // No Flattened case
+      __ test_field_is_allocated_inline(flags, rscratch1, is_allocated_inline);
+      // field is not allocated inline
       do_oop_store(_masm, field, rax);
       __ jmp(done);
-      __ bind(isFlattened);
-      // Flattened case
+      __ bind(is_allocated_inline);
+      // field is allocated inline
       __ load_klass(rdx, rax, rscratch1);
       __ data_for_oop(rax, rax, rdx);
       __ lea(rcx, field);
       __ access_value_copy(IN_HEAP, rax, rcx, rdx);
       __ bind(done);
@@ -3831,16 +3833,16 @@
 
   // access field
   switch (bytecode()) {
   case Bytecodes::_fast_qgetfield:
     {
-      Label isFlattened, nonnull, Done;
+      Label is_allocated_inline, nonnull, Done;
       __ movptr(rscratch1, Address(rcx, rbx, Address::times_ptr,
                                    in_bytes(ConstantPoolCache::base_offset() +
                                             ConstantPoolCacheEntry::flags_offset())));
-      __ test_field_is_flattened(rscratch1, rscratch2, isFlattened);
-        // Non-flattened field case
+      __ test_field_is_allocated_inline(rscratch1, rscratch2, is_allocated_inline);
+        // Case where field is not allocated inlines
         __ load_heap_oop(rax, field);
         __ testptr(rax, rax);
         __ jcc(Assembler::notZero, nonnull);
           __ movl(rdx, Address(rcx, rbx, Address::times_ptr,
                              in_bytes(ConstantPoolCache::base_offset() +
@@ -3852,21 +3854,21 @@
           __ get_value_field_klass(rcx, rdx, rbx);
           __ get_default_value_oop(rbx, rcx, rax);
         __ bind(nonnull);
         __ verify_oop(rax);
         __ jmp(Done);
-      __ bind(isFlattened);
+      __ bind(is_allocated_inline);
         __ push(rdx); // save offset
         __ movl(rdx, Address(rcx, rbx, Address::times_ptr,
                            in_bytes(ConstantPoolCache::base_offset() +
                                     ConstantPoolCacheEntry::flags_offset())));
         __ andl(rdx, ConstantPoolCacheEntry::field_index_mask);
         __ movptr(rcx, Address(rcx, rbx, Address::times_ptr,
                                      in_bytes(ConstantPoolCache::base_offset() +
                                               ConstantPoolCacheEntry::f1_offset())));
         __ pop(rbx); // restore offset
-        __ read_flattened_field(rcx, rdx, rbx, rax);
+        __ read_field_allocated_inline(rcx, rdx, rbx, rax);
       __ bind(Done);
       __ verify_oop(rax);
     }
     break;
   case Bytecodes::_fast_agetfield:
