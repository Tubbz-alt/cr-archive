<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../x86/interp_masm_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
2650     // use btos rewriting, no truncating to t/f bit is needed for getfield.
2651     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2652   }
2653   __ b(Done);
2654 
2655   __ bind(notBool);
2656   __ cmp(flags, (u1)atos);
2657   __ br(Assembler::NE, notObj);
2658   // atos
2659   if (!EnableValhalla) {
2660     do_oop_load(_masm, field, r0, IN_HEAP);
2661     __ push(atos);
2662     if (rc == may_rewrite) {
2663       patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2664     }
2665     __ b(Done);
2666   } else { // Valhalla
2667 
2668     if (is_static) {
2669       __ load_heap_oop(r0, field);
<span class="line-modified">2670       Label isFlattenable, isUninitialized;</span>
2671       // Issue below if the static field has not been initialized yet
<span class="line-modified">2672       __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);</span>
<span class="line-modified">2673         // Not flattenable case</span>
2674         __ push(atos);
2675         __ b(Done);
<span class="line-modified">2676       // Flattenable case, must not return null even if uninitialized</span>
<span class="line-modified">2677       __ bind(isFlattenable);</span>
2678         __ cbz(r0, isUninitialized);
2679           __ push(atos);
2680           __ b(Done);
2681         __ bind(isUninitialized);
2682           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2683           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_value_field), obj, raw_flags);
2684           __ verify_oop(r0);
2685           __ push(atos);
2686           __ b(Done);
2687     } else {
<span class="line-modified">2688       Label isFlattened, isInitialized, isFlattenable, rewriteFlattenable;</span>
<span class="line-modified">2689         __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);</span>
<span class="line-modified">2690         // Non-flattenable field case, also covers the object case</span>
2691         __ load_heap_oop(r0, field);
2692         __ push(atos);
2693         if (rc == may_rewrite) {
2694           patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2695         }
2696         __ b(Done);
<span class="line-modified">2697       __ bind(isFlattenable);</span>
<span class="line-modified">2698         __ test_field_is_flattened(raw_flags, r8 /* temp */, isFlattened);</span>
<span class="line-modified">2699          // Non-flattened field case</span>
2700           __ load_heap_oop(r0, field);
2701           __ cbnz(r0, isInitialized);
2702             __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2703             __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), obj, raw_flags);
2704           __ bind(isInitialized);
2705           __ verify_oop(r0);
2706           __ push(atos);
<span class="line-modified">2707           __ b(rewriteFlattenable);</span>
2708         __ bind(isFlattened);
2709           __ ldr(r10, Address(cache, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
2710           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2711           call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10);
2712           __ verify_oop(r0);
2713           __ push(atos);
<span class="line-modified">2714       __ bind(rewriteFlattenable);</span>
2715       if (rc == may_rewrite) {
2716          patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);
2717       }
2718       __ b(Done);
2719     }
2720   }
2721 
2722   __ bind(notObj);
2723   __ cmp(flags, (u1)itos);
2724   __ br(Assembler::NE, notInt);
2725   // itos
2726   __ access_load_at(T_INT, IN_HEAP, r0, field, noreg, noreg);
2727   __ push(itos);
2728   // Rewrite bytecode to be faster
2729   if (rc == may_rewrite) {
2730     patch_bytecode(Bytecodes::_fast_igetfield, bc, r1);
2731   }
2732   __ b(Done);
2733 
2734   __ bind(notInt);
</pre>
<hr />
<pre>
2950 
2951   __ bind(notBool);
2952   __ cmp(flags, (u1)atos);
2953   __ br(Assembler::NE, notObj);
2954 
2955   // atos
2956   {
2957      if (!EnableValhalla) {
2958       __ pop(atos);
2959       if (!is_static) pop_and_check_object(obj);
2960       // Store into the field
2961       do_oop_store(_masm, field, r0, IN_HEAP);
2962       if (rc == may_rewrite) {
2963         patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
2964       }
2965       __ b(Done);
2966      } else { // Valhalla
2967 
2968       __ pop(atos);
2969       if (is_static) {
<span class="line-modified">2970         Label notFlattenable;</span>
<span class="line-modified">2971          __ test_field_is_not_flattenable(flags2, r8 /* temp */, notFlattenable);</span>
2972          __ null_check(r0);
<span class="line-modified">2973          __ bind(notFlattenable);</span>
2974          do_oop_store(_masm, field, r0, IN_HEAP);
2975          __ b(Done);
2976       } else {
<span class="line-modified">2977         Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;</span>
<span class="line-modified">2978         __ test_field_is_flattenable(flags2, r8 /*temp*/, isFlattenable);</span>
<span class="line-modified">2979         // Not flattenable case, covers not flattenable values and objects</span>
2980         pop_and_check_object(obj);
2981         // Store into the field
2982         do_oop_store(_masm, field, r0, IN_HEAP);
<span class="line-modified">2983         __ bind(rewriteNotFlattenable);</span>
2984         if (rc == may_rewrite) {
2985           patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);
2986         }
2987         __ b(Done);
<span class="line-modified">2988         // Implementation of the flattenable semantic</span>
<span class="line-modified">2989         __ bind(isFlattenable);</span>
2990         __ null_check(r0);
<span class="line-modified">2991         __ test_field_is_flattened(flags2, r8 /*temp*/, isFlattened);</span>
<span class="line-modified">2992         // Not flattened case</span>
2993         pop_and_check_object(obj);
2994         // Store into the field
2995         do_oop_store(_masm, field, r0, IN_HEAP);
<span class="line-modified">2996         __ b(rewriteFlattenable);</span>
2997         __ bind(isFlattened);
2998         pop_and_check_object(obj);
2999         call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_flattened_value), r0, off, obj);
<span class="line-modified">3000         __ bind(rewriteFlattenable);</span>
3001         if (rc == may_rewrite) {
3002           patch_bytecode(Bytecodes::_fast_qputfield, bc, r19, true, byte_no);
3003         }
3004         __ b(Done);
3005       }
3006      }  // Valhalla
3007   }
3008 
3009   __ bind(notObj);
3010   __ cmp(flags, (u1)itos);
3011   __ br(Assembler::NE, notInt);
3012 
3013   // itos
3014   {
3015     __ pop(itos);
3016     if (!is_static) pop_and_check_object(obj);
3017     __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);
3018     if (rc == may_rewrite) {
3019       patch_bytecode(Bytecodes::_fast_iputfield, bc, r1, true, byte_no);
3020     }
</pre>
<hr />
<pre>
3315   // 8179954: We need to make sure that the code generated for
3316   // volatile accesses forms a sequentially-consistent set of
3317   // operations when combined with STLR and LDAR.  Without a leading
3318   // membar it&#39;s possible for a simple Dekker test to fail if loads
3319   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
3320   // the stores in one method and we interpret the loads in another.
3321   if (!is_c1_or_interpreter_only()) {
3322     Label notVolatile;
3323     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3324     __ membar(MacroAssembler::AnyAny);
3325     __ bind(notVolatile);
3326   }
3327 
3328   // access field
3329   switch (bytecode()) {
3330   case Bytecodes::_fast_qgetfield:
3331     {
3332        Label isFlattened, isInitialized, Done;
3333        // FIXME: We don&#39;t need to reload registers multiple times, but stay close to x86 code
3334        __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
<span class="line-modified">3335        __ test_field_is_flattened(r9, r8 /* temp */, isFlattened);</span>
3336         // Non-flattened field case
3337         __ mov(r9, r0);
3338         __ load_heap_oop(r0, field);
3339         __ cbnz(r0, isInitialized);
3340           __ mov(r0, r9);
3341           __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
3342           __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
3343           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), r0, r9);
3344         __ bind(isInitialized);
3345         __ verify_oop(r0);
3346         __ b(Done);
3347       __ bind(isFlattened);
3348         __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
3349         __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
3350         __ ldr(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
3351         call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), r0, r9, r3);
3352         __ verify_oop(r0);
3353       __ bind(Done);
3354     }
3355     break;
</pre>
</td>
<td>
<hr />
<pre>
2650     // use btos rewriting, no truncating to t/f bit is needed for getfield.
2651     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2652   }
2653   __ b(Done);
2654 
2655   __ bind(notBool);
2656   __ cmp(flags, (u1)atos);
2657   __ br(Assembler::NE, notObj);
2658   // atos
2659   if (!EnableValhalla) {
2660     do_oop_load(_masm, field, r0, IN_HEAP);
2661     __ push(atos);
2662     if (rc == may_rewrite) {
2663       patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2664     }
2665     __ b(Done);
2666   } else { // Valhalla
2667 
2668     if (is_static) {
2669       __ load_heap_oop(r0, field);
<span class="line-modified">2670       Label is_inline, isUninitialized;</span>
2671       // Issue below if the static field has not been initialized yet
<span class="line-modified">2672       __ test_field_is_inline_type(raw_flags, r8 /*temp*/, is_inline);</span>
<span class="line-modified">2673         // Not inline case</span>
2674         __ push(atos);
2675         __ b(Done);
<span class="line-modified">2676       // Inline case, must not return null even if uninitialized</span>
<span class="line-modified">2677       __ bind(is_inline);</span>
2678         __ cbz(r0, isUninitialized);
2679           __ push(atos);
2680           __ b(Done);
2681         __ bind(isUninitialized);
2682           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2683           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_value_field), obj, raw_flags);
2684           __ verify_oop(r0);
2685           __ push(atos);
2686           __ b(Done);
2687     } else {
<span class="line-modified">2688       Label isFlattened, isInitialized, is_inline, rewrite_inline;</span>
<span class="line-modified">2689         __ test_field_is_inline_type(raw_flags, r8 /*temp*/, is_inline);</span>
<span class="line-modified">2690         // Non-inline field case</span>
2691         __ load_heap_oop(r0, field);
2692         __ push(atos);
2693         if (rc == may_rewrite) {
2694           patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2695         }
2696         __ b(Done);
<span class="line-modified">2697       __ bind(is_inline);</span>
<span class="line-modified">2698         __ test_field_is_allocated_inline(raw_flags, r8 /* temp */, isFlattened);</span>
<span class="line-modified">2699          // Non-inline field case</span>
2700           __ load_heap_oop(r0, field);
2701           __ cbnz(r0, isInitialized);
2702             __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2703             __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), obj, raw_flags);
2704           __ bind(isInitialized);
2705           __ verify_oop(r0);
2706           __ push(atos);
<span class="line-modified">2707           __ b(rewrite_inline);</span>
2708         __ bind(isFlattened);
2709           __ ldr(r10, Address(cache, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
2710           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
2711           call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10);
2712           __ verify_oop(r0);
2713           __ push(atos);
<span class="line-modified">2714       __ bind(rewrite_inline);</span>
2715       if (rc == may_rewrite) {
2716          patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);
2717       }
2718       __ b(Done);
2719     }
2720   }
2721 
2722   __ bind(notObj);
2723   __ cmp(flags, (u1)itos);
2724   __ br(Assembler::NE, notInt);
2725   // itos
2726   __ access_load_at(T_INT, IN_HEAP, r0, field, noreg, noreg);
2727   __ push(itos);
2728   // Rewrite bytecode to be faster
2729   if (rc == may_rewrite) {
2730     patch_bytecode(Bytecodes::_fast_igetfield, bc, r1);
2731   }
2732   __ b(Done);
2733 
2734   __ bind(notInt);
</pre>
<hr />
<pre>
2950 
2951   __ bind(notBool);
2952   __ cmp(flags, (u1)atos);
2953   __ br(Assembler::NE, notObj);
2954 
2955   // atos
2956   {
2957      if (!EnableValhalla) {
2958       __ pop(atos);
2959       if (!is_static) pop_and_check_object(obj);
2960       // Store into the field
2961       do_oop_store(_masm, field, r0, IN_HEAP);
2962       if (rc == may_rewrite) {
2963         patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
2964       }
2965       __ b(Done);
2966      } else { // Valhalla
2967 
2968       __ pop(atos);
2969       if (is_static) {
<span class="line-modified">2970         Label not_inline;</span>
<span class="line-modified">2971          __ test_field_is_not_inline_type(flags2, r8 /* temp */, not_inline);</span>
2972          __ null_check(r0);
<span class="line-modified">2973          __ bind(not_inline);</span>
2974          do_oop_store(_masm, field, r0, IN_HEAP);
2975          __ b(Done);
2976       } else {
<span class="line-modified">2977         Label is_inline, isFlattened, rewrite_not_inline, rewrite_inline;</span>
<span class="line-modified">2978         __ test_field_is_inline_type(flags2, r8 /*temp*/, is_inline);</span>
<span class="line-modified">2979         // Not inline case</span>
2980         pop_and_check_object(obj);
2981         // Store into the field
2982         do_oop_store(_masm, field, r0, IN_HEAP);
<span class="line-modified">2983         __ bind(rewrite_not_inline);</span>
2984         if (rc == may_rewrite) {
2985           patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);
2986         }
2987         __ b(Done);
<span class="line-modified">2988         // Implementation of the inline semantic</span>
<span class="line-modified">2989         __ bind(is_inline);</span>
2990         __ null_check(r0);
<span class="line-modified">2991         __ test_field_is_allocated_inline(flags2, r8 /*temp*/, isFlattened);</span>
<span class="line-modified">2992         // Not inline case</span>
2993         pop_and_check_object(obj);
2994         // Store into the field
2995         do_oop_store(_masm, field, r0, IN_HEAP);
<span class="line-modified">2996         __ b(rewrite_inline);</span>
2997         __ bind(isFlattened);
2998         pop_and_check_object(obj);
2999         call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_flattened_value), r0, off, obj);
<span class="line-modified">3000         __ bind(rewrite_inline);</span>
3001         if (rc == may_rewrite) {
3002           patch_bytecode(Bytecodes::_fast_qputfield, bc, r19, true, byte_no);
3003         }
3004         __ b(Done);
3005       }
3006      }  // Valhalla
3007   }
3008 
3009   __ bind(notObj);
3010   __ cmp(flags, (u1)itos);
3011   __ br(Assembler::NE, notInt);
3012 
3013   // itos
3014   {
3015     __ pop(itos);
3016     if (!is_static) pop_and_check_object(obj);
3017     __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);
3018     if (rc == may_rewrite) {
3019       patch_bytecode(Bytecodes::_fast_iputfield, bc, r1, true, byte_no);
3020     }
</pre>
<hr />
<pre>
3315   // 8179954: We need to make sure that the code generated for
3316   // volatile accesses forms a sequentially-consistent set of
3317   // operations when combined with STLR and LDAR.  Without a leading
3318   // membar it&#39;s possible for a simple Dekker test to fail if loads
3319   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
3320   // the stores in one method and we interpret the loads in another.
3321   if (!is_c1_or_interpreter_only()) {
3322     Label notVolatile;
3323     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3324     __ membar(MacroAssembler::AnyAny);
3325     __ bind(notVolatile);
3326   }
3327 
3328   // access field
3329   switch (bytecode()) {
3330   case Bytecodes::_fast_qgetfield:
3331     {
3332        Label isFlattened, isInitialized, Done;
3333        // FIXME: We don&#39;t need to reload registers multiple times, but stay close to x86 code
3334        __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
<span class="line-modified">3335        __ test_field_is_allocated_inline(r9, r8 /* temp */, isFlattened);</span>
3336         // Non-flattened field case
3337         __ mov(r9, r0);
3338         __ load_heap_oop(r0, field);
3339         __ cbnz(r0, isInitialized);
3340           __ mov(r0, r9);
3341           __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
3342           __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
3343           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), r0, r9);
3344         __ bind(isInitialized);
3345         __ verify_oop(r0);
3346         __ b(Done);
3347       __ bind(isFlattened);
3348         __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
3349         __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
3350         __ ldr(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
3351         call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), r0, r9, r3);
3352         __ verify_oop(r0);
3353       __ bind(Done);
3354     }
3355     break;
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../x86/interp_masm_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>