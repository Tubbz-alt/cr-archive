<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/classfile/classFileParser.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../ci/ciReplay.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classFileParser.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/classfile/classFileParser.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1501                                             CHECK);
1502   parsed_annotations-&gt;set_field_annotations(a);
1503   a = assemble_annotations(runtime_visible_type_annotations,
1504                            runtime_visible_type_annotations_length,
1505                            runtime_invisible_type_annotations,
1506                            runtime_invisible_type_annotations_length,
1507                            CHECK);
1508   parsed_annotations-&gt;set_field_type_annotations(a);
1509   return;
1510 }
1511 
1512 
1513 // Field allocation types. Used for computing field offsets.
1514 
1515 enum FieldAllocationType {
1516   STATIC_OOP,           // Oops
1517   STATIC_BYTE,          // Boolean, Byte, char
1518   STATIC_SHORT,         // shorts
1519   STATIC_WORD,          // ints
1520   STATIC_DOUBLE,        // aligned long or double
<span class="line-modified">1521   STATIC_FLATTENABLE,   // flattenable field</span>
1522   NONSTATIC_OOP,
1523   NONSTATIC_BYTE,
1524   NONSTATIC_SHORT,
1525   NONSTATIC_WORD,
1526   NONSTATIC_DOUBLE,
<span class="line-modified">1527   NONSTATIC_FLATTENABLE,</span>
1528   MAX_FIELD_ALLOCATION_TYPE,
1529   BAD_ALLOCATION_TYPE = -1
1530 };
1531 
1532 static FieldAllocationType _basic_type_to_atype[2 * (T_CONFLICT + 1)] = {
1533   BAD_ALLOCATION_TYPE, // 0
1534   BAD_ALLOCATION_TYPE, // 1
1535   BAD_ALLOCATION_TYPE, // 2
1536   BAD_ALLOCATION_TYPE, // 3
1537   NONSTATIC_BYTE ,     // T_BOOLEAN     =  4,
1538   NONSTATIC_SHORT,     // T_CHAR        =  5,
1539   NONSTATIC_WORD,      // T_FLOAT       =  6,
1540   NONSTATIC_DOUBLE,    // T_DOUBLE      =  7,
1541   NONSTATIC_BYTE,      // T_BYTE        =  8,
1542   NONSTATIC_SHORT,     // T_SHORT       =  9,
1543   NONSTATIC_WORD,      // T_INT         = 10,
1544   NONSTATIC_DOUBLE,    // T_LONG        = 11,
1545   NONSTATIC_OOP,       // T_OBJECT      = 12,
1546   NONSTATIC_OOP,       // T_ARRAY       = 13,
1547   NONSTATIC_OOP,       // T_VALUETYPE   = 14,
</pre>
<hr />
<pre>
1557   BAD_ALLOCATION_TYPE, // 3
1558   STATIC_BYTE ,        // T_BOOLEAN     =  4,
1559   STATIC_SHORT,        // T_CHAR        =  5,
1560   STATIC_WORD,         // T_FLOAT       =  6,
1561   STATIC_DOUBLE,       // T_DOUBLE      =  7,
1562   STATIC_BYTE,         // T_BYTE        =  8,
1563   STATIC_SHORT,        // T_SHORT       =  9,
1564   STATIC_WORD,         // T_INT         = 10,
1565   STATIC_DOUBLE,       // T_LONG        = 11,
1566   STATIC_OOP,          // T_OBJECT      = 12,
1567   STATIC_OOP,          // T_ARRAY       = 13,
1568   STATIC_OOP,          // T_VALUETYPE   = 14,
1569   BAD_ALLOCATION_TYPE, // T_VOID        = 15,
1570   BAD_ALLOCATION_TYPE, // T_ADDRESS     = 16,
1571   BAD_ALLOCATION_TYPE, // T_NARROWOOP   = 17,
1572   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
1573   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
1574   BAD_ALLOCATION_TYPE, // T_CONFLICT    = 20
1575 };
1576 
<span class="line-modified">1577 static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_flattenable) {</span>
1578   assert(type &gt;= T_BOOLEAN &amp;&amp; type &lt; T_VOID, &quot;only allowable values&quot;);
1579   FieldAllocationType result = _basic_type_to_atype[type + (is_static ? (T_CONFLICT + 1) : 0)];
1580   assert(result != BAD_ALLOCATION_TYPE, &quot;bad type&quot;);
<span class="line-modified">1581   if (is_flattenable) {</span>
<span class="line-modified">1582     result = is_static ? STATIC_FLATTENABLE : NONSTATIC_FLATTENABLE;</span>
1583   }
1584   return result;
1585 }
1586 
1587 class ClassFileParser::FieldAllocationCount : public ResourceObj {
1588  public:
1589   u2 count[MAX_FIELD_ALLOCATION_TYPE];
1590 
1591   FieldAllocationCount() {
1592     for (int i = 0; i &lt; MAX_FIELD_ALLOCATION_TYPE; i++) {
1593       count[i] = 0;
1594     }
1595   }
1596 
<span class="line-modified">1597   FieldAllocationType update(bool is_static, BasicType type, bool is_flattenable) {</span>
<span class="line-modified">1598     FieldAllocationType atype = basic_type_to_atype(is_static, type, is_flattenable);</span>
1599     if (atype != BAD_ALLOCATION_TYPE) {
1600       // Make sure there is no overflow with injected fields.
1601       assert(count[atype] &lt; 0xFFFF, &quot;More than 65535 fields&quot;);
1602       count[atype]++;
1603     }
1604     return atype;
1605   }
1606 };
1607 
1608 // Side-effects: populates the _fields, _fields_annotations,
1609 // _fields_type_annotations fields
1610 void ClassFileParser::parse_fields(const ClassFileStream* const cfs,
1611                                    bool is_interface,
1612                                    bool is_inline_type,
1613                                    FieldAllocationCount* const fac,
1614                                    ConstantPool* cp,
1615                                    const int cp_size,
1616                                    u2* const java_fields_count_ptr,
1617                                    TRAPS) {
1618 
</pre>
<hr />
<pre>
1674     jint recognized_modifiers = JVM_RECOGNIZED_FIELD_MODIFIERS;
1675 
1676     const jint flags = cfs-&gt;get_u2_fast() &amp; recognized_modifiers;
1677     verify_legal_field_modifiers(flags, is_interface, is_inline_type, CHECK);
1678     AccessFlags access_flags;
1679     access_flags.set_flags(flags);
1680 
1681     const u2 name_index = cfs-&gt;get_u2_fast();
1682     check_property(valid_symbol_at(name_index),
1683       &quot;Invalid constant pool index %u for field name in class file %s&quot;,
1684       name_index, CHECK);
1685     const Symbol* const name = cp-&gt;symbol_at(name_index);
1686     verify_legal_field_name(name, CHECK);
1687 
1688     const u2 signature_index = cfs-&gt;get_u2_fast();
1689     check_property(valid_symbol_at(signature_index),
1690       &quot;Invalid constant pool index %u for field signature in class file %s&quot;,
1691       signature_index, CHECK);
1692     const Symbol* const sig = cp-&gt;symbol_at(signature_index);
1693     verify_legal_field_signature(name, sig, CHECK);
<span class="line-removed">1694     assert(!access_flags.is_flattenable(), &quot;ACC_FLATTENABLE should have been filtered out&quot;);</span>
<span class="line-removed">1695     if (sig-&gt;is_Q_signature()) {</span>
<span class="line-removed">1696       // assert(_major_version &gt;= CONSTANT_CLASS_DESCRIPTORS, &quot;Q-descriptors are only supported in recent classfiles&quot;);</span>
<span class="line-removed">1697       access_flags.set_is_flattenable();</span>
<span class="line-removed">1698     }</span>
<span class="line-removed">1699     if (access_flags.is_flattenable()) {</span>
<span class="line-removed">1700       // Array flattenability cannot be specified.  Arrays of value classes are</span>
<span class="line-removed">1701       // are always flattenable.  Arrays of other classes are not flattenable.</span>
<span class="line-removed">1702       if (sig-&gt;utf8_length() &gt; 1 &amp;&amp; sig-&gt;char_at(0) == &#39;[&#39;) {</span>
<span class="line-removed">1703         classfile_parse_error(</span>
<span class="line-removed">1704             &quot;Field \&quot;%s\&quot; with signature \&quot;%s\&quot; in class file %s is invalid.&quot;</span>
<span class="line-removed">1705             &quot; ACC_FLATTENABLE cannot be specified for an array&quot;,</span>
<span class="line-removed">1706             name-&gt;as_C_string(), sig-&gt;as_klass_external_name(), CHECK);</span>
<span class="line-removed">1707       }</span>
<span class="line-removed">1708       _has_flattenable_fields = true;</span>
<span class="line-removed">1709     }</span>
1710     if (!access_flags.is_static()) instance_fields_count++;
1711 
1712     u2 constantvalue_index = 0;
1713     bool is_synthetic = false;
1714     u2 generic_signature_index = 0;
1715     const bool is_static = access_flags.is_static();
1716     FieldAnnotationCollector parsed_annotations(_loader_data);
1717 
1718     const u2 attributes_count = cfs-&gt;get_u2_fast();
1719     if (attributes_count &gt; 0) {
1720       parse_field_attributes(cfs,
1721                              attributes_count,
1722                              is_static,
1723                              signature_index,
1724                              &amp;constantvalue_index,
1725                              &amp;is_synthetic,
1726                              &amp;generic_signature_index,
1727                              &amp;parsed_annotations,
1728                              CHECK);
1729 
</pre>
<hr />
<pre>
1750 
1751       if (is_synthetic) {
1752         access_flags.set_is_synthetic();
1753       }
1754       if (generic_signature_index != 0) {
1755         access_flags.set_field_has_generic_signature();
1756         fa[generic_signature_slot] = generic_signature_index;
1757         generic_signature_slot ++;
1758         num_generic_signature ++;
1759       }
1760     }
1761 
1762     FieldInfo* const field = FieldInfo::from_field_array(fa, n);
1763     field-&gt;initialize(access_flags.as_short(),
1764                       name_index,
1765                       signature_index,
1766                       constantvalue_index);
1767     const BasicType type = cp-&gt;basic_type_for_signature_at(signature_index);
1768 
1769     // Remember how many oops we encountered and compute allocation type
<span class="line-modified">1770     const FieldAllocationType atype = fac-&gt;update(is_static, type, access_flags.is_flattenable());</span>
1771     field-&gt;set_allocation_type(atype);
1772 
1773     // After field is initialized with type, we can augment it with aux info
1774     if (parsed_annotations.has_any_annotations()) {
1775       parsed_annotations.apply_to(field);
1776       if (field-&gt;is_contended()) {
1777         _has_contended_fields = true;
1778       }
1779     }
1780   }
1781 
1782   int index = length;
1783   if (num_injected != 0) {
1784     for (int n = 0; n &lt; num_injected; n++) {
1785       // Check for duplicates
1786       if (injected[n].may_be_java) {
1787         const Symbol* const name      = injected[n].name();
1788         const Symbol* const signature = injected[n].signature();
1789         bool duplicate = false;
1790         for (int i = 0; i &lt; length; i++) {
</pre>
<hr />
<pre>
4388   //
4389   // We ignore static fields, because @Contended is not supported for them.
4390   // The layout code below will also ignore the static fields.
4391   int nonstatic_contended_count = 0;
4392   FieldAllocationCount fac_contended;
4393   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
4394     FieldAllocationType atype = (FieldAllocationType) fs.allocation_type();
4395     if (fs.is_contended()) {
4396       fac_contended.count[atype]++;
4397       if (!fs.access_flags().is_static()) {
4398         nonstatic_contended_count++;
4399       }
4400     }
4401   }
4402 
4403 
4404   // Calculate the starting byte offsets
4405   int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();
4406   // Inline types in static fields are not embedded, they are handled with oops
4407   int next_static_double_offset = next_static_oop_offset +
<span class="line-modified">4408                                   ((fac-&gt;count[STATIC_OOP] + fac-&gt;count[STATIC_FLATTENABLE]) * heapOopSize);</span>
4409   if (fac-&gt;count[STATIC_DOUBLE]) {
4410     next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);
4411   }
4412 
4413   int next_static_word_offset   = next_static_double_offset +
4414                                     ((fac-&gt;count[STATIC_DOUBLE]) * BytesPerLong);
4415   int next_static_short_offset  = next_static_word_offset +
4416                                     ((fac-&gt;count[STATIC_WORD]) * BytesPerInt);
4417   int next_static_byte_offset   = next_static_short_offset +
4418                                   ((fac-&gt;count[STATIC_SHORT]) * BytesPerShort);
4419 
4420   int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +
4421                                 nonstatic_field_size * heapOopSize;
4422 
4423   // First field of inline types is aligned on a long boundary in order to ease
4424   // in-lining of inline types (with header removal) in packed arrays and
<span class="line-modified">4425   // flatten inline types</span>
4426   int initial_inline_type_padding = 0;
4427   if (is_inline_type()) {
4428     int old = nonstatic_fields_start;
4429     nonstatic_fields_start = align_up(nonstatic_fields_start, BytesPerLong);
4430     initial_inline_type_padding = nonstatic_fields_start - old;
4431   }
4432 
4433   int next_nonstatic_field_offset = nonstatic_fields_start;
4434 
4435   const bool is_contended_class     = parsed_annotations-&gt;is_contended();
4436 
4437   // Class is contended, pad before all the fields
4438   if (is_contended_class) {
4439     next_nonstatic_field_offset += ContendedPaddingWidth;
4440   }
4441 
4442   // Temporary inline types restrictions
4443   if (is_inline_type()) {
4444     if (is_contended_class) {
4445       throwInlineTypeLimitation(THREAD_AND_LOCATION, &quot;Inline Types do not support @Contended annotation yet&quot;);
4446       return;
4447     }
4448   }
4449 
4450   // Compute the non-contended fields count.
4451   // The packing code below relies on these counts to determine if some field
4452   // can be squeezed into the alignment gap. Contended fields are obviously
4453   // exempt from that.
4454   unsigned int nonstatic_double_count = fac-&gt;count[NONSTATIC_DOUBLE] - fac_contended.count[NONSTATIC_DOUBLE];
4455   unsigned int nonstatic_word_count   = fac-&gt;count[NONSTATIC_WORD]   - fac_contended.count[NONSTATIC_WORD];
4456   unsigned int nonstatic_short_count  = fac-&gt;count[NONSTATIC_SHORT]  - fac_contended.count[NONSTATIC_SHORT];
4457   unsigned int nonstatic_byte_count   = fac-&gt;count[NONSTATIC_BYTE]   - fac_contended.count[NONSTATIC_BYTE];
4458   unsigned int nonstatic_oop_count    = fac-&gt;count[NONSTATIC_OOP]    - fac_contended.count[NONSTATIC_OOP];
4459 
4460   int static_inline_type_count = 0;
4461   int nonstatic_inline_type_count = 0;
4462   int* nonstatic_inline_type_indexes = NULL;
4463   Klass** nonstatic_inline_type_klasses = NULL;
4464   unsigned int inline_type_oop_map_count = 0;
<span class="line-modified">4465   int not_flattened_inline_types = 0;</span>
4466   int not_atomic_inline_types = 0;
4467 
<span class="line-modified">4468   int max_nonstatic_inline_type = fac-&gt;count[NONSTATIC_FLATTENABLE] + 1;</span>
4469 
4470   nonstatic_inline_type_indexes = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, int,
4471                                                                max_nonstatic_inline_type);
4472   for (int i = 0; i &lt; max_nonstatic_inline_type; i++) {
4473     nonstatic_inline_type_indexes[i] = -1;
4474   }
4475   nonstatic_inline_type_klasses = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, Klass*,
4476                                                                max_nonstatic_inline_type);
4477 
4478   for (AllFieldStream fs(_fields, _cp); !fs.done(); fs.next()) {
<span class="line-modified">4479     if (fs.allocation_type() == STATIC_FLATTENABLE) {</span>
4480       ResourceMark rm;
4481       if (!fs.signature()-&gt;is_Q_signature()) {
4482         THROW(vmSymbols::java_lang_ClassFormatError());
4483       }
4484       static_inline_type_count++;
<span class="line-modified">4485     } else if (fs.allocation_type() == NONSTATIC_FLATTENABLE) {</span>
<span class="line-modified">4486       // Pre-resolve the flattenable field and check for inline type circularity issues.</span>
4487       ResourceMark rm;
4488       if (!fs.signature()-&gt;is_Q_signature()) {
4489         THROW(vmSymbols::java_lang_ClassFormatError());
4490       }
4491       Klass* klass =
<span class="line-modified">4492         SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,</span>
4493                                                             Handle(THREAD, _loader_data-&gt;class_loader()),
4494                                                             _protection_domain, true, CHECK);
4495       assert(klass != NULL, &quot;Sanity check&quot;);
4496       if (!klass-&gt;access_flags().is_inline_type()) {
4497         THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
4498       }
4499       ValueKlass* vk = ValueKlass::cast(klass);
4500       // Conditions to apply flattening or not should be defined in a single place
<span class="line-modified">4501       bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;</span>
4502                                  (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
<span class="line-modified">4503       bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();</span>
<span class="line-modified">4504       bool too_volatile_to_flatten = fs.access_flags().is_volatile();</span>
4505       if (vk-&gt;is_naturally_atomic()) {
<span class="line-modified">4506         too_atomic_to_flatten = false;</span>
<span class="line-modified">4507         //too_volatile_to_flatten = false; //FIXME</span>
<span class="line-modified">4508         // volatile fields are currently never flattened, this could change in the future</span>
4509       }
<span class="line-modified">4510       if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {</span>
4511         nonstatic_inline_type_indexes[nonstatic_inline_type_count] = fs.index();
4512         nonstatic_inline_type_klasses[nonstatic_inline_type_count] = klass;
4513         nonstatic_inline_type_count++;
4514 
4515         ValueKlass* vklass = ValueKlass::cast(klass);
4516         if (vklass-&gt;contains_oops()) {
4517           inline_type_oop_map_count += vklass-&gt;nonstatic_oop_map_count();
4518         }
<span class="line-modified">4519         fs.set_flattened(true);</span>
4520         if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
4521           not_atomic_inline_types++;
4522         }
4523       } else {
<span class="line-modified">4524         not_flattened_inline_types++;</span>
<span class="line-modified">4525         fs.set_flattened(false);</span>
4526       }
4527     }
4528   }
4529 
<span class="line-modified">4530   // Adjusting non_static_oop_count to take into account not flattened inline types;</span>
<span class="line-modified">4531   nonstatic_oop_count += not_flattened_inline_types;</span>
4532 
4533   // Total non-static fields count, including every contended field
4534   unsigned int nonstatic_fields_count = fac-&gt;count[NONSTATIC_DOUBLE] + fac-&gt;count[NONSTATIC_WORD] +
4535                                         fac-&gt;count[NONSTATIC_SHORT] + fac-&gt;count[NONSTATIC_BYTE] +
<span class="line-modified">4536                                         fac-&gt;count[NONSTATIC_OOP] + fac-&gt;count[NONSTATIC_FLATTENABLE];</span>
4537 
4538   const bool super_has_nonstatic_fields =
4539           (_super_klass != NULL &amp;&amp; _super_klass-&gt;has_nonstatic_fields());
4540   const bool has_nonstatic_fields =
4541     super_has_nonstatic_fields || (nonstatic_fields_count != 0);
4542   const bool has_nonstatic_value_fields = nonstatic_inline_type_count &gt; 0;
4543 
4544   if (is_inline_type() &amp;&amp; (!has_nonstatic_fields)) {
4545     // There are a number of fixes required throughout the type system and JIT
4546     throwInlineTypeLimitation(THREAD_AND_LOCATION, &quot;Inline Types do not support zero instance size yet&quot;);
4547     return;
4548   }
4549 
4550   // Prepare list of oops for oop map generation.
4551   //
4552   // &quot;offset&quot; and &quot;count&quot; lists are describing the set of contiguous oop
4553   // regions. offset[i] is the start of the i-th region, which then has
4554   // count[i] oops following. Before we know how many regions are required,
4555   // we pessimistically allocate the maps to fit all the oops into the
4556   // distinct regions.
4557   //
4558   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
4559   int max_oop_map_count =
4560       super_oop_map_count +
4561       fac-&gt;count[NONSTATIC_OOP] +
4562       inline_type_oop_map_count +
<span class="line-modified">4563       not_flattened_inline_types;</span>
4564 
4565   OopMapBlocksBuilder* nonstatic_oop_maps = new OopMapBlocksBuilder(max_oop_map_count);
4566   if (super_oop_map_count &gt; 0) {
4567     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
4568                                                     _super_klass-&gt;nonstatic_oop_map_count());
4569   }
4570 
4571   int first_nonstatic_oop_offset = 0; // will be set for first oop field
4572 
4573   bool compact_fields  = true;
4574   bool allocate_oops_first = false;
4575 
4576   int next_nonstatic_oop_offset = 0;
4577   int next_nonstatic_double_offset = 0;
4578 
4579   // Rearrange fields for a given allocation style
4580   if (allocate_oops_first) {
4581     // Fields order: oops, longs/doubles, ints, shorts/chars, bytes, padded fields
4582     next_nonstatic_oop_offset    = next_nonstatic_field_offset;
4583     next_nonstatic_double_offset = next_nonstatic_oop_offset +
</pre>
<hr />
<pre>
4665   next_nonstatic_inline_type_offset = align_up(next_nonstatic_padded_offset, BytesPerLong);
4666   int next_inline_type_index = 0;
4667 
4668   // Iterate over fields again and compute correct offsets.
4669   // The field allocation type was temporarily stored in the offset slot.
4670   // oop fields are located before non-oop fields (static and non-static).
4671   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
4672 
4673     // skip already laid out fields
4674     if (fs.is_offset_set()) continue;
4675 
4676     // contended instance fields are handled below
4677     if (fs.is_contended() &amp;&amp; !fs.access_flags().is_static()) continue;
4678 
4679     int real_offset = 0;
4680     const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();
4681 
4682     // pack the rest of the fields
4683     switch (atype) {
4684       // Inline types in static fields are handled with oops
<span class="line-modified">4685       case STATIC_FLATTENABLE:   // Fallthrough</span>
4686       case STATIC_OOP:
4687         real_offset = next_static_oop_offset;
4688         next_static_oop_offset += heapOopSize;
4689         break;
4690       case STATIC_BYTE:
4691         real_offset = next_static_byte_offset;
4692         next_static_byte_offset += 1;
4693         break;
4694       case STATIC_SHORT:
4695         real_offset = next_static_short_offset;
4696         next_static_short_offset += BytesPerShort;
4697         break;
4698       case STATIC_WORD:
4699         real_offset = next_static_word_offset;
4700         next_static_word_offset += BytesPerInt;
4701         break;
4702       case STATIC_DOUBLE:
4703         real_offset = next_static_double_offset;
4704         next_static_double_offset += BytesPerLong;
4705         break;
<span class="line-modified">4706       case NONSTATIC_FLATTENABLE:</span>
<span class="line-modified">4707         if (fs.is_flattened()) {</span>
4708           Klass* klass = nonstatic_inline_type_klasses[next_inline_type_index];
4709           assert(klass != NULL, &quot;Klass should have been loaded and resolved earlier&quot;);
4710           assert(klass-&gt;access_flags().is_inline_type(),&quot;Must be an inline type&quot;);
4711           ValueKlass* vklass = ValueKlass::cast(klass);
4712           real_offset = next_nonstatic_inline_type_offset;
4713           next_nonstatic_inline_type_offset += (vklass-&gt;size_helper()) * wordSize - vklass-&gt;first_field_offset();
4714           // aligning next inline type on a 64 bits boundary
4715           next_nonstatic_inline_type_offset = align_up(next_nonstatic_inline_type_offset, BytesPerLong);
4716           next_inline_type_index += 1;
4717 
4718           if (vklass-&gt;contains_oops()) { // add flatten oop maps
4719             int diff = real_offset - vklass-&gt;first_field_offset();
4720             const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
4721             const OopMapBlock* const last_map = map + vklass-&gt;nonstatic_oop_map_count();
4722             while (map &lt; last_map) {
4723               nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
4724               map++;
4725             }
4726           }
4727           break;
</pre>
<hr />
<pre>
4830 
4831           case NONSTATIC_SHORT:
4832             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerShort);
4833             real_offset = next_nonstatic_padded_offset;
4834             next_nonstatic_padded_offset += BytesPerShort;
4835             break;
4836 
4837           case NONSTATIC_WORD:
4838             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerInt);
4839             real_offset = next_nonstatic_padded_offset;
4840             next_nonstatic_padded_offset += BytesPerInt;
4841             break;
4842 
4843           case NONSTATIC_DOUBLE:
4844             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerLong);
4845             real_offset = next_nonstatic_padded_offset;
4846             next_nonstatic_padded_offset += BytesPerLong;
4847             break;
4848 
4849             // Inline types in static fields are handled with oops
<span class="line-modified">4850           case NONSTATIC_FLATTENABLE:</span>
4851             throwInlineTypeLimitation(THREAD_AND_LOCATION,
4852                                       &quot;@Contended annotation not supported for inline types yet&quot;, fs.name(), fs.signature());
4853             return;
4854 
4855           case NONSTATIC_OOP:
4856             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, heapOopSize);
4857             real_offset = next_nonstatic_padded_offset;
4858             next_nonstatic_padded_offset += heapOopSize;
4859             nonstatic_oop_maps-&gt;add(real_offset, 1);
4860             break;
4861 
4862           default:
4863             ShouldNotReachHere();
4864         }
4865 
4866         if (fs.contended_group() == 0) {
4867           // Contended group defines the equivalence class over the fields:
4868           // the fields within the same contended group are not inter-padded.
4869           // The only exception is default group, which does not incur the
4870           // equivalence, and so requires intra-padding.
</pre>
<hr />
<pre>
4944           instance_size,
4945           nonstatic_fields_start,
4946           nonstatic_fields_end,
4947           static_fields_end);
4948     nonstatic_oop_maps-&gt;print_on(tty);
4949     tty-&gt;print(&quot;\n&quot;);
4950     tty-&gt;print_cr(&quot;Instance size = %d&quot;, instance_size);
4951     tty-&gt;print_cr(&quot;Nonstatic_field_size = %d&quot;, nonstatic_field_size);
4952     tty-&gt;print_cr(&quot;Static_field_size = %d&quot;, static_field_size);
4953     tty-&gt;print_cr(&quot;Has nonstatic fields = %d&quot;, has_nonstatic_fields);
4954     tty-&gt;print_cr(&quot;---&quot;);
4955   }
4956 
4957 #endif
4958   // Pass back information needed for InstanceKlass creation
4959   info-&gt;oop_map_blocks = nonstatic_oop_maps;
4960   info-&gt;_instance_size = instance_size;
4961   info-&gt;_static_field_size = static_field_size;
4962   info-&gt;_nonstatic_field_size = nonstatic_field_size;
4963   info-&gt;_has_nonstatic_fields = has_nonstatic_fields;

4964 
4965   // An inline type is naturally atomic if it has just one field, and
4966   // that field is simple enough.
4967   info-&gt;_is_naturally_atomic = (is_inline_type() &amp;&amp;
4968                                 !super_has_nonstatic_fields &amp;&amp;
4969                                 (nonstatic_fields_count &lt;= 1) &amp;&amp;
4970                                 (not_atomic_inline_types == 0) &amp;&amp;
4971                                 (nonstatic_contended_count == 0));
4972   // This may be too restrictive, since if all the fields fit in 64
4973   // bits we could make the decision to align instances of this class
4974   // to 64-bit boundaries, and load and store them as single words.
4975   // And on machines which supported larger atomics we could similarly
4976   // allow larger values to be atomic, if properly aligned.
4977 }
4978 
4979 void ClassFileParser::set_precomputed_flags(InstanceKlass* ik) {
4980   assert(ik != NULL, &quot;invariant&quot;);
4981 
4982   const Klass* const super = ik-&gt;super();
4983 
</pre>
<hr />
<pre>
6261 
6262   // Not yet: supers are done below to support the new subtype-checking fields
6263   ik-&gt;set_nonstatic_field_size(_field_info-&gt;_nonstatic_field_size);
6264   ik-&gt;set_has_nonstatic_fields(_field_info-&gt;_has_nonstatic_fields);
6265   if (_field_info-&gt;_is_naturally_atomic &amp;&amp; ik-&gt;is_value()) {
6266     ik-&gt;set_is_naturally_atomic();
6267   }
6268   if (_is_empty_inline_type) {
6269     ik-&gt;set_is_empty_inline_type();
6270   }
6271 
6272   if (this-&gt;_invalid_inline_super) {
6273     ik-&gt;set_invalid_inline_super();
6274   }
6275 
6276   if (_has_injected_identityObject) {
6277     ik-&gt;set_has_injected_identityObject();
6278   }
6279 
6280   assert(_fac != NULL, &quot;invariant&quot;);
<span class="line-modified">6281   ik-&gt;set_static_oop_field_count(_fac-&gt;count[STATIC_OOP] + _fac-&gt;count[STATIC_FLATTENABLE]);</span>
6282 
6283   // this transfers ownership of a lot of arrays from
6284   // the parser onto the InstanceKlass*
6285   apply_parsed_class_metadata(ik, _java_fields_count, CHECK);
6286 
6287   // can only set dynamic nest-host after static nest information is set
6288   if (cl_inst_info.dynamic_nest_host() != NULL) {
6289     ik-&gt;set_nest_host(cl_inst_info.dynamic_nest_host(), THREAD);
6290   }
6291 
6292   // note that is not safe to use the fields in the parser from this point on
6293   assert(NULL == _cp, &quot;invariant&quot;);
6294   assert(NULL == _fields, &quot;invariant&quot;);
6295   assert(NULL == _methods, &quot;invariant&quot;);
6296   assert(NULL == _inner_classes, &quot;invariant&quot;);
6297   assert(NULL == _nest_members, &quot;invariant&quot;);
6298   assert(NULL == _combined_annotations, &quot;invariant&quot;);
6299   assert(NULL == _record_components, &quot;invariant&quot;);
6300   assert(NULL == _permitted_subclasses, &quot;invariant&quot;);
6301 
</pre>
<hr />
<pre>
6428   // Generate any default methods - default methods are public interface methods
6429   // that have a default implementation.  This is new with Java 8.
6430   if (_has_nonstatic_concrete_methods) {
6431     DefaultMethods::generate_default_methods(ik,
6432                                              _all_mirandas,
6433                                              CHECK);
6434   }
6435 
6436   // Add read edges to the unnamed modules of the bootstrap and app class loaders.
6437   if (changed_by_loadhook &amp;&amp; !module_handle.is_null() &amp;&amp; module_entry-&gt;is_named() &amp;&amp;
6438       !module_entry-&gt;has_default_read_edges()) {
6439     if (!module_entry-&gt;set_has_default_read_edges()) {
6440       // We won a potential race
6441       JvmtiExport::add_default_read_edges(module_handle, THREAD);
6442     }
6443   }
6444 
6445   int nfields = ik-&gt;java_fields_count();
6446   if (ik-&gt;is_value()) nfields++;
6447   for (int i = 0; i &lt; nfields; i++) {
<span class="line-modified">6448     if (ik-&gt;field_is_flattenable(i)) {</span>
6449       Symbol* klass_name = ik-&gt;field_signature(i)-&gt;fundamental_name(CHECK);
6450       // Inline classes for instance fields must have been pre-loaded
6451       // Inline classes for static fields might not have been loaded yet
6452       Klass* klass = SystemDictionary::find(klass_name,
6453           Handle(THREAD, ik-&gt;class_loader()),
6454           Handle(THREAD, ik-&gt;protection_domain()), CHECK);
6455       if (klass != NULL) {
6456         assert(klass-&gt;access_flags().is_inline_type(), &quot;Inline type expected&quot;);
6457         ik-&gt;set_value_field_klass(i, klass);
6458       }
6459       klass_name-&gt;decrement_refcount();
6460     } else
6461       if (is_inline_type() &amp;&amp; ((ik-&gt;field_access_flags(i) &amp; JVM_ACC_FIELD_INTERNAL) != 0)
6462         &amp;&amp; ((ik-&gt;field_access_flags(i) &amp; JVM_ACC_STATIC) != 0)) {
6463       ValueKlass::cast(ik)-&gt;set_default_value_offset(ik-&gt;field_offset(i));
6464     }
6465   }
6466 
6467   if (is_inline_type()) {
6468     ValueKlass* vk = ValueKlass::cast(ik);
</pre>
<hr />
<pre>
6654   _access_flags(),
6655   _pub_level(pub_level),
6656   _bad_constant_seen(0),
6657   _synthetic_flag(false),
6658   _sde_length(false),
6659   _sde_buffer(NULL),
6660   _sourcefile_index(0),
6661   _generic_signature_index(0),
6662   _major_version(0),
6663   _minor_version(0),
6664   _this_class_index(0),
6665   _super_class_index(0),
6666   _itfs_len(0),
6667   _java_fields_count(0),
6668   _need_verify(false),
6669   _relax_verify(false),
6670   _has_nonstatic_concrete_methods(false),
6671   _declares_nonstatic_concrete_methods(false),
6672   _has_final_method(false),
6673   _has_contended_fields(false),
<span class="line-modified">6674   _has_flattenable_fields(false),</span>
6675   _has_nonstatic_fields(false),
6676   _is_empty_inline_type(false),
6677   _is_naturally_atomic(false),
6678   _is_declared_atomic(false),
6679   _invalid_inline_super(false),
6680   _invalid_identity_super(false),
6681   _implements_identityObject(false),
6682   _has_injected_identityObject(false),
6683   _has_finalizer(false),
6684   _has_empty_finalizer(false),
6685   _has_vanilla_constructor(false),
6686   _max_bootstrap_specifier_index(-1) {
6687 
6688   _class_name = name != NULL ? name : vmSymbols::unknown_class_name();
6689   _class_name-&gt;increment_refcount();
6690 
6691   assert(THREAD-&gt;is_Java_thread(), &quot;invariant&quot;);
6692   assert(_loader_data != NULL, &quot;invariant&quot;);
6693   assert(stream != NULL, &quot;invariant&quot;);
6694   assert(_stream != NULL, &quot;invariant&quot;);
</pre>
<hr />
<pre>
7275                                                     &amp;_num_miranda_methods,
7276                                                     _all_mirandas,
7277                                                     _super_klass,
7278                                                     _methods,
7279                                                     _access_flags,
7280                                                     _major_version,
7281                                                     loader,
7282                                                     _class_name,
7283                                                     _local_interfaces,
7284                                                     CHECK);
7285 
7286   // Size of Java itable (in words)
7287   _itable_size = is_interface() ? 0 :
7288     klassItable::compute_itable_size(_transitive_interfaces);
7289 
7290   assert(_fac != NULL, &quot;invariant&quot;);
7291   assert(_parsed_annotations != NULL, &quot;invariant&quot;);
7292 
7293 
7294   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
<span class="line-modified">7295     if (fs.is_flattenable() &amp;&amp; !fs.access_flags().is_static()) {</span>
7296       // Pre-load value class
<span class="line-modified">7297       Klass* klass = SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,</span>
7298           Handle(THREAD, _loader_data-&gt;class_loader()),
7299           _protection_domain, true, CHECK);
7300       assert(klass != NULL, &quot;Sanity check&quot;);
<span class="line-modified">7301       assert(klass-&gt;access_flags().is_inline_type(), &quot;Inline type expected&quot;);</span>
<span class="line-removed">7302       _has_flattenable_fields = true;</span>
7303     }
7304   }
7305 
7306   _field_info = new FieldLayoutInfo();
7307   if (UseNewFieldLayout) {
7308     FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,
7309         _parsed_annotations-&gt;is_contended(), is_inline_type(),
7310         loader_data(), _protection_domain, _field_info);
7311     lb.build_layout(CHECK);
7312     if (is_inline_type()) {
7313       _alignment = lb.get_alignment();
7314       _first_field_offset = lb.get_first_field_offset();
7315       _exact_size_in_bytes = lb.get_exact_size_in_byte();
7316     }
7317   } else {
7318     layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);
7319   }

7320 
7321   // Compute reference type
7322   _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass-&gt;reference_type();
7323 }
7324 
7325 void ClassFileParser::set_klass(InstanceKlass* klass) {
7326 
7327 #ifdef ASSERT
7328   if (klass != NULL) {
7329     assert(NULL == _klass, &quot;leaking?&quot;);
7330   }
7331 #endif
7332 
7333   _klass = klass;
7334 }
7335 
7336 void ClassFileParser::set_klass_to_deallocate(InstanceKlass* klass) {
7337 
7338 #ifdef ASSERT
7339   if (klass != NULL) {
</pre>
</td>
<td>
<hr />
<pre>
1501                                             CHECK);
1502   parsed_annotations-&gt;set_field_annotations(a);
1503   a = assemble_annotations(runtime_visible_type_annotations,
1504                            runtime_visible_type_annotations_length,
1505                            runtime_invisible_type_annotations,
1506                            runtime_invisible_type_annotations_length,
1507                            CHECK);
1508   parsed_annotations-&gt;set_field_type_annotations(a);
1509   return;
1510 }
1511 
1512 
1513 // Field allocation types. Used for computing field offsets.
1514 
1515 enum FieldAllocationType {
1516   STATIC_OOP,           // Oops
1517   STATIC_BYTE,          // Boolean, Byte, char
1518   STATIC_SHORT,         // shorts
1519   STATIC_WORD,          // ints
1520   STATIC_DOUBLE,        // aligned long or double
<span class="line-modified">1521   STATIC_INLINE,        // inline type field</span>
1522   NONSTATIC_OOP,
1523   NONSTATIC_BYTE,
1524   NONSTATIC_SHORT,
1525   NONSTATIC_WORD,
1526   NONSTATIC_DOUBLE,
<span class="line-modified">1527   NONSTATIC_INLINE,</span>
1528   MAX_FIELD_ALLOCATION_TYPE,
1529   BAD_ALLOCATION_TYPE = -1
1530 };
1531 
1532 static FieldAllocationType _basic_type_to_atype[2 * (T_CONFLICT + 1)] = {
1533   BAD_ALLOCATION_TYPE, // 0
1534   BAD_ALLOCATION_TYPE, // 1
1535   BAD_ALLOCATION_TYPE, // 2
1536   BAD_ALLOCATION_TYPE, // 3
1537   NONSTATIC_BYTE ,     // T_BOOLEAN     =  4,
1538   NONSTATIC_SHORT,     // T_CHAR        =  5,
1539   NONSTATIC_WORD,      // T_FLOAT       =  6,
1540   NONSTATIC_DOUBLE,    // T_DOUBLE      =  7,
1541   NONSTATIC_BYTE,      // T_BYTE        =  8,
1542   NONSTATIC_SHORT,     // T_SHORT       =  9,
1543   NONSTATIC_WORD,      // T_INT         = 10,
1544   NONSTATIC_DOUBLE,    // T_LONG        = 11,
1545   NONSTATIC_OOP,       // T_OBJECT      = 12,
1546   NONSTATIC_OOP,       // T_ARRAY       = 13,
1547   NONSTATIC_OOP,       // T_VALUETYPE   = 14,
</pre>
<hr />
<pre>
1557   BAD_ALLOCATION_TYPE, // 3
1558   STATIC_BYTE ,        // T_BOOLEAN     =  4,
1559   STATIC_SHORT,        // T_CHAR        =  5,
1560   STATIC_WORD,         // T_FLOAT       =  6,
1561   STATIC_DOUBLE,       // T_DOUBLE      =  7,
1562   STATIC_BYTE,         // T_BYTE        =  8,
1563   STATIC_SHORT,        // T_SHORT       =  9,
1564   STATIC_WORD,         // T_INT         = 10,
1565   STATIC_DOUBLE,       // T_LONG        = 11,
1566   STATIC_OOP,          // T_OBJECT      = 12,
1567   STATIC_OOP,          // T_ARRAY       = 13,
1568   STATIC_OOP,          // T_VALUETYPE   = 14,
1569   BAD_ALLOCATION_TYPE, // T_VOID        = 15,
1570   BAD_ALLOCATION_TYPE, // T_ADDRESS     = 16,
1571   BAD_ALLOCATION_TYPE, // T_NARROWOOP   = 17,
1572   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
1573   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
1574   BAD_ALLOCATION_TYPE, // T_CONFLICT    = 20
1575 };
1576 
<span class="line-modified">1577 static FieldAllocationType basic_type_to_atype(bool is_static, BasicType type, bool is_inline_type) {</span>
1578   assert(type &gt;= T_BOOLEAN &amp;&amp; type &lt; T_VOID, &quot;only allowable values&quot;);
1579   FieldAllocationType result = _basic_type_to_atype[type + (is_static ? (T_CONFLICT + 1) : 0)];
1580   assert(result != BAD_ALLOCATION_TYPE, &quot;bad type&quot;);
<span class="line-modified">1581   if (is_inline_type) {</span>
<span class="line-modified">1582     result = is_static ? STATIC_INLINE : NONSTATIC_INLINE;</span>
1583   }
1584   return result;
1585 }
1586 
1587 class ClassFileParser::FieldAllocationCount : public ResourceObj {
1588  public:
1589   u2 count[MAX_FIELD_ALLOCATION_TYPE];
1590 
1591   FieldAllocationCount() {
1592     for (int i = 0; i &lt; MAX_FIELD_ALLOCATION_TYPE; i++) {
1593       count[i] = 0;
1594     }
1595   }
1596 
<span class="line-modified">1597   FieldAllocationType update(bool is_static, BasicType type, bool is_inline_type) {</span>
<span class="line-modified">1598     FieldAllocationType atype = basic_type_to_atype(is_static, type, is_inline_type);</span>
1599     if (atype != BAD_ALLOCATION_TYPE) {
1600       // Make sure there is no overflow with injected fields.
1601       assert(count[atype] &lt; 0xFFFF, &quot;More than 65535 fields&quot;);
1602       count[atype]++;
1603     }
1604     return atype;
1605   }
1606 };
1607 
1608 // Side-effects: populates the _fields, _fields_annotations,
1609 // _fields_type_annotations fields
1610 void ClassFileParser::parse_fields(const ClassFileStream* const cfs,
1611                                    bool is_interface,
1612                                    bool is_inline_type,
1613                                    FieldAllocationCount* const fac,
1614                                    ConstantPool* cp,
1615                                    const int cp_size,
1616                                    u2* const java_fields_count_ptr,
1617                                    TRAPS) {
1618 
</pre>
<hr />
<pre>
1674     jint recognized_modifiers = JVM_RECOGNIZED_FIELD_MODIFIERS;
1675 
1676     const jint flags = cfs-&gt;get_u2_fast() &amp; recognized_modifiers;
1677     verify_legal_field_modifiers(flags, is_interface, is_inline_type, CHECK);
1678     AccessFlags access_flags;
1679     access_flags.set_flags(flags);
1680 
1681     const u2 name_index = cfs-&gt;get_u2_fast();
1682     check_property(valid_symbol_at(name_index),
1683       &quot;Invalid constant pool index %u for field name in class file %s&quot;,
1684       name_index, CHECK);
1685     const Symbol* const name = cp-&gt;symbol_at(name_index);
1686     verify_legal_field_name(name, CHECK);
1687 
1688     const u2 signature_index = cfs-&gt;get_u2_fast();
1689     check_property(valid_symbol_at(signature_index),
1690       &quot;Invalid constant pool index %u for field signature in class file %s&quot;,
1691       signature_index, CHECK);
1692     const Symbol* const sig = cp-&gt;symbol_at(signature_index);
1693     verify_legal_field_signature(name, sig, CHECK);
















1694     if (!access_flags.is_static()) instance_fields_count++;
1695 
1696     u2 constantvalue_index = 0;
1697     bool is_synthetic = false;
1698     u2 generic_signature_index = 0;
1699     const bool is_static = access_flags.is_static();
1700     FieldAnnotationCollector parsed_annotations(_loader_data);
1701 
1702     const u2 attributes_count = cfs-&gt;get_u2_fast();
1703     if (attributes_count &gt; 0) {
1704       parse_field_attributes(cfs,
1705                              attributes_count,
1706                              is_static,
1707                              signature_index,
1708                              &amp;constantvalue_index,
1709                              &amp;is_synthetic,
1710                              &amp;generic_signature_index,
1711                              &amp;parsed_annotations,
1712                              CHECK);
1713 
</pre>
<hr />
<pre>
1734 
1735       if (is_synthetic) {
1736         access_flags.set_is_synthetic();
1737       }
1738       if (generic_signature_index != 0) {
1739         access_flags.set_field_has_generic_signature();
1740         fa[generic_signature_slot] = generic_signature_index;
1741         generic_signature_slot ++;
1742         num_generic_signature ++;
1743       }
1744     }
1745 
1746     FieldInfo* const field = FieldInfo::from_field_array(fa, n);
1747     field-&gt;initialize(access_flags.as_short(),
1748                       name_index,
1749                       signature_index,
1750                       constantvalue_index);
1751     const BasicType type = cp-&gt;basic_type_for_signature_at(signature_index);
1752 
1753     // Remember how many oops we encountered and compute allocation type
<span class="line-modified">1754     const FieldAllocationType atype = fac-&gt;update(is_static, type, type == T_VALUETYPE);</span>
1755     field-&gt;set_allocation_type(atype);
1756 
1757     // After field is initialized with type, we can augment it with aux info
1758     if (parsed_annotations.has_any_annotations()) {
1759       parsed_annotations.apply_to(field);
1760       if (field-&gt;is_contended()) {
1761         _has_contended_fields = true;
1762       }
1763     }
1764   }
1765 
1766   int index = length;
1767   if (num_injected != 0) {
1768     for (int n = 0; n &lt; num_injected; n++) {
1769       // Check for duplicates
1770       if (injected[n].may_be_java) {
1771         const Symbol* const name      = injected[n].name();
1772         const Symbol* const signature = injected[n].signature();
1773         bool duplicate = false;
1774         for (int i = 0; i &lt; length; i++) {
</pre>
<hr />
<pre>
4372   //
4373   // We ignore static fields, because @Contended is not supported for them.
4374   // The layout code below will also ignore the static fields.
4375   int nonstatic_contended_count = 0;
4376   FieldAllocationCount fac_contended;
4377   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
4378     FieldAllocationType atype = (FieldAllocationType) fs.allocation_type();
4379     if (fs.is_contended()) {
4380       fac_contended.count[atype]++;
4381       if (!fs.access_flags().is_static()) {
4382         nonstatic_contended_count++;
4383       }
4384     }
4385   }
4386 
4387 
4388   // Calculate the starting byte offsets
4389   int next_static_oop_offset    = InstanceMirrorKlass::offset_of_static_fields();
4390   // Inline types in static fields are not embedded, they are handled with oops
4391   int next_static_double_offset = next_static_oop_offset +
<span class="line-modified">4392                                   ((fac-&gt;count[STATIC_OOP] + fac-&gt;count[STATIC_INLINE]) * heapOopSize);</span>
4393   if (fac-&gt;count[STATIC_DOUBLE]) {
4394     next_static_double_offset = align_up(next_static_double_offset, BytesPerLong);
4395   }
4396 
4397   int next_static_word_offset   = next_static_double_offset +
4398                                     ((fac-&gt;count[STATIC_DOUBLE]) * BytesPerLong);
4399   int next_static_short_offset  = next_static_word_offset +
4400                                     ((fac-&gt;count[STATIC_WORD]) * BytesPerInt);
4401   int next_static_byte_offset   = next_static_short_offset +
4402                                   ((fac-&gt;count[STATIC_SHORT]) * BytesPerShort);
4403 
4404   int nonstatic_fields_start  = instanceOopDesc::base_offset_in_bytes() +
4405                                 nonstatic_field_size * heapOopSize;
4406 
4407   // First field of inline types is aligned on a long boundary in order to ease
4408   // in-lining of inline types (with header removal) in packed arrays and
<span class="line-modified">4409   // fields allocated inline</span>
4410   int initial_inline_type_padding = 0;
4411   if (is_inline_type()) {
4412     int old = nonstatic_fields_start;
4413     nonstatic_fields_start = align_up(nonstatic_fields_start, BytesPerLong);
4414     initial_inline_type_padding = nonstatic_fields_start - old;
4415   }
4416 
4417   int next_nonstatic_field_offset = nonstatic_fields_start;
4418 
4419   const bool is_contended_class     = parsed_annotations-&gt;is_contended();
4420 
4421   // Class is contended, pad before all the fields
4422   if (is_contended_class) {
4423     next_nonstatic_field_offset += ContendedPaddingWidth;
4424   }
4425 
4426   // Temporary inline types restrictions
4427   if (is_inline_type()) {
4428     if (is_contended_class) {
4429       throwInlineTypeLimitation(THREAD_AND_LOCATION, &quot;Inline Types do not support @Contended annotation yet&quot;);
4430       return;
4431     }
4432   }
4433 
4434   // Compute the non-contended fields count.
4435   // The packing code below relies on these counts to determine if some field
4436   // can be squeezed into the alignment gap. Contended fields are obviously
4437   // exempt from that.
4438   unsigned int nonstatic_double_count = fac-&gt;count[NONSTATIC_DOUBLE] - fac_contended.count[NONSTATIC_DOUBLE];
4439   unsigned int nonstatic_word_count   = fac-&gt;count[NONSTATIC_WORD]   - fac_contended.count[NONSTATIC_WORD];
4440   unsigned int nonstatic_short_count  = fac-&gt;count[NONSTATIC_SHORT]  - fac_contended.count[NONSTATIC_SHORT];
4441   unsigned int nonstatic_byte_count   = fac-&gt;count[NONSTATIC_BYTE]   - fac_contended.count[NONSTATIC_BYTE];
4442   unsigned int nonstatic_oop_count    = fac-&gt;count[NONSTATIC_OOP]    - fac_contended.count[NONSTATIC_OOP];
4443 
4444   int static_inline_type_count = 0;
4445   int nonstatic_inline_type_count = 0;
4446   int* nonstatic_inline_type_indexes = NULL;
4447   Klass** nonstatic_inline_type_klasses = NULL;
4448   unsigned int inline_type_oop_map_count = 0;
<span class="line-modified">4449   int inline_types_not_allocated_inline = 0;</span>
4450   int not_atomic_inline_types = 0;
4451 
<span class="line-modified">4452   int max_nonstatic_inline_type = fac-&gt;count[NONSTATIC_INLINE] + 1;</span>
4453 
4454   nonstatic_inline_type_indexes = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, int,
4455                                                                max_nonstatic_inline_type);
4456   for (int i = 0; i &lt; max_nonstatic_inline_type; i++) {
4457     nonstatic_inline_type_indexes[i] = -1;
4458   }
4459   nonstatic_inline_type_klasses = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, Klass*,
4460                                                                max_nonstatic_inline_type);
4461 
4462   for (AllFieldStream fs(_fields, _cp); !fs.done(); fs.next()) {
<span class="line-modified">4463     if (fs.allocation_type() == STATIC_INLINE) {</span>
4464       ResourceMark rm;
4465       if (!fs.signature()-&gt;is_Q_signature()) {
4466         THROW(vmSymbols::java_lang_ClassFormatError());
4467       }
4468       static_inline_type_count++;
<span class="line-modified">4469     } else if (fs.allocation_type() == NONSTATIC_INLINE) {</span>
<span class="line-modified">4470       // Pre-resolve the inline field and check for inline type circularity issues.</span>
4471       ResourceMark rm;
4472       if (!fs.signature()-&gt;is_Q_signature()) {
4473         THROW(vmSymbols::java_lang_ClassFormatError());
4474       }
4475       Klass* klass =
<span class="line-modified">4476         SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,</span>
4477                                                             Handle(THREAD, _loader_data-&gt;class_loader()),
4478                                                             _protection_domain, true, CHECK);
4479       assert(klass != NULL, &quot;Sanity check&quot;);
4480       if (!klass-&gt;access_flags().is_inline_type()) {
4481         THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
4482       }
4483       ValueKlass* vk = ValueKlass::cast(klass);
4484       // Conditions to apply flattening or not should be defined in a single place
<span class="line-modified">4485       bool too_big_to_allocate_inline = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;</span>
4486                                  (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
<span class="line-modified">4487       bool too_atomic_to_allocate_inline = vk-&gt;is_declared_atomic();</span>
<span class="line-modified">4488       bool too_volatile_to_allocate_inline = fs.access_flags().is_volatile();</span>
4489       if (vk-&gt;is_naturally_atomic()) {
<span class="line-modified">4490         too_atomic_to_allocate_inline = false;</span>
<span class="line-modified">4491         // too_volatile_to_allocate_inline = false; //FIXME</span>
<span class="line-modified">4492         // volatile fields are currently never allocated inline, this could change in the future</span>
4493       }
<span class="line-modified">4494       if (!(too_big_to_allocate_inline | too_atomic_to_allocate_inline | too_volatile_to_allocate_inline)) {</span>
4495         nonstatic_inline_type_indexes[nonstatic_inline_type_count] = fs.index();
4496         nonstatic_inline_type_klasses[nonstatic_inline_type_count] = klass;
4497         nonstatic_inline_type_count++;
4498 
4499         ValueKlass* vklass = ValueKlass::cast(klass);
4500         if (vklass-&gt;contains_oops()) {
4501           inline_type_oop_map_count += vklass-&gt;nonstatic_oop_map_count();
4502         }
<span class="line-modified">4503         fs.set_allocated_inline(true);</span>
4504         if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
4505           not_atomic_inline_types++;
4506         }
4507       } else {
<span class="line-modified">4508         inline_types_not_allocated_inline++;</span>
<span class="line-modified">4509         fs.set_allocated_inline(false);</span>
4510       }
4511     }
4512   }
4513 
<span class="line-modified">4514   // Adjusting non_static_oop_count to take into account not inline types not allocated inline;</span>
<span class="line-modified">4515   nonstatic_oop_count += inline_types_not_allocated_inline;</span>
4516 
4517   // Total non-static fields count, including every contended field
4518   unsigned int nonstatic_fields_count = fac-&gt;count[NONSTATIC_DOUBLE] + fac-&gt;count[NONSTATIC_WORD] +
4519                                         fac-&gt;count[NONSTATIC_SHORT] + fac-&gt;count[NONSTATIC_BYTE] +
<span class="line-modified">4520                                         fac-&gt;count[NONSTATIC_OOP] + fac-&gt;count[NONSTATIC_INLINE];</span>
4521 
4522   const bool super_has_nonstatic_fields =
4523           (_super_klass != NULL &amp;&amp; _super_klass-&gt;has_nonstatic_fields());
4524   const bool has_nonstatic_fields =
4525     super_has_nonstatic_fields || (nonstatic_fields_count != 0);
4526   const bool has_nonstatic_value_fields = nonstatic_inline_type_count &gt; 0;
4527 
4528   if (is_inline_type() &amp;&amp; (!has_nonstatic_fields)) {
4529     // There are a number of fixes required throughout the type system and JIT
4530     throwInlineTypeLimitation(THREAD_AND_LOCATION, &quot;Inline Types do not support zero instance size yet&quot;);
4531     return;
4532   }
4533 
4534   // Prepare list of oops for oop map generation.
4535   //
4536   // &quot;offset&quot; and &quot;count&quot; lists are describing the set of contiguous oop
4537   // regions. offset[i] is the start of the i-th region, which then has
4538   // count[i] oops following. Before we know how many regions are required,
4539   // we pessimistically allocate the maps to fit all the oops into the
4540   // distinct regions.
4541   //
4542   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
4543   int max_oop_map_count =
4544       super_oop_map_count +
4545       fac-&gt;count[NONSTATIC_OOP] +
4546       inline_type_oop_map_count +
<span class="line-modified">4547       inline_types_not_allocated_inline;</span>
4548 
4549   OopMapBlocksBuilder* nonstatic_oop_maps = new OopMapBlocksBuilder(max_oop_map_count);
4550   if (super_oop_map_count &gt; 0) {
4551     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
4552                                                     _super_klass-&gt;nonstatic_oop_map_count());
4553   }
4554 
4555   int first_nonstatic_oop_offset = 0; // will be set for first oop field
4556 
4557   bool compact_fields  = true;
4558   bool allocate_oops_first = false;
4559 
4560   int next_nonstatic_oop_offset = 0;
4561   int next_nonstatic_double_offset = 0;
4562 
4563   // Rearrange fields for a given allocation style
4564   if (allocate_oops_first) {
4565     // Fields order: oops, longs/doubles, ints, shorts/chars, bytes, padded fields
4566     next_nonstatic_oop_offset    = next_nonstatic_field_offset;
4567     next_nonstatic_double_offset = next_nonstatic_oop_offset +
</pre>
<hr />
<pre>
4649   next_nonstatic_inline_type_offset = align_up(next_nonstatic_padded_offset, BytesPerLong);
4650   int next_inline_type_index = 0;
4651 
4652   // Iterate over fields again and compute correct offsets.
4653   // The field allocation type was temporarily stored in the offset slot.
4654   // oop fields are located before non-oop fields (static and non-static).
4655   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
4656 
4657     // skip already laid out fields
4658     if (fs.is_offset_set()) continue;
4659 
4660     // contended instance fields are handled below
4661     if (fs.is_contended() &amp;&amp; !fs.access_flags().is_static()) continue;
4662 
4663     int real_offset = 0;
4664     const FieldAllocationType atype = (const FieldAllocationType) fs.allocation_type();
4665 
4666     // pack the rest of the fields
4667     switch (atype) {
4668       // Inline types in static fields are handled with oops
<span class="line-modified">4669       case STATIC_INLINE:   // Fallthrough</span>
4670       case STATIC_OOP:
4671         real_offset = next_static_oop_offset;
4672         next_static_oop_offset += heapOopSize;
4673         break;
4674       case STATIC_BYTE:
4675         real_offset = next_static_byte_offset;
4676         next_static_byte_offset += 1;
4677         break;
4678       case STATIC_SHORT:
4679         real_offset = next_static_short_offset;
4680         next_static_short_offset += BytesPerShort;
4681         break;
4682       case STATIC_WORD:
4683         real_offset = next_static_word_offset;
4684         next_static_word_offset += BytesPerInt;
4685         break;
4686       case STATIC_DOUBLE:
4687         real_offset = next_static_double_offset;
4688         next_static_double_offset += BytesPerLong;
4689         break;
<span class="line-modified">4690       case NONSTATIC_INLINE:</span>
<span class="line-modified">4691         if (fs.is_allocated_inline()) {</span>
4692           Klass* klass = nonstatic_inline_type_klasses[next_inline_type_index];
4693           assert(klass != NULL, &quot;Klass should have been loaded and resolved earlier&quot;);
4694           assert(klass-&gt;access_flags().is_inline_type(),&quot;Must be an inline type&quot;);
4695           ValueKlass* vklass = ValueKlass::cast(klass);
4696           real_offset = next_nonstatic_inline_type_offset;
4697           next_nonstatic_inline_type_offset += (vklass-&gt;size_helper()) * wordSize - vklass-&gt;first_field_offset();
4698           // aligning next inline type on a 64 bits boundary
4699           next_nonstatic_inline_type_offset = align_up(next_nonstatic_inline_type_offset, BytesPerLong);
4700           next_inline_type_index += 1;
4701 
4702           if (vklass-&gt;contains_oops()) { // add flatten oop maps
4703             int diff = real_offset - vklass-&gt;first_field_offset();
4704             const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
4705             const OopMapBlock* const last_map = map + vklass-&gt;nonstatic_oop_map_count();
4706             while (map &lt; last_map) {
4707               nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
4708               map++;
4709             }
4710           }
4711           break;
</pre>
<hr />
<pre>
4814 
4815           case NONSTATIC_SHORT:
4816             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerShort);
4817             real_offset = next_nonstatic_padded_offset;
4818             next_nonstatic_padded_offset += BytesPerShort;
4819             break;
4820 
4821           case NONSTATIC_WORD:
4822             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerInt);
4823             real_offset = next_nonstatic_padded_offset;
4824             next_nonstatic_padded_offset += BytesPerInt;
4825             break;
4826 
4827           case NONSTATIC_DOUBLE:
4828             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, BytesPerLong);
4829             real_offset = next_nonstatic_padded_offset;
4830             next_nonstatic_padded_offset += BytesPerLong;
4831             break;
4832 
4833             // Inline types in static fields are handled with oops
<span class="line-modified">4834           case NONSTATIC_INLINE:</span>
4835             throwInlineTypeLimitation(THREAD_AND_LOCATION,
4836                                       &quot;@Contended annotation not supported for inline types yet&quot;, fs.name(), fs.signature());
4837             return;
4838 
4839           case NONSTATIC_OOP:
4840             next_nonstatic_padded_offset = align_up(next_nonstatic_padded_offset, heapOopSize);
4841             real_offset = next_nonstatic_padded_offset;
4842             next_nonstatic_padded_offset += heapOopSize;
4843             nonstatic_oop_maps-&gt;add(real_offset, 1);
4844             break;
4845 
4846           default:
4847             ShouldNotReachHere();
4848         }
4849 
4850         if (fs.contended_group() == 0) {
4851           // Contended group defines the equivalence class over the fields:
4852           // the fields within the same contended group are not inter-padded.
4853           // The only exception is default group, which does not incur the
4854           // equivalence, and so requires intra-padding.
</pre>
<hr />
<pre>
4928           instance_size,
4929           nonstatic_fields_start,
4930           nonstatic_fields_end,
4931           static_fields_end);
4932     nonstatic_oop_maps-&gt;print_on(tty);
4933     tty-&gt;print(&quot;\n&quot;);
4934     tty-&gt;print_cr(&quot;Instance size = %d&quot;, instance_size);
4935     tty-&gt;print_cr(&quot;Nonstatic_field_size = %d&quot;, nonstatic_field_size);
4936     tty-&gt;print_cr(&quot;Static_field_size = %d&quot;, static_field_size);
4937     tty-&gt;print_cr(&quot;Has nonstatic fields = %d&quot;, has_nonstatic_fields);
4938     tty-&gt;print_cr(&quot;---&quot;);
4939   }
4940 
4941 #endif
4942   // Pass back information needed for InstanceKlass creation
4943   info-&gt;oop_map_blocks = nonstatic_oop_maps;
4944   info-&gt;_instance_size = instance_size;
4945   info-&gt;_static_field_size = static_field_size;
4946   info-&gt;_nonstatic_field_size = nonstatic_field_size;
4947   info-&gt;_has_nonstatic_fields = has_nonstatic_fields;
<span class="line-added">4948   info-&gt;_has_inline_fields = nonstatic_inline_type_count &gt; 0;</span>
4949 
4950   // An inline type is naturally atomic if it has just one field, and
4951   // that field is simple enough.
4952   info-&gt;_is_naturally_atomic = (is_inline_type() &amp;&amp;
4953                                 !super_has_nonstatic_fields &amp;&amp;
4954                                 (nonstatic_fields_count &lt;= 1) &amp;&amp;
4955                                 (not_atomic_inline_types == 0) &amp;&amp;
4956                                 (nonstatic_contended_count == 0));
4957   // This may be too restrictive, since if all the fields fit in 64
4958   // bits we could make the decision to align instances of this class
4959   // to 64-bit boundaries, and load and store them as single words.
4960   // And on machines which supported larger atomics we could similarly
4961   // allow larger values to be atomic, if properly aligned.
4962 }
4963 
4964 void ClassFileParser::set_precomputed_flags(InstanceKlass* ik) {
4965   assert(ik != NULL, &quot;invariant&quot;);
4966 
4967   const Klass* const super = ik-&gt;super();
4968 
</pre>
<hr />
<pre>
6246 
6247   // Not yet: supers are done below to support the new subtype-checking fields
6248   ik-&gt;set_nonstatic_field_size(_field_info-&gt;_nonstatic_field_size);
6249   ik-&gt;set_has_nonstatic_fields(_field_info-&gt;_has_nonstatic_fields);
6250   if (_field_info-&gt;_is_naturally_atomic &amp;&amp; ik-&gt;is_value()) {
6251     ik-&gt;set_is_naturally_atomic();
6252   }
6253   if (_is_empty_inline_type) {
6254     ik-&gt;set_is_empty_inline_type();
6255   }
6256 
6257   if (this-&gt;_invalid_inline_super) {
6258     ik-&gt;set_invalid_inline_super();
6259   }
6260 
6261   if (_has_injected_identityObject) {
6262     ik-&gt;set_has_injected_identityObject();
6263   }
6264 
6265   assert(_fac != NULL, &quot;invariant&quot;);
<span class="line-modified">6266   ik-&gt;set_static_oop_field_count(_fac-&gt;count[STATIC_OOP] + _fac-&gt;count[STATIC_INLINE]);</span>
6267 
6268   // this transfers ownership of a lot of arrays from
6269   // the parser onto the InstanceKlass*
6270   apply_parsed_class_metadata(ik, _java_fields_count, CHECK);
6271 
6272   // can only set dynamic nest-host after static nest information is set
6273   if (cl_inst_info.dynamic_nest_host() != NULL) {
6274     ik-&gt;set_nest_host(cl_inst_info.dynamic_nest_host(), THREAD);
6275   }
6276 
6277   // note that is not safe to use the fields in the parser from this point on
6278   assert(NULL == _cp, &quot;invariant&quot;);
6279   assert(NULL == _fields, &quot;invariant&quot;);
6280   assert(NULL == _methods, &quot;invariant&quot;);
6281   assert(NULL == _inner_classes, &quot;invariant&quot;);
6282   assert(NULL == _nest_members, &quot;invariant&quot;);
6283   assert(NULL == _combined_annotations, &quot;invariant&quot;);
6284   assert(NULL == _record_components, &quot;invariant&quot;);
6285   assert(NULL == _permitted_subclasses, &quot;invariant&quot;);
6286 
</pre>
<hr />
<pre>
6413   // Generate any default methods - default methods are public interface methods
6414   // that have a default implementation.  This is new with Java 8.
6415   if (_has_nonstatic_concrete_methods) {
6416     DefaultMethods::generate_default_methods(ik,
6417                                              _all_mirandas,
6418                                              CHECK);
6419   }
6420 
6421   // Add read edges to the unnamed modules of the bootstrap and app class loaders.
6422   if (changed_by_loadhook &amp;&amp; !module_handle.is_null() &amp;&amp; module_entry-&gt;is_named() &amp;&amp;
6423       !module_entry-&gt;has_default_read_edges()) {
6424     if (!module_entry-&gt;set_has_default_read_edges()) {
6425       // We won a potential race
6426       JvmtiExport::add_default_read_edges(module_handle, THREAD);
6427     }
6428   }
6429 
6430   int nfields = ik-&gt;java_fields_count();
6431   if (ik-&gt;is_value()) nfields++;
6432   for (int i = 0; i &lt; nfields; i++) {
<span class="line-modified">6433     if (ik-&gt;field_is_inline_type(i)) {</span>
6434       Symbol* klass_name = ik-&gt;field_signature(i)-&gt;fundamental_name(CHECK);
6435       // Inline classes for instance fields must have been pre-loaded
6436       // Inline classes for static fields might not have been loaded yet
6437       Klass* klass = SystemDictionary::find(klass_name,
6438           Handle(THREAD, ik-&gt;class_loader()),
6439           Handle(THREAD, ik-&gt;protection_domain()), CHECK);
6440       if (klass != NULL) {
6441         assert(klass-&gt;access_flags().is_inline_type(), &quot;Inline type expected&quot;);
6442         ik-&gt;set_value_field_klass(i, klass);
6443       }
6444       klass_name-&gt;decrement_refcount();
6445     } else
6446       if (is_inline_type() &amp;&amp; ((ik-&gt;field_access_flags(i) &amp; JVM_ACC_FIELD_INTERNAL) != 0)
6447         &amp;&amp; ((ik-&gt;field_access_flags(i) &amp; JVM_ACC_STATIC) != 0)) {
6448       ValueKlass::cast(ik)-&gt;set_default_value_offset(ik-&gt;field_offset(i));
6449     }
6450   }
6451 
6452   if (is_inline_type()) {
6453     ValueKlass* vk = ValueKlass::cast(ik);
</pre>
<hr />
<pre>
6639   _access_flags(),
6640   _pub_level(pub_level),
6641   _bad_constant_seen(0),
6642   _synthetic_flag(false),
6643   _sde_length(false),
6644   _sde_buffer(NULL),
6645   _sourcefile_index(0),
6646   _generic_signature_index(0),
6647   _major_version(0),
6648   _minor_version(0),
6649   _this_class_index(0),
6650   _super_class_index(0),
6651   _itfs_len(0),
6652   _java_fields_count(0),
6653   _need_verify(false),
6654   _relax_verify(false),
6655   _has_nonstatic_concrete_methods(false),
6656   _declares_nonstatic_concrete_methods(false),
6657   _has_final_method(false),
6658   _has_contended_fields(false),
<span class="line-modified">6659   _has_inline_type_fields(false),</span>
6660   _has_nonstatic_fields(false),
6661   _is_empty_inline_type(false),
6662   _is_naturally_atomic(false),
6663   _is_declared_atomic(false),
6664   _invalid_inline_super(false),
6665   _invalid_identity_super(false),
6666   _implements_identityObject(false),
6667   _has_injected_identityObject(false),
6668   _has_finalizer(false),
6669   _has_empty_finalizer(false),
6670   _has_vanilla_constructor(false),
6671   _max_bootstrap_specifier_index(-1) {
6672 
6673   _class_name = name != NULL ? name : vmSymbols::unknown_class_name();
6674   _class_name-&gt;increment_refcount();
6675 
6676   assert(THREAD-&gt;is_Java_thread(), &quot;invariant&quot;);
6677   assert(_loader_data != NULL, &quot;invariant&quot;);
6678   assert(stream != NULL, &quot;invariant&quot;);
6679   assert(_stream != NULL, &quot;invariant&quot;);
</pre>
<hr />
<pre>
7260                                                     &amp;_num_miranda_methods,
7261                                                     _all_mirandas,
7262                                                     _super_klass,
7263                                                     _methods,
7264                                                     _access_flags,
7265                                                     _major_version,
7266                                                     loader,
7267                                                     _class_name,
7268                                                     _local_interfaces,
7269                                                     CHECK);
7270 
7271   // Size of Java itable (in words)
7272   _itable_size = is_interface() ? 0 :
7273     klassItable::compute_itable_size(_transitive_interfaces);
7274 
7275   assert(_fac != NULL, &quot;invariant&quot;);
7276   assert(_parsed_annotations != NULL, &quot;invariant&quot;);
7277 
7278 
7279   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
<span class="line-modified">7280     if (Signature::basic_type(fs.signature()) == T_VALUETYPE  &amp;&amp; !fs.access_flags().is_static()) {</span>
7281       // Pre-load value class
<span class="line-modified">7282       Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,</span>
7283           Handle(THREAD, _loader_data-&gt;class_loader()),
7284           _protection_domain, true, CHECK);
7285       assert(klass != NULL, &quot;Sanity check&quot;);
<span class="line-modified">7286       assert(klass-&gt;access_flags().is_inline_type(), &quot;Value type expected&quot;);</span>

7287     }
7288   }
7289 
7290   _field_info = new FieldLayoutInfo();
7291   if (UseNewFieldLayout) {
7292     FieldLayoutBuilder lb(class_name(), super_klass(), _cp, _fields,
7293         _parsed_annotations-&gt;is_contended(), is_inline_type(),
7294         loader_data(), _protection_domain, _field_info);
7295     lb.build_layout(CHECK);
7296     if (is_inline_type()) {
7297       _alignment = lb.get_alignment();
7298       _first_field_offset = lb.get_first_field_offset();
7299       _exact_size_in_bytes = lb.get_exact_size_in_byte();
7300     }
7301   } else {
7302     layout_fields(cp, _fac, _parsed_annotations, _field_info, CHECK);
7303   }
<span class="line-added">7304   _has_inline_type_fields = _field_info-&gt;_has_inline_fields;</span>
7305 
7306   // Compute reference type
7307   _rt = (NULL ==_super_klass) ? REF_NONE : _super_klass-&gt;reference_type();
7308 }
7309 
7310 void ClassFileParser::set_klass(InstanceKlass* klass) {
7311 
7312 #ifdef ASSERT
7313   if (klass != NULL) {
7314     assert(NULL == _klass, &quot;leaking?&quot;);
7315   }
7316 #endif
7317 
7318   _klass = klass;
7319 }
7320 
7321 void ClassFileParser::set_klass_to_deallocate(InstanceKlass* klass) {
7322 
7323 #ifdef ASSERT
7324   if (klass != NULL) {
</pre>
</td>
</tr>
</table>
<center><a href="../ci/ciReplay.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classFileParser.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>