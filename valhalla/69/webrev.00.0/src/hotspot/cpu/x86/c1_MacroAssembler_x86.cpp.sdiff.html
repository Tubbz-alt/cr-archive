<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 37 #include &quot;runtime/frame.inline.hpp&quot;
 38 #include &quot;runtime/os.hpp&quot;
 39 #include &quot;runtime/sharedRuntime.hpp&quot;
 40 #include &quot;runtime/stubRoutines.hpp&quot;
 41 
 42 int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register scratch, Label&amp; slow_case) {
 43   const int aligned_mask = BytesPerWord -1;
 44   const int hdr_offset = oopDesc::mark_offset_in_bytes();
 45   assert(hdr == rax, &quot;hdr must be rax, for the cmpxchg instruction&quot;);
 46   assert(hdr != obj &amp;&amp; hdr != disp_hdr &amp;&amp; obj != disp_hdr, &quot;registers must be different&quot;);
 47   Label done;
 48   int null_check_offset = -1;
 49 
 50   verify_oop(obj);
 51 
 52   // save object being locked into the BasicObjectLock
 53   movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);
 54 
 55   if (UseBiasedLocking) {
 56     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
<span class="line-modified"> 57     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, false, done, &amp;slow_case);</span>

 58   } else {
 59     null_check_offset = offset();
 60   }
 61 
 62   // Load object header
 63   movptr(hdr, Address(obj, hdr_offset));
 64   // and mark it as unlocked
 65   orptr(hdr, markWord::unlocked_value);
 66   if (EnableValhalla &amp;&amp; !UseBiasedLocking) {
 67     // Mask always_locked bit such that we go to the slow path if object is a value type
 68     andptr(hdr, ~((int) markWord::biased_lock_bit_in_place));
 69   }
 70   // save unlocked object header into the displaced header location on the stack
 71   movptr(Address(disp_hdr, 0), hdr);
 72   // test if object header is still the same (i.e. unlocked), and if so, store the
 73   // displaced header address in the object header - if it is not the same, get the
 74   // object header instead
 75   MacroAssembler::lock(); // must be immediately before cmpxchg!
 76   cmpxchgptr(disp_hdr, Address(obj, hdr_offset));
 77   // if the object header was the same, we&#39;re done
</pre>
<hr />
<pre>
138   // if the object header was not pointing to the displaced header,
139   // we do unlocking via runtime call
140   jcc(Assembler::notEqual, slow_case);
141   // done
142   bind(done);
143 }
144 
145 
146 // Defines obj, preserves var_size_in_bytes
147 void C1_MacroAssembler::try_allocate(Register obj, Register var_size_in_bytes, int con_size_in_bytes, Register t1, Register t2, Label&amp; slow_case) {
148   if (UseTLAB) {
149     tlab_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
150   } else {
151     eden_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
152   }
153 }
154 
155 
156 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register t1, Register t2) {
157   assert_different_registers(obj, klass, len);

158   if ((UseBiasedLocking || EnableValhalla) &amp;&amp; !len-&gt;is_valid()) {
159     // Need to copy markWord::always_locked_pattern for values.
160     assert_different_registers(obj, klass, len, t1, t2);
161     movptr(t1, Address(klass, Klass::prototype_header_offset()));
162     movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);
163   } else {
164     // This assumes that all prototype bits fit in an int32_t
165     movptr(Address(obj, oopDesc::mark_offset_in_bytes ()), (int32_t)(intptr_t)markWord::prototype().value());
166   }
167 #ifdef _LP64
168   if (UseCompressedClassPointers) { // Take care not to kill klass
169     movptr(t1, klass);
<span class="line-modified">170     encode_klass_not_null(t1);</span>
171     movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);
172   } else
173 #endif
174   {
175     movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);
176   }
177 
178   if (len-&gt;is_valid()) {
179     movl(Address(obj, arrayOopDesc::length_offset_in_bytes()), len);
180   }
181 #ifdef _LP64
182   else if (UseCompressedClassPointers) {
183     xorptr(t1, t1);
184     store_klass_gap(obj, t1);
185   }
186 #endif
187 }
188 
189 
190 // preserves obj, destroys len_in_bytes
</pre>
<hr />
<pre>
285   // clear rest of allocated space
286   const Register len_zero = len;
287   initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);
288 
289   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
290     assert(obj == rax, &quot;must be&quot;);
291     call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
292   }
293 
294   verify_oop(obj);
295 }
296 
297 
298 
299 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
300   verify_oop(receiver);
301   // explicit NULL check not needed since load from [klass_offset] causes a trap
302   // check against inline cache
303   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
304   int start_offset = offset();

305 
306   if (UseCompressedClassPointers) {
<span class="line-modified">307     load_klass(rscratch1, receiver);</span>
308     cmpptr(rscratch1, iCache);
309   } else {
310     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
311   }
312   // if icache check fails, then jump to runtime routine
313   // Note: RECEIVER must still contain the receiver!
314   jump_cc(Assembler::notEqual,
315           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
316   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
317   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
318 }
319 
320 void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {
321   push(rbp);
322   if (PreserveFramePointer) {
323     mov(rbp, rsp);
324   }
325   #if !defined(_LP64) &amp;&amp; defined(TIERED)
326     if (UseSSE &lt; 2 ) {
327       // c2 leaves fpu stack dirty. Clean it on entry
</pre>
</td>
<td>
<hr />
<pre>
 37 #include &quot;runtime/frame.inline.hpp&quot;
 38 #include &quot;runtime/os.hpp&quot;
 39 #include &quot;runtime/sharedRuntime.hpp&quot;
 40 #include &quot;runtime/stubRoutines.hpp&quot;
 41 
 42 int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register scratch, Label&amp; slow_case) {
 43   const int aligned_mask = BytesPerWord -1;
 44   const int hdr_offset = oopDesc::mark_offset_in_bytes();
 45   assert(hdr == rax, &quot;hdr must be rax, for the cmpxchg instruction&quot;);
 46   assert(hdr != obj &amp;&amp; hdr != disp_hdr &amp;&amp; obj != disp_hdr, &quot;registers must be different&quot;);
 47   Label done;
 48   int null_check_offset = -1;
 49 
 50   verify_oop(obj);
 51 
 52   // save object being locked into the BasicObjectLock
 53   movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);
 54 
 55   if (UseBiasedLocking) {
 56     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
<span class="line-modified"> 57     Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added"> 58     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, rklass_decode_tmp, false, done, &amp;slow_case);</span>
 59   } else {
 60     null_check_offset = offset();
 61   }
 62 
 63   // Load object header
 64   movptr(hdr, Address(obj, hdr_offset));
 65   // and mark it as unlocked
 66   orptr(hdr, markWord::unlocked_value);
 67   if (EnableValhalla &amp;&amp; !UseBiasedLocking) {
 68     // Mask always_locked bit such that we go to the slow path if object is a value type
 69     andptr(hdr, ~((int) markWord::biased_lock_bit_in_place));
 70   }
 71   // save unlocked object header into the displaced header location on the stack
 72   movptr(Address(disp_hdr, 0), hdr);
 73   // test if object header is still the same (i.e. unlocked), and if so, store the
 74   // displaced header address in the object header - if it is not the same, get the
 75   // object header instead
 76   MacroAssembler::lock(); // must be immediately before cmpxchg!
 77   cmpxchgptr(disp_hdr, Address(obj, hdr_offset));
 78   // if the object header was the same, we&#39;re done
</pre>
<hr />
<pre>
139   // if the object header was not pointing to the displaced header,
140   // we do unlocking via runtime call
141   jcc(Assembler::notEqual, slow_case);
142   // done
143   bind(done);
144 }
145 
146 
147 // Defines obj, preserves var_size_in_bytes
148 void C1_MacroAssembler::try_allocate(Register obj, Register var_size_in_bytes, int con_size_in_bytes, Register t1, Register t2, Label&amp; slow_case) {
149   if (UseTLAB) {
150     tlab_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
151   } else {
152     eden_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
153   }
154 }
155 
156 
157 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register t1, Register t2) {
158   assert_different_registers(obj, klass, len);
<span class="line-added">159   Register tmp_encode_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
160   if ((UseBiasedLocking || EnableValhalla) &amp;&amp; !len-&gt;is_valid()) {
161     // Need to copy markWord::always_locked_pattern for values.
162     assert_different_registers(obj, klass, len, t1, t2);
163     movptr(t1, Address(klass, Klass::prototype_header_offset()));
164     movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);
165   } else {
166     // This assumes that all prototype bits fit in an int32_t
167     movptr(Address(obj, oopDesc::mark_offset_in_bytes ()), (int32_t)(intptr_t)markWord::prototype().value());
168   }
169 #ifdef _LP64
170   if (UseCompressedClassPointers) { // Take care not to kill klass
171     movptr(t1, klass);
<span class="line-modified">172     encode_klass_not_null(t1, tmp_encode_klass);</span>
173     movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);
174   } else
175 #endif
176   {
177     movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);
178   }
179 
180   if (len-&gt;is_valid()) {
181     movl(Address(obj, arrayOopDesc::length_offset_in_bytes()), len);
182   }
183 #ifdef _LP64
184   else if (UseCompressedClassPointers) {
185     xorptr(t1, t1);
186     store_klass_gap(obj, t1);
187   }
188 #endif
189 }
190 
191 
192 // preserves obj, destroys len_in_bytes
</pre>
<hr />
<pre>
287   // clear rest of allocated space
288   const Register len_zero = len;
289   initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);
290 
291   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
292     assert(obj == rax, &quot;must be&quot;);
293     call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
294   }
295 
296   verify_oop(obj);
297 }
298 
299 
300 
301 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
302   verify_oop(receiver);
303   // explicit NULL check not needed since load from [klass_offset] causes a trap
304   // check against inline cache
305   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
306   int start_offset = offset();
<span class="line-added">307   Register tmp_load_klass = LP64_ONLY(rscratch2) NOT_LP64(noreg);</span>
308 
309   if (UseCompressedClassPointers) {
<span class="line-modified">310     load_klass(rscratch1, receiver, tmp_load_klass);</span>
311     cmpptr(rscratch1, iCache);
312   } else {
313     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
314   }
315   // if icache check fails, then jump to runtime routine
316   // Note: RECEIVER must still contain the receiver!
317   jump_cc(Assembler::notEqual,
318           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
319   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
320   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
321 }
322 
323 void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {
324   push(rbp);
325   if (PreserveFramePointer) {
326     mov(rbp, rsp);
327   }
328   #if !defined(_LP64) &amp;&amp; defined(TIERED)
329     if (UseSSE &lt; 2 ) {
330       // c2 leaves fpu stack dirty. Clean it on entry
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>