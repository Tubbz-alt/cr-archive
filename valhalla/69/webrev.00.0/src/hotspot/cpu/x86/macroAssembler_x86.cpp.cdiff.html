<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1087,10 ***</span>
<span class="line-new-header">--- 1087,11 ---</span>
  
  int MacroAssembler::biased_locking_enter(Register lock_reg,
                                           Register obj_reg,
                                           Register swap_reg,
                                           Register tmp_reg,
<span class="line-added">+                                          Register tmp_reg2,</span>
                                           bool swap_reg_contains_mark,
                                           Label&amp; done,
                                           Label* slow_case,
                                           BiasedLockingCounters* counters) {
    assert(UseBiasedLocking, &quot;why call this otherwise?&quot;);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1131,11 ***</span>
    movptr(saved_mark_addr, swap_reg);
  #endif
    if (swap_reg_contains_mark) {
      null_check_offset = offset();
    }
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg);</span>
  #ifdef _LP64
    orptr(tmp_reg, r15_thread);
    xorptr(tmp_reg, swap_reg);
    Register header_reg = tmp_reg;
  #else
<span class="line-new-header">--- 1132,11 ---</span>
    movptr(saved_mark_addr, swap_reg);
  #endif
    if (swap_reg_contains_mark) {
      null_check_offset = offset();
    }
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg, tmp_reg2);</span>
  #ifdef _LP64
    orptr(tmp_reg, r15_thread);
    xorptr(tmp_reg, swap_reg);
    Register header_reg = tmp_reg;
  #else
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1217,11 ***</span>
    // bias in the current epoch. In other words, we allow transfer of
    // the bias from one thread to another directly in this situation.
    //
    // FIXME: due to a lack of registers we currently blow away the age
    // bits in this situation. Should attempt to preserve them.
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg);</span>
  #ifdef _LP64
    orptr(tmp_reg, r15_thread);
  #else
    get_thread(swap_reg);
    orptr(tmp_reg, swap_reg);
<span class="line-new-header">--- 1218,11 ---</span>
    // bias in the current epoch. In other words, we allow transfer of
    // the bias from one thread to another directly in this situation.
    //
    // FIXME: due to a lack of registers we currently blow away the age
    // bits in this situation. Should attempt to preserve them.
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg, tmp_reg2);</span>
  #ifdef _LP64
    orptr(tmp_reg, r15_thread);
  #else
    get_thread(swap_reg);
    orptr(tmp_reg, swap_reg);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1252,11 ***</span>
    // normal locking code.
    //
    // FIXME: due to a lack of registers we currently blow away the age
    // bits in this situation. Should attempt to preserve them.
    NOT_LP64( movptr(swap_reg, saved_mark_addr); )
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg);</span>
    lock();
    cmpxchgptr(tmp_reg, mark_addr); // compare tmp_reg and swap_reg
    // Fall through to the normal CAS-based lock, because no matter what
    // the result of the above CAS, some thread must have succeeded in
    // removing the bias bit from the object&#39;s header.
<span class="line-new-header">--- 1253,11 ---</span>
    // normal locking code.
    //
    // FIXME: due to a lack of registers we currently blow away the age
    // bits in this situation. Should attempt to preserve them.
    NOT_LP64( movptr(swap_reg, saved_mark_addr); )
<span class="line-modified">!   load_prototype_header(tmp_reg, obj_reg, tmp_reg2);</span>
    lock();
    cmpxchgptr(tmp_reg, mark_addr); // compare tmp_reg and swap_reg
    // Fall through to the normal CAS-based lock, because no matter what
    // the result of the above CAS, some thread must have succeeded in
    // removing the bias bit from the object&#39;s header.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1514,11 ***</span>
    assert(number_of_arguments &gt;= 0   , &quot;cannot have negative number of arguments&quot;);
    LP64_ONLY(assert(java_thread == r15_thread, &quot;unexpected register&quot;));
  #ifdef ASSERT
    // TraceBytecodes does not use r12 but saves it over the call, so don&#39;t verify
    // r12 is the heapbase.
<span class="line-modified">!   LP64_ONLY(if ((UseCompressedOops || UseCompressedClassPointers) &amp;&amp; !TraceBytecodes) verify_heapbase(&quot;call_VM_base: heap base corrupted?&quot;);)</span>
  #endif // ASSERT
  
    assert(java_thread != oop_result  , &quot;cannot use the same register for java_thread &amp; oop_result&quot;);
    assert(java_thread != last_java_sp, &quot;cannot use the same register for java_thread &amp; last_java_sp&quot;);
  
<span class="line-new-header">--- 1515,11 ---</span>
    assert(number_of_arguments &gt;= 0   , &quot;cannot have negative number of arguments&quot;);
    LP64_ONLY(assert(java_thread == r15_thread, &quot;unexpected register&quot;));
  #ifdef ASSERT
    // TraceBytecodes does not use r12 but saves it over the call, so don&#39;t verify
    // r12 is the heapbase.
<span class="line-modified">!   LP64_ONLY(if (UseCompressedOops &amp;&amp; !TraceBytecodes) verify_heapbase(&quot;call_VM_base: heap base corrupted?&quot;);)</span>
  #endif // ASSERT
  
    assert(java_thread != oop_result  , &quot;cannot use the same register for java_thread &amp; oop_result&quot;);
    assert(java_thread != last_java_sp, &quot;cannot use the same register for java_thread &amp; last_java_sp&quot;);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2659,30 ***</span>
    jcc(Assembler::notZero, is_flattened);
  }
  
  void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,
                                                Label&amp;is_flattened_array) {
<span class="line-modified">!   load_klass(temp_reg, oop);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_flattened_array_layout(temp_reg, is_flattened_array);
  }
  
  void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,
                                                    Label&amp;is_non_flattened_array) {
<span class="line-modified">!   load_klass(temp_reg, oop);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_non_flattened_array_layout(temp_reg, is_non_flattened_array);
  }
  
  void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {
<span class="line-modified">!   load_klass(temp_reg, oop);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_null_free_array_layout(temp_reg, is_null_free_array);
  }
  
  void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {
<span class="line-modified">!   load_klass(temp_reg, oop);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_non_null_free_array_layout(temp_reg, is_non_null_free_array);
  }
  
  void MacroAssembler::test_flattened_array_layout(Register lh, Label&amp; is_flattened_array) {
<span class="line-new-header">--- 2660,34 ---</span>
    jcc(Assembler::notZero, is_flattened);
  }
  
  void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,
                                                Label&amp;is_flattened_array) {
<span class="line-modified">!   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_flattened_array_layout(temp_reg, is_flattened_array);
  }
  
  void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,
                                                    Label&amp;is_non_flattened_array) {
<span class="line-modified">!   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_non_flattened_array_layout(temp_reg, is_non_flattened_array);
  }
  
  void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {
<span class="line-modified">!   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_null_free_array_layout(temp_reg, is_null_free_array);
  }
  
  void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {
<span class="line-modified">!   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
    movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));
    test_non_null_free_array_layout(temp_reg, is_non_null_free_array);
  }
  
  void MacroAssembler::test_flattened_array_layout(Register lh, Label&amp; is_flattened_array) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3516,11 ***</span>
  #ifdef _LP64
      xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)
      store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops
  #endif
      movptr(t2, klass);         // preserve klass
<span class="line-modified">!     store_klass(new_obj, t2);  // src klass reg is potentially compressed</span>
  
      jmp(done);
    }
  
    bind(slow_case);
<span class="line-new-header">--- 3521,12 ---</span>
  #ifdef _LP64
      xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)
      store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops
  #endif
      movptr(t2, klass);         // preserve klass
<span class="line-modified">!     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+     store_klass(new_obj, t2, tmp_store_klass);  // src klass reg is potentially compressed</span>
  
      jmp(done);
    }
  
    bind(slow_case);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4600,43 ***</span>
  void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
    load_method_holder(rresult, rmethod);
    movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
  }
  
  void MacroAssembler::load_metadata(Register dst, Register src) {
    if (UseCompressedClassPointers) {
      movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
    } else {
      movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
    }
  }
  
<span class="line-modified">! void MacroAssembler::load_method_holder(Register holder, Register method) {</span>
<span class="line-modified">!   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*</span>
<span class="line-modified">!   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*</span>
<span class="line-removed">-   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- void MacroAssembler::load_klass(Register dst, Register src) {</span>
  #ifdef _LP64
    if (UseCompressedClassPointers) {
      movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
<span class="line-modified">!     decode_klass_not_null(dst);</span>
    } else
  #endif
    movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
  }
  
<span class="line-modified">! void MacroAssembler::load_prototype_header(Register dst, Register src) {</span>
<span class="line-modified">!   load_klass(dst, src);</span>
    movptr(dst, Address(dst, Klass::prototype_header_offset()));
  }
  
<span class="line-modified">! void MacroAssembler::store_klass(Register dst, Register src) {</span>
  #ifdef _LP64
    if (UseCompressedClassPointers) {
<span class="line-modified">!     encode_klass_not_null(src);</span>
      movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
    } else
  #endif
      movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
  }
<span class="line-new-header">--- 4606,47 ---</span>
  void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
    load_method_holder(rresult, rmethod);
    movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
  }
  
<span class="line-added">+ void MacroAssembler::load_method_holder(Register holder, Register method) {</span>
<span class="line-added">+   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*</span>
<span class="line-added">+   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*</span>
<span class="line-added">+   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  void MacroAssembler::load_metadata(Register dst, Register src) {
    if (UseCompressedClassPointers) {
      movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
    } else {
      movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
    }
  }
  
<span class="line-modified">! void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {</span>
<span class="line-modified">!   assert_different_registers(src, tmp);</span>
<span class="line-modified">!   assert_different_registers(dst, tmp);</span>
  #ifdef _LP64
    if (UseCompressedClassPointers) {
      movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
<span class="line-modified">!     decode_klass_not_null(dst, tmp);</span>
    } else
  #endif
    movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
  }
  
<span class="line-modified">! void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {</span>
<span class="line-modified">!   load_klass(dst, src, tmp);</span>
    movptr(dst, Address(dst, Klass::prototype_header_offset()));
  }
  
<span class="line-modified">! void MacroAssembler::store_klass(Register dst, Register src, Register tmp) {</span>
<span class="line-added">+   assert_different_registers(src, tmp);</span>
<span class="line-added">+   assert_different_registers(dst, tmp);</span>
  #ifdef _LP64
    if (UseCompressedClassPointers) {
<span class="line-modified">!     encode_klass_not_null(src, tmp);</span>
      movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
    } else
  #endif
      movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 4886,90 ***</span>
        movq(dst, src);
      }
    }
  }
  
<span class="line-modified">! void MacroAssembler::encode_klass_not_null(Register r) {</span>
    if (CompressedKlassPointers::base() != NULL) {
<span class="line-modified">!     // Use r12 as a scratch register in which to temporarily load the narrow_klass_base.</span>
<span class="line-modified">!     assert(r != r12_heapbase, &quot;Encoding a klass in r12&quot;);</span>
<span class="line-removed">-     mov64(r12_heapbase, (int64_t)CompressedKlassPointers::base());</span>
<span class="line-removed">-     subq(r, r12_heapbase);</span>
    }
    if (CompressedKlassPointers::shift() != 0) {
      assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
      shrq(r, LogKlassAlignmentInBytes);
    }
<span class="line-removed">-   if (CompressedKlassPointers::base() != NULL) {</span>
<span class="line-removed">-     reinit_heapbase();</span>
<span class="line-removed">-   }</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- void MacroAssembler::encode_klass_not_null(Register dst, Register src) {</span>
<span class="line-removed">-   if (dst == src) {</span>
<span class="line-removed">-     encode_klass_not_null(src);</span>
<span class="line-removed">-   } else {</span>
<span class="line-removed">-     if (CompressedKlassPointers::base() != NULL) {</span>
<span class="line-removed">-       mov64(dst, (int64_t)CompressedKlassPointers::base());</span>
<span class="line-removed">-       negq(dst);</span>
<span class="line-removed">-       addq(dst, src);</span>
<span class="line-removed">-     } else {</span>
<span class="line-removed">-       movptr(dst, src);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     if (CompressedKlassPointers::shift() != 0) {</span>
<span class="line-removed">-       assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);</span>
<span class="line-removed">-       shrq(dst, LogKlassAlignmentInBytes);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-   }</span>
  }
  
<span class="line-modified">! // Function instr_size_for_decode_klass_not_null() counts the instructions</span>
<span class="line-modified">! // generated by decode_klass_not_null(register r) and reinit_heapbase(),</span>
<span class="line-removed">- // when (Universe::heap() != NULL).  Hence, if the instructions they</span>
<span class="line-removed">- // generate change, then this method needs to be updated.</span>
<span class="line-removed">- int MacroAssembler::instr_size_for_decode_klass_not_null() {</span>
<span class="line-removed">-   assert (UseCompressedClassPointers, &quot;only for compressed klass ptrs&quot;);</span>
    if (CompressedKlassPointers::base() != NULL) {
<span class="line-modified">!     // mov64 + addq + shlq? + mov64  (for reinit_heapbase()).</span>
<span class="line-modified">!     return (CompressedKlassPointers::shift() == 0 ? 20 : 24);</span>
    } else {
<span class="line-modified">!     // longest load decode klass function, mov64, leaq</span>
<span class="line-modified">!     return 16;</span>
    }
  }
  
  // !!! If the instructions that get generated here change then function
  // instr_size_for_decode_klass_not_null() needs to get updated.
<span class="line-modified">! void  MacroAssembler::decode_klass_not_null(Register r) {</span>
    // Note: it will change flags
<span class="line-modified">!   assert (UseCompressedClassPointers, &quot;should only be used for compressed headers&quot;);</span>
<span class="line-removed">-   assert(r != r12_heapbase, &quot;Decoding a klass in r12&quot;);</span>
    // Cannot assert, unverified entry point counts instructions (see .ad file)
    // vtableStubs also counts instructions in pd_code_size_limit.
    // Also do not verify_oop as this is called by verify_oop.
    if (CompressedKlassPointers::shift() != 0) {
      assert(LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
      shlq(r, LogKlassAlignmentInBytes);
    }
<span class="line-modified">!   // Use r12 as a scratch register in which to temporarily load the narrow_klass_base.</span>
<span class="line-modified">!   if (CompressedKlassPointers::base() != NULL) {</span>
<span class="line-removed">-     mov64(r12_heapbase, (int64_t)CompressedKlassPointers::base());</span>
<span class="line-removed">-     addq(r, r12_heapbase);</span>
      addq(r, tmp);
    }
  }
  
<span class="line-modified">! void  MacroAssembler::decode_klass_not_null(Register dst, Register src) {</span>
    // Note: it will change flags
    assert (UseCompressedClassPointers, &quot;should only be used for compressed headers&quot;);
<span class="line-modified">!   if (dst == src) {</span>
<span class="line-modified">!     decode_klass_not_null(dst);</span>
    } else {
<span class="line-modified">!     // Cannot assert, unverified entry point counts instructions (see .ad file)</span>
<span class="line-modified">!     // vtableStubs also counts instructions in pd_code_size_limit.</span>
<span class="line-modified">!     // Also do not verify_oop as this is called by verify_oop.</span>
<span class="line-modified">!     mov64(dst, (int64_t)CompressedKlassPointers::base());</span>
      if (CompressedKlassPointers::shift() != 0) {
        assert(LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
        assert(LogKlassAlignmentInBytes == Address::times_8, &quot;klass not aligned on 64bits?&quot;);
        leaq(dst, Address(dst, src, Address::times_8, 0));
      } else {
<span class="line-new-header">--- 4896,74 ---</span>
        movq(dst, src);
      }
    }
  }
  
<span class="line-modified">! void MacroAssembler::encode_klass_not_null(Register r, Register tmp) {</span>
<span class="line-added">+   assert_different_registers(r, tmp);</span>
    if (CompressedKlassPointers::base() != NULL) {
<span class="line-modified">!     mov64(tmp, (int64_t)CompressedKlassPointers::base());</span>
<span class="line-modified">!     subq(r, tmp);</span>
    }
    if (CompressedKlassPointers::shift() != 0) {
      assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
      shrq(r, LogKlassAlignmentInBytes);
    }
  }
  
<span class="line-modified">! void MacroAssembler::encode_and_move_klass_not_null(Register dst, Register src) {</span>
<span class="line-modified">!   assert_different_registers(src, dst);</span>
    if (CompressedKlassPointers::base() != NULL) {
<span class="line-modified">!     mov64(dst, -(int64_t)CompressedKlassPointers::base());</span>
<span class="line-modified">!     addq(dst, src);</span>
    } else {
<span class="line-modified">!     movptr(dst, src);</span>
<span class="line-modified">!   }</span>
<span class="line-added">+   if (CompressedKlassPointers::shift() != 0) {</span>
<span class="line-added">+     assert (LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);</span>
<span class="line-added">+     shrq(dst, LogKlassAlignmentInBytes);</span>
    }
  }
  
  // !!! If the instructions that get generated here change then function
  // instr_size_for_decode_klass_not_null() needs to get updated.
<span class="line-modified">! void  MacroAssembler::decode_klass_not_null(Register r, Register tmp) {</span>
<span class="line-added">+   assert_different_registers(r, tmp);</span>
    // Note: it will change flags
<span class="line-modified">!   assert(UseCompressedClassPointers, &quot;should only be used for compressed headers&quot;);</span>
    // Cannot assert, unverified entry point counts instructions (see .ad file)
    // vtableStubs also counts instructions in pd_code_size_limit.
    // Also do not verify_oop as this is called by verify_oop.
    if (CompressedKlassPointers::shift() != 0) {
      assert(LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
      shlq(r, LogKlassAlignmentInBytes);
    }
<span class="line-modified">!   if (CompressedKlassPointers::base() != NULL) {</span>
<span class="line-modified">!     mov64(tmp, (int64_t)CompressedKlassPointers::base());</span>
      addq(r, tmp);
    }
  }
  
<span class="line-modified">! void  MacroAssembler::decode_and_move_klass_not_null(Register dst, Register src) {</span>
<span class="line-added">+   assert_different_registers(src, dst);</span>
    // Note: it will change flags
    assert (UseCompressedClassPointers, &quot;should only be used for compressed headers&quot;);
<span class="line-modified">!   // Cannot assert, unverified entry point counts instructions (see .ad file)</span>
<span class="line-modified">!   // vtableStubs also counts instructions in pd_code_size_limit.</span>
<span class="line-added">+   // Also do not verify_oop as this is called by verify_oop.</span>
<span class="line-added">+ </span>
<span class="line-added">+   if (CompressedKlassPointers::base() == NULL &amp;&amp;</span>
<span class="line-added">+       CompressedKlassPointers::shift() == 0) {</span>
<span class="line-added">+     // The best case scenario is that there is no base or shift. Then it is already</span>
<span class="line-added">+     // a pointer that needs nothing but a register rename.</span>
<span class="line-added">+     movl(dst, src);</span>
    } else {
<span class="line-modified">!     if (CompressedKlassPointers::base() != NULL) {</span>
<span class="line-modified">!       mov64(dst, (int64_t)CompressedKlassPointers::base());</span>
<span class="line-modified">!     } else {</span>
<span class="line-modified">!       xorq(dst, dst);</span>
<span class="line-added">+     }</span>
      if (CompressedKlassPointers::shift() != 0) {
        assert(LogKlassAlignmentInBytes == CompressedKlassPointers::shift(), &quot;decode alg wrong&quot;);
        assert(LogKlassAlignmentInBytes == Address::times_8, &quot;klass not aligned on 64bits?&quot;);
        leaq(dst, Address(dst, src, Address::times_8, 0));
      } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 5045,11 ***</span>
    RelocationHolder rspec = metadata_Relocation::spec(klass_index);
    Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
  }
  
  void MacroAssembler::reinit_heapbase() {
<span class="line-modified">!   if (UseCompressedOops || UseCompressedClassPointers) {</span>
      if (Universe::heap() != NULL) {
        if (CompressedOops::base() == NULL) {
          MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
        } else {
          mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
<span class="line-new-header">--- 5039,11 ---</span>
    RelocationHolder rspec = metadata_Relocation::spec(klass_index);
    Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
  }
  
  void MacroAssembler::reinit_heapbase() {
<span class="line-modified">!   if (UseCompressedOops) {</span>
      if (Universe::heap() != NULL) {
        if (CompressedOops::base() == NULL) {
          MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
        } else {
          mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 5251,11 ***</span>
  
      if (vk == NULL) {
        // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
        mov(rax, rbx);
      }
<span class="line-modified">!     store_klass(r13, rbx);  // klass</span>
  
      // We have our new buffered value, initialize its fields with a
      // value class specific handler
      if (vk != NULL) {
        // FIXME -- do the packing in-line to avoid the runtime call
<span class="line-new-header">--- 5245,12 ---</span>
  
      if (vk == NULL) {
        // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
        mov(rax, rbx);
      }
<span class="line-modified">!     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">+     store_klass(r13, rbx, tmp_store_klass);  // klass</span>
  
      // We have our new buffered value, initialize its fields with a
      // value class specific handler
      if (vk != NULL) {
        // FIXME -- do the packing in-line to avoid the runtime call
</pre>
<center><a href="interp_masm_x86.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>