<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../aarch64/aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1199 #else
1200     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 0));
1201     // push and pop the part at src + wordSize, adding wordSize for the previous push
1202     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1203     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1204     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1205 #endif // _LP64
1206 
1207   } else {
1208     ShouldNotReachHere();
1209   }
1210 }
1211 
1212 
1213 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1214   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1215   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1216 
1217   LIR_Address* addr = src-&gt;as_address_ptr();
1218   Address from_addr = as_Address(addr);

1219 
1220   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) {
1221     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1222   }
1223 
1224   switch (type) {
1225     case T_BOOLEAN: // fall through
1226     case T_BYTE:    // fall through
1227     case T_CHAR:    // fall through
1228     case T_SHORT:
1229       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1230         // on pre P6 processors we may get partial register stalls
1231         // so blow away the value of to_rinfo before loading a
1232         // partial word into it.  Do it here so that it precedes
1233         // the potential patch point below.
1234         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1235       }
1236       break;
1237    default:
1238      break;
</pre>
<hr />
<pre>
1385   }
1386 
1387   if (patch != NULL) {
1388     patching_epilog(patch, patch_code, addr-&gt;base()-&gt;as_register(), info);
1389   }
1390 
1391   if (is_reference_type(type)) {
1392 #ifdef _LP64
1393     if (UseCompressedOops &amp;&amp; !wide) {
1394       __ decode_heap_oop(dest-&gt;as_register());
1395     }
1396 #endif
1397 
1398     // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1399     if (!UseZGC) {
1400       __ verify_oop(dest-&gt;as_register());
1401     }
1402   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1403 #ifdef _LP64
1404     if (UseCompressedClassPointers) {
<span class="line-modified">1405       __ decode_klass_not_null(dest-&gt;as_register());</span>
1406     }
1407 #endif
1408   }
1409 }
1410 
1411 
1412 NEEDS_CLEANUP; // This could be static?
1413 Address::ScaleFactor LIR_Assembler::array_element_size(BasicType type) const {
1414   int elem_size = type2aelembytes(type);
1415   switch (elem_size) {
1416     case 1: return Address::times_1;
1417     case 2: return Address::times_2;
1418     case 4: return Address::times_4;
1419     case 8: return Address::times_8;
1420   }
1421   ShouldNotReachHere();
1422   return Address::no_scale;
1423 }
1424 
1425 
</pre>
<hr />
<pre>
1713     Label next_test;
1714     Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_offset(i)));
1715     __ cmpptr(recv_addr, (intptr_t)NULL_WORD);
1716     __ jccb(Assembler::notEqual, next_test);
1717     __ movptr(recv_addr, recv);
1718     __ movptr(Address(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);
1719     __ jmp(*update_done);
1720     __ bind(next_test);
1721   }
1722 }
1723 
1724 void LIR_Assembler::emit_typecheck_helper(LIR_OpTypeCheck *op, Label* success, Label* failure, Label* obj_is_null) {
1725   // we always need a stub for the failure case.
1726   CodeStub* stub = op-&gt;stub();
1727   Register obj = op-&gt;object()-&gt;as_register();
1728   Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1729   Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1730   Register dst = op-&gt;result_opr()-&gt;as_register();
1731   ciKlass* k = op-&gt;klass();
1732   Register Rtmp1 = noreg;

1733 
1734   // check if it needs to be profiled
1735   ciMethodData* md = NULL;
1736   ciProfileData* data = NULL;
1737 
1738   if (op-&gt;should_profile()) {
1739     ciMethod* method = op-&gt;profiled_method();
1740     assert(method != NULL, &quot;Should have method&quot;);
1741     int bci = op-&gt;profiled_bci();
1742     md = method-&gt;method_data_or_null();
1743     assert(md != NULL, &quot;Sanity&quot;);
1744     data = md-&gt;bci_to_data(bci);
1745     assert(data != NULL,                &quot;need data for type check&quot;);
1746     assert(data-&gt;is_ReceiverTypeData(), &quot;need ReceiverTypeData for type check&quot;);
1747   }
1748   Label profile_cast_success, profile_cast_failure;
1749   Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : success;
1750   Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : failure;
1751 
1752   if (obj == k_RInfo) {
</pre>
<hr />
<pre>
1778       __ bind(not_null);
1779     } else {
1780       __ jcc(Assembler::equal, *obj_is_null);
1781     }
1782   }
1783 
1784   if (!k-&gt;is_loaded()) {
1785     klass2reg_with_patching(k_RInfo, op-&gt;info_for_patch());
1786   } else {
1787 #ifdef _LP64
1788     __ mov_metadata(k_RInfo, k-&gt;constant_encoding());
1789 #endif // _LP64
1790   }
1791   __ verify_oop(obj);
1792 
1793   if (op-&gt;fast_check()) {
1794     // get object class
1795     // not a safepoint as obj null check happens earlier
1796 #ifdef _LP64
1797     if (UseCompressedClassPointers) {
<span class="line-modified">1798       __ load_klass(Rtmp1, obj);</span>
1799       __ cmpptr(k_RInfo, Rtmp1);
1800     } else {
1801       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1802     }
1803 #else
1804     if (k-&gt;is_loaded()) {
1805       __ cmpklass(Address(obj, oopDesc::klass_offset_in_bytes()), k-&gt;constant_encoding());
1806     } else {
1807       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1808     }
1809 #endif
1810     __ jcc(Assembler::notEqual, *failure_target);
1811     // successful cast, fall through to profile or jump
1812   } else {
1813     // get object class
1814     // not a safepoint as obj null check happens earlier
<span class="line-modified">1815     __ load_klass(klass_RInfo, obj);</span>
1816     if (k-&gt;is_loaded()) {
1817       // See if we get an immediate positive hit
1818 #ifdef _LP64
1819       __ cmpptr(k_RInfo, Address(klass_RInfo, k-&gt;super_check_offset()));
1820 #else
1821       __ cmpklass(Address(klass_RInfo, k-&gt;super_check_offset()), k-&gt;constant_encoding());
1822 #endif // _LP64
1823       if ((juint)in_bytes(Klass::secondary_super_cache_offset()) != k-&gt;super_check_offset()) {
1824         __ jcc(Assembler::notEqual, *failure_target);
1825         // successful cast, fall through to profile or jump
1826       } else {
1827         // See if we get an immediate positive hit
1828         __ jcc(Assembler::equal, *success_target);
1829         // check for self
1830 #ifdef _LP64
1831         __ cmpptr(klass_RInfo, k_RInfo);
1832 #else
1833         __ cmpklass(klass_RInfo, k-&gt;constant_encoding());
1834 #endif // _LP64
1835         __ jcc(Assembler::equal, *success_target);
</pre>
<hr />
<pre>
1850       }
1851     } else {
1852       // perform the fast part of the checking logic
1853       __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1854       // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1855       __ push(klass_RInfo);
1856       __ push(k_RInfo);
1857       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1858       __ pop(klass_RInfo);
1859       __ pop(k_RInfo);
1860       // result is a boolean
1861       __ cmpl(k_RInfo, 0);
1862       __ jcc(Assembler::equal, *failure_target);
1863       // successful cast, fall through to profile or jump
1864     }
1865   }
1866   if (op-&gt;should_profile()) {
1867     Register mdo  = klass_RInfo, recv = k_RInfo;
1868     __ bind(profile_cast_success);
1869     __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1870     __ load_klass(recv, obj);</span>
1871     type_profile_helper(mdo, md, data, recv, success);
1872     __ jmp(*success);
1873 
1874     __ bind(profile_cast_failure);
1875     __ mov_metadata(mdo, md-&gt;constant_encoding());
1876     Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1877     __ subptr(counter_addr, DataLayout::counter_increment);
1878     __ jmp(*failure);
1879   }
1880   __ jmp(*success);
1881 }
1882 
1883 
1884 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {

1885   LIR_Code code = op-&gt;code();
1886   if (code == lir_store_check) {
1887     Register value = op-&gt;object()-&gt;as_register();
1888     Register array = op-&gt;array()-&gt;as_register();
1889     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1890     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1891     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
1892 
1893     CodeStub* stub = op-&gt;stub();
1894 
1895     // check if it needs to be profiled
1896     ciMethodData* md = NULL;
1897     ciProfileData* data = NULL;
1898 
1899     if (op-&gt;should_profile()) {
1900       ciMethod* method = op-&gt;profiled_method();
1901       assert(method != NULL, &quot;Should have method&quot;);
1902       int bci = op-&gt;profiled_bci();
1903       md = method-&gt;method_data_or_null();
1904       assert(md != NULL, &quot;Sanity&quot;);
</pre>
<hr />
<pre>
1910     Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : &amp;done;
1911     Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : stub-&gt;entry();
1912 
1913     __ cmpptr(value, (int32_t)NULL_WORD);
1914     if (op-&gt;should_profile()) {
1915       Label not_null;
1916       __ jccb(Assembler::notEqual, not_null);
1917       // Object is null; update MDO and exit
1918       Register mdo  = klass_RInfo;
1919       __ mov_metadata(mdo, md-&gt;constant_encoding());
1920       Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, DataLayout::flags_offset()));
1921       int header_bits = BitData::null_seen_byte_constant();
1922       __ orb(data_addr, header_bits);
1923       __ jmp(done);
1924       __ bind(not_null);
1925     } else {
1926       __ jcc(Assembler::equal, done);
1927     }
1928 
1929     add_debug_info_for_null_check_here(op-&gt;info_for_exception());
<span class="line-modified">1930     __ load_klass(k_RInfo, array);</span>
<span class="line-modified">1931     __ load_klass(klass_RInfo, value);</span>
1932 
1933     // get instance klass (it&#39;s already uncompressed)
1934     __ movptr(k_RInfo, Address(k_RInfo, ObjArrayKlass::element_klass_offset()));
1935     // perform the fast part of the checking logic
1936     __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1937     // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1938     __ push(klass_RInfo);
1939     __ push(k_RInfo);
1940     __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1941     __ pop(klass_RInfo);
1942     __ pop(k_RInfo);
1943     // result is a boolean
1944     __ cmpl(k_RInfo, 0);
1945     __ jcc(Assembler::equal, *failure_target);
1946     // fall through to the success case
1947 
1948     if (op-&gt;should_profile()) {
1949       Register mdo  = klass_RInfo, recv = k_RInfo;
1950       __ bind(profile_cast_success);
1951       __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1952       __ load_klass(recv, value);</span>
1953       type_profile_helper(mdo, md, data, recv, &amp;done);
1954       __ jmpb(done);
1955 
1956       __ bind(profile_cast_failure);
1957       __ mov_metadata(mdo, md-&gt;constant_encoding());
1958       Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1959       __ subptr(counter_addr, DataLayout::counter_increment);
1960       __ jmp(*stub-&gt;entry());
1961     }
1962 
1963     __ bind(done);
1964   } else
1965     if (code == lir_checkcast) {
1966       Register obj = op-&gt;object()-&gt;as_register();
1967       Register dst = op-&gt;result_opr()-&gt;as_register();
1968       Label success;
1969       emit_typecheck_helper(op, &amp;success, op-&gt;stub()-&gt;entry(), &amp;success);
1970       __ bind(success);
1971       if (dst != obj) {
1972         __ mov(dst, obj);
</pre>
<hr />
<pre>
1976         Register obj = op-&gt;object()-&gt;as_register();
1977         Register dst = op-&gt;result_opr()-&gt;as_register();
1978         Label success, failure, done;
1979         emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1980         __ bind(failure);
1981         __ xorptr(dst, dst);
1982         __ jmpb(done);
1983         __ bind(success);
1984         __ movptr(dst, 1);
1985         __ bind(done);
1986       } else {
1987         ShouldNotReachHere();
1988       }
1989 
1990 }
1991 
1992 void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {
1993   // We are loading/storing from/to an array that *may* be flattened (the
1994   // declared type is Object[], abstract[], interface[] or VT.ref[]).
1995   // If this array is flattened, take the slow path.

1996   Register klass = op-&gt;tmp()-&gt;as_register();
<span class="line-modified">1997   __ load_klass(klass, op-&gt;array()-&gt;as_register());</span>
1998   __ movl(klass, Address(klass, Klass::layout_helper_offset()));
1999   __ testl(klass, Klass::_lh_array_tag_vt_value_bit_inplace);
2000   __ jcc(Assembler::notZero, *op-&gt;stub()-&gt;entry());
2001   if (!op-&gt;value()-&gt;is_illegal()) {
2002     // The array is not flattened, but it might be null-free. If we are storing
2003     // a null into a null-free array, take the slow path (which will throw NPE).
2004     Label skip;
2005     __ cmpptr(op-&gt;value()-&gt;as_register(), (int32_t)NULL_WORD);
2006     __ jcc(Assembler::notEqual, skip);
2007     __ testl(klass, Klass::_lh_null_free_bit_inplace);
2008     __ jcc(Assembler::notZero, *op-&gt;stub()-&gt;entry());
2009     __ bind(skip);
2010   }
2011 }
2012 
2013 void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {
2014   // We are storing into an array that *may* be null-free (the declared type is
2015   // Object[], abstract[], interface[] or VT.ref[]).

2016   Register klass = op-&gt;tmp()-&gt;as_register();
<span class="line-modified">2017   __ load_klass(klass, op-&gt;array()-&gt;as_register());</span>
2018   __ movl(klass, Address(klass, Klass::layout_helper_offset()));
2019   __ testl(klass, Klass::_lh_null_free_bit_inplace);
2020 }
2021 
2022 void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {
2023   Label L_oops_equal;
2024   Label L_oops_not_equal;
2025   Label L_end;
2026 
2027   Register left  = op-&gt;left()-&gt;as_register();
2028   Register right = op-&gt;right()-&gt;as_register();
2029 
2030   __ cmpptr(left, right);
2031   __ jcc(Assembler::equal, L_oops_equal);
2032 
2033   // (1) Null check -- if one of the operands is null, the other must not be null (because
2034   //     the two references are not equal), so they are not substitutable,
2035   //     FIXME: do null check only if the operand is nullable
2036   {
2037     __ cmpptr(left, (int32_t)NULL_WORD);
</pre>
<hr />
<pre>
3241   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3242   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3243   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3244   __ movoop (Address(rsp, offset_from_rsp_in_bytes), o);
3245 }
3246 
3247 
3248 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3249   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3250   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3251   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3252   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3253 }
3254 
3255 
3256 void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {
3257   if (null_check) {
3258     __ testptr(obj, obj);
3259     __ jcc(Assembler::zero, *slow_path-&gt;entry());
3260   }
<span class="line-modified">3261   __ load_klass(tmp, obj);</span>

3262   __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));
3263   if (is_dest) {
3264     // We also take slow path if it&#39;s a null_free destination array, just in case the source array
3265     // contains NULLs.
3266     __ testl(tmp, Klass::_lh_null_free_bit_inplace);
3267   } else {
3268     __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);
3269   }
3270   __ jcc(Assembler::notZero, *slow_path-&gt;entry());
3271 }
3272 
3273 
3274 // This code replaces a call to arraycopy; no exception may
3275 // be thrown in this code, they must be thrown in the System.arraycopy
3276 // activation frame; we could save some checks if this would not be the case
3277 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
3278   ciArrayKlass* default_type = op-&gt;expected_type();
3279   Register src = op-&gt;src()-&gt;as_register();
3280   Register dst = op-&gt;dst()-&gt;as_register();
3281   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3282   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3283   Register length  = op-&gt;length()-&gt;as_register();
3284   Register tmp = op-&gt;tmp()-&gt;as_register();

3285 
3286   __ resolve(ACCESS_READ, src);
3287   __ resolve(ACCESS_WRITE, dst);
3288 
3289   CodeStub* stub = op-&gt;stub();
3290   int flags = op-&gt;flags();
3291   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3292   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3293 
3294   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {
3295     __ jmp(*stub-&gt;entry());
3296     __ bind(*stub-&gt;continuation());
3297     return;
3298   }
3299 
3300   if (flags &amp; LIR_OpArrayCopy::src_valuetype_check) {
3301     arraycopy_valuetype_check(src, tmp, stub, false, (flags &amp; LIR_OpArrayCopy::src_null_check));
3302   }
3303 
3304   if (flags &amp; LIR_OpArrayCopy::dst_valuetype_check) {
</pre>
<hr />
<pre>
3426   Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());
3427   Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());
3428 
3429   // length and pos&#39;s are all sign extended at this point on 64bit
3430 
3431   // test for NULL
3432   if (flags &amp; LIR_OpArrayCopy::src_null_check) {
3433     __ testptr(src, src);
3434     __ jcc(Assembler::zero, *stub-&gt;entry());
3435   }
3436   if (flags &amp; LIR_OpArrayCopy::dst_null_check) {
3437     __ testptr(dst, dst);
3438     __ jcc(Assembler::zero, *stub-&gt;entry());
3439   }
3440 
3441   // If the compiler was not able to prove that exact type of the source or the destination
3442   // of the arraycopy is an array type, check at runtime if the source or the destination is
3443   // an instance type.
3444   if (flags &amp; LIR_OpArrayCopy::type_check) {
3445     if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3446       __ load_klass(tmp, dst);</span>
3447       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3448       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3449     }
3450 
3451     if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3452       __ load_klass(tmp, src);</span>
3453       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3454       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3455     }
3456   }
3457 
3458   // check if negative
3459   if (flags &amp; LIR_OpArrayCopy::src_pos_positive_check) {
3460     __ testl(src_pos, src_pos);
3461     __ jcc(Assembler::less, *stub-&gt;entry());
3462   }
3463   if (flags &amp; LIR_OpArrayCopy::dst_pos_positive_check) {
3464     __ testl(dst_pos, dst_pos);
3465     __ jcc(Assembler::less, *stub-&gt;entry());
3466   }
3467 
3468   if (flags &amp; LIR_OpArrayCopy::src_range_check) {
3469     __ lea(tmp, Address(src_pos, length, Address::times_1, 0));
3470     __ cmpl(tmp, src_length_addr);
3471     __ jcc(Assembler::above, *stub-&gt;entry());
3472   }
</pre>
<hr />
<pre>
3489   if (flags &amp; LIR_OpArrayCopy::type_check) {
3490     // We don&#39;t know the array types are compatible
3491     if (basic_type != T_OBJECT) {
3492       // Simple test for basic type arrays
3493       if (UseCompressedClassPointers) {
3494         __ movl(tmp, src_klass_addr);
3495         __ cmpl(tmp, dst_klass_addr);
3496       } else {
3497         __ movptr(tmp, src_klass_addr);
3498         __ cmpptr(tmp, dst_klass_addr);
3499       }
3500       __ jcc(Assembler::notEqual, *stub-&gt;entry());
3501     } else {
3502       // For object arrays, if src is a sub class of dst then we can
3503       // safely do the copy.
3504       Label cont, slow;
3505 
3506       __ push(src);
3507       __ push(dst);
3508 
<span class="line-modified">3509       __ load_klass(src, src);</span>
<span class="line-modified">3510       __ load_klass(dst, dst);</span>
3511 
3512       __ check_klass_subtype_fast_path(src, dst, tmp, &amp;cont, &amp;slow, NULL);
3513 
3514       __ push(src);
3515       __ push(dst);
3516       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
3517       __ pop(dst);
3518       __ pop(src);
3519 
3520       __ cmpl(src, 0);
3521       __ jcc(Assembler::notEqual, cont);
3522 
3523       __ bind(slow);
3524       __ pop(dst);
3525       __ pop(src);
3526 
3527       address copyfunc_addr = StubRoutines::checkcast_arraycopy();
3528       if (copyfunc_addr != NULL) { // use stub if available
3529         // src is not a sub class of dst so we have to do a
3530         // per-element check.
3531 
3532         int mask = LIR_OpArrayCopy::src_objarray|LIR_OpArrayCopy::dst_objarray;
3533         if ((flags &amp; mask) != mask) {
3534           // Check that at least both of them object arrays.
3535           assert(flags &amp; mask, &quot;one of the two should be known to be an object array&quot;);
3536 
3537           if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3538             __ load_klass(tmp, src);</span>
3539           } else if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3540             __ load_klass(tmp, dst);</span>
3541           }
3542           int lh_offset = in_bytes(Klass::layout_helper_offset());
3543           Address klass_lh_addr(tmp, lh_offset);
3544           jint objArray_lh = Klass::array_layout_helper(T_OBJECT);
3545           __ cmpl(klass_lh_addr, objArray_lh);
3546           __ jcc(Assembler::notEqual, *stub-&gt;entry());
3547         }
3548 
3549        // Spill because stubs can use any register they like and it&#39;s
3550        // easier to restore just those that we care about.
3551        store_parameter(dst, 0);
3552        store_parameter(dst_pos, 1);
3553        store_parameter(length, 2);
3554        store_parameter(src_pos, 3);
3555        store_parameter(src, 4);
3556 
3557 #ifndef _LP64
3558         __ movptr(tmp, dst_klass_addr);
3559         __ movptr(tmp, Address(tmp, ObjArrayKlass::element_klass_offset()));
3560         __ push(tmp);
</pre>
<hr />
<pre>
3564         __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3565         __ push(tmp);
3566         __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3567         __ push(tmp);
3568 
3569         __ call_VM_leaf(copyfunc_addr, 5);
3570 #else
3571         __ movl2ptr(length, length); //higher 32bits must be null
3572 
3573         __ lea(c_rarg0, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3574         assert_different_registers(c_rarg0, dst, dst_pos, length);
3575         __ lea(c_rarg1, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3576         assert_different_registers(c_rarg1, dst, length);
3577 
3578         __ mov(c_rarg2, length);
3579         assert_different_registers(c_rarg2, dst);
3580 
3581 #ifdef _WIN64
3582         // Allocate abi space for args but be sure to keep stack aligned
3583         __ subptr(rsp, 6*wordSize);
<span class="line-modified">3584         __ load_klass(c_rarg3, dst);</span>
3585         __ movptr(c_rarg3, Address(c_rarg3, ObjArrayKlass::element_klass_offset()));
3586         store_parameter(c_rarg3, 4);
3587         __ movl(c_rarg3, Address(c_rarg3, Klass::super_check_offset_offset()));
3588         __ call(RuntimeAddress(copyfunc_addr));
3589         __ addptr(rsp, 6*wordSize);
3590 #else
<span class="line-modified">3591         __ load_klass(c_rarg4, dst);</span>
3592         __ movptr(c_rarg4, Address(c_rarg4, ObjArrayKlass::element_klass_offset()));
3593         __ movl(c_rarg3, Address(c_rarg4, Klass::super_check_offset_offset()));
3594         __ call(RuntimeAddress(copyfunc_addr));
3595 #endif
3596 
3597 #endif
3598 
3599 #ifndef PRODUCT
3600         if (PrintC1Statistics) {
3601           Label failed;
3602           __ testl(rax, rax);
3603           __ jcc(Assembler::notZero, failed);
3604           __ incrementl(ExternalAddress((address)&amp;Runtime1::_arraycopy_checkcast_cnt));
3605           __ bind(failed);
3606         }
3607 #endif
3608 
3609         __ testl(rax, rax);
3610         __ jcc(Assembler::zero, *stub-&gt;continuation());
3611 
</pre>
<hr />
<pre>
3636 
3637       __ bind(cont);
3638       __ pop(dst);
3639       __ pop(src);
3640     }
3641   }
3642 
3643 #ifdef ASSERT
3644   if (basic_type != T_OBJECT || !(flags &amp; LIR_OpArrayCopy::type_check)) {
3645     // Sanity check the known type with the incoming class.  For the
3646     // primitive case the types must match exactly with src.klass and
3647     // dst.klass each exactly matching the default type.  For the
3648     // object array case, if no type check is needed then either the
3649     // dst type is exactly the expected type and the src type is a
3650     // subtype which we can&#39;t check or src is the same array as dst
3651     // but not necessarily exactly of type default_type.
3652     Label known_ok, halt;
3653     __ mov_metadata(tmp, default_type-&gt;constant_encoding());
3654 #ifdef _LP64
3655     if (UseCompressedClassPointers) {
<span class="line-modified">3656       __ encode_klass_not_null(tmp);</span>
3657     }
3658 #endif
3659 
3660     if (basic_type != T_OBJECT) {
3661 
3662       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3663       else                   __ cmpptr(tmp, dst_klass_addr);
3664       __ jcc(Assembler::notEqual, halt);
3665       if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);
3666       else                   __ cmpptr(tmp, src_klass_addr);
3667       __ jcc(Assembler::equal, known_ok);
3668     } else {
3669       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3670       else                   __ cmpptr(tmp, dst_klass_addr);
3671       __ jcc(Assembler::equal, known_ok);
3672       __ cmpptr(src, dst);
3673       __ jcc(Assembler::equal, known_ok);
3674     }
3675     __ bind(halt);
3676     __ stop(&quot;incorrect type information in arraycopy&quot;);
</pre>
<hr />
<pre>
3741     // add debug info for NullPointerException only if one is possible
3742     int null_check_offset = __ lock_object(hdr, obj, lock, scratch, *op-&gt;stub()-&gt;entry());
3743     if (op-&gt;info() != NULL) {
3744       add_debug_info_for_null_check(null_check_offset, op-&gt;info());
3745     }
3746     // done
3747   } else if (op-&gt;code() == lir_unlock) {
3748     assert(BasicLock::displaced_header_offset_in_bytes() == 0, &quot;lock_reg must point to the displaced header&quot;);
3749     __ unlock_object(hdr, obj, lock, *op-&gt;stub()-&gt;entry());
3750   } else {
3751     Unimplemented();
3752   }
3753   __ bind(*op-&gt;stub()-&gt;continuation());
3754 }
3755 
3756 
3757 void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {
3758   ciMethod* method = op-&gt;profiled_method();
3759   int bci          = op-&gt;profiled_bci();
3760   ciMethod* callee = op-&gt;profiled_callee();

3761 
3762   // Update counter for all call types
3763   ciMethodData* md = method-&gt;method_data_or_null();
3764   assert(md != NULL, &quot;Sanity&quot;);
3765   ciProfileData* data = md-&gt;bci_to_data(bci);
3766   assert(data != NULL &amp;&amp; data-&gt;is_CounterData(), &quot;need CounterData for calls&quot;);
3767   assert(op-&gt;mdo()-&gt;is_single_cpu(),  &quot;mdo must be allocated&quot;);
3768   Register mdo  = op-&gt;mdo()-&gt;as_register();
3769   __ mov_metadata(mdo, md-&gt;constant_encoding());
3770   Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
3771   // Perform additional virtual call profiling for invokevirtual and
3772   // invokeinterface bytecodes
3773   if (op-&gt;should_profile_receiver_type()) {
3774     assert(op-&gt;recv()-&gt;is_single_cpu(), &quot;recv must be allocated&quot;);
3775     Register recv = op-&gt;recv()-&gt;as_register();
3776     assert_different_registers(mdo, recv);
3777     assert(data-&gt;is_VirtualCallData(), &quot;need VirtualCallData for virtual calls&quot;);
3778     ciKlass* known_klass = op-&gt;known_holder();
3779     if (C1OptimizeVirtualCallProfiling &amp;&amp; known_klass != NULL) {
3780       // We know the type that will be seen at this call site; we can
</pre>
<hr />
<pre>
3793           return;
3794         }
3795       }
3796 
3797       // Receiver type not found in profile data; select an empty slot
3798 
3799       // Note that this is less efficient than it should be because it
3800       // always does a write to the receiver part of the
3801       // VirtualCallData rather than just the first time
3802       for (i = 0; i &lt; VirtualCallData::row_limit(); i++) {
3803         ciKlass* receiver = vc_data-&gt;receiver(i);
3804         if (receiver == NULL) {
3805           Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));
3806           __ mov_metadata(recv_addr, known_klass-&gt;constant_encoding());
3807           Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));
3808           __ addptr(data_addr, DataLayout::counter_increment);
3809           return;
3810         }
3811       }
3812     } else {
<span class="line-modified">3813       __ load_klass(recv, recv);</span>
3814       Label update_done;
3815       type_profile_helper(mdo, md, data, recv, &amp;update_done);
3816       // Receiver did not match any saved receiver and there is no empty row for it.
3817       // Increment total counter to indicate polymorphic case.
3818       __ addptr(counter_addr, DataLayout::counter_increment);
3819 
3820       __ bind(update_done);
3821     }
3822   } else {
3823     // Static call
3824     __ addptr(counter_addr, DataLayout::counter_increment);
3825   }
3826 }
3827 
3828 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3829   Register obj = op-&gt;obj()-&gt;as_register();
3830   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();

3831   Address mdo_addr = as_Address(op-&gt;mdp()-&gt;as_address_ptr());
3832   ciKlass* exact_klass = op-&gt;exact_klass();
3833   intptr_t current_klass = op-&gt;current_klass();
3834   bool not_null = op-&gt;not_null();
3835   bool no_conflict = op-&gt;no_conflict();
3836 
3837   Label update, next, none;
3838 
3839   bool do_null = !not_null;
3840   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3841   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3842 
3843   assert(do_null || do_update, &quot;why are we here?&quot;);
3844   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3845 
3846   __ verify_oop(obj);
3847 
3848   if (tmp != obj) {
3849     __ mov(tmp, obj);
3850   }
</pre>
<hr />
<pre>
3857     if (do_update) {
3858 #ifndef ASSERT
3859       __ jmpb(next);
3860     }
3861 #else
3862       __ jmp(next);
3863     }
3864   } else {
3865     __ testptr(tmp, tmp);
3866     __ jcc(Assembler::notZero, update);
3867     __ stop(&quot;unexpect null obj&quot;);
3868 #endif
3869   }
3870 
3871   __ bind(update);
3872 
3873   if (do_update) {
3874 #ifdef ASSERT
3875     if (exact_klass != NULL) {
3876       Label ok;
<span class="line-modified">3877       __ load_klass(tmp, tmp);</span>
3878       __ push(tmp);
3879       __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3880       __ cmpptr(tmp, Address(rsp, 0));
3881       __ jcc(Assembler::equal, ok);
3882       __ stop(&quot;exact klass and actual klass differ&quot;);
3883       __ bind(ok);
3884       __ pop(tmp);
3885     }
3886 #endif
3887     if (!no_conflict) {
3888       if (exact_klass == NULL || TypeEntries::is_type_none(current_klass)) {
3889         if (exact_klass != NULL) {
3890           __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3891         } else {
<span class="line-modified">3892           __ load_klass(tmp, tmp);</span>
3893         }
3894 
3895         __ xorptr(tmp, mdo_addr);
3896         __ testptr(tmp, TypeEntries::type_klass_mask);
3897         // klass seen before, nothing to do. The unknown bit may have been
3898         // set already but no need to check.
3899         __ jccb(Assembler::zero, next);
3900 
3901         __ testptr(tmp, TypeEntries::type_unknown);
3902         __ jccb(Assembler::notZero, next); // already unknown. Nothing to do anymore.
3903 
3904         if (TypeEntries::is_type_none(current_klass)) {
3905           __ cmpptr(mdo_addr, 0);
3906           __ jccb(Assembler::equal, none);
3907           __ cmpptr(mdo_addr, TypeEntries::null_seen);
3908           __ jccb(Assembler::equal, none);
3909           // There is a chance that the checks above (re-reading profiling
3910           // data from memory) fail if another thread has just set the
3911           // profiling to this obj&#39;s klass
3912           __ xorptr(tmp, mdo_addr);
</pre>
</td>
<td>
<hr />
<pre>
1199 #else
1200     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 0));
1201     // push and pop the part at src + wordSize, adding wordSize for the previous push
1202     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1203     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1204     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1205 #endif // _LP64
1206 
1207   } else {
1208     ShouldNotReachHere();
1209   }
1210 }
1211 
1212 
1213 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1214   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1215   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1216 
1217   LIR_Address* addr = src-&gt;as_address_ptr();
1218   Address from_addr = as_Address(addr);
<span class="line-added">1219   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1220 
1221   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) {
1222     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1223   }
1224 
1225   switch (type) {
1226     case T_BOOLEAN: // fall through
1227     case T_BYTE:    // fall through
1228     case T_CHAR:    // fall through
1229     case T_SHORT:
1230       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1231         // on pre P6 processors we may get partial register stalls
1232         // so blow away the value of to_rinfo before loading a
1233         // partial word into it.  Do it here so that it precedes
1234         // the potential patch point below.
1235         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1236       }
1237       break;
1238    default:
1239      break;
</pre>
<hr />
<pre>
1386   }
1387 
1388   if (patch != NULL) {
1389     patching_epilog(patch, patch_code, addr-&gt;base()-&gt;as_register(), info);
1390   }
1391 
1392   if (is_reference_type(type)) {
1393 #ifdef _LP64
1394     if (UseCompressedOops &amp;&amp; !wide) {
1395       __ decode_heap_oop(dest-&gt;as_register());
1396     }
1397 #endif
1398 
1399     // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1400     if (!UseZGC) {
1401       __ verify_oop(dest-&gt;as_register());
1402     }
1403   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1404 #ifdef _LP64
1405     if (UseCompressedClassPointers) {
<span class="line-modified">1406       __ decode_klass_not_null(dest-&gt;as_register(), tmp_load_klass);</span>
1407     }
1408 #endif
1409   }
1410 }
1411 
1412 
1413 NEEDS_CLEANUP; // This could be static?
1414 Address::ScaleFactor LIR_Assembler::array_element_size(BasicType type) const {
1415   int elem_size = type2aelembytes(type);
1416   switch (elem_size) {
1417     case 1: return Address::times_1;
1418     case 2: return Address::times_2;
1419     case 4: return Address::times_4;
1420     case 8: return Address::times_8;
1421   }
1422   ShouldNotReachHere();
1423   return Address::no_scale;
1424 }
1425 
1426 
</pre>
<hr />
<pre>
1714     Label next_test;
1715     Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_offset(i)));
1716     __ cmpptr(recv_addr, (intptr_t)NULL_WORD);
1717     __ jccb(Assembler::notEqual, next_test);
1718     __ movptr(recv_addr, recv);
1719     __ movptr(Address(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);
1720     __ jmp(*update_done);
1721     __ bind(next_test);
1722   }
1723 }
1724 
1725 void LIR_Assembler::emit_typecheck_helper(LIR_OpTypeCheck *op, Label* success, Label* failure, Label* obj_is_null) {
1726   // we always need a stub for the failure case.
1727   CodeStub* stub = op-&gt;stub();
1728   Register obj = op-&gt;object()-&gt;as_register();
1729   Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1730   Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1731   Register dst = op-&gt;result_opr()-&gt;as_register();
1732   ciKlass* k = op-&gt;klass();
1733   Register Rtmp1 = noreg;
<span class="line-added">1734   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1735 
1736   // check if it needs to be profiled
1737   ciMethodData* md = NULL;
1738   ciProfileData* data = NULL;
1739 
1740   if (op-&gt;should_profile()) {
1741     ciMethod* method = op-&gt;profiled_method();
1742     assert(method != NULL, &quot;Should have method&quot;);
1743     int bci = op-&gt;profiled_bci();
1744     md = method-&gt;method_data_or_null();
1745     assert(md != NULL, &quot;Sanity&quot;);
1746     data = md-&gt;bci_to_data(bci);
1747     assert(data != NULL,                &quot;need data for type check&quot;);
1748     assert(data-&gt;is_ReceiverTypeData(), &quot;need ReceiverTypeData for type check&quot;);
1749   }
1750   Label profile_cast_success, profile_cast_failure;
1751   Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : success;
1752   Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : failure;
1753 
1754   if (obj == k_RInfo) {
</pre>
<hr />
<pre>
1780       __ bind(not_null);
1781     } else {
1782       __ jcc(Assembler::equal, *obj_is_null);
1783     }
1784   }
1785 
1786   if (!k-&gt;is_loaded()) {
1787     klass2reg_with_patching(k_RInfo, op-&gt;info_for_patch());
1788   } else {
1789 #ifdef _LP64
1790     __ mov_metadata(k_RInfo, k-&gt;constant_encoding());
1791 #endif // _LP64
1792   }
1793   __ verify_oop(obj);
1794 
1795   if (op-&gt;fast_check()) {
1796     // get object class
1797     // not a safepoint as obj null check happens earlier
1798 #ifdef _LP64
1799     if (UseCompressedClassPointers) {
<span class="line-modified">1800       __ load_klass(Rtmp1, obj, tmp_load_klass);</span>
1801       __ cmpptr(k_RInfo, Rtmp1);
1802     } else {
1803       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1804     }
1805 #else
1806     if (k-&gt;is_loaded()) {
1807       __ cmpklass(Address(obj, oopDesc::klass_offset_in_bytes()), k-&gt;constant_encoding());
1808     } else {
1809       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1810     }
1811 #endif
1812     __ jcc(Assembler::notEqual, *failure_target);
1813     // successful cast, fall through to profile or jump
1814   } else {
1815     // get object class
1816     // not a safepoint as obj null check happens earlier
<span class="line-modified">1817     __ load_klass(klass_RInfo, obj, tmp_load_klass);</span>
1818     if (k-&gt;is_loaded()) {
1819       // See if we get an immediate positive hit
1820 #ifdef _LP64
1821       __ cmpptr(k_RInfo, Address(klass_RInfo, k-&gt;super_check_offset()));
1822 #else
1823       __ cmpklass(Address(klass_RInfo, k-&gt;super_check_offset()), k-&gt;constant_encoding());
1824 #endif // _LP64
1825       if ((juint)in_bytes(Klass::secondary_super_cache_offset()) != k-&gt;super_check_offset()) {
1826         __ jcc(Assembler::notEqual, *failure_target);
1827         // successful cast, fall through to profile or jump
1828       } else {
1829         // See if we get an immediate positive hit
1830         __ jcc(Assembler::equal, *success_target);
1831         // check for self
1832 #ifdef _LP64
1833         __ cmpptr(klass_RInfo, k_RInfo);
1834 #else
1835         __ cmpklass(klass_RInfo, k-&gt;constant_encoding());
1836 #endif // _LP64
1837         __ jcc(Assembler::equal, *success_target);
</pre>
<hr />
<pre>
1852       }
1853     } else {
1854       // perform the fast part of the checking logic
1855       __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1856       // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1857       __ push(klass_RInfo);
1858       __ push(k_RInfo);
1859       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1860       __ pop(klass_RInfo);
1861       __ pop(k_RInfo);
1862       // result is a boolean
1863       __ cmpl(k_RInfo, 0);
1864       __ jcc(Assembler::equal, *failure_target);
1865       // successful cast, fall through to profile or jump
1866     }
1867   }
1868   if (op-&gt;should_profile()) {
1869     Register mdo  = klass_RInfo, recv = k_RInfo;
1870     __ bind(profile_cast_success);
1871     __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1872     __ load_klass(recv, obj, tmp_load_klass);</span>
1873     type_profile_helper(mdo, md, data, recv, success);
1874     __ jmp(*success);
1875 
1876     __ bind(profile_cast_failure);
1877     __ mov_metadata(mdo, md-&gt;constant_encoding());
1878     Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1879     __ subptr(counter_addr, DataLayout::counter_increment);
1880     __ jmp(*failure);
1881   }
1882   __ jmp(*success);
1883 }
1884 
1885 
1886 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {
<span class="line-added">1887   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1888   LIR_Code code = op-&gt;code();
1889   if (code == lir_store_check) {
1890     Register value = op-&gt;object()-&gt;as_register();
1891     Register array = op-&gt;array()-&gt;as_register();
1892     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1893     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1894     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
1895 
1896     CodeStub* stub = op-&gt;stub();
1897 
1898     // check if it needs to be profiled
1899     ciMethodData* md = NULL;
1900     ciProfileData* data = NULL;
1901 
1902     if (op-&gt;should_profile()) {
1903       ciMethod* method = op-&gt;profiled_method();
1904       assert(method != NULL, &quot;Should have method&quot;);
1905       int bci = op-&gt;profiled_bci();
1906       md = method-&gt;method_data_or_null();
1907       assert(md != NULL, &quot;Sanity&quot;);
</pre>
<hr />
<pre>
1913     Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : &amp;done;
1914     Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : stub-&gt;entry();
1915 
1916     __ cmpptr(value, (int32_t)NULL_WORD);
1917     if (op-&gt;should_profile()) {
1918       Label not_null;
1919       __ jccb(Assembler::notEqual, not_null);
1920       // Object is null; update MDO and exit
1921       Register mdo  = klass_RInfo;
1922       __ mov_metadata(mdo, md-&gt;constant_encoding());
1923       Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, DataLayout::flags_offset()));
1924       int header_bits = BitData::null_seen_byte_constant();
1925       __ orb(data_addr, header_bits);
1926       __ jmp(done);
1927       __ bind(not_null);
1928     } else {
1929       __ jcc(Assembler::equal, done);
1930     }
1931 
1932     add_debug_info_for_null_check_here(op-&gt;info_for_exception());
<span class="line-modified">1933     __ load_klass(k_RInfo, array, tmp_load_klass);</span>
<span class="line-modified">1934     __ load_klass(klass_RInfo, value, tmp_load_klass);</span>
1935 
1936     // get instance klass (it&#39;s already uncompressed)
1937     __ movptr(k_RInfo, Address(k_RInfo, ObjArrayKlass::element_klass_offset()));
1938     // perform the fast part of the checking logic
1939     __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1940     // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1941     __ push(klass_RInfo);
1942     __ push(k_RInfo);
1943     __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1944     __ pop(klass_RInfo);
1945     __ pop(k_RInfo);
1946     // result is a boolean
1947     __ cmpl(k_RInfo, 0);
1948     __ jcc(Assembler::equal, *failure_target);
1949     // fall through to the success case
1950 
1951     if (op-&gt;should_profile()) {
1952       Register mdo  = klass_RInfo, recv = k_RInfo;
1953       __ bind(profile_cast_success);
1954       __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1955       __ load_klass(recv, value, tmp_load_klass);</span>
1956       type_profile_helper(mdo, md, data, recv, &amp;done);
1957       __ jmpb(done);
1958 
1959       __ bind(profile_cast_failure);
1960       __ mov_metadata(mdo, md-&gt;constant_encoding());
1961       Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1962       __ subptr(counter_addr, DataLayout::counter_increment);
1963       __ jmp(*stub-&gt;entry());
1964     }
1965 
1966     __ bind(done);
1967   } else
1968     if (code == lir_checkcast) {
1969       Register obj = op-&gt;object()-&gt;as_register();
1970       Register dst = op-&gt;result_opr()-&gt;as_register();
1971       Label success;
1972       emit_typecheck_helper(op, &amp;success, op-&gt;stub()-&gt;entry(), &amp;success);
1973       __ bind(success);
1974       if (dst != obj) {
1975         __ mov(dst, obj);
</pre>
<hr />
<pre>
1979         Register obj = op-&gt;object()-&gt;as_register();
1980         Register dst = op-&gt;result_opr()-&gt;as_register();
1981         Label success, failure, done;
1982         emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1983         __ bind(failure);
1984         __ xorptr(dst, dst);
1985         __ jmpb(done);
1986         __ bind(success);
1987         __ movptr(dst, 1);
1988         __ bind(done);
1989       } else {
1990         ShouldNotReachHere();
1991       }
1992 
1993 }
1994 
1995 void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {
1996   // We are loading/storing from/to an array that *may* be flattened (the
1997   // declared type is Object[], abstract[], interface[] or VT.ref[]).
1998   // If this array is flattened, take the slow path.
<span class="line-added">1999   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
2000   Register klass = op-&gt;tmp()-&gt;as_register();
<span class="line-modified">2001   __ load_klass(klass, op-&gt;array()-&gt;as_register(), tmp_load_klass);</span>
2002   __ movl(klass, Address(klass, Klass::layout_helper_offset()));
2003   __ testl(klass, Klass::_lh_array_tag_vt_value_bit_inplace);
2004   __ jcc(Assembler::notZero, *op-&gt;stub()-&gt;entry());
2005   if (!op-&gt;value()-&gt;is_illegal()) {
2006     // The array is not flattened, but it might be null-free. If we are storing
2007     // a null into a null-free array, take the slow path (which will throw NPE).
2008     Label skip;
2009     __ cmpptr(op-&gt;value()-&gt;as_register(), (int32_t)NULL_WORD);
2010     __ jcc(Assembler::notEqual, skip);
2011     __ testl(klass, Klass::_lh_null_free_bit_inplace);
2012     __ jcc(Assembler::notZero, *op-&gt;stub()-&gt;entry());
2013     __ bind(skip);
2014   }
2015 }
2016 
2017 void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {
2018   // We are storing into an array that *may* be null-free (the declared type is
2019   // Object[], abstract[], interface[] or VT.ref[]).
<span class="line-added">2020   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
2021   Register klass = op-&gt;tmp()-&gt;as_register();
<span class="line-modified">2022   __ load_klass(klass, op-&gt;array()-&gt;as_register(), tmp_load_klass);</span>
2023   __ movl(klass, Address(klass, Klass::layout_helper_offset()));
2024   __ testl(klass, Klass::_lh_null_free_bit_inplace);
2025 }
2026 
2027 void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {
2028   Label L_oops_equal;
2029   Label L_oops_not_equal;
2030   Label L_end;
2031 
2032   Register left  = op-&gt;left()-&gt;as_register();
2033   Register right = op-&gt;right()-&gt;as_register();
2034 
2035   __ cmpptr(left, right);
2036   __ jcc(Assembler::equal, L_oops_equal);
2037 
2038   // (1) Null check -- if one of the operands is null, the other must not be null (because
2039   //     the two references are not equal), so they are not substitutable,
2040   //     FIXME: do null check only if the operand is nullable
2041   {
2042     __ cmpptr(left, (int32_t)NULL_WORD);
</pre>
<hr />
<pre>
3246   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3247   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3248   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3249   __ movoop (Address(rsp, offset_from_rsp_in_bytes), o);
3250 }
3251 
3252 
3253 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3254   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3255   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3256   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3257   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3258 }
3259 
3260 
3261 void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {
3262   if (null_check) {
3263     __ testptr(obj, obj);
3264     __ jcc(Assembler::zero, *slow_path-&gt;entry());
3265   }
<span class="line-modified">3266   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">3267   __ load_klass(tmp, obj, tmp_load_klass);</span>
3268   __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));
3269   if (is_dest) {
3270     // We also take slow path if it&#39;s a null_free destination array, just in case the source array
3271     // contains NULLs.
3272     __ testl(tmp, Klass::_lh_null_free_bit_inplace);
3273   } else {
3274     __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);
3275   }
3276   __ jcc(Assembler::notZero, *slow_path-&gt;entry());
3277 }
3278 
3279 
3280 // This code replaces a call to arraycopy; no exception may
3281 // be thrown in this code, they must be thrown in the System.arraycopy
3282 // activation frame; we could save some checks if this would not be the case
3283 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
3284   ciArrayKlass* default_type = op-&gt;expected_type();
3285   Register src = op-&gt;src()-&gt;as_register();
3286   Register dst = op-&gt;dst()-&gt;as_register();
3287   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3288   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3289   Register length  = op-&gt;length()-&gt;as_register();
3290   Register tmp = op-&gt;tmp()-&gt;as_register();
<span class="line-added">3291   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3292 
3293   __ resolve(ACCESS_READ, src);
3294   __ resolve(ACCESS_WRITE, dst);
3295 
3296   CodeStub* stub = op-&gt;stub();
3297   int flags = op-&gt;flags();
3298   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3299   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3300 
3301   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {
3302     __ jmp(*stub-&gt;entry());
3303     __ bind(*stub-&gt;continuation());
3304     return;
3305   }
3306 
3307   if (flags &amp; LIR_OpArrayCopy::src_valuetype_check) {
3308     arraycopy_valuetype_check(src, tmp, stub, false, (flags &amp; LIR_OpArrayCopy::src_null_check));
3309   }
3310 
3311   if (flags &amp; LIR_OpArrayCopy::dst_valuetype_check) {
</pre>
<hr />
<pre>
3433   Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());
3434   Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());
3435 
3436   // length and pos&#39;s are all sign extended at this point on 64bit
3437 
3438   // test for NULL
3439   if (flags &amp; LIR_OpArrayCopy::src_null_check) {
3440     __ testptr(src, src);
3441     __ jcc(Assembler::zero, *stub-&gt;entry());
3442   }
3443   if (flags &amp; LIR_OpArrayCopy::dst_null_check) {
3444     __ testptr(dst, dst);
3445     __ jcc(Assembler::zero, *stub-&gt;entry());
3446   }
3447 
3448   // If the compiler was not able to prove that exact type of the source or the destination
3449   // of the arraycopy is an array type, check at runtime if the source or the destination is
3450   // an instance type.
3451   if (flags &amp; LIR_OpArrayCopy::type_check) {
3452     if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3453       __ load_klass(tmp, dst, tmp_load_klass);</span>
3454       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3455       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3456     }
3457 
3458     if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3459       __ load_klass(tmp, src, tmp_load_klass);</span>
3460       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3461       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3462     }
3463   }
3464 
3465   // check if negative
3466   if (flags &amp; LIR_OpArrayCopy::src_pos_positive_check) {
3467     __ testl(src_pos, src_pos);
3468     __ jcc(Assembler::less, *stub-&gt;entry());
3469   }
3470   if (flags &amp; LIR_OpArrayCopy::dst_pos_positive_check) {
3471     __ testl(dst_pos, dst_pos);
3472     __ jcc(Assembler::less, *stub-&gt;entry());
3473   }
3474 
3475   if (flags &amp; LIR_OpArrayCopy::src_range_check) {
3476     __ lea(tmp, Address(src_pos, length, Address::times_1, 0));
3477     __ cmpl(tmp, src_length_addr);
3478     __ jcc(Assembler::above, *stub-&gt;entry());
3479   }
</pre>
<hr />
<pre>
3496   if (flags &amp; LIR_OpArrayCopy::type_check) {
3497     // We don&#39;t know the array types are compatible
3498     if (basic_type != T_OBJECT) {
3499       // Simple test for basic type arrays
3500       if (UseCompressedClassPointers) {
3501         __ movl(tmp, src_klass_addr);
3502         __ cmpl(tmp, dst_klass_addr);
3503       } else {
3504         __ movptr(tmp, src_klass_addr);
3505         __ cmpptr(tmp, dst_klass_addr);
3506       }
3507       __ jcc(Assembler::notEqual, *stub-&gt;entry());
3508     } else {
3509       // For object arrays, if src is a sub class of dst then we can
3510       // safely do the copy.
3511       Label cont, slow;
3512 
3513       __ push(src);
3514       __ push(dst);
3515 
<span class="line-modified">3516       __ load_klass(src, src, tmp_load_klass);</span>
<span class="line-modified">3517       __ load_klass(dst, dst, tmp_load_klass);</span>
3518 
3519       __ check_klass_subtype_fast_path(src, dst, tmp, &amp;cont, &amp;slow, NULL);
3520 
3521       __ push(src);
3522       __ push(dst);
3523       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
3524       __ pop(dst);
3525       __ pop(src);
3526 
3527       __ cmpl(src, 0);
3528       __ jcc(Assembler::notEqual, cont);
3529 
3530       __ bind(slow);
3531       __ pop(dst);
3532       __ pop(src);
3533 
3534       address copyfunc_addr = StubRoutines::checkcast_arraycopy();
3535       if (copyfunc_addr != NULL) { // use stub if available
3536         // src is not a sub class of dst so we have to do a
3537         // per-element check.
3538 
3539         int mask = LIR_OpArrayCopy::src_objarray|LIR_OpArrayCopy::dst_objarray;
3540         if ((flags &amp; mask) != mask) {
3541           // Check that at least both of them object arrays.
3542           assert(flags &amp; mask, &quot;one of the two should be known to be an object array&quot;);
3543 
3544           if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3545             __ load_klass(tmp, src, tmp_load_klass);</span>
3546           } else if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3547             __ load_klass(tmp, dst, tmp_load_klass);</span>
3548           }
3549           int lh_offset = in_bytes(Klass::layout_helper_offset());
3550           Address klass_lh_addr(tmp, lh_offset);
3551           jint objArray_lh = Klass::array_layout_helper(T_OBJECT);
3552           __ cmpl(klass_lh_addr, objArray_lh);
3553           __ jcc(Assembler::notEqual, *stub-&gt;entry());
3554         }
3555 
3556        // Spill because stubs can use any register they like and it&#39;s
3557        // easier to restore just those that we care about.
3558        store_parameter(dst, 0);
3559        store_parameter(dst_pos, 1);
3560        store_parameter(length, 2);
3561        store_parameter(src_pos, 3);
3562        store_parameter(src, 4);
3563 
3564 #ifndef _LP64
3565         __ movptr(tmp, dst_klass_addr);
3566         __ movptr(tmp, Address(tmp, ObjArrayKlass::element_klass_offset()));
3567         __ push(tmp);
</pre>
<hr />
<pre>
3571         __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3572         __ push(tmp);
3573         __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3574         __ push(tmp);
3575 
3576         __ call_VM_leaf(copyfunc_addr, 5);
3577 #else
3578         __ movl2ptr(length, length); //higher 32bits must be null
3579 
3580         __ lea(c_rarg0, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3581         assert_different_registers(c_rarg0, dst, dst_pos, length);
3582         __ lea(c_rarg1, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3583         assert_different_registers(c_rarg1, dst, length);
3584 
3585         __ mov(c_rarg2, length);
3586         assert_different_registers(c_rarg2, dst);
3587 
3588 #ifdef _WIN64
3589         // Allocate abi space for args but be sure to keep stack aligned
3590         __ subptr(rsp, 6*wordSize);
<span class="line-modified">3591         __ load_klass(c_rarg3, dst, tmp_load_klass);</span>
3592         __ movptr(c_rarg3, Address(c_rarg3, ObjArrayKlass::element_klass_offset()));
3593         store_parameter(c_rarg3, 4);
3594         __ movl(c_rarg3, Address(c_rarg3, Klass::super_check_offset_offset()));
3595         __ call(RuntimeAddress(copyfunc_addr));
3596         __ addptr(rsp, 6*wordSize);
3597 #else
<span class="line-modified">3598         __ load_klass(c_rarg4, dst, tmp_load_klass);</span>
3599         __ movptr(c_rarg4, Address(c_rarg4, ObjArrayKlass::element_klass_offset()));
3600         __ movl(c_rarg3, Address(c_rarg4, Klass::super_check_offset_offset()));
3601         __ call(RuntimeAddress(copyfunc_addr));
3602 #endif
3603 
3604 #endif
3605 
3606 #ifndef PRODUCT
3607         if (PrintC1Statistics) {
3608           Label failed;
3609           __ testl(rax, rax);
3610           __ jcc(Assembler::notZero, failed);
3611           __ incrementl(ExternalAddress((address)&amp;Runtime1::_arraycopy_checkcast_cnt));
3612           __ bind(failed);
3613         }
3614 #endif
3615 
3616         __ testl(rax, rax);
3617         __ jcc(Assembler::zero, *stub-&gt;continuation());
3618 
</pre>
<hr />
<pre>
3643 
3644       __ bind(cont);
3645       __ pop(dst);
3646       __ pop(src);
3647     }
3648   }
3649 
3650 #ifdef ASSERT
3651   if (basic_type != T_OBJECT || !(flags &amp; LIR_OpArrayCopy::type_check)) {
3652     // Sanity check the known type with the incoming class.  For the
3653     // primitive case the types must match exactly with src.klass and
3654     // dst.klass each exactly matching the default type.  For the
3655     // object array case, if no type check is needed then either the
3656     // dst type is exactly the expected type and the src type is a
3657     // subtype which we can&#39;t check or src is the same array as dst
3658     // but not necessarily exactly of type default_type.
3659     Label known_ok, halt;
3660     __ mov_metadata(tmp, default_type-&gt;constant_encoding());
3661 #ifdef _LP64
3662     if (UseCompressedClassPointers) {
<span class="line-modified">3663       __ encode_klass_not_null(tmp, rscratch1);</span>
3664     }
3665 #endif
3666 
3667     if (basic_type != T_OBJECT) {
3668 
3669       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3670       else                   __ cmpptr(tmp, dst_klass_addr);
3671       __ jcc(Assembler::notEqual, halt);
3672       if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);
3673       else                   __ cmpptr(tmp, src_klass_addr);
3674       __ jcc(Assembler::equal, known_ok);
3675     } else {
3676       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3677       else                   __ cmpptr(tmp, dst_klass_addr);
3678       __ jcc(Assembler::equal, known_ok);
3679       __ cmpptr(src, dst);
3680       __ jcc(Assembler::equal, known_ok);
3681     }
3682     __ bind(halt);
3683     __ stop(&quot;incorrect type information in arraycopy&quot;);
</pre>
<hr />
<pre>
3748     // add debug info for NullPointerException only if one is possible
3749     int null_check_offset = __ lock_object(hdr, obj, lock, scratch, *op-&gt;stub()-&gt;entry());
3750     if (op-&gt;info() != NULL) {
3751       add_debug_info_for_null_check(null_check_offset, op-&gt;info());
3752     }
3753     // done
3754   } else if (op-&gt;code() == lir_unlock) {
3755     assert(BasicLock::displaced_header_offset_in_bytes() == 0, &quot;lock_reg must point to the displaced header&quot;);
3756     __ unlock_object(hdr, obj, lock, *op-&gt;stub()-&gt;entry());
3757   } else {
3758     Unimplemented();
3759   }
3760   __ bind(*op-&gt;stub()-&gt;continuation());
3761 }
3762 
3763 
3764 void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {
3765   ciMethod* method = op-&gt;profiled_method();
3766   int bci          = op-&gt;profiled_bci();
3767   ciMethod* callee = op-&gt;profiled_callee();
<span class="line-added">3768   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3769 
3770   // Update counter for all call types
3771   ciMethodData* md = method-&gt;method_data_or_null();
3772   assert(md != NULL, &quot;Sanity&quot;);
3773   ciProfileData* data = md-&gt;bci_to_data(bci);
3774   assert(data != NULL &amp;&amp; data-&gt;is_CounterData(), &quot;need CounterData for calls&quot;);
3775   assert(op-&gt;mdo()-&gt;is_single_cpu(),  &quot;mdo must be allocated&quot;);
3776   Register mdo  = op-&gt;mdo()-&gt;as_register();
3777   __ mov_metadata(mdo, md-&gt;constant_encoding());
3778   Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
3779   // Perform additional virtual call profiling for invokevirtual and
3780   // invokeinterface bytecodes
3781   if (op-&gt;should_profile_receiver_type()) {
3782     assert(op-&gt;recv()-&gt;is_single_cpu(), &quot;recv must be allocated&quot;);
3783     Register recv = op-&gt;recv()-&gt;as_register();
3784     assert_different_registers(mdo, recv);
3785     assert(data-&gt;is_VirtualCallData(), &quot;need VirtualCallData for virtual calls&quot;);
3786     ciKlass* known_klass = op-&gt;known_holder();
3787     if (C1OptimizeVirtualCallProfiling &amp;&amp; known_klass != NULL) {
3788       // We know the type that will be seen at this call site; we can
</pre>
<hr />
<pre>
3801           return;
3802         }
3803       }
3804 
3805       // Receiver type not found in profile data; select an empty slot
3806 
3807       // Note that this is less efficient than it should be because it
3808       // always does a write to the receiver part of the
3809       // VirtualCallData rather than just the first time
3810       for (i = 0; i &lt; VirtualCallData::row_limit(); i++) {
3811         ciKlass* receiver = vc_data-&gt;receiver(i);
3812         if (receiver == NULL) {
3813           Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));
3814           __ mov_metadata(recv_addr, known_klass-&gt;constant_encoding());
3815           Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));
3816           __ addptr(data_addr, DataLayout::counter_increment);
3817           return;
3818         }
3819       }
3820     } else {
<span class="line-modified">3821       __ load_klass(recv, recv, tmp_load_klass);</span>
3822       Label update_done;
3823       type_profile_helper(mdo, md, data, recv, &amp;update_done);
3824       // Receiver did not match any saved receiver and there is no empty row for it.
3825       // Increment total counter to indicate polymorphic case.
3826       __ addptr(counter_addr, DataLayout::counter_increment);
3827 
3828       __ bind(update_done);
3829     }
3830   } else {
3831     // Static call
3832     __ addptr(counter_addr, DataLayout::counter_increment);
3833   }
3834 }
3835 
3836 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3837   Register obj = op-&gt;obj()-&gt;as_register();
3838   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();
<span class="line-added">3839   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3840   Address mdo_addr = as_Address(op-&gt;mdp()-&gt;as_address_ptr());
3841   ciKlass* exact_klass = op-&gt;exact_klass();
3842   intptr_t current_klass = op-&gt;current_klass();
3843   bool not_null = op-&gt;not_null();
3844   bool no_conflict = op-&gt;no_conflict();
3845 
3846   Label update, next, none;
3847 
3848   bool do_null = !not_null;
3849   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3850   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3851 
3852   assert(do_null || do_update, &quot;why are we here?&quot;);
3853   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3854 
3855   __ verify_oop(obj);
3856 
3857   if (tmp != obj) {
3858     __ mov(tmp, obj);
3859   }
</pre>
<hr />
<pre>
3866     if (do_update) {
3867 #ifndef ASSERT
3868       __ jmpb(next);
3869     }
3870 #else
3871       __ jmp(next);
3872     }
3873   } else {
3874     __ testptr(tmp, tmp);
3875     __ jcc(Assembler::notZero, update);
3876     __ stop(&quot;unexpect null obj&quot;);
3877 #endif
3878   }
3879 
3880   __ bind(update);
3881 
3882   if (do_update) {
3883 #ifdef ASSERT
3884     if (exact_klass != NULL) {
3885       Label ok;
<span class="line-modified">3886       __ load_klass(tmp, tmp, tmp_load_klass);</span>
3887       __ push(tmp);
3888       __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3889       __ cmpptr(tmp, Address(rsp, 0));
3890       __ jcc(Assembler::equal, ok);
3891       __ stop(&quot;exact klass and actual klass differ&quot;);
3892       __ bind(ok);
3893       __ pop(tmp);
3894     }
3895 #endif
3896     if (!no_conflict) {
3897       if (exact_klass == NULL || TypeEntries::is_type_none(current_klass)) {
3898         if (exact_klass != NULL) {
3899           __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3900         } else {
<span class="line-modified">3901           __ load_klass(tmp, tmp, tmp_load_klass);</span>
3902         }
3903 
3904         __ xorptr(tmp, mdo_addr);
3905         __ testptr(tmp, TypeEntries::type_klass_mask);
3906         // klass seen before, nothing to do. The unknown bit may have been
3907         // set already but no need to check.
3908         __ jccb(Assembler::zero, next);
3909 
3910         __ testptr(tmp, TypeEntries::type_unknown);
3911         __ jccb(Assembler::notZero, next); // already unknown. Nothing to do anymore.
3912 
3913         if (TypeEntries::is_type_none(current_klass)) {
3914           __ cmpptr(mdo_addr, 0);
3915           __ jccb(Assembler::equal, none);
3916           __ cmpptr(mdo_addr, TypeEntries::null_seen);
3917           __ jccb(Assembler::equal, none);
3918           // There is a chance that the checks above (re-reading profiling
3919           // data from memory) fail if another thread has just set the
3920           // profiling to this obj&#39;s klass
3921           __ xorptr(tmp, mdo_addr);
</pre>
</td>
</tr>
</table>
<center><a href="../aarch64/aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>