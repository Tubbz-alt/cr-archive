<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -43,14 +43,19 @@</span>
  #include &quot;runtime/objectMonitor.hpp&quot;
  #include &quot;runtime/os.hpp&quot;
  #include &quot;runtime/safepoint.hpp&quot;
  #include &quot;runtime/safepointMechanism.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/signature_cc.hpp&quot;</span>
  #include &quot;runtime/stubRoutines.hpp&quot;
  #include &quot;runtime/thread.hpp&quot;
  #include &quot;utilities/macros.hpp&quot;
<span class="udiff-line-added">+ #include &quot;vmreg_x86.inline.hpp&quot;</span>
  #include &quot;crc32c.h&quot;
<span class="udiff-line-added">+ #ifdef COMPILER2</span>
<span class="udiff-line-added">+ #include &quot;opto/output.hpp&quot;</span>
<span class="udiff-line-added">+ #endif</span>
  
  #ifdef PRODUCT
  #define BLOCK_COMMENT(str) /* nothing */
  #define STOP(error) stop(error)
  #else
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1637,10 +1642,14 @@</span>
    pass_arg1(this, arg_1);
    pass_arg0(this, arg_0);
    call_VM_leaf(entry_point, 3);
  }
  
<span class="udiff-line-added">+ void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="udiff-line-added">+   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
    pass_arg0(this, arg_0);
    MacroAssembler::call_VM_leaf_base(entry_point, 1);
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2605,10 +2614,104 @@</span>
      // nothing to do, (later) access of M[reg + offset]
      // will provoke OS NULL exception if reg = NULL
    }
  }
  
<span class="udiff-line-added">+ void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="udiff-line-added">+   testl(temp_reg, JVM_ACC_VALUE);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_value);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_klass_is_empty_value(Register klass, Register temp_reg, Label&amp; is_empty_value) {</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+   {</span>
<span class="udiff-line-added">+     Label done_check;</span>
<span class="udiff-line-added">+     test_klass_is_value(klass, temp_reg, done_check);</span>
<span class="udiff-line-added">+     stop(&quot;test_klass_is_empty_value with non value klass&quot;);</span>
<span class="udiff-line-added">+     bind(done_check);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));</span>
<span class="udiff-line-added">+   testl(temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_empty_value);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="udiff-line-added">+   movl(temp_reg, flags);</span>
<span class="udiff-line-added">+   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="udiff-line-added">+   andl(temp_reg, 0x1);</span>
<span class="udiff-line-added">+   testl(temp_reg, temp_reg);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_flattenable);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; notFlattenable) {</span>
<span class="udiff-line-added">+   movl(temp_reg, flags);</span>
<span class="udiff-line-added">+   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="udiff-line-added">+   andl(temp_reg, 0x1);</span>
<span class="udiff-line-added">+   testl(temp_reg, temp_reg);</span>
<span class="udiff-line-added">+   jcc(Assembler::zero, notFlattenable);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="udiff-line-added">+   movl(temp_reg, flags);</span>
<span class="udiff-line-added">+   shrl(temp_reg, ConstantPoolCacheEntry::is_flattened_field_shift);</span>
<span class="udiff-line-added">+   andl(temp_reg, 0x1);</span>
<span class="udiff-line-added">+   testl(temp_reg, temp_reg);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_flattened);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="udiff-line-added">+                                               Label&amp;is_flattened_array) {</span>
<span class="udiff-line-added">+   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+   test_flattened_array_layout(temp_reg, is_flattened_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="udiff-line-added">+                                                   Label&amp;is_non_flattened_array) {</span>
<span class="udiff-line-added">+   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+   test_non_flattened_array_layout(temp_reg, is_non_flattened_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {</span>
<span class="udiff-line-added">+   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+   test_null_free_array_layout(temp_reg, is_null_free_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {</span>
<span class="udiff-line-added">+   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="udiff-line-added">+   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+   test_non_null_free_array_layout(temp_reg, is_non_null_free_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_flattened_array_layout(Register lh, Label&amp; is_flattened_array) {</span>
<span class="udiff-line-added">+   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_flattened_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ void MacroAssembler::test_non_flattened_array_layout(Register lh, Label&amp; is_non_flattened_array) {</span>
<span class="udiff-line-added">+   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="udiff-line-added">+   jcc(Assembler::zero, is_non_flattened_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_null_free_array_layout(Register lh, Label&amp; is_null_free_array) {</span>
<span class="udiff-line-added">+   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, is_null_free_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::test_non_null_free_array_layout(Register lh, Label&amp; is_non_null_free_array) {</span>
<span class="udiff-line-added">+   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="udiff-line-added">+   jcc(Assembler::zero, is_non_null_free_array);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
  void MacroAssembler::os_breakpoint() {
    // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
    // (e.g., MSVC can&#39;t call ps() otherwise)
    call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
  }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3303,10 +3406,139 @@</span>
  
  void MacroAssembler::testptr(Register dst, Register src) {
    LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
  }
  
<span class="udiff-line-added">+ // Object / value buffer allocation...</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // Kills klass and rsi on LP64</span>
<span class="udiff-line-added">+ void MacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="udiff-line-added">+                                        Register t1, Register t2,</span>
<span class="udiff-line-added">+                                        bool clear_fields, Label&amp; alloc_failed)</span>
<span class="udiff-line-added">+ {</span>
<span class="udiff-line-added">+   Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;</span>
<span class="udiff-line-added">+   Register layout_size = t1;</span>
<span class="udiff-line-added">+   assert(new_obj == rax, &quot;needs to be rax, according to barrier asm eden_allocate&quot;);</span>
<span class="udiff-line-added">+   assert_different_registers(klass, new_obj, t1, t2);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+   {</span>
<span class="udiff-line-added">+     Label L;</span>
<span class="udiff-line-added">+     cmpb(Address(klass, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="udiff-line-added">+     jcc(Assembler::equal, L);</span>
<span class="udiff-line-added">+     stop(&quot;klass not initialized&quot;);</span>
<span class="udiff-line-added">+     bind(L);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // get instance_size in InstanceKlass (scaled to a count of bytes)</span>
<span class="udiff-line-added">+   movl(layout_size, Address(klass, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+   // test to see if it has a finalizer or is malformed in some way</span>
<span class="udiff-line-added">+   testl(layout_size, Klass::_lh_instance_slow_path_bit);</span>
<span class="udiff-line-added">+   jcc(Assembler::notZero, slow_case_no_pop);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Allocate the instance:</span>
<span class="udiff-line-added">+   //  If TLAB is enabled:</span>
<span class="udiff-line-added">+   //    Try to allocate in the TLAB.</span>
<span class="udiff-line-added">+   //    If fails, go to the slow path.</span>
<span class="udiff-line-added">+   //  Else If inline contiguous allocations are enabled:</span>
<span class="udiff-line-added">+   //    Try to allocate in eden.</span>
<span class="udiff-line-added">+   //    If fails due to heap end, go to slow path.</span>
<span class="udiff-line-added">+   //</span>
<span class="udiff-line-added">+   //  If TLAB is enabled OR inline contiguous is enabled:</span>
<span class="udiff-line-added">+   //    Initialize the allocation.</span>
<span class="udiff-line-added">+   //    Exit.</span>
<span class="udiff-line-added">+   //</span>
<span class="udiff-line-added">+   //  Go to slow path.</span>
<span class="udiff-line-added">+   const bool allow_shared_alloc =</span>
<span class="udiff-line-added">+     Universe::heap()-&gt;supports_inline_contig_alloc();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   push(klass);</span>
<span class="udiff-line-added">+   const Register thread = LP64_ONLY(r15_thread) NOT_LP64(klass);</span>
<span class="udiff-line-added">+ #ifndef _LP64</span>
<span class="udiff-line-added">+   if (UseTLAB || allow_shared_alloc) {</span>
<span class="udiff-line-added">+     get_thread(thread);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif // _LP64</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (UseTLAB) {</span>
<span class="udiff-line-added">+     tlab_allocate(thread, new_obj, layout_size, 0, klass, t2, slow_case);</span>
<span class="udiff-line-added">+     if (ZeroTLAB || (!clear_fields)) {</span>
<span class="udiff-line-added">+       // the fields have been already cleared</span>
<span class="udiff-line-added">+       jmp(initialize_header);</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       // initialize both the header and fields</span>
<span class="udiff-line-added">+       jmp(initialize_object);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     // Allocation in the shared Eden, if allowed.</span>
<span class="udiff-line-added">+     //</span>
<span class="udiff-line-added">+     eden_allocate(thread, new_obj, layout_size, 0, t2, slow_case);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // If UseTLAB or allow_shared_alloc are true, the object is created above and</span>
<span class="udiff-line-added">+   // there is an initialize need. Otherwise, skip and go to the slow path.</span>
<span class="udiff-line-added">+   if (UseTLAB || allow_shared_alloc) {</span>
<span class="udiff-line-added">+     if (clear_fields) {</span>
<span class="udiff-line-added">+       // The object is initialized before the header.  If the object size is</span>
<span class="udiff-line-added">+       // zero, go directly to the header initialization.</span>
<span class="udiff-line-added">+       bind(initialize_object);</span>
<span class="udiff-line-added">+       decrement(layout_size, sizeof(oopDesc));</span>
<span class="udiff-line-added">+       jcc(Assembler::zero, initialize_header);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // Initialize topmost object field, divide size by 8, check if odd and</span>
<span class="udiff-line-added">+       // test if zero.</span>
<span class="udiff-line-added">+       Register zero = klass;</span>
<span class="udiff-line-added">+       xorl(zero, zero);    // use zero reg to clear memory (shorter code)</span>
<span class="udiff-line-added">+       shrl(layout_size, LogBytesPerLong); // divide by 2*oopSize and set carry flag if odd</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   #ifdef ASSERT</span>
<span class="udiff-line-added">+       // make sure instance_size was multiple of 8</span>
<span class="udiff-line-added">+       Label L;</span>
<span class="udiff-line-added">+       // Ignore partial flag stall after shrl() since it is debug VM</span>
<span class="udiff-line-added">+       jcc(Assembler::carryClear, L);</span>
<span class="udiff-line-added">+       stop(&quot;object size is not multiple of 2 - adjust this code&quot;);</span>
<span class="udiff-line-added">+       bind(L);</span>
<span class="udiff-line-added">+       // must be &gt; 0, no extra check needed here</span>
<span class="udiff-line-added">+   #endif</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // initialize remaining object fields: instance_size was a multiple of 8</span>
<span class="udiff-line-added">+       {</span>
<span class="udiff-line-added">+         Label loop;</span>
<span class="udiff-line-added">+         bind(loop);</span>
<span class="udiff-line-added">+         movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 1*oopSize), zero);</span>
<span class="udiff-line-added">+         NOT_LP64(movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 2*oopSize), zero));</span>
<span class="udiff-line-added">+         decrement(layout_size);</span>
<span class="udiff-line-added">+         jcc(Assembler::notZero, loop);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     } // clear_fields</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // initialize object header only.</span>
<span class="udiff-line-added">+     bind(initialize_header);</span>
<span class="udiff-line-added">+     pop(klass);</span>
<span class="udiff-line-added">+     Register mark_word = t2;</span>
<span class="udiff-line-added">+     movptr(mark_word, Address(klass, Klass::prototype_header_offset()));</span>
<span class="udiff-line-added">+     movptr(Address(new_obj, oopDesc::mark_offset_in_bytes ()), mark_word);</span>
<span class="udiff-line-added">+ #ifdef _LP64</span>
<span class="udiff-line-added">+     xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)</span>
<span class="udiff-line-added">+     store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+     movptr(t2, klass);         // preserve klass</span>
<span class="udiff-line-added">+     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+     store_klass(new_obj, t2, tmp_store_klass);  // src klass reg is potentially compressed</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     jmp(done);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   bind(slow_case);</span>
<span class="udiff-line-added">+   pop(klass);</span>
<span class="udiff-line-added">+   bind(slow_case_no_pop);</span>
<span class="udiff-line-added">+   jmp(alloc_failed);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   bind(done);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
  void MacroAssembler::tlab_allocate(Register thread, Register obj,
                                     Register var_size_in_bytes,
                                     int con_size_in_bytes,
                                     Register t1,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3380,10 +3612,60 @@</span>
    }
  
    bind(done);
  }
  
<span class="udiff-line-added">+ void MacroAssembler::get_value_field_klass(Register klass, Register index, Register value_klass) {</span>
<span class="udiff-line-added">+   movptr(value_klass, Address(klass, InstanceKlass::value_field_klasses_offset()));</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+   {</span>
<span class="udiff-line-added">+     Label done;</span>
<span class="udiff-line-added">+     cmpptr(value_klass, 0);</span>
<span class="udiff-line-added">+     jcc(Assembler::notEqual, done);</span>
<span class="udiff-line-added">+     stop(&quot;get_value_field_klass contains no inline klasses&quot;);</span>
<span class="udiff-line-added">+     bind(done);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+   movptr(value_klass, Address(value_klass, index, Address::times_ptr));</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+   {</span>
<span class="udiff-line-added">+     Label done_check;</span>
<span class="udiff-line-added">+     test_klass_is_value(value_klass, temp_reg, done_check);</span>
<span class="udiff-line-added">+     stop(&quot;get_default_value_oop from non-value klass&quot;);</span>
<span class="udiff-line-added">+     bind(done_check);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+   Register offset = temp_reg;</span>
<span class="udiff-line-added">+   // Getting the offset of the pre-allocated default value</span>
<span class="udiff-line-added">+   movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_valueklass_fixed_block_offset())));</span>
<span class="udiff-line-added">+   movl(offset, Address(offset, in_bytes(ValueKlass::default_value_offset_offset())));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Getting the mirror</span>
<span class="udiff-line-added">+   movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="udiff-line-added">+   resolve_oop_handle(obj, value_klass);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Getting the pre-allocated default value from the mirror</span>
<span class="udiff-line-added">+   Address field(obj, offset, Address::times_1);</span>
<span class="udiff-line-added">+   load_heap_oop(obj, field);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::get_empty_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+   {</span>
<span class="udiff-line-added">+     Label done_check;</span>
<span class="udiff-line-added">+     test_klass_is_empty_value(value_klass, temp_reg, done_check);</span>
<span class="udiff-line-added">+     stop(&quot;get_empty_value from non-empty value klass&quot;);</span>
<span class="udiff-line-added">+     bind(done_check);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+   get_default_value_oop(value_klass, temp_reg, obj);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
  // Look up the method for a megamorphic invokeinterface call.
  // The target method is determined by &lt;intf_klass, itable_index&gt;.
  // The receiver klass is in recv_klass.
  // On success, the result will be in method_result, and execution falls through.
  // On failure, execution transfers to the given label.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3728,11 +4010,15 @@</span>
      bind(L);
    }
  }
  
  void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="udiff-line-modified-removed">-   if (!VerifyOops) return;</span>
<span class="udiff-line-modified-added">+   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="udiff-line-added">+     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="udiff-line-added">+     // because it may differ between otherwise equivalent adapters.</span>
<span class="udiff-line-added">+     return;</span>
<span class="udiff-line-added">+   }</span>
  
    // Pass register number to verify_oop_subroutine
    const char* b = NULL;
    {
      ResourceMark rm;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3826,11 +4112,15 @@</span>
    return Address(rsp, scale_reg, scale_factor, offset);
  }
  
  
  void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="udiff-line-modified-removed">-   if (!VerifyOops) return;</span>
<span class="udiff-line-modified-added">+   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="udiff-line-added">+     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="udiff-line-added">+     // because it may differ between otherwise equivalent adapters.</span>
<span class="udiff-line-added">+     return;</span>
<span class="udiff-line-added">+   }</span>
  
    // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
    // Pass register number to verify_oop_subroutine
    const char* b = NULL;
    {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4322,20 +4612,28 @@</span>
    movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
    movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
    movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
  }
  
<span class="udiff-line-added">+ void MacroAssembler::load_metadata(Register dst, Register src) {</span>
<span class="udiff-line-added">+   if (UseCompressedClassPointers) {</span>
<span class="udiff-line-added">+     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {
    assert_different_registers(src, tmp);
    assert_different_registers(dst, tmp);
  #ifdef _LP64
    if (UseCompressedClassPointers) {
      movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
      decode_klass_not_null(dst, tmp);
    } else
  #endif
<span class="udiff-line-modified-removed">-     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="udiff-line-modified-added">+   movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
  }
  
  void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {
    load_klass(dst, src, tmp);
    movptr(dst, Address(dst, Klass::prototype_header_offset()));
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4364,21 +4662,61 @@</span>
      bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
    }
  }
  
  void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="udiff-line-modified-removed">-                                      Register tmp1, Register tmp2) {</span>
<span class="udiff-line-modified-added">+                                      Register tmp1, Register tmp2, Register tmp3) {</span>
    BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
    decorators = AccessInternal::decorator_fixup(decorators);
    bool as_raw = (decorators &amp; AS_RAW) != 0;
    if (as_raw) {
<span class="udiff-line-modified-removed">-     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>
<span class="udiff-line-modified-added">+     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,</span>
<span class="udiff-line-added">+                                        Register value_klass) {</span>
<span class="udiff-line-added">+   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="udiff-line-added">+   bs-&gt;value_copy(this, decorators, src, dst, value_klass);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::first_field_offset(Register value_klass, Register offset) {</span>
<span class="udiff-line-added">+   movptr(offset, Address(value_klass, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="udiff-line-added">+   movl(offset, Address(offset, ValueKlass::first_field_offset_offset()));</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {</span>
<span class="udiff-line-added">+   // ((address) (void*) o) + vk-&gt;first_field_offset();</span>
<span class="udiff-line-added">+   Register offset = (data == oop) ? rscratch1 : data;</span>
<span class="udiff-line-added">+   first_field_offset(value_klass, offset);</span>
<span class="udiff-line-added">+   if (data == oop) {</span>
<span class="udiff-line-added">+     addptr(data, offset);</span>
    } else {
<span class="udiff-line-modified-removed">-     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>
<span class="udiff-line-modified-added">+     lea(data, Address(oop, offset));</span>
    }
  }
  
<span class="udiff-line-added">+ void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,</span>
<span class="udiff-line-added">+                                                 Register index, Register data) {</span>
<span class="udiff-line-added">+   assert(index != rcx, &quot;index needs to shift by rcx&quot;);</span>
<span class="udiff-line-added">+   assert_different_registers(array, array_klass, index);</span>
<span class="udiff-line-added">+   assert_different_registers(rcx, array, index);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));</span>
<span class="udiff-line-added">+   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Klass::layout_helper_log2_element_size(lh)</span>
<span class="udiff-line-added">+   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;</span>
<span class="udiff-line-added">+   shrl(rcx, Klass::_lh_log2_element_size_shift);</span>
<span class="udiff-line-added">+   andl(rcx, Klass::_lh_log2_element_size_mask);</span>
<span class="udiff-line-added">+   shlptr(index); // index &lt;&lt; rcx</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_VALUETYPE)));</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
    // Use stronger ACCESS_WRITE|ACCESS_READ by default.
    if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
      decorators |= ACCESS_READ | ACCESS_WRITE;
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4396,17 +4734,17 @@</span>
                                              Register thread_tmp, DecoratorSet decorators) {
    access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
  }
  
  void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="udiff-line-modified-removed">-                                     Register tmp2, DecoratorSet decorators) {</span>
<span class="udiff-line-modified-removed">-   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);</span>
<span class="udiff-line-modified-added">+                                     Register tmp2, Register tmp3, DecoratorSet decorators) {</span>
<span class="udiff-line-modified-added">+   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2, tmp3);</span>
  }
  
  // Used for storing NULLs.
  void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="udiff-line-modified-removed">-   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
<span class="udiff-line-modified-added">+   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
  }
  
  #ifdef _LP64
  void MacroAssembler::store_klass_gap(Register dst, Register src) {
    if (UseCompressedClassPointers) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4717,11 +5055,15 @@</span>
  }
  
  #endif // _LP64
  
  // C2 compiled method&#39;s prolog code.
<span class="udiff-line-modified-removed">- void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {</span>
<span class="udiff-line-modified-added">+ void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="udiff-line-added">+   int framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="udiff-line-added">+   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="udiff-line-added">+   bool fp_mode_24b = false;</span>
<span class="udiff-line-added">+   int stack_bang_size = C-&gt;output()-&gt;need_stack_bang(bangsize) ? bangsize : 0;</span>
  
    // WARNING: Initial instruction MUST be 5 bytes or longer so that
    // NativeJump::patch_verified_entry will be able to patch out the entry
    // code safely. The push to verify stack depth is ok at 5 bytes,
    // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4770,10 +5112,16 @@</span>
          addptr(rbp, framesize);
        }
      }
    }
  
<span class="udiff-line-added">+   if (C-&gt;needs_stack_repair()) {</span>
<span class="udiff-line-added">+     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="udiff-line-added">+     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="udiff-line-added">+     movptr(Address(rsp, C-&gt;output()-&gt;sp_inc_offset()), sp_inc + framesize + wordSize);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
      framesize -= wordSize;
      movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4798,26 +5146,23 @@</span>
      jcc(Assembler::equal, L);
      STOP(&quot;Stack is not properly aligned!&quot;);
      bind(L);
    }
  #endif
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-   if (!is_stub) {</span>
<span class="udiff-line-removed">-     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="udiff-line-removed">-     bs-&gt;nmethod_entry_barrier(this);</span>
<span class="udiff-line-removed">-   }</span>
  }
  
  // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="udiff-line-modified-removed">- void MacroAssembler::xmm_clear_mem(Register base, Register cnt, XMMRegister xtmp) {</span>
<span class="udiff-line-modified-added">+ void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp) {</span>
    // cnt - number of qwords (8-byte words).
    // base - start address, qword aligned.
    Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;
<span class="udiff-line-added">+   movdq(xtmp, val);</span>
    if (UseAVX &gt;= 2) {
<span class="udiff-line-modified-removed">-     vpxor(xtmp, xtmp, xtmp, AVX_256bit);</span>
<span class="udiff-line-modified-added">+     punpcklqdq(xtmp, xtmp);</span>
<span class="udiff-line-added">+     vinserti128_high(xtmp, xtmp);</span>
    } else {
<span class="udiff-line-modified-removed">-     pxor(xtmp, xtmp);</span>
<span class="udiff-line-modified-added">+     punpcklqdq(xtmp, xtmp);</span>
    }
    jmp(L_zero_64_bytes);
  
    BIND(L_loop);
    if (UseAVX &gt;= 2) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4857,26 +5202,381 @@</span>
    decrement(cnt);
    jccb(Assembler::greaterEqual, L_sloop);
    BIND(L_end);
  }
  
<span class="udiff-line-modified-removed">- void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp, bool is_large) {</span>
<span class="udiff-line-modified-added">+ int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="udiff-line-added">+   // A value type might be returned. If fields are in registers we</span>
<span class="udiff-line-added">+   // need to allocate a value type instance and initialize it with</span>
<span class="udiff-line-added">+   // the value of the fields.</span>
<span class="udiff-line-added">+   Label skip;</span>
<span class="udiff-line-added">+   // We only need a new buffered value if a new one is not returned</span>
<span class="udiff-line-added">+   testptr(rax, 1);</span>
<span class="udiff-line-added">+   jcc(Assembler::zero, skip);</span>
<span class="udiff-line-added">+   int call_offset = -1;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ #ifdef _LP64</span>
<span class="udiff-line-added">+   Label slow_case;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Try to allocate a new buffered value (from the heap)</span>
<span class="udiff-line-added">+   if (UseTLAB) {</span>
<span class="udiff-line-added">+     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.</span>
<span class="udiff-line-added">+     if (vk != NULL) {</span>
<span class="udiff-line-added">+       // Called from C1, where the return type is statically known.</span>
<span class="udiff-line-added">+       movptr(rbx, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="udiff-line-added">+       jint lh = vk-&gt;layout_helper();</span>
<span class="udiff-line-added">+       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="udiff-line-added">+       movl(r14, lh);</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       // Call from interpreter. RAX contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="udiff-line-added">+       mov(rbx, rax);</span>
<span class="udiff-line-added">+       andptr(rbx, -2);</span>
<span class="udiff-line-added">+       movl(r14, Address(rbx, Klass::layout_helper_offset()));</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="udiff-line-added">+     lea(r14, Address(r13, r14, Address::times_1));</span>
<span class="udiff-line-added">+     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="udiff-line-added">+     jcc(Assembler::above, slow_case);</span>
<span class="udiff-line-added">+     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);</span>
<span class="udiff-line-added">+     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     xorl(rax, rax); // use zero reg to clear memory (shorter code)</span>
<span class="udiff-line-added">+     store_klass_gap(r13, rax);  // zero klass gap for compressed oops</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (vk == NULL) {</span>
<span class="udiff-line-added">+       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="udiff-line-added">+       mov(rax, rbx);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="udiff-line-added">+     store_klass(r13, rbx, tmp_store_klass);  // klass</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // We have our new buffered value, initialize its fields with a</span>
<span class="udiff-line-added">+     // value class specific handler</span>
<span class="udiff-line-added">+     if (vk != NULL) {</span>
<span class="udiff-line-added">+       // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="udiff-line-added">+       mov(rax, r13);</span>
<span class="udiff-line-added">+       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       movptr(rbx, Address(rax, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="udiff-line-added">+       movptr(rbx, Address(rbx, ValueKlass::pack_handler_offset()));</span>
<span class="udiff-line-added">+       mov(rax, r13);</span>
<span class="udiff-line-added">+       call(rbx);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     jmp(skip);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   bind(slow_case);</span>
<span class="udiff-line-added">+   // We failed to allocate a new value, fall back to a runtime</span>
<span class="udiff-line-added">+   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="udiff-line-added">+   // tell. That runtime call will take care of preserving them</span>
<span class="udiff-line-added">+   // across a GC if there&#39;s one.</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (from_interpreter) {</span>
<span class="udiff-line-added">+     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     call(RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="udiff-line-added">+     call_offset = offset();</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   bind(skip);</span>
<span class="udiff-line-added">+   return call_offset;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Move a value between registers/stack slots and update the reg_state</span>
<span class="udiff-line-added">+ bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="udiff-line-added">+   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="udiff-line-added">+     return true; // Already written</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="udiff-line-added">+     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="udiff-line-added">+       return false; // Not yet writable</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     if (from-&gt;is_reg()) {</span>
<span class="udiff-line-added">+       if (to-&gt;is_reg()) {</span>
<span class="udiff-line-added">+         if (from-&gt;is_XMMRegister()) {</span>
<span class="udiff-line-added">+           if (bt == T_DOUBLE) {</span>
<span class="udiff-line-added">+             movdbl(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+           } else {</span>
<span class="udiff-line-added">+             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="udiff-line-added">+             movflt(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+           }</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           movq(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="udiff-line-added">+         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="udiff-line-added">+         Address to_addr = Address(rsp, st_off);</span>
<span class="udiff-line-added">+         if (from-&gt;is_XMMRegister()) {</span>
<span class="udiff-line-added">+           if (bt == T_DOUBLE) {</span>
<span class="udiff-line-added">+             movdbl(to_addr, from-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+           } else {</span>
<span class="udiff-line-added">+             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="udiff-line-added">+             movflt(to_addr, from-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+           }</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           movq(to_addr, from-&gt;as_Register());</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       Address from_addr = Address(rsp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="udiff-line-added">+       if (to-&gt;is_reg()) {</span>
<span class="udiff-line-added">+         if (to-&gt;is_XMMRegister()) {</span>
<span class="udiff-line-added">+           if (bt == T_DOUBLE) {</span>
<span class="udiff-line-added">+             movdbl(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="udiff-line-added">+           } else {</span>
<span class="udiff-line-added">+             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="udiff-line-added">+             movflt(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="udiff-line-added">+           }</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           movq(to-&gt;as_Register(), from_addr);</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="udiff-line-added">+         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="udiff-line-added">+         movq(r13, from_addr);</span>
<span class="udiff-line-added">+         movq(Address(rsp, st_off), r13);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   // Update register states</span>
<span class="udiff-line-added">+   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="udiff-line-added">+   reg_state[to-&gt;value()] = reg_written;</span>
<span class="udiff-line-added">+   return true;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="udiff-line-added">+ bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="udiff-line-added">+                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="udiff-line-added">+   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="udiff-line-added">+   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int vt = 1;</span>
<span class="udiff-line-added">+   bool done = true;</span>
<span class="udiff-line-added">+   bool mark_done = true;</span>
<span class="udiff-line-added">+   do {</span>
<span class="udiff-line-added">+     sig_index--;</span>
<span class="udiff-line-added">+     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="udiff-line-added">+     if (bt == T_VALUETYPE) {</span>
<span class="udiff-line-added">+       vt--;</span>
<span class="udiff-line-added">+     } else if (bt == T_VOID &amp;&amp;</span>
<span class="udiff-line-added">+                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="udiff-line-added">+                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="udiff-line-added">+       vt++;</span>
<span class="udiff-line-added">+     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="udiff-line-added">+       to_index--; // Ignore this</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="udiff-line-added">+       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="udiff-line-added">+       VMReg to = pair_to.first();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       if (bt == T_VOID) continue;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       int idx = (int)to-&gt;value();</span>
<span class="udiff-line-added">+       if (reg_state[idx] == reg_readonly) {</span>
<span class="udiff-line-added">+          if (idx != from-&gt;value()) {</span>
<span class="udiff-line-added">+            mark_done = false;</span>
<span class="udiff-line-added">+          }</span>
<span class="udiff-line-added">+          done = false;</span>
<span class="udiff-line-added">+          continue;</span>
<span class="udiff-line-added">+       } else if (reg_state[idx] == reg_written) {</span>
<span class="udiff-line-added">+         continue;</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="udiff-line-added">+         reg_state[idx] = reg_written;</span>
<span class="udiff-line-added">+        }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       if (fromReg == noreg) {</span>
<span class="udiff-line-added">+         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="udiff-line-added">+         movq(r10, Address(rsp, st_off));</span>
<span class="udiff-line-added">+         fromReg = r10;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="udiff-line-added">+       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="udiff-line-added">+       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       Address fromAddr = Address(fromReg, off);</span>
<span class="udiff-line-added">+       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="udiff-line-added">+       if (!to-&gt;is_XMMRegister()) {</span>
<span class="udiff-line-added">+         Register dst = to-&gt;is_stack() ? r13 : to-&gt;as_Register();</span>
<span class="udiff-line-added">+         if (is_oop) {</span>
<span class="udiff-line-added">+           load_heap_oop(dst, fromAddr);</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         if (to-&gt;is_stack()) {</span>
<span class="udiff-line-added">+           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="udiff-line-added">+           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="udiff-line-added">+           movq(Address(rsp, st_off), dst);</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         if (bt == T_DOUBLE) {</span>
<span class="udiff-line-added">+           movdbl(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="udiff-line-added">+           movflt(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   } while (vt != 0);</span>
<span class="udiff-line-added">+   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="udiff-line-added">+     // This is okay because no one else will write to that slot</span>
<span class="udiff-line-added">+     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   return done;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Pack fields back into a value type oop</span>
<span class="udiff-line-added">+ bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="udiff-line-added">+                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="udiff-line-added">+                                        int ret_off, int extra_stack_offset) {</span>
<span class="udiff-line-added">+   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="udiff-line-added">+   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="udiff-line-added">+     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="udiff-line-added">+     return true; // Already written</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   Register val_array = rax;</span>
<span class="udiff-line-added">+   Register val_obj_tmp = r11;</span>
<span class="udiff-line-added">+   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling</span>
<span class="udiff-line-added">+   Register tmp1 = r10;</span>
<span class="udiff-line-added">+   Register tmp2 = r13;</span>
<span class="udiff-line-added">+   Register tmp3 = rbx;</span>
<span class="udiff-line-added">+   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="udiff-line-added">+     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="udiff-line-added">+       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="udiff-line-added">+       return false; // Not yet writable</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     val_obj = val_obj_tmp;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="udiff-line-added">+   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="udiff-line-added">+   VMRegPair from_pair;</span>
<span class="udiff-line-added">+   BasicType bt;</span>
<span class="udiff-line-added">+   while (stream.next(from_pair, bt)) {</span>
<span class="udiff-line-added">+     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="udiff-line-added">+     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="udiff-line-added">+     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="udiff-line-added">+     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     VMReg from_r1 = from_pair.first();</span>
<span class="udiff-line-added">+     VMReg from_r2 = from_pair.second();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Pack the scalarized field into the value object.</span>
<span class="udiff-line-added">+     Address dst(val_obj, off);</span>
<span class="udiff-line-added">+     if (!from_r1-&gt;is_XMMRegister()) {</span>
<span class="udiff-line-added">+       Register from_reg;</span>
<span class="udiff-line-added">+       if (from_r1-&gt;is_stack()) {</span>
<span class="udiff-line-added">+         from_reg = from_reg_tmp;</span>
<span class="udiff-line-added">+         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="udiff-line-added">+         load_sized_value(from_reg, Address(rsp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         from_reg = from_r1-&gt;as_Register();</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       assert_different_registers(dst.base(), from_reg, tmp1, tmp2, tmp3, val_array);</span>
<span class="udiff-line-added">+       if (is_oop) {</span>
<span class="udiff-line-added">+         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       if (from_r2-&gt;is_valid()) {</span>
<span class="udiff-line-added">+         movdbl(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         movflt(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   sig_index = stream.sig_cc_index();</span>
<span class="udiff-line-added">+   from_index = stream.regs_cc_index();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="udiff-line-added">+   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="udiff-line-added">+   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   return true;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Unpack all value type arguments passed as oops</span>
<span class="udiff-line-added">+ void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="udiff-line-added">+   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="udiff-line-added">+   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="udiff-line-added">+   verified_entry(C, sp_inc);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="udiff-line-added">+                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="udiff-line-added">+                                         int args_passed, int args_on_stack, VMRegPair* regs,</span>
<span class="udiff-line-added">+                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {</span>
<span class="udiff-line-added">+   // Check if we need to extend the stack for packing/unpacking</span>
<span class="udiff-line-added">+   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {</span>
<span class="udiff-line-added">+     // Save the return address, adjust the stack (make sure it is properly</span>
<span class="udiff-line-added">+     // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="udiff-line-added">+     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="udiff-line-added">+     pop(r13);</span>
<span class="udiff-line-added">+     subptr(rsp, sp_inc);</span>
<span class="udiff-line-added">+     push(r13);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="udiff-line-added">+   if (is_packing) {</span>
<span class="udiff-line-added">+     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="udiff-line-added">+     // rsp[0] during shuffling.</span>
<span class="udiff-line-added">+     ret_off = 0;</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="udiff-line-added">+     ret_off = sp_inc;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="udiff-line-added">+                             sig_bt, sig_cc,</span>
<span class="udiff-line-added">+                             args_passed, args_on_stack, regs,</span>
<span class="udiff-line-added">+                             args_passed_to, args_on_stack_to, regs_to,</span>
<span class="udiff-line-added">+                             sp_inc, ret_off);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="udiff-line-added">+   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {</span>
<span class="udiff-line-added">+   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="udiff-line-added">+   if (needs_stack_repair) {</span>
<span class="udiff-line-added">+     movq(rbp, Address(rsp, initial_framesize));</span>
<span class="udiff-line-added">+     addq(rsp, Address(rsp, sp_inc_offset));</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     if (initial_framesize &gt; 0) {</span>
<span class="udiff-line-added">+       addq(rsp, initial_framesize);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     pop(rbp);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {</span>
    // cnt - number of qwords (8-byte words).
    // base - start address, qword aligned.
    // is_large - if optimizers know cnt is larger than InitArrayShortSize
    assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="udiff-line-modified-removed">-   assert(tmp==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
<span class="udiff-line-modified-added">+   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
    assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
    assert(InitArrayShortSize % BytesPerLong == 0,
      &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
  
    Label DONE;
  
<span class="udiff-line-removed">-   if (!is_large || !UseXMMForObjInit) {</span>
<span class="udiff-line-removed">-     xorptr(tmp, tmp);</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- </span>
    if (!is_large) {
      Label LOOP, LONG;
      cmpptr(cnt, InitArrayShortSize/BytesPerLong);
      jccb(Assembler::greater, LONG);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4885,25 +5585,24 @@</span>
      decrement(cnt);
      jccb(Assembler::negative, DONE); // Zero length
  
      // Use individual pointer-sized stores for small counts:
      BIND(LOOP);
<span class="udiff-line-modified-removed">-     movptr(Address(base, cnt, Address::times_ptr), tmp);</span>
<span class="udiff-line-modified-added">+     movptr(Address(base, cnt, Address::times_ptr), val);</span>
      decrement(cnt);
      jccb(Assembler::greaterEqual, LOOP);
      jmpb(DONE);
  
      BIND(LONG);
    }
  
    // Use longer rep-prefixed ops for non-small counts:
<span class="udiff-line-modified-removed">-   if (UseFastStosb) {</span>
<span class="udiff-line-modified-added">+   if (UseFastStosb &amp;&amp; !word_copy_only) {</span>
      shlptr(cnt, 3); // convert to number of bytes
      rep_stosb();
    } else if (UseXMMForObjInit) {
<span class="udiff-line-modified-removed">-     movptr(tmp, base);</span>
<span class="udiff-line-removed">-     xmm_clear_mem(tmp, cnt, xtmp);</span>
<span class="udiff-line-modified-added">+     xmm_clear_mem(base, cnt, val, xtmp);</span>
    } else {
      NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
      rep_stos();
    }
  
</pre>
<center><a href="interp_masm_x86.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>