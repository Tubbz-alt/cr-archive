<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;

  48 #include &quot;runtime/stubRoutines.hpp&quot;
  49 #include &quot;runtime/thread.hpp&quot;
  50 #include &quot;utilities/macros.hpp&quot;

  51 #include &quot;crc32c.h&quot;



  52 
  53 #ifdef PRODUCT
  54 #define BLOCK_COMMENT(str) /* nothing */
  55 #define STOP(error) stop(error)
  56 #else
  57 #define BLOCK_COMMENT(str) block_comment(str)
  58 #define STOP(error) block_comment(error); stop(error)
  59 #endif
  60 
  61 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  62 
  63 #ifdef ASSERT
  64 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  65 #endif
  66 
  67 static Assembler::Condition reverse[] = {
  68     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  69     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  70     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  71     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1622 }
1623 
1624 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1625 
1626   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1627   pass_arg1(this, arg_1);
1628   pass_arg0(this, arg_0);
1629   call_VM_leaf(entry_point, 2);
1630 }
1631 
1632 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1633   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1634   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1635   pass_arg2(this, arg_2);
1636   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1637   pass_arg1(this, arg_1);
1638   pass_arg0(this, arg_0);
1639   call_VM_leaf(entry_point, 3);
1640 }
1641 




1642 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1643   pass_arg0(this, arg_0);
1644   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1645 }
1646 
1647 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1648 
1649   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1650   pass_arg1(this, arg_1);
1651   pass_arg0(this, arg_0);
1652   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1653 }
1654 
1655 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1656   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1657   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1658   pass_arg2(this, arg_2);
1659   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1660   pass_arg1(this, arg_1);
1661   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2590     lea(rscratch1, src);
2591     Assembler::mulss(dst, Address(rscratch1, 0));
2592   }
2593 }
2594 
2595 void MacroAssembler::null_check(Register reg, int offset) {
2596   if (needs_explicit_null_check(offset)) {
2597     // provoke OS NULL exception if reg = NULL by
2598     // accessing M[reg] w/o changing any (non-CC) registers
2599     // NOTE: cmpl is plenty here to provoke a segv
2600     cmpptr(rax, Address(reg, 0));
2601     // Note: should probably use testl(rax, Address(reg, 0));
2602     //       may be shorter code (however, this version of
2603     //       testl needs to be implemented first)
2604   } else {
2605     // nothing to do, (later) access of M[reg + offset]
2606     // will provoke OS NULL exception if reg = NULL
2607   }
2608 }
2609 






























































































2610 void MacroAssembler::os_breakpoint() {
2611   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2612   // (e.g., MSVC can&#39;t call ps() otherwise)
2613   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2614 }
2615 
2616 void MacroAssembler::unimplemented(const char* what) {
2617   const char* buf = NULL;
2618   {
2619     ResourceMark rm;
2620     stringStream ss;
2621     ss.print(&quot;unimplemented: %s&quot;, what);
2622     buf = code_string(ss.as_string());
2623   }
2624   stop(buf);
2625 }
2626 
2627 #ifdef _LP64
2628 #define XSTATE_BV 0x200
2629 #endif
</pre>
<hr />
<pre>
3288 }
3289 
3290 // C++ bool manipulation
3291 void MacroAssembler::testbool(Register dst) {
3292   if(sizeof(bool) == 1)
3293     testb(dst, 0xff);
3294   else if(sizeof(bool) == 2) {
3295     // testw implementation needed for two byte bools
3296     ShouldNotReachHere();
3297   } else if(sizeof(bool) == 4)
3298     testl(dst, dst);
3299   else
3300     // unsupported
3301     ShouldNotReachHere();
3302 }
3303 
3304 void MacroAssembler::testptr(Register dst, Register src) {
3305   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3306 }
3307 

































































































































3308 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3309 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3310                                    Register var_size_in_bytes,
3311                                    int con_size_in_bytes,
3312                                    Register t1,
3313                                    Register t2,
3314                                    Label&amp; slow_case) {
3315   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3316   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3317 }
3318 
3319 // Defines obj, preserves var_size_in_bytes
3320 void MacroAssembler::eden_allocate(Register thread, Register obj,
3321                                    Register var_size_in_bytes,
3322                                    int con_size_in_bytes,
3323                                    Register t1,
3324                                    Label&amp; slow_case) {
3325   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3326   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3327 }
</pre>
<hr />
<pre>
3365     // clear topmost word (no jump would be needed if conditional assignment worked here)
3366     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3367     // index could be 0 now, must check again
3368     jcc(Assembler::zero, done);
3369     bind(even);
3370   }
3371 #endif // !_LP64
3372   // initialize remaining object fields: index is a multiple of 2 now
3373   {
3374     Label loop;
3375     bind(loop);
3376     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3377     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3378     decrement(index);
3379     jcc(Assembler::notZero, loop);
3380   }
3381 
3382   bind(done);
3383 }
3384 


















































3385 // Look up the method for a megamorphic invokeinterface call.
3386 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3387 // The receiver klass is in recv_klass.
3388 // On success, the result will be in method_result, and execution falls through.
3389 // On failure, execution transfers to the given label.
3390 void MacroAssembler::lookup_interface_method(Register recv_klass,
3391                                              Register intf_klass,
3392                                              RegisterOrConstant itable_index,
3393                                              Register method_result,
3394                                              Register scan_temp,
3395                                              Label&amp; L_no_such_interface,
3396                                              bool return_method) {
3397   assert_different_registers(recv_klass, intf_klass, scan_temp);
3398   assert_different_registers(method_result, intf_klass, scan_temp);
3399   assert(recv_klass != method_result || !return_method,
3400          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3401 
3402   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3403          &quot;caller must use same register for non-constant itable index as for method&quot;);
3404 
</pre>
<hr />
<pre>
3713   } else {
3714     Label L;
3715     jccb(negate_condition(cc), L);
3716     movl(dst, src);
3717     bind(L);
3718   }
3719 }
3720 
3721 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
3722   if (VM_Version::supports_cmov()) {
3723     cmovl(cc, dst, src);
3724   } else {
3725     Label L;
3726     jccb(negate_condition(cc), L);
3727     movl(dst, src);
3728     bind(L);
3729   }
3730 }
3731 
3732 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">3733   if (!VerifyOops) return;</span>




3734 
3735   // Pass register number to verify_oop_subroutine
3736   const char* b = NULL;
3737   {
3738     ResourceMark rm;
3739     stringStream ss;
3740     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
3741     b = code_string(ss.as_string());
3742   }
3743   BLOCK_COMMENT(&quot;verify_oop {&quot;);
3744 #ifdef _LP64
3745   push(rscratch1);                    // save r10, trashed by movptr()
3746 #endif
3747   push(rax);                          // save rax,
3748   push(reg);                          // pass register argument
3749   ExternalAddress buffer((address) b);
3750   // avoid using pushptr, as it modifies scratch registers
3751   // and our contract is not to modify anything
3752   movptr(rax, buffer.addr());
3753   push(rax);
</pre>
<hr />
<pre>
3811   int stackElementSize = Interpreter::stackElementSize;
3812   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
3813 #ifdef ASSERT
3814   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
3815   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
3816 #endif
3817   Register             scale_reg    = noreg;
3818   Address::ScaleFactor scale_factor = Address::no_scale;
3819   if (arg_slot.is_constant()) {
3820     offset += arg_slot.as_constant() * stackElementSize;
3821   } else {
3822     scale_reg    = arg_slot.as_register();
3823     scale_factor = Address::times(stackElementSize);
3824   }
3825   offset += wordSize;           // return PC is on stack
3826   return Address(rsp, scale_reg, scale_factor, offset);
3827 }
3828 
3829 
3830 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">3831   if (!VerifyOops) return;</span>




3832 
3833   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
3834   // Pass register number to verify_oop_subroutine
3835   const char* b = NULL;
3836   {
3837     ResourceMark rm;
3838     stringStream ss;
3839     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
3840     b = code_string(ss.as_string());
3841   }
3842 #ifdef _LP64
3843   push(rscratch1);                    // save r10, trashed by movptr()
3844 #endif
3845   push(rax);                          // save rax,
3846   // addr may contain rsp so we will have to adjust it based on the push
3847   // we just did (and on 64 bit we do two pushes)
3848   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
3849   // stores rax into addr which is backwards of what was intended.
3850   if (addr.uses(rsp)) {
3851     lea(rax, addr);
</pre>
<hr />
<pre>
4307 
4308 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4309   // get mirror
4310   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4311   load_method_holder(mirror, method);
4312   movptr(mirror, Address(mirror, mirror_offset));
4313   resolve_oop_handle(mirror, tmp);
4314 }
4315 
4316 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4317   load_method_holder(rresult, rmethod);
4318   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4319 }
4320 
4321 void MacroAssembler::load_method_holder(Register holder, Register method) {
4322   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4323   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4324   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4325 }
4326 








4327 void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {
4328   assert_different_registers(src, tmp);
4329   assert_different_registers(dst, tmp);
4330 #ifdef _LP64
4331   if (UseCompressedClassPointers) {
4332     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
4333     decode_klass_not_null(dst, tmp);
4334   } else
4335 #endif
<span class="line-modified">4336     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
4337 }
4338 
4339 void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {
4340   load_klass(dst, src, tmp);
4341   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4342 }
4343 
4344 void MacroAssembler::store_klass(Register dst, Register src, Register tmp) {
4345   assert_different_registers(src, tmp);
4346   assert_different_registers(dst, tmp);
4347 #ifdef _LP64
4348   if (UseCompressedClassPointers) {
4349     encode_klass_not_null(src, tmp);
4350     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4351   } else
4352 #endif
4353     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4354 }
4355 
4356 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4357                                     Register tmp1, Register thread_tmp) {
4358   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4359   decorators = AccessInternal::decorator_fixup(decorators);
4360   bool as_raw = (decorators &amp; AS_RAW) != 0;
4361   if (as_raw) {
4362     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4363   } else {
4364     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4365   }
4366 }
4367 
4368 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4369                                      Register tmp1, Register tmp2) {</span>
4370   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4371   decorators = AccessInternal::decorator_fixup(decorators);
4372   bool as_raw = (decorators &amp; AS_RAW) != 0;
4373   if (as_raw) {
<span class="line-modified">4374     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>






















4375   } else {
<span class="line-modified">4376     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>
4377   }
4378 }
4379 


















4380 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4381   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4382   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4383     decorators |= ACCESS_READ | ACCESS_WRITE;
4384   }
4385   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4386   return bs-&gt;resolve(this, decorators, obj);
4387 }
4388 
4389 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4390                                    Register thread_tmp, DecoratorSet decorators) {
4391   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4392 }
4393 
4394 // Doesn&#39;t do verfication, generates fixed size code
4395 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4396                                             Register thread_tmp, DecoratorSet decorators) {
4397   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4398 }
4399 
4400 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4401                                     Register tmp2, DecoratorSet decorators) {</span>
<span class="line-modified">4402   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);</span>
4403 }
4404 
4405 // Used for storing NULLs.
4406 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4407   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
4408 }
4409 
4410 #ifdef _LP64
4411 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4412   if (UseCompressedClassPointers) {
4413     // Store to klass gap in destination
4414     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4415   }
4416 }
4417 
4418 #ifdef ASSERT
4419 void MacroAssembler::verify_heapbase(const char* msg) {
4420   assert (UseCompressedOops, &quot;should be compressed&quot;);
4421   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4422   if (CheckCompressedOops) {
4423     Label ok;
4424     push(rscratch1); // cmpptr trashes rscratch1
4425     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4426     jcc(Assembler::equal, ok);
4427     STOP(msg);
</pre>
<hr />
<pre>
4702   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
4703 }
4704 
4705 void MacroAssembler::reinit_heapbase() {
4706   if (UseCompressedOops) {
4707     if (Universe::heap() != NULL) {
4708       if (CompressedOops::base() == NULL) {
4709         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
4710       } else {
4711         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
4712       }
4713     } else {
4714       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4715     }
4716   }
4717 }
4718 
4719 #endif // _LP64
4720 
4721 // C2 compiled method&#39;s prolog code.
<span class="line-modified">4722 void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {</span>




4723 
4724   // WARNING: Initial instruction MUST be 5 bytes or longer so that
4725   // NativeJump::patch_verified_entry will be able to patch out the entry
4726   // code safely. The push to verify stack depth is ok at 5 bytes,
4727   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
4728   // stack bang then we must use the 6 byte frame allocation even if
4729   // we have no frame. :-(
4730   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
4731 
4732   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
4733   // Remove word for return addr
4734   framesize -= wordSize;
4735   stack_bang_size -= wordSize;
4736 
4737   // Calls to C2R adapters often do not accept exceptional returns.
4738   // We require that their callers must bang for them.  But be careful, because
4739   // some VM calls (such as call site linkage) can use several kilobytes of
4740   // stack.  But the stack safety zone should account for that.
4741   // See bugs 4446381, 4468289, 4497237.
4742   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
4755     // Create frame
4756     if (framesize) {
4757       subptr(rsp, framesize);
4758     }
4759   } else {
4760     // Create frame (force generation of a 4 byte immediate value)
4761     subptr_imm32(rsp, framesize);
4762 
4763     // Save RBP register now.
4764     framesize -= wordSize;
4765     movptr(Address(rsp, framesize), rbp);
4766     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
4767     if (PreserveFramePointer) {
4768       movptr(rbp, rsp);
4769       if (framesize &gt; 0) {
4770         addptr(rbp, framesize);
4771       }
4772     }
4773   }
4774 






4775   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
4776     framesize -= wordSize;
4777     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
4778   }
4779 
4780 #ifndef _LP64
4781   // If method sets FPU control word do it now
4782   if (fp_mode_24b) {
4783     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
4784   }
4785   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
4786     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
4787   }
4788 #endif
4789 
4790 #ifdef ASSERT
4791   if (VerifyStackAtCalls) {
4792     Label L;
4793     push(rax);
4794     mov(rax, rsp);
4795     andptr(rax, StackAlignmentInBytes-1);
4796     cmpptr(rax, StackAlignmentInBytes-wordSize);
4797     pop(rax);
4798     jcc(Assembler::equal, L);
4799     STOP(&quot;Stack is not properly aligned!&quot;);
4800     bind(L);
4801   }
4802 #endif
<span class="line-removed">4803 </span>
<span class="line-removed">4804   if (!is_stub) {</span>
<span class="line-removed">4805     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-removed">4806     bs-&gt;nmethod_entry_barrier(this);</span>
<span class="line-removed">4807   }</span>
4808 }
4809 
4810 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">4811 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, XMMRegister xtmp) {</span>
4812   // cnt - number of qwords (8-byte words).
4813   // base - start address, qword aligned.
4814   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;

4815   if (UseAVX &gt;= 2) {
<span class="line-modified">4816     vpxor(xtmp, xtmp, xtmp, AVX_256bit);</span>

4817   } else {
<span class="line-modified">4818     pxor(xtmp, xtmp);</span>
4819   }
4820   jmp(L_zero_64_bytes);
4821 
4822   BIND(L_loop);
4823   if (UseAVX &gt;= 2) {
4824     vmovdqu(Address(base,  0), xtmp);
4825     vmovdqu(Address(base, 32), xtmp);
4826   } else {
4827     movdqu(Address(base,  0), xtmp);
4828     movdqu(Address(base, 16), xtmp);
4829     movdqu(Address(base, 32), xtmp);
4830     movdqu(Address(base, 48), xtmp);
4831   }
4832   addptr(base, 64);
4833 
4834   BIND(L_zero_64_bytes);
4835   subptr(cnt, 8);
4836   jccb(Assembler::greaterEqual, L_loop);
4837   addptr(cnt, 4);
4838   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
4842   } else {
4843     movdqu(Address(base,  0), xtmp);
4844     movdqu(Address(base, 16), xtmp);
4845   }
4846   addptr(base, 32);
4847   subptr(cnt, 4);
4848 
4849   BIND(L_tail);
4850   addptr(cnt, 4);
4851   jccb(Assembler::lessEqual, L_end);
4852   decrement(cnt);
4853 
4854   BIND(L_sloop);
4855   movq(Address(base, 0), xtmp);
4856   addptr(base, 8);
4857   decrement(cnt);
4858   jccb(Assembler::greaterEqual, L_sloop);
4859   BIND(L_end);
4860 }
4861 
<span class="line-modified">4862 void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp, bool is_large) {</span>







































































































































































































































































































































































4863   // cnt - number of qwords (8-byte words).
4864   // base - start address, qword aligned.
4865   // is_large - if optimizers know cnt is larger than InitArrayShortSize
4866   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">4867   assert(tmp==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
4868   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
4869   assert(InitArrayShortSize % BytesPerLong == 0,
4870     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
4871 
4872   Label DONE;
4873 
<span class="line-removed">4874   if (!is_large || !UseXMMForObjInit) {</span>
<span class="line-removed">4875     xorptr(tmp, tmp);</span>
<span class="line-removed">4876   }</span>
<span class="line-removed">4877 </span>
4878   if (!is_large) {
4879     Label LOOP, LONG;
4880     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
4881     jccb(Assembler::greater, LONG);
4882 
4883     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4884 
4885     decrement(cnt);
4886     jccb(Assembler::negative, DONE); // Zero length
4887 
4888     // Use individual pointer-sized stores for small counts:
4889     BIND(LOOP);
<span class="line-modified">4890     movptr(Address(base, cnt, Address::times_ptr), tmp);</span>
4891     decrement(cnt);
4892     jccb(Assembler::greaterEqual, LOOP);
4893     jmpb(DONE);
4894 
4895     BIND(LONG);
4896   }
4897 
4898   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">4899   if (UseFastStosb) {</span>
4900     shlptr(cnt, 3); // convert to number of bytes
4901     rep_stosb();
4902   } else if (UseXMMForObjInit) {
<span class="line-modified">4903     movptr(tmp, base);</span>
<span class="line-removed">4904     xmm_clear_mem(tmp, cnt, xtmp);</span>
4905   } else {
4906     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4907     rep_stos();
4908   }
4909 
4910   BIND(DONE);
4911 }
4912 
4913 void MacroAssembler::generate_fill(BasicType t, bool aligned,
4914                                    Register to, Register value, Register count,
4915                                    Register rtmp, XMMRegister xtmp) {
4916   ShortBranchVerifier sbv(this);
4917   assert_different_registers(to, value, count, rtmp);
4918   Label L_exit;
4919   Label L_fill_2_bytes, L_fill_4_bytes;
4920 
4921   int shift = -1;
4922   switch (t) {
4923     case T_BYTE:
4924       shift = 2;
</pre>
</td>
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  48 #include &quot;runtime/signature_cc.hpp&quot;</span>
  49 #include &quot;runtime/stubRoutines.hpp&quot;
  50 #include &quot;runtime/thread.hpp&quot;
  51 #include &quot;utilities/macros.hpp&quot;
<span class="line-added">  52 #include &quot;vmreg_x86.inline.hpp&quot;</span>
  53 #include &quot;crc32c.h&quot;
<span class="line-added">  54 #ifdef COMPILER2</span>
<span class="line-added">  55 #include &quot;opto/output.hpp&quot;</span>
<span class="line-added">  56 #endif</span>
  57 
  58 #ifdef PRODUCT
  59 #define BLOCK_COMMENT(str) /* nothing */
  60 #define STOP(error) stop(error)
  61 #else
  62 #define BLOCK_COMMENT(str) block_comment(str)
  63 #define STOP(error) block_comment(error); stop(error)
  64 #endif
  65 
  66 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  67 
  68 #ifdef ASSERT
  69 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  70 #endif
  71 
  72 static Assembler::Condition reverse[] = {
  73     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  74     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  75     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  76     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1627 }
1628 
1629 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1630 
1631   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1632   pass_arg1(this, arg_1);
1633   pass_arg0(this, arg_0);
1634   call_VM_leaf(entry_point, 2);
1635 }
1636 
1637 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1638   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1639   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1640   pass_arg2(this, arg_2);
1641   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1642   pass_arg1(this, arg_1);
1643   pass_arg0(this, arg_0);
1644   call_VM_leaf(entry_point, 3);
1645 }
1646 
<span class="line-added">1647 void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="line-added">1648   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="line-added">1649 }</span>
<span class="line-added">1650 </span>
1651 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1652   pass_arg0(this, arg_0);
1653   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1654 }
1655 
1656 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1657 
1658   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1659   pass_arg1(this, arg_1);
1660   pass_arg0(this, arg_0);
1661   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1662 }
1663 
1664 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1665   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1666   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1667   pass_arg2(this, arg_2);
1668   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1669   pass_arg1(this, arg_1);
1670   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2599     lea(rscratch1, src);
2600     Assembler::mulss(dst, Address(rscratch1, 0));
2601   }
2602 }
2603 
2604 void MacroAssembler::null_check(Register reg, int offset) {
2605   if (needs_explicit_null_check(offset)) {
2606     // provoke OS NULL exception if reg = NULL by
2607     // accessing M[reg] w/o changing any (non-CC) registers
2608     // NOTE: cmpl is plenty here to provoke a segv
2609     cmpptr(rax, Address(reg, 0));
2610     // Note: should probably use testl(rax, Address(reg, 0));
2611     //       may be shorter code (however, this version of
2612     //       testl needs to be implemented first)
2613   } else {
2614     // nothing to do, (later) access of M[reg + offset]
2615     // will provoke OS NULL exception if reg = NULL
2616   }
2617 }
2618 
<span class="line-added">2619 void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="line-added">2620   movl(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="line-added">2621   testl(temp_reg, JVM_ACC_VALUE);</span>
<span class="line-added">2622   jcc(Assembler::notZero, is_value);</span>
<span class="line-added">2623 }</span>
<span class="line-added">2624 </span>
<span class="line-added">2625 void MacroAssembler::test_klass_is_empty_value(Register klass, Register temp_reg, Label&amp; is_empty_value) {</span>
<span class="line-added">2626 #ifdef ASSERT</span>
<span class="line-added">2627   {</span>
<span class="line-added">2628     Label done_check;</span>
<span class="line-added">2629     test_klass_is_value(klass, temp_reg, done_check);</span>
<span class="line-added">2630     stop(&quot;test_klass_is_empty_value with non value klass&quot;);</span>
<span class="line-added">2631     bind(done_check);</span>
<span class="line-added">2632   }</span>
<span class="line-added">2633 #endif</span>
<span class="line-added">2634   movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));</span>
<span class="line-added">2635   testl(temp_reg, InstanceKlass::misc_flags_is_empty_inline_type());</span>
<span class="line-added">2636   jcc(Assembler::notZero, is_empty_value);</span>
<span class="line-added">2637 }</span>
<span class="line-added">2638 </span>
<span class="line-added">2639 void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="line-added">2640   movl(temp_reg, flags);</span>
<span class="line-added">2641   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2642   andl(temp_reg, 0x1);</span>
<span class="line-added">2643   testl(temp_reg, temp_reg);</span>
<span class="line-added">2644   jcc(Assembler::notZero, is_flattenable);</span>
<span class="line-added">2645 }</span>
<span class="line-added">2646 </span>
<span class="line-added">2647 void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; notFlattenable) {</span>
<span class="line-added">2648   movl(temp_reg, flags);</span>
<span class="line-added">2649   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2650   andl(temp_reg, 0x1);</span>
<span class="line-added">2651   testl(temp_reg, temp_reg);</span>
<span class="line-added">2652   jcc(Assembler::zero, notFlattenable);</span>
<span class="line-added">2653 }</span>
<span class="line-added">2654 </span>
<span class="line-added">2655 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="line-added">2656   movl(temp_reg, flags);</span>
<span class="line-added">2657   shrl(temp_reg, ConstantPoolCacheEntry::is_flattened_field_shift);</span>
<span class="line-added">2658   andl(temp_reg, 0x1);</span>
<span class="line-added">2659   testl(temp_reg, temp_reg);</span>
<span class="line-added">2660   jcc(Assembler::notZero, is_flattened);</span>
<span class="line-added">2661 }</span>
<span class="line-added">2662 </span>
<span class="line-added">2663 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2664                                               Label&amp;is_flattened_array) {</span>
<span class="line-added">2665   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2666   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2667   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2668   test_flattened_array_layout(temp_reg, is_flattened_array);</span>
<span class="line-added">2669 }</span>
<span class="line-added">2670 </span>
<span class="line-added">2671 void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2672                                                   Label&amp;is_non_flattened_array) {</span>
<span class="line-added">2673   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2674   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2675   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2676   test_non_flattened_array_layout(temp_reg, is_non_flattened_array);</span>
<span class="line-added">2677 }</span>
<span class="line-added">2678 </span>
<span class="line-added">2679 void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {</span>
<span class="line-added">2680   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2681   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2682   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2683   test_null_free_array_layout(temp_reg, is_null_free_array);</span>
<span class="line-added">2684 }</span>
<span class="line-added">2685 </span>
<span class="line-added">2686 void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {</span>
<span class="line-added">2687   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">2688   load_klass(temp_reg, oop, tmp_load_klass);</span>
<span class="line-added">2689   movl(temp_reg, Address(temp_reg, Klass::layout_helper_offset()));</span>
<span class="line-added">2690   test_non_null_free_array_layout(temp_reg, is_non_null_free_array);</span>
<span class="line-added">2691 }</span>
<span class="line-added">2692 </span>
<span class="line-added">2693 void MacroAssembler::test_flattened_array_layout(Register lh, Label&amp; is_flattened_array) {</span>
<span class="line-added">2694   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="line-added">2695   jcc(Assembler::notZero, is_flattened_array);</span>
<span class="line-added">2696 }</span>
<span class="line-added">2697 void MacroAssembler::test_non_flattened_array_layout(Register lh, Label&amp; is_non_flattened_array) {</span>
<span class="line-added">2698   testl(lh, Klass::_lh_array_tag_vt_value_bit_inplace);</span>
<span class="line-added">2699   jcc(Assembler::zero, is_non_flattened_array);</span>
<span class="line-added">2700 }</span>
<span class="line-added">2701 </span>
<span class="line-added">2702 void MacroAssembler::test_null_free_array_layout(Register lh, Label&amp; is_null_free_array) {</span>
<span class="line-added">2703   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="line-added">2704   jcc(Assembler::notZero, is_null_free_array);</span>
<span class="line-added">2705 }</span>
<span class="line-added">2706 </span>
<span class="line-added">2707 void MacroAssembler::test_non_null_free_array_layout(Register lh, Label&amp; is_non_null_free_array) {</span>
<span class="line-added">2708   testl(lh, Klass::_lh_null_free_bit_inplace);</span>
<span class="line-added">2709   jcc(Assembler::zero, is_non_null_free_array);</span>
<span class="line-added">2710 }</span>
<span class="line-added">2711 </span>
<span class="line-added">2712 </span>
2713 void MacroAssembler::os_breakpoint() {
2714   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2715   // (e.g., MSVC can&#39;t call ps() otherwise)
2716   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2717 }
2718 
2719 void MacroAssembler::unimplemented(const char* what) {
2720   const char* buf = NULL;
2721   {
2722     ResourceMark rm;
2723     stringStream ss;
2724     ss.print(&quot;unimplemented: %s&quot;, what);
2725     buf = code_string(ss.as_string());
2726   }
2727   stop(buf);
2728 }
2729 
2730 #ifdef _LP64
2731 #define XSTATE_BV 0x200
2732 #endif
</pre>
<hr />
<pre>
3391 }
3392 
3393 // C++ bool manipulation
3394 void MacroAssembler::testbool(Register dst) {
3395   if(sizeof(bool) == 1)
3396     testb(dst, 0xff);
3397   else if(sizeof(bool) == 2) {
3398     // testw implementation needed for two byte bools
3399     ShouldNotReachHere();
3400   } else if(sizeof(bool) == 4)
3401     testl(dst, dst);
3402   else
3403     // unsupported
3404     ShouldNotReachHere();
3405 }
3406 
3407 void MacroAssembler::testptr(Register dst, Register src) {
3408   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3409 }
3410 
<span class="line-added">3411 // Object / value buffer allocation...</span>
<span class="line-added">3412 //</span>
<span class="line-added">3413 // Kills klass and rsi on LP64</span>
<span class="line-added">3414 void MacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="line-added">3415                                        Register t1, Register t2,</span>
<span class="line-added">3416                                        bool clear_fields, Label&amp; alloc_failed)</span>
<span class="line-added">3417 {</span>
<span class="line-added">3418   Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;</span>
<span class="line-added">3419   Register layout_size = t1;</span>
<span class="line-added">3420   assert(new_obj == rax, &quot;needs to be rax, according to barrier asm eden_allocate&quot;);</span>
<span class="line-added">3421   assert_different_registers(klass, new_obj, t1, t2);</span>
<span class="line-added">3422 </span>
<span class="line-added">3423 #ifdef ASSERT</span>
<span class="line-added">3424   {</span>
<span class="line-added">3425     Label L;</span>
<span class="line-added">3426     cmpb(Address(klass, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="line-added">3427     jcc(Assembler::equal, L);</span>
<span class="line-added">3428     stop(&quot;klass not initialized&quot;);</span>
<span class="line-added">3429     bind(L);</span>
<span class="line-added">3430   }</span>
<span class="line-added">3431 #endif</span>
<span class="line-added">3432 </span>
<span class="line-added">3433   // get instance_size in InstanceKlass (scaled to a count of bytes)</span>
<span class="line-added">3434   movl(layout_size, Address(klass, Klass::layout_helper_offset()));</span>
<span class="line-added">3435   // test to see if it has a finalizer or is malformed in some way</span>
<span class="line-added">3436   testl(layout_size, Klass::_lh_instance_slow_path_bit);</span>
<span class="line-added">3437   jcc(Assembler::notZero, slow_case_no_pop);</span>
<span class="line-added">3438 </span>
<span class="line-added">3439   // Allocate the instance:</span>
<span class="line-added">3440   //  If TLAB is enabled:</span>
<span class="line-added">3441   //    Try to allocate in the TLAB.</span>
<span class="line-added">3442   //    If fails, go to the slow path.</span>
<span class="line-added">3443   //  Else If inline contiguous allocations are enabled:</span>
<span class="line-added">3444   //    Try to allocate in eden.</span>
<span class="line-added">3445   //    If fails due to heap end, go to slow path.</span>
<span class="line-added">3446   //</span>
<span class="line-added">3447   //  If TLAB is enabled OR inline contiguous is enabled:</span>
<span class="line-added">3448   //    Initialize the allocation.</span>
<span class="line-added">3449   //    Exit.</span>
<span class="line-added">3450   //</span>
<span class="line-added">3451   //  Go to slow path.</span>
<span class="line-added">3452   const bool allow_shared_alloc =</span>
<span class="line-added">3453     Universe::heap()-&gt;supports_inline_contig_alloc();</span>
<span class="line-added">3454 </span>
<span class="line-added">3455   push(klass);</span>
<span class="line-added">3456   const Register thread = LP64_ONLY(r15_thread) NOT_LP64(klass);</span>
<span class="line-added">3457 #ifndef _LP64</span>
<span class="line-added">3458   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3459     get_thread(thread);</span>
<span class="line-added">3460   }</span>
<span class="line-added">3461 #endif // _LP64</span>
<span class="line-added">3462 </span>
<span class="line-added">3463   if (UseTLAB) {</span>
<span class="line-added">3464     tlab_allocate(thread, new_obj, layout_size, 0, klass, t2, slow_case);</span>
<span class="line-added">3465     if (ZeroTLAB || (!clear_fields)) {</span>
<span class="line-added">3466       // the fields have been already cleared</span>
<span class="line-added">3467       jmp(initialize_header);</span>
<span class="line-added">3468     } else {</span>
<span class="line-added">3469       // initialize both the header and fields</span>
<span class="line-added">3470       jmp(initialize_object);</span>
<span class="line-added">3471     }</span>
<span class="line-added">3472   } else {</span>
<span class="line-added">3473     // Allocation in the shared Eden, if allowed.</span>
<span class="line-added">3474     //</span>
<span class="line-added">3475     eden_allocate(thread, new_obj, layout_size, 0, t2, slow_case);</span>
<span class="line-added">3476   }</span>
<span class="line-added">3477 </span>
<span class="line-added">3478   // If UseTLAB or allow_shared_alloc are true, the object is created above and</span>
<span class="line-added">3479   // there is an initialize need. Otherwise, skip and go to the slow path.</span>
<span class="line-added">3480   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3481     if (clear_fields) {</span>
<span class="line-added">3482       // The object is initialized before the header.  If the object size is</span>
<span class="line-added">3483       // zero, go directly to the header initialization.</span>
<span class="line-added">3484       bind(initialize_object);</span>
<span class="line-added">3485       decrement(layout_size, sizeof(oopDesc));</span>
<span class="line-added">3486       jcc(Assembler::zero, initialize_header);</span>
<span class="line-added">3487 </span>
<span class="line-added">3488       // Initialize topmost object field, divide size by 8, check if odd and</span>
<span class="line-added">3489       // test if zero.</span>
<span class="line-added">3490       Register zero = klass;</span>
<span class="line-added">3491       xorl(zero, zero);    // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3492       shrl(layout_size, LogBytesPerLong); // divide by 2*oopSize and set carry flag if odd</span>
<span class="line-added">3493 </span>
<span class="line-added">3494   #ifdef ASSERT</span>
<span class="line-added">3495       // make sure instance_size was multiple of 8</span>
<span class="line-added">3496       Label L;</span>
<span class="line-added">3497       // Ignore partial flag stall after shrl() since it is debug VM</span>
<span class="line-added">3498       jcc(Assembler::carryClear, L);</span>
<span class="line-added">3499       stop(&quot;object size is not multiple of 2 - adjust this code&quot;);</span>
<span class="line-added">3500       bind(L);</span>
<span class="line-added">3501       // must be &gt; 0, no extra check needed here</span>
<span class="line-added">3502   #endif</span>
<span class="line-added">3503 </span>
<span class="line-added">3504       // initialize remaining object fields: instance_size was a multiple of 8</span>
<span class="line-added">3505       {</span>
<span class="line-added">3506         Label loop;</span>
<span class="line-added">3507         bind(loop);</span>
<span class="line-added">3508         movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 1*oopSize), zero);</span>
<span class="line-added">3509         NOT_LP64(movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 2*oopSize), zero));</span>
<span class="line-added">3510         decrement(layout_size);</span>
<span class="line-added">3511         jcc(Assembler::notZero, loop);</span>
<span class="line-added">3512       }</span>
<span class="line-added">3513     } // clear_fields</span>
<span class="line-added">3514 </span>
<span class="line-added">3515     // initialize object header only.</span>
<span class="line-added">3516     bind(initialize_header);</span>
<span class="line-added">3517     pop(klass);</span>
<span class="line-added">3518     Register mark_word = t2;</span>
<span class="line-added">3519     movptr(mark_word, Address(klass, Klass::prototype_header_offset()));</span>
<span class="line-added">3520     movptr(Address(new_obj, oopDesc::mark_offset_in_bytes ()), mark_word);</span>
<span class="line-added">3521 #ifdef _LP64</span>
<span class="line-added">3522     xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3523     store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops</span>
<span class="line-added">3524 #endif</span>
<span class="line-added">3525     movptr(t2, klass);         // preserve klass</span>
<span class="line-added">3526     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">3527     store_klass(new_obj, t2, tmp_store_klass);  // src klass reg is potentially compressed</span>
<span class="line-added">3528 </span>
<span class="line-added">3529     jmp(done);</span>
<span class="line-added">3530   }</span>
<span class="line-added">3531 </span>
<span class="line-added">3532   bind(slow_case);</span>
<span class="line-added">3533   pop(klass);</span>
<span class="line-added">3534   bind(slow_case_no_pop);</span>
<span class="line-added">3535   jmp(alloc_failed);</span>
<span class="line-added">3536 </span>
<span class="line-added">3537   bind(done);</span>
<span class="line-added">3538 }</span>
<span class="line-added">3539 </span>
3540 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3541 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3542                                    Register var_size_in_bytes,
3543                                    int con_size_in_bytes,
3544                                    Register t1,
3545                                    Register t2,
3546                                    Label&amp; slow_case) {
3547   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3548   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3549 }
3550 
3551 // Defines obj, preserves var_size_in_bytes
3552 void MacroAssembler::eden_allocate(Register thread, Register obj,
3553                                    Register var_size_in_bytes,
3554                                    int con_size_in_bytes,
3555                                    Register t1,
3556                                    Label&amp; slow_case) {
3557   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3558   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3559 }
</pre>
<hr />
<pre>
3597     // clear topmost word (no jump would be needed if conditional assignment worked here)
3598     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3599     // index could be 0 now, must check again
3600     jcc(Assembler::zero, done);
3601     bind(even);
3602   }
3603 #endif // !_LP64
3604   // initialize remaining object fields: index is a multiple of 2 now
3605   {
3606     Label loop;
3607     bind(loop);
3608     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3609     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3610     decrement(index);
3611     jcc(Assembler::notZero, loop);
3612   }
3613 
3614   bind(done);
3615 }
3616 
<span class="line-added">3617 void MacroAssembler::get_value_field_klass(Register klass, Register index, Register value_klass) {</span>
<span class="line-added">3618   movptr(value_klass, Address(klass, InstanceKlass::value_field_klasses_offset()));</span>
<span class="line-added">3619 #ifdef ASSERT</span>
<span class="line-added">3620   {</span>
<span class="line-added">3621     Label done;</span>
<span class="line-added">3622     cmpptr(value_klass, 0);</span>
<span class="line-added">3623     jcc(Assembler::notEqual, done);</span>
<span class="line-added">3624     stop(&quot;get_value_field_klass contains no inline klasses&quot;);</span>
<span class="line-added">3625     bind(done);</span>
<span class="line-added">3626   }</span>
<span class="line-added">3627 #endif</span>
<span class="line-added">3628   movptr(value_klass, Address(value_klass, index, Address::times_ptr));</span>
<span class="line-added">3629 }</span>
<span class="line-added">3630 </span>
<span class="line-added">3631 void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3632 #ifdef ASSERT</span>
<span class="line-added">3633   {</span>
<span class="line-added">3634     Label done_check;</span>
<span class="line-added">3635     test_klass_is_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3636     stop(&quot;get_default_value_oop from non-value klass&quot;);</span>
<span class="line-added">3637     bind(done_check);</span>
<span class="line-added">3638   }</span>
<span class="line-added">3639 #endif</span>
<span class="line-added">3640   Register offset = temp_reg;</span>
<span class="line-added">3641   // Getting the offset of the pre-allocated default value</span>
<span class="line-added">3642   movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_valueklass_fixed_block_offset())));</span>
<span class="line-added">3643   movl(offset, Address(offset, in_bytes(ValueKlass::default_value_offset_offset())));</span>
<span class="line-added">3644 </span>
<span class="line-added">3645   // Getting the mirror</span>
<span class="line-added">3646   movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="line-added">3647   resolve_oop_handle(obj, value_klass);</span>
<span class="line-added">3648 </span>
<span class="line-added">3649   // Getting the pre-allocated default value from the mirror</span>
<span class="line-added">3650   Address field(obj, offset, Address::times_1);</span>
<span class="line-added">3651   load_heap_oop(obj, field);</span>
<span class="line-added">3652 }</span>
<span class="line-added">3653 </span>
<span class="line-added">3654 void MacroAssembler::get_empty_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3655 #ifdef ASSERT</span>
<span class="line-added">3656   {</span>
<span class="line-added">3657     Label done_check;</span>
<span class="line-added">3658     test_klass_is_empty_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3659     stop(&quot;get_empty_value from non-empty value klass&quot;);</span>
<span class="line-added">3660     bind(done_check);</span>
<span class="line-added">3661   }</span>
<span class="line-added">3662 #endif</span>
<span class="line-added">3663   get_default_value_oop(value_klass, temp_reg, obj);</span>
<span class="line-added">3664 }</span>
<span class="line-added">3665 </span>
<span class="line-added">3666 </span>
3667 // Look up the method for a megamorphic invokeinterface call.
3668 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3669 // The receiver klass is in recv_klass.
3670 // On success, the result will be in method_result, and execution falls through.
3671 // On failure, execution transfers to the given label.
3672 void MacroAssembler::lookup_interface_method(Register recv_klass,
3673                                              Register intf_klass,
3674                                              RegisterOrConstant itable_index,
3675                                              Register method_result,
3676                                              Register scan_temp,
3677                                              Label&amp; L_no_such_interface,
3678                                              bool return_method) {
3679   assert_different_registers(recv_klass, intf_klass, scan_temp);
3680   assert_different_registers(method_result, intf_klass, scan_temp);
3681   assert(recv_klass != method_result || !return_method,
3682          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3683 
3684   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3685          &quot;caller must use same register for non-constant itable index as for method&quot;);
3686 
</pre>
<hr />
<pre>
3995   } else {
3996     Label L;
3997     jccb(negate_condition(cc), L);
3998     movl(dst, src);
3999     bind(L);
4000   }
4001 }
4002 
4003 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
4004   if (VM_Version::supports_cmov()) {
4005     cmovl(cc, dst, src);
4006   } else {
4007     Label L;
4008     jccb(negate_condition(cc), L);
4009     movl(dst, src);
4010     bind(L);
4011   }
4012 }
4013 
4014 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">4015   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">4016     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">4017     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">4018     return;</span>
<span class="line-added">4019   }</span>
4020 
4021   // Pass register number to verify_oop_subroutine
4022   const char* b = NULL;
4023   {
4024     ResourceMark rm;
4025     stringStream ss;
4026     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
4027     b = code_string(ss.as_string());
4028   }
4029   BLOCK_COMMENT(&quot;verify_oop {&quot;);
4030 #ifdef _LP64
4031   push(rscratch1);                    // save r10, trashed by movptr()
4032 #endif
4033   push(rax);                          // save rax,
4034   push(reg);                          // pass register argument
4035   ExternalAddress buffer((address) b);
4036   // avoid using pushptr, as it modifies scratch registers
4037   // and our contract is not to modify anything
4038   movptr(rax, buffer.addr());
4039   push(rax);
</pre>
<hr />
<pre>
4097   int stackElementSize = Interpreter::stackElementSize;
4098   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
4099 #ifdef ASSERT
4100   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
4101   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
4102 #endif
4103   Register             scale_reg    = noreg;
4104   Address::ScaleFactor scale_factor = Address::no_scale;
4105   if (arg_slot.is_constant()) {
4106     offset += arg_slot.as_constant() * stackElementSize;
4107   } else {
4108     scale_reg    = arg_slot.as_register();
4109     scale_factor = Address::times(stackElementSize);
4110   }
4111   offset += wordSize;           // return PC is on stack
4112   return Address(rsp, scale_reg, scale_factor, offset);
4113 }
4114 
4115 
4116 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">4117   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">4118     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">4119     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">4120     return;</span>
<span class="line-added">4121   }</span>
4122 
4123   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
4124   // Pass register number to verify_oop_subroutine
4125   const char* b = NULL;
4126   {
4127     ResourceMark rm;
4128     stringStream ss;
4129     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
4130     b = code_string(ss.as_string());
4131   }
4132 #ifdef _LP64
4133   push(rscratch1);                    // save r10, trashed by movptr()
4134 #endif
4135   push(rax);                          // save rax,
4136   // addr may contain rsp so we will have to adjust it based on the push
4137   // we just did (and on 64 bit we do two pushes)
4138   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
4139   // stores rax into addr which is backwards of what was intended.
4140   if (addr.uses(rsp)) {
4141     lea(rax, addr);
</pre>
<hr />
<pre>
4597 
4598 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4599   // get mirror
4600   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4601   load_method_holder(mirror, method);
4602   movptr(mirror, Address(mirror, mirror_offset));
4603   resolve_oop_handle(mirror, tmp);
4604 }
4605 
4606 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4607   load_method_holder(rresult, rmethod);
4608   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4609 }
4610 
4611 void MacroAssembler::load_method_holder(Register holder, Register method) {
4612   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4613   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4614   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4615 }
4616 
<span class="line-added">4617 void MacroAssembler::load_metadata(Register dst, Register src) {</span>
<span class="line-added">4618   if (UseCompressedClassPointers) {</span>
<span class="line-added">4619     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4620   } else {</span>
<span class="line-added">4621     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4622   }</span>
<span class="line-added">4623 }</span>
<span class="line-added">4624 </span>
4625 void MacroAssembler::load_klass(Register dst, Register src, Register tmp) {
4626   assert_different_registers(src, tmp);
4627   assert_different_registers(dst, tmp);
4628 #ifdef _LP64
4629   if (UseCompressedClassPointers) {
4630     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));
4631     decode_klass_not_null(dst, tmp);
4632   } else
4633 #endif
<span class="line-modified">4634   movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
4635 }
4636 
4637 void MacroAssembler::load_prototype_header(Register dst, Register src, Register tmp) {
4638   load_klass(dst, src, tmp);
4639   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4640 }
4641 
4642 void MacroAssembler::store_klass(Register dst, Register src, Register tmp) {
4643   assert_different_registers(src, tmp);
4644   assert_different_registers(dst, tmp);
4645 #ifdef _LP64
4646   if (UseCompressedClassPointers) {
4647     encode_klass_not_null(src, tmp);
4648     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4649   } else
4650 #endif
4651     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4652 }
4653 
4654 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4655                                     Register tmp1, Register thread_tmp) {
4656   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4657   decorators = AccessInternal::decorator_fixup(decorators);
4658   bool as_raw = (decorators &amp; AS_RAW) != 0;
4659   if (as_raw) {
4660     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4661   } else {
4662     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4663   }
4664 }
4665 
4666 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4667                                      Register tmp1, Register tmp2, Register tmp3) {</span>
4668   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4669   decorators = AccessInternal::decorator_fixup(decorators);
4670   bool as_raw = (decorators &amp; AS_RAW) != 0;
4671   if (as_raw) {
<span class="line-modified">4672     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4673   } else {</span>
<span class="line-added">4674     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4675   }</span>
<span class="line-added">4676 }</span>
<span class="line-added">4677 </span>
<span class="line-added">4678 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,</span>
<span class="line-added">4679                                        Register value_klass) {</span>
<span class="line-added">4680   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added">4681   bs-&gt;value_copy(this, decorators, src, dst, value_klass);</span>
<span class="line-added">4682 }</span>
<span class="line-added">4683 </span>
<span class="line-added">4684 void MacroAssembler::first_field_offset(Register value_klass, Register offset) {</span>
<span class="line-added">4685   movptr(offset, Address(value_klass, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">4686   movl(offset, Address(offset, ValueKlass::first_field_offset_offset()));</span>
<span class="line-added">4687 }</span>
<span class="line-added">4688 </span>
<span class="line-added">4689 void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {</span>
<span class="line-added">4690   // ((address) (void*) o) + vk-&gt;first_field_offset();</span>
<span class="line-added">4691   Register offset = (data == oop) ? rscratch1 : data;</span>
<span class="line-added">4692   first_field_offset(value_klass, offset);</span>
<span class="line-added">4693   if (data == oop) {</span>
<span class="line-added">4694     addptr(data, offset);</span>
4695   } else {
<span class="line-modified">4696     lea(data, Address(oop, offset));</span>
4697   }
4698 }
4699 
<span class="line-added">4700 void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,</span>
<span class="line-added">4701                                                 Register index, Register data) {</span>
<span class="line-added">4702   assert(index != rcx, &quot;index needs to shift by rcx&quot;);</span>
<span class="line-added">4703   assert_different_registers(array, array_klass, index);</span>
<span class="line-added">4704   assert_different_registers(rcx, array, index);</span>
<span class="line-added">4705 </span>
<span class="line-added">4706   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));</span>
<span class="line-added">4707   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));</span>
<span class="line-added">4708 </span>
<span class="line-added">4709   // Klass::layout_helper_log2_element_size(lh)</span>
<span class="line-added">4710   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;</span>
<span class="line-added">4711   shrl(rcx, Klass::_lh_log2_element_size_shift);</span>
<span class="line-added">4712   andl(rcx, Klass::_lh_log2_element_size_mask);</span>
<span class="line-added">4713   shlptr(index); // index &lt;&lt; rcx</span>
<span class="line-added">4714 </span>
<span class="line-added">4715   lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_VALUETYPE)));</span>
<span class="line-added">4716 }</span>
<span class="line-added">4717 </span>
4718 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4719   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4720   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4721     decorators |= ACCESS_READ | ACCESS_WRITE;
4722   }
4723   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4724   return bs-&gt;resolve(this, decorators, obj);
4725 }
4726 
4727 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4728                                    Register thread_tmp, DecoratorSet decorators) {
4729   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4730 }
4731 
4732 // Doesn&#39;t do verfication, generates fixed size code
4733 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4734                                             Register thread_tmp, DecoratorSet decorators) {
4735   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4736 }
4737 
4738 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4739                                     Register tmp2, Register tmp3, DecoratorSet decorators) {</span>
<span class="line-modified">4740   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2, tmp3);</span>
4741 }
4742 
4743 // Used for storing NULLs.
4744 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4745   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
4746 }
4747 
4748 #ifdef _LP64
4749 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4750   if (UseCompressedClassPointers) {
4751     // Store to klass gap in destination
4752     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4753   }
4754 }
4755 
4756 #ifdef ASSERT
4757 void MacroAssembler::verify_heapbase(const char* msg) {
4758   assert (UseCompressedOops, &quot;should be compressed&quot;);
4759   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4760   if (CheckCompressedOops) {
4761     Label ok;
4762     push(rscratch1); // cmpptr trashes rscratch1
4763     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4764     jcc(Assembler::equal, ok);
4765     STOP(msg);
</pre>
<hr />
<pre>
5040   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
5041 }
5042 
5043 void MacroAssembler::reinit_heapbase() {
5044   if (UseCompressedOops) {
5045     if (Universe::heap() != NULL) {
5046       if (CompressedOops::base() == NULL) {
5047         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
5048       } else {
5049         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
5050       }
5051     } else {
5052       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
5053     }
5054   }
5055 }
5056 
5057 #endif // _LP64
5058 
5059 // C2 compiled method&#39;s prolog code.
<span class="line-modified">5060 void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="line-added">5061   int framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-added">5062   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-added">5063   bool fp_mode_24b = false;</span>
<span class="line-added">5064   int stack_bang_size = C-&gt;output()-&gt;need_stack_bang(bangsize) ? bangsize : 0;</span>
5065 
5066   // WARNING: Initial instruction MUST be 5 bytes or longer so that
5067   // NativeJump::patch_verified_entry will be able to patch out the entry
5068   // code safely. The push to verify stack depth is ok at 5 bytes,
5069   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
5070   // stack bang then we must use the 6 byte frame allocation even if
5071   // we have no frame. :-(
5072   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
5073 
5074   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
5075   // Remove word for return addr
5076   framesize -= wordSize;
5077   stack_bang_size -= wordSize;
5078 
5079   // Calls to C2R adapters often do not accept exceptional returns.
5080   // We require that their callers must bang for them.  But be careful, because
5081   // some VM calls (such as call site linkage) can use several kilobytes of
5082   // stack.  But the stack safety zone should account for that.
5083   // See bugs 4446381, 4468289, 4497237.
5084   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
5097     // Create frame
5098     if (framesize) {
5099       subptr(rsp, framesize);
5100     }
5101   } else {
5102     // Create frame (force generation of a 4 byte immediate value)
5103     subptr_imm32(rsp, framesize);
5104 
5105     // Save RBP register now.
5106     framesize -= wordSize;
5107     movptr(Address(rsp, framesize), rbp);
5108     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
5109     if (PreserveFramePointer) {
5110       movptr(rbp, rsp);
5111       if (framesize &gt; 0) {
5112         addptr(rbp, framesize);
5113       }
5114     }
5115   }
5116 
<span class="line-added">5117   if (C-&gt;needs_stack_repair()) {</span>
<span class="line-added">5118     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="line-added">5119     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="line-added">5120     movptr(Address(rsp, C-&gt;output()-&gt;sp_inc_offset()), sp_inc + framesize + wordSize);</span>
<span class="line-added">5121   }</span>
<span class="line-added">5122 </span>
5123   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
5124     framesize -= wordSize;
5125     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
5126   }
5127 
5128 #ifndef _LP64
5129   // If method sets FPU control word do it now
5130   if (fp_mode_24b) {
5131     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
5132   }
5133   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
5134     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
5135   }
5136 #endif
5137 
5138 #ifdef ASSERT
5139   if (VerifyStackAtCalls) {
5140     Label L;
5141     push(rax);
5142     mov(rax, rsp);
5143     andptr(rax, StackAlignmentInBytes-1);
5144     cmpptr(rax, StackAlignmentInBytes-wordSize);
5145     pop(rax);
5146     jcc(Assembler::equal, L);
5147     STOP(&quot;Stack is not properly aligned!&quot;);
5148     bind(L);
5149   }
5150 #endif





5151 }
5152 
5153 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">5154 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp) {</span>
5155   // cnt - number of qwords (8-byte words).
5156   // base - start address, qword aligned.
5157   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;
<span class="line-added">5158   movdq(xtmp, val);</span>
5159   if (UseAVX &gt;= 2) {
<span class="line-modified">5160     punpcklqdq(xtmp, xtmp);</span>
<span class="line-added">5161     vinserti128_high(xtmp, xtmp);</span>
5162   } else {
<span class="line-modified">5163     punpcklqdq(xtmp, xtmp);</span>
5164   }
5165   jmp(L_zero_64_bytes);
5166 
5167   BIND(L_loop);
5168   if (UseAVX &gt;= 2) {
5169     vmovdqu(Address(base,  0), xtmp);
5170     vmovdqu(Address(base, 32), xtmp);
5171   } else {
5172     movdqu(Address(base,  0), xtmp);
5173     movdqu(Address(base, 16), xtmp);
5174     movdqu(Address(base, 32), xtmp);
5175     movdqu(Address(base, 48), xtmp);
5176   }
5177   addptr(base, 64);
5178 
5179   BIND(L_zero_64_bytes);
5180   subptr(cnt, 8);
5181   jccb(Assembler::greaterEqual, L_loop);
5182   addptr(cnt, 4);
5183   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
5187   } else {
5188     movdqu(Address(base,  0), xtmp);
5189     movdqu(Address(base, 16), xtmp);
5190   }
5191   addptr(base, 32);
5192   subptr(cnt, 4);
5193 
5194   BIND(L_tail);
5195   addptr(cnt, 4);
5196   jccb(Assembler::lessEqual, L_end);
5197   decrement(cnt);
5198 
5199   BIND(L_sloop);
5200   movq(Address(base, 0), xtmp);
5201   addptr(base, 8);
5202   decrement(cnt);
5203   jccb(Assembler::greaterEqual, L_sloop);
5204   BIND(L_end);
5205 }
5206 
<span class="line-modified">5207 int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="line-added">5208   // A value type might be returned. If fields are in registers we</span>
<span class="line-added">5209   // need to allocate a value type instance and initialize it with</span>
<span class="line-added">5210   // the value of the fields.</span>
<span class="line-added">5211   Label skip;</span>
<span class="line-added">5212   // We only need a new buffered value if a new one is not returned</span>
<span class="line-added">5213   testptr(rax, 1);</span>
<span class="line-added">5214   jcc(Assembler::zero, skip);</span>
<span class="line-added">5215   int call_offset = -1;</span>
<span class="line-added">5216 </span>
<span class="line-added">5217 #ifdef _LP64</span>
<span class="line-added">5218   Label slow_case;</span>
<span class="line-added">5219 </span>
<span class="line-added">5220   // Try to allocate a new buffered value (from the heap)</span>
<span class="line-added">5221   if (UseTLAB) {</span>
<span class="line-added">5222     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.</span>
<span class="line-added">5223     if (vk != NULL) {</span>
<span class="line-added">5224       // Called from C1, where the return type is statically known.</span>
<span class="line-added">5225       movptr(rbx, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="line-added">5226       jint lh = vk-&gt;layout_helper();</span>
<span class="line-added">5227       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="line-added">5228       movl(r14, lh);</span>
<span class="line-added">5229     } else {</span>
<span class="line-added">5230       // Call from interpreter. RAX contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="line-added">5231       mov(rbx, rax);</span>
<span class="line-added">5232       andptr(rbx, -2);</span>
<span class="line-added">5233       movl(r14, Address(rbx, Klass::layout_helper_offset()));</span>
<span class="line-added">5234     }</span>
<span class="line-added">5235 </span>
<span class="line-added">5236     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5237     lea(r14, Address(r13, r14, Address::times_1));</span>
<span class="line-added">5238     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="line-added">5239     jcc(Assembler::above, slow_case);</span>
<span class="line-added">5240     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);</span>
<span class="line-added">5241     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());</span>
<span class="line-added">5242 </span>
<span class="line-added">5243     xorl(rax, rax); // use zero reg to clear memory (shorter code)</span>
<span class="line-added">5244     store_klass_gap(r13, rax);  // zero klass gap for compressed oops</span>
<span class="line-added">5245 </span>
<span class="line-added">5246     if (vk == NULL) {</span>
<span class="line-added">5247       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="line-added">5248       mov(rax, rbx);</span>
<span class="line-added">5249     }</span>
<span class="line-added">5250     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">5251     store_klass(r13, rbx, tmp_store_klass);  // klass</span>
<span class="line-added">5252 </span>
<span class="line-added">5253     // We have our new buffered value, initialize its fields with a</span>
<span class="line-added">5254     // value class specific handler</span>
<span class="line-added">5255     if (vk != NULL) {</span>
<span class="line-added">5256       // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="line-added">5257       mov(rax, r13);</span>
<span class="line-added">5258       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="line-added">5259     } else {</span>
<span class="line-added">5260       movptr(rbx, Address(rax, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">5261       movptr(rbx, Address(rbx, ValueKlass::pack_handler_offset()));</span>
<span class="line-added">5262       mov(rax, r13);</span>
<span class="line-added">5263       call(rbx);</span>
<span class="line-added">5264     }</span>
<span class="line-added">5265     jmp(skip);</span>
<span class="line-added">5266   }</span>
<span class="line-added">5267 </span>
<span class="line-added">5268   bind(slow_case);</span>
<span class="line-added">5269   // We failed to allocate a new value, fall back to a runtime</span>
<span class="line-added">5270   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="line-added">5271   // tell. That runtime call will take care of preserving them</span>
<span class="line-added">5272   // across a GC if there&#39;s one.</span>
<span class="line-added">5273 #endif</span>
<span class="line-added">5274 </span>
<span class="line-added">5275   if (from_interpreter) {</span>
<span class="line-added">5276     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="line-added">5277   } else {</span>
<span class="line-added">5278     call(RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="line-added">5279     call_offset = offset();</span>
<span class="line-added">5280   }</span>
<span class="line-added">5281 </span>
<span class="line-added">5282   bind(skip);</span>
<span class="line-added">5283   return call_offset;</span>
<span class="line-added">5284 }</span>
<span class="line-added">5285 </span>
<span class="line-added">5286 </span>
<span class="line-added">5287 // Move a value between registers/stack slots and update the reg_state</span>
<span class="line-added">5288 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5289   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5290     return true; // Already written</span>
<span class="line-added">5291   }</span>
<span class="line-added">5292   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="line-added">5293     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5294       return false; // Not yet writable</span>
<span class="line-added">5295     }</span>
<span class="line-added">5296     if (from-&gt;is_reg()) {</span>
<span class="line-added">5297       if (to-&gt;is_reg()) {</span>
<span class="line-added">5298         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5299           if (bt == T_DOUBLE) {</span>
<span class="line-added">5300             movdbl(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5301           } else {</span>
<span class="line-added">5302             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5303             movflt(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5304           }</span>
<span class="line-added">5305         } else {</span>
<span class="line-added">5306           movq(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="line-added">5307         }</span>
<span class="line-added">5308       } else {</span>
<span class="line-added">5309         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5310         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5311         Address to_addr = Address(rsp, st_off);</span>
<span class="line-added">5312         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5313           if (bt == T_DOUBLE) {</span>
<span class="line-added">5314             movdbl(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5315           } else {</span>
<span class="line-added">5316             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5317             movflt(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5318           }</span>
<span class="line-added">5319         } else {</span>
<span class="line-added">5320           movq(to_addr, from-&gt;as_Register());</span>
<span class="line-added">5321         }</span>
<span class="line-added">5322       }</span>
<span class="line-added">5323     } else {</span>
<span class="line-added">5324       Address from_addr = Address(rsp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="line-added">5325       if (to-&gt;is_reg()) {</span>
<span class="line-added">5326         if (to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5327           if (bt == T_DOUBLE) {</span>
<span class="line-added">5328             movdbl(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5329           } else {</span>
<span class="line-added">5330             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5331             movflt(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5332           }</span>
<span class="line-added">5333         } else {</span>
<span class="line-added">5334           movq(to-&gt;as_Register(), from_addr);</span>
<span class="line-added">5335         }</span>
<span class="line-added">5336       } else {</span>
<span class="line-added">5337         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5338         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5339         movq(r13, from_addr);</span>
<span class="line-added">5340         movq(Address(rsp, st_off), r13);</span>
<span class="line-added">5341       }</span>
<span class="line-added">5342     }</span>
<span class="line-added">5343   }</span>
<span class="line-added">5344   // Update register states</span>
<span class="line-added">5345   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5346   reg_state[to-&gt;value()] = reg_written;</span>
<span class="line-added">5347   return true;</span>
<span class="line-added">5348 }</span>
<span class="line-added">5349 </span>
<span class="line-added">5350 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-added">5351 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-added">5352                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5353   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="line-added">5354   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5355 </span>
<span class="line-added">5356   int vt = 1;</span>
<span class="line-added">5357   bool done = true;</span>
<span class="line-added">5358   bool mark_done = true;</span>
<span class="line-added">5359   do {</span>
<span class="line-added">5360     sig_index--;</span>
<span class="line-added">5361     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="line-added">5362     if (bt == T_VALUETYPE) {</span>
<span class="line-added">5363       vt--;</span>
<span class="line-added">5364     } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">5365                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="line-added">5366                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="line-added">5367       vt++;</span>
<span class="line-added">5368     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="line-added">5369       to_index--; // Ignore this</span>
<span class="line-added">5370     } else {</span>
<span class="line-added">5371       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="line-added">5372       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="line-added">5373       VMReg to = pair_to.first();</span>
<span class="line-added">5374 </span>
<span class="line-added">5375       if (bt == T_VOID) continue;</span>
<span class="line-added">5376 </span>
<span class="line-added">5377       int idx = (int)to-&gt;value();</span>
<span class="line-added">5378       if (reg_state[idx] == reg_readonly) {</span>
<span class="line-added">5379          if (idx != from-&gt;value()) {</span>
<span class="line-added">5380            mark_done = false;</span>
<span class="line-added">5381          }</span>
<span class="line-added">5382          done = false;</span>
<span class="line-added">5383          continue;</span>
<span class="line-added">5384       } else if (reg_state[idx] == reg_written) {</span>
<span class="line-added">5385         continue;</span>
<span class="line-added">5386       } else {</span>
<span class="line-added">5387         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="line-added">5388         reg_state[idx] = reg_written;</span>
<span class="line-added">5389        }</span>
<span class="line-added">5390 </span>
<span class="line-added">5391       if (fromReg == noreg) {</span>
<span class="line-added">5392         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5393         movq(r10, Address(rsp, st_off));</span>
<span class="line-added">5394         fromReg = r10;</span>
<span class="line-added">5395       }</span>
<span class="line-added">5396 </span>
<span class="line-added">5397       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="line-added">5398       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5399       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5400 </span>
<span class="line-added">5401       Address fromAddr = Address(fromReg, off);</span>
<span class="line-added">5402       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="line-added">5403       if (!to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5404         Register dst = to-&gt;is_stack() ? r13 : to-&gt;as_Register();</span>
<span class="line-added">5405         if (is_oop) {</span>
<span class="line-added">5406           load_heap_oop(dst, fromAddr);</span>
<span class="line-added">5407         } else {</span>
<span class="line-added">5408           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="line-added">5409         }</span>
<span class="line-added">5410         if (to-&gt;is_stack()) {</span>
<span class="line-added">5411           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5412           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5413           movq(Address(rsp, st_off), dst);</span>
<span class="line-added">5414         }</span>
<span class="line-added">5415       } else {</span>
<span class="line-added">5416         if (bt == T_DOUBLE) {</span>
<span class="line-added">5417           movdbl(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5418         } else {</span>
<span class="line-added">5419           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5420           movflt(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5421         }</span>
<span class="line-added">5422       }</span>
<span class="line-added">5423     }</span>
<span class="line-added">5424   } while (vt != 0);</span>
<span class="line-added">5425   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="line-added">5426     // This is okay because no one else will write to that slot</span>
<span class="line-added">5427     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5428   }</span>
<span class="line-added">5429   return done;</span>
<span class="line-added">5430 }</span>
<span class="line-added">5431 </span>
<span class="line-added">5432 // Pack fields back into a value type oop</span>
<span class="line-added">5433 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-added">5434                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-added">5435                                        int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5436   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5437   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="line-added">5438 </span>
<span class="line-added">5439   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5440     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5441     return true; // Already written</span>
<span class="line-added">5442   }</span>
<span class="line-added">5443 </span>
<span class="line-added">5444   Register val_array = rax;</span>
<span class="line-added">5445   Register val_obj_tmp = r11;</span>
<span class="line-added">5446   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling</span>
<span class="line-added">5447   Register tmp1 = r10;</span>
<span class="line-added">5448   Register tmp2 = r13;</span>
<span class="line-added">5449   Register tmp3 = rbx;</span>
<span class="line-added">5450   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="line-added">5451 </span>
<span class="line-added">5452   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5453     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="line-added">5454       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5455       return false; // Not yet writable</span>
<span class="line-added">5456     }</span>
<span class="line-added">5457     val_obj = val_obj_tmp;</span>
<span class="line-added">5458   }</span>
<span class="line-added">5459 </span>
<span class="line-added">5460   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="line-added">5461   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="line-added">5462 </span>
<span class="line-added">5463   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5464   VMRegPair from_pair;</span>
<span class="line-added">5465   BasicType bt;</span>
<span class="line-added">5466   while (stream.next(from_pair, bt)) {</span>
<span class="line-added">5467     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="line-added">5468     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5469     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5470     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">5471 </span>
<span class="line-added">5472     VMReg from_r1 = from_pair.first();</span>
<span class="line-added">5473     VMReg from_r2 = from_pair.second();</span>
<span class="line-added">5474 </span>
<span class="line-added">5475     // Pack the scalarized field into the value object.</span>
<span class="line-added">5476     Address dst(val_obj, off);</span>
<span class="line-added">5477     if (!from_r1-&gt;is_XMMRegister()) {</span>
<span class="line-added">5478       Register from_reg;</span>
<span class="line-added">5479       if (from_r1-&gt;is_stack()) {</span>
<span class="line-added">5480         from_reg = from_reg_tmp;</span>
<span class="line-added">5481         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5482         load_sized_value(from_reg, Address(rsp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">5483       } else {</span>
<span class="line-added">5484         from_reg = from_r1-&gt;as_Register();</span>
<span class="line-added">5485       }</span>
<span class="line-added">5486       assert_different_registers(dst.base(), from_reg, tmp1, tmp2, tmp3, val_array);</span>
<span class="line-added">5487       if (is_oop) {</span>
<span class="line-added">5488         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="line-added">5489       } else {</span>
<span class="line-added">5490         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="line-added">5491       }</span>
<span class="line-added">5492     } else {</span>
<span class="line-added">5493       if (from_r2-&gt;is_valid()) {</span>
<span class="line-added">5494         movdbl(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5495       } else {</span>
<span class="line-added">5496         movflt(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5497       }</span>
<span class="line-added">5498     }</span>
<span class="line-added">5499     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="line-added">5500   }</span>
<span class="line-added">5501   sig_index = stream.sig_cc_index();</span>
<span class="line-added">5502   from_index = stream.regs_cc_index();</span>
<span class="line-added">5503 </span>
<span class="line-added">5504   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="line-added">5505   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="line-added">5506   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="line-added">5507 </span>
<span class="line-added">5508   return true;</span>
<span class="line-added">5509 }</span>
<span class="line-added">5510 </span>
<span class="line-added">5511 // Unpack all value type arguments passed as oops</span>
<span class="line-added">5512 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-added">5513   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="line-added">5514   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="line-added">5515   verified_entry(C, sp_inc);</span>
<span class="line-added">5516 }</span>
<span class="line-added">5517 </span>
<span class="line-added">5518 void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-added">5519                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">5520                                         int args_passed, int args_on_stack, VMRegPair* regs,</span>
<span class="line-added">5521                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {</span>
<span class="line-added">5522   // Check if we need to extend the stack for packing/unpacking</span>
<span class="line-added">5523   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {</span>
<span class="line-added">5524     // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-added">5525     // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-added">5526     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-added">5527     pop(r13);</span>
<span class="line-added">5528     subptr(rsp, sp_inc);</span>
<span class="line-added">5529     push(r13);</span>
<span class="line-added">5530   }</span>
<span class="line-added">5531 </span>
<span class="line-added">5532   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="line-added">5533   if (is_packing) {</span>
<span class="line-added">5534     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="line-added">5535     // rsp[0] during shuffling.</span>
<span class="line-added">5536     ret_off = 0;</span>
<span class="line-added">5537   } else {</span>
<span class="line-added">5538     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="line-added">5539     ret_off = sp_inc;</span>
<span class="line-added">5540   }</span>
<span class="line-added">5541 </span>
<span class="line-added">5542   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-added">5543                             sig_bt, sig_cc,</span>
<span class="line-added">5544                             args_passed, args_on_stack, regs,</span>
<span class="line-added">5545                             args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-added">5546                             sp_inc, ret_off);</span>
<span class="line-added">5547 }</span>
<span class="line-added">5548 </span>
<span class="line-added">5549 VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="line-added">5550   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="line-added">5551 }</span>
<span class="line-added">5552 </span>
<span class="line-added">5553 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {</span>
<span class="line-added">5554   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="line-added">5555   if (needs_stack_repair) {</span>
<span class="line-added">5556     movq(rbp, Address(rsp, initial_framesize));</span>
<span class="line-added">5557     addq(rsp, Address(rsp, sp_inc_offset));</span>
<span class="line-added">5558   } else {</span>
<span class="line-added">5559     if (initial_framesize &gt; 0) {</span>
<span class="line-added">5560       addq(rsp, initial_framesize);</span>
<span class="line-added">5561     }</span>
<span class="line-added">5562     pop(rbp);</span>
<span class="line-added">5563   }</span>
<span class="line-added">5564 }</span>
<span class="line-added">5565 </span>
<span class="line-added">5566 void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {</span>
5567   // cnt - number of qwords (8-byte words).
5568   // base - start address, qword aligned.
5569   // is_large - if optimizers know cnt is larger than InitArrayShortSize
5570   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">5571   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
5572   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
5573   assert(InitArrayShortSize % BytesPerLong == 0,
5574     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
5575 
5576   Label DONE;
5577 




5578   if (!is_large) {
5579     Label LOOP, LONG;
5580     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
5581     jccb(Assembler::greater, LONG);
5582 
5583     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5584 
5585     decrement(cnt);
5586     jccb(Assembler::negative, DONE); // Zero length
5587 
5588     // Use individual pointer-sized stores for small counts:
5589     BIND(LOOP);
<span class="line-modified">5590     movptr(Address(base, cnt, Address::times_ptr), val);</span>
5591     decrement(cnt);
5592     jccb(Assembler::greaterEqual, LOOP);
5593     jmpb(DONE);
5594 
5595     BIND(LONG);
5596   }
5597 
5598   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">5599   if (UseFastStosb &amp;&amp; !word_copy_only) {</span>
5600     shlptr(cnt, 3); // convert to number of bytes
5601     rep_stosb();
5602   } else if (UseXMMForObjInit) {
<span class="line-modified">5603     xmm_clear_mem(base, cnt, val, xtmp);</span>

5604   } else {
5605     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5606     rep_stos();
5607   }
5608 
5609   BIND(DONE);
5610 }
5611 
5612 void MacroAssembler::generate_fill(BasicType t, bool aligned,
5613                                    Register to, Register value, Register count,
5614                                    Register rtmp, XMMRegister xtmp) {
5615   ShortBranchVerifier sbv(this);
5616   assert_different_registers(to, value, count, rtmp);
5617   Label L_exit;
5618   Label L_fill_2_bytes, L_fill_4_bytes;
5619 
5620   int shift = -1;
5621   switch (t) {
5622     case T_BYTE:
5623       shift = 2;
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>