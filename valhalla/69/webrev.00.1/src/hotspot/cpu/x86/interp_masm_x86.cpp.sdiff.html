<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/interp_masm_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/interp_masm_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;interp_masm_x86.hpp&quot;
  27 #include &quot;interpreter/interpreter.hpp&quot;
  28 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  29 #include &quot;logging/log.hpp&quot;
  30 #include &quot;oops/arrayOop.hpp&quot;
  31 #include &quot;oops/markWord.hpp&quot;
  32 #include &quot;oops/methodData.hpp&quot;
  33 #include &quot;oops/method.hpp&quot;

  34 #include &quot;prims/jvmtiExport.hpp&quot;
  35 #include &quot;prims/jvmtiThreadState.hpp&quot;
  36 #include &quot;runtime/basicLock.hpp&quot;
  37 #include &quot;runtime/biasedLocking.hpp&quot;
  38 #include &quot;runtime/frame.inline.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/thread.inline.hpp&quot;
  42 #include &quot;utilities/powerOfTwo.hpp&quot;
  43 
  44 // Implementation of InterpreterMacroAssembler
  45 
  46 void InterpreterMacroAssembler::jump_to_entry(address entry) {
  47   assert(entry, &quot;Entry must have been generated by now&quot;);
  48   jump(RuntimeAddress(entry));
  49 }
  50 
  51 void InterpreterMacroAssembler::profile_obj_type(Register obj, const Address&amp; mdo_addr) {
  52   Label update, next, none;
  53 
</pre>
<hr />
<pre>
 134         Address mdo_arg_addr(mdp, in_bytes(TypeEntriesAtCall::argument_type_offset(i))-off_to_args);
 135         profile_obj_type(tmp, mdo_arg_addr);
 136 
 137         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
 138         addptr(mdp, to_add);
 139         off_to_args += to_add;
 140       }
 141 
 142       if (MethodData::profile_return()) {
 143         movptr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())-off_to_args));
 144         subl(tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
 145       }
 146 
 147       bind(done);
 148 
 149       if (MethodData::profile_return()) {
 150         // We&#39;re right after the type profile for the last
 151         // argument. tmp is the number of cells left in the
 152         // CallTypeData/VirtualCallTypeData to reach its end. Non null
 153         // if there&#39;s a return to profile.
<span class="line-modified"> 154         assert(ReturnTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
 155         shll(tmp, exact_log2(DataLayout::cell_size));
 156         addptr(mdp, tmp);
 157       }
 158       movptr(Address(rbp, frame::interpreter_frame_mdp_offset * wordSize), mdp);
 159     } else {
 160       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
 161       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
 162     }
 163 
 164     // mdp points right after the end of the
 165     // CallTypeData/VirtualCallTypeData, right after the cells for the
 166     // return value type if there&#39;s one
 167 
 168     bind(profile_continue);
 169   }
 170 }
 171 
 172 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
 173   assert_different_registers(mdp, ret, tmp, _bcp_register);
 174   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
</pre>
<hr />
<pre>
 179     if (MethodData::profile_return_jsr292_only()) {
 180       assert(Method::intrinsic_id_size_in_bytes() == 2, &quot;assuming Method::_intrinsic_id is u2&quot;);
 181 
 182       // If we don&#39;t profile all invoke bytecodes we must make sure
 183       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
 184       // begining of the ProfileData we intend to update to check its
 185       // type because we&#39;re right after it and we don&#39;t known its
 186       // length
 187       Label do_profile;
 188       cmpb(Address(_bcp_register, 0), Bytecodes::_invokedynamic);
 189       jcc(Assembler::equal, do_profile);
 190       cmpb(Address(_bcp_register, 0), Bytecodes::_invokehandle);
 191       jcc(Assembler::equal, do_profile);
 192       get_method(tmp);
 193       cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), vmIntrinsics::_compiledLambdaForm);
 194       jcc(Assembler::notEqual, profile_continue);
 195 
 196       bind(do_profile);
 197     }
 198 
<span class="line-modified"> 199     Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));</span>
 200     mov(tmp, ret);
 201     profile_obj_type(tmp, mdo_ret_addr);
 202 
 203     bind(profile_continue);
 204   }
 205 }
 206 
 207 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
 208   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
 209     Label profile_continue;
 210 
 211     test_method_data_pointer(mdp, profile_continue);
 212 
 213     // Load the offset of the area within the MDO used for
 214     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
 215     movl(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
 216     testl(tmp1, tmp1);
 217     jcc(Assembler::negative, profile_continue);
 218 
 219     // Compute a pointer to the area for parameters from the offset
</pre>
<hr />
<pre>
 539 
 540   const int method_offset = in_bytes(
 541     ConstantPoolCache::base_offset() +
 542       ((byte_no == TemplateTable::f2_byte)
 543        ? ConstantPoolCacheEntry::f2_offset()
 544        : ConstantPoolCacheEntry::f1_offset()));
 545 
 546   movptr(method, Address(cache, index, Address::times_ptr, method_offset)); // get f1 Method*
 547 }
 548 
 549 // Generate a subtype check: branch to ok_is_subtype if sub_klass is a
 550 // subtype of super_klass.
 551 //
 552 // Args:
 553 //      rax: superklass
 554 //      Rsub_klass: subklass
 555 //
 556 // Kills:
 557 //      rcx, rdi
 558 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
<span class="line-modified"> 559                                                   Label&amp; ok_is_subtype) {</span>

 560   assert(Rsub_klass != rax, &quot;rax holds superklass&quot;);
 561   LP64_ONLY(assert(Rsub_klass != r14, &quot;r14 holds locals&quot;);)
 562   LP64_ONLY(assert(Rsub_klass != r13, &quot;r13 holds bcp&quot;);)
 563   assert(Rsub_klass != rcx, &quot;rcx holds 2ndary super array length&quot;);
 564   assert(Rsub_klass != rdi, &quot;rdi holds 2ndary super array scan ptr&quot;);
 565 
 566   // Profile the not-null value&#39;s klass.
<span class="line-modified"> 567   profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi</span>


 568 
 569   // Do the check.
 570   check_klass_subtype(Rsub_klass, rax, rcx, ok_is_subtype); // blows rcx
 571 
 572   // Profile the failure of the check.
<span class="line-modified"> 573   profile_typecheck_failed(rcx); // blows rcx</span>


 574 }
 575 
 576 
 577 #ifndef _LP64
 578 void InterpreterMacroAssembler::f2ieee() {
 579   if (IEEEPrecision) {
 580     fstp_s(Address(rsp, 0));
 581     fld_s(Address(rsp, 0));
 582   }
 583 }
 584 
 585 
 586 void InterpreterMacroAssembler::d2ieee() {
 587   if (IEEEPrecision) {
 588     fstp_d(Address(rsp, 0));
 589     fld_d(Address(rsp, 0));
 590   }
 591 }
 592 #endif // _LP64
 593 
</pre>
<hr />
<pre>
 978         bool throw_monitor_exception,
 979         bool install_monitor_exception,
 980         bool notify_jvmdi) {
 981   // Note: Registers rdx xmm0 may be in use for the
 982   // result check if synchronized method
 983   Label unlocked, unlock, no_unlock;
 984 
 985   const Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
 986   const Register robj    = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
 987   const Register rmon    = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
 988                               // monitor pointers need different register
 989                               // because rdx may have the result in it
 990   NOT_LP64(get_thread(rcx);)
 991 
 992   // get the value of _do_not_unlock_if_synchronized into rdx
 993   const Address do_not_unlock_if_synchronized(rthread,
 994     in_bytes(JavaThread::do_not_unlock_if_synchronized_offset()));
 995   movbool(rbx, do_not_unlock_if_synchronized);
 996   movbool(do_not_unlock_if_synchronized, false); // reset the flag
 997 
<span class="line-modified"> 998  // get method access flags</span>
 999   movptr(rcx, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
1000   movl(rcx, Address(rcx, Method::access_flags_offset()));
1001   testl(rcx, JVM_ACC_SYNCHRONIZED);
1002   jcc(Assembler::zero, unlocked);
1003 
1004   // Don&#39;t unlock anything if the _do_not_unlock_if_synchronized flag
1005   // is set.
1006   testbool(rbx);
1007   jcc(Assembler::notZero, no_unlock);
1008 
1009   // unlock monitor
1010   push(state); // save result
1011 
1012   // BasicObjectLock will be first in list, since this is a
1013   // synchronized method. However, need to check that the object has
1014   // not been unlocked by an explicit monitorexit bytecode.
1015   const Address monitor(rbp, frame::interpreter_frame_initial_sp_offset *
1016                         wordSize - (int) sizeof(BasicObjectLock));
1017   // We use c_rarg1/rdx so that if we go slow path it will be the correct
1018   // register for unlock_object to pass to VM directly
</pre>
<hr />
<pre>
1102     bind(loop);
1103     // check if current entry is used
1104     cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL);
1105     jcc(Assembler::notEqual, exception);
1106 
1107     addptr(rmon, entry_size); // otherwise advance to next entry
1108     bind(entry);
1109     cmpptr(rmon, rbx); // check if bottom reached
1110     jcc(Assembler::notEqual, loop); // if not at bottom then check this entry
1111   }
1112 
1113   bind(no_unlock);
1114 
1115   // jvmti support
1116   if (notify_jvmdi) {
1117     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
1118   } else {
1119     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
1120   }
1121 
<span class="line-modified">1122   // remove activation</span>
<span class="line-modified">1123   // get sender sp</span>
<span class="line-removed">1124   movptr(rbx,</span>
<span class="line-removed">1125          Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
1126   if (StackReservedPages &gt; 0) {
1127     // testing if reserved zone needs to be re-enabled
1128     Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
1129     Label no_reserved_zone_enabling;
1130 
1131     NOT_LP64(get_thread(rthread);)
1132 
1133     cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);
1134     jcc(Assembler::equal, no_reserved_zone_enabling);
1135 
1136     cmpptr(rbx, Address(rthread, JavaThread::reserved_stack_activation_offset()));
1137     jcc(Assembler::lessEqual, no_reserved_zone_enabling);
1138 
1139     call_VM_leaf(
1140       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
1141     call_VM(noreg, CAST_FROM_FN_PTR(address,
1142                    InterpreterRuntime::throw_delayed_StackOverflowError));
1143     should_not_reach_here();
1144 
1145     bind(no_reserved_zone_enabling);
1146   }


































1147   leave();                           // remove frame anchor
1148   pop(ret_addr);                     // get return address
1149   mov(rsp, rbx);                     // set sp to sender sp
1150 }
1151 
1152 void InterpreterMacroAssembler::get_method_counters(Register method,
1153                                                     Register mcs, Label&amp; skip) {
1154   Label has_counters;
1155   movptr(mcs, Address(method, Method::method_counters_offset()));
1156   testptr(mcs, mcs);
1157   jcc(Assembler::notZero, has_counters);
1158   call_VM(noreg, CAST_FROM_FN_PTR(address,
1159           InterpreterRuntime::build_method_counters), method);
1160   movptr(mcs, Address(method,Method::method_counters_offset()));
1161   testptr(mcs, mcs);
1162   jcc(Assembler::zero, skip); // No MethodCounters allocated, OutOfMemory
1163   bind(has_counters);
1164 }
1165 










































































































1166 
1167 // Lock object
1168 //
1169 // Args:
1170 //      rdx, c_rarg1: BasicObjectLock to be used for locking
1171 //
1172 // Kills:
1173 //      rax, rbx
1174 void InterpreterMacroAssembler::lock_object(Register lock_reg) {
1175   assert(lock_reg == LP64_ONLY(c_rarg1) NOT_LP64(rdx),
1176          &quot;The argument is only for looks. It must be c_rarg1&quot;);
1177 
1178   if (UseHeavyMonitors) {
1179     call_VM(noreg,
1180             CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1181             lock_reg);
1182   } else {
1183     Label done;
1184 
1185     const Register swap_reg = rax; // Must use rax for cmpxchg instruction
</pre>
<hr />
<pre>
1190     const int obj_offset = BasicObjectLock::obj_offset_in_bytes();
1191     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
1192     const int mark_offset = lock_offset +
1193                             BasicLock::displaced_header_offset_in_bytes();
1194 
1195     Label slow_case;
1196 
1197     // Load object pointer into obj_reg
1198     movptr(obj_reg, Address(lock_reg, obj_offset));
1199 
1200     if (UseBiasedLocking) {
1201       Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1202       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp_reg, rklass_decode_tmp, false, done, &amp;slow_case);
1203     }
1204 
1205     // Load immediate 1 into swap_reg %rax
1206     movl(swap_reg, (int32_t)1);
1207 
1208     // Load (object-&gt;mark() | 1) into swap_reg %rax
1209     orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));




1210 
1211     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
1212     movptr(Address(lock_reg, mark_offset), swap_reg);
1213 
1214     assert(lock_offset == 0,
1215            &quot;displaced header must be first word in BasicObjectLock&quot;);
1216 
1217     lock();
1218     cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
1219     if (PrintBiasedLockingStatistics) {
1220       cond_inc32(Assembler::zero,
1221                  ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));
1222     }
1223     jcc(Assembler::zero, done);
1224 
1225     const int zero_bits = LP64_ONLY(7) NOT_LP64(3);
1226 
1227     // Test if the oopMark is an obvious stack pointer, i.e.,
1228     //  1) (mark &amp; zero_bits) == 0, and
1229     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
</pre>
<hr />
<pre>
1914     // case_array_offset_in_bytes()
1915     movl(reg2, in_bytes(MultiBranchData::per_case_size()));
1916     imulptr(index, reg2); // XXX l ?
1917     addptr(index, in_bytes(MultiBranchData::case_array_offset())); // XXX l ?
1918 
1919     // Update the case count
1920     increment_mdp_data_at(mdp,
1921                           index,
1922                           in_bytes(MultiBranchData::relative_count_offset()));
1923 
1924     // The method data pointer needs to be updated.
1925     update_mdp_by_offset(mdp,
1926                          index,
1927                          in_bytes(MultiBranchData::
1928                                   relative_displacement_offset()));
1929 
1930     bind(profile_continue);
1931   }
1932 }
1933 






































1934 









1935 
1936 void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {
1937   if (state == atos) {
1938     MacroAssembler::_verify_oop(reg, &quot;broken oop&quot;, file, line);
1939   }
1940 }
1941 
1942 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
1943 #ifndef _LP64
1944   if ((state == ftos &amp;&amp; UseSSE &lt; 1) ||
1945       (state == dtos &amp;&amp; UseSSE &lt; 2)) {
1946     MacroAssembler::verify_FPU(stack_depth);
1947   }
1948 #endif
1949 }
1950 
1951 // Jump if ((*counter_addr += increment) &amp; mask) satisfies the condition.
1952 void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,
1953                                                         int increment, Address mask,
1954                                                         Register scratch, bool preloaded,
</pre>
</td>
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;interp_masm_x86.hpp&quot;
  27 #include &quot;interpreter/interpreter.hpp&quot;
  28 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  29 #include &quot;logging/log.hpp&quot;
  30 #include &quot;oops/arrayOop.hpp&quot;
  31 #include &quot;oops/markWord.hpp&quot;
  32 #include &quot;oops/methodData.hpp&quot;
  33 #include &quot;oops/method.hpp&quot;
<span class="line-added">  34 #include &quot;oops/valueKlass.hpp&quot;</span>
  35 #include &quot;prims/jvmtiExport.hpp&quot;
  36 #include &quot;prims/jvmtiThreadState.hpp&quot;
  37 #include &quot;runtime/basicLock.hpp&quot;
  38 #include &quot;runtime/biasedLocking.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/safepointMechanism.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/thread.inline.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 
  45 // Implementation of InterpreterMacroAssembler
  46 
  47 void InterpreterMacroAssembler::jump_to_entry(address entry) {
  48   assert(entry, &quot;Entry must have been generated by now&quot;);
  49   jump(RuntimeAddress(entry));
  50 }
  51 
  52 void InterpreterMacroAssembler::profile_obj_type(Register obj, const Address&amp; mdo_addr) {
  53   Label update, next, none;
  54 
</pre>
<hr />
<pre>
 135         Address mdo_arg_addr(mdp, in_bytes(TypeEntriesAtCall::argument_type_offset(i))-off_to_args);
 136         profile_obj_type(tmp, mdo_arg_addr);
 137 
 138         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
 139         addptr(mdp, to_add);
 140         off_to_args += to_add;
 141       }
 142 
 143       if (MethodData::profile_return()) {
 144         movptr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())-off_to_args));
 145         subl(tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
 146       }
 147 
 148       bind(done);
 149 
 150       if (MethodData::profile_return()) {
 151         // We&#39;re right after the type profile for the last
 152         // argument. tmp is the number of cells left in the
 153         // CallTypeData/VirtualCallTypeData to reach its end. Non null
 154         // if there&#39;s a return to profile.
<span class="line-modified"> 155         assert(SingleTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
 156         shll(tmp, exact_log2(DataLayout::cell_size));
 157         addptr(mdp, tmp);
 158       }
 159       movptr(Address(rbp, frame::interpreter_frame_mdp_offset * wordSize), mdp);
 160     } else {
 161       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
 162       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
 163     }
 164 
 165     // mdp points right after the end of the
 166     // CallTypeData/VirtualCallTypeData, right after the cells for the
 167     // return value type if there&#39;s one
 168 
 169     bind(profile_continue);
 170   }
 171 }
 172 
 173 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
 174   assert_different_registers(mdp, ret, tmp, _bcp_register);
 175   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
</pre>
<hr />
<pre>
 180     if (MethodData::profile_return_jsr292_only()) {
 181       assert(Method::intrinsic_id_size_in_bytes() == 2, &quot;assuming Method::_intrinsic_id is u2&quot;);
 182 
 183       // If we don&#39;t profile all invoke bytecodes we must make sure
 184       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
 185       // begining of the ProfileData we intend to update to check its
 186       // type because we&#39;re right after it and we don&#39;t known its
 187       // length
 188       Label do_profile;
 189       cmpb(Address(_bcp_register, 0), Bytecodes::_invokedynamic);
 190       jcc(Assembler::equal, do_profile);
 191       cmpb(Address(_bcp_register, 0), Bytecodes::_invokehandle);
 192       jcc(Assembler::equal, do_profile);
 193       get_method(tmp);
 194       cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), vmIntrinsics::_compiledLambdaForm);
 195       jcc(Assembler::notEqual, profile_continue);
 196 
 197       bind(do_profile);
 198     }
 199 
<span class="line-modified"> 200     Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));</span>
 201     mov(tmp, ret);
 202     profile_obj_type(tmp, mdo_ret_addr);
 203 
 204     bind(profile_continue);
 205   }
 206 }
 207 
 208 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
 209   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
 210     Label profile_continue;
 211 
 212     test_method_data_pointer(mdp, profile_continue);
 213 
 214     // Load the offset of the area within the MDO used for
 215     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
 216     movl(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
 217     testl(tmp1, tmp1);
 218     jcc(Assembler::negative, profile_continue);
 219 
 220     // Compute a pointer to the area for parameters from the offset
</pre>
<hr />
<pre>
 540 
 541   const int method_offset = in_bytes(
 542     ConstantPoolCache::base_offset() +
 543       ((byte_no == TemplateTable::f2_byte)
 544        ? ConstantPoolCacheEntry::f2_offset()
 545        : ConstantPoolCacheEntry::f1_offset()));
 546 
 547   movptr(method, Address(cache, index, Address::times_ptr, method_offset)); // get f1 Method*
 548 }
 549 
 550 // Generate a subtype check: branch to ok_is_subtype if sub_klass is a
 551 // subtype of super_klass.
 552 //
 553 // Args:
 554 //      rax: superklass
 555 //      Rsub_klass: subklass
 556 //
 557 // Kills:
 558 //      rcx, rdi
 559 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
<span class="line-modified"> 560                                                   Label&amp; ok_is_subtype,</span>
<span class="line-added"> 561                                                   bool profile) {</span>
 562   assert(Rsub_klass != rax, &quot;rax holds superklass&quot;);
 563   LP64_ONLY(assert(Rsub_klass != r14, &quot;r14 holds locals&quot;);)
 564   LP64_ONLY(assert(Rsub_klass != r13, &quot;r13 holds bcp&quot;);)
 565   assert(Rsub_klass != rcx, &quot;rcx holds 2ndary super array length&quot;);
 566   assert(Rsub_klass != rdi, &quot;rdi holds 2ndary super array scan ptr&quot;);
 567 
 568   // Profile the not-null value&#39;s klass.
<span class="line-modified"> 569   if (profile) {</span>
<span class="line-added"> 570     profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi</span>
<span class="line-added"> 571   }</span>
 572 
 573   // Do the check.
 574   check_klass_subtype(Rsub_klass, rax, rcx, ok_is_subtype); // blows rcx
 575 
 576   // Profile the failure of the check.
<span class="line-modified"> 577   if (profile) {</span>
<span class="line-added"> 578     profile_typecheck_failed(rcx); // blows rcx</span>
<span class="line-added"> 579   }</span>
 580 }
 581 
 582 
 583 #ifndef _LP64
 584 void InterpreterMacroAssembler::f2ieee() {
 585   if (IEEEPrecision) {
 586     fstp_s(Address(rsp, 0));
 587     fld_s(Address(rsp, 0));
 588   }
 589 }
 590 
 591 
 592 void InterpreterMacroAssembler::d2ieee() {
 593   if (IEEEPrecision) {
 594     fstp_d(Address(rsp, 0));
 595     fld_d(Address(rsp, 0));
 596   }
 597 }
 598 #endif // _LP64
 599 
</pre>
<hr />
<pre>
 984         bool throw_monitor_exception,
 985         bool install_monitor_exception,
 986         bool notify_jvmdi) {
 987   // Note: Registers rdx xmm0 may be in use for the
 988   // result check if synchronized method
 989   Label unlocked, unlock, no_unlock;
 990 
 991   const Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
 992   const Register robj    = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
 993   const Register rmon    = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
 994                               // monitor pointers need different register
 995                               // because rdx may have the result in it
 996   NOT_LP64(get_thread(rcx);)
 997 
 998   // get the value of _do_not_unlock_if_synchronized into rdx
 999   const Address do_not_unlock_if_synchronized(rthread,
1000     in_bytes(JavaThread::do_not_unlock_if_synchronized_offset()));
1001   movbool(rbx, do_not_unlock_if_synchronized);
1002   movbool(do_not_unlock_if_synchronized, false); // reset the flag
1003 
<span class="line-modified">1004   // get method access flags</span>
1005   movptr(rcx, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
1006   movl(rcx, Address(rcx, Method::access_flags_offset()));
1007   testl(rcx, JVM_ACC_SYNCHRONIZED);
1008   jcc(Assembler::zero, unlocked);
1009 
1010   // Don&#39;t unlock anything if the _do_not_unlock_if_synchronized flag
1011   // is set.
1012   testbool(rbx);
1013   jcc(Assembler::notZero, no_unlock);
1014 
1015   // unlock monitor
1016   push(state); // save result
1017 
1018   // BasicObjectLock will be first in list, since this is a
1019   // synchronized method. However, need to check that the object has
1020   // not been unlocked by an explicit monitorexit bytecode.
1021   const Address monitor(rbp, frame::interpreter_frame_initial_sp_offset *
1022                         wordSize - (int) sizeof(BasicObjectLock));
1023   // We use c_rarg1/rdx so that if we go slow path it will be the correct
1024   // register for unlock_object to pass to VM directly
</pre>
<hr />
<pre>
1108     bind(loop);
1109     // check if current entry is used
1110     cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL);
1111     jcc(Assembler::notEqual, exception);
1112 
1113     addptr(rmon, entry_size); // otherwise advance to next entry
1114     bind(entry);
1115     cmpptr(rmon, rbx); // check if bottom reached
1116     jcc(Assembler::notEqual, loop); // if not at bottom then check this entry
1117   }
1118 
1119   bind(no_unlock);
1120 
1121   // jvmti support
1122   if (notify_jvmdi) {
1123     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
1124   } else {
1125     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
1126   }
1127 
<span class="line-modified">1128   if (StackReservedPages &gt; 0) {</span>
<span class="line-modified">1129     movptr(rbx,</span>


1130                Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));
1131     // testing if reserved zone needs to be re-enabled
1132     Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
1133     Label no_reserved_zone_enabling;
1134 
1135     NOT_LP64(get_thread(rthread);)
1136 
1137     cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);
1138     jcc(Assembler::equal, no_reserved_zone_enabling);
1139 
1140     cmpptr(rbx, Address(rthread, JavaThread::reserved_stack_activation_offset()));
1141     jcc(Assembler::lessEqual, no_reserved_zone_enabling);
1142 
1143     call_VM_leaf(
1144       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
1145     call_VM(noreg, CAST_FROM_FN_PTR(address,
1146                    InterpreterRuntime::throw_delayed_StackOverflowError));
1147     should_not_reach_here();
1148 
1149     bind(no_reserved_zone_enabling);
1150   }
<span class="line-added">1151 </span>
<span class="line-added">1152   // remove activation</span>
<span class="line-added">1153   // get sender sp</span>
<span class="line-added">1154   movptr(rbx,</span>
<span class="line-added">1155          Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
<span class="line-added">1156 </span>
<span class="line-added">1157   if (state == atos &amp;&amp; InlineTypeReturnedAsFields) {</span>
<span class="line-added">1158     Label skip;</span>
<span class="line-added">1159     // Test if the return type is an inline type</span>
<span class="line-added">1160     movptr(rdi, Address(rbp, frame::interpreter_frame_method_offset * wordSize));</span>
<span class="line-added">1161     movptr(rdi, Address(rdi, Method::const_offset()));</span>
<span class="line-added">1162     load_unsigned_byte(rdi, Address(rdi, ConstMethod::result_type_offset()));</span>
<span class="line-added">1163     cmpl(rdi, T_VALUETYPE);</span>
<span class="line-added">1164     jcc(Assembler::notEqual, skip);</span>
<span class="line-added">1165 </span>
<span class="line-added">1166     // We are returning a value type, load its fields into registers</span>
<span class="line-added">1167 #ifndef _LP64</span>
<span class="line-added">1168     super_call_VM_leaf(StubRoutines::load_value_type_fields_in_regs());</span>
<span class="line-added">1169 #else</span>
<span class="line-added">1170     // Load fields from a buffered value with a value class specific handler</span>
<span class="line-added">1171     Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">1172     load_klass(rdi, rax, tmp_load_klass);</span>
<span class="line-added">1173     movptr(rdi, Address(rdi, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">1174     movptr(rdi, Address(rdi, ValueKlass::unpack_handler_offset()));</span>
<span class="line-added">1175 </span>
<span class="line-added">1176     testptr(rdi, rdi);</span>
<span class="line-added">1177     jcc(Assembler::equal, skip);</span>
<span class="line-added">1178 </span>
<span class="line-added">1179     call(rdi);</span>
<span class="line-added">1180 #endif</span>
<span class="line-added">1181     // call above kills the value in rbx. Reload it.</span>
<span class="line-added">1182     movptr(rbx, Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
<span class="line-added">1183     bind(skip);</span>
<span class="line-added">1184   }</span>
1185   leave();                           // remove frame anchor
1186   pop(ret_addr);                     // get return address
1187   mov(rsp, rbx);                     // set sp to sender sp
1188 }
1189 
1190 void InterpreterMacroAssembler::get_method_counters(Register method,
1191                                                     Register mcs, Label&amp; skip) {
1192   Label has_counters;
1193   movptr(mcs, Address(method, Method::method_counters_offset()));
1194   testptr(mcs, mcs);
1195   jcc(Assembler::notZero, has_counters);
1196   call_VM(noreg, CAST_FROM_FN_PTR(address,
1197           InterpreterRuntime::build_method_counters), method);
1198   movptr(mcs, Address(method,Method::method_counters_offset()));
1199   testptr(mcs, mcs);
1200   jcc(Assembler::zero, skip); // No MethodCounters allocated, OutOfMemory
1201   bind(has_counters);
1202 }
1203 
<span class="line-added">1204 void InterpreterMacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="line-added">1205                                                   Register t1, Register t2,</span>
<span class="line-added">1206                                                   bool clear_fields, Label&amp; alloc_failed) {</span>
<span class="line-added">1207   MacroAssembler::allocate_instance(klass, new_obj, t1, t2, clear_fields, alloc_failed);</span>
<span class="line-added">1208   {</span>
<span class="line-added">1209     SkipIfEqual skip_if(this, &amp;DTraceAllocProbes, 0);</span>
<span class="line-added">1210     // Trigger dtrace event for fastpath</span>
<span class="line-added">1211     push(atos);</span>
<span class="line-added">1212     call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), new_obj);</span>
<span class="line-added">1213     pop(atos);</span>
<span class="line-added">1214   }</span>
<span class="line-added">1215 }</span>
<span class="line-added">1216 </span>
<span class="line-added">1217 </span>
<span class="line-added">1218 void InterpreterMacroAssembler::read_flattened_field(Register holder_klass,</span>
<span class="line-added">1219                                                      Register field_index, Register field_offset,</span>
<span class="line-added">1220                                                      Register obj) {</span>
<span class="line-added">1221   Label alloc_failed, empty_value, done;</span>
<span class="line-added">1222   const Register src = field_offset;</span>
<span class="line-added">1223   const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);</span>
<span class="line-added">1224   const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);</span>
<span class="line-added">1225   assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);</span>
<span class="line-added">1226 </span>
<span class="line-added">1227   // Grap the inline field klass</span>
<span class="line-added">1228   push(holder_klass);</span>
<span class="line-added">1229   const Register field_klass = holder_klass;</span>
<span class="line-added">1230   get_value_field_klass(holder_klass, field_index, field_klass);</span>
<span class="line-added">1231 </span>
<span class="line-added">1232   //check for empty value klass</span>
<span class="line-added">1233   test_klass_is_empty_value(field_klass, dst_temp, empty_value);</span>
<span class="line-added">1234 </span>
<span class="line-added">1235   // allocate buffer</span>
<span class="line-added">1236   push(obj); // save holder</span>
<span class="line-added">1237   allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);</span>
<span class="line-added">1238 </span>
<span class="line-added">1239   // Have an oop instance buffer, copy into it</span>
<span class="line-added">1240   data_for_oop(obj, dst_temp, field_klass);</span>
<span class="line-added">1241   pop(alloc_temp);             // restore holder</span>
<span class="line-added">1242   lea(src, Address(alloc_temp, field_offset));</span>
<span class="line-added">1243   // call_VM_leaf, clobbers a few regs, save restore new obj</span>
<span class="line-added">1244   push(obj);</span>
<span class="line-added">1245   access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);</span>
<span class="line-added">1246   pop(obj);</span>
<span class="line-added">1247   pop(holder_klass);</span>
<span class="line-added">1248   jmp(done);</span>
<span class="line-added">1249 </span>
<span class="line-added">1250   bind(empty_value);</span>
<span class="line-added">1251   get_empty_value_oop(field_klass, dst_temp, obj);</span>
<span class="line-added">1252   pop(holder_klass);</span>
<span class="line-added">1253   jmp(done);</span>
<span class="line-added">1254 </span>
<span class="line-added">1255   bind(alloc_failed);</span>
<span class="line-added">1256   pop(obj);</span>
<span class="line-added">1257   pop(holder_klass);</span>
<span class="line-added">1258   call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field),</span>
<span class="line-added">1259           obj, field_index, holder_klass);</span>
<span class="line-added">1260 </span>
<span class="line-added">1261   bind(done);</span>
<span class="line-added">1262 }</span>
<span class="line-added">1263 </span>
<span class="line-added">1264 void InterpreterMacroAssembler::read_flattened_element(Register array, Register index,</span>
<span class="line-added">1265                                                        Register t1, Register t2,</span>
<span class="line-added">1266                                                        Register obj) {</span>
<span class="line-added">1267   assert_different_registers(array, index, t1, t2);</span>
<span class="line-added">1268   Label alloc_failed, empty_value, done;</span>
<span class="line-added">1269   const Register array_klass = t2;</span>
<span class="line-added">1270   const Register elem_klass = t1;</span>
<span class="line-added">1271   const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);</span>
<span class="line-added">1272   const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);</span>
<span class="line-added">1273 </span>
<span class="line-added">1274   // load in array-&gt;klass()-&gt;element_klass()</span>
<span class="line-added">1275   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added">1276   load_klass(array_klass, array, tmp_load_klass);</span>
<span class="line-added">1277   movptr(elem_klass, Address(array_klass, ArrayKlass::element_klass_offset()));</span>
<span class="line-added">1278 </span>
<span class="line-added">1279   //check for empty value klass</span>
<span class="line-added">1280   test_klass_is_empty_value(elem_klass, dst_temp, empty_value);</span>
<span class="line-added">1281 </span>
<span class="line-added">1282   // calc source into &quot;array_klass&quot; and free up some regs</span>
<span class="line-added">1283   const Register src = array_klass;</span>
<span class="line-added">1284   push(index); // preserve index reg in case alloc_failed</span>
<span class="line-added">1285   data_for_value_array_index(array, array_klass, index, src);</span>
<span class="line-added">1286 </span>
<span class="line-added">1287   allocate_instance(elem_klass, obj, alloc_temp, dst_temp, false, alloc_failed);</span>
<span class="line-added">1288   // Have an oop instance buffer, copy into it</span>
<span class="line-added">1289   store_ptr(0, obj); // preserve obj (overwrite index, no longer needed)</span>
<span class="line-added">1290   data_for_oop(obj, dst_temp, elem_klass);</span>
<span class="line-added">1291   access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, elem_klass);</span>
<span class="line-added">1292   pop(obj);</span>
<span class="line-added">1293   jmp(done);</span>
<span class="line-added">1294 </span>
<span class="line-added">1295   bind(empty_value);</span>
<span class="line-added">1296   get_empty_value_oop(elem_klass, dst_temp, obj);</span>
<span class="line-added">1297   jmp(done);</span>
<span class="line-added">1298 </span>
<span class="line-added">1299   bind(alloc_failed);</span>
<span class="line-added">1300   pop(index);</span>
<span class="line-added">1301   if (array == c_rarg2) {</span>
<span class="line-added">1302     mov(elem_klass, array);</span>
<span class="line-added">1303     array = elem_klass;</span>
<span class="line-added">1304   }</span>
<span class="line-added">1305   call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), array, index);</span>
<span class="line-added">1306 </span>
<span class="line-added">1307   bind(done);</span>
<span class="line-added">1308 }</span>
<span class="line-added">1309 </span>
1310 
1311 // Lock object
1312 //
1313 // Args:
1314 //      rdx, c_rarg1: BasicObjectLock to be used for locking
1315 //
1316 // Kills:
1317 //      rax, rbx
1318 void InterpreterMacroAssembler::lock_object(Register lock_reg) {
1319   assert(lock_reg == LP64_ONLY(c_rarg1) NOT_LP64(rdx),
1320          &quot;The argument is only for looks. It must be c_rarg1&quot;);
1321 
1322   if (UseHeavyMonitors) {
1323     call_VM(noreg,
1324             CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1325             lock_reg);
1326   } else {
1327     Label done;
1328 
1329     const Register swap_reg = rax; // Must use rax for cmpxchg instruction
</pre>
<hr />
<pre>
1334     const int obj_offset = BasicObjectLock::obj_offset_in_bytes();
1335     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
1336     const int mark_offset = lock_offset +
1337                             BasicLock::displaced_header_offset_in_bytes();
1338 
1339     Label slow_case;
1340 
1341     // Load object pointer into obj_reg
1342     movptr(obj_reg, Address(lock_reg, obj_offset));
1343 
1344     if (UseBiasedLocking) {
1345       Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1346       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp_reg, rklass_decode_tmp, false, done, &amp;slow_case);
1347     }
1348 
1349     // Load immediate 1 into swap_reg %rax
1350     movl(swap_reg, (int32_t)1);
1351 
1352     // Load (object-&gt;mark() | 1) into swap_reg %rax
1353     orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
<span class="line-added">1354     if (EnableValhalla &amp;&amp; !UseBiasedLocking) {</span>
<span class="line-added">1355       // For slow path is_always_locked, using biased, which is never natural for !UseBiasLocking</span>
<span class="line-added">1356       andptr(swap_reg, ~((int) markWord::biased_lock_bit_in_place));</span>
<span class="line-added">1357     }</span>
1358 
1359     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
1360     movptr(Address(lock_reg, mark_offset), swap_reg);
1361 
1362     assert(lock_offset == 0,
1363            &quot;displaced header must be first word in BasicObjectLock&quot;);
1364 
1365     lock();
1366     cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
1367     if (PrintBiasedLockingStatistics) {
1368       cond_inc32(Assembler::zero,
1369                  ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));
1370     }
1371     jcc(Assembler::zero, done);
1372 
1373     const int zero_bits = LP64_ONLY(7) NOT_LP64(3);
1374 
1375     // Test if the oopMark is an obvious stack pointer, i.e.,
1376     //  1) (mark &amp; zero_bits) == 0, and
1377     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
</pre>
<hr />
<pre>
2062     // case_array_offset_in_bytes()
2063     movl(reg2, in_bytes(MultiBranchData::per_case_size()));
2064     imulptr(index, reg2); // XXX l ?
2065     addptr(index, in_bytes(MultiBranchData::case_array_offset())); // XXX l ?
2066 
2067     // Update the case count
2068     increment_mdp_data_at(mdp,
2069                           index,
2070                           in_bytes(MultiBranchData::relative_count_offset()));
2071 
2072     // The method data pointer needs to be updated.
2073     update_mdp_by_offset(mdp,
2074                          index,
2075                          in_bytes(MultiBranchData::
2076                                   relative_displacement_offset()));
2077 
2078     bind(profile_continue);
2079   }
2080 }
2081 
<span class="line-added">2082 void InterpreterMacroAssembler::profile_array(Register mdp,</span>
<span class="line-added">2083                                               Register array,</span>
<span class="line-added">2084                                               Register tmp) {</span>
<span class="line-added">2085   if (ProfileInterpreter) {</span>
<span class="line-added">2086     Label profile_continue;</span>
<span class="line-added">2087 </span>
<span class="line-added">2088     // If no method data exists, go to profile_continue.</span>
<span class="line-added">2089     test_method_data_pointer(mdp, profile_continue);</span>
<span class="line-added">2090 </span>
<span class="line-added">2091     mov(tmp, array);</span>
<span class="line-added">2092     profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::array_offset())));</span>
<span class="line-added">2093 </span>
<span class="line-added">2094     Label not_flat;</span>
<span class="line-added">2095     test_non_flattened_array_oop(array, tmp, not_flat);</span>
<span class="line-added">2096 </span>
<span class="line-added">2097     set_mdp_flag_at(mdp, ArrayLoadStoreData::flat_array_byte_constant());</span>
<span class="line-added">2098 </span>
<span class="line-added">2099     bind(not_flat);</span>
<span class="line-added">2100 </span>
<span class="line-added">2101     Label not_null_free;</span>
<span class="line-added">2102     test_non_null_free_array_oop(array, tmp, not_null_free);</span>
<span class="line-added">2103 </span>
<span class="line-added">2104     set_mdp_flag_at(mdp, ArrayLoadStoreData::null_free_array_byte_constant());</span>
<span class="line-added">2105 </span>
<span class="line-added">2106     bind(not_null_free);</span>
<span class="line-added">2107 </span>
<span class="line-added">2108     bind(profile_continue);</span>
<span class="line-added">2109   }</span>
<span class="line-added">2110 }</span>
<span class="line-added">2111 </span>
<span class="line-added">2112 void InterpreterMacroAssembler::profile_element(Register mdp,</span>
<span class="line-added">2113                                                 Register element,</span>
<span class="line-added">2114                                                 Register tmp) {</span>
<span class="line-added">2115   if (ProfileInterpreter) {</span>
<span class="line-added">2116     Label profile_continue;</span>
<span class="line-added">2117 </span>
<span class="line-added">2118     // If no method data exists, go to profile_continue.</span>
<span class="line-added">2119     test_method_data_pointer(mdp, profile_continue);</span>
2120 
<span class="line-added">2121     mov(tmp, element);</span>
<span class="line-added">2122     profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::element_offset())));</span>
<span class="line-added">2123 </span>
<span class="line-added">2124     // The method data pointer needs to be updated.</span>
<span class="line-added">2125     update_mdp_by_constant(mdp, in_bytes(ArrayLoadStoreData::array_load_store_data_size()));</span>
<span class="line-added">2126 </span>
<span class="line-added">2127     bind(profile_continue);</span>
<span class="line-added">2128   }</span>
<span class="line-added">2129 }</span>
2130 
2131 void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {
2132   if (state == atos) {
2133     MacroAssembler::_verify_oop(reg, &quot;broken oop&quot;, file, line);
2134   }
2135 }
2136 
2137 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2138 #ifndef _LP64
2139   if ((state == ftos &amp;&amp; UseSSE &lt; 1) ||
2140       (state == dtos &amp;&amp; UseSSE &lt; 2)) {
2141     MacroAssembler::verify_FPU(stack_depth);
2142   }
2143 #endif
2144 }
2145 
2146 // Jump if ((*counter_addr += increment) &amp; mask) satisfies the condition.
2147 void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,
2148                                                         int increment, Address mask,
2149                                                         Register scratch, bool preloaded,
</pre>
</td>
</tr>
</table>
<center><a href="gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>