<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_x86.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,7 +1,7 @@</span>
  /*
<span class="udiff-line-modified-removed">-  * Copyright (c) 1999, 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="udiff-line-modified-added">+  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -32,10 +32,11 @@</span>
  #include &quot;interpreter/interpreter.hpp&quot;
  #include &quot;oops/arrayOop.hpp&quot;
  #include &quot;oops/markWord.hpp&quot;
  #include &quot;runtime/basicLock.hpp&quot;
  #include &quot;runtime/biasedLocking.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/frame.inline.hpp&quot;</span>
  #include &quot;runtime/os.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
  #include &quot;runtime/stubRoutines.hpp&quot;
  
  int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register scratch, Label&amp; slow_case) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -61,10 +62,14 @@</span>
  
    // Load object header
    movptr(hdr, Address(obj, hdr_offset));
    // and mark it as unlocked
    orptr(hdr, markWord::unlocked_value);
<span class="udiff-line-added">+   if (EnableValhalla &amp;&amp; !UseBiasedLocking) {</span>
<span class="udiff-line-added">+     // Mask always_locked bit such that we go to the slow path if object is a value type</span>
<span class="udiff-line-added">+     andptr(hdr, ~((int) markWord::biased_lock_bit_in_place));</span>
<span class="udiff-line-added">+   }</span>
    // save unlocked object header into the displaced header location on the stack
    movptr(Address(disp_hdr, 0), hdr);
    // test if object header is still the same (i.e. unlocked), and if so, store the
    // displaced header address in the object header - if it is not the same, get the
    // object header instead
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -150,11 +155,12 @@</span>
  
  
  void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register t1, Register t2) {
    assert_different_registers(obj, klass, len);
    Register tmp_encode_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
<span class="udiff-line-modified-removed">-   if (UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {</span>
<span class="udiff-line-modified-added">+   if ((UseBiasedLocking || EnableValhalla) &amp;&amp; !len-&gt;is_valid()) {</span>
<span class="udiff-line-added">+     // Need to copy markWord::always_locked_pattern for values.</span>
      assert_different_registers(obj, klass, len, t1, t2);
      movptr(t1, Address(klass, Klass::prototype_header_offset()));
      movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);
    } else {
      // This assumes that all prototype bits fit in an int32_t
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -312,43 +318,58 @@</span>
            RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
    const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
    assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
  }
  
<span class="udiff-line-added">+ void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {</span>
<span class="udiff-line-added">+   push(rbp);</span>
<span class="udiff-line-added">+   if (PreserveFramePointer) {</span>
<span class="udiff-line-added">+     mov(rbp, rsp);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>
<span class="udiff-line-added">+     if (UseSSE &lt; 2 ) {</span>
<span class="udiff-line-added">+       // c2 leaves fpu stack dirty. Clean it on entry</span>
<span class="udiff-line-added">+       empty_FPU_stack();</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   #endif // !_LP64 &amp;&amp; TIERED</span>
<span class="udiff-line-added">+   decrement(rsp, frame_size_in_bytes);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (needs_stack_repair) {</span>
<span class="udiff-line-added">+     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="udiff-line-added">+     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="udiff-line-added">+     int real_frame_size = sp_inc + frame_size_in_bytes + wordSize;</span>
<span class="udiff-line-added">+     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
  
<span class="udiff-line-modified-removed">- void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {</span>
<span class="udiff-line-modified-removed">-   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>
<span class="udiff-line-modified-added">+ void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_value_entry_label) {</span>
<span class="udiff-line-modified-added">+   if (has_scalarized_args) {</span>
<span class="udiff-line-added">+     // Initialize orig_pc to detect deoptimization during buffering in the entry points</span>
<span class="udiff-line-added">+     movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (!needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {</span>
<span class="udiff-line-added">+     bind(*verified_value_entry_label);</span>
<span class="udiff-line-added">+   }</span>
    // Make sure there is enough stack space for this method&#39;s activation.
    // Note that we do this before doing an enter(). This matches the
    // ordering of C2&#39;s stack overflow check / rsp decrement and allows
    // the SharedRuntime stack overflow handling to be consistent
    // between the two compilers.
<span class="udiff-line-added">+   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>
    generate_stack_overflow_check(bang_size_in_bytes);
  
<span class="udiff-line-modified-removed">-   push(rbp);</span>
<span class="udiff-line-removed">-   if (PreserveFramePointer) {</span>
<span class="udiff-line-removed">-     mov(rbp, rsp);</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>
<span class="udiff-line-removed">-   if (UseSSE &lt; 2 ) {</span>
<span class="udiff-line-removed">-     // c2 leaves fpu stack dirty. Clean it on entry</span>
<span class="udiff-line-removed">-     empty_FPU_stack();</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- #endif // !_LP64 &amp;&amp; TIERED</span>
<span class="udiff-line-removed">-   decrement(rsp, frame_size_in_bytes); // does not emit code for frame_size == 0</span>
<span class="udiff-line-modified-added">+   build_frame_helper(frame_size_in_bytes, 0, needs_stack_repair);</span>
  
<span class="udiff-line-added">+   if (needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {</span>
<span class="udiff-line-added">+     // Jump here from the scalarized entry points that require additional stack space</span>
<span class="udiff-line-added">+     // for packing scalarized arguments and therefore already created the frame.</span>
<span class="udiff-line-added">+     bind(*verified_value_entry_label);</span>
<span class="udiff-line-added">+   }</span>
    BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
    bs-&gt;nmethod_entry_barrier(this);
  }
  
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">- void C1_MacroAssembler::remove_frame(int frame_size_in_bytes) {</span>
<span class="udiff-line-removed">-   increment(rsp, frame_size_in_bytes);  // Does not emit code for frame_size == 0</span>
<span class="udiff-line-removed">-   pop(rbp);</span>
<span class="udiff-line-removed">- }</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">- </span>
  void C1_MacroAssembler::verified_entry() {
    if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
      // Verified Entry first instruction should be 5 bytes long for correct
      // patching by patch_verified_entry().
      //
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -361,10 +382,73 @@</span>
    if (C1Breakpoint)int3();
    // build frame
    IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )
  }
  
<span class="udiff-line-added">+ int C1_MacroAssembler::scalarized_entry(const CompiledEntrySignature *ces, int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, Label&amp; verified_value_entry_label, bool is_value_ro_entry) {</span>
<span class="udiff-line-added">+   assert(InlineTypePassFieldsAsArgs, &quot;sanity&quot;);</span>
<span class="udiff-line-added">+   // Make sure there is enough stack space for this method&#39;s activation.</span>
<span class="udiff-line-added">+   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>
<span class="udiff-line-added">+   generate_stack_overflow_check(bang_size_in_bytes);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   GrowableArray&lt;SigEntry&gt;* sig    = &amp;ces-&gt;sig();</span>
<span class="udiff-line-added">+   GrowableArray&lt;SigEntry&gt;* sig_cc = is_value_ro_entry ? &amp;ces-&gt;sig_cc_ro() : &amp;ces-&gt;sig_cc();</span>
<span class="udiff-line-added">+   VMRegPair* regs      = ces-&gt;regs();</span>
<span class="udiff-line-added">+   VMRegPair* regs_cc   = is_value_ro_entry ? ces-&gt;regs_cc_ro() : ces-&gt;regs_cc();</span>
<span class="udiff-line-added">+   int args_on_stack    = ces-&gt;args_on_stack();</span>
<span class="udiff-line-added">+   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);</span>
<span class="udiff-line-added">+   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());</span>
<span class="udiff-line-added">+   int args_passed = sig-&gt;length();</span>
<span class="udiff-line-added">+   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);</span>
<span class="udiff-line-added">+   int extra_stack_offset = wordSize; // tos is return address.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Check if we need to extend the stack for packing</span>
<span class="udiff-line-added">+   int sp_inc = 0;</span>
<span class="udiff-line-added">+   if (args_on_stack &gt; args_on_stack_cc) {</span>
<span class="udiff-line-added">+     // Two additional slots to account for return address</span>
<span class="udiff-line-added">+     sp_inc = (args_on_stack + 2) * VMRegImpl::stack_slot_size;</span>
<span class="udiff-line-added">+     sp_inc = align_up(sp_inc, StackAlignmentInBytes);</span>
<span class="udiff-line-added">+     pop(r13); // Copy return address</span>
<span class="udiff-line-added">+     subptr(rsp, sp_inc);</span>
<span class="udiff-line-added">+     push(r13);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Create a temp frame so we can call into the runtime. It must be properly set up to accommodate GC.</span>
<span class="udiff-line-added">+   build_frame_helper(frame_size_in_bytes, sp_inc, ces-&gt;c1_needs_stack_repair());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Initialize orig_pc to detect deoptimization during buffering in below runtime call</span>
<span class="udiff-line-added">+   movptr(Address(rsp, sp_offset_for_orig_pc), 0);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.</span>
<span class="udiff-line-added">+   movptr(rbx, (intptr_t)(ces-&gt;method()));</span>
<span class="udiff-line-added">+   if (is_value_ro_entry) {</span>
<span class="udiff-line-added">+     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   int rt_call_offset = offset();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Remove the temp frame</span>
<span class="udiff-line-added">+   addptr(rsp, frame_size_in_bytes);</span>
<span class="udiff-line-added">+   pop(rbp);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,</span>
<span class="udiff-line-added">+                      args_passed_cc, args_on_stack_cc, regs_cc, // from</span>
<span class="udiff-line-added">+                      args_passed, args_on_stack, regs, sp_inc); // to</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (ces-&gt;c1_needs_stack_repair()) {</span>
<span class="udiff-line-added">+     // Create the real frame. Below jump will then skip over the stack banging and frame</span>
<span class="udiff-line-added">+     // setup code in the verified_value_entry (which has a different real_frame_size).</span>
<span class="udiff-line-added">+     build_frame_helper(frame_size_in_bytes, sp_inc, true);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   jmp(verified_value_entry_label);</span>
<span class="udiff-line-added">+   return rt_call_offset;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
    // rbp, + 0: link
    //     + 1: return address
    //     + 2: argument with offset 0
    //     + 3: argument with offset 1
</pre>
<center><a href="c1_LIRAssembler_x86.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>