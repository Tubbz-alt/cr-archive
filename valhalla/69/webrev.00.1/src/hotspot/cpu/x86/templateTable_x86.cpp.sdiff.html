<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/templateTable_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vtableStubs_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/templateTable_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;compiler/disassembler.hpp&quot;
  28 #include &quot;interpreter/interpreter.hpp&quot;
  29 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  30 #include &quot;interpreter/interp_masm.hpp&quot;
  31 #include &quot;interpreter/templateTable.hpp&quot;
  32 #include &quot;memory/universe.hpp&quot;
  33 #include &quot;oops/methodData.hpp&quot;
  34 #include &quot;oops/objArrayKlass.hpp&quot;
  35 #include &quot;oops/oop.inline.hpp&quot;

  36 #include &quot;prims/methodHandles.hpp&quot;
  37 #include &quot;runtime/frame.inline.hpp&quot;
  38 #include &quot;runtime/safepointMechanism.hpp&quot;
  39 #include &quot;runtime/sharedRuntime.hpp&quot;
  40 #include &quot;runtime/stubRoutines.hpp&quot;
  41 #include &quot;runtime/synchronizer.hpp&quot;
  42 #include &quot;utilities/macros.hpp&quot;
  43 
  44 #define __ Disassembler::hook&lt;InterpreterMacroAssembler&gt;(__FILE__, __LINE__, _masm)-&gt;
  45 
  46 // Global Register Names
  47 static const Register rbcp     = LP64_ONLY(r13) NOT_LP64(rsi);
  48 static const Register rlocals  = LP64_ONLY(r14) NOT_LP64(rdi);
  49 
  50 // Platform-dependent initialization
  51 void TemplateTable::pd_initialize() {
  52   // No x86 specific initialization
  53 }
  54 
  55 // Address Computation: local variables
</pre>
<hr />
<pre>
 137   case TemplateTable::less_equal   : return Assembler::greater;
 138   case TemplateTable::greater      : return Assembler::lessEqual;
 139   case TemplateTable::greater_equal: return Assembler::less;
 140   }
 141   ShouldNotReachHere();
 142   return Assembler::zero;
 143 }
 144 
 145 
 146 
 147 // Miscelaneous helper routines
 148 // Store an oop (or NULL) at the address described by obj.
 149 // If val == noreg this means store a NULL
 150 
 151 
 152 static void do_oop_store(InterpreterMacroAssembler* _masm,
 153                          Address dst,
 154                          Register val,
 155                          DecoratorSet decorators = 0) {
 156   assert(val == noreg || val == rax, &quot;parameter is just for looks&quot;);
<span class="line-modified"> 157   __ store_heap_oop(dst, val, rdx, rbx, decorators);</span>
 158 }
 159 
 160 static void do_oop_load(InterpreterMacroAssembler* _masm,
 161                         Address src,
 162                         Register dst,
 163                         DecoratorSet decorators = 0) {
 164   __ load_heap_oop(dst, src, rdx, rbx, decorators);
 165 }
 166 
 167 Address TemplateTable::at_bcp(int offset) {
 168   assert(_desc-&gt;uses_bcp(), &quot;inconsistent uses_bcp information&quot;);
 169   return Address(rbcp, offset);
 170 }
 171 
 172 
 173 void TemplateTable::patch_bytecode(Bytecodes::Code bc, Register bc_reg,
 174                                    Register temp_reg, bool load_bc_into_bc_reg/*=true*/,
 175                                    int byte_no) {
 176   if (!RewriteBytecodes)  return;
 177   Label L_patch_done;
 178 
 179   switch (bc) {

 180   case Bytecodes::_fast_aputfield:
 181   case Bytecodes::_fast_bputfield:
 182   case Bytecodes::_fast_zputfield:
 183   case Bytecodes::_fast_cputfield:
 184   case Bytecodes::_fast_dputfield:
 185   case Bytecodes::_fast_fputfield:
 186   case Bytecodes::_fast_iputfield:
 187   case Bytecodes::_fast_lputfield:
 188   case Bytecodes::_fast_sputfield:
 189     {
 190       // We skip bytecode quickening for putfield instructions when
 191       // the put_code written to the constant pool cache is zero.
 192       // This is required so that every execution of this instruction
 193       // calls out to InterpreterRuntime::resolve_get_put to do
 194       // additional, required work.
 195       assert(byte_no == f1_byte || byte_no == f2_byte, &quot;byte_no out of range&quot;);
 196       assert(load_bc_into_bc_reg, &quot;we use bc_reg as temp&quot;);
 197       __ get_cache_and_index_and_bytecode_at_bcp(temp_reg, bc_reg, temp_reg, byte_no, 1);
 198       __ movl(bc_reg, bc);
 199       __ cmpl(temp_reg, (int) 0);
</pre>
<hr />
<pre>
 352   __ sarl(rax, 16);
 353 }
 354 
 355 void TemplateTable::ldc(bool wide) {
 356   transition(vtos, vtos);
 357   Register rarg = NOT_LP64(rcx) LP64_ONLY(c_rarg1);
 358   Label call_ldc, notFloat, notClass, notInt, Done;
 359 
 360   if (wide) {
 361     __ get_unsigned_2_byte_index_at_bcp(rbx, 1);
 362   } else {
 363     __ load_unsigned_byte(rbx, at_bcp(1));
 364   }
 365 
 366   __ get_cpool_and_tags(rcx, rax);
 367   const int base_offset = ConstantPool::header_size() * wordSize;
 368   const int tags_offset = Array&lt;u1&gt;::base_offset_in_bytes();
 369 
 370   // get type
 371   __ movzbl(rdx, Address(rax, rbx, Address::times_1, tags_offset));

 372 
 373   // unresolved class - get the resolved class
 374   __ cmpl(rdx, JVM_CONSTANT_UnresolvedClass);
 375   __ jccb(Assembler::equal, call_ldc);
 376 
 377   // unresolved class in error state - call into runtime to throw the error
 378   // from the first resolution attempt
 379   __ cmpl(rdx, JVM_CONSTANT_UnresolvedClassInError);
 380   __ jccb(Assembler::equal, call_ldc);
 381 
 382   // resolved class - need to call vm to get java mirror of the class
 383   __ cmpl(rdx, JVM_CONSTANT_Class);
 384   __ jcc(Assembler::notEqual, notClass);
 385 
 386   __ bind(call_ldc);
 387 
 388   __ movl(rarg, wide);
 389   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::ldc), rarg);
 390 
 391   __ push(atos);
</pre>
<hr />
<pre>
 802                     Address(rdx, rax,
 803                             Address::times_4,
 804                             arrayOopDesc::base_offset_in_bytes(T_FLOAT)),
 805                     noreg, noreg);
 806 }
 807 
 808 void TemplateTable::daload() {
 809   transition(itos, dtos);
 810   // rax: index
 811   // rdx: array
 812   index_check(rdx, rax); // kills rbx
 813   __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg /* dtos */,
 814                     Address(rdx, rax,
 815                             Address::times_8,
 816                             arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),
 817                     noreg, noreg);
 818 }
 819 
 820 void TemplateTable::aaload() {
 821   transition(itos, atos);
<span class="line-modified"> 822   // rax: index</span>
<span class="line-modified"> 823   // rdx: array</span>
<span class="line-modified"> 824   index_check(rdx, rax); // kills rbx</span>
<span class="line-modified"> 825   do_oop_load(_masm,</span>
<span class="line-modified"> 826               Address(rdx, rax,</span>
<span class="line-modified"> 827                       UseCompressedOops ? Address::times_4 : Address::times_ptr,</span>
<span class="line-modified"> 828                       arrayOopDesc::base_offset_in_bytes(T_OBJECT)),</span>
<span class="line-modified"> 829               rax,</span>
<span class="line-modified"> 830               IS_ARRAY);</span>


















 831 }
 832 
 833 void TemplateTable::baload() {
 834   transition(itos, itos);
 835   // rax: index
 836   // rdx: array
 837   index_check(rdx, rax); // kills rbx
 838   __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax,
 839                     Address(rdx, rax, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_BYTE)),
 840                     noreg, noreg);
 841 }
 842 
 843 void TemplateTable::caload() {
 844   transition(itos, itos);
 845   // rax: index
 846   // rdx: array
 847   index_check(rdx, rax); // kills rbx
 848   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax,
 849                     Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_CHAR)),
 850                     noreg, noreg);
</pre>
<hr />
<pre>
1096   __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY,
1097                      Address(rdx, rbx, Address::times_4,
1098                              arrayOopDesc::base_offset_in_bytes(T_FLOAT)),
1099                      noreg /* ftos */, noreg, noreg);
1100 }
1101 
1102 void TemplateTable::dastore() {
1103   transition(dtos, vtos);
1104   __ pop_i(rbx);
1105   // value is in UseSSE &gt;= 2 ? xmm0 : ST(0)
1106   // rbx:  index
1107   // rdx:  array
1108   index_check(rdx, rbx); // prefer index in rbx
1109   __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY,
1110                      Address(rdx, rbx, Address::times_8,
1111                              arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),
1112                      noreg /* dtos */, noreg, noreg);
1113 }
1114 
1115 void TemplateTable::aastore() {
<span class="line-modified">1116   Label is_null, ok_is_subtype, done;</span>
1117   transition(vtos, vtos);
1118   // stack: ..., array, index, value
1119   __ movptr(rax, at_tos());    // value
1120   __ movl(rcx, at_tos_p1()); // index
1121   __ movptr(rdx, at_tos_p2()); // array
1122 
1123   Address element_address(rdx, rcx,
1124                           UseCompressedOops? Address::times_4 : Address::times_ptr,
1125                           arrayOopDesc::base_offset_in_bytes(T_OBJECT));
1126 
1127   index_check_without_pop(rdx, rcx);     // kills rbx




1128   __ testptr(rax, rax);
1129   __ jcc(Assembler::zero, is_null);
1130 

1131   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);






1132   // Move subklass into rbx
1133   __ load_klass(rbx, rax, tmp_load_klass);
<span class="line-modified">1134   // Move superklass into rax</span>
<span class="line-modified">1135   __ load_klass(rax, rdx, tmp_load_klass);</span>
<span class="line-removed">1136   __ movptr(rax, Address(rax,</span>
1137                          ObjArrayKlass::element_klass_offset()));
1138 
1139   // Generate subtype check.  Blows rcx, rdi
1140   // Superklass in rax.  Subklass in rbx.
<span class="line-modified">1141   __ gen_subtype_check(rbx, ok_is_subtype);</span>

1142 
1143   // Come here on failure
1144   // object is at TOS
1145   __ jump(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));
1146 
1147   // Come here on success
1148   __ bind(ok_is_subtype);
1149 
1150   // Get the value we will store
1151   __ movptr(rax, at_tos());
1152   __ movl(rcx, at_tos_p1()); // index
1153   // Now store using the appropriate barrier
1154   do_oop_store(_masm, element_address, rax, IS_ARRAY);
1155   __ jmp(done);
1156 
1157   // Have a NULL in rax, rdx=array, ecx=index.  Store NULL at ary[idx]
1158   __ bind(is_null);
<span class="line-modified">1159   __ profile_null_seen(rbx);</span>

1160 









1161   // Store a NULL
1162   do_oop_store(_masm, element_address, noreg, IS_ARRAY);







1163 



























1164   // Pop stack arguments
1165   __ bind(done);
1166   __ addptr(rsp, 3 * Interpreter::stackElementSize);
1167 }
1168 
1169 void TemplateTable::bastore() {
1170   transition(itos, vtos);
1171   __ pop_i(rbx);
1172   // rax: value
1173   // rbx: index
1174   // rdx: array
1175   index_check(rdx, rbx); // prefer index in rbx
1176   // Need to check whether array is boolean or byte
1177   // since both types share the bastore bytecode.
1178   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1179   __ load_klass(rcx, rdx, tmp_load_klass);
1180   __ movl(rcx, Address(rcx, Klass::layout_helper_offset()));
1181   int diffbit = Klass::layout_helper_boolean_diffbit();
1182   __ testl(rcx, diffbit);
1183   Label L_skip;
</pre>
<hr />
<pre>
2390   __ jcc(j_not(cc), not_taken);
2391   branch(false, false);
2392   __ bind(not_taken);
2393   __ profile_not_taken_branch(rax);
2394 }
2395 
2396 void TemplateTable::if_nullcmp(Condition cc) {
2397   transition(atos, vtos);
2398   // assume branch is more often taken than not (loops use backward branches)
2399   Label not_taken;
2400   __ testptr(rax, rax);
2401   __ jcc(j_not(cc), not_taken);
2402   branch(false, false);
2403   __ bind(not_taken);
2404   __ profile_not_taken_branch(rax);
2405 }
2406 
2407 void TemplateTable::if_acmp(Condition cc) {
2408   transition(atos, vtos);
2409   // assume branch is more often taken than not (loops use backward branches)
<span class="line-modified">2410   Label not_taken;</span>
2411   __ pop_ptr(rdx);




































2412   __ cmpoop(rdx, rax);
2413   __ jcc(j_not(cc), not_taken);

2414   branch(false, false);
2415   __ bind(not_taken);
2416   __ profile_not_taken_branch(rax);
2417 }
2418 









2419 void TemplateTable::ret() {
2420   transition(vtos, vtos);
2421   locals_index(rbx);
2422   LP64_ONLY(__ movslq(rbx, iaddress(rbx))); // get return bci, compute return bcp
2423   NOT_LP64(__ movptr(rbx, iaddress(rbx)));
2424   __ profile_ret(rbx, rcx);
2425   __ get_method(rax);
2426   __ movptr(rbcp, Address(rax, Method::const_offset()));
2427   __ lea(rbcp, Address(rbcp, rbx, Address::times_1,
2428                       ConstMethod::codes_offset()));
2429   __ dispatch_next(vtos, 0, true);
2430 }
2431 
2432 void TemplateTable::wide_ret() {
2433   transition(vtos, vtos);
2434   locals_index_wide(rbx);
2435   __ movptr(rbx, aaddress(rbx)); // get return bci, compute return bcp
2436   __ profile_ret(rbx, rcx);
2437   __ get_method(rax);
2438   __ movptr(rbcp, Address(rax, Method::const_offset()));
</pre>
<hr />
<pre>
2665     __ testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
2666 #else
2667     const Register thread = rdi;
2668     __ get_thread(thread);
2669     __ testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
2670 #endif
2671     __ jcc(Assembler::zero, no_safepoint);
2672     __ push(state);
2673     __ call_VM(noreg, CAST_FROM_FN_PTR(address,
2674                                     InterpreterRuntime::at_safepoint));
2675     __ pop(state);
2676     __ bind(no_safepoint);
2677   }
2678 
2679   // Narrow result if state is itos but result type is smaller.
2680   // Need to narrow in the return bytecode rather than in generate_return_entry
2681   // since compiled code callers expect the result to already be narrowed.
2682   if (state == itos) {
2683     __ narrow(rax);
2684   }
<span class="line-modified">2685   __ remove_activation(state, rbcp);</span>

2686 
2687   __ jmp(rbcp);
2688 }
2689 
2690 // ----------------------------------------------------------------------------
2691 // Volatile variables demand their effects be made known to all CPU&#39;s
2692 // in order.  Store buffers on most chips allow reads &amp; writes to
2693 // reorder; the JMM&#39;s ReadAfterWrite.java test fails in -Xint mode
2694 // without some kind of memory barrier (i.e., it&#39;s not sufficient that
2695 // the interpreter does not reorder volatile references, the hardware
2696 // also must not reorder them).
2697 //
2698 // According to the new Java Memory Model (JMM):
2699 // (1) All volatiles are serialized wrt to each other.  ALSO reads &amp;
2700 //     writes act as aquire &amp; release, so:
2701 // (2) A read cannot let unrelated NON-volatile memory refs that
2702 //     happen after the read float up to before the read.  It&#39;s OK for
2703 //     non-volatile memory refs that happen before the volatile read to
2704 //     float down below it.
2705 // (3) Similar a volatile write cannot let unrelated NON-volatile
</pre>
<hr />
<pre>
2863     __ get_cache_and_index_at_bcp(cache, index, 1);
2864     __ bind(L1);
2865   }
2866 }
2867 
2868 void TemplateTable::pop_and_check_object(Register r) {
2869   __ pop_ptr(r);
2870   __ null_check(r);  // for field access must check obj.
2871   __ verify_oop(r);
2872 }
2873 
2874 void TemplateTable::getfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
2875   transition(vtos, vtos);
2876 
2877   const Register cache = rcx;
2878   const Register index = rdx;
2879   const Register obj   = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
2880   const Register off   = rbx;
2881   const Register flags = rax;
2882   const Register bc    = LP64_ONLY(c_rarg3) NOT_LP64(rcx); // uses same reg as obj, so don&#39;t mix them

2883 
2884   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
2885   jvmti_post_field_access(cache, index, is_static, false);
2886   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
2887 
<span class="line-removed">2888   if (!is_static) pop_and_check_object(obj);</span>
<span class="line-removed">2889 </span>
2890   const Address field(obj, off, Address::times_1, 0*wordSize);
2891 
<span class="line-modified">2892   Label Done, notByte, notBool, notInt, notShort, notChar, notLong, notFloat, notObj;</span>








2893 
2894   __ shrl(flags, ConstantPoolCacheEntry::tos_state_shift);
2895   // Make sure we don&#39;t need to mask edx after the above shift
2896   assert(btos == 0, &quot;change code, btos != 0&quot;);
2897 
2898   __ andl(flags, ConstantPoolCacheEntry::tos_state_mask);
2899 
2900   __ jcc(Assembler::notZero, notByte);
2901   // btos

2902   __ access_load_at(T_BYTE, IN_HEAP, rax, field, noreg, noreg);
2903   __ push(btos);
2904   // Rewrite bytecode to be faster
2905   if (!is_static &amp;&amp; rc == may_rewrite) {
2906     patch_bytecode(Bytecodes::_fast_bgetfield, bc, rbx);
2907   }
2908   __ jmp(Done);
2909 
2910   __ bind(notByte);

2911   __ cmpl(flags, ztos);
2912   __ jcc(Assembler::notEqual, notBool);
<span class="line-modified">2913 </span>
2914   // ztos (same code as btos)
2915   __ access_load_at(T_BOOLEAN, IN_HEAP, rax, field, noreg, noreg);
2916   __ push(ztos);
2917   // Rewrite bytecode to be faster
2918   if (!is_static &amp;&amp; rc == may_rewrite) {
2919     // use btos rewriting, no truncating to t/f bit is needed for getfield.
2920     patch_bytecode(Bytecodes::_fast_bgetfield, bc, rbx);
2921   }
2922   __ jmp(Done);
2923 
2924   __ bind(notBool);
2925   __ cmpl(flags, atos);
2926   __ jcc(Assembler::notEqual, notObj);
2927   // atos
<span class="line-modified">2928   do_oop_load(_masm, field, rax);</span>
<span class="line-modified">2929   __ push(atos);</span>
<span class="line-modified">2930   if (!is_static &amp;&amp; rc == may_rewrite) {</span>
<span class="line-modified">2931     patch_bytecode(Bytecodes::_fast_agetfield, bc, rbx);</span>













































































2932   }
<span class="line-removed">2933   __ jmp(Done);</span>
2934 
2935   __ bind(notObj);



2936   __ cmpl(flags, itos);
2937   __ jcc(Assembler::notEqual, notInt);
2938   // itos
2939   __ access_load_at(T_INT, IN_HEAP, rax, field, noreg, noreg);
2940   __ push(itos);
2941   // Rewrite bytecode to be faster
2942   if (!is_static &amp;&amp; rc == may_rewrite) {
2943     patch_bytecode(Bytecodes::_fast_igetfield, bc, rbx);
2944   }
2945   __ jmp(Done);
2946 
2947   __ bind(notInt);
2948   __ cmpl(flags, ctos);
2949   __ jcc(Assembler::notEqual, notChar);
2950   // ctos
2951   __ access_load_at(T_CHAR, IN_HEAP, rax, field, noreg, noreg);
2952   __ push(ctos);
2953   // Rewrite bytecode to be faster
2954   if (!is_static &amp;&amp; rc == may_rewrite) {
2955     patch_bytecode(Bytecodes::_fast_cgetfield, bc, rbx);
</pre>
<hr />
<pre>
3015 #endif
3016 
3017   __ bind(Done);
3018   // [jk] not needed currently
3019   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadLoad |
3020   //                                              Assembler::LoadStore));
3021 }
3022 
3023 void TemplateTable::getfield(int byte_no) {
3024   getfield_or_static(byte_no, false);
3025 }
3026 
3027 void TemplateTable::nofast_getfield(int byte_no) {
3028   getfield_or_static(byte_no, false, may_not_rewrite);
3029 }
3030 
3031 void TemplateTable::getstatic(int byte_no) {
3032   getfield_or_static(byte_no, true);
3033 }
3034 















3035 
3036 // The registers cache and index expected to be set before call.
3037 // The function may destroy various registers, just not the cache and index registers.
3038 void TemplateTable::jvmti_post_field_mod(Register cache, Register index, bool is_static) {
3039 
3040   const Register robj = LP64_ONLY(c_rarg2)   NOT_LP64(rax);
3041   const Register RBX  = LP64_ONLY(c_rarg1)   NOT_LP64(rbx);
3042   const Register RCX  = LP64_ONLY(c_rarg3)   NOT_LP64(rcx);
3043   const Register RDX  = LP64_ONLY(rscratch1) NOT_LP64(rdx);
3044 
3045   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
3046 
3047   if (JvmtiExport::can_post_field_modification()) {
3048     // Check to see if a field modification watch has been set before
3049     // we take the time to call into the VM.
3050     Label L1;
3051     assert_different_registers(cache, index, rax);
3052     __ mov32(rax, ExternalAddress((address)JvmtiExport::get_field_modification_count_addr()));
3053     __ testl(rax, rax);
3054     __ jcc(Assembler::zero, L1);
</pre>
<hr />
<pre>
3110     // c_rarg1: object pointer set up above (NULL if static)
3111     // c_rarg2: cache entry pointer
3112     // c_rarg3: jvalue object on the stack
3113     __ call_VM(noreg,
3114                CAST_FROM_FN_PTR(address,
3115                                 InterpreterRuntime::post_field_modification),
3116                RBX, robj, RCX);
3117     __ get_cache_and_index_at_bcp(cache, index, 1);
3118     __ bind(L1);
3119   }
3120 }
3121 
3122 void TemplateTable::putfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
3123   transition(vtos, vtos);
3124 
3125   const Register cache = rcx;
3126   const Register index = rdx;
3127   const Register obj   = rcx;
3128   const Register off   = rbx;
3129   const Register flags = rax;

3130 
3131   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
3132   jvmti_post_field_mod(cache, index, is_static);
3133   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
3134 
3135   // [jk] not needed currently
3136   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadStore |
3137   //                                              Assembler::StoreStore));
3138 
3139   Label notVolatile, Done;
3140   __ movl(rdx, flags);
3141   __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3142   __ andl(rdx, 0x1);
3143 
3144   // Check for volatile store
3145   __ testl(rdx, rdx);

3146   __ jcc(Assembler::zero, notVolatile);
3147 
<span class="line-modified">3148   putfield_or_static_helper(byte_no, is_static, rc, obj, off, flags);</span>
3149   volatile_barrier(Assembler::Membar_mask_bits(Assembler::StoreLoad |
3150                                                Assembler::StoreStore));
3151   __ jmp(Done);
3152   __ bind(notVolatile);
3153 
<span class="line-modified">3154   putfield_or_static_helper(byte_no, is_static, rc, obj, off, flags);</span>
3155 
3156   __ bind(Done);
3157 }
3158 
3159 void TemplateTable::putfield_or_static_helper(int byte_no, bool is_static, RewriteControl rc,
<span class="line-modified">3160                                               Register obj, Register off, Register flags) {</span>
3161 
3162   // field addresses
3163   const Address field(obj, off, Address::times_1, 0*wordSize);
3164   NOT_LP64( const Address hi(obj, off, Address::times_1, 1*wordSize);)
3165 
3166   Label notByte, notBool, notInt, notShort, notChar,
<span class="line-modified">3167         notLong, notFloat, notObj;</span>
3168   Label Done;
3169 
3170   const Register bc    = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
3171 
3172   __ shrl(flags, ConstantPoolCacheEntry::tos_state_shift);
3173 
3174   assert(btos == 0, &quot;change code, btos != 0&quot;);
3175   __ andl(flags, ConstantPoolCacheEntry::tos_state_mask);
3176   __ jcc(Assembler::notZero, notByte);
3177 
3178   // btos
3179   {
3180     __ pop(btos);
3181     if (!is_static) pop_and_check_object(obj);
3182     __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);
3183     if (!is_static &amp;&amp; rc == may_rewrite) {
3184       patch_bytecode(Bytecodes::_fast_bputfield, bc, rbx, true, byte_no);
3185     }
3186     __ jmp(Done);
3187   }
</pre>
<hr />
<pre>
3190   __ cmpl(flags, ztos);
3191   __ jcc(Assembler::notEqual, notBool);
3192 
3193   // ztos
3194   {
3195     __ pop(ztos);
3196     if (!is_static) pop_and_check_object(obj);
3197     __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);
3198     if (!is_static &amp;&amp; rc == may_rewrite) {
3199       patch_bytecode(Bytecodes::_fast_zputfield, bc, rbx, true, byte_no);
3200     }
3201     __ jmp(Done);
3202   }
3203 
3204   __ bind(notBool);
3205   __ cmpl(flags, atos);
3206   __ jcc(Assembler::notEqual, notObj);
3207 
3208   // atos
3209   {
<span class="line-modified">3210     __ pop(atos);</span>
<span class="line-modified">3211     if (!is_static) pop_and_check_object(obj);</span>
<span class="line-modified">3212     // Store into the field</span>
<span class="line-modified">3213     do_oop_store(_masm, field, rax);</span>
<span class="line-modified">3214     if (!is_static &amp;&amp; rc == may_rewrite) {</span>
<span class="line-modified">3215       patch_bytecode(Bytecodes::_fast_aputfield, bc, rbx, true, byte_no);</span>














































3216     }
<span class="line-removed">3217     __ jmp(Done);</span>
3218   }
3219 
3220   __ bind(notObj);
3221   __ cmpl(flags, itos);
3222   __ jcc(Assembler::notEqual, notInt);
3223 
3224   // itos
3225   {
3226     __ pop(itos);
3227     if (!is_static) pop_and_check_object(obj);
3228     __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);
3229     if (!is_static &amp;&amp; rc == may_rewrite) {
3230       patch_bytecode(Bytecodes::_fast_iputfield, bc, rbx, true, byte_no);
3231     }
3232     __ jmp(Done);
3233   }
3234 
3235   __ bind(notInt);
3236   __ cmpl(flags, ctos);
3237   __ jcc(Assembler::notEqual, notChar);
</pre>
<hr />
<pre>
3336 }
3337 
3338 void TemplateTable::jvmti_post_fast_field_mod() {
3339 
3340   const Register scratch = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
3341 
3342   if (JvmtiExport::can_post_field_modification()) {
3343     // Check to see if a field modification watch has been set before
3344     // we take the time to call into the VM.
3345     Label L2;
3346     __ mov32(scratch, ExternalAddress((address)JvmtiExport::get_field_modification_count_addr()));
3347     __ testl(scratch, scratch);
3348     __ jcc(Assembler::zero, L2);
3349     __ pop_ptr(rbx);                  // copy the object pointer from tos
3350     __ verify_oop(rbx);
3351     __ push_ptr(rbx);                 // put the object pointer back on tos
3352     // Save tos values before call_VM() clobbers them. Since we have
3353     // to do it for every data type, we use the saved values as the
3354     // jvalue object.
3355     switch (bytecode()) {          // load values into the jvalue object

3356     case Bytecodes::_fast_aputfield: __ push_ptr(rax); break;
3357     case Bytecodes::_fast_bputfield: // fall through
3358     case Bytecodes::_fast_zputfield: // fall through
3359     case Bytecodes::_fast_sputfield: // fall through
3360     case Bytecodes::_fast_cputfield: // fall through
3361     case Bytecodes::_fast_iputfield: __ push_i(rax); break;
3362     case Bytecodes::_fast_dputfield: __ push(dtos); break;
3363     case Bytecodes::_fast_fputfield: __ push(ftos); break;
3364     case Bytecodes::_fast_lputfield: __ push_l(rax); break;
3365 
3366     default:
3367       ShouldNotReachHere();
3368     }
3369     __ mov(scratch, rsp);             // points to jvalue on the stack
3370     // access constant pool cache entry
3371     LP64_ONLY(__ get_cache_entry_pointer_at_bcp(c_rarg2, rax, 1));
3372     NOT_LP64(__ get_cache_entry_pointer_at_bcp(rax, rdx, 1));
3373     __ verify_oop(rbx);
3374     // rbx: object pointer copied above
3375     // c_rarg2: cache entry pointer
3376     // c_rarg3: jvalue object on the stack
3377     LP64_ONLY(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_modification), rbx, c_rarg2, c_rarg3));
3378     NOT_LP64(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_modification), rbx, rax, rcx));
3379 
3380     switch (bytecode()) {             // restore tos values

3381     case Bytecodes::_fast_aputfield: __ pop_ptr(rax); break;
3382     case Bytecodes::_fast_bputfield: // fall through
3383     case Bytecodes::_fast_zputfield: // fall through
3384     case Bytecodes::_fast_sputfield: // fall through
3385     case Bytecodes::_fast_cputfield: // fall through
3386     case Bytecodes::_fast_iputfield: __ pop_i(rax); break;
3387     case Bytecodes::_fast_dputfield: __ pop(dtos); break;
3388     case Bytecodes::_fast_fputfield: __ pop(ftos); break;
3389     case Bytecodes::_fast_lputfield: __ pop_l(rax); break;
3390     default: break;
3391     }
3392     __ bind(L2);
3393   }
3394 }
3395 
3396 void TemplateTable::fast_storefield(TosState state) {
3397   transition(state, vtos);
3398 
3399   ByteSize base = ConstantPoolCache::base_offset();
3400 
3401   jvmti_post_fast_field_mod();
3402 
3403   // access constant pool cache
3404   __ get_cache_and_index_at_bcp(rcx, rbx, 1);
3405 
3406   // test for volatile with rdx but rdx is tos register for lputfield.
3407   __ movl(rdx, Address(rcx, rbx, Address::times_ptr,
3408                        in_bytes(base +
3409                                 ConstantPoolCacheEntry::flags_offset())));
3410 
3411   // replace index with field offset from cache entry
3412   __ movptr(rbx, Address(rcx, rbx, Address::times_ptr,
3413                          in_bytes(base + ConstantPoolCacheEntry::f2_offset())));
3414 
3415   // [jk] not needed currently
3416   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadStore |
3417   //                                              Assembler::StoreStore));
3418 
3419   Label notVolatile, Done;




3420   __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3421   __ andl(rdx, 0x1);
3422 
3423   // Get object from stack
3424   pop_and_check_object(rcx);
3425 
3426   // field address
3427   const Address field(rcx, rbx, Address::times_1);
3428 
3429   // Check for volatile store
3430   __ testl(rdx, rdx);
3431   __ jcc(Assembler::zero, notVolatile);
3432 
<span class="line-modified">3433   fast_storefield_helper(field, rax);</span>



3434   volatile_barrier(Assembler::Membar_mask_bits(Assembler::StoreLoad |
3435                                                Assembler::StoreStore));
3436   __ jmp(Done);
3437   __ bind(notVolatile);
3438 
<span class="line-modified">3439   fast_storefield_helper(field, rax);</span>



3440 
3441   __ bind(Done);
3442 }
3443 
<span class="line-modified">3444 void TemplateTable::fast_storefield_helper(Address field, Register rax) {</span>
3445 
3446   // access field
3447   switch (bytecode()) {

















3448   case Bytecodes::_fast_aputfield:
<span class="line-modified">3449     do_oop_store(_masm, field, rax);</span>


3450     break;
3451   case Bytecodes::_fast_lputfield:
3452 #ifdef _LP64
3453     __ access_store_at(T_LONG, IN_HEAP, field, noreg /* ltos */, noreg, noreg);
3454 #else
3455   __ stop(&quot;should not be rewritten&quot;);
3456 #endif
3457     break;
3458   case Bytecodes::_fast_iputfield:
3459     __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);
3460     break;
3461   case Bytecodes::_fast_zputfield:
3462     __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);
3463     break;
3464   case Bytecodes::_fast_bputfield:
3465     __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);
3466     break;
3467   case Bytecodes::_fast_sputfield:
3468     __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg);
3469     break;
</pre>
<hr />
<pre>
3499     __ push_ptr(rax);  // save object pointer before call_VM() clobbers it
3500     LP64_ONLY(__ mov(c_rarg1, rax));
3501     // c_rarg1: object pointer copied above
3502     // c_rarg2: cache entry pointer
3503     LP64_ONLY(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_access), c_rarg1, c_rarg2));
3504     NOT_LP64(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_access), rax, rcx));
3505     __ pop_ptr(rax); // restore object pointer
3506     __ bind(L1);
3507   }
3508 
3509   // access constant pool cache
3510   __ get_cache_and_index_at_bcp(rcx, rbx, 1);
3511   // replace index with field offset from cache entry
3512   // [jk] not needed currently
3513   // __ movl(rdx, Address(rcx, rbx, Address::times_8,
3514   //                      in_bytes(ConstantPoolCache::base_offset() +
3515   //                               ConstantPoolCacheEntry::flags_offset())));
3516   // __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3517   // __ andl(rdx, 0x1);
3518   //
<span class="line-modified">3519   __ movptr(rbx, Address(rcx, rbx, Address::times_ptr,</span>
3520                          in_bytes(ConstantPoolCache::base_offset() +
3521                                   ConstantPoolCacheEntry::f2_offset())));
3522 
3523   // rax: object
3524   __ verify_oop(rax);
3525   __ null_check(rax);
<span class="line-modified">3526   Address field(rax, rbx, Address::times_1);</span>
3527 
3528   // access field
3529   switch (bytecode()) {






































3530   case Bytecodes::_fast_agetfield:
3531     do_oop_load(_masm, field, rax);
3532     __ verify_oop(rax);
3533     break;
3534   case Bytecodes::_fast_lgetfield:
3535 #ifdef _LP64
3536     __ access_load_at(T_LONG, IN_HEAP, noreg /* ltos */, field, noreg, noreg);
3537 #else
3538   __ stop(&quot;should not be rewritten&quot;);
3539 #endif
3540     break;
3541   case Bytecodes::_fast_igetfield:
3542     __ access_load_at(T_INT, IN_HEAP, rax, field, noreg, noreg);
3543     break;
3544   case Bytecodes::_fast_bgetfield:
3545     __ access_load_at(T_BYTE, IN_HEAP, rax, field, noreg, noreg);
3546     break;
3547   case Bytecodes::_fast_sgetfield:
3548     __ access_load_at(T_SHORT, IN_HEAP, rax, field, noreg, noreg);
3549     break;
</pre>
<hr />
<pre>
3983 
3984   // Note:  rax_callsite is already pushed by prepare_invoke
3985 
3986   // %%% should make a type profile for any invokedynamic that takes a ref argument
3987   // profile this call
3988   __ profile_call(rbcp);
3989   __ profile_arguments_type(rdx, rbx_method, rbcp, false);
3990 
3991   __ verify_oop(rax_callsite);
3992 
3993   __ jump_from_interpreted(rbx_method, rdx);
3994 }
3995 
3996 //-----------------------------------------------------------------------------
3997 // Allocation
3998 
3999 void TemplateTable::_new() {
4000   transition(vtos, atos);
4001   __ get_unsigned_2_byte_index_at_bcp(rdx, 1);
4002   Label slow_case;
<span class="line-modified">4003   Label slow_case_no_pop;</span>
<span class="line-removed">4004   Label done;</span>
<span class="line-removed">4005   Label initialize_header;</span>
4006   Label initialize_object;  // including clearing the fields
4007 
4008   __ get_cpool_and_tags(rcx, rax);
4009 
4010   // Make sure the class we&#39;re about to instantiate has been resolved.
4011   // This is done before loading InstanceKlass to be consistent with the order
4012   // how Constant Pool is updated (see ConstantPool::klass_at_put)
4013   const int tags_offset = Array&lt;u1&gt;::base_offset_in_bytes();
4014   __ cmpb(Address(rax, rdx, Address::times_1, tags_offset), JVM_CONSTANT_Class);
<span class="line-modified">4015   __ jcc(Assembler::notEqual, slow_case_no_pop);</span>
4016 
4017   // get InstanceKlass
4018   __ load_resolved_klass_at_index(rcx, rcx, rdx);
<span class="line-modified">4019   __ push(rcx);  // save the contexts of klass for initializing the header</span>






4020 
4021   // make sure klass is initialized &amp; doesn&#39;t have finalizer
<span class="line-removed">4022   // make sure klass is fully initialized</span>
4023   __ cmpb(Address(rcx, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);
4024   __ jcc(Assembler::notEqual, slow_case);
4025 
<span class="line-modified">4026   // get instance_size in InstanceKlass (scaled to a count of bytes)</span>
<span class="line-modified">4027   __ movl(rdx, Address(rcx, Klass::layout_helper_offset()));</span>
<span class="line-removed">4028   // test to see if it has a finalizer or is malformed in some way</span>
<span class="line-removed">4029   __ testl(rdx, Klass::_lh_instance_slow_path_bit);</span>
<span class="line-removed">4030   __ jcc(Assembler::notZero, slow_case);</span>
<span class="line-removed">4031 </span>
<span class="line-removed">4032   // Allocate the instance:</span>
<span class="line-removed">4033   //  If TLAB is enabled:</span>
<span class="line-removed">4034   //    Try to allocate in the TLAB.</span>
<span class="line-removed">4035   //    If fails, go to the slow path.</span>
<span class="line-removed">4036   //  Else If inline contiguous allocations are enabled:</span>
<span class="line-removed">4037   //    Try to allocate in eden.</span>
<span class="line-removed">4038   //    If fails due to heap end, go to slow path.</span>
<span class="line-removed">4039   //</span>
<span class="line-removed">4040   //  If TLAB is enabled OR inline contiguous is enabled:</span>
<span class="line-removed">4041   //    Initialize the allocation.</span>
<span class="line-removed">4042   //    Exit.</span>
<span class="line-removed">4043   //</span>
<span class="line-removed">4044   //  Go to slow path.</span>
4045 
<span class="line-modified">4046   const bool allow_shared_alloc =</span>
<span class="line-modified">4047     Universe::heap()-&gt;supports_inline_contig_alloc();</span>
4048 
<span class="line-modified">4049   const Register thread = LP64_ONLY(r15_thread) NOT_LP64(rcx);</span>
<span class="line-modified">4050 #ifndef _LP64</span>
<span class="line-removed">4051   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-removed">4052     __ get_thread(thread);</span>
<span class="line-removed">4053   }</span>
<span class="line-removed">4054 #endif // _LP64</span>
4055 
<span class="line-modified">4056   if (UseTLAB) {</span>
<span class="line-modified">4057     __ tlab_allocate(thread, rax, rdx, 0, rcx, rbx, slow_case);</span>
<span class="line-modified">4058     if (ZeroTLAB) {</span>
<span class="line-modified">4059       // the fields have been already cleared</span>
<span class="line-removed">4060       __ jmp(initialize_header);</span>
<span class="line-removed">4061     } else {</span>
<span class="line-removed">4062       // initialize both the header and fields</span>
<span class="line-removed">4063       __ jmp(initialize_object);</span>
<span class="line-removed">4064     }</span>
<span class="line-removed">4065   } else {</span>
<span class="line-removed">4066     // Allocation in the shared Eden, if allowed.</span>
<span class="line-removed">4067     //</span>
<span class="line-removed">4068     // rdx: instance size in bytes</span>
<span class="line-removed">4069     __ eden_allocate(thread, rax, rdx, 0, rbx, slow_case);</span>
<span class="line-removed">4070   }</span>
4071 
<span class="line-modified">4072   // If UseTLAB or allow_shared_alloc are true, the object is created above and</span>
<span class="line-modified">4073   // there is an initialize need. Otherwise, skip and go to the slow path.</span>
<span class="line-modified">4074   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-removed">4075     // The object is initialized before the header.  If the object size is</span>
<span class="line-removed">4076     // zero, go directly to the header initialization.</span>
<span class="line-removed">4077     __ bind(initialize_object);</span>
<span class="line-removed">4078     __ decrement(rdx, sizeof(oopDesc));</span>
<span class="line-removed">4079     __ jcc(Assembler::zero, initialize_header);</span>
<span class="line-removed">4080 </span>
<span class="line-removed">4081     // Initialize topmost object field, divide rdx by 8, check if odd and</span>
<span class="line-removed">4082     // test if zero.</span>
<span class="line-removed">4083     __ xorl(rcx, rcx);    // use zero reg to clear memory (shorter code)</span>
<span class="line-removed">4084     __ shrl(rdx, LogBytesPerLong); // divide by 2*oopSize and set carry flag if odd</span>
<span class="line-removed">4085 </span>
<span class="line-removed">4086     // rdx must have been multiple of 8</span>
<span class="line-removed">4087 #ifdef ASSERT</span>
<span class="line-removed">4088     // make sure rdx was multiple of 8</span>
<span class="line-removed">4089     Label L;</span>
<span class="line-removed">4090     // Ignore partial flag stall after shrl() since it is debug VM</span>
<span class="line-removed">4091     __ jcc(Assembler::carryClear, L);</span>
<span class="line-removed">4092     __ stop(&quot;object size is not multiple of 2 - adjust this code&quot;);</span>
<span class="line-removed">4093     __ bind(L);</span>
<span class="line-removed">4094     // rdx must be &gt; 0, no extra check needed here</span>
<span class="line-removed">4095 #endif</span>
4096 
<span class="line-modified">4097     // initialize remaining object fields: rdx was a multiple of 8</span>
<span class="line-modified">4098     { Label loop;</span>
<span class="line-removed">4099     __ bind(loop);</span>
<span class="line-removed">4100     __ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 1*oopSize), rcx);</span>
<span class="line-removed">4101     NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 2*oopSize), rcx));</span>
<span class="line-removed">4102     __ decrement(rdx);</span>
<span class="line-removed">4103     __ jcc(Assembler::notZero, loop);</span>
<span class="line-removed">4104     }</span>
4105 
<span class="line-modified">4106     // initialize object header only.</span>
<span class="line-modified">4107     __ bind(initialize_header);</span>
<span class="line-modified">4108     if (UseBiasedLocking) {</span>
<span class="line-removed">4109       __ pop(rcx);   // get saved klass back in the register.</span>
<span class="line-removed">4110       __ movptr(rbx, Address(rcx, Klass::prototype_header_offset()));</span>
<span class="line-removed">4111       __ movptr(Address(rax, oopDesc::mark_offset_in_bytes ()), rbx);</span>
<span class="line-removed">4112     } else {</span>
<span class="line-removed">4113       __ movptr(Address(rax, oopDesc::mark_offset_in_bytes ()),</span>
<span class="line-removed">4114                 (intptr_t)markWord::prototype().value()); // header</span>
<span class="line-removed">4115       __ pop(rcx);   // get saved klass back in the register.</span>
<span class="line-removed">4116     }</span>
<span class="line-removed">4117 #ifdef _LP64</span>
<span class="line-removed">4118     __ xorl(rsi, rsi); // use zero reg to clear memory (shorter code)</span>
<span class="line-removed">4119     __ store_klass_gap(rax, rsi);  // zero klass gap for compressed oops</span>
<span class="line-removed">4120 #endif</span>
<span class="line-removed">4121     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-removed">4122     __ store_klass(rax, rcx, tmp_store_klass);  // klass</span>
4123 
<span class="line-modified">4124     {</span>
<span class="line-modified">4125       SkipIfEqual skip_if(_masm, &amp;DTraceAllocProbes, 0);</span>
<span class="line-removed">4126       // Trigger dtrace event for fastpath</span>
<span class="line-removed">4127       __ push(atos);</span>
<span class="line-removed">4128       __ call_VM_leaf(</span>
<span class="line-removed">4129            CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), rax);</span>
<span class="line-removed">4130       __ pop(atos);</span>
<span class="line-removed">4131     }</span>
4132 
<span class="line-modified">4133     __ jmp(done);</span>
<span class="line-modified">4134   }</span>























4135 
<span class="line-modified">4136   // slow case</span>
<span class="line-removed">4137   __ bind(slow_case);</span>
<span class="line-removed">4138   __ pop(rcx);   // restore stack pointer to what it was when we came in.</span>
<span class="line-removed">4139   __ bind(slow_case_no_pop);</span>
4140 
4141   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rax);
4142   Register rarg2 = LP64_ONLY(c_rarg2) NOT_LP64(rdx);
4143 
<span class="line-modified">4144   __ get_constant_pool(rarg1);</span>
<span class="line-modified">4145   __ get_unsigned_2_byte_index_at_bcp(rarg2, 1);</span>
<span class="line-modified">4146   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), rarg1, rarg2);</span>

4147    __ verify_oop(rax);
4148 
<span class="line-modified">4149   // continue</span>
4150   __ bind(done);
4151 }
4152 
4153 void TemplateTable::newarray() {
4154   transition(itos, atos);
4155   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4156   __ load_unsigned_byte(rarg1, at_bcp(1));
4157   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::newarray),
4158           rarg1, rax);
4159 }
4160 
4161 void TemplateTable::anewarray() {
4162   transition(itos, atos);
4163 
4164   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
4165   Register rarg2 = LP64_ONLY(c_rarg2) NOT_LP64(rdx);
4166 
4167   __ get_unsigned_2_byte_index_at_bcp(rarg2, 1);
4168   __ get_constant_pool(rarg1);
4169   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::anewarray),
4170           rarg1, rarg2, rax);
4171 }
4172 
4173 void TemplateTable::arraylength() {
4174   transition(atos, itos);
4175   __ null_check(rax, arrayOopDesc::length_offset_in_bytes());
4176   __ movl(rax, Address(rax, arrayOopDesc::length_offset_in_bytes()));
4177 }
4178 
4179 void TemplateTable::checkcast() {
4180   transition(atos, atos);
4181   Label done, is_null, ok_is_subtype, quicked, resolved;
4182   __ testptr(rax, rax); // object is in rax
4183   __ jcc(Assembler::zero, is_null);
4184 
4185   // Get cpool &amp; tags index
4186   __ get_cpool_and_tags(rcx, rdx); // rcx=cpool, rdx=tags array
4187   __ get_unsigned_2_byte_index_at_bcp(rbx, 1); // rbx=index
4188   // See if bytecode has already been quicked
<span class="line-modified">4189   __ cmpb(Address(rdx, rbx,</span>
<span class="line-modified">4190                   Address::times_1,</span>
<span class="line-modified">4191                   Array&lt;u1&gt;::base_offset_in_bytes()),</span>
<span class="line-modified">4192           JVM_CONSTANT_Class);</span>

4193   __ jcc(Assembler::equal, quicked);
4194   __ push(atos); // save receiver for result, and for GC
4195   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
4196 
4197   // vm_result_2 has metadata result
4198 #ifndef _LP64
4199   // borrow rdi from locals
4200   __ get_thread(rdi);
4201   __ get_vm_result_2(rax, rdi);
4202   __ restore_locals();
4203 #else
4204   __ get_vm_result_2(rax, r15_thread);
4205 #endif
4206 
4207   __ pop_ptr(rdx); // restore receiver
4208   __ jmpb(resolved);
4209 
4210   // Get superklass in rax and subklass in rbx
4211   __ bind(quicked);
4212   __ mov(rdx, rax); // Save object in rdx; rax needed for subtype check
4213   __ load_resolved_klass_at_index(rax, rcx, rbx);
4214 
4215   __ bind(resolved);
4216   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
4217   __ load_klass(rbx, rdx, tmp_load_klass);
4218 
4219   // Generate subtype check.  Blows rcx, rdi.  Object in rdx.
4220   // Superklass in rax.  Subklass in rbx.
4221   __ gen_subtype_check(rbx, ok_is_subtype);
4222 
4223   // Come here on failure
4224   __ push_ptr(rdx);
4225   // object is at TOS
4226   __ jump(ExternalAddress(Interpreter::_throw_ClassCastException_entry));
4227 
4228   // Come here on success
4229   __ bind(ok_is_subtype);
4230   __ mov(rax, rdx); // Restore object in rdx



4231 
4232   // Collect counts on whether this check-cast sees NULLs a lot or not.
4233   if (ProfileInterpreter) {
<span class="line-modified">4234     __ jmp(done);</span>
<span class="line-modified">4235     __ bind(is_null);</span>
<span class="line-modified">4236     __ profile_null_seen(rcx);</span>
<span class="line-modified">4237   } else {</span>











4238     __ bind(is_null);   // same as &#39;done&#39;
4239   }
4240   __ bind(done);
4241 }
4242 
4243 void TemplateTable::instanceof() {
4244   transition(atos, itos);
4245   Label done, is_null, ok_is_subtype, quicked, resolved;
4246   __ testptr(rax, rax);
4247   __ jcc(Assembler::zero, is_null);
4248 
4249   // Get cpool &amp; tags index
4250   __ get_cpool_and_tags(rcx, rdx); // rcx=cpool, rdx=tags array
4251   __ get_unsigned_2_byte_index_at_bcp(rbx, 1); // rbx=index
4252   // See if bytecode has already been quicked
<span class="line-modified">4253   __ cmpb(Address(rdx, rbx,</span>
<span class="line-modified">4254                   Address::times_1,</span>
<span class="line-modified">4255                   Array&lt;u1&gt;::base_offset_in_bytes()),</span>
<span class="line-modified">4256           JVM_CONSTANT_Class);</span>

4257   __ jcc(Assembler::equal, quicked);
4258 
4259   __ push(atos); // save receiver for result, and for GC
4260   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
4261   // vm_result_2 has metadata result
4262 
4263 #ifndef _LP64
4264   // borrow rdi from locals
4265   __ get_thread(rdi);
4266   __ get_vm_result_2(rax, rdi);
4267   __ restore_locals();
4268 #else
4269   __ get_vm_result_2(rax, r15_thread);
4270 #endif
4271 
4272   __ pop_ptr(rdx); // restore receiver
4273   __ verify_oop(rdx);
4274   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
4275   __ load_klass(rdx, rdx, tmp_load_klass);
4276   __ jmpb(resolved);
</pre>
<hr />
<pre>
4289   // Come here on failure
4290   __ xorl(rax, rax);
4291   __ jmpb(done);
4292   // Come here on success
4293   __ bind(ok_is_subtype);
4294   __ movl(rax, 1);
4295 
4296   // Collect counts on whether this test sees NULLs a lot or not.
4297   if (ProfileInterpreter) {
4298     __ jmp(done);
4299     __ bind(is_null);
4300     __ profile_null_seen(rcx);
4301   } else {
4302     __ bind(is_null);   // same as &#39;done&#39;
4303   }
4304   __ bind(done);
4305   // rax = 0: obj == NULL or  obj is not an instanceof the specified klass
4306   // rax = 1: obj != NULL and obj is     an instanceof the specified klass
4307 }
4308 
<span class="line-removed">4309 </span>
4310 //----------------------------------------------------------------------------------------------------
4311 // Breakpoints
4312 void TemplateTable::_breakpoint() {
4313   // Note: We get here even if we are single stepping..
4314   // jbug insists on setting breakpoints at every bytecode
4315   // even if we are in single step mode.
4316 
4317   transition(vtos, vtos);
4318 
4319   Register rarg = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
4320 
4321   // get the unpatched byte code
4322   __ get_method(rarg);
4323   __ call_VM(noreg,
4324              CAST_FROM_FN_PTR(address,
4325                               InterpreterRuntime::get_original_bytecode_at),
4326              rarg, rbcp);
4327   __ mov(rbx, rax);  // why?
4328 
4329   // post the breakpoint event
</pre>
<hr />
<pre>
4353 //
4354 // Stack layout:
4355 //
4356 // [expressions  ] &lt;--- rsp               = expression stack top
4357 // ..
4358 // [expressions  ]
4359 // [monitor entry] &lt;--- monitor block top = expression stack bot
4360 // ..
4361 // [monitor entry]
4362 // [frame data   ] &lt;--- monitor block bot
4363 // ...
4364 // [saved rbp    ] &lt;--- rbp
4365 void TemplateTable::monitorenter() {
4366   transition(atos, vtos);
4367 
4368   // check for NULL object
4369   __ null_check(rax);
4370 
4371   __ resolve(IS_NOT_NULL, rax);
4372 











4373   const Address monitor_block_top(
4374         rbp, frame::interpreter_frame_monitor_block_top_offset * wordSize);
4375   const Address monitor_block_bot(
4376         rbp, frame::interpreter_frame_initial_sp_offset * wordSize);
4377   const int entry_size = frame::interpreter_frame_monitor_size() * wordSize;
4378 
4379   Label allocated;
4380 
4381   Register rtop = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
4382   Register rbot = LP64_ONLY(c_rarg2) NOT_LP64(rbx);
4383   Register rmon = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4384 
4385   // initialize entry pointer
4386   __ xorl(rmon, rmon); // points to free slot or NULL
4387 
4388   // find a free slot in the monitor block (result in rmon)
4389   {
4390     Label entry, loop, exit;
4391     __ movptr(rtop, monitor_block_top); // points to current entry,
4392                                         // starting with top-most entry
</pre>
<hr />
<pre>
4452   __ movptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), rax);
4453   __ lock_object(rmon);
4454 
4455   // check to make sure this monitor doesn&#39;t cause stack overflow after locking
4456   __ save_bcp();  // in case of exception
4457   __ generate_stack_overflow_check(0);
4458 
4459   // The bcp has already been incremented. Just need to dispatch to
4460   // next instruction.
4461   __ dispatch_next(vtos);
4462 }
4463 
4464 void TemplateTable::monitorexit() {
4465   transition(atos, vtos);
4466 
4467   // check for NULL object
4468   __ null_check(rax);
4469 
4470   __ resolve(IS_NOT_NULL, rax);
4471 











4472   const Address monitor_block_top(
4473         rbp, frame::interpreter_frame_monitor_block_top_offset * wordSize);
4474   const Address monitor_block_bot(
4475         rbp, frame::interpreter_frame_initial_sp_offset * wordSize);
4476   const int entry_size = frame::interpreter_frame_monitor_size() * wordSize;
4477 
4478   Register rtop = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4479   Register rbot = LP64_ONLY(c_rarg2) NOT_LP64(rbx);
4480 
4481   Label found;
4482 
4483   // find matching slot
4484   {
4485     Label entry, loop;
4486     __ movptr(rtop, monitor_block_top); // points to current entry,
4487                                         // starting with top-most entry
4488     __ lea(rbot, monitor_block_bot);    // points to word before bottom
4489                                         // of monitor block
4490     __ jmpb(entry);
4491 
</pre>
</td>
<td>
<hr />
<pre>
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;compiler/disassembler.hpp&quot;
  28 #include &quot;interpreter/interpreter.hpp&quot;
  29 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  30 #include &quot;interpreter/interp_masm.hpp&quot;
  31 #include &quot;interpreter/templateTable.hpp&quot;
  32 #include &quot;memory/universe.hpp&quot;
  33 #include &quot;oops/methodData.hpp&quot;
  34 #include &quot;oops/objArrayKlass.hpp&quot;
  35 #include &quot;oops/oop.inline.hpp&quot;
<span class="line-added">  36 #include &quot;oops/valueKlass.hpp&quot;</span>
  37 #include &quot;prims/methodHandles.hpp&quot;
  38 #include &quot;runtime/frame.inline.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/stubRoutines.hpp&quot;
  42 #include &quot;runtime/synchronizer.hpp&quot;
  43 #include &quot;utilities/macros.hpp&quot;
  44 
  45 #define __ Disassembler::hook&lt;InterpreterMacroAssembler&gt;(__FILE__, __LINE__, _masm)-&gt;
  46 
  47 // Global Register Names
  48 static const Register rbcp     = LP64_ONLY(r13) NOT_LP64(rsi);
  49 static const Register rlocals  = LP64_ONLY(r14) NOT_LP64(rdi);
  50 
  51 // Platform-dependent initialization
  52 void TemplateTable::pd_initialize() {
  53   // No x86 specific initialization
  54 }
  55 
  56 // Address Computation: local variables
</pre>
<hr />
<pre>
 138   case TemplateTable::less_equal   : return Assembler::greater;
 139   case TemplateTable::greater      : return Assembler::lessEqual;
 140   case TemplateTable::greater_equal: return Assembler::less;
 141   }
 142   ShouldNotReachHere();
 143   return Assembler::zero;
 144 }
 145 
 146 
 147 
 148 // Miscelaneous helper routines
 149 // Store an oop (or NULL) at the address described by obj.
 150 // If val == noreg this means store a NULL
 151 
 152 
 153 static void do_oop_store(InterpreterMacroAssembler* _masm,
 154                          Address dst,
 155                          Register val,
 156                          DecoratorSet decorators = 0) {
 157   assert(val == noreg || val == rax, &quot;parameter is just for looks&quot;);
<span class="line-modified"> 158   __ store_heap_oop(dst, val, rdx, rbx, noreg, decorators);</span>
 159 }
 160 
 161 static void do_oop_load(InterpreterMacroAssembler* _masm,
 162                         Address src,
 163                         Register dst,
 164                         DecoratorSet decorators = 0) {
 165   __ load_heap_oop(dst, src, rdx, rbx, decorators);
 166 }
 167 
 168 Address TemplateTable::at_bcp(int offset) {
 169   assert(_desc-&gt;uses_bcp(), &quot;inconsistent uses_bcp information&quot;);
 170   return Address(rbcp, offset);
 171 }
 172 
 173 
 174 void TemplateTable::patch_bytecode(Bytecodes::Code bc, Register bc_reg,
 175                                    Register temp_reg, bool load_bc_into_bc_reg/*=true*/,
 176                                    int byte_no) {
 177   if (!RewriteBytecodes)  return;
 178   Label L_patch_done;
 179 
 180   switch (bc) {
<span class="line-added"> 181   case Bytecodes::_fast_qputfield:</span>
 182   case Bytecodes::_fast_aputfield:
 183   case Bytecodes::_fast_bputfield:
 184   case Bytecodes::_fast_zputfield:
 185   case Bytecodes::_fast_cputfield:
 186   case Bytecodes::_fast_dputfield:
 187   case Bytecodes::_fast_fputfield:
 188   case Bytecodes::_fast_iputfield:
 189   case Bytecodes::_fast_lputfield:
 190   case Bytecodes::_fast_sputfield:
 191     {
 192       // We skip bytecode quickening for putfield instructions when
 193       // the put_code written to the constant pool cache is zero.
 194       // This is required so that every execution of this instruction
 195       // calls out to InterpreterRuntime::resolve_get_put to do
 196       // additional, required work.
 197       assert(byte_no == f1_byte || byte_no == f2_byte, &quot;byte_no out of range&quot;);
 198       assert(load_bc_into_bc_reg, &quot;we use bc_reg as temp&quot;);
 199       __ get_cache_and_index_and_bytecode_at_bcp(temp_reg, bc_reg, temp_reg, byte_no, 1);
 200       __ movl(bc_reg, bc);
 201       __ cmpl(temp_reg, (int) 0);
</pre>
<hr />
<pre>
 354   __ sarl(rax, 16);
 355 }
 356 
 357 void TemplateTable::ldc(bool wide) {
 358   transition(vtos, vtos);
 359   Register rarg = NOT_LP64(rcx) LP64_ONLY(c_rarg1);
 360   Label call_ldc, notFloat, notClass, notInt, Done;
 361 
 362   if (wide) {
 363     __ get_unsigned_2_byte_index_at_bcp(rbx, 1);
 364   } else {
 365     __ load_unsigned_byte(rbx, at_bcp(1));
 366   }
 367 
 368   __ get_cpool_and_tags(rcx, rax);
 369   const int base_offset = ConstantPool::header_size() * wordSize;
 370   const int tags_offset = Array&lt;u1&gt;::base_offset_in_bytes();
 371 
 372   // get type
 373   __ movzbl(rdx, Address(rax, rbx, Address::times_1, tags_offset));
<span class="line-added"> 374   __ andl(rdx, ~JVM_CONSTANT_QDescBit);</span>
 375 
 376   // unresolved class - get the resolved class
 377   __ cmpl(rdx, JVM_CONSTANT_UnresolvedClass);
 378   __ jccb(Assembler::equal, call_ldc);
 379 
 380   // unresolved class in error state - call into runtime to throw the error
 381   // from the first resolution attempt
 382   __ cmpl(rdx, JVM_CONSTANT_UnresolvedClassInError);
 383   __ jccb(Assembler::equal, call_ldc);
 384 
 385   // resolved class - need to call vm to get java mirror of the class
 386   __ cmpl(rdx, JVM_CONSTANT_Class);
 387   __ jcc(Assembler::notEqual, notClass);
 388 
 389   __ bind(call_ldc);
 390 
 391   __ movl(rarg, wide);
 392   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::ldc), rarg);
 393 
 394   __ push(atos);
</pre>
<hr />
<pre>
 805                     Address(rdx, rax,
 806                             Address::times_4,
 807                             arrayOopDesc::base_offset_in_bytes(T_FLOAT)),
 808                     noreg, noreg);
 809 }
 810 
 811 void TemplateTable::daload() {
 812   transition(itos, dtos);
 813   // rax: index
 814   // rdx: array
 815   index_check(rdx, rax); // kills rbx
 816   __ access_load_at(T_DOUBLE, IN_HEAP | IS_ARRAY, noreg /* dtos */,
 817                     Address(rdx, rax,
 818                             Address::times_8,
 819                             arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),
 820                     noreg, noreg);
 821 }
 822 
 823 void TemplateTable::aaload() {
 824   transition(itos, atos);
<span class="line-modified"> 825   Register array = rdx;</span>
<span class="line-modified"> 826   Register index = rax;</span>
<span class="line-modified"> 827 </span>
<span class="line-modified"> 828   index_check(array, index); // kills rbx</span>
<span class="line-modified"> 829   __ profile_array(rbx, array, rcx);</span>
<span class="line-modified"> 830   if (ValueArrayFlatten) {</span>
<span class="line-modified"> 831     Label is_flat_array, done;</span>
<span class="line-modified"> 832     __ test_flattened_array_oop(array, rbx, is_flat_array);</span>
<span class="line-modified"> 833     do_oop_load(_masm,</span>
<span class="line-added"> 834                 Address(array, index,</span>
<span class="line-added"> 835                         UseCompressedOops ? Address::times_4 : Address::times_ptr,</span>
<span class="line-added"> 836                         arrayOopDesc::base_offset_in_bytes(T_OBJECT)),</span>
<span class="line-added"> 837                 rax,</span>
<span class="line-added"> 838                 IS_ARRAY);</span>
<span class="line-added"> 839     __ jmp(done);</span>
<span class="line-added"> 840     __ bind(is_flat_array);</span>
<span class="line-added"> 841     __ read_flattened_element(array, index, rbx, rcx, rax);</span>
<span class="line-added"> 842     __ bind(done);</span>
<span class="line-added"> 843   } else {</span>
<span class="line-added"> 844     do_oop_load(_masm,</span>
<span class="line-added"> 845                 Address(array, index,</span>
<span class="line-added"> 846                         UseCompressedOops ? Address::times_4 : Address::times_ptr,</span>
<span class="line-added"> 847                         arrayOopDesc::base_offset_in_bytes(T_OBJECT)),</span>
<span class="line-added"> 848                 rax,</span>
<span class="line-added"> 849                 IS_ARRAY);</span>
<span class="line-added"> 850   }</span>
<span class="line-added"> 851   __ profile_element(rbx, rax, rcx);</span>
 852 }
 853 
 854 void TemplateTable::baload() {
 855   transition(itos, itos);
 856   // rax: index
 857   // rdx: array
 858   index_check(rdx, rax); // kills rbx
 859   __ access_load_at(T_BYTE, IN_HEAP | IS_ARRAY, rax,
 860                     Address(rdx, rax, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_BYTE)),
 861                     noreg, noreg);
 862 }
 863 
 864 void TemplateTable::caload() {
 865   transition(itos, itos);
 866   // rax: index
 867   // rdx: array
 868   index_check(rdx, rax); // kills rbx
 869   __ access_load_at(T_CHAR, IN_HEAP | IS_ARRAY, rax,
 870                     Address(rdx, rax, Address::times_2, arrayOopDesc::base_offset_in_bytes(T_CHAR)),
 871                     noreg, noreg);
</pre>
<hr />
<pre>
1117   __ access_store_at(T_FLOAT, IN_HEAP | IS_ARRAY,
1118                      Address(rdx, rbx, Address::times_4,
1119                              arrayOopDesc::base_offset_in_bytes(T_FLOAT)),
1120                      noreg /* ftos */, noreg, noreg);
1121 }
1122 
1123 void TemplateTable::dastore() {
1124   transition(dtos, vtos);
1125   __ pop_i(rbx);
1126   // value is in UseSSE &gt;= 2 ? xmm0 : ST(0)
1127   // rbx:  index
1128   // rdx:  array
1129   index_check(rdx, rbx); // prefer index in rbx
1130   __ access_store_at(T_DOUBLE, IN_HEAP | IS_ARRAY,
1131                      Address(rdx, rbx, Address::times_8,
1132                              arrayOopDesc::base_offset_in_bytes(T_DOUBLE)),
1133                      noreg /* dtos */, noreg, noreg);
1134 }
1135 
1136 void TemplateTable::aastore() {
<span class="line-modified">1137   Label is_null, is_flat_array, ok_is_subtype, done;</span>
1138   transition(vtos, vtos);
1139   // stack: ..., array, index, value
1140   __ movptr(rax, at_tos());    // value
1141   __ movl(rcx, at_tos_p1()); // index
1142   __ movptr(rdx, at_tos_p2()); // array
1143 
1144   Address element_address(rdx, rcx,
1145                           UseCompressedOops? Address::times_4 : Address::times_ptr,
1146                           arrayOopDesc::base_offset_in_bytes(T_OBJECT));
1147 
1148   index_check_without_pop(rdx, rcx);     // kills rbx
<span class="line-added">1149 </span>
<span class="line-added">1150   __ profile_array(rdi, rdx, rbx);</span>
<span class="line-added">1151   __ profile_element(rdi, rax, rbx);</span>
<span class="line-added">1152 </span>
1153   __ testptr(rax, rax);
1154   __ jcc(Assembler::zero, is_null);
1155 
<span class="line-added">1156   // Move array class to rdi</span>
1157   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
<span class="line-added">1158   __ load_klass(rdi, rdx, tmp_load_klass);</span>
<span class="line-added">1159   if (ValueArrayFlatten) {</span>
<span class="line-added">1160     __ movl(rbx, Address(rdi, Klass::layout_helper_offset()));</span>
<span class="line-added">1161     __ test_flattened_array_layout(rbx, is_flat_array);</span>
<span class="line-added">1162   }</span>
<span class="line-added">1163 </span>
1164   // Move subklass into rbx
1165   __ load_klass(rbx, rax, tmp_load_klass);
<span class="line-modified">1166   // Move array element superklass into rax</span>
<span class="line-modified">1167   __ movptr(rax, Address(rdi,</span>

1168                          ObjArrayKlass::element_klass_offset()));
1169 
1170   // Generate subtype check.  Blows rcx, rdi
1171   // Superklass in rax.  Subklass in rbx.
<span class="line-modified">1172   // is &quot;rbx &lt;: rax&quot; ? (value subclass &lt;: array element superclass)</span>
<span class="line-added">1173   __ gen_subtype_check(rbx, ok_is_subtype, false);</span>
1174 
1175   // Come here on failure
1176   // object is at TOS
1177   __ jump(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));
1178 
1179   // Come here on success
1180   __ bind(ok_is_subtype);
1181 
1182   // Get the value we will store
1183   __ movptr(rax, at_tos());
1184   __ movl(rcx, at_tos_p1()); // index
1185   // Now store using the appropriate barrier
1186   do_oop_store(_masm, element_address, rax, IS_ARRAY);
1187   __ jmp(done);
1188 
1189   // Have a NULL in rax, rdx=array, ecx=index.  Store NULL at ary[idx]
1190   __ bind(is_null);
<span class="line-modified">1191   if (EnableValhalla) {</span>
<span class="line-added">1192     Label is_null_into_value_array_npe, store_null;</span>
1193 
<span class="line-added">1194     // No way to store null in null-free array</span>
<span class="line-added">1195     __ test_null_free_array_oop(rdx, rbx, is_null_into_value_array_npe);</span>
<span class="line-added">1196     __ jmp(store_null);</span>
<span class="line-added">1197 </span>
<span class="line-added">1198     __ bind(is_null_into_value_array_npe);</span>
<span class="line-added">1199     __ jump(ExternalAddress(Interpreter::_throw_NullPointerException_entry));</span>
<span class="line-added">1200 </span>
<span class="line-added">1201     __ bind(store_null);</span>
<span class="line-added">1202   }</span>
1203   // Store a NULL
1204   do_oop_store(_masm, element_address, noreg, IS_ARRAY);
<span class="line-added">1205   __ jmp(done);</span>
<span class="line-added">1206 </span>
<span class="line-added">1207   if (EnableValhalla) {</span>
<span class="line-added">1208     Label is_type_ok;</span>
<span class="line-added">1209     __ bind(is_flat_array); // Store non-null value to flat</span>
<span class="line-added">1210 </span>
<span class="line-added">1211     // Simplistic type check...</span>
1212 
<span class="line-added">1213     // Profile the not-null value&#39;s klass.</span>
<span class="line-added">1214     __ load_klass(rbx, rax, tmp_load_klass);</span>
<span class="line-added">1215     // Move element klass into rax</span>
<span class="line-added">1216     __ movptr(rax, Address(rdi, ArrayKlass::element_klass_offset()));</span>
<span class="line-added">1217     // flat value array needs exact type match</span>
<span class="line-added">1218     // is &quot;rax == rbx&quot; (value subclass == array element superclass)</span>
<span class="line-added">1219     __ cmpptr(rax, rbx);</span>
<span class="line-added">1220     __ jccb(Assembler::equal, is_type_ok);</span>
<span class="line-added">1221 </span>
<span class="line-added">1222     __ jump(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));</span>
<span class="line-added">1223 </span>
<span class="line-added">1224     __ bind(is_type_ok);</span>
<span class="line-added">1225     // rbx: value&#39;s klass</span>
<span class="line-added">1226     // rdx: array</span>
<span class="line-added">1227     // rdi: array klass</span>
<span class="line-added">1228     __ test_klass_is_empty_value(rbx, rax, done);</span>
<span class="line-added">1229 </span>
<span class="line-added">1230     // calc dst for copy</span>
<span class="line-added">1231     __ movl(rax, at_tos_p1()); // index</span>
<span class="line-added">1232     __ data_for_value_array_index(rdx, rdi, rax, rax);</span>
<span class="line-added">1233 </span>
<span class="line-added">1234     // ...and src for copy</span>
<span class="line-added">1235     __ movptr(rcx, at_tos());  // value</span>
<span class="line-added">1236     __ data_for_oop(rcx, rcx, rbx);</span>
<span class="line-added">1237 </span>
<span class="line-added">1238     __ access_value_copy(IN_HEAP, rcx, rax, rbx);</span>
<span class="line-added">1239   }</span>
1240   // Pop stack arguments
1241   __ bind(done);
1242   __ addptr(rsp, 3 * Interpreter::stackElementSize);
1243 }
1244 
1245 void TemplateTable::bastore() {
1246   transition(itos, vtos);
1247   __ pop_i(rbx);
1248   // rax: value
1249   // rbx: index
1250   // rdx: array
1251   index_check(rdx, rbx); // prefer index in rbx
1252   // Need to check whether array is boolean or byte
1253   // since both types share the bastore bytecode.
1254   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1255   __ load_klass(rcx, rdx, tmp_load_klass);
1256   __ movl(rcx, Address(rcx, Klass::layout_helper_offset()));
1257   int diffbit = Klass::layout_helper_boolean_diffbit();
1258   __ testl(rcx, diffbit);
1259   Label L_skip;
</pre>
<hr />
<pre>
2466   __ jcc(j_not(cc), not_taken);
2467   branch(false, false);
2468   __ bind(not_taken);
2469   __ profile_not_taken_branch(rax);
2470 }
2471 
2472 void TemplateTable::if_nullcmp(Condition cc) {
2473   transition(atos, vtos);
2474   // assume branch is more often taken than not (loops use backward branches)
2475   Label not_taken;
2476   __ testptr(rax, rax);
2477   __ jcc(j_not(cc), not_taken);
2478   branch(false, false);
2479   __ bind(not_taken);
2480   __ profile_not_taken_branch(rax);
2481 }
2482 
2483 void TemplateTable::if_acmp(Condition cc) {
2484   transition(atos, vtos);
2485   // assume branch is more often taken than not (loops use backward branches)
<span class="line-modified">2486   Label taken, not_taken;</span>
2487   __ pop_ptr(rdx);
<span class="line-added">2488 </span>
<span class="line-added">2489   const int is_value_mask = markWord::always_locked_pattern;</span>
<span class="line-added">2490   if (EnableValhalla) {</span>
<span class="line-added">2491     __ cmpoop(rdx, rax);</span>
<span class="line-added">2492     __ jcc(Assembler::equal, (cc == equal) ? taken : not_taken);</span>
<span class="line-added">2493 </span>
<span class="line-added">2494     // might be substitutable, test if either rax or rdx is null</span>
<span class="line-added">2495     __ movptr(rbx, rdx);</span>
<span class="line-added">2496     __ andptr(rbx, rax);</span>
<span class="line-added">2497     __ testptr(rbx, rbx);</span>
<span class="line-added">2498     __ jcc(Assembler::zero, (cc == equal) ? not_taken : taken);</span>
<span class="line-added">2499 </span>
<span class="line-added">2500     // and both are values ?</span>
<span class="line-added">2501     __ movptr(rbx, Address(rdx, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">2502     __ andptr(rbx, is_value_mask);</span>
<span class="line-added">2503     __ movptr(rcx, Address(rax, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">2504     __ andptr(rbx, is_value_mask);</span>
<span class="line-added">2505     __ andptr(rbx, rcx);</span>
<span class="line-added">2506     __ cmpl(rbx, is_value_mask);</span>
<span class="line-added">2507     __ jcc(Assembler::notEqual, (cc == equal) ? not_taken : taken);</span>
<span class="line-added">2508 </span>
<span class="line-added">2509     // same value klass ?</span>
<span class="line-added">2510     __ load_metadata(rbx, rdx);</span>
<span class="line-added">2511     __ load_metadata(rcx, rax);</span>
<span class="line-added">2512     __ cmpptr(rbx, rcx);</span>
<span class="line-added">2513     __ jcc(Assembler::notEqual, (cc == equal) ? not_taken : taken);</span>
<span class="line-added">2514 </span>
<span class="line-added">2515     // Know both are the same type, let&#39;s test for substitutability...</span>
<span class="line-added">2516     if (cc == equal) {</span>
<span class="line-added">2517       invoke_is_substitutable(rax, rdx, taken, not_taken);</span>
<span class="line-added">2518     } else {</span>
<span class="line-added">2519       invoke_is_substitutable(rax, rdx, not_taken, taken);</span>
<span class="line-added">2520     }</span>
<span class="line-added">2521     __ stop(&quot;Not reachable&quot;);</span>
<span class="line-added">2522   }</span>
<span class="line-added">2523 </span>
2524   __ cmpoop(rdx, rax);
2525   __ jcc(j_not(cc), not_taken);
<span class="line-added">2526   __ bind(taken);</span>
2527   branch(false, false);
2528   __ bind(not_taken);
2529   __ profile_not_taken_branch(rax);
2530 }
2531 
<span class="line-added">2532 void TemplateTable::invoke_is_substitutable(Register aobj, Register bobj,</span>
<span class="line-added">2533                                             Label&amp; is_subst, Label&amp; not_subst) {</span>
<span class="line-added">2534   __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::is_substitutable), aobj, bobj);</span>
<span class="line-added">2535   // Restored...rax answer, jmp to outcome...</span>
<span class="line-added">2536   __ testl(rax, rax);</span>
<span class="line-added">2537   __ jcc(Assembler::zero, not_subst);</span>
<span class="line-added">2538   __ jmp(is_subst);</span>
<span class="line-added">2539 }</span>
<span class="line-added">2540 </span>
2541 void TemplateTable::ret() {
2542   transition(vtos, vtos);
2543   locals_index(rbx);
2544   LP64_ONLY(__ movslq(rbx, iaddress(rbx))); // get return bci, compute return bcp
2545   NOT_LP64(__ movptr(rbx, iaddress(rbx)));
2546   __ profile_ret(rbx, rcx);
2547   __ get_method(rax);
2548   __ movptr(rbcp, Address(rax, Method::const_offset()));
2549   __ lea(rbcp, Address(rbcp, rbx, Address::times_1,
2550                       ConstMethod::codes_offset()));
2551   __ dispatch_next(vtos, 0, true);
2552 }
2553 
2554 void TemplateTable::wide_ret() {
2555   transition(vtos, vtos);
2556   locals_index_wide(rbx);
2557   __ movptr(rbx, aaddress(rbx)); // get return bci, compute return bcp
2558   __ profile_ret(rbx, rcx);
2559   __ get_method(rax);
2560   __ movptr(rbcp, Address(rax, Method::const_offset()));
</pre>
<hr />
<pre>
2787     __ testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
2788 #else
2789     const Register thread = rdi;
2790     __ get_thread(thread);
2791     __ testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
2792 #endif
2793     __ jcc(Assembler::zero, no_safepoint);
2794     __ push(state);
2795     __ call_VM(noreg, CAST_FROM_FN_PTR(address,
2796                                     InterpreterRuntime::at_safepoint));
2797     __ pop(state);
2798     __ bind(no_safepoint);
2799   }
2800 
2801   // Narrow result if state is itos but result type is smaller.
2802   // Need to narrow in the return bytecode rather than in generate_return_entry
2803   // since compiled code callers expect the result to already be narrowed.
2804   if (state == itos) {
2805     __ narrow(rax);
2806   }
<span class="line-modified">2807 </span>
<span class="line-added">2808   __ remove_activation(state, rbcp, true, true, true);</span>
2809 
2810   __ jmp(rbcp);
2811 }
2812 
2813 // ----------------------------------------------------------------------------
2814 // Volatile variables demand their effects be made known to all CPU&#39;s
2815 // in order.  Store buffers on most chips allow reads &amp; writes to
2816 // reorder; the JMM&#39;s ReadAfterWrite.java test fails in -Xint mode
2817 // without some kind of memory barrier (i.e., it&#39;s not sufficient that
2818 // the interpreter does not reorder volatile references, the hardware
2819 // also must not reorder them).
2820 //
2821 // According to the new Java Memory Model (JMM):
2822 // (1) All volatiles are serialized wrt to each other.  ALSO reads &amp;
2823 //     writes act as aquire &amp; release, so:
2824 // (2) A read cannot let unrelated NON-volatile memory refs that
2825 //     happen after the read float up to before the read.  It&#39;s OK for
2826 //     non-volatile memory refs that happen before the volatile read to
2827 //     float down below it.
2828 // (3) Similar a volatile write cannot let unrelated NON-volatile
</pre>
<hr />
<pre>
2986     __ get_cache_and_index_at_bcp(cache, index, 1);
2987     __ bind(L1);
2988   }
2989 }
2990 
2991 void TemplateTable::pop_and_check_object(Register r) {
2992   __ pop_ptr(r);
2993   __ null_check(r);  // for field access must check obj.
2994   __ verify_oop(r);
2995 }
2996 
2997 void TemplateTable::getfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
2998   transition(vtos, vtos);
2999 
3000   const Register cache = rcx;
3001   const Register index = rdx;
3002   const Register obj   = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
3003   const Register off   = rbx;
3004   const Register flags = rax;
3005   const Register bc    = LP64_ONLY(c_rarg3) NOT_LP64(rcx); // uses same reg as obj, so don&#39;t mix them
<span class="line-added">3006   const Register flags2 = rdx;</span>
3007 
3008   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
3009   jvmti_post_field_access(cache, index, is_static, false);
3010   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
3011 


3012   const Address field(obj, off, Address::times_1, 0*wordSize);
3013 
<span class="line-modified">3014   Label Done, notByte, notBool, notInt, notShort, notChar, notLong, notFloat, notObj, notValueType;</span>
<span class="line-added">3015 </span>
<span class="line-added">3016   if (!is_static) {</span>
<span class="line-added">3017     __ movptr(rcx, Address(cache, index, Address::times_ptr,</span>
<span class="line-added">3018                            in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3019                                     ConstantPoolCacheEntry::f1_offset())));</span>
<span class="line-added">3020   }</span>
<span class="line-added">3021 </span>
<span class="line-added">3022   __ movl(flags2, flags);</span>
3023 
3024   __ shrl(flags, ConstantPoolCacheEntry::tos_state_shift);
3025   // Make sure we don&#39;t need to mask edx after the above shift
3026   assert(btos == 0, &quot;change code, btos != 0&quot;);
3027 
3028   __ andl(flags, ConstantPoolCacheEntry::tos_state_mask);
3029 
3030   __ jcc(Assembler::notZero, notByte);
3031   // btos
<span class="line-added">3032   if (!is_static) pop_and_check_object(obj);</span>
3033   __ access_load_at(T_BYTE, IN_HEAP, rax, field, noreg, noreg);
3034   __ push(btos);
3035   // Rewrite bytecode to be faster
3036   if (!is_static &amp;&amp; rc == may_rewrite) {
3037     patch_bytecode(Bytecodes::_fast_bgetfield, bc, rbx);
3038   }
3039   __ jmp(Done);
3040 
3041   __ bind(notByte);
<span class="line-added">3042 </span>
3043   __ cmpl(flags, ztos);
3044   __ jcc(Assembler::notEqual, notBool);
<span class="line-modified">3045    if (!is_static) pop_and_check_object(obj);</span>
3046   // ztos (same code as btos)
3047   __ access_load_at(T_BOOLEAN, IN_HEAP, rax, field, noreg, noreg);
3048   __ push(ztos);
3049   // Rewrite bytecode to be faster
3050   if (!is_static &amp;&amp; rc == may_rewrite) {
3051     // use btos rewriting, no truncating to t/f bit is needed for getfield.
3052     patch_bytecode(Bytecodes::_fast_bgetfield, bc, rbx);
3053   }
3054   __ jmp(Done);
3055 
3056   __ bind(notBool);
3057   __ cmpl(flags, atos);
3058   __ jcc(Assembler::notEqual, notObj);
3059   // atos
<span class="line-modified">3060   if (!EnableValhalla) {</span>
<span class="line-modified">3061     if (!is_static) pop_and_check_object(obj);</span>
<span class="line-modified">3062     do_oop_load(_masm, field, rax);</span>
<span class="line-modified">3063     __ push(atos);</span>
<span class="line-added">3064     if (!is_static &amp;&amp; rc == may_rewrite) {</span>
<span class="line-added">3065       patch_bytecode(Bytecodes::_fast_agetfield, bc, rbx);</span>
<span class="line-added">3066     }</span>
<span class="line-added">3067     __ jmp(Done);</span>
<span class="line-added">3068   } else {</span>
<span class="line-added">3069     if (is_static) {</span>
<span class="line-added">3070       __ load_heap_oop(rax, field);</span>
<span class="line-added">3071       Label isFlattenable, uninitialized;</span>
<span class="line-added">3072       // Issue below if the static field has not been initialized yet</span>
<span class="line-added">3073       __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);</span>
<span class="line-added">3074         // Not flattenable case</span>
<span class="line-added">3075         __ push(atos);</span>
<span class="line-added">3076         __ jmp(Done);</span>
<span class="line-added">3077       // Flattenable case, must not return null even if uninitialized</span>
<span class="line-added">3078       __ bind(isFlattenable);</span>
<span class="line-added">3079         __ testptr(rax, rax);</span>
<span class="line-added">3080         __ jcc(Assembler::zero, uninitialized);</span>
<span class="line-added">3081           __ push(atos);</span>
<span class="line-added">3082           __ jmp(Done);</span>
<span class="line-added">3083         __ bind(uninitialized);</span>
<span class="line-added">3084           __ andl(flags2, ConstantPoolCacheEntry::field_index_mask);</span>
<span class="line-added">3085 #ifdef _LP64</span>
<span class="line-added">3086           Label slow_case, finish;</span>
<span class="line-added">3087           __ cmpb(Address(rcx, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="line-added">3088           __ jcc(Assembler::notEqual, slow_case);</span>
<span class="line-added">3089         __ get_default_value_oop(rcx, off, rax);</span>
<span class="line-added">3090         __ jmp(finish);</span>
<span class="line-added">3091         __ bind(slow_case);</span>
<span class="line-added">3092 #endif // LP64</span>
<span class="line-added">3093           __ call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_value_field),</span>
<span class="line-added">3094                  obj, flags2);</span>
<span class="line-added">3095 #ifdef _LP64</span>
<span class="line-added">3096           __ bind(finish);</span>
<span class="line-added">3097 #endif // _LP64</span>
<span class="line-added">3098           __ verify_oop(rax);</span>
<span class="line-added">3099           __ push(atos);</span>
<span class="line-added">3100           __ jmp(Done);</span>
<span class="line-added">3101     } else {</span>
<span class="line-added">3102       Label isFlattened, nonnull, isFlattenable, rewriteFlattenable;</span>
<span class="line-added">3103       __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);</span>
<span class="line-added">3104         // Non-flattenable field case, also covers the object case</span>
<span class="line-added">3105         pop_and_check_object(obj);</span>
<span class="line-added">3106         __ load_heap_oop(rax, field);</span>
<span class="line-added">3107         __ push(atos);</span>
<span class="line-added">3108         if (rc == may_rewrite) {</span>
<span class="line-added">3109           patch_bytecode(Bytecodes::_fast_agetfield, bc, rbx);</span>
<span class="line-added">3110         }</span>
<span class="line-added">3111         __ jmp(Done);</span>
<span class="line-added">3112       __ bind(isFlattenable);</span>
<span class="line-added">3113         __ test_field_is_flattened(flags2, rscratch1, isFlattened);</span>
<span class="line-added">3114           // Non-flattened field case</span>
<span class="line-added">3115           __ movptr(rax, rcx);  // small dance required to preserve the klass_holder somewhere</span>
<span class="line-added">3116           pop_and_check_object(obj);</span>
<span class="line-added">3117           __ push(rax);</span>
<span class="line-added">3118           __ load_heap_oop(rax, field);</span>
<span class="line-added">3119           __ pop(rcx);</span>
<span class="line-added">3120           __ testptr(rax, rax);</span>
<span class="line-added">3121           __ jcc(Assembler::notZero, nonnull);</span>
<span class="line-added">3122             __ andl(flags2, ConstantPoolCacheEntry::field_index_mask);</span>
<span class="line-added">3123             __ get_value_field_klass(rcx, flags2, rbx);</span>
<span class="line-added">3124             __ get_default_value_oop(rbx, rcx, rax);</span>
<span class="line-added">3125           __ bind(nonnull);</span>
<span class="line-added">3126           __ verify_oop(rax);</span>
<span class="line-added">3127           __ push(atos);</span>
<span class="line-added">3128           __ jmp(rewriteFlattenable);</span>
<span class="line-added">3129         __ bind(isFlattened);</span>
<span class="line-added">3130           __ andl(flags2, ConstantPoolCacheEntry::field_index_mask);</span>
<span class="line-added">3131           pop_and_check_object(rax);</span>
<span class="line-added">3132           __ read_flattened_field(rcx, flags2, rbx, rax);</span>
<span class="line-added">3133           __ verify_oop(rax);</span>
<span class="line-added">3134           __ push(atos);</span>
<span class="line-added">3135       __ bind(rewriteFlattenable);</span>
<span class="line-added">3136       if (rc == may_rewrite) {</span>
<span class="line-added">3137         patch_bytecode(Bytecodes::_fast_qgetfield, bc, rbx);</span>
<span class="line-added">3138       }</span>
<span class="line-added">3139       __ jmp(Done);</span>
<span class="line-added">3140     }</span>
3141   }

3142 
3143   __ bind(notObj);
<span class="line-added">3144 </span>
<span class="line-added">3145   if (!is_static) pop_and_check_object(obj);</span>
<span class="line-added">3146 </span>
3147   __ cmpl(flags, itos);
3148   __ jcc(Assembler::notEqual, notInt);
3149   // itos
3150   __ access_load_at(T_INT, IN_HEAP, rax, field, noreg, noreg);
3151   __ push(itos);
3152   // Rewrite bytecode to be faster
3153   if (!is_static &amp;&amp; rc == may_rewrite) {
3154     patch_bytecode(Bytecodes::_fast_igetfield, bc, rbx);
3155   }
3156   __ jmp(Done);
3157 
3158   __ bind(notInt);
3159   __ cmpl(flags, ctos);
3160   __ jcc(Assembler::notEqual, notChar);
3161   // ctos
3162   __ access_load_at(T_CHAR, IN_HEAP, rax, field, noreg, noreg);
3163   __ push(ctos);
3164   // Rewrite bytecode to be faster
3165   if (!is_static &amp;&amp; rc == may_rewrite) {
3166     patch_bytecode(Bytecodes::_fast_cgetfield, bc, rbx);
</pre>
<hr />
<pre>
3226 #endif
3227 
3228   __ bind(Done);
3229   // [jk] not needed currently
3230   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadLoad |
3231   //                                              Assembler::LoadStore));
3232 }
3233 
3234 void TemplateTable::getfield(int byte_no) {
3235   getfield_or_static(byte_no, false);
3236 }
3237 
3238 void TemplateTable::nofast_getfield(int byte_no) {
3239   getfield_or_static(byte_no, false, may_not_rewrite);
3240 }
3241 
3242 void TemplateTable::getstatic(int byte_no) {
3243   getfield_or_static(byte_no, true);
3244 }
3245 
<span class="line-added">3246 void TemplateTable::withfield() {</span>
<span class="line-added">3247   transition(vtos, atos);</span>
<span class="line-added">3248 </span>
<span class="line-added">3249   Register cache = LP64_ONLY(c_rarg1) NOT_LP64(rcx);</span>
<span class="line-added">3250   Register index = LP64_ONLY(c_rarg2) NOT_LP64(rdx);</span>
<span class="line-added">3251 </span>
<span class="line-added">3252   resolve_cache_and_index(f2_byte, cache, index, sizeof(u2));</span>
<span class="line-added">3253 </span>
<span class="line-added">3254   call_VM(rbx, CAST_FROM_FN_PTR(address, InterpreterRuntime::withfield), cache);</span>
<span class="line-added">3255   // new value type is returned in rbx</span>
<span class="line-added">3256   // stack adjustement is returned in rax</span>
<span class="line-added">3257   __ verify_oop(rbx);</span>
<span class="line-added">3258   __ addptr(rsp, rax);</span>
<span class="line-added">3259   __ movptr(rax, rbx);</span>
<span class="line-added">3260 }</span>
3261 
3262 // The registers cache and index expected to be set before call.
3263 // The function may destroy various registers, just not the cache and index registers.
3264 void TemplateTable::jvmti_post_field_mod(Register cache, Register index, bool is_static) {
3265 
3266   const Register robj = LP64_ONLY(c_rarg2)   NOT_LP64(rax);
3267   const Register RBX  = LP64_ONLY(c_rarg1)   NOT_LP64(rbx);
3268   const Register RCX  = LP64_ONLY(c_rarg3)   NOT_LP64(rcx);
3269   const Register RDX  = LP64_ONLY(rscratch1) NOT_LP64(rdx);
3270 
3271   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
3272 
3273   if (JvmtiExport::can_post_field_modification()) {
3274     // Check to see if a field modification watch has been set before
3275     // we take the time to call into the VM.
3276     Label L1;
3277     assert_different_registers(cache, index, rax);
3278     __ mov32(rax, ExternalAddress((address)JvmtiExport::get_field_modification_count_addr()));
3279     __ testl(rax, rax);
3280     __ jcc(Assembler::zero, L1);
</pre>
<hr />
<pre>
3336     // c_rarg1: object pointer set up above (NULL if static)
3337     // c_rarg2: cache entry pointer
3338     // c_rarg3: jvalue object on the stack
3339     __ call_VM(noreg,
3340                CAST_FROM_FN_PTR(address,
3341                                 InterpreterRuntime::post_field_modification),
3342                RBX, robj, RCX);
3343     __ get_cache_and_index_at_bcp(cache, index, 1);
3344     __ bind(L1);
3345   }
3346 }
3347 
3348 void TemplateTable::putfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
3349   transition(vtos, vtos);
3350 
3351   const Register cache = rcx;
3352   const Register index = rdx;
3353   const Register obj   = rcx;
3354   const Register off   = rbx;
3355   const Register flags = rax;
<span class="line-added">3356   const Register flags2 = rdx;</span>
3357 
3358   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
3359   jvmti_post_field_mod(cache, index, is_static);
3360   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
3361 
3362   // [jk] not needed currently
3363   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadStore |
3364   //                                              Assembler::StoreStore));
3365 
3366   Label notVolatile, Done;
3367   __ movl(rdx, flags);
3368   __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3369   __ andl(rdx, 0x1);
3370 
3371   // Check for volatile store
3372   __ testl(rdx, rdx);
<span class="line-added">3373   __ movl(flags2, flags);</span>
3374   __ jcc(Assembler::zero, notVolatile);
3375 
<span class="line-modified">3376   putfield_or_static_helper(byte_no, is_static, rc, obj, off, flags, flags2);</span>
3377   volatile_barrier(Assembler::Membar_mask_bits(Assembler::StoreLoad |
3378                                                Assembler::StoreStore));
3379   __ jmp(Done);
3380   __ bind(notVolatile);
3381 
<span class="line-modified">3382   putfield_or_static_helper(byte_no, is_static, rc, obj, off, flags, flags2);</span>
3383 
3384   __ bind(Done);
3385 }
3386 
3387 void TemplateTable::putfield_or_static_helper(int byte_no, bool is_static, RewriteControl rc,
<span class="line-modified">3388                                               Register obj, Register off, Register flags, Register flags2) {</span>
3389 
3390   // field addresses
3391   const Address field(obj, off, Address::times_1, 0*wordSize);
3392   NOT_LP64( const Address hi(obj, off, Address::times_1, 1*wordSize);)
3393 
3394   Label notByte, notBool, notInt, notShort, notChar,
<span class="line-modified">3395         notLong, notFloat, notObj, notValueType;</span>
3396   Label Done;
3397 
3398   const Register bc    = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
3399 
3400   __ shrl(flags, ConstantPoolCacheEntry::tos_state_shift);
3401 
3402   assert(btos == 0, &quot;change code, btos != 0&quot;);
3403   __ andl(flags, ConstantPoolCacheEntry::tos_state_mask);
3404   __ jcc(Assembler::notZero, notByte);
3405 
3406   // btos
3407   {
3408     __ pop(btos);
3409     if (!is_static) pop_and_check_object(obj);
3410     __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);
3411     if (!is_static &amp;&amp; rc == may_rewrite) {
3412       patch_bytecode(Bytecodes::_fast_bputfield, bc, rbx, true, byte_no);
3413     }
3414     __ jmp(Done);
3415   }
</pre>
<hr />
<pre>
3418   __ cmpl(flags, ztos);
3419   __ jcc(Assembler::notEqual, notBool);
3420 
3421   // ztos
3422   {
3423     __ pop(ztos);
3424     if (!is_static) pop_and_check_object(obj);
3425     __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);
3426     if (!is_static &amp;&amp; rc == may_rewrite) {
3427       patch_bytecode(Bytecodes::_fast_zputfield, bc, rbx, true, byte_no);
3428     }
3429     __ jmp(Done);
3430   }
3431 
3432   __ bind(notBool);
3433   __ cmpl(flags, atos);
3434   __ jcc(Assembler::notEqual, notObj);
3435 
3436   // atos
3437   {
<span class="line-modified">3438     if (!EnableValhalla) {</span>
<span class="line-modified">3439       __ pop(atos);</span>
<span class="line-modified">3440       if (!is_static) pop_and_check_object(obj);</span>
<span class="line-modified">3441       // Store into the field</span>
<span class="line-modified">3442       do_oop_store(_masm, field, rax);</span>
<span class="line-modified">3443       if (!is_static &amp;&amp; rc == may_rewrite) {</span>
<span class="line-added">3444         patch_bytecode(Bytecodes::_fast_aputfield, bc, rbx, true, byte_no);</span>
<span class="line-added">3445       }</span>
<span class="line-added">3446       __ jmp(Done);</span>
<span class="line-added">3447     } else {</span>
<span class="line-added">3448       __ pop(atos);</span>
<span class="line-added">3449       if (is_static) {</span>
<span class="line-added">3450         Label notFlattenable, notBuffered;</span>
<span class="line-added">3451         __ test_field_is_not_flattenable(flags2, rscratch1, notFlattenable);</span>
<span class="line-added">3452         __ null_check(rax);</span>
<span class="line-added">3453         __ bind(notFlattenable);</span>
<span class="line-added">3454         do_oop_store(_masm, field, rax);</span>
<span class="line-added">3455         __ jmp(Done);</span>
<span class="line-added">3456       } else {</span>
<span class="line-added">3457         Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;</span>
<span class="line-added">3458         __ test_field_is_flattenable(flags2, rscratch1, isFlattenable);</span>
<span class="line-added">3459         // Not flattenable case, covers not flattenable values and objects</span>
<span class="line-added">3460         pop_and_check_object(obj);</span>
<span class="line-added">3461         // Store into the field</span>
<span class="line-added">3462         do_oop_store(_masm, field, rax);</span>
<span class="line-added">3463         __ bind(rewriteNotFlattenable);</span>
<span class="line-added">3464         if (rc == may_rewrite) {</span>
<span class="line-added">3465           patch_bytecode(Bytecodes::_fast_aputfield, bc, rbx, true, byte_no);</span>
<span class="line-added">3466         }</span>
<span class="line-added">3467         __ jmp(Done);</span>
<span class="line-added">3468         // Implementation of the flattenable semantic</span>
<span class="line-added">3469         __ bind(isFlattenable);</span>
<span class="line-added">3470         __ null_check(rax);</span>
<span class="line-added">3471         __ test_field_is_flattened(flags2, rscratch1, isFlattened);</span>
<span class="line-added">3472         // Not flattened case</span>
<span class="line-added">3473         pop_and_check_object(obj);</span>
<span class="line-added">3474         // Store into the field</span>
<span class="line-added">3475         do_oop_store(_masm, field, rax);</span>
<span class="line-added">3476         __ jmp(rewriteFlattenable);</span>
<span class="line-added">3477         __ bind(isFlattened);</span>
<span class="line-added">3478         pop_and_check_object(obj);</span>
<span class="line-added">3479         assert_different_registers(rax, rdx, obj, off);</span>
<span class="line-added">3480         __ load_klass(rdx, rax, rscratch1);</span>
<span class="line-added">3481         __ data_for_oop(rax, rax, rdx);</span>
<span class="line-added">3482         __ addptr(obj, off);</span>
<span class="line-added">3483         __ access_value_copy(IN_HEAP, rax, obj, rdx);</span>
<span class="line-added">3484         __ bind(rewriteFlattenable);</span>
<span class="line-added">3485         if (rc == may_rewrite) {</span>
<span class="line-added">3486           patch_bytecode(Bytecodes::_fast_qputfield, bc, rbx, true, byte_no);</span>
<span class="line-added">3487         }</span>
<span class="line-added">3488         __ jmp(Done);</span>
<span class="line-added">3489       }</span>
3490     }

3491   }
3492 
3493   __ bind(notObj);
3494   __ cmpl(flags, itos);
3495   __ jcc(Assembler::notEqual, notInt);
3496 
3497   // itos
3498   {
3499     __ pop(itos);
3500     if (!is_static) pop_and_check_object(obj);
3501     __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);
3502     if (!is_static &amp;&amp; rc == may_rewrite) {
3503       patch_bytecode(Bytecodes::_fast_iputfield, bc, rbx, true, byte_no);
3504     }
3505     __ jmp(Done);
3506   }
3507 
3508   __ bind(notInt);
3509   __ cmpl(flags, ctos);
3510   __ jcc(Assembler::notEqual, notChar);
</pre>
<hr />
<pre>
3609 }
3610 
3611 void TemplateTable::jvmti_post_fast_field_mod() {
3612 
3613   const Register scratch = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
3614 
3615   if (JvmtiExport::can_post_field_modification()) {
3616     // Check to see if a field modification watch has been set before
3617     // we take the time to call into the VM.
3618     Label L2;
3619     __ mov32(scratch, ExternalAddress((address)JvmtiExport::get_field_modification_count_addr()));
3620     __ testl(scratch, scratch);
3621     __ jcc(Assembler::zero, L2);
3622     __ pop_ptr(rbx);                  // copy the object pointer from tos
3623     __ verify_oop(rbx);
3624     __ push_ptr(rbx);                 // put the object pointer back on tos
3625     // Save tos values before call_VM() clobbers them. Since we have
3626     // to do it for every data type, we use the saved values as the
3627     // jvalue object.
3628     switch (bytecode()) {          // load values into the jvalue object
<span class="line-added">3629     case Bytecodes::_fast_qputfield: //fall through</span>
3630     case Bytecodes::_fast_aputfield: __ push_ptr(rax); break;
3631     case Bytecodes::_fast_bputfield: // fall through
3632     case Bytecodes::_fast_zputfield: // fall through
3633     case Bytecodes::_fast_sputfield: // fall through
3634     case Bytecodes::_fast_cputfield: // fall through
3635     case Bytecodes::_fast_iputfield: __ push_i(rax); break;
3636     case Bytecodes::_fast_dputfield: __ push(dtos); break;
3637     case Bytecodes::_fast_fputfield: __ push(ftos); break;
3638     case Bytecodes::_fast_lputfield: __ push_l(rax); break;
3639 
3640     default:
3641       ShouldNotReachHere();
3642     }
3643     __ mov(scratch, rsp);             // points to jvalue on the stack
3644     // access constant pool cache entry
3645     LP64_ONLY(__ get_cache_entry_pointer_at_bcp(c_rarg2, rax, 1));
3646     NOT_LP64(__ get_cache_entry_pointer_at_bcp(rax, rdx, 1));
3647     __ verify_oop(rbx);
3648     // rbx: object pointer copied above
3649     // c_rarg2: cache entry pointer
3650     // c_rarg3: jvalue object on the stack
3651     LP64_ONLY(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_modification), rbx, c_rarg2, c_rarg3));
3652     NOT_LP64(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_modification), rbx, rax, rcx));
3653 
3654     switch (bytecode()) {             // restore tos values
<span class="line-added">3655     case Bytecodes::_fast_qputfield: // fall through</span>
3656     case Bytecodes::_fast_aputfield: __ pop_ptr(rax); break;
3657     case Bytecodes::_fast_bputfield: // fall through
3658     case Bytecodes::_fast_zputfield: // fall through
3659     case Bytecodes::_fast_sputfield: // fall through
3660     case Bytecodes::_fast_cputfield: // fall through
3661     case Bytecodes::_fast_iputfield: __ pop_i(rax); break;
3662     case Bytecodes::_fast_dputfield: __ pop(dtos); break;
3663     case Bytecodes::_fast_fputfield: __ pop(ftos); break;
3664     case Bytecodes::_fast_lputfield: __ pop_l(rax); break;
3665     default: break;
3666     }
3667     __ bind(L2);
3668   }
3669 }
3670 
3671 void TemplateTable::fast_storefield(TosState state) {
3672   transition(state, vtos);
3673 
3674   ByteSize base = ConstantPoolCache::base_offset();
3675 
3676   jvmti_post_fast_field_mod();
3677 
3678   // access constant pool cache
3679   __ get_cache_and_index_at_bcp(rcx, rbx, 1);
3680 
3681   // test for volatile with rdx but rdx is tos register for lputfield.
3682   __ movl(rdx, Address(rcx, rbx, Address::times_ptr,
3683                        in_bytes(base +
3684                                 ConstantPoolCacheEntry::flags_offset())));
3685 
3686   // replace index with field offset from cache entry
3687   __ movptr(rbx, Address(rcx, rbx, Address::times_ptr,
3688                          in_bytes(base + ConstantPoolCacheEntry::f2_offset())));
3689 
3690   // [jk] not needed currently
3691   // volatile_barrier(Assembler::Membar_mask_bits(Assembler::LoadStore |
3692   //                                              Assembler::StoreStore));
3693 
3694   Label notVolatile, Done;
<span class="line-added">3695   if (bytecode() == Bytecodes::_fast_qputfield) {</span>
<span class="line-added">3696     __ movl(rscratch2, rdx);  // saving flags for isFlattened test</span>
<span class="line-added">3697   }</span>
<span class="line-added">3698 </span>
3699   __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3700   __ andl(rdx, 0x1);
3701 
3702   // Get object from stack
3703   pop_and_check_object(rcx);
3704 
3705   // field address
3706   const Address field(rcx, rbx, Address::times_1);
3707 
3708   // Check for volatile store
3709   __ testl(rdx, rdx);
3710   __ jcc(Assembler::zero, notVolatile);
3711 
<span class="line-modified">3712   if (bytecode() == Bytecodes::_fast_qputfield) {</span>
<span class="line-added">3713     __ movl(rdx, rscratch2);  // restoring flags for isFlattened test</span>
<span class="line-added">3714   }</span>
<span class="line-added">3715   fast_storefield_helper(field, rax, rdx);</span>
3716   volatile_barrier(Assembler::Membar_mask_bits(Assembler::StoreLoad |
3717                                                Assembler::StoreStore));
3718   __ jmp(Done);
3719   __ bind(notVolatile);
3720 
<span class="line-modified">3721   if (bytecode() == Bytecodes::_fast_qputfield) {</span>
<span class="line-added">3722     __ movl(rdx, rscratch2);  // restoring flags for isFlattened test</span>
<span class="line-added">3723   }</span>
<span class="line-added">3724   fast_storefield_helper(field, rax, rdx);</span>
3725 
3726   __ bind(Done);
3727 }
3728 
<span class="line-modified">3729 void TemplateTable::fast_storefield_helper(Address field, Register rax, Register flags) {</span>
3730 
3731   // access field
3732   switch (bytecode()) {
<span class="line-added">3733   case Bytecodes::_fast_qputfield:</span>
<span class="line-added">3734     {</span>
<span class="line-added">3735       Label isFlattened, done;</span>
<span class="line-added">3736       __ null_check(rax);</span>
<span class="line-added">3737       __ test_field_is_flattened(flags, rscratch1, isFlattened);</span>
<span class="line-added">3738       // No Flattened case</span>
<span class="line-added">3739       do_oop_store(_masm, field, rax);</span>
<span class="line-added">3740       __ jmp(done);</span>
<span class="line-added">3741       __ bind(isFlattened);</span>
<span class="line-added">3742       // Flattened case</span>
<span class="line-added">3743       __ load_klass(rdx, rax, rscratch1);</span>
<span class="line-added">3744       __ data_for_oop(rax, rax, rdx);</span>
<span class="line-added">3745       __ lea(rcx, field);</span>
<span class="line-added">3746       __ access_value_copy(IN_HEAP, rax, rcx, rdx);</span>
<span class="line-added">3747       __ bind(done);</span>
<span class="line-added">3748     }</span>
<span class="line-added">3749     break;</span>
3750   case Bytecodes::_fast_aputfield:
<span class="line-modified">3751     {</span>
<span class="line-added">3752       do_oop_store(_masm, field, rax);</span>
<span class="line-added">3753     }</span>
3754     break;
3755   case Bytecodes::_fast_lputfield:
3756 #ifdef _LP64
3757     __ access_store_at(T_LONG, IN_HEAP, field, noreg /* ltos */, noreg, noreg);
3758 #else
3759   __ stop(&quot;should not be rewritten&quot;);
3760 #endif
3761     break;
3762   case Bytecodes::_fast_iputfield:
3763     __ access_store_at(T_INT, IN_HEAP, field, rax, noreg, noreg);
3764     break;
3765   case Bytecodes::_fast_zputfield:
3766     __ access_store_at(T_BOOLEAN, IN_HEAP, field, rax, noreg, noreg);
3767     break;
3768   case Bytecodes::_fast_bputfield:
3769     __ access_store_at(T_BYTE, IN_HEAP, field, rax, noreg, noreg);
3770     break;
3771   case Bytecodes::_fast_sputfield:
3772     __ access_store_at(T_SHORT, IN_HEAP, field, rax, noreg, noreg);
3773     break;
</pre>
<hr />
<pre>
3803     __ push_ptr(rax);  // save object pointer before call_VM() clobbers it
3804     LP64_ONLY(__ mov(c_rarg1, rax));
3805     // c_rarg1: object pointer copied above
3806     // c_rarg2: cache entry pointer
3807     LP64_ONLY(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_access), c_rarg1, c_rarg2));
3808     NOT_LP64(__ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::post_field_access), rax, rcx));
3809     __ pop_ptr(rax); // restore object pointer
3810     __ bind(L1);
3811   }
3812 
3813   // access constant pool cache
3814   __ get_cache_and_index_at_bcp(rcx, rbx, 1);
3815   // replace index with field offset from cache entry
3816   // [jk] not needed currently
3817   // __ movl(rdx, Address(rcx, rbx, Address::times_8,
3818   //                      in_bytes(ConstantPoolCache::base_offset() +
3819   //                               ConstantPoolCacheEntry::flags_offset())));
3820   // __ shrl(rdx, ConstantPoolCacheEntry::is_volatile_shift);
3821   // __ andl(rdx, 0x1);
3822   //
<span class="line-modified">3823   __ movptr(rdx, Address(rcx, rbx, Address::times_ptr,</span>
3824                          in_bytes(ConstantPoolCache::base_offset() +
3825                                   ConstantPoolCacheEntry::f2_offset())));
3826 
3827   // rax: object
3828   __ verify_oop(rax);
3829   __ null_check(rax);
<span class="line-modified">3830   Address field(rax, rdx, Address::times_1);</span>
3831 
3832   // access field
3833   switch (bytecode()) {
<span class="line-added">3834   case Bytecodes::_fast_qgetfield:</span>
<span class="line-added">3835     {</span>
<span class="line-added">3836       Label isFlattened, nonnull, Done;</span>
<span class="line-added">3837       __ movptr(rscratch1, Address(rcx, rbx, Address::times_ptr,</span>
<span class="line-added">3838                                    in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3839                                             ConstantPoolCacheEntry::flags_offset())));</span>
<span class="line-added">3840       __ test_field_is_flattened(rscratch1, rscratch2, isFlattened);</span>
<span class="line-added">3841         // Non-flattened field case</span>
<span class="line-added">3842         __ load_heap_oop(rax, field);</span>
<span class="line-added">3843         __ testptr(rax, rax);</span>
<span class="line-added">3844         __ jcc(Assembler::notZero, nonnull);</span>
<span class="line-added">3845           __ movl(rdx, Address(rcx, rbx, Address::times_ptr,</span>
<span class="line-added">3846                              in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3847                                       ConstantPoolCacheEntry::flags_offset())));</span>
<span class="line-added">3848           __ andl(rdx, ConstantPoolCacheEntry::field_index_mask);</span>
<span class="line-added">3849           __ movptr(rcx, Address(rcx, rbx, Address::times_ptr,</span>
<span class="line-added">3850                                        in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3851                                                 ConstantPoolCacheEntry::f1_offset())));</span>
<span class="line-added">3852           __ get_value_field_klass(rcx, rdx, rbx);</span>
<span class="line-added">3853           __ get_default_value_oop(rbx, rcx, rax);</span>
<span class="line-added">3854         __ bind(nonnull);</span>
<span class="line-added">3855         __ verify_oop(rax);</span>
<span class="line-added">3856         __ jmp(Done);</span>
<span class="line-added">3857       __ bind(isFlattened);</span>
<span class="line-added">3858         __ push(rdx); // save offset</span>
<span class="line-added">3859         __ movl(rdx, Address(rcx, rbx, Address::times_ptr,</span>
<span class="line-added">3860                            in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3861                                     ConstantPoolCacheEntry::flags_offset())));</span>
<span class="line-added">3862         __ andl(rdx, ConstantPoolCacheEntry::field_index_mask);</span>
<span class="line-added">3863         __ movptr(rcx, Address(rcx, rbx, Address::times_ptr,</span>
<span class="line-added">3864                                      in_bytes(ConstantPoolCache::base_offset() +</span>
<span class="line-added">3865                                               ConstantPoolCacheEntry::f1_offset())));</span>
<span class="line-added">3866         __ pop(rbx); // restore offset</span>
<span class="line-added">3867         __ read_flattened_field(rcx, rdx, rbx, rax);</span>
<span class="line-added">3868       __ bind(Done);</span>
<span class="line-added">3869       __ verify_oop(rax);</span>
<span class="line-added">3870     }</span>
<span class="line-added">3871     break;</span>
3872   case Bytecodes::_fast_agetfield:
3873     do_oop_load(_masm, field, rax);
3874     __ verify_oop(rax);
3875     break;
3876   case Bytecodes::_fast_lgetfield:
3877 #ifdef _LP64
3878     __ access_load_at(T_LONG, IN_HEAP, noreg /* ltos */, field, noreg, noreg);
3879 #else
3880   __ stop(&quot;should not be rewritten&quot;);
3881 #endif
3882     break;
3883   case Bytecodes::_fast_igetfield:
3884     __ access_load_at(T_INT, IN_HEAP, rax, field, noreg, noreg);
3885     break;
3886   case Bytecodes::_fast_bgetfield:
3887     __ access_load_at(T_BYTE, IN_HEAP, rax, field, noreg, noreg);
3888     break;
3889   case Bytecodes::_fast_sgetfield:
3890     __ access_load_at(T_SHORT, IN_HEAP, rax, field, noreg, noreg);
3891     break;
</pre>
<hr />
<pre>
4325 
4326   // Note:  rax_callsite is already pushed by prepare_invoke
4327 
4328   // %%% should make a type profile for any invokedynamic that takes a ref argument
4329   // profile this call
4330   __ profile_call(rbcp);
4331   __ profile_arguments_type(rdx, rbx_method, rbcp, false);
4332 
4333   __ verify_oop(rax_callsite);
4334 
4335   __ jump_from_interpreted(rbx_method, rdx);
4336 }
4337 
4338 //-----------------------------------------------------------------------------
4339 // Allocation
4340 
4341 void TemplateTable::_new() {
4342   transition(vtos, atos);
4343   __ get_unsigned_2_byte_index_at_bcp(rdx, 1);
4344   Label slow_case;
<span class="line-modified">4345   Label done;</span>


4346   Label is_not_value;
4347 
4348   __ get_cpool_and_tags(rcx, rax);
4349 
4350   // Make sure the class we&#39;re about to instantiate has been resolved.
4351   // This is done before loading InstanceKlass to be consistent with the order
4352   // how Constant Pool is updated (see ConstantPool::klass_at_put)
4353   const int tags_offset = Array&lt;u1&gt;::base_offset_in_bytes();
4354   __ cmpb(Address(rax, rdx, Address::times_1, tags_offset), JVM_CONSTANT_Class);
<span class="line-modified">4355   __ jcc(Assembler::notEqual, slow_case);</span>
4356 
4357   // get InstanceKlass
4358   __ load_resolved_klass_at_index(rcx, rcx, rdx);
<span class="line-modified">4359 </span>
<span class="line-added">4360   __ cmpb(Address(rcx, InstanceKlass::kind_offset()), InstanceKlass::_kind_inline_type);</span>
<span class="line-added">4361   __ jcc(Assembler::notEqual, is_not_value);</span>
<span class="line-added">4362 </span>
<span class="line-added">4363   __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::throw_InstantiationError));</span>
<span class="line-added">4364 </span>
<span class="line-added">4365   __ bind(is_not_value);</span>
4366 
4367   // make sure klass is initialized &amp; doesn&#39;t have finalizer

4368   __ cmpb(Address(rcx, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);
4369   __ jcc(Assembler::notEqual, slow_case);
4370 
<span class="line-modified">4371   __ allocate_instance(rcx, rax, rdx, rbx, true, slow_case);</span>
<span class="line-modified">4372   __ jmp(done);</span>

















4373 
<span class="line-modified">4374   // slow case</span>
<span class="line-modified">4375   __ bind(slow_case);</span>
4376 
<span class="line-modified">4377   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rax);</span>
<span class="line-modified">4378   Register rarg2 = LP64_ONLY(c_rarg2) NOT_LP64(rdx);</span>




4379 
<span class="line-modified">4380   __ get_constant_pool(rarg1);</span>
<span class="line-modified">4381   __ get_unsigned_2_byte_index_at_bcp(rarg2, 1);</span>
<span class="line-modified">4382   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), rarg1, rarg2);</span>
<span class="line-modified">4383    __ verify_oop(rax);</span>











4384 
<span class="line-modified">4385   // continue</span>
<span class="line-modified">4386   __ bind(done);</span>
<span class="line-modified">4387 }</span>





















4388 
<span class="line-modified">4389 void TemplateTable::defaultvalue() {</span>
<span class="line-modified">4390   transition(vtos, atos);</span>






4391 
<span class="line-modified">4392   Label slow_case;</span>
<span class="line-modified">4393   Label done;</span>
<span class="line-modified">4394   Label is_value;</span>














4395 
<span class="line-modified">4396   __ get_unsigned_2_byte_index_at_bcp(rdx, 1);</span>
<span class="line-modified">4397   __ get_cpool_and_tags(rcx, rax);</span>






4398 
<span class="line-modified">4399   // Make sure the class we&#39;re about to instantiate has been resolved.</span>
<span class="line-modified">4400   // This is done before loading InstanceKlass to be consistent with the order</span>
<span class="line-added">4401   // how Constant Pool is updated (see ConstantPool::klass_at_put)</span>
<span class="line-added">4402   const int tags_offset = Array&lt;u1&gt;::base_offset_in_bytes();</span>
<span class="line-added">4403   __ cmpb(Address(rax, rdx, Address::times_1, tags_offset), JVM_CONSTANT_Class);</span>
<span class="line-added">4404   __ jcc(Assembler::notEqual, slow_case);</span>
<span class="line-added">4405 </span>
<span class="line-added">4406   // get InstanceKlass</span>
<span class="line-added">4407   __ load_resolved_klass_at_index(rcx, rcx, rdx);</span>
<span class="line-added">4408 </span>
<span class="line-added">4409   __ cmpb(Address(rcx, InstanceKlass::kind_offset()), InstanceKlass::_kind_inline_type);</span>
<span class="line-added">4410   __ jcc(Assembler::equal, is_value);</span>
<span class="line-added">4411 </span>
<span class="line-added">4412   // in the future, defaultvalue will just return null instead of throwing an exception</span>
<span class="line-added">4413   __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::throw_IncompatibleClassChangeError));</span>
<span class="line-added">4414 </span>
<span class="line-added">4415   __ bind(is_value);</span>
<span class="line-added">4416 </span>
<span class="line-added">4417   // make sure klass is fully initialized</span>
<span class="line-added">4418   __ cmpb(Address(rcx, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="line-added">4419   __ jcc(Assembler::notEqual, slow_case);</span>
<span class="line-added">4420 </span>
<span class="line-added">4421   // have a resolved ValueKlass in rcx, return the default value oop from it</span>
<span class="line-added">4422   __ get_default_value_oop(rcx, rdx, rax);</span>
<span class="line-added">4423   __ jmp(done);</span>
4424 
<span class="line-modified">4425   __ bind(slow_case);</span>



4426 
4427   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
4428   Register rarg2 = LP64_ONLY(c_rarg2) NOT_LP64(rdx);
4429 
<span class="line-modified">4430   __ get_unsigned_2_byte_index_at_bcp(rarg2, 1);</span>
<span class="line-modified">4431   __ get_constant_pool(rarg1);</span>
<span class="line-modified">4432 </span>
<span class="line-added">4433   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::defaultvalue),</span>
4434       rarg1, rarg2);
4435 
<span class="line-modified">4436   __ bind(done);</span>
4437   __ verify_oop(rax);
4438 }
4439 
4440 void TemplateTable::newarray() {
4441   transition(itos, atos);
4442   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4443   __ load_unsigned_byte(rarg1, at_bcp(1));
4444   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::newarray),
4445           rarg1, rax);
4446 }
4447 
4448 void TemplateTable::anewarray() {
4449   transition(itos, atos);
4450 
4451   Register rarg1 = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
4452   Register rarg2 = LP64_ONLY(c_rarg2) NOT_LP64(rdx);
4453 
4454   __ get_unsigned_2_byte_index_at_bcp(rarg2, 1);
4455   __ get_constant_pool(rarg1);
4456   call_VM(rax, CAST_FROM_FN_PTR(address, InterpreterRuntime::anewarray),
4457           rarg1, rarg2, rax);
4458 }
4459 
4460 void TemplateTable::arraylength() {
4461   transition(atos, itos);
4462   __ null_check(rax, arrayOopDesc::length_offset_in_bytes());
4463   __ movl(rax, Address(rax, arrayOopDesc::length_offset_in_bytes()));
4464 }
4465 
4466 void TemplateTable::checkcast() {
4467   transition(atos, atos);
4468   Label done, is_null, ok_is_subtype, quicked, resolved;
4469   __ testptr(rax, rax); // object is in rax
4470   __ jcc(Assembler::zero, is_null);
4471 
4472   // Get cpool &amp; tags index
4473   __ get_cpool_and_tags(rcx, rdx); // rcx=cpool, rdx=tags array
4474   __ get_unsigned_2_byte_index_at_bcp(rbx, 1); // rbx=index
4475   // See if bytecode has already been quicked
<span class="line-modified">4476   __ movzbl(rdx, Address(rdx, rbx,</span>
<span class="line-modified">4477       Address::times_1,</span>
<span class="line-modified">4478       Array&lt;u1&gt;::base_offset_in_bytes()));</span>
<span class="line-modified">4479   __ andl (rdx, ~JVM_CONSTANT_QDescBit);</span>
<span class="line-added">4480   __ cmpl(rdx, JVM_CONSTANT_Class);</span>
4481   __ jcc(Assembler::equal, quicked);
4482   __ push(atos); // save receiver for result, and for GC
4483   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
4484 
4485   // vm_result_2 has metadata result
4486 #ifndef _LP64
4487   // borrow rdi from locals
4488   __ get_thread(rdi);
4489   __ get_vm_result_2(rax, rdi);
4490   __ restore_locals();
4491 #else
4492   __ get_vm_result_2(rax, r15_thread);
4493 #endif
4494 
4495   __ pop_ptr(rdx); // restore receiver
4496   __ jmpb(resolved);
4497 
4498   // Get superklass in rax and subklass in rbx
4499   __ bind(quicked);
4500   __ mov(rdx, rax); // Save object in rdx; rax needed for subtype check
4501   __ load_resolved_klass_at_index(rax, rcx, rbx);
4502 
4503   __ bind(resolved);
4504   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
4505   __ load_klass(rbx, rdx, tmp_load_klass);
4506 
4507   // Generate subtype check.  Blows rcx, rdi.  Object in rdx.
4508   // Superklass in rax.  Subklass in rbx.
4509   __ gen_subtype_check(rbx, ok_is_subtype);
4510 
4511   // Come here on failure
4512   __ push_ptr(rdx);
4513   // object is at TOS
4514   __ jump(ExternalAddress(Interpreter::_throw_ClassCastException_entry));
4515 
4516   // Come here on success
4517   __ bind(ok_is_subtype);
4518   __ mov(rax, rdx); // Restore object in rdx
<span class="line-added">4519   __ jmp(done);</span>
<span class="line-added">4520 </span>
<span class="line-added">4521   __ bind(is_null);</span>
4522 
4523   // Collect counts on whether this check-cast sees NULLs a lot or not.
4524   if (ProfileInterpreter) {
<span class="line-modified">4525     __ profile_null_seen(rcx);</span>
<span class="line-modified">4526   }</span>
<span class="line-modified">4527 </span>
<span class="line-modified">4528   if (EnableValhalla) {</span>
<span class="line-added">4529     // Get cpool &amp; tags index</span>
<span class="line-added">4530     __ get_cpool_and_tags(rcx, rdx); // rcx=cpool, rdx=tags array</span>
<span class="line-added">4531     __ get_unsigned_2_byte_index_at_bcp(rbx, 1); // rbx=index</span>
<span class="line-added">4532     // See if CP entry is a Q-descriptor</span>
<span class="line-added">4533     __ movzbl(rcx, Address(rdx, rbx,</span>
<span class="line-added">4534         Address::times_1,</span>
<span class="line-added">4535         Array&lt;u1&gt;::base_offset_in_bytes()));</span>
<span class="line-added">4536     __ andl (rcx, JVM_CONSTANT_QDescBit);</span>
<span class="line-added">4537     __ cmpl(rcx, JVM_CONSTANT_QDescBit);</span>
<span class="line-added">4538     __ jcc(Assembler::notEqual, done);</span>
<span class="line-added">4539     __ jump(ExternalAddress(Interpreter::_throw_NullPointerException_entry));</span>
4540   }
4541 
4542   __ bind(done);
4543 }
4544 
4545 void TemplateTable::instanceof() {
4546   transition(atos, itos);
4547   Label done, is_null, ok_is_subtype, quicked, resolved;
4548   __ testptr(rax, rax);
4549   __ jcc(Assembler::zero, is_null);
4550 
4551   // Get cpool &amp; tags index
4552   __ get_cpool_and_tags(rcx, rdx); // rcx=cpool, rdx=tags array
4553   __ get_unsigned_2_byte_index_at_bcp(rbx, 1); // rbx=index
4554   // See if bytecode has already been quicked
<span class="line-modified">4555   __ movzbl(rdx, Address(rdx, rbx,</span>
<span class="line-modified">4556         Address::times_1,</span>
<span class="line-modified">4557         Array&lt;u1&gt;::base_offset_in_bytes()));</span>
<span class="line-modified">4558   __ andl (rdx, ~JVM_CONSTANT_QDescBit);</span>
<span class="line-added">4559   __ cmpl(rdx, JVM_CONSTANT_Class);</span>
4560   __ jcc(Assembler::equal, quicked);
4561 
4562   __ push(atos); // save receiver for result, and for GC
4563   call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::quicken_io_cc));
4564   // vm_result_2 has metadata result
4565 
4566 #ifndef _LP64
4567   // borrow rdi from locals
4568   __ get_thread(rdi);
4569   __ get_vm_result_2(rax, rdi);
4570   __ restore_locals();
4571 #else
4572   __ get_vm_result_2(rax, r15_thread);
4573 #endif
4574 
4575   __ pop_ptr(rdx); // restore receiver
4576   __ verify_oop(rdx);
4577   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
4578   __ load_klass(rdx, rdx, tmp_load_klass);
4579   __ jmpb(resolved);
</pre>
<hr />
<pre>
4592   // Come here on failure
4593   __ xorl(rax, rax);
4594   __ jmpb(done);
4595   // Come here on success
4596   __ bind(ok_is_subtype);
4597   __ movl(rax, 1);
4598 
4599   // Collect counts on whether this test sees NULLs a lot or not.
4600   if (ProfileInterpreter) {
4601     __ jmp(done);
4602     __ bind(is_null);
4603     __ profile_null_seen(rcx);
4604   } else {
4605     __ bind(is_null);   // same as &#39;done&#39;
4606   }
4607   __ bind(done);
4608   // rax = 0: obj == NULL or  obj is not an instanceof the specified klass
4609   // rax = 1: obj != NULL and obj is     an instanceof the specified klass
4610 }
4611 

4612 //----------------------------------------------------------------------------------------------------
4613 // Breakpoints
4614 void TemplateTable::_breakpoint() {
4615   // Note: We get here even if we are single stepping..
4616   // jbug insists on setting breakpoints at every bytecode
4617   // even if we are in single step mode.
4618 
4619   transition(vtos, vtos);
4620 
4621   Register rarg = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
4622 
4623   // get the unpatched byte code
4624   __ get_method(rarg);
4625   __ call_VM(noreg,
4626              CAST_FROM_FN_PTR(address,
4627                               InterpreterRuntime::get_original_bytecode_at),
4628              rarg, rbcp);
4629   __ mov(rbx, rax);  // why?
4630 
4631   // post the breakpoint event
</pre>
<hr />
<pre>
4655 //
4656 // Stack layout:
4657 //
4658 // [expressions  ] &lt;--- rsp               = expression stack top
4659 // ..
4660 // [expressions  ]
4661 // [monitor entry] &lt;--- monitor block top = expression stack bot
4662 // ..
4663 // [monitor entry]
4664 // [frame data   ] &lt;--- monitor block bot
4665 // ...
4666 // [saved rbp    ] &lt;--- rbp
4667 void TemplateTable::monitorenter() {
4668   transition(atos, vtos);
4669 
4670   // check for NULL object
4671   __ null_check(rax);
4672 
4673   __ resolve(IS_NOT_NULL, rax);
4674 
<span class="line-added">4675   const int is_value_mask = markWord::always_locked_pattern;</span>
<span class="line-added">4676   Label has_identity;</span>
<span class="line-added">4677   __ movptr(rbx, Address(rax, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">4678   __ andptr(rbx, is_value_mask);</span>
<span class="line-added">4679   __ cmpl(rbx, is_value_mask);</span>
<span class="line-added">4680   __ jcc(Assembler::notEqual, has_identity);</span>
<span class="line-added">4681   __ call_VM(noreg, CAST_FROM_FN_PTR(address,</span>
<span class="line-added">4682                      InterpreterRuntime::throw_illegal_monitor_state_exception));</span>
<span class="line-added">4683   __ should_not_reach_here();</span>
<span class="line-added">4684   __ bind(has_identity);</span>
<span class="line-added">4685 </span>
4686   const Address monitor_block_top(
4687         rbp, frame::interpreter_frame_monitor_block_top_offset * wordSize);
4688   const Address monitor_block_bot(
4689         rbp, frame::interpreter_frame_initial_sp_offset * wordSize);
4690   const int entry_size = frame::interpreter_frame_monitor_size() * wordSize;
4691 
4692   Label allocated;
4693 
4694   Register rtop = LP64_ONLY(c_rarg3) NOT_LP64(rcx);
4695   Register rbot = LP64_ONLY(c_rarg2) NOT_LP64(rbx);
4696   Register rmon = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4697 
4698   // initialize entry pointer
4699   __ xorl(rmon, rmon); // points to free slot or NULL
4700 
4701   // find a free slot in the monitor block (result in rmon)
4702   {
4703     Label entry, loop, exit;
4704     __ movptr(rtop, monitor_block_top); // points to current entry,
4705                                         // starting with top-most entry
</pre>
<hr />
<pre>
4765   __ movptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), rax);
4766   __ lock_object(rmon);
4767 
4768   // check to make sure this monitor doesn&#39;t cause stack overflow after locking
4769   __ save_bcp();  // in case of exception
4770   __ generate_stack_overflow_check(0);
4771 
4772   // The bcp has already been incremented. Just need to dispatch to
4773   // next instruction.
4774   __ dispatch_next(vtos);
4775 }
4776 
4777 void TemplateTable::monitorexit() {
4778   transition(atos, vtos);
4779 
4780   // check for NULL object
4781   __ null_check(rax);
4782 
4783   __ resolve(IS_NOT_NULL, rax);
4784 
<span class="line-added">4785   const int is_value_mask = markWord::always_locked_pattern;</span>
<span class="line-added">4786   Label has_identity;</span>
<span class="line-added">4787   __ movptr(rbx, Address(rax, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">4788   __ andptr(rbx, is_value_mask);</span>
<span class="line-added">4789   __ cmpl(rbx, is_value_mask);</span>
<span class="line-added">4790   __ jcc(Assembler::notEqual, has_identity);</span>
<span class="line-added">4791   __ call_VM(noreg, CAST_FROM_FN_PTR(address,</span>
<span class="line-added">4792                      InterpreterRuntime::throw_illegal_monitor_state_exception));</span>
<span class="line-added">4793   __ should_not_reach_here();</span>
<span class="line-added">4794   __ bind(has_identity);</span>
<span class="line-added">4795 </span>
4796   const Address monitor_block_top(
4797         rbp, frame::interpreter_frame_monitor_block_top_offset * wordSize);
4798   const Address monitor_block_bot(
4799         rbp, frame::interpreter_frame_initial_sp_offset * wordSize);
4800   const int entry_size = frame::interpreter_frame_monitor_size() * wordSize;
4801 
4802   Register rtop = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
4803   Register rbot = LP64_ONLY(c_rarg2) NOT_LP64(rbx);
4804 
4805   Label found;
4806 
4807   // find matching slot
4808   {
4809     Label entry, loop;
4810     __ movptr(rtop, monitor_block_top); // points to current entry,
4811                                         // starting with top-most entry
4812     __ lea(rbot, monitor_block_bot);    // points to word before bottom
4813                                         // of monitor block
4814     __ jmpb(entry);
4815 
</pre>
</td>
</tr>
</table>
<center><a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vtableStubs_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>