<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/deoptimization.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="arguments.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../../../test/hotspot/jtreg/ProblemList.txt.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/deoptimization.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  32 #include &quot;code/codeCache.hpp&quot;
  33 #include &quot;code/debugInfoRec.hpp&quot;
  34 #include &quot;code/nmethod.hpp&quot;
  35 #include &quot;code/pcDesc.hpp&quot;
  36 #include &quot;code/scopeDesc.hpp&quot;
  37 #include &quot;compiler/compilationPolicy.hpp&quot;
  38 #include &quot;interpreter/bytecode.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;interpreter/oopMapCache.hpp&quot;
  41 #include &quot;memory/allocation.inline.hpp&quot;
  42 #include &quot;memory/oopFactory.hpp&quot;
  43 #include &quot;memory/resourceArea.hpp&quot;
  44 #include &quot;memory/universe.hpp&quot;
  45 #include &quot;oops/constantPool.hpp&quot;
  46 #include &quot;oops/method.hpp&quot;
  47 #include &quot;oops/objArrayKlass.hpp&quot;
  48 #include &quot;oops/objArrayOop.inline.hpp&quot;
  49 #include &quot;oops/oop.inline.hpp&quot;
  50 #include &quot;oops/fieldStreams.inline.hpp&quot;
  51 #include &quot;oops/typeArrayOop.inline.hpp&quot;



  52 #include &quot;oops/verifyOopClosure.hpp&quot;
  53 #include &quot;prims/jvmtiThreadState.hpp&quot;
  54 #include &quot;runtime/atomic.hpp&quot;
  55 #include &quot;runtime/biasedLocking.hpp&quot;
  56 #include &quot;runtime/deoptimization.hpp&quot;
  57 #include &quot;runtime/fieldDescriptor.hpp&quot;
  58 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  59 #include &quot;runtime/frame.inline.hpp&quot;
  60 #include &quot;runtime/handles.inline.hpp&quot;
  61 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  62 #include &quot;runtime/jniHandles.inline.hpp&quot;
  63 #include &quot;runtime/safepointVerifiers.hpp&quot;
  64 #include &quot;runtime/sharedRuntime.hpp&quot;
  65 #include &quot;runtime/signature.hpp&quot;
  66 #include &quot;runtime/stubRoutines.hpp&quot;
  67 #include &quot;runtime/thread.hpp&quot;
  68 #include &quot;runtime/threadSMR.hpp&quot;
  69 #include &quot;runtime/vframe.hpp&quot;
  70 #include &quot;runtime/vframeArray.hpp&quot;
  71 #include &quot;runtime/vframe_hp.hpp&quot;
</pre>
<hr />
<pre>
 165   return fetch_unroll_info_helper(thread, exec_mode);
 166 JRT_END
 167 
 168 #if COMPILER2_OR_JVMCI
 169 static bool eliminate_allocations(JavaThread* thread, int exec_mode, CompiledMethod* compiled_method,
 170                                   frame&amp; deoptee, RegisterMap&amp; map, GrowableArray&lt;compiledVFrame*&gt;* chunk) {
 171   bool realloc_failures = false;
 172   assert (chunk-&gt;at(0)-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 173 
 174   GrowableArray&lt;ScopeValue*&gt;* objects = chunk-&gt;at(0)-&gt;scope()-&gt;objects();
 175 
 176   // The flag return_oop() indicates call sites which return oop
 177   // in compiled code. Such sites include java method calls,
 178   // runtime calls (for example, used to allocate new objects/arrays
 179   // on slow code path) and any other calls generated in compiled code.
 180   // It is not guaranteed that we can get such information here only
 181   // by analyzing bytecode in deoptimized frames. This is why this flag
 182   // is set during method compilation (see Compile::Process_OopMap_Node()).
 183   // If the previous frame was popped or if we are dispatching an exception,
 184   // we don&#39;t have an oop result.
<span class="line-modified"> 185   bool save_oop_result = chunk-&gt;at(0)-&gt;scope()-&gt;return_oop() &amp;&amp; !thread-&gt;popframe_forcing_deopt_reexecution() &amp;&amp; (exec_mode == Deoptimization::Unpack_deopt);</span>
<span class="line-modified"> 186   Handle return_value;</span>











 187   if (save_oop_result) {
 188     // Reallocation may trigger GC. If deoptimization happened on return from
 189     // call which returns oop we need to save it since it is not in oopmap.
 190     oop result = deoptee.saved_oop_result(&amp;map);
 191     assert(oopDesc::is_oop_or_null(result), &quot;must be oop&quot;);
<span class="line-modified"> 192     return_value = Handle(thread, result);</span>
 193     assert(Universe::heap()-&gt;is_in_or_null(result), &quot;must be heap pointer&quot;);
 194     if (TraceDeoptimization) {
 195       ttyLocker ttyl;
 196       tty-&gt;print_cr(&quot;SAVED OOP RESULT &quot; INTPTR_FORMAT &quot; in thread &quot; INTPTR_FORMAT, p2i(result), p2i(thread));
 197     }
 198   }
<span class="line-modified"> 199   if (objects != NULL) {</span>

 200     JRT_BLOCK
<span class="line-modified"> 201       realloc_failures = Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);</span>






 202     JRT_END
<span class="line-removed"> 203     bool skip_internal = (compiled_method != NULL) &amp;&amp; !compiled_method-&gt;is_compiled_by_jvmci();</span>
<span class="line-removed"> 204     Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal);</span>
 205 #ifndef PRODUCT
 206     if (TraceDeoptimization) {
 207       ttyLocker ttyl;
 208       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
<span class="line-modified"> 209       Deoptimization::print_objects(objects, realloc_failures);</span>





 210     }
 211 #endif
 212   }
<span class="line-modified"> 213   if (save_oop_result) {</span>
 214     // Restore result.
<span class="line-modified"> 215     deoptee.set_saved_oop_result(&amp;map, return_value());</span>

 216   }
 217   return realloc_failures;
 218 }
 219 
 220 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 221 #ifndef PRODUCT
 222   bool first = true;
 223 #endif
 224   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 225     compiledVFrame* cvf = chunk-&gt;at(i);
 226     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 227     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 228     if (monitors-&gt;is_nonempty()) {
 229       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 230 #ifndef PRODUCT
 231       if (PrintDeoptimizationDetails) {
 232         ttyLocker ttyl;
 233         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 234           MonitorInfo* mi = monitors-&gt;at(j);
 235           if (mi-&gt;eliminated()) {
</pre>
<hr />
<pre>
 496   // its caller&#39;s stack by. If the caller is a compiled frame then
 497   // we pretend that the callee has no parameters so that the
 498   // extension counts for the full amount of locals and not just
 499   // locals-parms. This is because without a c2i adapter the parm
 500   // area as created by the compiled frame will not be usable by
 501   // the interpreter. (Depending on the calling convention there
 502   // may not even be enough space).
 503 
 504   // QQQ I&#39;d rather see this pushed down into last_frame_adjust
 505   // and have it take the sender (aka caller).
 506 
 507   if (deopt_sender.is_compiled_frame() || caller_was_method_handle) {
 508     caller_adjustment = last_frame_adjust(0, callee_locals);
 509   } else if (callee_locals &gt; callee_parameters) {
 510     // The caller frame may need extending to accommodate
 511     // non-parameter locals of the first unpacked interpreted frame.
 512     // Compute that adjustment.
 513     caller_adjustment = last_frame_adjust(callee_parameters, callee_locals);
 514   }
 515 
<span class="line-modified"> 516   // If the sender is deoptimized the we must retrieve the address of the handler</span>
 517   // since the frame will &quot;magically&quot; show the original pc before the deopt
 518   // and we&#39;d undo the deopt.
 519 
 520   frame_pcs[0] = deopt_sender.raw_pc();
 521 
 522   assert(CodeCache::find_blob_unsafe(frame_pcs[0]) != NULL, &quot;bad pc&quot;);
 523 
 524 #if INCLUDE_JVMCI
 525   if (exceptionObject() != NULL) {
 526     thread-&gt;set_exception_oop(exceptionObject());
 527     exec_mode = Unpack_exception;
 528   }
 529 #endif
 530 
 531   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0 &amp;&amp; exec_mode != Unpack_uncommon_trap) {
 532     assert(thread-&gt;has_pending_exception(), &quot;should have thrown OOME&quot;);
 533     thread-&gt;set_exception_oop(thread-&gt;pending_exception());
 534     thread-&gt;clear_pending_exception();
 535     exec_mode = Unpack_exception;
 536   }
</pre>
<hr />
<pre>
 987 
 988     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
 989     oop obj = NULL;
 990 
 991     if (k-&gt;is_instance_klass()) {
 992 #if INCLUDE_JVMCI || INCLUDE_AOT
 993       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
 994       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
 995         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
 996         obj = get_cached_box(abv, fr, reg_map, THREAD);
 997         if (obj != NULL) {
 998           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
 999           abv-&gt;set_cached(true);
1000         }
1001       }
1002 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1003       InstanceKlass* ik = InstanceKlass::cast(k);
1004       if (obj == NULL) {
1005         obj = ik-&gt;allocate_instance(THREAD);
1006       }




1007     } else if (k-&gt;is_typeArray_klass()) {
1008       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1009       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1010       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1011       obj = ak-&gt;allocate(len, THREAD);
1012     } else if (k-&gt;is_objArray_klass()) {
1013       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1014       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1015     }
1016 
1017     if (obj == NULL) {
1018       failures = true;
1019     }
1020 
1021     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1022     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1023     CLEAR_PENDING_EXCEPTION;
1024     sv-&gt;set_value(obj);
1025   }
1026 
1027   if (failures) {
1028     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), failures);
1029   } else if (pending_exception.not_null()) {
1030     thread-&gt;set_pending_exception(pending_exception(), exception_file, exception_line);
1031   }
1032 
1033   return failures;
1034 }
1035 















1036 #if INCLUDE_JVMCI
1037 /**
1038  * For primitive types whose kind gets &quot;erased&quot; at runtime (shorts become stack ints),
1039  * we need to somehow be able to recover the actual kind to be able to write the correct
1040  * amount of bytes.
1041  * For that purpose, this method assumes that, for an entry spanning n bytes at index i,
1042  * the entries at index n + 1 to n + i are &#39;markers&#39;.
1043  * For example, if we were writing a short at index 4 of a byte array of size 8, the
1044  * expected form of the array would be:
1045  *
1046  * {b0, b1, b2, b3, INT, marker, b6, b7}
1047  *
1048  * Thus, in order to get back the size of the entry, we simply need to count the number
1049  * of marked entries
1050  *
1051  * @param virtualArray the virtualized byte array
1052  * @param i index of the virtual entry we are recovering
1053  * @return The number of bytes the entry spans
1054  */
1055 static int count_number_of_bytes_for_entry(ObjectValue *virtualArray, int i) {
</pre>
<hr />
<pre>
1212       default:
1213         ShouldNotReachHere();
1214     }
1215     index++;
1216   }
1217 }
1218 
1219 // restore fields of an eliminated object array
1220 void Deoptimization::reassign_object_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, objArrayOop obj) {
1221   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {
1222     StackValue* value = StackValue::create_stack_value(fr, reg_map, sv-&gt;field_at(i));
1223     assert(value-&gt;type() == T_OBJECT, &quot;object element expected&quot;);
1224     obj-&gt;obj_at_put(i, value-&gt;get_obj()());
1225   }
1226 }
1227 
1228 class ReassignedField {
1229 public:
1230   int _offset;
1231   BasicType _type;

1232 public:
1233   ReassignedField() {
1234     _offset = 0;
1235     _type = T_ILLEGAL;

1236   }
1237 };
1238 
1239 int compare(ReassignedField* left, ReassignedField* right) {
1240   return left-&gt;_offset - right-&gt;_offset;
1241 }
1242 
1243 // Restore fields of an eliminated instance object using the same field order
1244 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
<span class="line-modified">1245 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {</span>

1246   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1247   InstanceKlass* ik = klass;
1248   while (ik != NULL) {
1249     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1250       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1251         ReassignedField field;
1252         field._offset = fs.offset();
1253         field._type = Signature::basic_type(fs.signature());









1254         fields-&gt;append(field);
1255       }
1256     }
1257     ik = ik-&gt;superklass();
1258   }
1259   fields-&gt;sort(compare);
1260   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1261     intptr_t val;
1262     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1263     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
<span class="line-modified">1264     int offset = fields-&gt;at(i)._offset;</span>
1265     BasicType type = fields-&gt;at(i)._type;
1266     switch (type) {
<span class="line-modified">1267       case T_OBJECT: case T_ARRAY:</span>

1268         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1269         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1270         break;
1271 









1272       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1273       case T_INT: case T_FLOAT: { // 4 bytes.
1274         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1275         bool big_value = false;
1276         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1277           if (scope_field-&gt;is_location()) {
1278             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1279             if (type == Location::dbl || type == Location::lng) {
1280               big_value = true;
1281             }
1282           }
1283           if (scope_field-&gt;is_constant_int()) {
1284             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
1285             if (next_scope_field-&gt;is_constant_long() || next_scope_field-&gt;is_constant_double()) {
1286               big_value = true;
1287             }
1288           }
1289         }
1290 
1291         if (big_value) {
</pre>
<hr />
<pre>
1332       case T_BYTE:
1333         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1334         val = value-&gt;get_int();
1335         obj-&gt;byte_field_put(offset, (jbyte)*((jint*)&amp;val));
1336         break;
1337 
1338       case T_BOOLEAN:
1339         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1340         val = value-&gt;get_int();
1341         obj-&gt;bool_field_put(offset, (jboolean)*((jint*)&amp;val));
1342         break;
1343 
1344       default:
1345         ShouldNotReachHere();
1346     }
1347     svIndex++;
1348   }
1349   return svIndex;
1350 }
1351 














1352 // restore fields of all eliminated objects and arrays
<span class="line-modified">1353 void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures, bool skip_internal) {</span>
1354   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1355     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1356     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1357     Handle obj = sv-&gt;value();
1358     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);
1359     if (PrintDeoptimizationDetails) {
1360       tty-&gt;print_cr(&quot;reassign fields for object of type %s!&quot;, k-&gt;name()-&gt;as_C_string());
1361     }
1362     if (obj.is_null()) {
1363       continue;
1364     }
1365 #if INCLUDE_JVMCI || INCLUDE_AOT
1366     // Don&#39;t reassign fields of boxes that came from a cache. Caches may be in CDS.
1367     if (sv-&gt;is_auto_box() &amp;&amp; ((AutoBoxObjectValue*) sv)-&gt;is_cached()) {
1368       continue;
1369     }
1370 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1371     if (k-&gt;is_instance_klass()) {
1372       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1373       reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);</span>



1374     } else if (k-&gt;is_typeArray_klass()) {
1375       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1376       reassign_type_array_elements(fr, reg_map, sv, (typeArrayOop) obj(), ak-&gt;element_type());
1377     } else if (k-&gt;is_objArray_klass()) {
1378       reassign_object_array_elements(fr, reg_map, sv, (objArrayOop) obj());
1379     }
1380   }
1381 }
1382 
1383 
1384 // relock objects for which synchronization was eliminated
1385 void Deoptimization::relock_objects(GrowableArray&lt;MonitorInfo*&gt;* monitors, JavaThread* thread, bool realloc_failures) {
1386   for (int i = 0; i &lt; monitors-&gt;length(); i++) {
1387     MonitorInfo* mon_info = monitors-&gt;at(i);
1388     if (mon_info-&gt;eliminated()) {
1389       assert(!mon_info-&gt;owner_is_scalar_replaced() || realloc_failures, &quot;reallocation was missed&quot;);
1390       if (!mon_info-&gt;owner_is_scalar_replaced()) {
1391         Handle obj(thread, mon_info-&gt;owner());
1392         markWord mark = obj-&gt;mark();
1393         if (UseBiasedLocking &amp;&amp; mark.has_bias_pattern()) {
</pre>
<hr />
<pre>
1396           // where the thread-local object is bias locked to the current thread.
1397           assert(mark.is_biased_anonymously() ||
1398                  mark.biased_locker() == thread, &quot;should be locked to current thread&quot;);
1399           // Reset mark word to unbiased prototype.
1400           markWord unbiased_prototype = markWord::prototype().set_age(mark.age());
1401           obj-&gt;set_mark(unbiased_prototype);
1402         }
1403         BasicLock* lock = mon_info-&gt;lock();
1404         ObjectSynchronizer::enter(obj, lock, thread);
1405         assert(mon_info-&gt;owner()-&gt;is_locked(), &quot;object must be locked now&quot;);
1406       }
1407     }
1408   }
1409 }
1410 
1411 
1412 #ifndef PRODUCT
1413 // print information about reallocated objects
1414 void Deoptimization::print_objects(GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures) {
1415   fieldDescriptor fd;
<span class="line-removed">1416 </span>
1417   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1418     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1419     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
<span class="line-modified">1420     Handle obj = sv-&gt;value();</span>


1421 
<span class="line-modified">1422     tty-&gt;print(&quot;     object &lt;&quot; INTPTR_FORMAT &quot;&gt; of type &quot;, p2i(sv-&gt;value()()));</span>
<span class="line-modified">1423     k-&gt;print_value();</span>
<span class="line-modified">1424     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);</span>
<span class="line-modified">1425     if (obj.is_null()) {</span>
<span class="line-modified">1426       tty-&gt;print(&quot; allocation failed&quot;);</span>
<span class="line-modified">1427     } else {</span>
<span class="line-modified">1428       tty-&gt;print(&quot; allocated (%d bytes)&quot;, obj-&gt;size() * HeapWordSize);</span>
<span class="line-modified">1429     }</span>
<span class="line-modified">1430     tty-&gt;cr();</span>

1431 
<span class="line-modified">1432     if (Verbose &amp;&amp; !obj.is_null()) {</span>
<span class="line-modified">1433       k-&gt;oop_print_on(obj(), tty);</span>
<span class="line-removed">1434     }</span>
1435   }
1436 }
1437 #endif
1438 #endif // COMPILER2_OR_JVMCI
1439 
1440 vframeArray* Deoptimization::create_vframeArray(JavaThread* thread, frame fr, RegisterMap *reg_map, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
1441   Events::log_deopt_message(thread, &quot;DEOPT PACKING pc=&quot; INTPTR_FORMAT &quot; sp=&quot; INTPTR_FORMAT, p2i(fr.pc()), p2i(fr.sp()));
1442 
1443 #ifndef PRODUCT
1444   if (PrintDeoptimizationDetails) {
1445     ttyLocker ttyl;
1446     tty-&gt;print(&quot;DEOPT PACKING thread &quot; INTPTR_FORMAT &quot; &quot;, p2i(thread));
1447     fr.print_on(tty);
1448     tty-&gt;print_cr(&quot;     Virtual frames (innermost first):&quot;);
1449     for (int index = 0; index &lt; chunk-&gt;length(); index++) {
1450       compiledVFrame* vf = chunk-&gt;at(index);
1451       tty-&gt;print(&quot;       %2d - &quot;, index);
1452       vf-&gt;print_value();
1453       int bci = chunk-&gt;at(index)-&gt;raw_bci();
1454       const char* code_name;
</pre>
<hr />
<pre>
1587 
1588     ttyLocker ttyl;
1589     xtty-&gt;begin_head(&quot;deoptimized thread=&#39;&quot; UINTX_FORMAT &quot;&#39; reason=&#39;%s&#39; pc=&#39;&quot; INTPTR_FORMAT &quot;&#39;&quot;,(uintx)thread-&gt;osthread()-&gt;thread_id(), trap_reason_name(reason), p2i(fr.pc()));
1590     cm-&gt;log_identity(xtty);
1591     xtty-&gt;end_head();
1592     for (ScopeDesc* sd = cm-&gt;scope_desc_at(fr.pc()); ; sd = sd-&gt;sender()) {
1593       xtty-&gt;begin_elem(&quot;jvms bci=&#39;%d&#39;&quot;, sd-&gt;bci());
1594       xtty-&gt;method(sd-&gt;method());
1595       xtty-&gt;end_elem();
1596       if (sd-&gt;is_top())  break;
1597     }
1598     xtty-&gt;tail(&quot;deoptimized&quot;);
1599   }
1600 
1601   // Patch the compiled method so that when execution returns to it we will
1602   // deopt the execution state and return to the interpreter.
1603   fr.deoptimize(thread);
1604 }
1605 
1606 void Deoptimization::deoptimize(JavaThread* thread, frame fr, DeoptReason reason) {
<span class="line-modified">1607   // Deoptimize only if the frame comes from compile code.</span>
1608   // Do not deoptimize the frame which is already patched
1609   // during the execution of the loops below.
1610   if (!fr.is_compiled_frame() || fr.is_deoptimized_frame()) {
1611     return;
1612   }
1613   ResourceMark rm;
1614   DeoptimizationMarker dm;
1615   deoptimize_single_frame(thread, fr, reason);
1616 }
1617 
1618 #if INCLUDE_JVMCI
1619 address Deoptimization::deoptimize_for_missing_exception_handler(CompiledMethod* cm) {
1620   // there is no exception handler for this pc =&gt; deoptimize
1621   cm-&gt;make_not_entrant();
1622 
1623   // Use Deoptimization::deoptimize for all of its side-effects:
1624   // gathering traps statistics, logging...
1625   // it also patches the return pc but we do not care about that
1626   // since we return a continuation to the deopt_blob below.
1627   JavaThread* thread = JavaThread::current();
</pre>
</td>
<td>
<hr />
<pre>
  32 #include &quot;code/codeCache.hpp&quot;
  33 #include &quot;code/debugInfoRec.hpp&quot;
  34 #include &quot;code/nmethod.hpp&quot;
  35 #include &quot;code/pcDesc.hpp&quot;
  36 #include &quot;code/scopeDesc.hpp&quot;
  37 #include &quot;compiler/compilationPolicy.hpp&quot;
  38 #include &quot;interpreter/bytecode.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;interpreter/oopMapCache.hpp&quot;
  41 #include &quot;memory/allocation.inline.hpp&quot;
  42 #include &quot;memory/oopFactory.hpp&quot;
  43 #include &quot;memory/resourceArea.hpp&quot;
  44 #include &quot;memory/universe.hpp&quot;
  45 #include &quot;oops/constantPool.hpp&quot;
  46 #include &quot;oops/method.hpp&quot;
  47 #include &quot;oops/objArrayKlass.hpp&quot;
  48 #include &quot;oops/objArrayOop.inline.hpp&quot;
  49 #include &quot;oops/oop.inline.hpp&quot;
  50 #include &quot;oops/fieldStreams.inline.hpp&quot;
  51 #include &quot;oops/typeArrayOop.inline.hpp&quot;
<span class="line-added">  52 #include &quot;oops/valueArrayKlass.hpp&quot;</span>
<span class="line-added">  53 #include &quot;oops/valueArrayOop.hpp&quot;</span>
<span class="line-added">  54 #include &quot;oops/valueKlass.inline.hpp&quot;</span>
  55 #include &quot;oops/verifyOopClosure.hpp&quot;
  56 #include &quot;prims/jvmtiThreadState.hpp&quot;
  57 #include &quot;runtime/atomic.hpp&quot;
  58 #include &quot;runtime/biasedLocking.hpp&quot;
  59 #include &quot;runtime/deoptimization.hpp&quot;
  60 #include &quot;runtime/fieldDescriptor.hpp&quot;
  61 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  62 #include &quot;runtime/frame.inline.hpp&quot;
  63 #include &quot;runtime/handles.inline.hpp&quot;
  64 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  65 #include &quot;runtime/jniHandles.inline.hpp&quot;
  66 #include &quot;runtime/safepointVerifiers.hpp&quot;
  67 #include &quot;runtime/sharedRuntime.hpp&quot;
  68 #include &quot;runtime/signature.hpp&quot;
  69 #include &quot;runtime/stubRoutines.hpp&quot;
  70 #include &quot;runtime/thread.hpp&quot;
  71 #include &quot;runtime/threadSMR.hpp&quot;
  72 #include &quot;runtime/vframe.hpp&quot;
  73 #include &quot;runtime/vframeArray.hpp&quot;
  74 #include &quot;runtime/vframe_hp.hpp&quot;
</pre>
<hr />
<pre>
 168   return fetch_unroll_info_helper(thread, exec_mode);
 169 JRT_END
 170 
 171 #if COMPILER2_OR_JVMCI
 172 static bool eliminate_allocations(JavaThread* thread, int exec_mode, CompiledMethod* compiled_method,
 173                                   frame&amp; deoptee, RegisterMap&amp; map, GrowableArray&lt;compiledVFrame*&gt;* chunk) {
 174   bool realloc_failures = false;
 175   assert (chunk-&gt;at(0)-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 176 
 177   GrowableArray&lt;ScopeValue*&gt;* objects = chunk-&gt;at(0)-&gt;scope()-&gt;objects();
 178 
 179   // The flag return_oop() indicates call sites which return oop
 180   // in compiled code. Such sites include java method calls,
 181   // runtime calls (for example, used to allocate new objects/arrays
 182   // on slow code path) and any other calls generated in compiled code.
 183   // It is not guaranteed that we can get such information here only
 184   // by analyzing bytecode in deoptimized frames. This is why this flag
 185   // is set during method compilation (see Compile::Process_OopMap_Node()).
 186   // If the previous frame was popped or if we are dispatching an exception,
 187   // we don&#39;t have an oop result.
<span class="line-modified"> 188   ScopeDesc* scope = chunk-&gt;at(0)-&gt;scope();</span>
<span class="line-modified"> 189   bool save_oop_result = scope-&gt;return_oop() &amp;&amp; !thread-&gt;popframe_forcing_deopt_reexecution() &amp;&amp; (exec_mode == Deoptimization::Unpack_deopt);</span>
<span class="line-added"> 190   // In case of the return of multiple values, we must take care</span>
<span class="line-added"> 191   // of all oop return values.</span>
<span class="line-added"> 192   GrowableArray&lt;Handle&gt; return_oops;</span>
<span class="line-added"> 193   ValueKlass* vk = NULL;</span>
<span class="line-added"> 194   if (save_oop_result &amp;&amp; scope-&gt;return_vt()) {</span>
<span class="line-added"> 195     vk = ValueKlass::returned_value_klass(map);</span>
<span class="line-added"> 196     if (vk != NULL) {</span>
<span class="line-added"> 197       vk-&gt;save_oop_fields(map, return_oops);</span>
<span class="line-added"> 198       save_oop_result = false;</span>
<span class="line-added"> 199     }</span>
<span class="line-added"> 200   }</span>
 201   if (save_oop_result) {
 202     // Reallocation may trigger GC. If deoptimization happened on return from
 203     // call which returns oop we need to save it since it is not in oopmap.
 204     oop result = deoptee.saved_oop_result(&amp;map);
 205     assert(oopDesc::is_oop_or_null(result), &quot;must be oop&quot;);
<span class="line-modified"> 206     return_oops.push(Handle(thread, result));</span>
 207     assert(Universe::heap()-&gt;is_in_or_null(result), &quot;must be heap pointer&quot;);
 208     if (TraceDeoptimization) {
 209       ttyLocker ttyl;
 210       tty-&gt;print_cr(&quot;SAVED OOP RESULT &quot; INTPTR_FORMAT &quot; in thread &quot; INTPTR_FORMAT, p2i(result), p2i(thread));
 211     }
 212   }
<span class="line-modified"> 213   if (objects != NULL || vk != NULL) {</span>
<span class="line-added"> 214     bool skip_internal = (compiled_method != NULL) &amp;&amp; !compiled_method-&gt;is_compiled_by_jvmci();</span>
 215     JRT_BLOCK
<span class="line-modified"> 216       if (vk != NULL) {</span>
<span class="line-added"> 217         realloc_failures = Deoptimization::realloc_value_type_result(vk, map, return_oops, THREAD);</span>
<span class="line-added"> 218       }</span>
<span class="line-added"> 219       if (objects != NULL) {</span>
<span class="line-added"> 220         realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);</span>
<span class="line-added"> 221         Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal, THREAD);</span>
<span class="line-added"> 222       }</span>
 223     JRT_END


 224 #ifndef PRODUCT
 225     if (TraceDeoptimization) {
 226       ttyLocker ttyl;
 227       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
<span class="line-modified"> 228       if (objects != NULL) {</span>
<span class="line-added"> 229         Deoptimization::print_objects(objects, realloc_failures);</span>
<span class="line-added"> 230       } else {</span>
<span class="line-added"> 231         Handle obj = realloc_failures ? Handle() : return_oops.first();</span>
<span class="line-added"> 232         Deoptimization::print_object(vk, obj, realloc_failures);</span>
<span class="line-added"> 233       }</span>
 234     }
 235 #endif
 236   }
<span class="line-modified"> 237   if (save_oop_result || vk != NULL) {</span>
 238     // Restore result.
<span class="line-modified"> 239     assert(return_oops.length() == 1, &quot;no value type&quot;);</span>
<span class="line-added"> 240     deoptee.set_saved_oop_result(&amp;map, return_oops.pop()());</span>
 241   }
 242   return realloc_failures;
 243 }
 244 
 245 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 246 #ifndef PRODUCT
 247   bool first = true;
 248 #endif
 249   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 250     compiledVFrame* cvf = chunk-&gt;at(i);
 251     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 252     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 253     if (monitors-&gt;is_nonempty()) {
 254       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 255 #ifndef PRODUCT
 256       if (PrintDeoptimizationDetails) {
 257         ttyLocker ttyl;
 258         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 259           MonitorInfo* mi = monitors-&gt;at(j);
 260           if (mi-&gt;eliminated()) {
</pre>
<hr />
<pre>
 521   // its caller&#39;s stack by. If the caller is a compiled frame then
 522   // we pretend that the callee has no parameters so that the
 523   // extension counts for the full amount of locals and not just
 524   // locals-parms. This is because without a c2i adapter the parm
 525   // area as created by the compiled frame will not be usable by
 526   // the interpreter. (Depending on the calling convention there
 527   // may not even be enough space).
 528 
 529   // QQQ I&#39;d rather see this pushed down into last_frame_adjust
 530   // and have it take the sender (aka caller).
 531 
 532   if (deopt_sender.is_compiled_frame() || caller_was_method_handle) {
 533     caller_adjustment = last_frame_adjust(0, callee_locals);
 534   } else if (callee_locals &gt; callee_parameters) {
 535     // The caller frame may need extending to accommodate
 536     // non-parameter locals of the first unpacked interpreted frame.
 537     // Compute that adjustment.
 538     caller_adjustment = last_frame_adjust(callee_parameters, callee_locals);
 539   }
 540 
<span class="line-modified"> 541   // If the sender is deoptimized we must retrieve the address of the handler</span>
 542   // since the frame will &quot;magically&quot; show the original pc before the deopt
 543   // and we&#39;d undo the deopt.
 544 
 545   frame_pcs[0] = deopt_sender.raw_pc();
 546 
 547   assert(CodeCache::find_blob_unsafe(frame_pcs[0]) != NULL, &quot;bad pc&quot;);
 548 
 549 #if INCLUDE_JVMCI
 550   if (exceptionObject() != NULL) {
 551     thread-&gt;set_exception_oop(exceptionObject());
 552     exec_mode = Unpack_exception;
 553   }
 554 #endif
 555 
 556   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0 &amp;&amp; exec_mode != Unpack_uncommon_trap) {
 557     assert(thread-&gt;has_pending_exception(), &quot;should have thrown OOME&quot;);
 558     thread-&gt;set_exception_oop(thread-&gt;pending_exception());
 559     thread-&gt;clear_pending_exception();
 560     exec_mode = Unpack_exception;
 561   }
</pre>
<hr />
<pre>
1012 
1013     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1014     oop obj = NULL;
1015 
1016     if (k-&gt;is_instance_klass()) {
1017 #if INCLUDE_JVMCI || INCLUDE_AOT
1018       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
1019       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
1020         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
1021         obj = get_cached_box(abv, fr, reg_map, THREAD);
1022         if (obj != NULL) {
1023           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
1024           abv-&gt;set_cached(true);
1025         }
1026       }
1027 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1028       InstanceKlass* ik = InstanceKlass::cast(k);
1029       if (obj == NULL) {
1030         obj = ik-&gt;allocate_instance(THREAD);
1031       }
<span class="line-added">1032     } else if (k-&gt;is_valueArray_klass()) {</span>
<span class="line-added">1033       ValueArrayKlass* ak = ValueArrayKlass::cast(k);</span>
<span class="line-added">1034       // Value type array must be zeroed because not all memory is reassigned</span>
<span class="line-added">1035       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);</span>
1036     } else if (k-&gt;is_typeArray_klass()) {
1037       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1038       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1039       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1040       obj = ak-&gt;allocate(len, THREAD);
1041     } else if (k-&gt;is_objArray_klass()) {
1042       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1043       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1044     }
1045 
1046     if (obj == NULL) {
1047       failures = true;
1048     }
1049 
1050     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1051     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1052     CLEAR_PENDING_EXCEPTION;
1053     sv-&gt;set_value(obj);
1054   }
1055 
1056   if (failures) {
1057     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), failures);
1058   } else if (pending_exception.not_null()) {
1059     thread-&gt;set_pending_exception(pending_exception(), exception_file, exception_line);
1060   }
1061 
1062   return failures;
1063 }
1064 
<span class="line-added">1065 // We&#39;re deoptimizing at the return of a call, value type fields are</span>
<span class="line-added">1066 // in registers. When we go back to the interpreter, it will expect a</span>
<span class="line-added">1067 // reference to a value type instance. Allocate and initialize it from</span>
<span class="line-added">1068 // the register values here.</span>
<span class="line-added">1069 bool Deoptimization::realloc_value_type_result(ValueKlass* vk, const RegisterMap&amp; map, GrowableArray&lt;Handle&gt;&amp; return_oops, TRAPS) {</span>
<span class="line-added">1070   oop new_vt = vk-&gt;realloc_result(map, return_oops, THREAD);</span>
<span class="line-added">1071   if (new_vt == NULL) {</span>
<span class="line-added">1072     CLEAR_PENDING_EXCEPTION;</span>
<span class="line-added">1073     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);</span>
<span class="line-added">1074   }</span>
<span class="line-added">1075   return_oops.clear();</span>
<span class="line-added">1076   return_oops.push(Handle(THREAD, new_vt));</span>
<span class="line-added">1077   return false;</span>
<span class="line-added">1078 }</span>
<span class="line-added">1079 </span>
1080 #if INCLUDE_JVMCI
1081 /**
1082  * For primitive types whose kind gets &quot;erased&quot; at runtime (shorts become stack ints),
1083  * we need to somehow be able to recover the actual kind to be able to write the correct
1084  * amount of bytes.
1085  * For that purpose, this method assumes that, for an entry spanning n bytes at index i,
1086  * the entries at index n + 1 to n + i are &#39;markers&#39;.
1087  * For example, if we were writing a short at index 4 of a byte array of size 8, the
1088  * expected form of the array would be:
1089  *
1090  * {b0, b1, b2, b3, INT, marker, b6, b7}
1091  *
1092  * Thus, in order to get back the size of the entry, we simply need to count the number
1093  * of marked entries
1094  *
1095  * @param virtualArray the virtualized byte array
1096  * @param i index of the virtual entry we are recovering
1097  * @return The number of bytes the entry spans
1098  */
1099 static int count_number_of_bytes_for_entry(ObjectValue *virtualArray, int i) {
</pre>
<hr />
<pre>
1256       default:
1257         ShouldNotReachHere();
1258     }
1259     index++;
1260   }
1261 }
1262 
1263 // restore fields of an eliminated object array
1264 void Deoptimization::reassign_object_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, objArrayOop obj) {
1265   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {
1266     StackValue* value = StackValue::create_stack_value(fr, reg_map, sv-&gt;field_at(i));
1267     assert(value-&gt;type() == T_OBJECT, &quot;object element expected&quot;);
1268     obj-&gt;obj_at_put(i, value-&gt;get_obj()());
1269   }
1270 }
1271 
1272 class ReassignedField {
1273 public:
1274   int _offset;
1275   BasicType _type;
<span class="line-added">1276   InstanceKlass* _klass;</span>
1277 public:
1278   ReassignedField() {
1279     _offset = 0;
1280     _type = T_ILLEGAL;
<span class="line-added">1281     _klass = NULL;</span>
1282   }
1283 };
1284 
1285 int compare(ReassignedField* left, ReassignedField* right) {
1286   return left-&gt;_offset - right-&gt;_offset;
1287 }
1288 
1289 // Restore fields of an eliminated instance object using the same field order
1290 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
<span class="line-modified">1291 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {</span>
<span class="line-added">1292 </span>
1293   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1294   InstanceKlass* ik = klass;
1295   while (ik != NULL) {
1296     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1297       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1298         ReassignedField field;
1299         field._offset = fs.offset();
1300         field._type = Signature::basic_type(fs.signature());
<span class="line-added">1301         if (field._type == T_VALUETYPE) {</span>
<span class="line-added">1302           field._type = T_OBJECT;</span>
<span class="line-added">1303         }</span>
<span class="line-added">1304         if (fs.is_flattened()) {</span>
<span class="line-added">1305           // Resolve klass of flattened value type field</span>
<span class="line-added">1306           Klass* vk = klass-&gt;get_value_field_klass(fs.index());</span>
<span class="line-added">1307           field._klass = ValueKlass::cast(vk);</span>
<span class="line-added">1308           field._type = T_VALUETYPE;</span>
<span class="line-added">1309         }</span>
1310         fields-&gt;append(field);
1311       }
1312     }
1313     ik = ik-&gt;superklass();
1314   }
1315   fields-&gt;sort(compare);
1316   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1317     intptr_t val;
1318     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1319     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
<span class="line-modified">1320     int offset = base_offset + fields-&gt;at(i)._offset;</span>
1321     BasicType type = fields-&gt;at(i)._type;
1322     switch (type) {
<span class="line-modified">1323       case T_OBJECT:</span>
<span class="line-added">1324       case T_ARRAY:</span>
1325         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1326         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1327         break;
1328 
<span class="line-added">1329       case T_VALUETYPE: {</span>
<span class="line-added">1330         // Recursively re-assign flattened value type fields</span>
<span class="line-added">1331         InstanceKlass* vk = fields-&gt;at(i)._klass;</span>
<span class="line-added">1332         assert(vk != NULL, &quot;must be resolved&quot;);</span>
<span class="line-added">1333         offset -= ValueKlass::cast(vk)-&gt;first_field_offset(); // Adjust offset to omit oop header</span>
<span class="line-added">1334         svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);</span>
<span class="line-added">1335         continue; // Continue because we don&#39;t need to increment svIndex</span>
<span class="line-added">1336       }</span>
<span class="line-added">1337 </span>
1338       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1339       case T_INT: case T_FLOAT: { // 4 bytes.
1340         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1341         bool big_value = false;
1342         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1343           if (scope_field-&gt;is_location()) {
1344             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1345             if (type == Location::dbl || type == Location::lng) {
1346               big_value = true;
1347             }
1348           }
1349           if (scope_field-&gt;is_constant_int()) {
1350             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
1351             if (next_scope_field-&gt;is_constant_long() || next_scope_field-&gt;is_constant_double()) {
1352               big_value = true;
1353             }
1354           }
1355         }
1356 
1357         if (big_value) {
</pre>
<hr />
<pre>
1398       case T_BYTE:
1399         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1400         val = value-&gt;get_int();
1401         obj-&gt;byte_field_put(offset, (jbyte)*((jint*)&amp;val));
1402         break;
1403 
1404       case T_BOOLEAN:
1405         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1406         val = value-&gt;get_int();
1407         obj-&gt;bool_field_put(offset, (jboolean)*((jint*)&amp;val));
1408         break;
1409 
1410       default:
1411         ShouldNotReachHere();
1412     }
1413     svIndex++;
1414   }
1415   return svIndex;
1416 }
1417 
<span class="line-added">1418 // restore fields of an eliminated value type array</span>
<span class="line-added">1419 void Deoptimization::reassign_value_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, valueArrayOop obj, ValueArrayKlass* vak, TRAPS) {</span>
<span class="line-added">1420   ValueKlass* vk = vak-&gt;element_klass();</span>
<span class="line-added">1421   assert(vk-&gt;flatten_array(), &quot;should only be used for flattened value type arrays&quot;);</span>
<span class="line-added">1422   // Adjust offset to omit oop header</span>
<span class="line-added">1423   int base_offset = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE) - ValueKlass::cast(vk)-&gt;first_field_offset();</span>
<span class="line-added">1424   // Initialize all elements of the flattened value type array</span>
<span class="line-added">1425   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {</span>
<span class="line-added">1426     ScopeValue* val = sv-&gt;field_at(i);</span>
<span class="line-added">1427     int offset = base_offset + (i &lt;&lt; Klass::layout_helper_log2_element_size(vak-&gt;layout_helper()));</span>
<span class="line-added">1428     reassign_fields_by_klass(vk, fr, reg_map, val-&gt;as_ObjectValue(), 0, (oop)obj, false /* skip_internal */, offset, CHECK);</span>
<span class="line-added">1429   }</span>
<span class="line-added">1430 }</span>
<span class="line-added">1431 </span>
1432 // restore fields of all eliminated objects and arrays
<span class="line-modified">1433 void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures, bool skip_internal, TRAPS) {</span>
1434   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1435     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1436     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1437     Handle obj = sv-&gt;value();
1438     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);
1439     if (PrintDeoptimizationDetails) {
1440       tty-&gt;print_cr(&quot;reassign fields for object of type %s!&quot;, k-&gt;name()-&gt;as_C_string());
1441     }
1442     if (obj.is_null()) {
1443       continue;
1444     }
1445 #if INCLUDE_JVMCI || INCLUDE_AOT
1446     // Don&#39;t reassign fields of boxes that came from a cache. Caches may be in CDS.
1447     if (sv-&gt;is_auto_box() &amp;&amp; ((AutoBoxObjectValue*) sv)-&gt;is_cached()) {
1448       continue;
1449     }
1450 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1451     if (k-&gt;is_instance_klass()) {
1452       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1453       reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);</span>
<span class="line-added">1454     } else if (k-&gt;is_valueArray_klass()) {</span>
<span class="line-added">1455       ValueArrayKlass* vak = ValueArrayKlass::cast(k);</span>
<span class="line-added">1456       reassign_value_array_elements(fr, reg_map, sv, (valueArrayOop) obj(), vak, CHECK);</span>
1457     } else if (k-&gt;is_typeArray_klass()) {
1458       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1459       reassign_type_array_elements(fr, reg_map, sv, (typeArrayOop) obj(), ak-&gt;element_type());
1460     } else if (k-&gt;is_objArray_klass()) {
1461       reassign_object_array_elements(fr, reg_map, sv, (objArrayOop) obj());
1462     }
1463   }
1464 }
1465 
1466 
1467 // relock objects for which synchronization was eliminated
1468 void Deoptimization::relock_objects(GrowableArray&lt;MonitorInfo*&gt;* monitors, JavaThread* thread, bool realloc_failures) {
1469   for (int i = 0; i &lt; monitors-&gt;length(); i++) {
1470     MonitorInfo* mon_info = monitors-&gt;at(i);
1471     if (mon_info-&gt;eliminated()) {
1472       assert(!mon_info-&gt;owner_is_scalar_replaced() || realloc_failures, &quot;reallocation was missed&quot;);
1473       if (!mon_info-&gt;owner_is_scalar_replaced()) {
1474         Handle obj(thread, mon_info-&gt;owner());
1475         markWord mark = obj-&gt;mark();
1476         if (UseBiasedLocking &amp;&amp; mark.has_bias_pattern()) {
</pre>
<hr />
<pre>
1479           // where the thread-local object is bias locked to the current thread.
1480           assert(mark.is_biased_anonymously() ||
1481                  mark.biased_locker() == thread, &quot;should be locked to current thread&quot;);
1482           // Reset mark word to unbiased prototype.
1483           markWord unbiased_prototype = markWord::prototype().set_age(mark.age());
1484           obj-&gt;set_mark(unbiased_prototype);
1485         }
1486         BasicLock* lock = mon_info-&gt;lock();
1487         ObjectSynchronizer::enter(obj, lock, thread);
1488         assert(mon_info-&gt;owner()-&gt;is_locked(), &quot;object must be locked now&quot;);
1489       }
1490     }
1491   }
1492 }
1493 
1494 
1495 #ifndef PRODUCT
1496 // print information about reallocated objects
1497 void Deoptimization::print_objects(GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures) {
1498   fieldDescriptor fd;

1499   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1500     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1501     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
<span class="line-modified">1502     print_object(k, sv-&gt;value(), realloc_failures);</span>
<span class="line-added">1503   }</span>
<span class="line-added">1504 }</span>
1505 
<span class="line-modified">1506 void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {</span>
<span class="line-modified">1507   tty-&gt;print(&quot;     object &lt;&quot; INTPTR_FORMAT &quot;&gt; of type &quot;, p2i(obj()));</span>
<span class="line-modified">1508   k-&gt;print_value();</span>
<span class="line-modified">1509   assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);</span>
<span class="line-modified">1510   if (obj.is_null()) {</span>
<span class="line-modified">1511     tty-&gt;print(&quot; allocation failed&quot;);</span>
<span class="line-modified">1512   } else {</span>
<span class="line-modified">1513     tty-&gt;print(&quot; allocated (%d bytes)&quot;, obj-&gt;size() * HeapWordSize);</span>
<span class="line-modified">1514   }</span>
<span class="line-added">1515   tty-&gt;cr();</span>
1516 
<span class="line-modified">1517   if (Verbose &amp;&amp; !obj.is_null()) {</span>
<span class="line-modified">1518     k-&gt;oop_print_on(obj(), tty);</span>

1519   }
1520 }
1521 #endif
1522 #endif // COMPILER2_OR_JVMCI
1523 
1524 vframeArray* Deoptimization::create_vframeArray(JavaThread* thread, frame fr, RegisterMap *reg_map, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
1525   Events::log_deopt_message(thread, &quot;DEOPT PACKING pc=&quot; INTPTR_FORMAT &quot; sp=&quot; INTPTR_FORMAT, p2i(fr.pc()), p2i(fr.sp()));
1526 
1527 #ifndef PRODUCT
1528   if (PrintDeoptimizationDetails) {
1529     ttyLocker ttyl;
1530     tty-&gt;print(&quot;DEOPT PACKING thread &quot; INTPTR_FORMAT &quot; &quot;, p2i(thread));
1531     fr.print_on(tty);
1532     tty-&gt;print_cr(&quot;     Virtual frames (innermost first):&quot;);
1533     for (int index = 0; index &lt; chunk-&gt;length(); index++) {
1534       compiledVFrame* vf = chunk-&gt;at(index);
1535       tty-&gt;print(&quot;       %2d - &quot;, index);
1536       vf-&gt;print_value();
1537       int bci = chunk-&gt;at(index)-&gt;raw_bci();
1538       const char* code_name;
</pre>
<hr />
<pre>
1671 
1672     ttyLocker ttyl;
1673     xtty-&gt;begin_head(&quot;deoptimized thread=&#39;&quot; UINTX_FORMAT &quot;&#39; reason=&#39;%s&#39; pc=&#39;&quot; INTPTR_FORMAT &quot;&#39;&quot;,(uintx)thread-&gt;osthread()-&gt;thread_id(), trap_reason_name(reason), p2i(fr.pc()));
1674     cm-&gt;log_identity(xtty);
1675     xtty-&gt;end_head();
1676     for (ScopeDesc* sd = cm-&gt;scope_desc_at(fr.pc()); ; sd = sd-&gt;sender()) {
1677       xtty-&gt;begin_elem(&quot;jvms bci=&#39;%d&#39;&quot;, sd-&gt;bci());
1678       xtty-&gt;method(sd-&gt;method());
1679       xtty-&gt;end_elem();
1680       if (sd-&gt;is_top())  break;
1681     }
1682     xtty-&gt;tail(&quot;deoptimized&quot;);
1683   }
1684 
1685   // Patch the compiled method so that when execution returns to it we will
1686   // deopt the execution state and return to the interpreter.
1687   fr.deoptimize(thread);
1688 }
1689 
1690 void Deoptimization::deoptimize(JavaThread* thread, frame fr, DeoptReason reason) {
<span class="line-modified">1691   // Deoptimize only if the frame comes from compiled code.</span>
1692   // Do not deoptimize the frame which is already patched
1693   // during the execution of the loops below.
1694   if (!fr.is_compiled_frame() || fr.is_deoptimized_frame()) {
1695     return;
1696   }
1697   ResourceMark rm;
1698   DeoptimizationMarker dm;
1699   deoptimize_single_frame(thread, fr, reason);
1700 }
1701 
1702 #if INCLUDE_JVMCI
1703 address Deoptimization::deoptimize_for_missing_exception_handler(CompiledMethod* cm) {
1704   // there is no exception handler for this pc =&gt; deoptimize
1705   cm-&gt;make_not_entrant();
1706 
1707   // Use Deoptimization::deoptimize for all of its side-effects:
1708   // gathering traps statistics, logging...
1709   // it also patches the return pc but we do not care about that
1710   // since we return a continuation to the deopt_blob below.
1711   JavaThread* thread = JavaThread::current();
</pre>
</td>
</tr>
</table>
<center><a href="arguments.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../../../../test/hotspot/jtreg/ProblemList.txt.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>