diff a/.hgtags b/.hgtags
--- a/.hgtags
+++ b/.hgtags
@@ -640,5 +640,7 @@
 12b55fad80f30d24b1f8fdb3b947ea6465ef9518 jdk-15+21
 7223c6d610343fd8323af9d07d501e01fa1a7696 jdk-15+22
 f143729ca00ec14a98ea5c7f73acba88da97746e jdk-15+23
 497fd9f9129c4928fd5a876dd55e0daf6298b511 jdk-15+24
 58833044988772ca06c97ab2f142474a8627af80 jdk-15+25
+58833044988772ca06c97ab2f142474a8627af80 jdk-15+25
+90b266a84c06f1b3dc0ed8767856793e8c1c357e jdk-15+25
diff a/make/data/jdwp/jdwp.spec b/make/data/jdwp/jdwp.spec
--- a/make/data/jdwp/jdwp.spec
+++ b/make/data/jdwp/jdwp.spec
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -3158,12 +3158,12 @@
                                           "different modifiers "
                                           "than its counterpart in the old class version and "
                                           "canUnrestrictedlyRedefineClasses is false.")
     (Constant CLASS_ATTRIBUTE_CHANGE_NOT_IMPLEMENTED
                                      =72  "The new class version has a different NestHost, "
-                                          "NestMembers, or Record class attribute and "
-                                          "canUnrestrictedlyRedefineClasses is false.")
+                                          "NestMembers, PermittedSubclasses, or Record class attribute "
+                                          "and canUnrestrictedlyRedefineClasses is false.")
     (Constant NOT_IMPLEMENTED        =99  "The functionality is not implemented in "
                                           "this virtual machine.")
     (Constant NULL_POINTER           =100 "Invalid pointer.")
     (Constant ABSENT_INFORMATION     =101 "Desired information is not available.")
     (Constant INVALID_EVENT_TYPE     =102 "The specified event type id is not recognized.")
diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -15323,11 +15323,11 @@
   ins_cost(CALL_COST);
   format %{ "ShouldNotReachHere" %}
 
   ins_encode %{
     if (is_reachable()) {
-      __ dcps1(0xdead + 1);
+      __ stop(_halt_reason);
     }
   %}
 
   ins_pipe(pipe_class_default);
 %}
diff a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
@@ -470,11 +470,11 @@
       right.load_item();
     }
     if (need_zero_check) {
       CodeEmitInfo* info = state_for(x);
       __ cmp(lir_cond_equal, right.result(), LIR_OprFact::longConst(0));
-      __ branch(lir_cond_equal, T_LONG, new DivByZeroStub(info));
+      __ branch(lir_cond_equal, new DivByZeroStub(info));
     }
 
     rlock_result(x);
     switch (x->op()) {
     case Bytecodes::_lrem:
@@ -545,11 +545,11 @@
       right_arg->load_item();
     }
     if (need_zero_check) {
       CodeEmitInfo* info = state_for(x);
       __ cmp(lir_cond_equal, right_arg->result(), LIR_OprFact::longConst(0));
-      __ branch(lir_cond_equal, T_INT, new DivByZeroStub(info));
+      __ branch(lir_cond_equal, new DivByZeroStub(info));
     }
 
     LIR_Opr ill = LIR_OprFact::illegalOpr;
     if (x->op() == Bytecodes::_irem) {
       __ irem(left_arg->result(), right_arg->result(), x->operand(), ill, NULL);
@@ -1422,13 +1422,13 @@
   __ cmp(lir_cond(cond), left, right);
   // Generate branch profiling. Profiling code doesn't kill flags.
   profile_branch(x, cond);
   move_to_phi(x->state());
   if (x->x()->type()->is_float_kind()) {
-    __ branch(lir_cond(cond), right->type(), x->tsux(), x->usux());
+    __ branch(lir_cond(cond), x->tsux(), x->usux());
   } else {
-    __ branch(lir_cond(cond), right->type(), x->tsux());
+    __ branch(lir_cond(cond), x->tsux());
   }
   assert(x->default_sux() == x->fsux(), "wrong destination above");
   __ jump(x->default_sux());
 }
 
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -59,15 +59,13 @@
 #include "opto/output.hpp"
 #endif
 
 #ifdef PRODUCT
 #define BLOCK_COMMENT(str) /* nothing */
-#define STOP(error) stop(error)
 #else
 #define BLOCK_COMMENT(str) block_comment(str)
-#define STOP(error) block_comment(error); stop(error)
-#endif
+#endif
 
 #define BIND(label) bind(label); BLOCK_COMMENT(#label ":")
 
 // Patch any kind of instruction; there may be several instructions.
 // Return the total length (in bytes) of the instructions.
@@ -2267,26 +2265,13 @@
   verify_oop(value);
   bind(done);
 }
 
 void MacroAssembler::stop(const char* msg) {
-  address ip = pc();
-  pusha();
-  mov(c_rarg0, (address)msg);
-  mov(c_rarg1, (address)ip);
-  mov(c_rarg2, sp);
-  mov(c_rarg3, CAST_FROM_FN_PTR(address, MacroAssembler::debug64));
-  blr(c_rarg3);
-  hlt(0);
-}
-
-void MacroAssembler::warn(const char* msg) {
-  pusha();
-  mov(c_rarg0, (address)msg);
-  mov(lr, CAST_FROM_FN_PTR(address, warning));
-  blr(lr);
-  popa();
+  BLOCK_COMMENT(msg);
+  dcps1(0xdeae);
+  emit_int64((uintptr_t)msg);
 }
 
 void MacroAssembler::unimplemented(const char* what) {
   const char* buf = NULL;
   {
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
@@ -996,13 +996,10 @@
   void verify_FPU(int stack_depth, const char* s = "illegal FPU state");
 
   // prints msg, dumps registers and stops execution
   void stop(const char* msg);
 
-  // prints msg and continues
-  void warn(const char* msg);
-
   static void debug64(char* msg, int64_t pc, int64_t regs[]);
 
   void untested()                                { stop("untested"); }
 
   void unimplemented(const char* what = "");
diff a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
@@ -944,12 +944,11 @@
 
   // LR is live.  It must be saved around calls.
 
   address entry = __ pc();
 
-  const int referent_offset = java_lang_ref_Reference::referent_offset;
-  guarantee(referent_offset > 0, "referent offset not initialized");
+  const int referent_offset = java_lang_ref_Reference::referent_offset();
 
   Label slow_path;
   const Register local_0 = c_rarg0;
   // Check if local 0 != NULL
   // If the receiver is null then it is OK to jump to the slow path.
diff a/src/hotspot/cpu/x86/c1_CodeStubs_x86.cpp b/src/hotspot/cpu/x86/c1_CodeStubs_x86.cpp
--- a/src/hotspot/cpu/x86/c1_CodeStubs_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_CodeStubs_x86.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -453,11 +453,11 @@
     Register tmp2 = rbx;
     __ push(tmp);
     __ push(tmp2);
     // Load without verification to keep code size small. We need it because
     // begin_initialized_entry_offset has to fit in a byte. Also, we know it's not null.
-    __ movptr(tmp2, Address(_obj, java_lang_Class::klass_offset_in_bytes()));
+    __ movptr(tmp2, Address(_obj, java_lang_Class::klass_offset()));
     __ get_thread(tmp);
     __ cmpptr(tmp, Address(tmp2, InstanceKlass::init_thread_offset()));
     __ pop(tmp2);
     __ pop(tmp);
     __ jcc(Assembler::notEqual, call_patch);
diff a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
@@ -499,11 +499,11 @@
     right.load_item();
 
     __ move(right.result(), cc->at(0));
 
     __ cmp(lir_cond_equal, right.result(), LIR_OprFact::longConst(0));
-    __ branch(lir_cond_equal, T_LONG, new DivByZeroStub(info));
+    __ branch(lir_cond_equal, new DivByZeroStub(info));
 
     address entry = NULL;
     switch (x->op()) {
     case Bytecodes::_lrem:
       entry = CAST_FROM_FN_PTR(address, SharedRuntime::lrem);
@@ -583,11 +583,11 @@
       result_reg = remOutOpr();
     }
 
     if (!ImplicitDiv0Checks) {
       __ cmp(lir_cond_equal, right.result(), LIR_OprFact::intConst(0));
-      __ branch(lir_cond_equal, T_INT, new DivByZeroStub(info));
+      __ branch(lir_cond_equal, new DivByZeroStub(info));
       // Idiv/irem cannot trap (passing info would generate an assertion).
       info = NULL;
     }
     LIR_Opr tmp = FrameMap::rdx_opr; // idiv and irem use rdx in their implementation
     if (x->op() == Bytecodes::_irem) {
@@ -1548,13 +1548,13 @@
   }
   // Generate branch profiling. Profiling code doesn't kill flags.
   profile_branch(x, cond);
   move_to_phi(x->state());
   if (x->x()->type()->is_float_kind()) {
-    __ branch(lir_cond(cond), right->type(), x->tsux(), x->usux());
+    __ branch(lir_cond(cond), x->tsux(), x->usux());
   } else {
-    __ branch(lir_cond(cond), right->type(), x->tsux());
+    __ branch(lir_cond(cond), x->tsux());
   }
   assert(x->default_sux() == x->fsux(), "wrong destination above");
   __ jump(x->default_sux());
 }
 
diff a/src/hotspot/cpu/x86/c1_globals_x86.hpp b/src/hotspot/cpu/x86/c1_globals_x86.hpp
--- a/src/hotspot/cpu/x86/c1_globals_x86.hpp
+++ b/src/hotspot/cpu/x86/c1_globals_x86.hpp
@@ -58,11 +58,10 @@
 define_pd_global(uint64_t, MaxRAM,                    1ULL*G);
 define_pd_global(bool,   CICompileOSR,                 true );
 #endif // !TIERED
 define_pd_global(bool, UseTypeProfile,                 false);
 
-define_pd_global(bool, LIRFillDelaySlots,              false);
 define_pd_global(bool, OptimizeSinglePrecision,        true );
 define_pd_global(bool, CSEArrayLength,                 false);
 define_pd_global(bool, TwoOperandLIRForm,              true );
 
 #endif // CPU_X86_C1_GLOBALS_X86_HPP
diff a/src/hotspot/cpu/x86/methodHandles_x86.cpp b/src/hotspot/cpu/x86/methodHandles_x86.cpp
--- a/src/hotspot/cpu/x86/methodHandles_x86.cpp
+++ b/src/hotspot/cpu/x86/methodHandles_x86.cpp
@@ -51,11 +51,11 @@
 
 void MethodHandles::load_klass_from_Class(MacroAssembler* _masm, Register klass_reg) {
   if (VerifyMethodHandles)
     verify_klass(_masm, klass_reg, SystemDictionary::WK_KLASS_ENUM_NAME(java_lang_Class),
                  "MH argument is a Class");
-  __ movptr(klass_reg, Address(klass_reg, java_lang_Class::klass_offset_in_bytes()));
+  __ movptr(klass_reg, Address(klass_reg, java_lang_Class::klass_offset()));
 }
 
 #ifdef ASSERT
 static int check_nonzero(const char* xname, int x) {
   assert(x != 0, "%s should be nonzero", xname);
@@ -98,11 +98,11 @@
 }
 
 void MethodHandles::verify_ref_kind(MacroAssembler* _masm, int ref_kind, Register member_reg, Register temp) {
   Label L;
   BLOCK_COMMENT("verify_ref_kind {");
-  __ movl(temp, Address(member_reg, NONZERO(java_lang_invoke_MemberName::flags_offset_in_bytes())));
+  __ movl(temp, Address(member_reg, NONZERO(java_lang_invoke_MemberName::flags_offset())));
   __ shrl(temp, java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT);
   __ andl(temp, java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK);
   __ cmpl(temp, ref_kind);
   __ jcc(Assembler::equal, L);
   { char* buf = NEW_C_HEAP_ARRAY(char, 100, mtInternal);
@@ -173,18 +173,18 @@
 
   //NOT_PRODUCT({ FlagSetting fs(TraceMethodHandles, true); trace_method_handle(_masm, "LZMH"); });
 
   // Load the invoker, as MH -> MH.form -> LF.vmentry
   __ verify_oop(recv);
-  __ load_heap_oop(method_temp, Address(recv, NONZERO(java_lang_invoke_MethodHandle::form_offset_in_bytes())), temp2);
+  __ load_heap_oop(method_temp, Address(recv, NONZERO(java_lang_invoke_MethodHandle::form_offset())), temp2);
   __ verify_oop(method_temp);
-  __ load_heap_oop(method_temp, Address(method_temp, NONZERO(java_lang_invoke_LambdaForm::vmentry_offset_in_bytes())), temp2);
+  __ load_heap_oop(method_temp, Address(method_temp, NONZERO(java_lang_invoke_LambdaForm::vmentry_offset())), temp2);
   __ verify_oop(method_temp);
-  __ load_heap_oop(method_temp, Address(method_temp, NONZERO(java_lang_invoke_MemberName::method_offset_in_bytes())), temp2);
+  __ load_heap_oop(method_temp, Address(method_temp, NONZERO(java_lang_invoke_MemberName::method_offset())), temp2);
   __ verify_oop(method_temp);
   __ access_load_at(T_ADDRESS, IN_HEAP, method_temp,
-                    Address(method_temp, NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset_in_bytes())),
+                    Address(method_temp, NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset())),
                     noreg, noreg);
 
   if (VerifyMethodHandles && !for_compiler_entry) {
     // make sure recv is already on stack
     __ movptr(temp2, Address(method_temp, Method::const_offset()));
@@ -340,14 +340,14 @@
       // make sure the trailing argument really is a MemberName (caller responsibility)
       verify_klass(_masm, member_reg, SystemDictionary::WK_KLASS_ENUM_NAME(java_lang_invoke_MemberName),
                    "MemberName required for invokeVirtual etc.");
     }
 
-    Address member_clazz(    member_reg, NONZERO(java_lang_invoke_MemberName::clazz_offset_in_bytes()));
-    Address member_vmindex(  member_reg, NONZERO(java_lang_invoke_MemberName::vmindex_offset_in_bytes()));
-    Address member_vmtarget( member_reg, NONZERO(java_lang_invoke_MemberName::method_offset_in_bytes()));
-    Address vmtarget_method( rbx_method, NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset_in_bytes()));
+    Address member_clazz(    member_reg, NONZERO(java_lang_invoke_MemberName::clazz_offset()));
+    Address member_vmindex(  member_reg, NONZERO(java_lang_invoke_MemberName::vmindex_offset()));
+    Address member_vmtarget( member_reg, NONZERO(java_lang_invoke_MemberName::method_offset()));
+    Address vmtarget_method( rbx_method, NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset()));
 
     Register temp1_recv_klass = temp1;
     if (iid != vmIntrinsics::_linkToStatic) {
       __ verify_oop(receiver_reg);
       if (iid == vmIntrinsics::_linkToSpecial) {
@@ -583,13 +583,11 @@
       values.print(p);
     }
     if (has_mh && oopDesc::is_oop(mh)) {
       mh->print();
       if (java_lang_invoke_MethodHandle::is_instance(mh)) {
-        if (java_lang_invoke_MethodHandle::form_offset_in_bytes() != 0) {
-          java_lang_invoke_MethodHandle::form(mh)->print();
-        }
+        java_lang_invoke_MethodHandle::form(mh)->print();
       }
     }
   }
 }
 
diff a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
@@ -722,12 +722,11 @@
 
   // r13: senderSP must preserve for slow path, set SP to it on fast path
 
   address entry = __ pc();
 
-  const int referent_offset = java_lang_ref_Reference::referent_offset;
-  guarantee(referent_offset > 0, "referent offset not initialized");
+  const int referent_offset = java_lang_ref_Reference::referent_offset();
 
   Label slow_path;
   // rbx: method
 
   // Check if local 0 != NULL
diff a/src/hotspot/share/c1/c1_GraphBuilder.cpp b/src/hotspot/share/c1/c1_GraphBuilder.cpp
--- a/src/hotspot/share/c1/c1_GraphBuilder.cpp
+++ b/src/hotspot/share/c1/c1_GraphBuilder.cpp
@@ -4330,11 +4330,11 @@
         // We don't do CHA here so only inline static and statically bindable methods.
         if (target->is_static() || target->can_be_statically_bound()) {
           if (ciMethod::is_consistent_info(callee, target)) {
             Bytecodes::Code bc = target->is_static() ? Bytecodes::_invokestatic : Bytecodes::_invokevirtual;
             ignore_return = ignore_return || (callee->return_type()->is_void() && !target->return_type()->is_void());
-            if (try_inline(target, /*holder_known*/ true, ignore_return, bc)) {
+            if (try_inline(target, /*holder_known*/ !callee->is_static(), ignore_return, bc)) {
               return true;
             }
           } else {
             print_inlining(target, "signatures mismatch", /*success*/ false);
           }
@@ -4396,11 +4396,11 @@
             j += t->size();  // long and double take two slots
           }
           // We don't do CHA here so only inline static and statically bindable methods.
           if (target->is_static() || target->can_be_statically_bound()) {
             Bytecodes::Code bc = target->is_static() ? Bytecodes::_invokestatic : Bytecodes::_invokevirtual;
-            if (try_inline(target, /*holder_known*/ true, ignore_return, bc)) {
+            if (try_inline(target, /*holder_known*/ !callee->is_static(), ignore_return, bc)) {
               return true;
             }
           } else {
             print_inlining(target, "not static or statically bindable", /*success*/ false);
           }
diff a/src/hotspot/share/c1/c1_LIR.cpp b/src/hotspot/share/c1/c1_LIR.cpp
--- a/src/hotspot/share/c1/c1_LIR.cpp
+++ b/src/hotspot/share/c1/c1_LIR.cpp
@@ -237,34 +237,31 @@
   }
 #endif
 }
 
 
-LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, BasicType type, BlockBegin* block)
+LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, BlockBegin* block)
   : LIR_Op(lir_branch, LIR_OprFact::illegalOpr, (CodeEmitInfo*)NULL)
   , _cond(cond)
-  , _type(type)
   , _label(block->label())
   , _block(block)
   , _ublock(NULL)
   , _stub(NULL) {
 }
 
-LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, BasicType type, CodeStub* stub) :
+LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, CodeStub* stub) :
   LIR_Op(lir_branch, LIR_OprFact::illegalOpr, (CodeEmitInfo*)NULL)
   , _cond(cond)
-  , _type(type)
   , _label(stub->entry())
   , _block(NULL)
   , _ublock(NULL)
   , _stub(stub) {
 }
 
-LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, BasicType type, BlockBegin* block, BlockBegin* ublock)
+LIR_OpBranch::LIR_OpBranch(LIR_Condition cond, BlockBegin* block, BlockBegin* ublock)
   : LIR_Op(lir_cond_float_branch, LIR_OprFact::illegalOpr, (CodeEmitInfo*)NULL)
   , _cond(cond)
-  , _type(type)
   , _label(block->label())
   , _block(block)
   , _ublock(ublock)
   , _stub(NULL)
 {
@@ -1550,11 +1547,11 @@
 void LIR_List::null_check(LIR_Opr opr, CodeEmitInfo* info, bool deoptimize_on_null) {
   if (deoptimize_on_null) {
     // Emit an explicit null check and deoptimize if opr is null
     CodeStub* deopt = new DeoptimizeStub(info, Deoptimization::Reason_null_check, Deoptimization::Action_none);
     cmp(lir_cond_equal, opr, LIR_OprFact::oopConst(NULL));
-    branch(lir_cond_equal, T_OBJECT, deopt);
+    branch(lir_cond_equal, deopt);
   } else {
     // Emit an implicit null check
     append(new LIR_Op1(lir_null_check, opr, info));
   }
 }
diff a/src/hotspot/share/c1/c1_LIR.hpp b/src/hotspot/share/c1/c1_LIR.hpp
--- a/src/hotspot/share/c1/c1_LIR.hpp
+++ b/src/hotspot/share/c1/c1_LIR.hpp
@@ -1427,34 +1427,31 @@
 class LIR_OpBranch: public LIR_Op {
  friend class LIR_OpVisitState;
 
  private:
   LIR_Condition _cond;
-  BasicType     _type;
   Label*        _label;
   BlockBegin*   _block;  // if this is a branch to a block, this is the block
   BlockBegin*   _ublock; // if this is a float-branch, this is the unorderd block
   CodeStub*     _stub;   // if this is a branch to a stub, this is the stub
 
  public:
-  LIR_OpBranch(LIR_Condition cond, BasicType type, Label* lbl)
+  LIR_OpBranch(LIR_Condition cond, Label* lbl)
     : LIR_Op(lir_branch, LIR_OprFact::illegalOpr, (CodeEmitInfo*) NULL)
     , _cond(cond)
-    , _type(type)
     , _label(lbl)
     , _block(NULL)
     , _ublock(NULL)
     , _stub(NULL) { }
 
-  LIR_OpBranch(LIR_Condition cond, BasicType type, BlockBegin* block);
-  LIR_OpBranch(LIR_Condition cond, BasicType type, CodeStub* stub);
+  LIR_OpBranch(LIR_Condition cond, BlockBegin* block);
+  LIR_OpBranch(LIR_Condition cond, CodeStub* stub);
 
   // for unordered comparisons
-  LIR_OpBranch(LIR_Condition cond, BasicType type, BlockBegin* block, BlockBegin* ublock);
+  LIR_OpBranch(LIR_Condition cond, BlockBegin* block, BlockBegin* ublock);
 
   LIR_Condition cond()        const              { return _cond;        }
-  BasicType     type()        const              { return _type;        }
   Label*        label()       const              { return _label;       }
   BlockBegin*   block()       const              { return _block;       }
   BlockBegin*   ublock()      const              { return _ublock;      }
   CodeStub*     stub()        const              { return _stub;       }
 
@@ -1908,11 +1905,11 @@
 
  public:
   LIR_OpDelay(LIR_Op* op, CodeEmitInfo* info):
     LIR_Op(lir_delay_slot, LIR_OprFact::illegalOpr, info),
     _op(op) {
-    assert(op->code() == lir_nop || LIRFillDelaySlots, "should be filling with nops");
+    assert(op->code() == lir_nop, "should be filling with nops");
   }
   virtual void emit_code(LIR_Assembler* masm);
   virtual LIR_OpDelay* as_OpDelay() { return this; }
   void print_instr(outputStream* out) const PRODUCT_RETURN;
   LIR_Op* delay_op() const { return _op; }
@@ -2279,27 +2276,29 @@
   void allocate_object(LIR_Opr dst, LIR_Opr t1, LIR_Opr t2, LIR_Opr t3, LIR_Opr t4, int header_size, int object_size, LIR_Opr klass, bool init_check, CodeStub* stub);
   void allocate_array(LIR_Opr dst, LIR_Opr len, LIR_Opr t1,LIR_Opr t2, LIR_Opr t3,LIR_Opr t4, BasicType type, LIR_Opr klass, CodeStub* stub);
 
   // jump is an unconditional branch
   void jump(BlockBegin* block) {
-    append(new LIR_OpBranch(lir_cond_always, T_ILLEGAL, block));
+    append(new LIR_OpBranch(lir_cond_always, block));
   }
   void jump(CodeStub* stub) {
-    append(new LIR_OpBranch(lir_cond_always, T_ILLEGAL, stub));
+    append(new LIR_OpBranch(lir_cond_always, stub));
+  }
+  void branch(LIR_Condition cond, Label* lbl) {
+    append(new LIR_OpBranch(cond, lbl));
   }
-  void branch(LIR_Condition cond, BasicType type, Label* lbl)        { append(new LIR_OpBranch(cond, type, lbl)); }
-  void branch(LIR_Condition cond, BasicType type, BlockBegin* block) {
-    assert(type != T_FLOAT && type != T_DOUBLE, "no fp comparisons");
-    append(new LIR_OpBranch(cond, type, block));
+  // Should not be used for fp comparisons
+  void branch(LIR_Condition cond, BlockBegin* block) {
+    append(new LIR_OpBranch(cond, block));
   }
-  void branch(LIR_Condition cond, BasicType type, CodeStub* stub)    {
-    assert(type != T_FLOAT && type != T_DOUBLE, "no fp comparisons");
-    append(new LIR_OpBranch(cond, type, stub));
+  // Should not be used for fp comparisons
+  void branch(LIR_Condition cond, CodeStub* stub) {
+    append(new LIR_OpBranch(cond, stub));
   }
-  void branch(LIR_Condition cond, BasicType type, BlockBegin* block, BlockBegin* unordered) {
-    assert(type == T_FLOAT || type == T_DOUBLE, "fp comparisons only");
-    append(new LIR_OpBranch(cond, type, block, unordered));
+  // Should only be used for fp comparisons
+  void branch(LIR_Condition cond, BlockBegin* block, BlockBegin* unordered) {
+    append(new LIR_OpBranch(cond, block, unordered));
   }
 
   void shift_left(LIR_Opr value, LIR_Opr count, LIR_Opr dst, LIR_Opr tmp);
   void shift_right(LIR_Opr value, LIR_Opr count, LIR_Opr dst, LIR_Opr tmp);
   void unsigned_shift_right(LIR_Opr value, LIR_Opr count, LIR_Opr dst, LIR_Opr tmp);
diff a/src/hotspot/share/c1/c1_LIRGenerator.cpp b/src/hotspot/share/c1/c1_LIRGenerator.cpp
--- a/src/hotspot/share/c1/c1_LIRGenerator.cpp
+++ b/src/hotspot/share/c1/c1_LIRGenerator.cpp
@@ -480,28 +480,28 @@
                                     CodeEmitInfo* null_check_info, CodeEmitInfo* range_check_info) {
   CodeStub* stub = new RangeCheckStub(range_check_info, index, array);
   if (index->is_constant()) {
     cmp_mem_int(lir_cond_belowEqual, array, arrayOopDesc::length_offset_in_bytes(),
                 index->as_jint(), null_check_info);
-    __ branch(lir_cond_belowEqual, T_INT, stub); // forward branch
+    __ branch(lir_cond_belowEqual, stub); // forward branch
   } else {
     cmp_reg_mem(lir_cond_aboveEqual, index, array,
                 arrayOopDesc::length_offset_in_bytes(), T_INT, null_check_info);
-    __ branch(lir_cond_aboveEqual, T_INT, stub); // forward branch
+    __ branch(lir_cond_aboveEqual, stub); // forward branch
   }
 }
 
 
 void LIRGenerator::nio_range_check(LIR_Opr buffer, LIR_Opr index, LIR_Opr result, CodeEmitInfo* info) {
   CodeStub* stub = new RangeCheckStub(info, index);
   if (index->is_constant()) {
     cmp_mem_int(lir_cond_belowEqual, buffer, java_nio_Buffer::limit_offset(), index->as_jint(), info);
-    __ branch(lir_cond_belowEqual, T_INT, stub); // forward branch
+    __ branch(lir_cond_belowEqual, stub); // forward branch
   } else {
     cmp_reg_mem(lir_cond_aboveEqual, index, buffer,
                 java_nio_Buffer::limit_offset(), T_INT, info);
-    __ branch(lir_cond_aboveEqual, T_INT, stub); // forward branch
+    __ branch(lir_cond_aboveEqual, stub); // forward branch
   }
   __ move(index, result);
 }
 
 
@@ -689,11 +689,11 @@
     const int instance_size = align_object_size(klass->size_helper());
     __ allocate_object(dst, scratch1, scratch2, scratch3, scratch4,
                        oopDesc::header_size(), instance_size, klass_reg, !klass->is_initialized(), slow_path);
   } else {
     CodeStub* slow_path = new NewInstanceStub(klass_reg, dst, klass, info, Runtime1::new_instance_id);
-    __ branch(lir_cond_always, T_ILLEGAL, slow_path);
+    __ branch(lir_cond_always, slow_path);
     __ branch_destination(slow_path->continuation());
   }
 }
 
 
@@ -1233,12 +1233,11 @@
 
 // Examble: ref.get()
 // Combination of LoadField and g1 pre-write barrier
 void LIRGenerator::do_Reference_get(Intrinsic* x) {
 
-  const int referent_offset = java_lang_ref_Reference::referent_offset;
-  guarantee(referent_offset > 0, "referent offset not initialized");
+  const int referent_offset = java_lang_ref_Reference::referent_offset();
 
   assert(x->number_of_arguments() == 1, "wrong type");
 
   LIRItem reference(x->argument_at(0), this);
   reference.load_item();
@@ -1320,11 +1319,11 @@
   CodeEmitInfo* info = NULL;
   if (x->needs_null_check()) {
     info = state_for(x);
   }
 
-  __ move(new LIR_Address(rcvr.result(), java_lang_Class::klass_offset_in_bytes(), T_ADDRESS), temp, info);
+  __ move(new LIR_Address(rcvr.result(), java_lang_Class::klass_offset(), T_ADDRESS), temp, info);
   __ cmp(lir_cond_notEqual, temp, LIR_OprFact::metadataConst(0));
   __ cmove(lir_cond_notEqual, LIR_OprFact::intConst(0), LIR_OprFact::intConst(1), result, T_BOOLEAN);
 }
 
 
@@ -1562,11 +1561,11 @@
       assert(!x->field()->holder()->is_loaded(), "must be");
       // We don't know the offset of this field. Let's deopt and recompile.
       CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),
                                           Deoptimization::Reason_unloaded,
                                           Deoptimization::Action_make_not_entrant);
-      __ branch(lir_cond_always, T_ILLEGAL, stub);
+      __ branch(lir_cond_always, stub);
     } else {
       // Emit an explicit null check because the offset is too large.
       // If the class is not loaded and the object is NULL, we need to deoptimize to throw a
       // NoClassDefFoundError in the interpreter instead of an implicit NPE from compiled code.
       __ null_check(object.result(), new CodeEmitInfo(info), /* deoptimize */ needs_patching);
@@ -1681,11 +1680,11 @@
 
 void LIRGenerator::check_null_free_array(LIRItem& array, LIRItem& value, CodeEmitInfo* info) {
   LabelObj* L_end = new LabelObj();
   LIR_Opr tmp = new_register(T_METADATA);
   __ check_null_free_array(array.result(), tmp);
-  __ branch(lir_cond_equal, T_ILLEGAL, L_end->label());
+  __ branch(lir_cond_equal, L_end->label());
   __ null_check(value.result(), info);
   __ branch_destination(L_end->label());
 }
 
 bool LIRGenerator::needs_flattened_array_store_check(StoreIndexed* x) {
@@ -1752,11 +1751,11 @@
   }
 
   if (GenerateRangeChecks && needs_range_check) {
     if (use_length) {
       __ cmp(lir_cond_belowEqual, length.result(), index.result());
-      __ branch(lir_cond_belowEqual, T_INT, new RangeCheckStub(range_check_info, index.result(), array.result()));
+      __ branch(lir_cond_belowEqual, new RangeCheckStub(range_check_info, index.result(), array.result()));
     } else {
       array_range_check(array.result(), index.result(), null_check_info, range_check_info);
       // range_check also does the null check
       null_check_info = NULL;
     }
@@ -1946,11 +1945,11 @@
     assert(x->needs_patching(), "must be");
     assert(info != NULL, "must be");
     CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),
                                         Deoptimization::Reason_unloaded,
                                         Deoptimization::Action_make_not_entrant);
-    __ branch(lir_cond_always, T_ILLEGAL, stub);
+    __ branch(lir_cond_always, stub);
   } else if (need_default) {
     assert(!field_type_unloaded, "must be");
     assert(field->type()->is_valuetype(), "must be");
     ciValueKlass* value_klass = field->type()->as_value_klass();
     assert(value_klass->is_loaded(), "must be");
@@ -2039,11 +2038,11 @@
                  info ? new CodeEmitInfo(info) : NULL, info);
 
   if (default_value != NULL) {
     LabelObj* L_end = new LabelObj();
     __ cmp(lir_cond_notEqual, result, LIR_OprFact::oopConst(NULL));
-    __ branch(lir_cond_notEqual, T_OBJECT, L_end->label());
+    __ branch(lir_cond_notEqual, L_end->label());
     set_in_conditional_code(true);
     __ move(load_constant(default_value), result);
     __ branch_destination(L_end->label());
     set_in_conditional_code(false);
   }
@@ -2068,15 +2067,15 @@
     CodeEmitInfo* info = state_for(x);
     CodeStub* stub = new RangeCheckStub(info, index.result());
     LIR_Opr buf_obj = access_resolve(IS_NOT_NULL | ACCESS_READ, buf.result());
     if (index.result()->is_constant()) {
       cmp_mem_int(lir_cond_belowEqual, buf_obj, java_nio_Buffer::limit_offset(), index.result()->as_jint(), info);
-      __ branch(lir_cond_belowEqual, T_INT, stub);
+      __ branch(lir_cond_belowEqual, stub);
     } else {
       cmp_reg_mem(lir_cond_aboveEqual, index.result(), buf_obj,
                   java_nio_Buffer::limit_offset(), T_INT, info);
-      __ branch(lir_cond_aboveEqual, T_INT, stub);
+      __ branch(lir_cond_aboveEqual, stub);
     }
     __ move(index.result(), result);
   } else {
     // Just load the index into the result register
     __ move(index.result(), result);
@@ -2146,16 +2145,16 @@
     }
   }
 
   if (GenerateRangeChecks && needs_range_check) {
     if (StressLoopInvariantCodeMotion && range_check_info->deoptimize_on_exception()) {
-      __ branch(lir_cond_always, T_ILLEGAL, new RangeCheckStub(range_check_info, index.result(), array.result()));
+      __ branch(lir_cond_always, new RangeCheckStub(range_check_info, index.result(), array.result()));
     } else if (use_length) {
       // TODO: use a (modified) version of array_range_check that does not require a
       //       constant length to be loaded to a register
       __ cmp(lir_cond_belowEqual, length.result(), index.result());
-      __ branch(lir_cond_belowEqual, T_INT, new RangeCheckStub(range_check_info, index.result(), array.result()));
+      __ branch(lir_cond_belowEqual, new RangeCheckStub(range_check_info, index.result(), array.result()));
     } else {
       array_range_check(array.result(), index.result(), null_check_info, range_check_info);
       // The range check performs the null check, so clear it out for the load
       null_check_info = NULL;
     }
@@ -2221,22 +2220,22 @@
   // case. Let's just deoptimize.
   CodeEmitInfo* info = state_for(x, x->state_before());
   CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),
                                       Deoptimization::Reason_unloaded,
                                       Deoptimization::Action_make_not_entrant);
-  __ branch(lir_cond_always, T_ILLEGAL, stub);
+  __ branch(lir_cond_always, stub);
   LIR_Opr reg = rlock_result(x, T_OBJECT);
   __ move(LIR_OprFact::oopConst(NULL), reg);
 }
 
 void LIRGenerator::do_DefaultValue(DefaultValue* x) {
   // Same as withfield above. Let's deoptimize.
   CodeEmitInfo* info = state_for(x, x->state_before());
   CodeStub* stub = new DeoptimizeStub(new CodeEmitInfo(info),
                                       Deoptimization::Reason_unloaded,
                                       Deoptimization::Action_make_not_entrant);
-  __ branch(lir_cond_always, T_ILLEGAL, stub);
+  __ branch(lir_cond_always, stub);
   LIR_Opr reg = rlock_result(x, T_OBJECT);
   __ move(LIR_OprFact::oopConst(NULL), reg);
 }
 
 void LIRGenerator::do_NullCheck(NullCheck* x) {
@@ -2596,22 +2595,22 @@
     int low_key = one_range->low_key();
     int high_key = one_range->high_key();
     BlockBegin* dest = one_range->sux();
     if (low_key == high_key) {
       __ cmp(lir_cond_equal, value, low_key);
-      __ branch(lir_cond_equal, T_INT, dest);
+      __ branch(lir_cond_equal, dest);
     } else if (high_key - low_key == 1) {
       __ cmp(lir_cond_equal, value, low_key);
-      __ branch(lir_cond_equal, T_INT, dest);
+      __ branch(lir_cond_equal, dest);
       __ cmp(lir_cond_equal, value, high_key);
-      __ branch(lir_cond_equal, T_INT, dest);
+      __ branch(lir_cond_equal, dest);
     } else {
       LabelObj* L = new LabelObj();
       __ cmp(lir_cond_less, value, low_key);
-      __ branch(lir_cond_less, T_INT, L->label());
+      __ branch(lir_cond_less, L->label());
       __ cmp(lir_cond_lessEqual, value, high_key);
-      __ branch(lir_cond_lessEqual, T_INT, dest);
+      __ branch(lir_cond_lessEqual, dest);
       __ branch_destination(L->label());
     }
   }
   __ jump(default_sux);
 }
@@ -2727,11 +2726,11 @@
   if (UseTableRanges) {
     do_SwitchRanges(create_lookup_ranges(x), value, x->default_sux());
   } else {
     for (int i = 0; i < len; i++) {
       __ cmp(lir_cond_equal, value, i + lo_key);
-      __ branch(lir_cond_equal, T_INT, x->sux_at(i));
+      __ branch(lir_cond_equal, x->sux_at(i));
     }
     __ jump(x->default_sux());
   }
 }
 
@@ -2786,11 +2785,11 @@
     do_SwitchRanges(create_lookup_ranges(x), value, x->default_sux());
   } else {
     int len = x->length();
     for (int i = 0; i < len; i++) {
       __ cmp(lir_cond_equal, value, x->key_at(i));
-      __ branch(lir_cond_equal, T_INT, x->sux_at(i));
+      __ branch(lir_cond_equal, x->sux_at(i));
     }
     __ jump(x->default_sux());
   }
 }
 
@@ -3004,11 +3003,11 @@
   LIR_Opr tmp = new_register(T_METADATA);
   LIR_Opr mdp = new_register(T_METADATA);
   assert(md != NULL, "should have been initialized");
   __ metadata2reg(md->constant_encoding(), mdp);
   __ check_null_free_array(array.result(), tmp);
-  __ branch(lir_cond_equal, T_ILLEGAL, L_end->label());
+  __ branch(lir_cond_equal, L_end->label());
 
   profile_array_load_store_flags(md, load_store, ArrayLoadStoreData::null_free_array_byte_constant(), mdp);
 
   __ branch_destination(L_end->label());
 }
@@ -3121,11 +3120,11 @@
     // Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized value type arguments
     // in the entry point (see comments in frame::deoptimize). If so, deoptimize only now that we have the right state.
     CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, 0), NULL, false);
     CodeStub* deopt_stub = new DeoptimizeStub(info, Deoptimization::Reason_none, Deoptimization::Action_none);
     __ append(new LIR_Op0(lir_check_orig_pc));
-    __ branch(lir_cond_notEqual, T_ADDRESS, deopt_stub);
+    __ branch(lir_cond_notEqual, deopt_stub);
   }
 
   // all blocks with a successor must end with an unconditional jump
   // to the successor even if they are consecutive
   __ jump(x->default_sux());
@@ -3428,11 +3427,11 @@
   assert(info != NULL, "must have info");
   LIRItem arg(x->argument_at(0), this);
 
   arg.load_item();
   LIR_Opr klass = new_register(T_METADATA);
-  __ move(new LIR_Address(arg.result(), java_lang_Class::klass_offset_in_bytes(), T_ADDRESS), klass, info);
+  __ move(new LIR_Address(arg.result(), java_lang_Class::klass_offset(), T_ADDRESS), klass, info);
   LIR_Opr id = new_register(T_LONG);
   ByteSize offset = KLASS_TRACE_ID_OFFSET;
   LIR_Address* trace_id_addr = new LIR_Address(klass, in_bytes(offset), T_LONG);
 
   __ move(trace_id_addr, id);
@@ -3450,20 +3449,22 @@
 }
 
 void LIRGenerator::do_getEventWriter(Intrinsic* x) {
   LabelObj* L_end = new LabelObj();
 
+  // FIXME T_ADDRESS should actually be T_METADATA but it can't because the
+  // meaning of these two is mixed up (see JDK-8026837).
   LIR_Address* jobj_addr = new LIR_Address(getThreadPointer(),
                                            in_bytes(THREAD_LOCAL_WRITER_OFFSET_JFR),
-                                           T_OBJECT);
+                                           T_ADDRESS);
   LIR_Opr result = rlock_result(x);
-  __ move_wide(jobj_addr, result);
-  __ cmp(lir_cond_equal, result, LIR_OprFact::oopConst(NULL));
-  __ branch(lir_cond_equal, T_OBJECT, L_end->label());
+  __ move(LIR_OprFact::oopConst(NULL), result);
+  LIR_Opr jobj = new_register(T_METADATA);
+  __ move_wide(jobj_addr, jobj);
+  __ cmp(lir_cond_equal, jobj, LIR_OprFact::metadataConst(0));
+  __ branch(lir_cond_equal, L_end->label());
 
-  LIR_Opr jobj = new_register(T_OBJECT);
-  __ move(result, jobj);
   access_load(IN_NATIVE, T_OBJECT, LIR_OprFact::address(new LIR_Address(jobj, T_OBJECT)), result);
 
   __ branch_destination(L_end->label());
 }
 
@@ -3817,11 +3818,11 @@
     __ store(result, counter);
     // DeoptimizeStub will reexecute from the current state in code info.
     CodeStub* deopt = new DeoptimizeStub(info, Deoptimization::Reason_tenured,
                                          Deoptimization::Action_make_not_entrant);
     __ cmp(lir_cond_lessEqual, result, LIR_OprFact::intConst(0));
-    __ branch(lir_cond_lessEqual, T_INT, deopt);
+    __ branch(lir_cond_lessEqual, deopt);
   }
 }
 
 
 void LIRGenerator::increment_event_counter_impl(CodeEmitInfo* info,
@@ -3864,24 +3865,24 @@
     CodeStub* overflow = new CounterOverflowStub(info, bci, meth);
     int freq = frequency << InvocationCounter::count_shift;
     if (freq == 0) {
       if (!step->is_constant()) {
         __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));
-        __ branch(lir_cond_notEqual, T_ILLEGAL, overflow);
+        __ branch(lir_cond_notEqual, overflow);
       } else {
-        __ branch(lir_cond_always, T_ILLEGAL, overflow);
+        __ branch(lir_cond_always, overflow);
       }
     } else {
       LIR_Opr mask = load_immediate(freq, T_INT);
       if (!step->is_constant()) {
         // If step is 0, make sure the overflow check below always fails
         __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));
         __ cmove(lir_cond_notEqual, result, LIR_OprFact::intConst(InvocationCounter::count_increment), result, T_INT);
       }
       __ logical_and(result, mask, result);
       __ cmp(lir_cond_equal, result, LIR_OprFact::intConst(0));
-      __ branch(lir_cond_equal, T_INT, overflow);
+      __ branch(lir_cond_equal, overflow);
     }
     __ branch_destination(overflow->continuation());
   }
 }
 
@@ -3991,11 +3992,11 @@
 
     CodeEmitInfo *info = state_for(x, x->state());
     CodeStub* stub = new PredicateFailedStub(info);
 
     __ cmp(lir_cond(cond), left, right);
-    __ branch(lir_cond(cond), right->type(), stub);
+    __ branch(lir_cond(cond), stub);
   }
 }
 
 
 LIR_Opr LIRGenerator::call_runtime(Value arg1, address entry, ValueType* result_type, CodeEmitInfo* info) {
diff a/src/hotspot/share/ci/ciField.cpp b/src/hotspot/share/ci/ciField.cpp
--- a/src/hotspot/share/ci/ciField.cpp
+++ b/src/hotspot/share/ci/ciField.cpp
@@ -291,13 +291,13 @@
       // whose value may change.  The three examples are java.lang.System.in,
       // java.lang.System.out, and java.lang.System.err.
       assert(SystemDictionary::System_klass() != NULL, "Check once per vm");
       if (k == SystemDictionary::System_klass()) {
         // Check offsets for case 2: System.in, System.out, or System.err
-        if( _offset == java_lang_System::in_offset_in_bytes()  ||
-            _offset == java_lang_System::out_offset_in_bytes() ||
-            _offset == java_lang_System::err_offset_in_bytes() ) {
+        if (_offset == java_lang_System::in_offset()  ||
+            _offset == java_lang_System::out_offset() ||
+            _offset == java_lang_System::err_offset()) {
           _is_constant = false;
           return;
         }
       }
       _is_constant = true;
@@ -309,11 +309,11 @@
     }
   } else {
     // For CallSite objects treat the target field as a compile time constant.
     assert(SystemDictionary::CallSite_klass() != NULL, "should be already initialized");
     if (k == SystemDictionary::CallSite_klass() &&
-        _offset == java_lang_invoke_CallSite::target_offset_in_bytes()) {
+        _offset == java_lang_invoke_CallSite::target_offset()) {
       assert(!has_initialized_final_update(), "CallSite is not supposed to have writes to final fields outside initializers");
       _is_constant = true;
     } else {
       // Non-final & non-stable fields are not constants.
       _is_constant = false;
diff a/src/hotspot/share/ci/ciInstanceKlass.cpp b/src/hotspot/share/ci/ciInstanceKlass.cpp
--- a/src/hotspot/share/ci/ciInstanceKlass.cpp
+++ b/src/hotspot/share/ci/ciInstanceKlass.cpp
@@ -275,11 +275,11 @@
  *  Is this boxed value offset?
  */
 bool ciInstanceKlass::is_boxed_value_offset(int offset) const {
   BasicType bt = box_klass_type();
   return is_java_primitive(bt) &&
-         (offset == java_lang_boxing_object::value_offset_in_bytes(bt));
+         (offset == java_lang_boxing_object::value_offset(bt));
 }
 
 // ------------------------------------------------------------------
 // ciInstanceKlass::is_in_package
 //
diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -3376,10 +3376,45 @@
   cfs->set_current(current_mark);
 
   return length;
 }
 
+u2 ClassFileParser::parse_classfile_permitted_subclasses_attribute(const ClassFileStream* const cfs,
+                                                                   const u1* const permitted_subclasses_attribute_start,
+                                                                   TRAPS) {
+  const u1* const current_mark = cfs->current();
+  u2 length = 0;
+  if (permitted_subclasses_attribute_start != NULL) {
+    cfs->set_current(permitted_subclasses_attribute_start);
+    cfs->guarantee_more(2, CHECK_0);  // length
+    length = cfs->get_u2_fast();
+  }
+  if (length < 1) {
+    classfile_parse_error("PermittedSubclasses attribute is empty in class file %s", CHECK_0);
+  }
+  const int size = length;
+  Array<u2>* const permitted_subclasses = MetadataFactory::new_array<u2>(_loader_data, size, CHECK_0);
+  _permitted_subclasses = permitted_subclasses;
+
+  int index = 0;
+  cfs->guarantee_more(2 * length, CHECK_0);
+  for (int n = 0; n < length; n++) {
+    const u2 class_info_index = cfs->get_u2_fast();
+    check_property(
+      valid_klass_reference_at(class_info_index),
+      "Permitted subclass class_info_index %u has bad constant type in class file %s",
+      class_info_index, CHECK_0);
+    permitted_subclasses->at_put(index++, class_info_index);
+  }
+  assert(index == size, "wrong size");
+
+  // Restore buffer's current position.
+  cfs->set_current(current_mark);
+
+  return length;
+}
+
 //  Record {
 //    u2 attribute_name_index;
 //    u4 attribute_length;
 //    u2 components_count;
 //    component_info components[components_count];
@@ -3640,14 +3675,20 @@
   guarantee_property(current_start + attribute_byte_length == cfs->current(),
                      "Bad length on BootstrapMethods in class file %s",
                      CHECK);
 }
 
+bool ClassFileParser::supports_sealed_types() {
+  return _major_version == JVM_CLASSFILE_MAJOR_VERSION &&
+         _minor_version == JAVA_PREVIEW_MINOR_VERSION &&
+         Arguments::enable_preview();
+}
+
 bool ClassFileParser::supports_records() {
   return _major_version == JVM_CLASSFILE_MAJOR_VERSION &&
-    _minor_version == JAVA_PREVIEW_MINOR_VERSION &&
-    Arguments::enable_preview();
+         _minor_version == JAVA_PREVIEW_MINOR_VERSION &&
+         Arguments::enable_preview();
 }
 
 void ClassFileParser::parse_classfile_attributes(const ClassFileStream* const cfs,
                                                  ConstantPool* cp,
                  ClassFileParser::ClassAnnotationCollector* parsed_annotations,
@@ -3658,15 +3699,18 @@
 
   // Set inner classes attribute to default sentinel
   _inner_classes = Universe::the_empty_short_array();
   // Set nest members attribute to default sentinel
   _nest_members = Universe::the_empty_short_array();
+  // Set _permitted_subclasses attribute to default sentinel
+  _permitted_subclasses = Universe::the_empty_short_array();
   cfs->guarantee_more(2, CHECK);  // attributes_count
   u2 attributes_count = cfs->get_u2_fast();
   bool parsed_sourcefile_attribute = false;
   bool parsed_innerclasses_attribute = false;
   bool parsed_nest_members_attribute = false;
+  bool parsed_permitted_subclasses_attribute = false;
   bool parsed_nest_host_attribute = false;
   bool parsed_record_attribute = false;
   bool parsed_enclosingmethod_attribute = false;
   bool parsed_bootstrap_methods_attribute = false;
   const u1* runtime_visible_annotations = NULL;
@@ -3686,10 +3730,12 @@
   u2  enclosing_method_method_index = 0;
   const u1* nest_members_attribute_start = NULL;
   u4  nest_members_attribute_length = 0;
   const u1* record_attribute_start = NULL;
   u4  record_attribute_length = 0;
+  const u1* permitted_subclasses_attribute_start = NULL;
+  u4  permitted_subclasses_attribute_length = 0;
 
   // Iterate over attributes
   while (attributes_count--) {
     cfs->guarantee_more(6, CHECK);  // attribute_name_index, attribute_length
     const u2 attribute_name_index = cfs->get_u2_fast();
@@ -3902,10 +3948,30 @@
                   "Ignoring Record attribute in class %s because class file version is not %d.65535",
                    _class_name->as_C_string(), JVM_CLASSFILE_MAJOR_VERSION);
               }
             }
             cfs->skip_u1(attribute_length, CHECK);
+          } else if (_major_version >= JAVA_15_VERSION) {
+            // Check for PermittedSubclasses tag
+            if (tag == vmSymbols::tag_permitted_subclasses()) {
+              if (supports_sealed_types()) {
+                if (parsed_permitted_subclasses_attribute) {
+                  classfile_parse_error("Multiple PermittedSubclasses attributes in class file %s", CHECK);
+                }
+                // Classes marked ACC_FINAL cannot have a PermittedSubclasses attribute.
+                if (_access_flags.is_final()) {
+                  classfile_parse_error("PermittedSubclasses attribute in final class file %s", CHECK);
+                }
+                parsed_permitted_subclasses_attribute = true;
+                permitted_subclasses_attribute_start = cfs->current();
+                permitted_subclasses_attribute_length = attribute_length;
+              }
+              cfs->skip_u1(attribute_length, CHECK);
+            } else {
+              // Unknown attribute
+              cfs->skip_u1(attribute_length, CHECK);
+            }
           } else {
             // Unknown attribute
             cfs->skip_u1(attribute_length, CHECK);
           }
         } else {
@@ -3970,10 +4036,22 @@
                          "Record attribute has wrong length in class file %s",
                          CHECK);
     }
   }
 
+  if (parsed_permitted_subclasses_attribute) {
+    const u2 num_subclasses = parse_classfile_permitted_subclasses_attribute(
+                            cfs,
+                            permitted_subclasses_attribute_start,
+                            CHECK);
+    if (_need_verify) {
+      guarantee_property(
+        permitted_subclasses_attribute_length == sizeof(num_subclasses) + sizeof(u2) * num_subclasses,
+        "Wrong PermittedSubclasses attribute length in class file %s", CHECK);
+    }
+  }
+
   if (_max_bootstrap_specifier_index >= 0) {
     guarantee_property(parsed_bootstrap_methods_attribute,
                        "Missing BootstrapMethods attribute in class file %s", CHECK);
   }
 }
@@ -4037,10 +4115,11 @@
   this_klass->set_inner_classes(_inner_classes);
   this_klass->set_nest_members(_nest_members);
   this_klass->set_nest_host_index(_nest_host);
   this_klass->set_local_interfaces(_local_interfaces);
   this_klass->set_annotations(_combined_annotations);
+  this_klass->set_permitted_subclasses(_permitted_subclasses);
   this_klass->set_record_components(_record_components);
   // Delay the setting of _transitive_interfaces until after initialize_supers() in
   // fill_instance_klass(). It is because the _transitive_interfaces may be shared with
   // its _super. If an OOM occurs while loading the current klass, its _super field
   // may not have been set. When GC tries to free the klass, the _transitive_interfaces
@@ -5066,16 +5145,38 @@
 static void check_super_class_access(const InstanceKlass* this_klass, TRAPS) {
   assert(this_klass != NULL, "invariant");
   const Klass* const super = this_klass->super();
 
   if (super != NULL) {
+    const InstanceKlass* super_ik = InstanceKlass::cast(super);
+
+    if (super->is_final()) {
+      ResourceMark rm(THREAD);
+      Exceptions::fthrow(
+        THREAD_AND_LOCATION,
+        vmSymbols::java_lang_VerifyError(),
+        "class %s cannot inherit from final class %s",
+        this_klass->external_name(),
+        super_ik->external_name());
+      return;
+    }
+
+    if (super_ik->is_sealed() && !super_ik->has_as_permitted_subclass(this_klass)) {
+      ResourceMark rm(THREAD);
+      Exceptions::fthrow(
+        THREAD_AND_LOCATION,
+        vmSymbols::java_lang_IncompatibleClassChangeError(),
+        "class %s cannot inherit from sealed class %s",
+        this_klass->external_name(),
+        super_ik->external_name());
+      return;
+    }
 
     // If the loader is not the boot loader then throw an exception if its
     // superclass is in package jdk.internal.reflect and its loader is not a
     // special reflection class loader
     if (!this_klass->class_loader_data()->is_the_null_class_loader_data()) {
-      assert(super->is_instance_klass(), "super is not instance klass");
       PackageEntry* super_package = super->package();
       if (super_package != NULL &&
           super_package->name()->fast_compare(vmSymbols::jdk_internal_reflect()) == 0 &&
           !java_lang_ClassLoader::is_reflection_class_loader(this_klass->class_loader())) {
         ResourceMark rm(THREAD);
@@ -5127,10 +5228,23 @@
   const Array<InstanceKlass*>* const local_interfaces = this_klass->local_interfaces();
   const int lng = local_interfaces->length();
   for (int i = lng - 1; i >= 0; i--) {
     InstanceKlass* const k = local_interfaces->at(i);
     assert (k != NULL && k->is_interface(), "invalid interface");
+
+    if (k->is_sealed() && !k->has_as_permitted_subclass(this_klass)) {
+      ResourceMark rm(THREAD);
+      Exceptions::fthrow(
+        THREAD_AND_LOCATION,
+        vmSymbols::java_lang_IncompatibleClassChangeError(),
+        "class %s cannot %s sealed interface %s",
+        this_klass->external_name(),
+        this_klass->is_interface() ? "extend" : "implement",
+        k->external_name());
+      return;
+    }
+
     Reflection::VerifyClassAccessResults vca_result =
       Reflection::verify_class_access(this_klass, k, false);
     if (vca_result != Reflection::ACCESS_OK) {
       ResourceMark rm(THREAD);
       char* msg = Reflection::verify_class_access_msg(this_klass,
@@ -6182,10 +6296,11 @@
   assert(NULL == _inner_classes, "invariant");
   assert(NULL == _nest_members, "invariant");
   assert(NULL == _local_interfaces, "invariant");
   assert(NULL == _combined_annotations, "invariant");
   assert(NULL == _record_components, "invariant");
+  assert(NULL == _permitted_subclasses, "invariant");
 
   if (_has_final_method) {
     ik->set_has_final_method();
   }
 
@@ -6511,10 +6626,11 @@
   _fields(NULL),
   _methods(NULL),
   _inner_classes(NULL),
   _nest_members(NULL),
   _nest_host(0),
+  _permitted_subclasses(NULL),
   _record_components(NULL),
   _temp_local_interfaces(NULL),
   _local_interfaces(NULL),
   _transitive_interfaces(NULL),
   _combined_annotations(NULL),
@@ -6629,10 +6745,11 @@
   _cp = NULL;
   _fields = NULL;
   _methods = NULL;
   _inner_classes = NULL;
   _nest_members = NULL;
+  _permitted_subclasses = NULL;
   _local_interfaces = NULL;
   _combined_annotations = NULL;
   _class_annotations = _class_type_annotations = NULL;
   _fields_annotations = _fields_type_annotations = NULL;
   _record_components = NULL;
@@ -6665,10 +6782,14 @@
 
   if (_record_components != NULL) {
     InstanceKlass::deallocate_record_components(_loader_data, _record_components);
   }
 
+  if (_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array()) {
+    MetadataFactory::free_array<u2>(_loader_data, _permitted_subclasses);
+  }
+
   // Free interfaces
   InstanceKlass::deallocate_interfaces(_loader_data, _super_klass,
                                        _local_interfaces, _transitive_interfaces);
 
   if (_combined_annotations != NULL) {
@@ -7075,15 +7196,10 @@
         _super_klass->external_name()
       );
       return;
     }
 
-    // Make sure super class is not final
-    if (_super_klass->is_final()) {
-      THROW_MSG(vmSymbols::java_lang_VerifyError(), "Cannot inherit from final class");
-    }
-
     // For an inline class, only java/lang/Object or special abstract classes
     // are acceptable super classes.
     if (is_inline_type()) {
       const InstanceKlass* super_ik = _super_klass;
       if (super_ik->invalid_inline_super()) {
diff a/src/hotspot/share/classfile/classFileParser.hpp b/src/hotspot/share/classfile/classFileParser.hpp
--- a/src/hotspot/share/classfile/classFileParser.hpp
+++ b/src/hotspot/share/classfile/classFileParser.hpp
@@ -131,10 +131,11 @@
   Array<u2>* _fields;
   Array<Method*>* _methods;
   Array<u2>* _inner_classes;
   Array<u2>* _nest_members;
   u2 _nest_host;
+  Array<u2>* _permitted_subclasses;
   Array<RecordComponent*>* _record_components;
   GrowableArray<InstanceKlass*>* _temp_local_interfaces;
   Array<InstanceKlass*>* _local_interfaces;
   Array<InstanceKlass*>* _transitive_interfaces;
   Annotations* _combined_annotations;
@@ -346,15 +347,20 @@
 
   u2 parse_classfile_nest_members_attribute(const ClassFileStream* const cfs,
                                             const u1* const nest_members_attribute_start,
                                             TRAPS);
 
+  u2 parse_classfile_permitted_subclasses_attribute(const ClassFileStream* const cfs,
+                                                    const u1* const permitted_subclasses_attribute_start,
+                                                    TRAPS);
+
   u2 parse_classfile_record_attribute(const ClassFileStream* const cfs,
                                       const ConstantPool* cp,
                                       const u1* const record_attribute_start,
                                       TRAPS);
 
+  bool supports_sealed_types();
   bool supports_records();
 
   void parse_classfile_attributes(const ClassFileStream* const cfs,
                                   ConstantPool* cp,
                                   ClassAnnotationCollector* parsed_annotations,
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -177,50 +177,54 @@
     vm_exit_during_initialization("Invalid layout of well-known class", ik->external_name());
   }
   compute_offset(dest_offset, ik, name, signature_symbol, is_static);
 }
 
-int java_lang_String::value_offset  = 0;
-int java_lang_String::hash_offset   = 0;
-int java_lang_String::hashIsZero_offset = 0;
-int java_lang_String::coder_offset  = 0;
-
-bool java_lang_String::initialized  = false;
-
-bool java_lang_String::is_instance(oop obj) {
-  return is_instance_inlined(obj);
-}
 
 #if INCLUDE_CDS
 #define FIELD_SERIALIZE_OFFSET(offset, klass, name, signature, is_static) \
   f->do_u4((u4*)&offset)
 #endif
 
 #define FIELD_COMPUTE_OFFSET(offset, klass, name, signature, is_static) \
   compute_offset(offset, klass, name, vmSymbols::signature(), is_static)
 
+
+// java_lang_String
+
+int java_lang_String::_value_offset;
+int java_lang_String::_hash_offset;
+int java_lang_String::_hashIsZero_offset;
+int java_lang_String::_coder_offset;
+
+bool java_lang_String::_initialized;
+
+bool java_lang_String::is_instance(oop obj) {
+  return is_instance_inlined(obj);
+}
+
 #define STRING_FIELDS_DO(macro) \
-  macro(value_offset, k, vmSymbols::value_name(), byte_array_signature, false); \
-  macro(hash_offset,  k, "hash",                  int_signature,        false); \
-  macro(hashIsZero_offset, k, "hashIsZero",       bool_signature,       false); \
-  macro(coder_offset, k, "coder",                 byte_signature,       false);
+  macro(_value_offset, k, vmSymbols::value_name(), byte_array_signature, false); \
+  macro(_hash_offset,  k, "hash",                  int_signature,        false); \
+  macro(_hashIsZero_offset, k, "hashIsZero",       bool_signature,       false); \
+  macro(_coder_offset, k, "coder",                 byte_signature,       false);
 
 void java_lang_String::compute_offsets() {
-  if (initialized) {
+  if (_initialized) {
     return;
   }
 
   InstanceKlass* k = SystemDictionary::String_klass();
   STRING_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 
-  initialized = true;
+  _initialized = true;
 }
 
 #if INCLUDE_CDS
 void java_lang_String::serialize_offsets(SerializeClosure* f) {
   STRING_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
-  f->do_bool(&initialized);
+  f->do_bool(&_initialized);
 }
 #endif
 
 class CompactStringsFixup : public FieldClosure {
 private:
@@ -243,11 +247,11 @@
   CompactStringsFixup fix(value);
   SystemDictionary::String_klass()->do_local_static_fields(&fix);
 }
 
 Handle java_lang_String::basic_create(int length, bool is_latin1, TRAPS) {
-  assert(initialized, "Must be initialized");
+  assert(_initialized, "Must be initialized");
   assert(CompactStrings || !is_latin1, "Must be UTF16 without CompactStrings");
 
   // Create the String object first, so there's a chance that the String
   // and the char array it points to end up in the same cache line.
   oop obj;
@@ -541,13 +545,13 @@
   // these fields. Necessary restrictions to allow this to be correct
   // without explicit memory fences or similar concurrency primitives is
   // that we can ever only write to one of these two fields for a given
   // String instance, and that the computation is idempotent and derived
   // from immutable state
-  assert(initialized && (hash_offset > 0) && (hashIsZero_offset > 0), "Must be initialized");
+  assert(_initialized && (_hash_offset > 0) && (_hashIsZero_offset > 0), "Must be initialized");
   if (java_lang_String::hash_is_set(java_string)) {
-    return java_string->int_field(hash_offset);
+    return java_string->int_field(_hash_offset);
   }
 
   typeArrayOop value = java_lang_String::value(java_string);
   int         length = java_lang_String::length(java_string, value);
   bool     is_latin1 = java_lang_String::is_latin1(java_string);
@@ -560,13 +564,13 @@
       hash = java_lang_String::hash_code(value->char_at_addr(0), length);
     }
   }
 
   if (hash != 0) {
-    java_string->int_field_put(hash_offset, hash);
+    java_string->int_field_put(_hash_offset, hash);
   } else {
-    java_string->bool_field_put(hashIsZero_offset, true);
+    java_string->bool_field_put(_hashIsZero_offset, true);
   }
   return hash;
 }
 
 char* java_lang_String::as_quoted_ascii(oop java_string) {
@@ -794,10 +798,32 @@
                            ((jchar) value->byte_at(index)) & 0xff );
   }
   st->print("\"");
 }
 
+// java_lang_Class
+
+int java_lang_Class::_klass_offset;
+int java_lang_Class::_array_klass_offset;
+int java_lang_Class::_oop_size_offset;
+int java_lang_Class::_static_oop_field_count_offset;
+int java_lang_Class::_class_loader_offset;
+int java_lang_Class::_module_offset;
+int java_lang_Class::_protection_domain_offset;
+int java_lang_Class::_component_mirror_offset;
+int java_lang_Class::_val_type_mirror_offset;
+int java_lang_Class::_ref_type_mirror_offset;
+int java_lang_Class::_init_lock_offset;
+int java_lang_Class::_signers_offset;
+int java_lang_Class::_name_offset;
+int java_lang_Class::_source_file_offset;
+int java_lang_Class::_classData_offset;
+int java_lang_Class::_classRedefinedCount_offset;
+
+bool java_lang_Class::_offsets_computed = false;
+GrowableArray<Klass*>* java_lang_Class::_fixup_mirror_list = NULL;
+GrowableArray<Klass*>* java_lang_Class::_fixup_module_field_list = NULL;
 
 static void initialize_static_field(fieldDescriptor* fd, Handle mirror, TRAPS) {
   assert(mirror.not_null() && fd->is_static(), "just checking");
   if (fd->has_initial_value()) {
     BasicType t = fd->field_type();
@@ -1674,29 +1700,26 @@
   assert(mirror != NULL && mirror->is_a(SystemDictionary::Class_klass()), "must be a Class");
   assert(java_lang_Class::is_primitive(mirror), "must be primitive");
   return mirror;
 }
 
-bool java_lang_Class::offsets_computed = false;
-int  java_lang_Class::classRedefinedCount_offset = -1;
-
-#define CLASS_FIELDS_DO(macro) \
-  macro(classRedefinedCount_offset, k, "classRedefinedCount", int_signature,         false); \
-  macro(_class_loader_offset,       k, "classLoader",         classloader_signature, false); \
-  macro(_component_mirror_offset,   k, "componentType",       class_signature,       false); \
-  macro(_module_offset,             k, "module",              module_signature,      false); \
-  macro(_name_offset,               k, "name",                string_signature,      false); \
-  macro(_val_type_mirror_offset,    k, "valType",             class_signature,       false); \
-  macro(_ref_type_mirror_offset,    k, "refType",             class_signature,       false); \
+#define CLASS_FIELDS_DO(macro) \
+  macro(_classRedefinedCount_offset, k, "classRedefinedCount", int_signature,         false); \
+  macro(_class_loader_offset,        k, "classLoader",         classloader_signature, false); \
+  macro(_component_mirror_offset,    k, "componentType",       class_signature,       false); \
+  macro(_module_offset,              k, "module",              module_signature,      false); \
+  macro(_name_offset,                k, "name",                string_signature,      false); \
+  macro(_val_type_mirror_offset,     k, "valType",             class_signature,       false); \
+  macro(_ref_type_mirror_offset,     k, "refType",             class_signature,       false); \
   macro(_classData_offset,          k, "classData",           object_signature,      false);
 
 void java_lang_Class::compute_offsets() {
-  if (offsets_computed) {
+  if (_offsets_computed) {
     return;
   }
 
-  offsets_computed = true;
+  _offsets_computed = true;
 
   InstanceKlass* k = SystemDictionary::Class_klass();
   CLASS_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 
   // Init lock is a C union with component_mirror.  Only instanceKlass mirrors have
@@ -1707,27 +1730,27 @@
   CLASS_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);
 }
 
 #if INCLUDE_CDS
 void java_lang_Class::serialize_offsets(SerializeClosure* f) {
-  f->do_bool(&offsets_computed);
+  f->do_bool(&_offsets_computed);
   f->do_u4((u4*)&_init_lock_offset);
 
   CLASS_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 
   CLASS_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 int java_lang_Class::classRedefinedCount(oop the_class_mirror) {
-  assert(classRedefinedCount_offset != -1, "offsets should have been initialized");
-  return the_class_mirror->int_field(classRedefinedCount_offset);
+  assert(_classRedefinedCount_offset != 0, "offsets should have been initialized");
+  return the_class_mirror->int_field(_classRedefinedCount_offset);
 }
 
 void java_lang_Class::set_classRedefinedCount(oop the_class_mirror, int value) {
-  assert(classRedefinedCount_offset != -1, "offsets should have been initialized");
-  the_class_mirror->int_field_put(classRedefinedCount_offset, value);
+  assert(_classRedefinedCount_offset != 0, "offsets should have been initialized");
+  the_class_mirror->int_field_put(_classRedefinedCount_offset, value);
 }
 
 
 // Note: JDK1.1 and before had a privateInfo_offset field which was used for the
 //       platform thread structure, and a eetop offset which was used for thread
@@ -1735,23 +1758,23 @@
 //       merged, so in the HotSpot VM we just use the eetop field for the thread
 //       instead of the privateInfo_offset.
 //
 // Note: The stackSize field is only present starting in 1.4.
 
-int java_lang_Thread::_name_offset = 0;
-int java_lang_Thread::_group_offset = 0;
-int java_lang_Thread::_contextClassLoader_offset = 0;
-int java_lang_Thread::_inheritedAccessControlContext_offset = 0;
-int java_lang_Thread::_priority_offset = 0;
-int java_lang_Thread::_eetop_offset = 0;
-int java_lang_Thread::_interrupted_offset = 0;
-int java_lang_Thread::_daemon_offset = 0;
-int java_lang_Thread::_stillborn_offset = 0;
-int java_lang_Thread::_stackSize_offset = 0;
-int java_lang_Thread::_tid_offset = 0;
-int java_lang_Thread::_thread_status_offset = 0;
-int java_lang_Thread::_park_blocker_offset = 0;
+int java_lang_Thread::_name_offset;
+int java_lang_Thread::_group_offset;
+int java_lang_Thread::_contextClassLoader_offset;
+int java_lang_Thread::_inheritedAccessControlContext_offset;
+int java_lang_Thread::_priority_offset;
+int java_lang_Thread::_eetop_offset;
+int java_lang_Thread::_interrupted_offset;
+int java_lang_Thread::_daemon_offset;
+int java_lang_Thread::_stillborn_offset;
+int java_lang_Thread::_stackSize_offset;
+int java_lang_Thread::_tid_offset;
+int java_lang_Thread::_thread_status_offset;
+int java_lang_Thread::_park_blocker_offset;
 
 #define THREAD_FIELDS_DO(macro) \
   macro(_name_offset,          k, vmSymbols::name_name(), string_signature, false); \
   macro(_group_offset,         k, vmSymbols::group_name(), threadgroup_signature, false); \
   macro(_contextClassLoader_offset, k, vmSymbols::contextClassLoader_name(), classloader_signature, false); \
@@ -1909,19 +1932,19 @@
     case BLOCKED_ON_MONITOR_ENTER : return "BLOCKED (on object monitor)";
     case TERMINATED               : return "TERMINATED";
     default                       : return "UNKNOWN";
   };
 }
-int java_lang_ThreadGroup::_parent_offset = 0;
-int java_lang_ThreadGroup::_name_offset = 0;
-int java_lang_ThreadGroup::_threads_offset = 0;
-int java_lang_ThreadGroup::_groups_offset = 0;
-int java_lang_ThreadGroup::_maxPriority_offset = 0;
-int java_lang_ThreadGroup::_destroyed_offset = 0;
-int java_lang_ThreadGroup::_daemon_offset = 0;
-int java_lang_ThreadGroup::_nthreads_offset = 0;
-int java_lang_ThreadGroup::_ngroups_offset = 0;
+int java_lang_ThreadGroup::_parent_offset;
+int java_lang_ThreadGroup::_name_offset;
+int java_lang_ThreadGroup::_threads_offset;
+int java_lang_ThreadGroup::_groups_offset;
+int java_lang_ThreadGroup::_maxPriority_offset;
+int java_lang_ThreadGroup::_destroyed_offset;
+int java_lang_ThreadGroup::_daemon_offset;
+int java_lang_ThreadGroup::_nthreads_offset;
+int java_lang_ThreadGroup::_ngroups_offset;
 
 oop  java_lang_ThreadGroup::parent(oop java_thread_group) {
   assert(oopDesc::is_oop(java_thread_group), "thread group must be oop");
   return java_thread_group->obj_field(_parent_offset);
 }
@@ -1997,16 +2020,24 @@
 void java_lang_ThreadGroup::serialize_offsets(SerializeClosure* f) {
   THREADGROUP_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+// java_lang_Throwable
+
+int java_lang_Throwable::_backtrace_offset;
+int java_lang_Throwable::_detailMessage_offset;
+int java_lang_Throwable::_stackTrace_offset;
+int java_lang_Throwable::_depth_offset;
+int java_lang_Throwable::_static_unassigned_stacktrace_offset;
+
 #define THROWABLE_FIELDS_DO(macro) \
-  macro(backtrace_offset,     k, "backtrace",     object_signature,                  false); \
-  macro(detailMessage_offset, k, "detailMessage", string_signature,                  false); \
-  macro(stackTrace_offset,    k, "stackTrace",    java_lang_StackTraceElement_array, false); \
-  macro(depth_offset,         k, "depth",         int_signature,                     false); \
-  macro(static_unassigned_stacktrace_offset, k, "UNASSIGNED_STACK", java_lang_StackTraceElement_array, true)
+  macro(_backtrace_offset,     k, "backtrace",     object_signature,                  false); \
+  macro(_detailMessage_offset, k, "detailMessage", string_signature,                  false); \
+  macro(_stackTrace_offset,    k, "stackTrace",    java_lang_StackTraceElement_array, false); \
+  macro(_depth_offset,         k, "depth",         int_signature,                     false); \
+  macro(_static_unassigned_stacktrace_offset, k, "UNASSIGNED_STACK", java_lang_StackTraceElement_array, true)
 
 void java_lang_Throwable::compute_offsets() {
   InstanceKlass* k = SystemDictionary::Throwable_klass();
   THROWABLE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -2018,32 +2049,32 @@
 #endif
 
 oop java_lang_Throwable::unassigned_stacktrace() {
   InstanceKlass* ik = SystemDictionary::Throwable_klass();
   oop base = ik->static_field_base_raw();
-  return base->obj_field(static_unassigned_stacktrace_offset);
+  return base->obj_field(_static_unassigned_stacktrace_offset);
 }
 
 oop java_lang_Throwable::backtrace(oop throwable) {
-  return throwable->obj_field_acquire(backtrace_offset);
+  return throwable->obj_field_acquire(_backtrace_offset);
 }
 
 
 void java_lang_Throwable::set_backtrace(oop throwable, oop value) {
-  throwable->release_obj_field_put(backtrace_offset, value);
+  throwable->release_obj_field_put(_backtrace_offset, value);
 }
 
 int java_lang_Throwable::depth(oop throwable) {
-  return throwable->int_field(depth_offset);
+  return throwable->int_field(_depth_offset);
 }
 
 void java_lang_Throwable::set_depth(oop throwable, int value) {
-  throwable->int_field_put(depth_offset, value);
+  throwable->int_field_put(_depth_offset, value);
 }
 
 oop java_lang_Throwable::message(oop throwable) {
-  return throwable->obj_field(detailMessage_offset);
+  return throwable->obj_field(_detailMessage_offset);
 }
 
 
 // Return Symbol for detailed_message or NULL
 Symbol* java_lang_Throwable::detail_message(oop throwable) {
@@ -2054,16 +2085,16 @@
   }
   return NULL;
 }
 
 void java_lang_Throwable::set_message(oop throwable, oop value) {
-  throwable->obj_field_put(detailMessage_offset, value);
+  throwable->obj_field_put(_detailMessage_offset, value);
 }
 
 
 void java_lang_Throwable::set_stacktrace(oop throwable, oop st_element_array) {
-  throwable->obj_field_put(stackTrace_offset, st_element_array);
+  throwable->obj_field_put(_stackTrace_offset, st_element_array);
 }
 
 void java_lang_Throwable::clear_stacktrace(oop throwable) {
   set_stacktrace(throwable, NULL);
 }
@@ -2838,10 +2869,33 @@
   Handle java_class(THREAD, holder->java_mirror());
   decode_file_and_line(java_class, holder, version, method, bci, filename, source_file, line_number, CHECK);
 }
 #endif // INCLUDE_JVMCI
 
+// java_lang_StackFrameInfo
+
+int java_lang_StackFrameInfo::_memberName_offset;
+int java_lang_StackFrameInfo::_bci_offset;
+int java_lang_StackFrameInfo::_version_offset;
+
+#define STACKFRAMEINFO_FIELDS_DO(macro) \
+  macro(_memberName_offset,     k, "memberName",  object_signature, false); \
+  macro(_bci_offset,            k, "bci",         int_signature,    false)
+
+void java_lang_StackFrameInfo::compute_offsets() {
+  InstanceKlass* k = SystemDictionary::StackFrameInfo_klass();
+  STACKFRAMEINFO_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+  STACKFRAMEINFO_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void java_lang_StackFrameInfo::serialize_offsets(SerializeClosure* f) {
+  STACKFRAMEINFO_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+  STACKFRAMEINFO_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);
+}
+#endif
+
 Method* java_lang_StackFrameInfo::get_method(Handle stackFrame, InstanceKlass* holder, TRAPS) {
   HandleMark hm(THREAD);
   Handle mname(THREAD, stackFrame->obj_field(_memberName_offset));
   Method* method = (Method*)java_lang_invoke_MemberName::vmtarget(mname());
   // we should expand MemberName::name when Throwable uses StackTrace
@@ -2877,26 +2931,23 @@
   Symbol* name = method->name();
   java_lang_StackTraceElement::fill_in(stack_trace_element, holder, methodHandle(THREAD, method),
                                        version, bci, name, CHECK);
 }
 
-#define STACKFRAMEINFO_FIELDS_DO(macro) \
-  macro(_memberName_offset,     k, "memberName",  object_signature, false); \
-  macro(_bci_offset,            k, "bci",         int_signature,    false)
-
-void java_lang_StackFrameInfo::compute_offsets() {
-  InstanceKlass* k = SystemDictionary::StackFrameInfo_klass();
-  STACKFRAMEINFO_FIELDS_DO(FIELD_COMPUTE_OFFSET);
-  STACKFRAMEINFO_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);
+void java_lang_StackFrameInfo::set_version(oop element, short value) {
+  element->short_field_put(_version_offset, value);
 }
 
-#if INCLUDE_CDS
-void java_lang_StackFrameInfo::serialize_offsets(SerializeClosure* f) {
-  STACKFRAMEINFO_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
-  STACKFRAMEINFO_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);
+void java_lang_StackFrameInfo::set_bci(oop element, int value) {
+  assert(value >= 0 && value < max_jushort, "must be a valid bci value");
+  element->int_field_put(_bci_offset, value);
 }
-#endif
+
+int java_lang_LiveStackFrameInfo::_monitors_offset;
+int java_lang_LiveStackFrameInfo::_locals_offset;
+int java_lang_LiveStackFrameInfo::_operands_offset;
+int java_lang_LiveStackFrameInfo::_mode_offset;
 
 #define LIVESTACKFRAMEINFO_FIELDS_DO(macro) \
   macro(_monitors_offset,   k, "monitors",    object_array_signature, false); \
   macro(_locals_offset,     k, "locals",      object_array_signature, false); \
   macro(_operands_offset,   k, "operands",    object_array_signature, false); \
@@ -2911,12 +2962,33 @@
 void java_lang_LiveStackFrameInfo::serialize_offsets(SerializeClosure* f) {
   LIVESTACKFRAMEINFO_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+void java_lang_LiveStackFrameInfo::set_monitors(oop element, oop value) {
+  element->obj_field_put(_monitors_offset, value);
+}
+
+void java_lang_LiveStackFrameInfo::set_locals(oop element, oop value) {
+  element->obj_field_put(_locals_offset, value);
+}
+
+void java_lang_LiveStackFrameInfo::set_operands(oop element, oop value) {
+  element->obj_field_put(_operands_offset, value);
+}
+
+void java_lang_LiveStackFrameInfo::set_mode(oop element, int value) {
+  element->int_field_put(_mode_offset, value);
+}
+
+
+// java_lang_AccessibleObject
+
+int java_lang_reflect_AccessibleObject::_override_offset;
+
 #define ACCESSIBLEOBJECT_FIELDS_DO(macro) \
-  macro(override_offset, k, "override", bool_signature, false)
+  macro(_override_offset, k, "override", bool_signature, false)
 
 void java_lang_reflect_AccessibleObject::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_AccessibleObject_klass();
   ACCESSIBLEOBJECT_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -2926,31 +2998,43 @@
   ACCESSIBLEOBJECT_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 jboolean java_lang_reflect_AccessibleObject::override(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return (jboolean) reflect->bool_field(override_offset);
+  return (jboolean) reflect->bool_field(_override_offset);
 }
 
 void java_lang_reflect_AccessibleObject::set_override(oop reflect, jboolean value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  reflect->bool_field_put(override_offset, (int) value);
+  reflect->bool_field_put(_override_offset, (int) value);
 }
 
+// java_lang_reflect_Method
+
+int java_lang_reflect_Method::_clazz_offset;
+int java_lang_reflect_Method::_name_offset;
+int java_lang_reflect_Method::_returnType_offset;
+int java_lang_reflect_Method::_parameterTypes_offset;
+int java_lang_reflect_Method::_exceptionTypes_offset;
+int java_lang_reflect_Method::_slot_offset;
+int java_lang_reflect_Method::_modifiers_offset;
+int java_lang_reflect_Method::_signature_offset;
+int java_lang_reflect_Method::_annotations_offset;
+int java_lang_reflect_Method::_parameter_annotations_offset;
+int java_lang_reflect_Method::_annotation_default_offset;
+
 #define METHOD_FIELDS_DO(macro) \
-  macro(clazz_offset,          k, vmSymbols::clazz_name(),          class_signature,       false); \
-  macro(name_offset,           k, vmSymbols::name_name(),           string_signature,      false); \
-  macro(returnType_offset,     k, vmSymbols::returnType_name(),     class_signature,       false); \
-  macro(parameterTypes_offset, k, vmSymbols::parameterTypes_name(), class_array_signature, false); \
-  macro(exceptionTypes_offset, k, vmSymbols::exceptionTypes_name(), class_array_signature, false); \
-  macro(slot_offset,           k, vmSymbols::slot_name(),           int_signature,         false); \
-  macro(modifiers_offset,      k, vmSymbols::modifiers_name(),      int_signature,         false); \
-  macro(signature_offset,             k, vmSymbols::signature_name(),             string_signature,     false); \
-  macro(annotations_offset,           k, vmSymbols::annotations_name(),           byte_array_signature, false); \
-  macro(parameter_annotations_offset, k, vmSymbols::parameter_annotations_name(), byte_array_signature, false); \
-  macro(annotation_default_offset,    k, vmSymbols::annotation_default_name(),    byte_array_signature, false);
+  macro(_clazz_offset,          k, vmSymbols::clazz_name(),          class_signature,       false); \
+  macro(_name_offset,           k, vmSymbols::name_name(),           string_signature,      false); \
+  macro(_returnType_offset,     k, vmSymbols::returnType_name(),     class_signature,       false); \
+  macro(_parameterTypes_offset, k, vmSymbols::parameterTypes_name(), class_array_signature, false); \
+  macro(_exceptionTypes_offset, k, vmSymbols::exceptionTypes_name(), class_array_signature, false); \
+  macro(_slot_offset,           k, vmSymbols::slot_name(),           int_signature,         false); \
+  macro(_modifiers_offset,      k, vmSymbols::modifiers_name(),      int_signature,         false); \
+  macro(_signature_offset,             k, vmSymbols::signature_name(),             string_signature,     false); \
+  macro(_annotations_offset,           k, vmSymbols::annotations_name(),           byte_array_signature, false); \
+  macro(_parameter_annotations_offset, k, vmSymbols::parameter_annotations_name(), byte_array_signature, false); \
+  macro(_annotation_default_offset,    k, vmSymbols::annotation_default_name(),    byte_array_signature, false);
 
 void java_lang_reflect_Method::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_Method_klass();
   METHOD_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -2969,93 +3053,87 @@
   assert(InstanceKlass::cast(klass)->is_initialized(), "must be initialized");
   return InstanceKlass::cast(klass)->allocate_instance_handle(THREAD);
 }
 
 oop java_lang_reflect_Method::clazz(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->obj_field(clazz_offset);
+  return reflect->obj_field(_clazz_offset);
 }
 
 void java_lang_reflect_Method::set_clazz(oop reflect, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-   reflect->obj_field_put(clazz_offset, value);
+   reflect->obj_field_put(_clazz_offset, value);
 }
 
 int java_lang_reflect_Method::slot(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->int_field(slot_offset);
+  return reflect->int_field(_slot_offset);
 }
 
 void java_lang_reflect_Method::set_slot(oop reflect, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  reflect->int_field_put(slot_offset, value);
+  reflect->int_field_put(_slot_offset, value);
 }
 
 void java_lang_reflect_Method::set_name(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(name_offset, value);
+  method->obj_field_put(_name_offset, value);
 }
 
 oop java_lang_reflect_Method::return_type(oop method) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return method->obj_field(returnType_offset);
+  return method->obj_field(_returnType_offset);
 }
 
 void java_lang_reflect_Method::set_return_type(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(returnType_offset, value);
+  method->obj_field_put(_returnType_offset, value);
 }
 
 oop java_lang_reflect_Method::parameter_types(oop method) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return method->obj_field(parameterTypes_offset);
+  return method->obj_field(_parameterTypes_offset);
 }
 
 void java_lang_reflect_Method::set_parameter_types(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(parameterTypes_offset, value);
+  method->obj_field_put(_parameterTypes_offset, value);
 }
 
 void java_lang_reflect_Method::set_exception_types(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(exceptionTypes_offset, value);
+  method->obj_field_put(_exceptionTypes_offset, value);
 }
 
 void java_lang_reflect_Method::set_modifiers(oop method, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->int_field_put(modifiers_offset, value);
+  method->int_field_put(_modifiers_offset, value);
 }
 
 void java_lang_reflect_Method::set_signature(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(signature_offset, value);
+  method->obj_field_put(_signature_offset, value);
 }
 
 void java_lang_reflect_Method::set_annotations(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(annotations_offset, value);
+  method->obj_field_put(_annotations_offset, value);
 }
 
 void java_lang_reflect_Method::set_parameter_annotations(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(parameter_annotations_offset, value);
+  method->obj_field_put(_parameter_annotations_offset, value);
 }
 
 void java_lang_reflect_Method::set_annotation_default(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(annotation_default_offset, value);
+  method->obj_field_put(_annotation_default_offset, value);
 }
 
+int java_lang_reflect_Constructor::_clazz_offset;
+int java_lang_reflect_Constructor::_parameterTypes_offset;
+int java_lang_reflect_Constructor::_exceptionTypes_offset;
+int java_lang_reflect_Constructor::_slot_offset;
+int java_lang_reflect_Constructor::_modifiers_offset;
+int java_lang_reflect_Constructor::_signature_offset;
+int java_lang_reflect_Constructor::_annotations_offset;
+int java_lang_reflect_Constructor::_parameter_annotations_offset;
+
 #define CONSTRUCTOR_FIELDS_DO(macro) \
-  macro(clazz_offset,          k, vmSymbols::clazz_name(),          class_signature,       false); \
-  macro(parameterTypes_offset, k, vmSymbols::parameterTypes_name(), class_array_signature, false); \
-  macro(exceptionTypes_offset, k, vmSymbols::exceptionTypes_name(), class_array_signature, false); \
-  macro(slot_offset,           k, vmSymbols::slot_name(),           int_signature,         false); \
-  macro(modifiers_offset,      k, vmSymbols::modifiers_name(),      int_signature,         false); \
-  macro(signature_offset,             k, vmSymbols::signature_name(),             string_signature,     false); \
-  macro(annotations_offset,           k, vmSymbols::annotations_name(),           byte_array_signature, false); \
-  macro(parameter_annotations_offset, k, vmSymbols::parameter_annotations_name(), byte_array_signature, false);
+  macro(_clazz_offset,          k, vmSymbols::clazz_name(),          class_signature,       false); \
+  macro(_parameterTypes_offset, k, vmSymbols::parameterTypes_name(), class_array_signature, false); \
+  macro(_exceptionTypes_offset, k, vmSymbols::exceptionTypes_name(), class_array_signature, false); \
+  macro(_slot_offset,           k, vmSymbols::slot_name(),           int_signature,         false); \
+  macro(_modifiers_offset,      k, vmSymbols::modifiers_name(),      int_signature,         false); \
+  macro(_signature_offset,             k, vmSymbols::signature_name(),             string_signature,     false); \
+  macro(_annotations_offset,           k, vmSymbols::annotations_name(),           byte_array_signature, false); \
+  macro(_parameter_annotations_offset, k, vmSymbols::parameter_annotations_name(), byte_array_signature, false);
 
 void java_lang_reflect_Constructor::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_Constructor_klass();
   CONSTRUCTOR_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -3075,72 +3153,69 @@
   ik->initialize(CHECK_NH);
   return ik->allocate_instance_handle(THREAD);
 }
 
 oop java_lang_reflect_Constructor::clazz(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->obj_field(clazz_offset);
+  return reflect->obj_field(_clazz_offset);
 }
 
 void java_lang_reflect_Constructor::set_clazz(oop reflect, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-   reflect->obj_field_put(clazz_offset, value);
+   reflect->obj_field_put(_clazz_offset, value);
 }
 
 oop java_lang_reflect_Constructor::parameter_types(oop constructor) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return constructor->obj_field(parameterTypes_offset);
+  return constructor->obj_field(_parameterTypes_offset);
 }
 
 void java_lang_reflect_Constructor::set_parameter_types(oop constructor, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  constructor->obj_field_put(parameterTypes_offset, value);
+  constructor->obj_field_put(_parameterTypes_offset, value);
 }
 
 void java_lang_reflect_Constructor::set_exception_types(oop constructor, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  constructor->obj_field_put(exceptionTypes_offset, value);
+  constructor->obj_field_put(_exceptionTypes_offset, value);
 }
 
 int java_lang_reflect_Constructor::slot(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->int_field(slot_offset);
+  return reflect->int_field(_slot_offset);
 }
 
 void java_lang_reflect_Constructor::set_slot(oop reflect, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  reflect->int_field_put(slot_offset, value);
+  reflect->int_field_put(_slot_offset, value);
 }
 
 void java_lang_reflect_Constructor::set_modifiers(oop constructor, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  constructor->int_field_put(modifiers_offset, value);
+  constructor->int_field_put(_modifiers_offset, value);
 }
 
 void java_lang_reflect_Constructor::set_signature(oop constructor, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  constructor->obj_field_put(signature_offset, value);
+  constructor->obj_field_put(_signature_offset, value);
 }
 
 void java_lang_reflect_Constructor::set_annotations(oop constructor, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  constructor->obj_field_put(annotations_offset, value);
+  constructor->obj_field_put(_annotations_offset, value);
 }
 
 void java_lang_reflect_Constructor::set_parameter_annotations(oop method, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  method->obj_field_put(parameter_annotations_offset, value);
+  method->obj_field_put(_parameter_annotations_offset, value);
 }
 
+int java_lang_reflect_Field::_clazz_offset;
+int java_lang_reflect_Field::_name_offset;
+int java_lang_reflect_Field::_type_offset;
+int java_lang_reflect_Field::_slot_offset;
+int java_lang_reflect_Field::_modifiers_offset;
+int java_lang_reflect_Field::_signature_offset;
+int java_lang_reflect_Field::_annotations_offset;
+
 #define FIELD_FIELDS_DO(macro) \
-  macro(clazz_offset,     k, vmSymbols::clazz_name(),     class_signature,  false); \
-  macro(name_offset,      k, vmSymbols::name_name(),      string_signature, false); \
-  macro(type_offset,      k, vmSymbols::type_name(),      class_signature,  false); \
-  macro(slot_offset,      k, vmSymbols::slot_name(),      int_signature,    false); \
-  macro(modifiers_offset, k, vmSymbols::modifiers_name(), int_signature,    false); \
-  macro(signature_offset,        k, vmSymbols::signature_name(),        string_signature,     false); \
-  macro(annotations_offset,      k, vmSymbols::annotations_name(),      byte_array_signature, false);
+  macro(_clazz_offset,     k, vmSymbols::clazz_name(),     class_signature,  false); \
+  macro(_name_offset,      k, vmSymbols::name_name(),      string_signature, false); \
+  macro(_type_offset,      k, vmSymbols::type_name(),      class_signature,  false); \
+  macro(_slot_offset,      k, vmSymbols::slot_name(),      int_signature,    false); \
+  macro(_modifiers_offset, k, vmSymbols::modifiers_name(), int_signature,    false); \
+  macro(_signature_offset,        k, vmSymbols::signature_name(),        string_signature,     false); \
+  macro(_annotations_offset,      k, vmSymbols::annotations_name(),      byte_array_signature, false);
 
 void java_lang_reflect_Field::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_Field_klass();
   FIELD_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -3160,67 +3235,55 @@
   ik->initialize(CHECK_NH);
   return ik->allocate_instance_handle(THREAD);
 }
 
 oop java_lang_reflect_Field::clazz(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->obj_field(clazz_offset);
+  return reflect->obj_field(_clazz_offset);
 }
 
 void java_lang_reflect_Field::set_clazz(oop reflect, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-   reflect->obj_field_put(clazz_offset, value);
+  reflect->obj_field_put(_clazz_offset, value);
 }
 
 oop java_lang_reflect_Field::name(oop field) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return field->obj_field(name_offset);
+  return field->obj_field(_name_offset);
 }
 
 void java_lang_reflect_Field::set_name(oop field, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  field->obj_field_put(name_offset, value);
+  field->obj_field_put(_name_offset, value);
 }
 
 oop java_lang_reflect_Field::type(oop field) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return field->obj_field(type_offset);
+  return field->obj_field(_type_offset);
 }
 
 void java_lang_reflect_Field::set_type(oop field, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  field->obj_field_put(type_offset, value);
+  field->obj_field_put(_type_offset, value);
 }
 
 int java_lang_reflect_Field::slot(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return reflect->int_field(slot_offset);
+  return reflect->int_field(_slot_offset);
 }
 
 void java_lang_reflect_Field::set_slot(oop reflect, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  reflect->int_field_put(slot_offset, value);
+  reflect->int_field_put(_slot_offset, value);
 }
 
 int java_lang_reflect_Field::modifiers(oop field) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return field->int_field(modifiers_offset);
+  return field->int_field(_modifiers_offset);
 }
 
 void java_lang_reflect_Field::set_modifiers(oop field, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  field->int_field_put(modifiers_offset, value);
+  field->int_field_put(_modifiers_offset, value);
 }
 
 void java_lang_reflect_Field::set_signature(oop field, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  field->obj_field_put(signature_offset, value);
+  field->obj_field_put(_signature_offset, value);
 }
 
 void java_lang_reflect_Field::set_annotations(oop field, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  field->obj_field_put(annotations_offset, value);
+  field->obj_field_put(_annotations_offset, value);
 }
 
 oop java_lang_reflect_RecordComponent::create(InstanceKlass* holder, RecordComponent* component, TRAPS) {
   // Allocate java.lang.reflect.RecordComponent instance
   HandleMark hm(THREAD);
@@ -3277,10 +3340,12 @@
   java_lang_reflect_RecordComponent::set_typeAnnotations(element(), type_annotation_oop);
 
   return element();
 }
 
+int reflect_ConstantPool::_oop_offset;
+
 #define CONSTANTPOOL_FIELDS_DO(macro) \
   macro(_oop_offset, k, "constantPoolOop", object_signature, false)
 
 void reflect_ConstantPool::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_ConstantPool_klass();
@@ -3292,15 +3357,20 @@
 void reflect_ConstantPool::serialize_offsets(SerializeClosure* f) {
   CONSTANTPOOL_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+int java_lang_reflect_Parameter::_name_offset;
+int java_lang_reflect_Parameter::_modifiers_offset;
+int java_lang_reflect_Parameter::_index_offset;
+int java_lang_reflect_Parameter::_executable_offset;
+
 #define PARAMETER_FIELDS_DO(macro) \
-  macro(name_offset,        k, vmSymbols::name_name(),        string_signature, false); \
-  macro(modifiers_offset,   k, vmSymbols::modifiers_name(),   int_signature,    false); \
-  macro(index_offset,       k, vmSymbols::index_name(),       int_signature,    false); \
-  macro(executable_offset,  k, vmSymbols::executable_name(),  executable_signature, false)
+  macro(_name_offset,        k, vmSymbols::name_name(),        string_signature, false); \
+  macro(_modifiers_offset,   k, vmSymbols::modifiers_name(),   int_signature,    false); \
+  macro(_index_offset,       k, vmSymbols::index_name(),       int_signature,    false); \
+  macro(_executable_offset,  k, vmSymbols::executable_name(),  executable_signature, false)
 
 void java_lang_reflect_Parameter::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_Parameter_klass();
   PARAMETER_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -3320,64 +3390,57 @@
   ik->initialize(CHECK_NH);
   return ik->allocate_instance_handle(THREAD);
 }
 
 oop java_lang_reflect_Parameter::name(oop param) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return param->obj_field(name_offset);
+  return param->obj_field(_name_offset);
 }
 
 void java_lang_reflect_Parameter::set_name(oop param, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  param->obj_field_put(name_offset, value);
+  param->obj_field_put(_name_offset, value);
 }
 
 int java_lang_reflect_Parameter::modifiers(oop param) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return param->int_field(modifiers_offset);
+  return param->int_field(_modifiers_offset);
 }
 
 void java_lang_reflect_Parameter::set_modifiers(oop param, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  param->int_field_put(modifiers_offset, value);
+  param->int_field_put(_modifiers_offset, value);
 }
 
 int java_lang_reflect_Parameter::index(oop param) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return param->int_field(index_offset);
+  return param->int_field(_index_offset);
 }
 
 void java_lang_reflect_Parameter::set_index(oop param, int value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  param->int_field_put(index_offset, value);
+  param->int_field_put(_index_offset, value);
 }
 
 oop java_lang_reflect_Parameter::executable(oop param) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return param->obj_field(executable_offset);
+  return param->obj_field(_executable_offset);
 }
 
 void java_lang_reflect_Parameter::set_executable(oop param, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  param->obj_field_put(executable_offset, value);
+  param->obj_field_put(_executable_offset, value);
 }
 
+// java_lang_Module
 
-int java_lang_Module::loader_offset;
-int java_lang_Module::name_offset;
-int java_lang_Module::_module_entry_offset = -1;
+int java_lang_Module::_loader_offset;
+int java_lang_Module::_name_offset;
+int java_lang_Module::_module_entry_offset;
 
 Handle java_lang_Module::create(Handle loader, Handle module_name, TRAPS) {
   assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
   return JavaCalls::construct_new_instance(SystemDictionary::Module_klass(),
                           vmSymbols::java_lang_module_init_signature(),
                           loader, module_name, CHECK_NH);
 }
 
 #define MODULE_FIELDS_DO(macro) \
-  macro(loader_offset,  k, vmSymbols::loader_name(),  classloader_signature, false); \
-  macro(name_offset,    k, vmSymbols::name_name(),    string_signature,      false)
+  macro(_loader_offset,  k, vmSymbols::loader_name(),  classloader_signature, false); \
+  macro(_name_offset,    k, vmSymbols::name_name(),    string_signature,      false)
 
 void java_lang_Module::compute_offsets() {
   InstanceKlass* k = SystemDictionary::Module_klass();
   MODULE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
   MODULE_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);
@@ -3389,31 +3452,27 @@
   MODULE_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 oop java_lang_Module::loader(oop module) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return module->obj_field(loader_offset);
+  return module->obj_field(_loader_offset);
 }
 
 void java_lang_Module::set_loader(oop module, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  module->obj_field_put(loader_offset, value);
+  module->obj_field_put(_loader_offset, value);
 }
 
 oop java_lang_Module::name(oop module) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  return module->obj_field(name_offset);
+  return module->obj_field(_name_offset);
 }
 
 void java_lang_Module::set_name(oop module, oop value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
-  module->obj_field_put(name_offset, value);
+  module->obj_field_put(_name_offset, value);
 }
 
 ModuleEntry* java_lang_Module::module_entry(oop module) {
-  assert(_module_entry_offset != -1, "Uninitialized module_entry_offset");
+  assert(_module_entry_offset != 0, "Uninitialized module_entry_offset");
   assert(module != NULL, "module can't be null");
   assert(oopDesc::is_oop(module), "module must be oop");
 
   ModuleEntry* module_entry = (ModuleEntry*)module->address_field(_module_entry_offset);
   if (module_entry == NULL) {
@@ -3426,11 +3485,11 @@
   }
   return module_entry;
 }
 
 void java_lang_Module::set_module_entry(oop module, ModuleEntry* module_entry) {
-  assert(_module_entry_offset != -1, "Uninitialized module_entry_offset");
+  assert(_module_entry_offset != 0, "Uninitialized module_entry_offset");
   assert(module != NULL, "module can't be null");
   assert(oopDesc::is_oop(module), "module must be oop");
   module->address_field_put(_module_entry_offset, (address)module_entry);
 }
 
@@ -3442,18 +3501,16 @@
   return k->allocate_instance_handle(THREAD);
 }
 
 
 void reflect_ConstantPool::set_cp(oop reflect, ConstantPool* value) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
   oop mirror = value->pool_holder()->java_mirror();
   // Save the mirror to get back the constant pool.
   reflect->obj_field_put(_oop_offset, mirror);
 }
 
 ConstantPool* reflect_ConstantPool::get_cp(oop reflect) {
-  assert(Universe::is_fully_initialized(), "Need to find another solution to the reflection problem");
 
   oop mirror = reflect->obj_field(_oop_offset);
   Klass* k = java_lang_Class::as_Klass(mirror);
   assert(k->is_instance_klass(), "Must be");
 
@@ -3463,10 +3520,12 @@
   // no longer done in the future, this will have to change to save
   // the original.
   return InstanceKlass::cast(k)->constants();
 }
 
+int reflect_UnsafeStaticFieldAccessorImpl::_base_offset;
+
 #define UNSAFESTATICFIELDACCESSORIMPL_FIELDS_DO(macro) \
   macro(_base_offset, k, "base", object_signature, false)
 
 void reflect_UnsafeStaticFieldAccessorImpl::compute_offsets() {
   InstanceKlass* k = SystemDictionary::reflect_UnsafeStaticFieldAccessorImpl_klass();
@@ -3477,10 +3536,77 @@
 void reflect_UnsafeStaticFieldAccessorImpl::serialize_offsets(SerializeClosure* f) {
   UNSAFESTATICFIELDACCESSORIMPL_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+// Support for java_lang_ref_Reference
+
+bool java_lang_ref_Reference::_offsets_initialized;
+
+int java_lang_ref_Reference::_referent_offset;
+int java_lang_ref_Reference::_queue_offset;
+int java_lang_ref_Reference::_next_offset;
+int java_lang_ref_Reference::_discovered_offset;
+
+#define REFERENCE_FIELDS_DO(macro) \
+  macro(_referent_offset,   k, "referent", object_signature, false); \
+  macro(_queue_offset,      k, "queue", referencequeue_signature, false); \
+  macro(_next_offset,       k, "next", reference_signature, false); \
+  macro(_discovered_offset, k, "discovered", reference_signature, false);
+
+void java_lang_ref_Reference::compute_offsets() {
+  if (_offsets_initialized) {
+    return;
+  }
+  _offsets_initialized = true;
+  InstanceKlass* k = SystemDictionary::Reference_klass();
+  REFERENCE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void java_lang_ref_Reference::serialize_offsets(SerializeClosure* f) {
+  f->do_bool(&_offsets_initialized);
+  REFERENCE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+}
+#endif
+
+bool java_lang_ref_Reference::is_referent_field(oop obj, ptrdiff_t offset) {
+  assert(obj != NULL, "sanity");
+  if (offset != _referent_offset) {
+    return false;
+  }
+
+  Klass* k = obj->klass();
+  if (!k->is_instance_klass()) {
+    return false;
+  }
+
+  InstanceKlass* ik = InstanceKlass::cast(obj->klass());
+  bool is_reference = ik->reference_type() != REF_NONE;
+  assert(!is_reference || ik->is_subclass_of(SystemDictionary::Reference_klass()), "sanity");
+  return is_reference;
+}
+
+int java_lang_boxing_object::_value_offset;
+int java_lang_boxing_object::_long_value_offset;
+
+#define BOXING_FIELDS_DO(macro) \
+  macro(_value_offset,      integerKlass, "value", int_signature, false); \
+  macro(_long_value_offset, longKlass, "value", long_signature, false);
+
+void java_lang_boxing_object::compute_offsets() {
+  InstanceKlass* integerKlass = SystemDictionary::Integer_klass();
+  InstanceKlass* longKlass = SystemDictionary::Long_klass();
+  BOXING_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void java_lang_boxing_object::serialize_offsets(SerializeClosure* f) {
+  BOXING_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+}
+#endif
+
 oop java_lang_boxing_object::initialize_and_allocate(BasicType type, TRAPS) {
   Klass* k = SystemDictionary::box_klass(type);
   if (k == NULL)  return NULL;
   InstanceKlass* ik = InstanceKlass::cast(k);
   if (!ik->is_initialized())  ik->initialize(CHECK_NULL);
@@ -3491,32 +3617,32 @@
 oop java_lang_boxing_object::create(BasicType type, jvalue* value, TRAPS) {
   oop box = initialize_and_allocate(type, CHECK_NULL);
   if (box == NULL)  return NULL;
   switch (type) {
     case T_BOOLEAN:
-      box->bool_field_put(value_offset, value->z);
+      box->bool_field_put(_value_offset, value->z);
       break;
     case T_CHAR:
-      box->char_field_put(value_offset, value->c);
+      box->char_field_put(_value_offset, value->c);
       break;
     case T_FLOAT:
-      box->float_field_put(value_offset, value->f);
+      box->float_field_put(_value_offset, value->f);
       break;
     case T_DOUBLE:
-      box->double_field_put(long_value_offset, value->d);
+      box->double_field_put(_long_value_offset, value->d);
       break;
     case T_BYTE:
-      box->byte_field_put(value_offset, value->b);
+      box->byte_field_put(_value_offset, value->b);
       break;
     case T_SHORT:
-      box->short_field_put(value_offset, value->s);
+      box->short_field_put(_value_offset, value->s);
       break;
     case T_INT:
-      box->int_field_put(value_offset, value->i);
+      box->int_field_put(_value_offset, value->i);
       break;
     case T_LONG:
-      box->long_field_put(long_value_offset, value->j);
+      box->long_field_put(_long_value_offset, value->j);
       break;
     default:
       return NULL;
   }
   return box;
@@ -3534,32 +3660,32 @@
 
 BasicType java_lang_boxing_object::get_value(oop box, jvalue* value) {
   BasicType type = SystemDictionary::box_klass_type(box->klass());
   switch (type) {
   case T_BOOLEAN:
-    value->z = box->bool_field(value_offset);
+    value->z = box->bool_field(_value_offset);
     break;
   case T_CHAR:
-    value->c = box->char_field(value_offset);
+    value->c = box->char_field(_value_offset);
     break;
   case T_FLOAT:
-    value->f = box->float_field(value_offset);
+    value->f = box->float_field(_value_offset);
     break;
   case T_DOUBLE:
-    value->d = box->double_field(long_value_offset);
+    value->d = box->double_field(_long_value_offset);
     break;
   case T_BYTE:
-    value->b = box->byte_field(value_offset);
+    value->b = box->byte_field(_value_offset);
     break;
   case T_SHORT:
-    value->s = box->short_field(value_offset);
+    value->s = box->short_field(_value_offset);
     break;
   case T_INT:
-    value->i = box->int_field(value_offset);
+    value->i = box->int_field(_value_offset);
     break;
   case T_LONG:
-    value->j = box->long_field(long_value_offset);
+    value->j = box->long_field(_long_value_offset);
     break;
   default:
     return T_ILLEGAL;
   } // end switch
   return type;
@@ -3568,32 +3694,32 @@
 
 BasicType java_lang_boxing_object::set_value(oop box, jvalue* value) {
   BasicType type = SystemDictionary::box_klass_type(box->klass());
   switch (type) {
   case T_BOOLEAN:
-    box->bool_field_put(value_offset, value->z);
+    box->bool_field_put(_value_offset, value->z);
     break;
   case T_CHAR:
-    box->char_field_put(value_offset, value->c);
+    box->char_field_put(_value_offset, value->c);
     break;
   case T_FLOAT:
-    box->float_field_put(value_offset, value->f);
+    box->float_field_put(_value_offset, value->f);
     break;
   case T_DOUBLE:
-    box->double_field_put(long_value_offset, value->d);
+    box->double_field_put(_long_value_offset, value->d);
     break;
   case T_BYTE:
-    box->byte_field_put(value_offset, value->b);
+    box->byte_field_put(_value_offset, value->b);
     break;
   case T_SHORT:
-    box->short_field_put(value_offset, value->s);
+    box->short_field_put(_value_offset, value->s);
     break;
   case T_INT:
-    box->int_field_put(value_offset, value->i);
+    box->int_field_put(_value_offset, value->i);
     break;
   case T_LONG:
-    box->long_field_put(long_value_offset, value->j);
+    box->long_field_put(_long_value_offset, value->j);
     break;
   default:
     return T_ILLEGAL;
   } // end switch
   return type;
@@ -3612,73 +3738,20 @@
   case T_DOUBLE:    st->print("%lf", value->d);                     break;
   default:          st->print("type %d?", type);                    break;
   }
 }
 
-// Support for java_lang_ref_Reference
-
-bool java_lang_ref_Reference::is_referent_field(oop obj, ptrdiff_t offset) {
-  assert(obj != NULL, "sanity");
-  if (offset != java_lang_ref_Reference::referent_offset) {
-    return false;
-  }
-
-  Klass* k = obj->klass();
-  if (!k->is_instance_klass()) {
-    return false;
-  }
-
-  InstanceKlass* ik = InstanceKlass::cast(obj->klass());
-  bool is_reference = ik->reference_type() != REF_NONE;
-  assert(!is_reference || ik->is_subclass_of(SystemDictionary::Reference_klass()), "sanity");
-  return is_reference;
-}
-
-#define REFERENCE_FIELDS_DO(macro) \
-  macro(referent_offset,   k, "referent", object_signature, false); \
-  macro(queue_offset,      k, "queue", referencequeue_signature, false); \
-  macro(next_offset,       k, "next", reference_signature, false); \
-  macro(discovered_offset, k, "discovered", reference_signature, false);
-
-void java_lang_ref_Reference::compute_offsets() {
-  if (_offsets_initialized) {
-    return;
-  }
-  _offsets_initialized = true;
-  InstanceKlass* k = SystemDictionary::Reference_klass();
-  REFERENCE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
-}
-
-#if INCLUDE_CDS
-void java_lang_ref_Reference::serialize_offsets(SerializeClosure* f) {
-  f->do_bool(&_offsets_initialized);
-  REFERENCE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
-}
-#endif
-
-#define BOXING_FIELDS_DO(macro) \
-  macro(value_offset,      integerKlass, "value", int_signature, false); \
-  macro(long_value_offset, longKlass, "value", long_signature, false);
-
-void java_lang_boxing_object::compute_offsets() {
-  InstanceKlass* integerKlass = SystemDictionary::Integer_klass();
-  InstanceKlass* longKlass = SystemDictionary::Long_klass();
-  BOXING_FIELDS_DO(FIELD_COMPUTE_OFFSET);
-}
-
-#if INCLUDE_CDS
-void java_lang_boxing_object::serialize_offsets(SerializeClosure* f) {
-  BOXING_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
-}
-#endif
 
 // Support for java_lang_ref_SoftReference
 //
 
+int java_lang_ref_SoftReference::_timestamp_offset;
+int java_lang_ref_SoftReference::_static_clock_offset;
+
 #define SOFTREFERENCE_FIELDS_DO(macro) \
-  macro(timestamp_offset,    k, "timestamp", long_signature, false); \
-  macro(static_clock_offset, k, "clock",     long_signature, true)
+  macro(_timestamp_offset,    k, "timestamp", long_signature, false); \
+  macro(_static_clock_offset, k, "clock",     long_signature, true)
 
 void java_lang_ref_SoftReference::compute_offsets() {
   InstanceKlass* k = SystemDictionary::SoftReference_klass();
   SOFTREFERENCE_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -3688,34 +3761,34 @@
   SOFTREFERENCE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 jlong java_lang_ref_SoftReference::timestamp(oop ref) {
-  return ref->long_field(timestamp_offset);
+  return ref->long_field(_timestamp_offset);
 }
 
 jlong java_lang_ref_SoftReference::clock() {
   InstanceKlass* ik = SystemDictionary::SoftReference_klass();
   oop base = ik->static_field_base_raw();
-  return base->long_field(static_clock_offset);
+  return base->long_field(_static_clock_offset);
 }
 
 void java_lang_ref_SoftReference::set_clock(jlong value) {
   InstanceKlass* ik = SystemDictionary::SoftReference_klass();
   oop base = ik->static_field_base_raw();
-  base->long_field_put(static_clock_offset, value);
+  base->long_field_put(_static_clock_offset, value);
 }
 
 // Support for java_lang_invoke_DirectMethodHandle
 
 int java_lang_invoke_DirectMethodHandle::_member_offset;
 
 oop java_lang_invoke_DirectMethodHandle::member(oop dmh) {
   oop member_name = NULL;
   assert(oopDesc::is_oop(dmh) && java_lang_invoke_DirectMethodHandle::is_instance(dmh),
          "a DirectMethodHandle oop is expected");
-  return dmh->obj_field(member_offset_in_bytes());
+  return dmh->obj_field(_member_offset);
 }
 
 #define DIRECTMETHODHANDLE_FIELDS_DO(macro) \
   macro(_member_offset, k, "member", java_lang_invoke_MemberName_signature, false)
 
@@ -4129,14 +4202,14 @@
   return dep_ctx;
 }
 
 // Support for java_security_AccessControlContext
 
-int java_security_AccessControlContext::_context_offset = 0;
-int java_security_AccessControlContext::_privilegedContext_offset = 0;
-int java_security_AccessControlContext::_isPrivileged_offset = 0;
-int java_security_AccessControlContext::_isAuthorized_offset = -1;
+int java_security_AccessControlContext::_context_offset;
+int java_security_AccessControlContext::_privilegedContext_offset;
+int java_security_AccessControlContext::_isPrivileged_offset;
+int java_security_AccessControlContext::_isAuthorized_offset;
 
 #define ACCESSCONTROLCONTEXT_FIELDS_DO(macro) \
   macro(_context_offset,           k, "context",      protectiondomain_signature, false); \
   macro(_privilegedContext_offset, k, "privilegedContext", accesscontrolcontext_signature, false); \
   macro(_isPrivileged_offset,      k, "isPrivileged", bool_signature, false); \
@@ -4154,11 +4227,11 @@
 }
 #endif
 
 oop java_security_AccessControlContext::create(objArrayHandle context, bool isPrivileged, Handle privileged_context, TRAPS) {
   assert(_isPrivileged_offset != 0, "offsets should have been initialized");
-  assert(_isAuthorized_offset != -1, "offsets should have been initialized");
+  assert(_isAuthorized_offset != 0, "offsets should have been initialized");
   // Ensure klass is initialized
   SystemDictionary::AccessControlContext_klass()->initialize(CHECK_NULL);
   // Allocate result
   oop result = SystemDictionary::AccessControlContext_klass()->allocate_instance(CHECK_NULL);
   // Fill in values
@@ -4171,16 +4244,16 @@
 }
 
 
 // Support for java_lang_ClassLoader
 
-bool java_lang_ClassLoader::offsets_computed = false;
-int  java_lang_ClassLoader::_loader_data_offset = -1;
-int  java_lang_ClassLoader::parallelCapable_offset = -1;
-int  java_lang_ClassLoader::name_offset = -1;
-int  java_lang_ClassLoader::nameAndId_offset = -1;
-int  java_lang_ClassLoader::unnamedModule_offset = -1;
+int  java_lang_ClassLoader::_loader_data_offset;
+int  java_lang_ClassLoader::_parallelCapable_offset;
+int  java_lang_ClassLoader::_name_offset;
+int  java_lang_ClassLoader::_nameAndId_offset;
+int  java_lang_ClassLoader::_unnamedModule_offset;
+int  java_lang_ClassLoader::_parent_offset;
 
 ClassLoaderData* java_lang_ClassLoader::loader_data_acquire(oop loader) {
   assert(loader != NULL, "loader must not be NULL");
   assert(oopDesc::is_oop(loader), "loader must be oop");
   return HeapAccess<MO_ACQUIRE>::load_at(loader, _loader_data_offset);
@@ -4197,20 +4270,17 @@
   assert(oopDesc::is_oop(loader), "loader must be oop");
   HeapAccess<MO_RELEASE>::store_at(loader, _loader_data_offset, new_data);
 }
 
 #define CLASSLOADER_FIELDS_DO(macro) \
-  macro(parallelCapable_offset, k1, "parallelLockMap",      concurrenthashmap_signature, false); \
-  macro(name_offset,            k1, vmSymbols::name_name(), string_signature, false); \
-  macro(nameAndId_offset,       k1, "nameAndId",            string_signature, false); \
-  macro(unnamedModule_offset,   k1, "unnamedModule",        module_signature, false); \
-  macro(parent_offset,          k1, "parent",               classloader_signature, false)
+  macro(_parallelCapable_offset, k1, "parallelLockMap",      concurrenthashmap_signature, false); \
+  macro(_name_offset,            k1, vmSymbols::name_name(), string_signature, false); \
+  macro(_nameAndId_offset,       k1, "nameAndId",            string_signature, false); \
+  macro(_unnamedModule_offset,   k1, "unnamedModule",        module_signature, false); \
+  macro(_parent_offset,          k1, "parent",               classloader_signature, false)
 
 void java_lang_ClassLoader::compute_offsets() {
-  assert(!offsets_computed, "offsets should be initialized only once");
-  offsets_computed = true;
-
   InstanceKlass* k1 = SystemDictionary::ClassLoader_klass();
   CLASSLOADER_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 
   CLASSLOADER_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);
 }
@@ -4222,29 +4292,29 @@
 }
 #endif
 
 oop java_lang_ClassLoader::parent(oop loader) {
   assert(is_instance(loader), "loader must be oop");
-  return loader->obj_field(parent_offset);
+  return loader->obj_field(_parent_offset);
 }
 
 // Returns the name field of this class loader.  If the name field has not
 // been set, null will be returned.
 oop java_lang_ClassLoader::name(oop loader) {
   assert(is_instance(loader), "loader must be oop");
-  return loader->obj_field(name_offset);
+  return loader->obj_field(_name_offset);
 }
 
 // Returns the nameAndId field of this class loader. The format is
 // as follows:
 //   If the defining loader has a name explicitly set then '<loader-name>' @<id>
 //   If the defining loader has no name then <qualified-class-name> @<id>
 //   If built-in loader, then omit '@<id>' as there is only one instance.
 // Use ClassLoader::loader_name_id() to obtain this String as a char*.
 oop java_lang_ClassLoader::nameAndId(oop loader) {
   assert(is_instance(loader), "loader must be oop");
-  return loader->obj_field(nameAndId_offset);
+  return loader->obj_field(_nameAndId_offset);
 }
 
 bool java_lang_ClassLoader::isAncestor(oop loader, oop cl) {
   assert(is_instance(loader), "loader must be oop");
   assert(cl == NULL || is_instance(cl), "cl argument must be oop");
@@ -4268,12 +4338,12 @@
 
 // For class loader classes, parallelCapable defined
 // based on non-null field
 // Written to by java.lang.ClassLoader, vm only reads this field, doesn't set it
 bool java_lang_ClassLoader::parallelCapable(oop class_loader) {
-  assert(parallelCapable_offset != -1, "offsets should have been initialized");
-  return (class_loader->obj_field(parallelCapable_offset) != NULL);
+  assert(_parallelCapable_offset != 0, "offsets should have been initialized");
+  return (class_loader->obj_field(_parallelCapable_offset) != NULL);
 }
 
 bool java_lang_ClassLoader::is_trusted_loader(oop loader) {
   // Fix for 4474172; see evaluation for more details
   loader = non_reflection_class_loader(loader);
@@ -4308,20 +4378,26 @@
   return loader;
 }
 
 oop java_lang_ClassLoader::unnamedModule(oop loader) {
   assert(is_instance(loader), "loader must be oop");
-  return loader->obj_field(unnamedModule_offset);
+  return loader->obj_field(_unnamedModule_offset);
 }
 
 // Support for java_lang_System
 //
+
+int java_lang_System::_static_in_offset;
+int java_lang_System::_static_out_offset;
+int java_lang_System::_static_err_offset;
+int java_lang_System::_static_security_offset;
+
 #define SYSTEM_FIELDS_DO(macro) \
-  macro(static_in_offset,  k, "in",  input_stream_signature, true); \
-  macro(static_out_offset, k, "out", print_stream_signature, true); \
-  macro(static_err_offset, k, "err", print_stream_signature, true); \
-  macro(static_security_offset, k, "security", security_manager_signature, true)
+  macro(_static_in_offset,  k, "in",  input_stream_signature, true); \
+  macro(_static_out_offset, k, "out", print_stream_signature, true); \
+  macro(_static_err_offset, k, "err", print_stream_signature, true); \
+  macro(_static_security_offset, k, "security", security_manager_signature, true)
 
 void java_lang_System::compute_offsets() {
   InstanceKlass* k = SystemDictionary::System_klass();
   SYSTEM_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -4330,14 +4406,10 @@
 void java_lang_System::serialize_offsets(SerializeClosure* f) {
    SYSTEM_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
-int java_lang_System::in_offset_in_bytes() { return static_in_offset; }
-int java_lang_System::out_offset_in_bytes() { return static_out_offset; }
-int java_lang_System::err_offset_in_bytes() { return static_err_offset; }
-
 // Support for jdk_internal_misc_UnsafeConstants
 //
 class UnsafeConstantsFixup : public FieldClosure {
 private:
   int _address_size;
@@ -4380,132 +4452,31 @@
 void jdk_internal_misc_UnsafeConstants::set_unsafe_constants() {
   UnsafeConstantsFixup fixup;
   SystemDictionary::UnsafeConstants_klass()->do_local_static_fields(&fixup);
 }
 
-int java_lang_Class::_klass_offset;
-int java_lang_Class::_array_klass_offset;
-int java_lang_Class::_oop_size_offset;
-int java_lang_Class::_static_oop_field_count_offset;
-int java_lang_Class::_class_loader_offset;
-int java_lang_Class::_module_offset;
-int java_lang_Class::_protection_domain_offset;
-int java_lang_Class::_component_mirror_offset;
-int java_lang_Class::_val_type_mirror_offset;
-int java_lang_Class::_ref_type_mirror_offset;
-int java_lang_Class::_init_lock_offset;
-int java_lang_Class::_signers_offset;
-int java_lang_Class::_name_offset;
-int java_lang_Class::_source_file_offset;
-int java_lang_Class::_classData_offset;
-GrowableArray<Klass*>* java_lang_Class::_fixup_mirror_list = NULL;
-GrowableArray<Klass*>* java_lang_Class::_fixup_module_field_list = NULL;
-int java_lang_Throwable::backtrace_offset;
-int java_lang_Throwable::detailMessage_offset;
-int java_lang_Throwable::stackTrace_offset;
-int java_lang_Throwable::depth_offset;
-int java_lang_Throwable::static_unassigned_stacktrace_offset;
-int java_lang_reflect_AccessibleObject::override_offset;
-int java_lang_reflect_Method::clazz_offset;
-int java_lang_reflect_Method::name_offset;
-int java_lang_reflect_Method::returnType_offset;
-int java_lang_reflect_Method::parameterTypes_offset;
-int java_lang_reflect_Method::exceptionTypes_offset;
-int java_lang_reflect_Method::slot_offset;
-int java_lang_reflect_Method::modifiers_offset;
-int java_lang_reflect_Method::signature_offset;
-int java_lang_reflect_Method::annotations_offset;
-int java_lang_reflect_Method::parameter_annotations_offset;
-int java_lang_reflect_Method::annotation_default_offset;
-int java_lang_reflect_Constructor::clazz_offset;
-int java_lang_reflect_Constructor::parameterTypes_offset;
-int java_lang_reflect_Constructor::exceptionTypes_offset;
-int java_lang_reflect_Constructor::slot_offset;
-int java_lang_reflect_Constructor::modifiers_offset;
-int java_lang_reflect_Constructor::signature_offset;
-int java_lang_reflect_Constructor::annotations_offset;
-int java_lang_reflect_Constructor::parameter_annotations_offset;
-int java_lang_reflect_Field::clazz_offset;
-int java_lang_reflect_Field::name_offset;
-int java_lang_reflect_Field::type_offset;
-int java_lang_reflect_Field::slot_offset;
-int java_lang_reflect_Field::modifiers_offset;
-int java_lang_reflect_Field::signature_offset;
-int java_lang_reflect_Field::annotations_offset;
-int java_lang_reflect_Parameter::name_offset;
-int java_lang_reflect_Parameter::modifiers_offset;
-int java_lang_reflect_Parameter::index_offset;
-int java_lang_reflect_Parameter::executable_offset;
-int java_lang_boxing_object::value_offset;
-int java_lang_boxing_object::long_value_offset;
-bool java_lang_ref_Reference::_offsets_initialized;
-int java_lang_ref_Reference::referent_offset;
-int java_lang_ref_Reference::queue_offset;
-int java_lang_ref_Reference::next_offset;
-int java_lang_ref_Reference::discovered_offset;
-int java_lang_ref_SoftReference::timestamp_offset;
-int java_lang_ref_SoftReference::static_clock_offset;
-int java_lang_ClassLoader::parent_offset;
-int java_lang_System::static_in_offset;
-int java_lang_System::static_out_offset;
-int java_lang_System::static_err_offset;
-int java_lang_System::static_security_offset;
-int java_lang_StackTraceElement::methodName_offset;
-int java_lang_StackTraceElement::fileName_offset;
-int java_lang_StackTraceElement::lineNumber_offset;
-int java_lang_StackTraceElement::moduleName_offset;
-int java_lang_StackTraceElement::moduleVersion_offset;
-int java_lang_StackTraceElement::classLoaderName_offset;
-int java_lang_StackTraceElement::declaringClass_offset;
-int java_lang_StackTraceElement::declaringClassObject_offset;
-int java_lang_StackFrameInfo::_memberName_offset;
-int java_lang_StackFrameInfo::_bci_offset;
-int java_lang_StackFrameInfo::_version_offset;
-int java_lang_LiveStackFrameInfo::_monitors_offset;
-int java_lang_LiveStackFrameInfo::_locals_offset;
-int java_lang_LiveStackFrameInfo::_operands_offset;
-int java_lang_LiveStackFrameInfo::_mode_offset;
-int java_lang_AssertionStatusDirectives::classes_offset;
-int java_lang_AssertionStatusDirectives::classEnabled_offset;
-int java_lang_AssertionStatusDirectives::packages_offset;
-int java_lang_AssertionStatusDirectives::packageEnabled_offset;
-int java_lang_AssertionStatusDirectives::deflt_offset;
-int java_nio_Buffer::_limit_offset;
-int java_util_concurrent_locks_AbstractOwnableSynchronizer::_owner_offset;
-int reflect_ConstantPool::_oop_offset;
-int reflect_UnsafeStaticFieldAccessorImpl::_base_offset;
-int java_lang_Integer_IntegerCache::_static_cache_offset;
-int java_lang_Long_LongCache::_static_cache_offset;
-int java_lang_Character_CharacterCache::_static_cache_offset;
-int java_lang_Short_ShortCache::_static_cache_offset;
-int java_lang_Byte_ByteCache::_static_cache_offset;
-int java_lang_Boolean::_static_TRUE_offset;
-int java_lang_Boolean::_static_FALSE_offset;
-int java_lang_reflect_RecordComponent::clazz_offset;
-int java_lang_reflect_RecordComponent::name_offset;
-int java_lang_reflect_RecordComponent::type_offset;
-int java_lang_reflect_RecordComponent::accessor_offset;
-int java_lang_reflect_RecordComponent::signature_offset;
-int java_lang_reflect_RecordComponent::annotations_offset;
-int java_lang_reflect_RecordComponent::typeAnnotations_offset;
-int jdk_internal_vm_jni_SubElementSelector::_arrayElementType_offset;
-int jdk_internal_vm_jni_SubElementSelector::_subElementType_offset;
-int jdk_internal_vm_jni_SubElementSelector::_offset_offset;
-int jdk_internal_vm_jni_SubElementSelector::_isFlattened_offset;
-int jdk_internal_vm_jni_SubElementSelector::_isFlattenable_offset;
+
 
 
+int java_lang_StackTraceElement::_methodName_offset;
+int java_lang_StackTraceElement::_fileName_offset;
+int java_lang_StackTraceElement::_lineNumber_offset;
+int java_lang_StackTraceElement::_moduleName_offset;
+int java_lang_StackTraceElement::_moduleVersion_offset;
+int java_lang_StackTraceElement::_classLoaderName_offset;
+int java_lang_StackTraceElement::_declaringClass_offset;
+int java_lang_StackTraceElement::_declaringClassObject_offset;
 
 #define STACKTRACEELEMENT_FIELDS_DO(macro) \
-  macro(declaringClassObject_offset,  k, "declaringClassObject", class_signature, false); \
-  macro(classLoaderName_offset, k, "classLoaderName", string_signature, false); \
-  macro(moduleName_offset,      k, "moduleName",      string_signature, false); \
-  macro(moduleVersion_offset,   k, "moduleVersion",   string_signature, false); \
-  macro(declaringClass_offset,  k, "declaringClass",  string_signature, false); \
-  macro(methodName_offset,      k, "methodName",      string_signature, false); \
-  macro(fileName_offset,        k, "fileName",        string_signature, false); \
-  macro(lineNumber_offset,      k, "lineNumber",      int_signature,    false)
+  macro(_declaringClassObject_offset,  k, "declaringClassObject", class_signature, false); \
+  macro(_classLoaderName_offset, k, "classLoaderName", string_signature, false); \
+  macro(_moduleName_offset,      k, "moduleName",      string_signature, false); \
+  macro(_moduleVersion_offset,   k, "moduleVersion",   string_signature, false); \
+  macro(_declaringClass_offset,  k, "declaringClass",  string_signature, false); \
+  macro(_methodName_offset,      k, "methodName",      string_signature, false); \
+  macro(_fileName_offset,        k, "fileName",        string_signature, false); \
+  macro(_lineNumber_offset,      k, "lineNumber",      int_signature,    false)
 
 // Support for java_lang_StackTraceElement
 void java_lang_StackTraceElement::compute_offsets() {
   InstanceKlass* k = SystemDictionary::StackTraceElement_klass();
   STACKTRACEELEMENT_FIELDS_DO(FIELD_COMPUTE_OFFSET);
@@ -4516,73 +4487,57 @@
   STACKTRACEELEMENT_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 void java_lang_StackTraceElement::set_fileName(oop element, oop value) {
-  element->obj_field_put(fileName_offset, value);
+  element->obj_field_put(_fileName_offset, value);
 }
 
 void java_lang_StackTraceElement::set_declaringClass(oop element, oop value) {
-  element->obj_field_put(declaringClass_offset, value);
+  element->obj_field_put(_declaringClass_offset, value);
 }
 
 void java_lang_StackTraceElement::set_methodName(oop element, oop value) {
-  element->obj_field_put(methodName_offset, value);
+  element->obj_field_put(_methodName_offset, value);
 }
 
 void java_lang_StackTraceElement::set_lineNumber(oop element, int value) {
-  element->int_field_put(lineNumber_offset, value);
+  element->int_field_put(_lineNumber_offset, value);
 }
 
 void java_lang_StackTraceElement::set_moduleName(oop element, oop value) {
-  element->obj_field_put(moduleName_offset, value);
+  element->obj_field_put(_moduleName_offset, value);
 }
 
 void java_lang_StackTraceElement::set_moduleVersion(oop element, oop value) {
-  element->obj_field_put(moduleVersion_offset, value);
+  element->obj_field_put(_moduleVersion_offset, value);
 }
 
 void java_lang_StackTraceElement::set_classLoaderName(oop element, oop value) {
-  element->obj_field_put(classLoaderName_offset, value);
+  element->obj_field_put(_classLoaderName_offset, value);
 }
 
 void java_lang_StackTraceElement::set_declaringClassObject(oop element, oop value) {
-  element->obj_field_put(declaringClassObject_offset, value);
+  element->obj_field_put(_declaringClassObject_offset, value);
 }
 
-void java_lang_StackFrameInfo::set_version(oop element, short value) {
-  element->short_field_put(_version_offset, value);
-}
-
-void java_lang_StackFrameInfo::set_bci(oop element, int value) {
-  assert(value >= 0 && value < max_jushort, "must be a valid bci value");
-  element->int_field_put(_bci_offset, value);
-}
-
-void java_lang_LiveStackFrameInfo::set_monitors(oop element, oop value) {
-  element->obj_field_put(_monitors_offset, value);
-}
-
-void java_lang_LiveStackFrameInfo::set_locals(oop element, oop value) {
-  element->obj_field_put(_locals_offset, value);
+
 }
 
-void java_lang_LiveStackFrameInfo::set_operands(oop element, oop value) {
-  element->obj_field_put(_operands_offset, value);
-}
-
-void java_lang_LiveStackFrameInfo::set_mode(oop element, int value) {
-  element->int_field_put(_mode_offset, value);
-}
+int java_lang_AssertionStatusDirectives::_classes_offset;
+int java_lang_AssertionStatusDirectives::_classEnabled_offset;
+int java_lang_AssertionStatusDirectives::_packages_offset;
+int java_lang_AssertionStatusDirectives::_packageEnabled_offset;
+int java_lang_AssertionStatusDirectives::_deflt_offset;
 
 // Support for java Assertions - java_lang_AssertionStatusDirectives.
 #define ASSERTIONSTATUSDIRECTIVES_FIELDS_DO(macro) \
-  macro(classes_offset,        k, "classes",        string_array_signature, false); \
-  macro(classEnabled_offset,   k, "classEnabled",   bool_array_signature, false); \
-  macro(packages_offset,       k, "packages",       string_array_signature, false); \
-  macro(packageEnabled_offset, k, "packageEnabled", bool_array_signature,   false); \
-  macro(deflt_offset,          k, "deflt",          bool_signature,         false)
+  macro(_classes_offset,        k, "classes",        string_array_signature, false); \
+  macro(_classEnabled_offset,   k, "classEnabled",   bool_array_signature, false); \
+  macro(_packages_offset,       k, "packages",       string_array_signature, false); \
+  macro(_packageEnabled_offset, k, "packageEnabled", bool_array_signature,   false); \
+  macro(_deflt_offset,          k, "deflt",          bool_signature,         false)
 
 void java_lang_AssertionStatusDirectives::compute_offsets() {
   InstanceKlass* k = SystemDictionary::AssertionStatusDirectives_klass();
   ASSERTIONSTATUSDIRECTIVES_FIELDS_DO(FIELD_COMPUTE_OFFSET);
 }
@@ -4592,34 +4547,33 @@
   ASSERTIONSTATUSDIRECTIVES_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 void java_lang_AssertionStatusDirectives::set_classes(oop o, oop val) {
-  o->obj_field_put(classes_offset, val);
+  o->obj_field_put(_classes_offset, val);
 }
 
 void java_lang_AssertionStatusDirectives::set_classEnabled(oop o, oop val) {
-  o->obj_field_put(classEnabled_offset, val);
+  o->obj_field_put(_classEnabled_offset, val);
 }
 
 void java_lang_AssertionStatusDirectives::set_packages(oop o, oop val) {
-  o->obj_field_put(packages_offset, val);
+  o->obj_field_put(_packages_offset, val);
 }
 
 void java_lang_AssertionStatusDirectives::set_packageEnabled(oop o, oop val) {
-  o->obj_field_put(packageEnabled_offset, val);
+  o->obj_field_put(_packageEnabled_offset, val);
 }
 
 void java_lang_AssertionStatusDirectives::set_deflt(oop o, bool val) {
-  o->bool_field_put(deflt_offset, val);
+  o->bool_field_put(_deflt_offset, val);
 }
 
 
 // Support for intrinsification of java.nio.Buffer.checkIndex
-int java_nio_Buffer::limit_offset() {
-  return _limit_offset;
-}
+
+int java_nio_Buffer::_limit_offset;
 
 #define BUFFER_FIELDS_DO(macro) \
   macro(_limit_offset, k, "limit", int_signature, false)
 
 void java_nio_Buffer::compute_offsets() {
@@ -4632,10 +4586,12 @@
 void java_nio_Buffer::serialize_offsets(SerializeClosure* f) {
   BUFFER_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+int java_util_concurrent_locks_AbstractOwnableSynchronizer::_owner_offset;
+
 #define AOS_FIELDS_DO(macro) \
   macro(_owner_offset, k, "exclusiveOwnerThread", thread_signature, false)
 
 void java_util_concurrent_locks_AbstractOwnableSynchronizer::compute_offsets() {
   InstanceKlass* k = SystemDictionary::java_util_concurrent_locks_AbstractOwnableSynchronizer_klass();
@@ -4651,10 +4607,16 @@
 void java_util_concurrent_locks_AbstractOwnableSynchronizer::serialize_offsets(SerializeClosure* f) {
   AOS_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
+int java_lang_Integer_IntegerCache::_static_cache_offset;
+int java_lang_Long_LongCache::_static_cache_offset;
+int java_lang_Character_CharacterCache::_static_cache_offset;
+int java_lang_Short_ShortCache::_static_cache_offset;
+int java_lang_Byte_ByteCache::_static_cache_offset;
+
 #define INTEGER_CACHE_FIELDS_DO(macro) \
   macro(_static_cache_offset, k, "cache", java_lang_Integer_array_signature, true)
 
 void java_lang_Integer_IntegerCache::compute_offsets(InstanceKlass *k) {
   guarantee(k != NULL && k->is_initialized(), "must be loaded and initialized");
@@ -4795,10 +4757,18 @@
   BYTE_CACHE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 #undef BYTE_CACHE_FIELDS_DO
 
+// jdk_internal_vm_jni_SubElementSelector
+
+int jdk_internal_vm_jni_SubElementSelector::_arrayElementType_offset;
+int jdk_internal_vm_jni_SubElementSelector::_subElementType_offset;
+int jdk_internal_vm_jni_SubElementSelector::_offset_offset;
+int jdk_internal_vm_jni_SubElementSelector::_isFlattened_offset;
+int jdk_internal_vm_jni_SubElementSelector::_isFlattenable_offset;
+
 #define SUBELEMENT_SELECTOR_FIELDS_DO(macro) \
   macro(_arrayElementType_offset,  k, "arrayElementType", class_signature, false); \
   macro(_subElementType_offset,    k, "subElementType",   class_signature, false); \
   macro(_offset_offset,            k, "offset",           int_signature,   false); \
   macro(_isFlattened_offset,       k, "isFlattened",      bool_signature,  false); \
@@ -4863,10 +4833,14 @@
 jbyte java_lang_Byte::value(oop obj) {
    jvalue v;
    java_lang_boxing_object::get_value(obj, &v);
    return v.b;
 }
+
+int java_lang_Boolean::_static_TRUE_offset;
+int java_lang_Boolean::_static_FALSE_offset;
+
 #define BOOLEAN_FIELDS_DO(macro) \
   macro(_static_TRUE_offset, k, "TRUE", java_lang_Boolean_signature, true); \
   macro(_static_FALSE_offset, k, "FALSE", java_lang_Boolean_signature, true)
 
 
@@ -4900,18 +4874,28 @@
    jvalue v;
    java_lang_boxing_object::get_value(obj, &v);
    return v.z;
 }
 
+// java_lang_reflect_RecordComponent
+
+int java_lang_reflect_RecordComponent::_clazz_offset;
+int java_lang_reflect_RecordComponent::_name_offset;
+int java_lang_reflect_RecordComponent::_type_offset;
+int java_lang_reflect_RecordComponent::_accessor_offset;
+int java_lang_reflect_RecordComponent::_signature_offset;
+int java_lang_reflect_RecordComponent::_annotations_offset;
+int java_lang_reflect_RecordComponent::_typeAnnotations_offset;
+
 #define RECORDCOMPONENT_FIELDS_DO(macro) \
-  macro(clazz_offset,       k, "clazz",       class_signature,  false); \
-  macro(name_offset,        k, "name",        string_signature, false); \
-  macro(type_offset,        k, "type",        class_signature,  false); \
-  macro(accessor_offset,    k, "accessor",    reflect_method_signature, false); \
-  macro(signature_offset,   k, "signature",   string_signature, false); \
-  macro(annotations_offset, k, "annotations", byte_array_signature,     false); \
-  macro(typeAnnotations_offset, k, "typeAnnotations", byte_array_signature, false);
+  macro(_clazz_offset,       k, "clazz",       class_signature,  false); \
+  macro(_name_offset,        k, "name",        string_signature, false); \
+  macro(_type_offset,        k, "type",        class_signature,  false); \
+  macro(_accessor_offset,    k, "accessor",    reflect_method_signature, false); \
+  macro(_signature_offset,   k, "signature",   string_signature, false); \
+  macro(_annotations_offset, k, "annotations", byte_array_signature,     false); \
+  macro(_typeAnnotations_offset, k, "typeAnnotations", byte_array_signature, false);
 
 // Support for java_lang_reflect_RecordComponent
 void java_lang_reflect_RecordComponent::compute_offsets() {
   InstanceKlass* k = SystemDictionary::RecordComponent_klass();
   RECORDCOMPONENT_FIELDS_DO(FIELD_COMPUTE_OFFSET);
@@ -4922,47 +4906,47 @@
   RECORDCOMPONENT_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 
 void java_lang_reflect_RecordComponent::set_clazz(oop element, oop value) {
-  element->obj_field_put(clazz_offset, value);
+  element->obj_field_put(_clazz_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_name(oop element, oop value) {
-  element->obj_field_put(name_offset, value);
+  element->obj_field_put(_name_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_type(oop element, oop value) {
-  element->obj_field_put(type_offset, value);
+  element->obj_field_put(_type_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_accessor(oop element, oop value) {
-  element->obj_field_put(accessor_offset, value);
+  element->obj_field_put(_accessor_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_signature(oop element, oop value) {
-  element->obj_field_put(signature_offset, value);
+  element->obj_field_put(_signature_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_annotations(oop element, oop value) {
-  element->obj_field_put(annotations_offset, value);
+  element->obj_field_put(_annotations_offset, value);
 }
 
 void java_lang_reflect_RecordComponent::set_typeAnnotations(oop element, oop value) {
-  element->obj_field_put(typeAnnotations_offset, value);
+  element->obj_field_put(_typeAnnotations_offset, value);
 }
 
 #define DO_COMPUTE_OFFSETS(k) k::compute_offsets();
 
-// Compute non-hard-coded field offsets of all the classes in this file
+// Compute field offsets of all the classes in this file
 void JavaClasses::compute_offsets() {
   if (UseSharedSpaces) {
     JVMTI_ONLY(assert(JvmtiExport::is_early_phase() && !(JvmtiExport::should_post_class_file_load_hook() &&
                                                          JvmtiExport::has_early_class_hook_env()),
                       "JavaClasses::compute_offsets() must be called in early JVMTI phase."));
     // None of the classes used by the rest of this function can be replaced by
-    // JMVTI ClassFileLoadHook.
+    // JVMTI ClassFileLoadHook.
     // We are safe to use the archived offsets, which have already been restored
     // by JavaClasses::serialize_offsets, without computing the offsets again.
     return;
   }
 
@@ -5003,14 +4987,14 @@
 }
 #endif
 
 #ifndef PRODUCT
 
-// These functions exist to assert the validity of hard-coded field offsets to guard
-// against changes in the class files
+// These functions exist to assert the validity of de-serialized offsets in boxing object as a sanity check.
 
-bool JavaClasses::check_offset(const char *klass_name, int hardcoded_offset, const char *field_name, const char* field_sig) {
+bool JavaClasses::check_offset(const char *klass_name, int deserialized_offset, const char *field_name,
+                               const char* field_sig) {
   EXCEPTION_MARK;
   fieldDescriptor fd;
   TempNewSymbol klass_sym = SymbolTable::new_symbol(klass_name);
   Klass* k = SystemDictionary::resolve_or_fail(klass_sym, true, CATCH);
   InstanceKlass* ik = InstanceKlass::cast(k);
@@ -5022,29 +5006,27 @@
   }
   if (fd.is_static()) {
     tty->print_cr("Nonstatic field %s.%s appears to be static", klass_name, field_name);
     return false;
   }
-  if (fd.offset() == hardcoded_offset ) {
+  if (fd.offset() == deserialized_offset ) {
     return true;
   } else {
-    tty->print_cr("Offset of nonstatic field %s.%s is hardcoded as %d but should really be %d.",
-                  klass_name, field_name, hardcoded_offset, fd.offset());
+    tty->print_cr("Offset of nonstatic field %s.%s is deserialized as %d but should really be %d.",
+                  klass_name, field_name, deserialized_offset, fd.offset());
     return false;
   }
 }
 
-// Check the hard-coded field offsets of all the classes in this file
-
 void JavaClasses::check_offsets() {
   bool valid = true;
 
 #define CHECK_OFFSET(klass_name, cpp_klass_name, field_name, field_sig) \
-  valid &= check_offset(klass_name, cpp_klass_name :: field_name ## _offset, #field_name, field_sig)
+  valid &= check_offset(klass_name, cpp_klass_name :: _##field_name ## _offset, #field_name, field_sig)
 
 #define CHECK_LONG_OFFSET(klass_name, cpp_klass_name, field_name, field_sig) \
-  valid &= check_offset(klass_name, cpp_klass_name :: long_ ## field_name ## _offset, #field_name, field_sig)
+  valid &= check_offset(klass_name, cpp_klass_name :: _##long_ ## field_name ## _offset, #field_name, field_sig)
 
   // Boxed primitive objects (java_lang_boxing_object)
 
   CHECK_OFFSET("java/lang/Boolean",   java_lang_boxing_object, value, "Z");
   CHECK_OFFSET("java/lang/Character", java_lang_boxing_object, value, "C");
@@ -5053,11 +5035,11 @@
   CHECK_OFFSET("java/lang/Byte",      java_lang_boxing_object, value, "B");
   CHECK_OFFSET("java/lang/Short",     java_lang_boxing_object, value, "S");
   CHECK_OFFSET("java/lang/Integer",   java_lang_boxing_object, value, "I");
   CHECK_LONG_OFFSET("java/lang/Long", java_lang_boxing_object, value, "J");
 
-  if (!valid) vm_exit_during_initialization("Hard-coded field offset verification failed");
+  if (!valid) vm_exit_during_initialization("Field offset verification failed");
 }
 
 #endif // PRODUCT
 
 int InjectedField::compute_offset() {
diff a/src/hotspot/share/classfile/javaClasses.hpp b/src/hotspot/share/classfile/javaClasses.hpp
--- a/src/hotspot/share/classfile/javaClasses.hpp
+++ b/src/hotspot/share/classfile/javaClasses.hpp
@@ -79,10 +79,12 @@
 
 #define BASIC_JAVA_CLASSES_DO(f) \
         BASIC_JAVA_CLASSES_DO_PART1(f) \
         BASIC_JAVA_CLASSES_DO_PART2(f)
 
+#define CHECK_INIT(offset)  assert(offset != 0, "should be initialized"); return offset;
+
 // Interface to java.lang.Object objects
 
 class java_lang_Object : AllStatic {
  public:
   static void register_natives(TRAPS);
@@ -90,16 +92,16 @@
 
 // Interface to java.lang.String objects
 
 class java_lang_String : AllStatic {
  private:
-  static int value_offset;
-  static int hash_offset;
-  static int hashIsZero_offset;
-  static int coder_offset;
+  static int _value_offset;
+  static int _hash_offset;
+  static int _hashIsZero_offset;
+  static int _coder_offset;
 
-  static bool initialized;
+  static bool _initialized;
 
   static Handle basic_create(int length, bool byte_arr, TRAPS);
 
   static inline void set_coder(oop string, jbyte coder);
 
@@ -123,26 +125,12 @@
   static Handle create_from_platform_dependent_str(const char* str, TRAPS);
   static Handle char_converter(Handle java_string, jchar from_char, jchar to_char, TRAPS);
 
   static void set_compact_strings(bool value);
 
-  static int value_offset_in_bytes()  {
-    assert(initialized && (value_offset > 0), "Must be initialized");
-    return value_offset;
-  }
-  static int hash_offset_in_bytes()   {
-    assert(initialized && (hash_offset > 0), "Must be initialized");
-    return hash_offset;
-  }
-  static int hashIsZero_offset_in_bytes()   {
-    assert(initialized && (hashIsZero_offset > 0), "Must be initialized");
-    return hashIsZero_offset;
-  }
-  static int coder_offset_in_bytes()   {
-    assert(initialized && (coder_offset > 0), "Must be initialized");
-    return coder_offset;
-  }
+  static int value_offset() { CHECK_INIT(_value_offset); }
+  static int coder_offset() { CHECK_INIT(_coder_offset); }
 
   static inline void set_value_raw(oop string, typeArrayOop buffer);
   static inline void set_value(oop string, typeArrayOop buffer);
 
   // Accessors
@@ -236,10 +224,11 @@
 class java_lang_Class : AllStatic {
   friend class VMStructs;
   friend class JVMCIVMStructs;
 
  private:
+
   // The fake offsets are added by the class loader when java.lang.Class is loaded
 
   static int _klass_offset;
   static int _array_klass_offset;
 
@@ -255,13 +244,13 @@
   static int _name_offset;
   static int _source_file_offset;
   static int _val_type_mirror_offset;
   static int _ref_type_mirror_offset;
   static int _classData_offset;
+  static int _classRedefinedCount_offset;
 
-  static bool offsets_computed;
-  static int classRedefinedCount_offset;
+  static bool _offsets_computed;
 
   static GrowableArray<Klass*>* _fixup_mirror_list;
   static GrowableArray<Klass*>* _fixup_module_field_list;
 
   static void set_init_lock(oop java_class, oop init_lock);
@@ -311,20 +300,23 @@
   static oop primitive_mirror(BasicType t);
   // JVM_NewArray support
   static Klass* array_klass_acquire(oop java_class);
   static void release_set_array_klass(oop java_class, Klass* klass);
   // compiler support for class operations
-  static int klass_offset_in_bytes()                { return _klass_offset; }
-  static int array_klass_offset_in_bytes()          { return _array_klass_offset; }
-  static int component_mirror_offset_in_bytes()     { return _component_mirror_offset; }
+  static int klass_offset()                { CHECK_INIT(_klass_offset); }
+  static int array_klass_offset()          { CHECK_INIT(_array_klass_offset); }
+  static int component_mirror_offset()     { CHECK_INIT(_component_mirror_offset); }
   // Support for classRedefinedCount field
   static int classRedefinedCount(oop the_class_mirror);
   static void set_classRedefinedCount(oop the_class_mirror, int value);
 
   // Support for embedded per-class oops
   static oop  protection_domain(oop java_class);
   static oop  init_lock(oop java_class);
+  static void clear_init_lock(oop java_class) {
+    set_init_lock(java_class, NULL);
+  }
   static oop  component_mirror(oop java_class);
   static objArrayOop  signers(oop java_class);
   static void set_signers(oop java_class, objArrayOop signers);
   static oop  class_data(oop java_class);
   static void set_class_data(oop java_class, oop classData);
@@ -365,12 +357,10 @@
     _fixup_module_field_list = v;
   }
 
   // Debugging
   friend class JavaClasses;
-  friend class InstanceKlass;   // verification code accesses offsets
-  friend class ClassFileParser; // access to number_of_fake_fields
 };
 
 // Interface to java.lang.Thread objects
 
 class java_lang_Thread : AllStatic {
@@ -537,15 +527,15 @@
     trace_hidden_offset  = 5,
     trace_size           = 6,
     trace_chunk_size     = 32
   };
 
-  static int backtrace_offset;
-  static int detailMessage_offset;
-  static int stackTrace_offset;
-  static int depth_offset;
-  static int static_unassigned_stacktrace_offset;
+  static int _backtrace_offset;
+  static int _detailMessage_offset;
+  static int _stackTrace_offset;
+  static int _depth_offset;
+  static int _static_unassigned_stacktrace_offset;
 
   // StackTrace (programmatic access, new since 1.4)
   static void clear_stacktrace(oop throwable);
   // Stacktrace (post JDK 1.7.0 to allow immutability protocol to be followed)
   static void set_stacktrace(oop throwable, oop st_element_array);
@@ -555,13 +545,11 @@
   // Backtrace
   static oop backtrace(oop throwable);
   static void set_backtrace(oop throwable, oop value);
   static int depth(oop throwable);
   static void set_depth(oop throwable, int value);
-  // Needed by JVMTI to filter out this internal field.
-  static int get_backtrace_offset() { return backtrace_offset;}
-  static int get_detailMessage_offset() { return detailMessage_offset;}
+  static int get_detailMessage_offset() { CHECK_INIT(_detailMessage_offset); }
   // Message
   static oop message(oop throwable);
   static void set_message(oop throwable, oop value);
   static Symbol* detail_message(oop throwable);
   static void print_stack_element(outputStream *st, Method* method, int bci);
@@ -594,11 +582,11 @@
 
 class java_lang_reflect_AccessibleObject: AllStatic {
  private:
   // Note that to reduce dependencies on the JDK we compute these
   // offsets at run-time.
-  static int override_offset;
+  static int _override_offset;
 
   static void compute_offsets();
 
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
@@ -616,21 +604,21 @@
 
 class java_lang_reflect_Method : public java_lang_reflect_AccessibleObject {
  private:
   // Note that to reduce dependencies on the JDK we compute these
   // offsets at run-time.
-  static int clazz_offset;
-  static int name_offset;
-  static int returnType_offset;
-  static int parameterTypes_offset;
-  static int exceptionTypes_offset;
-  static int slot_offset;
-  static int modifiers_offset;
-  static int signature_offset;
-  static int annotations_offset;
-  static int parameter_annotations_offset;
-  static int annotation_default_offset;
+  static int _clazz_offset;
+  static int _name_offset;
+  static int _returnType_offset;
+  static int _parameterTypes_offset;
+  static int _exceptionTypes_offset;
+  static int _slot_offset;
+  static int _modifiers_offset;
+  static int _signature_offset;
+  static int _annotations_offset;
+  static int _parameter_annotations_offset;
+  static int _annotation_default_offset;
 
   static void compute_offsets();
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
@@ -668,18 +656,18 @@
 
 class java_lang_reflect_Constructor : public java_lang_reflect_AccessibleObject {
  private:
   // Note that to reduce dependencies on the JDK we compute these
   // offsets at run-time.
-  static int clazz_offset;
-  static int parameterTypes_offset;
-  static int exceptionTypes_offset;
-  static int slot_offset;
-  static int modifiers_offset;
-  static int signature_offset;
-  static int annotations_offset;
-  static int parameter_annotations_offset;
+  static int _clazz_offset;
+  static int _parameterTypes_offset;
+  static int _exceptionTypes_offset;
+  static int _slot_offset;
+  static int _modifiers_offset;
+  static int _signature_offset;
+  static int _annotations_offset;
+  static int _parameter_annotations_offset;
 
   static void compute_offsets();
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
@@ -711,17 +699,17 @@
 
 class java_lang_reflect_Field : public java_lang_reflect_AccessibleObject {
  private:
   // Note that to reduce dependencies on the JDK we compute these
   // offsets at run-time.
-  static int clazz_offset;
-  static int name_offset;
-  static int type_offset;
-  static int slot_offset;
-  static int modifiers_offset;
-  static int signature_offset;
-  static int annotations_offset;
+  static int _clazz_offset;
+  static int _name_offset;
+  static int _type_offset;
+  static int _slot_offset;
+  static int _modifiers_offset;
+  static int _signature_offset;
+  static int _annotations_offset;
 
   static void compute_offsets();
 
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
@@ -756,14 +744,14 @@
 
 class java_lang_reflect_Parameter {
  private:
   // Note that to reduce dependencies on the JDK we compute these
   // offsets at run-time.
-  static int name_offset;
-  static int modifiers_offset;
-  static int index_offset;
-  static int executable_offset;
+  static int _name_offset;
+  static int _modifiers_offset;
+  static int _index_offset;
+  static int _executable_offset;
 
   static void compute_offsets();
 
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
@@ -790,13 +778,14 @@
 #define MODULE_INJECTED_FIELDS(macro)                            \
   macro(java_lang_Module, module_entry, intptr_signature, false)
 
 class java_lang_Module {
   private:
-    static int loader_offset;
-    static int name_offset;
+    static int _loader_offset;
+    static int _name_offset;
     static int _module_entry_offset;
+
     static void compute_offsets();
 
   public:
     static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
@@ -834,13 +823,11 @@
   // Allocation
   static Handle create(TRAPS);
 
   // Accessors
   static void set_cp(oop reflect, ConstantPool* value);
-  static int oop_offset() {
-    return _oop_offset;
-  }
+  static int oop_offset() { CHECK_INIT(_oop_offset); }
 
   static ConstantPool* get_cp(oop reflect);
 
   // Debugging
   friend class JavaClasses;
@@ -853,13 +840,11 @@
   static void compute_offsets();
 
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
-  static int base_offset() {
-    return _base_offset;
-  }
+  static int base_offset() { CHECK_INIT(_base_offset); }
 
   // Debugging
   friend class JavaClasses;
 };
 
@@ -875,13 +860,14 @@
 
 // This could be separated out into 8 individual classes.
 
 class java_lang_boxing_object: AllStatic {
  private:
-  static int value_offset;
-  static int long_value_offset;
+  static int _value_offset;
+  static int _long_value_offset;
 
+  static void compute_offsets();
   static oop initialize_and_allocate(BasicType type, TRAPS);
  public:
   // Allocation. Returns a boxed value, or NULL for invalid type.
   static oop create(BasicType type, jvalue* value, TRAPS);
   // Accessors. Returns the basic type being boxed, or T_ILLEGAL for invalid oop.
@@ -891,35 +877,33 @@
   static bool is_instance(oop box)                 { return basic_type(box) != T_ILLEGAL; }
   static bool is_instance(oop box, BasicType type) { return basic_type(box) == type; }
   static void print(oop box, outputStream* st)     { jvalue value;  print(get_value(box, &value), &value, st); }
   static void print(BasicType type, jvalue* value, outputStream* st);
 
-  static int value_offset_in_bytes(BasicType type) {
-    return ( type == T_LONG || type == T_DOUBLE ) ? long_value_offset :
-                                                    value_offset;
+  static int value_offset(BasicType type) {
+    return is_double_word_type(type) ? _long_value_offset : _value_offset;
   }
 
-  static void compute_offsets();
-  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
+  static void serialize_offsets(SerializeClosure* f);
 
   // Debugging
   friend class JavaClasses;
 };
 
 
 
 // Interface to java.lang.ref.Reference objects
 
 class java_lang_ref_Reference: AllStatic {
+  static int _referent_offset;
+  static int _queue_offset;
+  static int _next_offset;
+  static int _discovered_offset;
+
   static bool _offsets_initialized;
 
  public:
-  static int referent_offset;
-  static int queue_offset;
-  static int next_offset;
-  static int discovered_offset;
-
   // Accessors
   static inline oop referent(oop ref);
   static inline void set_referent(oop ref, oop value);
   static inline void set_referent_raw(oop ref, oop value);
   static inline HeapWord* referent_addr_raw(oop ref);
@@ -935,22 +919,27 @@
   static inline void set_queue(oop ref, oop value);
   static bool is_referent_field(oop obj, ptrdiff_t offset);
   static inline bool is_final(oop ref);
   static inline bool is_phantom(oop ref);
 
+  static int referent_offset()    { CHECK_INIT(_referent_offset); }
+  static int queue_offset()       { CHECK_INIT(_queue_offset); }
+  static int next_offset()        { CHECK_INIT(_next_offset); }
+  static int discovered_offset()  { CHECK_INIT(_discovered_offset); }
+
   static void compute_offsets();
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 };
 
 
 // Interface to java.lang.ref.SoftReference objects
 
 class java_lang_ref_SoftReference: public java_lang_ref_Reference {
- public:
-  static int timestamp_offset;
-  static int static_clock_offset;
+  static int _timestamp_offset;
+  static int _static_clock_offset;
 
+ public:
   // Accessors
   static jlong timestamp(oop ref);
 
   // Accessors for statics
   static jlong clock();
@@ -988,12 +977,12 @@
     return klass->is_subclass_of(SystemDictionary::MethodHandle_klass());
   }
   static bool is_instance(oop obj);
 
   // Accessors for code generation:
-  static int type_offset_in_bytes()             { return _type_offset; }
-  static int form_offset_in_bytes()             { return _form_offset; }
+  static int type_offset()             { CHECK_INIT(_type_offset); }
+  static int form_offset()             { CHECK_INIT(_form_offset); }
 };
 
 // Interface to java.lang.invoke.DirectMethodHandle objects
 
 class java_lang_invoke_DirectMethodHandle: AllStatic {
@@ -1015,11 +1004,11 @@
     return klass->is_subclass_of(SystemDictionary::DirectMethodHandle_klass());
   }
   static bool is_instance(oop obj);
 
   // Accessors for code generation:
-  static int member_offset_in_bytes()           { return _member_offset; }
+  static int member_offset()           { CHECK_INIT(_member_offset); }
 };
 
 // Interface to java.lang.invoke.LambdaForm objects
 // (These are a private interface for managing adapter code generation.)
 
@@ -1044,11 +1033,11 @@
       klass->is_subclass_of(SystemDictionary::LambdaForm_klass());
   }
   static bool is_instance(oop obj);
 
   // Accessors for code generation:
-  static int vmentry_offset_in_bytes()          { return _vmentry_offset; }
+  static int vmentry_offset()          { CHECK_INIT(_vmentry_offset); }
 };
 
 
 // Interface to java.lang.invoke.MemberName objects
 // (These are a private interface for Java code to query the class hierarchy.)
@@ -1065,11 +1054,11 @@
 
   static void compute_offsets();
  public:
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
-  static int vmtarget_offset_in_bytes() { return _vmtarget_offset; }
+  static int vmtarget_offset() { CHECK_INIT(_vmtarget_offset); }
 
   static Method* vmtarget(oop resolved_method);
   static void set_vmtarget(oop resolved_method, Method* method);
 
   static void set_vmholder(oop resolved_method, oop holder);
@@ -1152,16 +1141,15 @@
     MN_STRONG_LOADER_LINK    = 0x00000004,
     MN_ACCESS_VM_ANNOTATIONS = 0x00000008
   };
 
   // Accessors for code generation:
-  static int clazz_offset_in_bytes()            { return _clazz_offset; }
-  static int type_offset_in_bytes()             { return _type_offset; }
-  static int name_offset_in_bytes()             { return _name_offset; }
-  static int flags_offset_in_bytes()            { return _flags_offset; }
-  static int method_offset_in_bytes()           { return _method_offset; }
-  static int vmindex_offset_in_bytes()          { return _vmindex_offset; }
+  static int clazz_offset()   { CHECK_INIT(_clazz_offset); }
+  static int type_offset()    { CHECK_INIT(_type_offset); }
+  static int flags_offset()   { CHECK_INIT(_flags_offset); }
+  static int method_offset()  { CHECK_INIT(_method_offset); }
+  static int vmindex_offset() { CHECK_INIT(_vmindex_offset); }
 };
 
 
 // Interface to java.lang.invoke.MethodType objects
 
@@ -1192,12 +1180,12 @@
   static bool is_instance(oop obj);
 
   static bool equals(oop mt1, oop mt2);
 
   // Accessors for code generation:
-  static int rtype_offset_in_bytes()            { return _rtype_offset; }
-  static int ptypes_offset_in_bytes()           { return _ptypes_offset; }
+  static int rtype_offset()  { CHECK_INIT(_rtype_offset); }
+  static int ptypes_offset() { CHECK_INIT(_ptypes_offset); }
 };
 
 
 // Interface to java.lang.invoke.CallSite objects
 
@@ -1224,11 +1212,12 @@
     return klass->is_subclass_of(SystemDictionary::CallSite_klass());
   }
   static bool is_instance(oop obj);
 
   // Accessors for code generation:
-  static int target_offset_in_bytes()           { return _target_offset; }
+  static int target_offset()  { CHECK_INIT(_target_offset); }
+  static int context_offset() { CHECK_INIT(_context_offset); }
 };
 
 // Interface to java.lang.invoke.ConstantCallSite objects
 
 class java_lang_invoke_ConstantCallSite: AllStatic {
@@ -1307,18 +1296,18 @@
   macro(java_lang_ClassLoader, loader_data,  intptr_signature, false)
 
 class java_lang_ClassLoader : AllStatic {
  private:
   static int _loader_data_offset;
-  static bool offsets_computed;
-  static int parent_offset;
-  static int parallelCapable_offset;
-  static int name_offset;
-  static int nameAndId_offset;
-  static int unnamedModule_offset;
+  static int _parent_offset;
+  static int _parallelCapable_offset;
+  static int _name_offset;
+  static int _nameAndId_offset;
+  static int _unnamedModule_offset;
 
- public:
+  static void compute_offsets();
+
   static void compute_offsets();
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
   static ClassLoaderData* loader_data_acquire(oop loader);
   static ClassLoaderData* loader_data_raw(oop loader);
@@ -1349,27 +1338,26 @@
 
   static oop unnamedModule(oop loader);
 
   // Debugging
   friend class JavaClasses;
-  friend class ClassFileParser; // access to number_of_fake_fields
 };
 
 
 // Interface to java.lang.System objects
 
 class java_lang_System : AllStatic {
  private:
-  static int  static_in_offset;
-  static int static_out_offset;
-  static int static_err_offset;
-  static int static_security_offset;
+  static int _static_in_offset;
+  static int _static_out_offset;
+  static int _static_err_offset;
+  static int _static_security_offset;
 
  public:
-  static int  in_offset_in_bytes();
-  static int out_offset_in_bytes();
-  static int err_offset_in_bytes();
+  static int  in_offset() { CHECK_INIT(_static_in_offset); }
+  static int out_offset() { CHECK_INIT(_static_out_offset); }
+  static int err_offset() { CHECK_INIT(_static_err_offset); }
 
   static void compute_offsets();
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 
   // Debugging
@@ -1379,18 +1367,18 @@
 
 // Interface to java.lang.StackTraceElement objects
 
 class java_lang_StackTraceElement: AllStatic {
  private:
-  static int declaringClassObject_offset;
-  static int classLoaderName_offset;
-  static int moduleName_offset;
-  static int moduleVersion_offset;
-  static int declaringClass_offset;
-  static int methodName_offset;
-  static int fileName_offset;
-  static int lineNumber_offset;
+  static int _declaringClassObject_offset;
+  static int _classLoaderName_offset;
+  static int _moduleName_offset;
+  static int _moduleVersion_offset;
+  static int _declaringClass_offset;
+  static int _methodName_offset;
+  static int _fileName_offset;
+  static int _lineNumber_offset;
 
   // Setters
   static void set_classLoaderName(oop element, oop value);
   static void set_moduleName(oop element, oop value);
   static void set_moduleVersion(oop element, oop value);
@@ -1490,17 +1478,17 @@
 
 // Interface to java.lang.reflect.RecordComponent objects
 
 class java_lang_reflect_RecordComponent: AllStatic {
  private:
-  static int clazz_offset;
-  static int name_offset;
-  static int type_offset;
-  static int accessor_offset;
-  static int signature_offset;
-  static int annotations_offset;
-  static int typeAnnotations_offset;
+  static int _clazz_offset;
+  static int _name_offset;
+  static int _type_offset;
+  static int _accessor_offset;
+  static int _signature_offset;
+  static int _annotations_offset;
+  static int _typeAnnotations_offset;
 
   // Setters
   static void set_clazz(oop element, oop value);
   static void set_name(oop element, oop value);
   static void set_type(oop element, oop value);
@@ -1523,15 +1511,15 @@
 
 // Interface to java.lang.AssertionStatusDirectives objects
 
 class java_lang_AssertionStatusDirectives: AllStatic {
  private:
-  static int classes_offset;
-  static int classEnabled_offset;
-  static int packages_offset;
-  static int packageEnabled_offset;
-  static int deflt_offset;
+  static int _classes_offset;
+  static int _classEnabled_offset;
+  static int _packages_offset;
+  static int _packageEnabled_offset;
+  static int _deflt_offset;
 
  public:
   // Setters
   static void set_classes(oop obj, oop val);
   static void set_classEnabled(oop obj, oop val);
@@ -1550,11 +1538,11 @@
 class java_nio_Buffer: AllStatic {
  private:
   static int _limit_offset;
 
  public:
-  static int  limit_offset();
+  static int  limit_offset() { CHECK_INIT(_limit_offset); }
   static void compute_offsets();
   static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;
 };
 
 class java_util_concurrent_locks_AbstractOwnableSynchronizer : AllStatic {
@@ -1751,6 +1739,7 @@
   static bool is_supported_for_archiving(oop obj) NOT_CDS_JAVA_HEAP_RETURN_(false);
 };
 
 #undef DECLARE_INJECTED_FIELD_ENUM
 
+#undef CHECK_INIT
 #endif // SHARE_CLASSFILE_JAVACLASSES_HPP
diff a/src/hotspot/share/classfile/vmSymbols.hpp b/src/hotspot/share/classfile/vmSymbols.hpp
--- a/src/hotspot/share/classfile/vmSymbols.hpp
+++ b/src/hotspot/share/classfile/vmSymbols.hpp
@@ -173,10 +173,11 @@
   template(tag_annotation_default,                    "AnnotationDefault")                        \
   template(tag_runtime_visible_type_annotations,      "RuntimeVisibleTypeAnnotations")            \
   template(tag_runtime_invisible_type_annotations,    "RuntimeInvisibleTypeAnnotations")          \
   template(tag_enclosing_method,                      "EnclosingMethod")                          \
   template(tag_bootstrap_methods,                     "BootstrapMethods")                         \
+  template(tag_permitted_subclasses,                  "PermittedSubclasses")                      \
                                                                                                   \
   /* exception klasses: at least all exceptions thrown by the VM have entries here */             \
   template(java_lang_ArithmeticException,             "java/lang/ArithmeticException")            \
   template(java_lang_ArrayIndexOutOfBoundsException,  "java/lang/ArrayIndexOutOfBoundsException") \
   template(java_lang_ArrayStoreException,             "java/lang/ArrayStoreException")            \
diff a/src/hotspot/share/code/nmethod.cpp b/src/hotspot/share/code/nmethod.cpp
--- a/src/hotspot/share/code/nmethod.cpp
+++ b/src/hotspot/share/code/nmethod.cpp
@@ -2026,27 +2026,26 @@
 void nmethod::oops_do_marking_epilogue() {
   assert_at_safepoint();
 
   nmethod* next = _oops_do_mark_nmethods;
   _oops_do_mark_nmethods = NULL;
-  if (next == NULL) {
-    return;
+  if (next != NULL) {
+    nmethod* cur;
+    do {
+      cur = next;
+      next = extract_nmethod(cur->_oops_do_mark_link);
+      cur->_oops_do_mark_link = NULL;
+      DEBUG_ONLY(cur->verify_oop_relocations());
+
+      LogTarget(Trace, gc, nmethod) lt;
+      if (lt.is_enabled()) {
+        LogStream ls(lt);
+        CompileTask::print(&ls, cur, "oops_do, unmark", /*short_form:*/ true);
+      }
+      // End if self-loop has been detected.
+    } while (cur != next);
   }
-  nmethod* cur;
-  do {
-    cur = next;
-    next = extract_nmethod(cur->_oops_do_mark_link);
-    cur->_oops_do_mark_link = NULL;
-    DEBUG_ONLY(cur->verify_oop_relocations());
-
-    LogTarget(Trace, gc, nmethod) lt;
-    if (lt.is_enabled()) {
-      LogStream ls(lt);
-      CompileTask::print(&ls, cur, "oops_do, unmark", /*short_form:*/ true);
-    }
-    // End if self-loop has been detected.
-  } while (cur != next);
   log_trace(gc, nmethod)("oops_do_marking_epilogue");
 }
 
 inline bool includes(void* p, void* from, void* to) {
   return from <= p && p < to;
diff a/src/hotspot/share/compiler/compileBroker.cpp b/src/hotspot/share/compiler/compileBroker.cpp
--- a/src/hotspot/share/compiler/compileBroker.cpp
+++ b/src/hotspot/share/compiler/compileBroker.cpp
@@ -883,10 +883,13 @@
   return new_thread;
 }
 
 
 void CompileBroker::init_compiler_sweeper_threads() {
+  NMethodSweeper::set_sweep_threshold_bytes(static_cast<size_t>(SweeperThreshold * ReservedCodeCacheSize / 100.0));
+  log_info(codecache, sweep)("Sweeper threshold: " SIZE_FORMAT " bytes", NMethodSweeper::sweep_threshold_bytes());
+
   // Ensure any exceptions lead to vm_exit_during_initialization.
   EXCEPTION_MARK;
 #if !defined(ZERO)
   assert(_c2_count > 0 || _c1_count > 0, "No compilers?");
 #endif // !ZERO
diff a/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp b/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
--- a/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
+++ b/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -508,11 +508,11 @@
   // Some compile time checks.
 
   // If offset is a constant, is it java_lang_ref_Reference::_reference_offset?
   const TypeX* otype = offset->find_intptr_t_type();
   if (otype != NULL && otype->is_con() &&
-      otype->get_con() != java_lang_ref_Reference::referent_offset) {
+      otype->get_con() != java_lang_ref_Reference::referent_offset()) {
     // Constant offset but not the reference_offset so just return
     return;
   }
 
   // We only need to generate the runtime guards for instances.
@@ -548,11 +548,11 @@
   float likely   = PROB_LIKELY(  0.999);
   float unlikely = PROB_UNLIKELY(0.999);
 
   IdealKit ideal(kit);
 
-  Node* referent_off = __ ConX(java_lang_ref_Reference::referent_offset);
+  Node* referent_off = __ ConX(java_lang_ref_Reference::referent_offset());
 
   __ if_then(offset, BoolTest::eq, referent_off, unlikely); {
       // Update graphKit memory and control from IdealKit.
       kit->sync_kit(ideal);
 
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
@@ -373,11 +373,11 @@
   // Some compile time checks.
 
   // If offset is a constant, is it java_lang_ref_Reference::_reference_offset?
   const TypeX* otype = offset->find_intptr_t_type();
   if (otype != NULL && otype->is_con() &&
-      otype->get_con() != java_lang_ref_Reference::referent_offset) {
+      otype->get_con() != java_lang_ref_Reference::referent_offset()) {
     // Constant offset but not the reference_offset so just return
     return;
   }
 
   // We only need to generate the runtime guards for instances.
@@ -413,11 +413,11 @@
   float likely   = PROB_LIKELY(  0.999);
   float unlikely = PROB_UNLIKELY(0.999);
 
   IdealKit ideal(kit);
 
-  Node* referent_off = __ ConX(java_lang_ref_Reference::referent_offset);
+  Node* referent_off = __ ConX(java_lang_ref_Reference::referent_offset());
 
   __ if_then(offset, BoolTest::eq, referent_off, unlikely); {
       // Update graphKit memory and control from IdealKit.
       kit->sync_kit(ideal);
 
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
@@ -296,11 +296,11 @@
 
         if (adr_type->isa_oopptr() && adr_type->is_oopptr()->offset() == oopDesc::mark_offset_in_bytes()) {
           if (trace) {tty->print_cr("Mark load");}
         } else if (adr_type->isa_instptr() &&
                    adr_type->is_instptr()->klass()->is_subtype_of(Compile::current()->env()->Reference_klass()) &&
-                   adr_type->is_instptr()->offset() == java_lang_ref_Reference::referent_offset) {
+                   adr_type->is_instptr()->offset() == java_lang_ref_Reference::referent_offset()) {
           if (trace) {tty->print_cr("Reference.get()");}
         } else if (!verify_helper(n->in(MemNode::Address), phis, visited, ShenandoahLoad, trace, barriers_used)) {
           report_verify_failure("Shenandoah verification: Load should have barriers", n);
         }
       }
@@ -1093,13 +1093,10 @@
 
   Node_Stack stack(0);
   Node_List clones;
   for (int i = state->load_reference_barriers_count() - 1; i >= 0; i--) {
     ShenandoahLoadReferenceBarrierNode* lrb = state->load_reference_barrier(i);
-    if (lrb->is_redundant()) {
-      continue;
-    }
 
     Node* ctrl = phase->get_ctrl(lrb);
     Node* val = lrb->in(ShenandoahLoadReferenceBarrierNode::ValueIn);
 
     CallStaticJavaNode* unc = NULL;
@@ -1285,13 +1282,10 @@
     }
   }
 
   for (int i = 0; i < state->load_reference_barriers_count(); i++) {
     ShenandoahLoadReferenceBarrierNode* lrb = state->load_reference_barrier(i);
-    if (lrb->is_redundant()) {
-      continue;
-    }
     Node* ctrl = phase->get_ctrl(lrb);
     IdealLoopTree* loop = phase->get_loop(ctrl);
     if (loop->_head->is_OuterStripMinedLoop()) {
       // Expanding a barrier here will break loop strip mining
       // verification. Transform the loop so the loop nest doesn't
@@ -1304,14 +1298,10 @@
   // Expand load-reference-barriers
   MemoryGraphFixer fixer(Compile::AliasIdxRaw, true, phase);
   Unique_Node_List uses_to_ignore;
   for (int i = state->load_reference_barriers_count() - 1; i >= 0; i--) {
     ShenandoahLoadReferenceBarrierNode* lrb = state->load_reference_barrier(i);
-    if (lrb->is_redundant()) {
-      phase->igvn().replace_node(lrb, lrb->in(ShenandoahLoadReferenceBarrierNode::ValueIn));
-      continue;
-    }
     uint last = phase->C->unique();
     Node* ctrl = phase->get_ctrl(lrb);
     Node* val = lrb->in(ShenandoahLoadReferenceBarrierNode::ValueIn);
 
 
@@ -3020,165 +3010,5 @@
   n->dump(-2);
   ShouldNotReachHere();
 #endif
   return true;
 }
-
-bool ShenandoahLoadReferenceBarrierNode::is_redundant() {
-  Unique_Node_List visited;
-  Node_Stack stack(0);
-  stack.push(this, 0);
-
-  // Check if the barrier is actually useful: go over nodes looking for useful uses
-  // (e.g. memory accesses). Stop once we detected a required use. Otherwise, walk
-  // until we ran out of nodes, and then declare the barrier redundant.
-  while (stack.size() > 0) {
-    Node* n = stack.node();
-    if (visited.member(n)) {
-      stack.pop();
-      continue;
-    }
-    visited.push(n);
-    bool visit_users = false;
-    switch (n->Opcode()) {
-      case Op_CallStaticJava:
-      case Op_CallDynamicJava:
-      case Op_CallLeaf:
-      case Op_CallLeafNoFP:
-      case Op_CompareAndSwapL:
-      case Op_CompareAndSwapI:
-      case Op_CompareAndSwapB:
-      case Op_CompareAndSwapS:
-      case Op_CompareAndSwapN:
-      case Op_CompareAndSwapP:
-      case Op_CompareAndExchangeL:
-      case Op_CompareAndExchangeI:
-      case Op_CompareAndExchangeB:
-      case Op_CompareAndExchangeS:
-      case Op_CompareAndExchangeN:
-      case Op_CompareAndExchangeP:
-      case Op_WeakCompareAndSwapL:
-      case Op_WeakCompareAndSwapI:
-      case Op_WeakCompareAndSwapB:
-      case Op_WeakCompareAndSwapS:
-      case Op_WeakCompareAndSwapN:
-      case Op_WeakCompareAndSwapP:
-      case Op_ShenandoahCompareAndSwapN:
-      case Op_ShenandoahCompareAndSwapP:
-      case Op_ShenandoahWeakCompareAndSwapN:
-      case Op_ShenandoahWeakCompareAndSwapP:
-      case Op_ShenandoahCompareAndExchangeN:
-      case Op_ShenandoahCompareAndExchangeP:
-      case Op_GetAndSetL:
-      case Op_GetAndSetI:
-      case Op_GetAndSetB:
-      case Op_GetAndSetS:
-      case Op_GetAndSetP:
-      case Op_GetAndSetN:
-      case Op_GetAndAddL:
-      case Op_GetAndAddI:
-      case Op_GetAndAddB:
-      case Op_GetAndAddS:
-      case Op_ShenandoahEnqueueBarrier:
-      case Op_FastLock:
-      case Op_FastUnlock:
-      case Op_Rethrow:
-      case Op_Return:
-      case Op_StoreB:
-      case Op_StoreC:
-      case Op_StoreD:
-      case Op_StoreF:
-      case Op_StoreL:
-      case Op_StoreLConditional:
-      case Op_StoreI:
-      case Op_StoreIConditional:
-      case Op_StoreN:
-      case Op_StoreP:
-      case Op_StoreVector:
-      case Op_StrInflatedCopy:
-      case Op_StrCompressedCopy:
-      case Op_EncodeP:
-      case Op_CastP2X:
-      case Op_SafePoint:
-      case Op_EncodeISOArray:
-      case Op_AryEq:
-      case Op_StrEquals:
-      case Op_StrComp:
-      case Op_StrIndexOf:
-      case Op_StrIndexOfChar:
-      case Op_HasNegatives:
-        // Known to require barriers
-        return false;
-      case Op_CmpP: {
-        if (n->in(1)->bottom_type()->higher_equal(TypePtr::NULL_PTR) ||
-            n->in(2)->bottom_type()->higher_equal(TypePtr::NULL_PTR)) {
-          // One of the sides is known null, no need for barrier.
-        } else {
-          return false;
-        }
-        break;
-      }
-      case Op_LoadB:
-      case Op_LoadUB:
-      case Op_LoadUS:
-      case Op_LoadD:
-      case Op_LoadF:
-      case Op_LoadL:
-      case Op_LoadI:
-      case Op_LoadS:
-      case Op_LoadN:
-      case Op_LoadP:
-      case Op_LoadVector: {
-        const TypePtr* adr_type = n->adr_type();
-        int alias_idx = Compile::current()->get_alias_index(adr_type);
-        Compile::AliasType* alias_type = Compile::current()->alias_type(alias_idx);
-        ciField* field = alias_type->field();
-        bool is_static = field != NULL && field->is_static();
-        bool is_final = field != NULL && field->is_final();
-
-        if (ShenandoahOptimizeStaticFinals && is_static && is_final) {
-          // Loading the constant does not require barriers: it should be handled
-          // as part of GC roots already.
-        } else {
-          return false;
-        }
-        break;
-      }
-      case Op_Conv2B:
-      case Op_LoadRange:
-      case Op_LoadKlass:
-      case Op_LoadNKlass:
-        // Do not require barriers
-        break;
-      case Op_AddP:
-      case Op_CheckCastPP:
-      case Op_CastPP:
-      case Op_CMoveP:
-      case Op_Phi:
-      case Op_ShenandoahLoadReferenceBarrier:
-        // Whether or not these need the barriers depends on their users
-        visit_users = true;
-        break;
-      default: {
-#ifdef ASSERT
-        fatal("Unknown node in is_redundant: %s", NodeClassNames[n->Opcode()]);
-#else
-        // Default to have excess barriers, rather than miss some.
-        return false;
-#endif
-      }
-    }
-
-    stack.pop();
-    if (visit_users) {
-      for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {
-        Node* user = n->fast_out(i);
-        if (user != NULL) {
-          stack.push(user, 0);
-        }
-      }
-    }
-  }
-
-  // No need for barrier found.
-  return true;
-}
diff a/src/hotspot/share/gc/z/zBarrierSet.hpp b/src/hotspot/share/gc/z/zBarrierSet.hpp
--- a/src/hotspot/share/gc/z/zBarrierSet.hpp
+++ b/src/hotspot/share/gc/z/zBarrierSet.hpp
@@ -38,11 +38,11 @@
   virtual void on_thread_create(Thread* thread);
   virtual void on_thread_destroy(Thread* thread);
   virtual void on_thread_attach(Thread* thread);
   virtual void on_thread_detach(Thread* thread);
 
-  virtual void print_on(outputStream* st) const {}
+  virtual void print_on(outputStream* st) const;
 
   template <DecoratorSet decorators, typename BarrierSetT = ZBarrierSet>
   class AccessBarrier : public BarrierSet::AccessBarrier<decorators, BarrierSetT> {
   private:
     typedef BarrierSet::AccessBarrier<decorators, BarrierSetT> Raw;
diff a/src/hotspot/share/interpreter/interpreterRuntime.cpp b/src/hotspot/share/interpreter/interpreterRuntime.cpp
--- a/src/hotspot/share/interpreter/interpreterRuntime.cpp
+++ b/src/hotspot/share/interpreter/interpreterRuntime.cpp
@@ -216,11 +216,11 @@
 #endif
   thread->set_vm_result(result);
   if (!is_fast_aldc) {
     // Tell the interpreter how to unbox the primitive.
     guarantee(java_lang_boxing_object::is_instance(result, type), "");
-    int offset = java_lang_boxing_object::value_offset_in_bytes(type);
+    int offset = java_lang_boxing_object::value_offset(type);
     intptr_t flags = ((as_TosState(type) << ConstantPoolCacheEntry::tos_state_shift)
                       | (offset & ConstantPoolCacheEntry::field_index_mask));
     thread->set_vm_result_2((Metadata*)flags);
   }
 }
diff a/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp b/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
--- a/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
+++ b/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
@@ -155,11 +155,11 @@
     if (is_reference_type(type)) {
       (type == T_VALUETYPE) ? _jca->push_oop(next_arg(T_VALUETYPE)) : _jca->push_oop(next_arg(T_OBJECT));
       return;
     }
     Handle arg = next_arg(type);
-    int box_offset = java_lang_boxing_object::value_offset_in_bytes(type);
+    int box_offset = java_lang_boxing_object::value_offset(type);
     switch (type) {
     case T_BOOLEAN:     _jca->push_int(arg->bool_field(box_offset));    break;
     case T_CHAR:        _jca->push_int(arg->char_field(box_offset));    break;
     case T_SHORT:       _jca->push_int(arg->short_field(box_offset));   break;
     case T_BYTE:        _jca->push_int(arg->byte_field(box_offset));    break;
diff a/src/hotspot/share/logging/logTag.hpp b/src/hotspot/share/logging/logTag.hpp
--- a/src/hotspot/share/logging/logTag.hpp
+++ b/src/hotspot/share/logging/logTag.hpp
@@ -145,10 +145,11 @@
   LOG_TAG(record) \
   LOG_TAG(resolve) \
   LOG_TAG(safepoint) \
   LOG_TAG(sampling) \
   LOG_TAG(scavenge) \
+  LOG_TAG(sealed) \
   LOG_TAG(setting) \
   LOG_TAG(smr) \
   LOG_TAG(stacktrace) \
   LOG_TAG(stackwalk) \
   LOG_TAG(start) \
diff a/src/hotspot/share/memory/dynamicArchive.cpp b/src/hotspot/share/memory/dynamicArchive.cpp
--- a/src/hotspot/share/memory/dynamicArchive.cpp
+++ b/src/hotspot/share/memory/dynamicArchive.cpp
@@ -990,17 +990,17 @@
 
   intx addr_delta = MetaspaceShared::final_delta();
   if (addr_delta == 0) {
     ArchivePtrMarker::compact(relocatable_base, relocatable_end);
   } else {
-    // The base archive is NOT mapped at Arguments::default_SharedBaseAddress() (due to ASLR).
+    // The base archive is NOT mapped at MetaspaceShared::requested_base_address() (due to ASLR).
     // This means that the current content of the dynamic archive is based on a random
     // address. Let's relocate all the pointers, so that it can be mapped to
-    // Arguments::default_SharedBaseAddress() without runtime relocation.
+    // MetaspaceShared::requested_base_address() without runtime relocation.
     //
     // Note: both the base and dynamic archive are written with
-    // FileMapHeader::_shared_base_address == Arguments::default_SharedBaseAddress()
+    // FileMapHeader::_requested_base_address == MetaspaceShared::requested_base_address()
 
     // Patch all pointers that are marked by ptrmap within this region,
     // where we have just dumped all the metaspace data.
     address patch_base = (address)_alloc_bottom;
     address patch_end  = (address)current_dump_space()->top();
@@ -1016,11 +1016,11 @@
     assert(base_plus_top_size > base_size, "no overflow");
     assert(base_plus_top_size > top_size, "no overflow");
 
     // after patching, the pointers must point inside this range
     // (the requested location of the archive, as mapped at runtime).
-    address valid_new_base = (address)Arguments::default_SharedBaseAddress();
+    address valid_new_base = (address)MetaspaceShared::requested_base_address();
     address valid_new_end  = valid_new_base + base_plus_top_size;
 
     log_debug(cds)("Relocating archive from [" INTPTR_FORMAT " - " INTPTR_FORMAT "] to "
                    "[" INTPTR_FORMAT " - " INTPTR_FORMAT "], delta = " INTX_FORMAT " bytes",
                    p2i(patch_base + base_size), p2i(patch_end),
@@ -1044,11 +1044,11 @@
 
   // Now write the archived data including the file offsets.
   const char* archive_name = Arguments::GetSharedDynamicArchivePath();
   dynamic_info->open_for_write(archive_name);
   MetaspaceShared::write_core_archive_regions(dynamic_info, NULL, NULL);
-  dynamic_info->set_final_requested_base((char*)Arguments::default_SharedBaseAddress());
+  dynamic_info->set_final_requested_base((char*)MetaspaceShared::requested_base_address());
   dynamic_info->set_header_crc(dynamic_info->compute_header_crc());
   dynamic_info->write_header();
   dynamic_info->close();
 
   address base = to_target(_alloc_bottom);
diff a/src/hotspot/share/memory/metaspaceShared.cpp b/src/hotspot/share/memory/metaspaceShared.cpp
--- a/src/hotspot/share/memory/metaspaceShared.cpp
+++ b/src/hotspot/share/memory/metaspaceShared.cpp
@@ -88,10 +88,11 @@
 bool MetaspaceShared::_remapped_readwrite = false;
 address MetaspaceShared::_i2i_entry_code_buffers = NULL;
 size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;
 void* MetaspaceShared::_shared_metaspace_static_top = NULL;
 intx MetaspaceShared::_relocation_delta;
+char* MetaspaceShared::_requested_base_address;
 
 // The CDS archive is divided into the following regions:
 //     mc  - misc code (the method entry trampolines, c++ vtables)
 //     rw  - read-write metadata
 //     ro  - read-only metadata and read-only tables
@@ -240,37 +241,57 @@
   return _ro_region.allocate(num_bytes);
 }
 
 size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 
+static bool shared_base_valid(char* shared_base) {
 #ifdef _LP64
-// Check SharedBaseAddress for validity. At this point, os::init() must
-//  have been ran.
-static void check_SharedBaseAddress() {
-  SharedBaseAddress = align_up(SharedBaseAddress,
-                               MetaspaceShared::reserved_space_alignment());
-  if (!CompressedKlassPointers::is_valid_base((address)SharedBaseAddress)) {
-    log_warning(cds)("SharedBaseAddress=" PTR_FORMAT " is invalid for this "
-                     "platform, option will be ignored.",
-                     p2i((address)SharedBaseAddress));
+  return CompressedKlassPointers::is_valid_base((address)shared_base);
+#else
+  return true;
+#endif
+}
+
+static bool shared_base_too_high(char* shared_base, size_t cds_total) {
+  if (SharedBaseAddress != 0 && shared_base < (char*)SharedBaseAddress) {
+    // SharedBaseAddress is very high (e.g., 0xffffffffffffff00) so
+    // align_up(SharedBaseAddress, MetaspaceShared::reserved_space_alignment()) has wrapped around.
+    return true;
+  }
+  if (max_uintx - uintx(shared_base) < uintx(cds_total)) {
+    // The end of the archive will wrap around
+    return true;
+  }
+
+  return false;
+}
+
+static char* compute_shared_base(size_t cds_total) {
+  char* shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());
+  const char* err = NULL;
+  if (shared_base_too_high(shared_base, cds_total)) {
+    err = "too high";
+  } else if (!shared_base_valid(shared_base)) {
+    err = "invalid for this platform";
+  }
+  if (err) {
+    log_warning(cds)("SharedBaseAddress (" INTPTR_FORMAT ") is %s. Reverted to " INTPTR_FORMAT,
+                     p2i((void*)SharedBaseAddress), err,
+                     p2i((void*)Arguments::default_SharedBaseAddress()));
     SharedBaseAddress = Arguments::default_SharedBaseAddress();
+    shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());
   }
+  assert(!shared_base_too_high(shared_base, cds_total) && shared_base_valid(shared_base), "Sanity");
+  return shared_base;
 }
-#endif
 
 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
   assert(DumpSharedSpaces, "should be called for dump time only");
 
-#ifdef _LP64
-  check_SharedBaseAddress();
-#endif
-
-  const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();
   char* shared_base = (char*)align_up((char*)SharedBaseAddress, reserve_alignment);
 
 #ifdef _LP64
-  assert(CompressedKlassPointers::is_valid_base((address)shared_base), "Sanity");
   // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
   //  will use that to house both the archives and the ccs. See below for
   //  details.
   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
@@ -278,10 +299,13 @@
   // We don't support archives larger than 256MB on 32-bit due to limited
   //  virtual address space.
   size_t cds_total = align_down(256*M, reserve_alignment);
 #endif
 
+  char* shared_base = compute_shared_base(cds_total);
+  _requested_base_address = shared_base;
+
   // Whether to use SharedBaseAddress as attach address.
   bool use_requested_base = true;
 
   if (shared_base == NULL) {
     use_requested_base = false;
@@ -398,10 +422,14 @@
   init_shared_dump_space(&_mc_region);
   SharedBaseAddress = (size_t)_shared_rs.base();
   log_info(cds)("Allocated shared space: " SIZE_FORMAT " bytes at " PTR_FORMAT,
                 _shared_rs.size(), p2i(_shared_rs.base()));
 
+  // We don't want any valid object to be at the very bottom of the archive.
+  // See ArchivePtrMarker::mark_pointer().
+  MetaspaceShared::misc_code_space_alloc(16);
+
   size_t symbol_rs_size = LP64_ONLY(3 * G) NOT_LP64(128 * M);
   _symbol_rs = ReservedSpace(symbol_rs_size);
   if (!_symbol_rs.is_reserved()) {
     vm_exit_during_initialization("Unable to reserve memory for symbols",
                                   err_msg(SIZE_FORMAT " bytes.", symbol_rs_size));
@@ -1204,11 +1232,11 @@
   void print_class_stats();
   void print_region_stats(FileMapInfo* map_info);
   void print_bitmap_region_stats(size_t size, size_t total_size);
   void print_heap_region_stats(GrowableArray<MemRegion> *heap_mem,
                                const char *name, size_t total_size);
-  void relocate_to_default_base_address(CHeapBitMap* ptrmap);
+  void relocate_to_requested_base_address(CHeapBitMap* ptrmap);
 
 public:
 
   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
   void doit();   // outline because gdb sucks
@@ -1586,22 +1614,22 @@
     log_info(cds)("    obj array classes  = %5d", num_obj_array);
     log_info(cds)("    type array classes = %5d", num_type_array);
   }
 }
 
-void VM_PopulateDumpSharedSpace::relocate_to_default_base_address(CHeapBitMap* ptrmap) {
+void VM_PopulateDumpSharedSpace::relocate_to_requested_base_address(CHeapBitMap* ptrmap) {
   intx addr_delta = MetaspaceShared::final_delta();
   if (addr_delta == 0) {
     ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());
   } else {
-    // We are not able to reserve space at Arguments::default_SharedBaseAddress() (due to ASLR).
+    // We are not able to reserve space at MetaspaceShared::requested_base_address() (due to ASLR).
     // This means that the current content of the archive is based on a random
     // address. Let's relocate all the pointers, so that it can be mapped to
-    // Arguments::default_SharedBaseAddress() without runtime relocation.
+    // MetaspaceShared::requested_base_address() without runtime relocation.
     //
     // Note: both the base and dynamic archive are written with
-    // FileMapHeader::_shared_base_address == Arguments::default_SharedBaseAddress()
+    // FileMapHeader::_requested_base_address == MetaspaceShared::requested_base_address()
 
     // Patch all pointers that are marked by ptrmap within this region,
     // where we have just dumped all the metaspace data.
     address patch_base = (address)SharedBaseAddress;
     address patch_end  = (address)_ro_region.top();
@@ -1612,11 +1640,11 @@
     address valid_old_base = patch_base;
     address valid_old_end  = patch_end;
 
     // after patching, the pointers must point inside this range
     // (the requested location of the archive, as mapped at runtime).
-    address valid_new_base = (address)Arguments::default_SharedBaseAddress();
+    address valid_new_base = (address)MetaspaceShared::requested_base_address();
     address valid_new_end  = valid_new_base + size;
 
     log_debug(cds)("Relocating archive from [" INTPTR_FORMAT " - " INTPTR_FORMAT " ] to "
                    "[" INTPTR_FORMAT " - " INTPTR_FORMAT " ]", p2i(patch_base), p2i(patch_end),
                    p2i(valid_new_base), p2i(valid_new_end));
@@ -1699,13 +1727,13 @@
   // We don't want to write these addresses into the archive. Same for i2i buffer.
   MetaspaceShared::zero_cpp_vtable_clones_for_writing();
   memset(MetaspaceShared::i2i_entry_code_buffers(), 0,
          MetaspaceShared::i2i_entry_code_buffers_size());
 
-  // relocate the data so that it can be mapped to Arguments::default_SharedBaseAddress()
+  // relocate the data so that it can be mapped to MetaspaceShared::requested_base_address()
   // without runtime relocation.
-  relocate_to_default_base_address(&ptrmap);
+  relocate_to_requested_base_address(&ptrmap);
 
   // Create and write the archive file that maps the shared spaces.
 
   FileMapInfo* mapinfo = new FileMapInfo(true);
   mapinfo->populate_header(os::vm_allocation_granularity());
@@ -1724,11 +1752,11 @@
                                         _open_archive_heap_regions,
                                         _open_archive_heap_oopmaps,
                                         MetaspaceShared::first_open_archive_heap_region,
                                         MetaspaceShared::max_open_archive_heap_region);
 
-  mapinfo->set_final_requested_base((char*)Arguments::default_SharedBaseAddress());
+  mapinfo->set_final_requested_base((char*)MetaspaceShared::requested_base_address());
   mapinfo->set_header_crc(mapinfo->compute_header_crc());
   mapinfo->write_header();
   print_region_stats(mapinfo);
   mapinfo->close();
 
@@ -2180,10 +2208,11 @@
     if (dynamic_mapped) {
       FileMapInfo::set_shared_path_table(dynamic_mapinfo);
     } else {
       FileMapInfo::set_shared_path_table(static_mapinfo);
     }
+    _requested_base_address = static_mapinfo->requested_base_address();
   } else {
     set_shared_metaspace_range(NULL, NULL, NULL);
     UseSharedSpaces = false;
     FileMapInfo::fail_continue("Unable to map shared spaces");
     if (PrintSharedArchiveAndExit) {
@@ -2227,10 +2256,15 @@
 // use_requested_addr:
 //  true  = map at FileMapHeader::_requested_base_address
 //  false = map at an alternative address picked by OS.
 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
                                                bool use_requested_addr) {
+  if (use_requested_addr && static_mapinfo->requested_base_address() == NULL) {
+    log_info(cds)("Archive(s) were created with -XX:SharedBaseAddress=0. Always map at os-selected address.");
+    return MAP_ARCHIVE_MMAP_FAILURE;
+  }
+
   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 && use_requested_addr) {
       // For product build only -- this is for benchmarking the cost of doing relocation.
       // For debug builds, the check is done below, after reserving the space, for better test coverage
       // (see comment below).
       log_info(cds)("ArchiveRelocationMode == 1: always map archive(s) at an alternative address");
@@ -2678,15 +2712,15 @@
 
   vm_exit_during_initialization(err_msg("Unable to allocate from '%s' region", name),
                                 "Please reduce the number of shared classes.");
 }
 
-// This is used to relocate the pointers so that the archive can be mapped at
-// Arguments::default_SharedBaseAddress() without runtime relocation.
+// This is used to relocate the pointers so that the base archive can be mapped at
+// MetaspaceShared::requested_base_address() without runtime relocation.
 intx MetaspaceShared::final_delta() {
-  return intx(Arguments::default_SharedBaseAddress())  // We want the archive to be mapped to here at runtime
-       - intx(SharedBaseAddress);                      // .. but the archive is mapped at here at dump time
+  return intx(MetaspaceShared::requested_base_address())  // We want the base archive to be mapped to here at runtime
+       - intx(SharedBaseAddress);                         // .. but the base archive is mapped at here at dump time
 }
 
 void MetaspaceShared::print_on(outputStream* st) {
   if (UseSharedSpaces || DumpSharedSpaces) {
     st->print("CDS archive(s) mapped at: ");
diff a/src/hotspot/share/memory/universe.cpp b/src/hotspot/share/memory/universe.cpp
--- a/src/hotspot/share/memory/universe.cpp
+++ b/src/hotspot/share/memory/universe.cpp
@@ -35,10 +35,11 @@
 #include "code/codeCache.hpp"
 #include "code/dependencies.hpp"
 #include "gc/shared/collectedHeap.inline.hpp"
 #include "gc/shared/gcArguments.hpp"
 #include "gc/shared/gcConfig.hpp"
+#include "gc/shared/gcLogPrecious.hpp"
 #include "gc/shared/gcTraceTime.inline.hpp"
 #include "interpreter/interpreter.hpp"
 #include "logging/log.hpp"
 #include "logging/logStream.hpp"
 #include "memory/heapShared.hpp"
@@ -669,10 +670,12 @@
 
   TraceTime timer("Genesis", TRACETIME_LOG(Info, startuptime));
 
   initialize_global_behaviours();
 
+  GCLogPrecious::initialize();
+
   GCConfig::arguments()->initialize_heap_sizes();
 
   jint status = Universe::initialize_heap();
   if (status != JNI_OK) {
     return status;
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -217,10 +217,61 @@
   }
   log_trace(class, nestmates)("- class is NOT a nest member!");
   return false;
 }
 
+// Called to verify that k is a permitted subclass of this class
+bool InstanceKlass::has_as_permitted_subclass(const InstanceKlass* k) const {
+  Thread* THREAD = Thread::current();
+  assert(k != NULL, "sanity check");
+  assert(_permitted_subclasses != NULL && _permitted_subclasses != Universe::the_empty_short_array(),
+         "unexpected empty _permitted_subclasses array");
+
+  if (log_is_enabled(Trace, class, sealed)) {
+    ResourceMark rm(THREAD);
+    log_trace(class, sealed)("Checking for permitted subclass of %s in %s",
+                             k->external_name(), this->external_name());
+  }
+
+  // Check that the class and its super are in the same module.
+  if (k->module() != this->module()) {
+    ResourceMark rm(THREAD);
+    log_trace(class, sealed)("Check failed for same module of permitted subclass %s and sealed class %s",
+                             k->external_name(), this->external_name());
+    return false;
+  }
+
+  if (!k->is_public() && !is_same_class_package(k)) {
+    ResourceMark rm(THREAD);
+    log_trace(class, sealed)("Check failed, subclass %s not public and not in the same package as sealed class %s",
+                             k->external_name(), this->external_name());
+    return false;
+  }
+
+  // Check for a resolved cp entry, else fall back to a name check.
+  // We don't want to resolve any class other than the one being checked.
+  for (int i = 0; i < _permitted_subclasses->length(); i++) {
+    int cp_index = _permitted_subclasses->at(i);
+    if (_constants->tag_at(cp_index).is_klass()) {
+      Klass* k2 = _constants->klass_at(cp_index, THREAD);
+      assert(!HAS_PENDING_EXCEPTION, "Unexpected exception");
+      if (k2 == k) {
+        log_trace(class, sealed)("- class is listed at permitted_subclasses[%d] => cp[%d]", i, cp_index);
+        return true;
+      }
+    } else {
+      Symbol* name = _constants->klass_name_at(cp_index);
+      if (name == k->name()) {
+        log_trace(class, sealed)("- Found it at permitted_subclasses[%d] => cp[%d]", i, cp_index);
+        return true;
+      }
+    }
+  }
+  log_trace(class, sealed)("- class is NOT a permitted subclass!");
+  return false;
+}
+
 // Return nest-host class, resolving, validating and saving it if needed.
 // In cases where this is called from a thread that cannot do classloading
 // (such as a native JIT thread) then we simply return NULL, which in turn
 // causes the access check to return false. Such code will retry the access
 // from a more suitable environment later. Otherwise the _nest_host is always
@@ -517,10 +568,11 @@
 
 InstanceKlass::InstanceKlass(const ClassFileParser& parser, unsigned kind, KlassID id) :
   Klass(id),
   _nest_members(NULL),
   _nest_host(NULL),
+  _permitted_subclasses(NULL),
   _record_components(NULL),
   _static_field_size(parser.static_field_size()),
   _nonstatic_oop_map_size(nonstatic_oop_map_size(parser.total_oop_map_count())),
   _itable_len(parser.itable_size()),
   _nest_host_index(0),
@@ -709,10 +761,17 @@
       !nest_members()->is_shared()) {
     MetadataFactory::free_array<jushort>(loader_data, nest_members());
   }
   set_nest_members(NULL);
 
+  if (permitted_subclasses() != NULL &&
+      permitted_subclasses() != Universe::the_empty_short_array() &&
+      !permitted_subclasses()->is_shared()) {
+    MetadataFactory::free_array<jushort>(loader_data, permitted_subclasses());
+  }
+  set_permitted_subclasses(NULL);
+
   // We should deallocate the Annotations instance if it's not in shared spaces.
   if (annotations() != NULL && !annotations()->is_shared()) {
     MetadataFactory::free_metadata(loader_data, annotations());
   }
   set_annotations(NULL);
@@ -720,10 +779,16 @@
   if (Arguments::is_dumping_archive()) {
     SystemDictionaryShared::remove_dumptime_info(this);
   }
 }
 
+bool InstanceKlass::is_sealed() const {
+  return _permitted_subclasses != NULL &&
+         _permitted_subclasses != Universe::the_empty_short_array() &&
+         _permitted_subclasses->length() > 0;
+}
+
 bool InstanceKlass::should_be_initialized() const {
   return !is_initialized();
 }
 
 klassItable InstanceKlass::itable() const {
@@ -778,11 +843,11 @@
 // That's okay because they all check for initialized state after getting
 // the lock and return.
 void InstanceKlass::fence_and_clear_init_lock() {
   // make sure previous stores are all done, notably the init_state.
   OrderAccess::storestore();
-  java_lang_Class::set_init_lock(java_mirror(), NULL);
+  java_lang_Class::clear_init_lock(java_mirror());
   assert(!is_not_initialized(), "class must be initialized now");
 }
 
 void InstanceKlass::eager_initialize_impl() {
   EXCEPTION_MARK;
@@ -2553,10 +2618,11 @@
       }
     }
   }
 
   it->push(&_nest_members);
+  it->push(&_permitted_subclasses);
   it->push(&_record_components);
 }
 
 void InstanceKlass::remove_unshareable_info() {
   Klass::remove_unshareable_info();
@@ -3509,10 +3575,11 @@
   st->print(BULLET"inner classes:     "); inner_classes()->print_value_on(st);     st->cr();
   st->print(BULLET"nest members:     "); nest_members()->print_value_on(st);     st->cr();
   if (record_components() != NULL) {
     st->print(BULLET"record components:     "); record_components()->print_value_on(st);     st->cr();
   }
+  st->print(BULLET"permitted subclasses:     "); permitted_subclasses()->print_value_on(st);     st->cr();
   if (java_mirror() != NULL) {
     st->print(BULLET"java mirror:       ");
     java_mirror()->print_value_on(st);
     st->cr();
   } else {
diff a/src/hotspot/share/oops/instanceKlass.hpp b/src/hotspot/share/oops/instanceKlass.hpp
--- a/src/hotspot/share/oops/instanceKlass.hpp
+++ b/src/hotspot/share/oops/instanceKlass.hpp
@@ -225,10 +225,14 @@
   // By always being set it makes nest-member access checks simpler.
   InstanceKlass* _nest_host;
 
   Array<InlineTypes>* _inline_types;
 
+  // The PermittedSubclasses attribute. An array of shorts, where each is a
+  // class info index for the class that is a permitted subclass.
+  Array<jushort>* _permitted_subclasses;
+
   // The contents of the Record attribute.
   Array<RecordComponent*>* _record_components;
 
   // the source debug extension for this klass, NULL if not specified.
   // Specified as UTF-8 string without terminating zero byte in the classfile,
@@ -574,10 +578,14 @@
   void set_record_components(Array<RecordComponent*>* record_components) {
     _record_components = record_components;
   }
   bool is_record() const { return _record_components != NULL; }
 
+  // permitted subclasses
+  Array<u2>* permitted_subclasses() const     { return _permitted_subclasses; }
+  void set_permitted_subclasses(Array<u2>* s) { _permitted_subclasses = s; }
+
 private:
   // Called to verify that k is a member of this nest - does not look at k's nest-host
   bool has_nest_member(InstanceKlass* k, TRAPS) const;
 
 public:
@@ -589,10 +597,13 @@
   // Returns NULL if resolution is not possible from the calling context.
   InstanceKlass* nest_host(TRAPS);
   // Check if this klass is a nestmate of k - resolves this nest-host and k's
   bool has_nestmate_access_to(InstanceKlass* k, TRAPS);
 
+  // Called to verify that k is a permitted subclass of this class
+  bool has_as_permitted_subclass(const InstanceKlass* k) const;
+
   enum InnerClassAttributeOffset {
     // From http://mirror.eng/products/jdk/1.1/docs/guide/innerclasses/spec/innerclasses.doc10.html#18814
     inner_class_inner_class_info_offset = 0,
     inner_class_outer_class_info_offset = 1,
     inner_class_inner_name_offset = 2,
@@ -646,10 +657,13 @@
   bool is_in_error_state() const           { return _init_state == initialization_error; }
   bool is_reentrant_initialization(Thread *thread)  { return thread == _init_thread; }
   ClassState  init_state()                 { return (ClassState)_init_state; }
   bool is_rewritten() const                { return (_misc_flags & _misc_rewritten) != 0; }
 
+  // is this a sealed class
+  bool is_sealed() const;
+
   // defineClass specified verification
   bool should_verify_class() const         {
     return (_misc_flags & _misc_should_verify_class) != 0;
   }
   void set_should_verify_class(bool value) {
diff a/src/hotspot/share/opto/c2_globals.hpp b/src/hotspot/share/opto/c2_globals.hpp
--- a/src/hotspot/share/opto/c2_globals.hpp
+++ b/src/hotspot/share/opto/c2_globals.hpp
@@ -355,14 +355,10 @@
                                                                             \
   product_pd(intx, ConditionalMoveLimit,                                    \
           "Limit of ops to make speculative when using CMOVE")              \
           range(0, max_jint)                                                \
                                                                             \
-  /* Set BranchOnRegister == false. See 4965987. */                         \
-  product(bool, BranchOnRegister, false,                                    \
-          "Use Sparc V9 branch-on-register opcodes")                        \
-                                                                            \
   product(bool, UseRDPCForConstantTableBase, false,                         \
           "Use Sparc RDPC instruction for the constant table base.")        \
                                                                             \
   notproduct(bool, PrintIdealGraph, false,                                  \
           "Print ideal graph to XML file / network interface. "             \
diff a/src/hotspot/share/opto/compile.cpp b/src/hotspot/share/opto/compile.cpp
--- a/src/hotspot/share/opto/compile.cpp
+++ b/src/hotspot/share/opto/compile.cpp
@@ -1615,11 +1615,11 @@
     idx = _num_alias_types++;
     _alias_types[idx]->Init(idx, flat);
     if (flat == TypeInstPtr::KLASS)  alias_type(idx)->set_rewritable(false);
     if (flat == TypeAryPtr::RANGE)   alias_type(idx)->set_rewritable(false);
     if (flat->isa_instptr()) {
-      if (flat->offset() == java_lang_Class::klass_offset_in_bytes()
+      if (flat->offset() == java_lang_Class::klass_offset()
           && flat->is_instptr()->klass() == env()->Class_klass())
         alias_type(idx)->set_rewritable(false);
     }
     ciField* field = NULL;
     if (flat->isa_aryptr()) {
diff a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -4426,11 +4426,11 @@
   // Divide length by 2 if coder is UTF16
   return _gvn.transform(new RShiftINode(len, coder));
 }
 
 Node* GraphKit::load_String_value(Node* str, bool set_ctrl) {
-  int value_offset = java_lang_String::value_offset_in_bytes();
+  int value_offset = java_lang_String::value_offset();
   const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C->env()->String_klass(),
                                                      false, NULL, Type::Offset(0), false);
   const TypePtr* value_field_type = string_type->add_offset(value_offset);
   const TypeAryPtr* value_type = TypeAryPtr::make(TypePtr::NotNull,
                                                   TypeAry::make(TypeInt::BYTE, TypeInt::POS, false, true, true),
@@ -4443,11 +4443,11 @@
 
 Node* GraphKit::load_String_coder(Node* str, bool set_ctrl) {
   if (!CompactStrings) {
     return intcon(java_lang_String::CODER_UTF16);
   }
-  int coder_offset = java_lang_String::coder_offset_in_bytes();
+  int coder_offset = java_lang_String::coder_offset();
   const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C->env()->String_klass(),
                                                      false, NULL, Type::Offset(0), false);
   const TypePtr* coder_field_type = string_type->add_offset(coder_offset);
 
   Node* p = basic_plus_adr(str, str, coder_offset);
@@ -4455,21 +4455,21 @@
                               IN_HEAP | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0) | MO_UNORDERED);
   return load;
 }
 
 void GraphKit::store_String_value(Node* str, Node* value) {
-  int value_offset = java_lang_String::value_offset_in_bytes();
+  int value_offset = java_lang_String::value_offset();
   const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C->env()->String_klass(),
                                                      false, NULL, Type::Offset(0), false);
   const TypePtr* value_field_type = string_type->add_offset(value_offset);
 
   access_store_at(str,  basic_plus_adr(str, value_offset), value_field_type,
                   value, TypeAryPtr::BYTES, T_OBJECT, IN_HEAP | MO_UNORDERED);
 }
 
 void GraphKit::store_String_coder(Node* str, Node* value) {
-  int coder_offset = java_lang_String::coder_offset_in_bytes();
+  int coder_offset = java_lang_String::coder_offset();
   const TypeInstPtr* string_type = TypeInstPtr::make(TypePtr::NotNull, C->env()->String_klass(),
                                                      false, NULL, Type::Offset(0), false);
   const TypePtr* coder_field_type = string_type->add_offset(coder_offset);
 
   access_store_at(str, basic_plus_adr(str, coder_offset), coder_field_type,
diff a/src/hotspot/share/opto/library_call.cpp b/src/hotspot/share/opto/library_call.cpp
--- a/src/hotspot/share/opto/library_call.cpp
+++ b/src/hotspot/share/opto/library_call.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -176,18 +176,18 @@
   Node* load_klass_from_mirror_common(Node* mirror, bool never_see_null,
                                       RegionNode* region, int null_path,
                                       int offset);
   Node* load_klass_from_mirror(Node* mirror, bool never_see_null,
                                RegionNode* region, int null_path) {
-    int offset = java_lang_Class::klass_offset_in_bytes();
+    int offset = java_lang_Class::klass_offset();
     return load_klass_from_mirror_common(mirror, never_see_null,
                                          region, null_path,
                                          offset);
   }
   Node* load_array_klass_from_mirror(Node* mirror, bool never_see_null,
                                      RegionNode* region, int null_path) {
-    int offset = java_lang_Class::array_klass_offset_in_bytes();
+    int offset = java_lang_Class::array_klass_offset();
     return load_klass_from_mirror_common(mirror, never_see_null,
                                          region, null_path,
                                          offset);
   }
   Node* generate_access_flags_guard(Node* kls,
@@ -3630,11 +3630,11 @@
   record_for_igvn(region);
   record_for_igvn(prim_region);
 
   const TypePtr* adr_type = TypeRawPtr::BOTTOM;   // memory type of loads
   const TypeKlassPtr* kls_type = TypeKlassPtr::OBJECT_OR_NULL;
-  int class_klass_offset = java_lang_Class::klass_offset_in_bytes();
+  int class_klass_offset = java_lang_Class::klass_offset();
 
   // First null-check both mirrors and load each mirror's klass metaobject.
   int which_arg;
   for (which_arg = 0; which_arg <= 1; which_arg++) {
     Node* arg = args[which_arg];
@@ -6032,12 +6032,11 @@
 }
 
 //----------------------------inline_reference_get----------------------------
 // public T java.lang.ref.Reference.get();
 bool LibraryCallKit::inline_reference_get() {
-  const int referent_offset = java_lang_ref_Reference::referent_offset;
-  guarantee(referent_offset > 0, "should have already been set");
+  const int referent_offset = java_lang_ref_Reference::referent_offset();
 
   // Get the argument:
   Node* reference_obj = null_check_receiver();
   if (stopped()) return true;
 
diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -1016,12 +1016,12 @@
         // Disconnect ArrayCopy node
         ArrayCopyNode* ac = use->as_ArrayCopy();
         if (ac->is_clonebasic()) {
           Node* membar_after = ac->proj_out(TypeFunc::Control)->unique_ctrl_out();
           disconnect_projections(ac, _igvn);
-          assert(alloc->in(0)->is_Proj() && alloc->in(0)->in(0)->Opcode() == Op_MemBarCPUOrder, "mem barrier expected before allocation");
-          Node* membar_before = alloc->in(0)->in(0);
+          assert(alloc->in(TypeFunc::Memory)->is_Proj() && alloc->in(TypeFunc::Memory)->in(0)->Opcode() == Op_MemBarCPUOrder, "mem barrier expected before allocation");
+          Node* membar_before = alloc->in(TypeFunc::Memory)->in(0);
           disconnect_projections(membar_before->as_MemBar(), _igvn);
           if (membar_after->is_MemBar()) {
             disconnect_projections(membar_after->as_MemBar(), _igvn);
           }
         } else {
diff a/src/hotspot/share/opto/memnode.cpp b/src/hotspot/share/opto/memnode.cpp
--- a/src/hotspot/share/opto/memnode.cpp
+++ b/src/hotspot/share/opto/memnode.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -2225,19 +2225,19 @@
   const TypeInstPtr *tinst = tp->isa_instptr();
   if (tinst != NULL) {
     ciInstanceKlass* ik = tinst->klass()->as_instance_klass();
     int offset = tinst->offset();
     if (ik == phase->C->env()->Class_klass()
-        && (offset == java_lang_Class::klass_offset_in_bytes() ||
-            offset == java_lang_Class::array_klass_offset_in_bytes())) {
+        && (offset == java_lang_Class::klass_offset() ||
+            offset == java_lang_Class::array_klass_offset())) {
       // We are loading a special hidden field from a Class mirror object,
       // the field which points to the VM's Klass metaobject.
       ciType* t = tinst->java_mirror_type();
       // java_mirror_type returns non-null for compile-time Class constants.
       if (t != NULL) {
         // constant oop => constant klass
-        if (offset == java_lang_Class::array_klass_offset_in_bytes()) {
+        if (offset == java_lang_Class::array_klass_offset()) {
           if (t->is_void()) {
             // We cannot create a void array.  Since void is a primitive type return null
             // klass.  Users of this result need to do a null check on the returned klass.
             return TypePtr::NULL_PTR;
           }
@@ -2390,11 +2390,11 @@
   // mirror go completely dead.  (Current exception:  Class
   // mirrors may appear in debug info, but we could clean them out by
   // introducing a new debug info operator for Klass.java_mirror).
 
   if (toop->isa_instptr() && toop->klass() == phase->C->env()->Class_klass()
-      && offset == java_lang_Class::klass_offset_in_bytes()) {
+      && offset == java_lang_Class::klass_offset()) {
     if (base->is_Load()) {
       Node* base2 = base->in(MemNode::Address);
       if (base2->is_Load()) { /* direct load of a load which is the OopHandle */
         Node* adr2 = base2->in(MemNode::Address);
         const TypeKlassPtr* tkls = phase->type(adr2)->isa_klassptr();
diff a/src/hotspot/share/opto/stringopts.cpp b/src/hotspot/share/opto/stringopts.cpp
--- a/src/hotspot/share/opto/stringopts.cpp
+++ b/src/hotspot/share/opto/stringopts.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2009, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -1664,11 +1664,11 @@
 
 jbyte PhaseStringOpts::get_constant_coder(GraphKit& kit, Node* str) {
   assert(str->is_Con(), "String must be constant");
   const TypeOopPtr* str_type = kit.gvn().type(str)->isa_oopptr();
   ciInstance* str_instance = str_type->const_oop()->as_instance();
-  jbyte coder = str_instance->field_value_by_offset(java_lang_String::coder_offset_in_bytes()).as_byte();
+  jbyte coder = str_instance->field_value_by_offset(java_lang_String::coder_offset()).as_byte();
   assert(CompactStrings || (coder == java_lang_String::CODER_UTF16), "Strings must be UTF16 encoded");
   return coder;
 }
 
 int PhaseStringOpts::get_constant_length(GraphKit& kit, Node* str) {
@@ -1678,11 +1678,11 @@
 
 ciTypeArray* PhaseStringOpts::get_constant_value(GraphKit& kit, Node* str) {
   assert(str->is_Con(), "String must be constant");
   const TypeOopPtr* str_type = kit.gvn().type(str)->isa_oopptr();
   ciInstance* str_instance = str_type->const_oop()->as_instance();
-  ciObject* src_array = str_instance->field_value_by_offset(java_lang_String::value_offset_in_bytes()).as_object();
+  ciObject* src_array = str_instance->field_value_by_offset(java_lang_String::value_offset()).as_object();
   return src_array->as_type_array();
 }
 
 void PhaseStringOpts::replace_string_concat(StringConcat* sc) {
   // Log a little info about the transformation
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -3264,12 +3264,12 @@
       } else if (_offset == Offset::bottom || _offset == Offset::top) {
         // unsafe access
         _is_ptr_to_narrowoop = UseCompressedOops;
       } else { // exclude unsafe ops
         assert(this->isa_instptr(), "must be an instance ptr.");
-        if (klass() == ciEnv::current()->Class_klass() &&
-            (this->offset() == java_lang_Class::klass_offset_in_bytes() ||
+        if (klass() == ciEnv::current()->Class_klass() &&
+            (this->offset() == java_lang_Class::klass_offset() ||
              this->offset() == java_lang_Class::array_klass_offset_in_bytes())) {
           // Special hidden fields from the Class.
           assert(this->isa_instptr(), "must be an instance ptr.");
           _is_ptr_to_narrowoop = false;
         } else if (klass() == ciEnv::current()->Class_klass() &&
diff a/src/hotspot/share/prims/jvm.cpp b/src/hotspot/share/prims/jvm.cpp
--- a/src/hotspot/share/prims/jvm.cpp
+++ b/src/hotspot/share/prims/jvm.cpp
@@ -73,10 +73,11 @@
 #include "runtime/jfieldIDWorkaround.hpp"
 #include "runtime/jniHandles.inline.hpp"
 #include "runtime/os.inline.hpp"
 #include "runtime/perfData.hpp"
 #include "runtime/reflection.hpp"
+#include "runtime/synchronizer.hpp"
 #include "runtime/thread.inline.hpp"
 #include "runtime/threadSMR.hpp"
 #include "runtime/vframe.inline.hpp"
 #include "runtime/vmOperations.hpp"
 #include "runtime/vm_version.hpp"
@@ -489,10 +490,15 @@
 
 
 JVM_ENTRY_NO_ENV(void, JVM_GC(void))
   JVMWrapper("JVM_GC");
   if (!DisableExplicitGC) {
+    if (AsyncDeflateIdleMonitors) {
+      // AsyncDeflateIdleMonitors needs to know when System.gc() is
+      // called so any special deflation can be done at a safepoint.
+      ObjectSynchronizer::set_is_special_deflation_requested(true);
+    }
     Universe::heap()->collect(GCCause::_java_lang_system_gc);
   }
 JVM_END
 
 
@@ -2116,10 +2122,37 @@
     return (jobjectArray)JNIHandles::make_local(THREAD, result());
   }
 }
 JVM_END
 
+JVM_ENTRY(jobjectArray, JVM_GetPermittedSubclasses(JNIEnv* env, jclass current))
+{
+  JVMWrapper("JVM_GetPermittedSubclasses");
+  assert(!java_lang_Class::is_primitive(JNIHandles::resolve_non_null(current)), "should not be");
+  Klass* c = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(current));
+  assert(c->is_instance_klass(), "must be");
+  InstanceKlass* ik = InstanceKlass::cast(c);
+  {
+    JvmtiVMObjectAllocEventCollector oam;
+    Array<u2>* subclasses = ik->permitted_subclasses();
+    int length = subclasses == NULL ? 0 : subclasses->length();
+    objArrayOop r = oopFactory::new_objArray(SystemDictionary::String_klass(),
+                                             length, CHECK_NULL);
+    objArrayHandle result(THREAD, r);
+    for (int i = 0; i < length; i++) {
+      int cp_index = subclasses->at(i);
+      // This returns <package-name>/<class-name>.
+      Symbol* klass_name = ik->constants()->klass_name_at(cp_index);
+      assert(klass_name != NULL, "Unexpected null klass_name");
+      Handle perm_subtype_h = java_lang_String::create_from_symbol(klass_name, CHECK_NULL);
+      result->obj_at_put(i, perm_subtype_h());
+    }
+    return (jobjectArray)JNIHandles::make_local(THREAD, result());
+  }
+}
+JVM_END
+
 // Constant pool access //////////////////////////////////////////////////////////
 
 JVM_ENTRY(jobject, JVM_GetClassConstantPool(JNIEnv *env, jclass cls))
 {
   JVMWrapper("JVM_GetClassConstantPool");
diff a/src/hotspot/share/prims/jvmtiClassFileReconstituter.cpp b/src/hotspot/share/prims/jvmtiClassFileReconstituter.cpp
--- a/src/hotspot/share/prims/jvmtiClassFileReconstituter.cpp
+++ b/src/hotspot/share/prims/jvmtiClassFileReconstituter.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -422,10 +422,30 @@
     u2 class_cp_index = nest_members->at(i);
     write_u2(class_cp_index);
   }
 }
 
+//  PermittedSubclasses {
+//    u2 attribute_name_index;
+//    u4 attribute_length;
+//    u2 number_of_classes;
+//    u2 classes[number_of_classes];
+//  }
+void JvmtiClassFileReconstituter::write_permitted_subclasses_attribute() {
+  Array<u2>* permitted_subclasses = ik()->permitted_subclasses();
+  int number_of_classes = permitted_subclasses->length();
+  int length = sizeof(u2) * (1 + number_of_classes); // '1 +' is for number_of_classes field
+
+  write_attribute_name_index("PermittedSubclasses");
+  write_u4(length);
+  write_u2(number_of_classes);
+  for (int i = 0; i < number_of_classes; i++) {
+    u2 class_cp_index = permitted_subclasses->at(i);
+    write_u2(class_cp_index);
+  }
+}
+
 //  Record {
 //    u2 attribute_name_index;
 //    u4 attribute_length;
 //    u2 components_count;
 //    component_info components[components_count];
@@ -749,10 +769,13 @@
     ++attr_count;
   }
   if (ik()->nest_members() != Universe::the_empty_short_array()) {
     ++attr_count;
   }
+  if (ik()->permitted_subclasses() != Universe::the_empty_short_array()) {
+    ++attr_count;
+  }
   if (ik()->record_components() != NULL) {
     ++attr_count;
   }
 
   write_u2(attr_count);
@@ -782,10 +805,13 @@
     write_nest_host_attribute();
   }
   if (ik()->nest_members() != Universe::the_empty_short_array()) {
     write_nest_members_attribute();
   }
+  if (ik()->permitted_subclasses() != Universe::the_empty_short_array()) {
+    write_permitted_subclasses_attribute();
+  }
   if (ik()->record_components() != NULL) {
     write_record_attribute();
   }
 }
 
diff a/src/hotspot/share/prims/jvmtiRedefineClasses.cpp b/src/hotspot/share/prims/jvmtiRedefineClasses.cpp
--- a/src/hotspot/share/prims/jvmtiRedefineClasses.cpp
+++ b/src/hotspot/share/prims/jvmtiRedefineClasses.cpp
@@ -851,10 +851,69 @@
 
   return JVMTI_ERROR_NONE;
 }
 
 
+static jvmtiError check_permitted_subclasses_attribute(InstanceKlass* the_class,
+                                                       InstanceKlass* scratch_class) {
+  // Check whether the class PermittedSubclasses attribute has been changed.
+  Thread* thread = Thread::current();
+  ResourceMark rm(thread);
+  Array<u2>* the_permitted_subclasses = the_class->permitted_subclasses();
+  Array<u2>* scr_permitted_subclasses = scratch_class->permitted_subclasses();
+  bool the_subclasses_exist = the_permitted_subclasses != Universe::the_empty_short_array();
+  bool scr_subclasses_exist = scr_permitted_subclasses != Universe::the_empty_short_array();
+  int subclasses_len = the_permitted_subclasses->length();
+  if (the_subclasses_exist && scr_subclasses_exist) {
+    if (subclasses_len != scr_permitted_subclasses->length()) {
+      log_trace(redefine, class, sealed)
+        ("redefined class %s attribute change error: PermittedSubclasses len=%d changed to len=%d",
+         the_class->external_name(), subclasses_len, scr_permitted_subclasses->length());
+      return JVMTI_ERROR_UNSUPPORTED_REDEFINITION_CLASS_ATTRIBUTE_CHANGED;
+    }
+
+    // The order of entries in the PermittedSubclasses array is not specified so
+    // we have to explicitly check for the same contents. We do this by copying
+    // the referenced symbols into their own arrays, sorting them and then
+    // comparing each element pair.
+
+    Symbol** the_syms = NEW_RESOURCE_ARRAY_RETURN_NULL(Symbol*, subclasses_len);
+    Symbol** scr_syms = NEW_RESOURCE_ARRAY_RETURN_NULL(Symbol*, subclasses_len);
+
+    if (the_syms == NULL || scr_syms == NULL) {
+      return JVMTI_ERROR_OUT_OF_MEMORY;
+    }
+
+    for (int i = 0; i < subclasses_len; i++) {
+      int the_cp_index = the_permitted_subclasses->at(i);
+      int scr_cp_index = scr_permitted_subclasses->at(i);
+      the_syms[i] = the_class->constants()->klass_name_at(the_cp_index);
+      scr_syms[i] = scratch_class->constants()->klass_name_at(scr_cp_index);
+    }
+
+    qsort(the_syms, subclasses_len, sizeof(Symbol*), symcmp);
+    qsort(scr_syms, subclasses_len, sizeof(Symbol*), symcmp);
+
+    for (int i = 0; i < subclasses_len; i++) {
+      if (the_syms[i] != scr_syms[i]) {
+        log_trace(redefine, class, sealed)
+          ("redefined class %s attribute change error: PermittedSubclasses[%d]: %s changed to %s",
+           the_class->external_name(), i, the_syms[i]->as_C_string(), scr_syms[i]->as_C_string());
+        return JVMTI_ERROR_UNSUPPORTED_REDEFINITION_CLASS_ATTRIBUTE_CHANGED;
+      }
+    }
+  } else if (the_subclasses_exist ^ scr_subclasses_exist) {
+    const char* action_str = (the_subclasses_exist) ? "removed" : "added";
+    log_trace(redefine, class, sealed)
+      ("redefined class %s attribute change error: PermittedSubclasses attribute %s",
+       the_class->external_name(), action_str);
+    return JVMTI_ERROR_UNSUPPORTED_REDEFINITION_CLASS_ATTRIBUTE_CHANGED;
+  }
+
+  return JVMTI_ERROR_NONE;
+}
+
 static bool can_add_or_delete(Method* m) {
       // Compatibility mode
   return (AllowRedefinitionToAddDeleteMethods &&
           (m->is_private() && (m->is_static() || m->is_final())));
 }
@@ -910,10 +969,16 @@
   err = check_record_attribute(the_class, scratch_class);
   if (err != JVMTI_ERROR_NONE) {
     return err;
   }
 
+  // Check whether the PermittedSubclasses attribute has been changed.
+  err = check_permitted_subclasses_attribute(the_class, scratch_class);
+  if (err != JVMTI_ERROR_NONE) {
+    return err;
+  }
+
   // Check whether class modifiers are the same.
   jushort old_flags = (jushort) the_class->access_flags().get_flags();
   jushort new_flags = (jushort) scratch_class->access_flags().get_flags();
   if (old_flags != new_flags) {
     return JVMTI_ERROR_UNSUPPORTED_REDEFINITION_CLASS_MODIFIERS_CHANGED;
@@ -1789,10 +1854,16 @@
   if (!rewrite_cp_refs_in_record_attribute(scratch_class, THREAD)) {
     // propagate failure back to caller
     return false;
   }
 
+  // rewrite constant pool references in the PermittedSubclasses attribute:
+  if (!rewrite_cp_refs_in_permitted_subclasses_attribute(scratch_class)) {
+    // propagate failure back to caller
+    return false;
+  }
+
   // rewrite constant pool references in the methods:
   if (!rewrite_cp_refs_in_methods(scratch_class, THREAD)) {
     // propagate failure back to caller
     return false;
   }
@@ -1927,10 +1998,23 @@
     }
   }
   return true;
 }
 
+// Rewrite constant pool references in the PermittedSubclasses attribute.
+bool VM_RedefineClasses::rewrite_cp_refs_in_permitted_subclasses_attribute(
+       InstanceKlass* scratch_class) {
+
+  Array<u2>* permitted_subclasses = scratch_class->permitted_subclasses();
+  assert(permitted_subclasses != NULL, "unexpected null permitted_subclasses");
+  for (int i = 0; i < permitted_subclasses->length(); i++) {
+    u2 cp_index = permitted_subclasses->at(i);
+    permitted_subclasses->at_put(i, find_new_index(cp_index));
+  }
+  return true;
+}
+
 // Rewrite constant pool references in the methods.
 bool VM_RedefineClasses::rewrite_cp_refs_in_methods(
        InstanceKlass* scratch_class, TRAPS) {
 
   Array<Method*>* methods = scratch_class->methods();
diff a/src/hotspot/share/prims/methodHandles.cpp b/src/hotspot/share/prims/methodHandles.cpp
--- a/src/hotspot/share/prims/methodHandles.cpp
+++ b/src/hotspot/share/prims/methodHandles.cpp
@@ -1504,12 +1504,10 @@
 }
 JVM_END
 
 /// JVM_RegisterMethodHandleMethods
 
-#undef CS  // Solaris builds complain
-
 #define LANG "Ljava/lang/"
 #define JLINV "Ljava/lang/invoke/"
 
 #define OBJ   LANG "Object;"
 #define CLS   LANG "Class;"
diff a/src/hotspot/share/prims/whitebox.cpp b/src/hotspot/share/prims/whitebox.cpp
--- a/src/hotspot/share/prims/whitebox.cpp
+++ b/src/hotspot/share/prims/whitebox.cpp
@@ -73,10 +73,11 @@
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/javaCalls.hpp"
 #include "runtime/jniHandles.inline.hpp"
 #include "runtime/os.hpp"
 #include "runtime/sweeper.hpp"
+#include "runtime/synchronizer.hpp"
 #include "runtime/thread.hpp"
 #include "runtime/threadSMR.hpp"
 #include "runtime/vm_version.hpp"
 #include "services/memoryService.hpp"
 #include "utilities/align.hpp"
@@ -477,10 +478,16 @@
   THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), "WB_G1InConcurrentMark: G1 GC is not enabled");
 WB_END
 
 WB_ENTRY(jboolean, WB_G1StartMarkCycle(JNIEnv* env, jobject o))
   if (UseG1GC) {
+    if (AsyncDeflateIdleMonitors) {
+      // AsyncDeflateIdleMonitors needs to know when System.gc() or
+      // the equivalent is called so any special clean up can be done
+      // at a safepoint, e.g., TestHumongousClassLoader.java.
+      ObjectSynchronizer::set_is_special_deflation_requested(true);
+    }
     G1CollectedHeap* g1h = G1CollectedHeap::heap();
     if (!g1h->concurrent_mark()->cm_thread()->during_cycle()) {
       g1h->collect(GCCause::_wb_conc_mark);
       return true;
     }
@@ -1448,10 +1455,16 @@
   jchar* name = java_lang_String::as_unicode_string(JNIHandles::resolve(javaString), len, CHECK_false);
   return (StringTable::lookup(name, len) != NULL);
 WB_END
 
 WB_ENTRY(void, WB_FullGC(JNIEnv* env, jobject o))
+  if (AsyncDeflateIdleMonitors) {
+    // AsyncDeflateIdleMonitors needs to know when System.gc() or
+    // the equivalent is called so any special clean up can be done
+    // at a safepoint, e.g., TestHumongousClassLoader.java.
+    ObjectSynchronizer::set_is_special_deflation_requested(true);
+  }
   Universe::heap()->soft_ref_policy()->set_should_clear_all_soft_refs(true);
   Universe::heap()->collect(GCCause::_wb_full_gc);
 #if INCLUDE_G1GC
   if (UseG1GC) {
     // Needs to be cleared explicitly for G1
@@ -1797,10 +1810,17 @@
   oop obj_oop = JNIHandles::resolve(obj);
   return (jboolean) obj_oop->mark().has_monitor();
 WB_END
 
 WB_ENTRY(void, WB_ForceSafepoint(JNIEnv* env, jobject wb))
+  if (AsyncDeflateIdleMonitors) {
+    // AsyncDeflateIdleMonitors needs to know when System.gc() or
+    // the equivalent is called so any special clean up can be done
+    // at a safepoint, e.g., TestRTMTotalCountIncrRate.java or
+    // TestUseRTMForStackLocks.java.
+    ObjectSynchronizer::set_is_special_deflation_requested(true);
+  }
   VM_ForceSafepoint force_safepoint_op;
   VMThread::execute(&force_safepoint_op);
 WB_END
 
 WB_ENTRY(jlong, WB_GetConstantPool(JNIEnv* env, jobject wb, jclass klass))
diff a/src/hotspot/share/runtime/arguments.cpp b/src/hotspot/share/runtime/arguments.cpp
--- a/src/hotspot/share/runtime/arguments.cpp
+++ b/src/hotspot/share/runtime/arguments.cpp
@@ -83,11 +83,11 @@
 bool   Arguments::_UseOnStackReplacement        = UseOnStackReplacement;
 bool   Arguments::_BackgroundCompilation        = BackgroundCompilation;
 bool   Arguments::_ClipInlining                 = ClipInlining;
 intx   Arguments::_Tier3InvokeNotifyFreqLog     = Tier3InvokeNotifyFreqLog;
 intx   Arguments::_Tier4InvocationThreshold     = Tier4InvocationThreshold;
-size_t Arguments::_SharedBaseAddress            = SharedBaseAddress;
+size_t Arguments::_default_SharedBaseAddress    = SharedBaseAddress;
 
 bool   Arguments::_enable_preview               = false;
 
 char*  Arguments::SharedArchivePath             = NULL;
 char*  Arguments::SharedDynamicArchivePath      = NULL;
@@ -562,10 +562,12 @@
   { "MonitorBound",                  JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },
 #ifdef AARCH64
   { "UseBarriersForVolatile",        JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
 #endif
   { "UseLWPSynchronization",         JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "BranchOnRegister",              JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+  { "LIRFillDelaySlots",             JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
 
 #ifdef TEST_VERIFY_SPECIAL_JVM_FLAGS
   // These entries will generate build errors.  Their purpose is to test the macros.
   { "dep > obs",                    JDK_Version::jdk(9), JDK_Version::jdk(8), JDK_Version::undefined() },
   { "dep > exp ",                   JDK_Version::jdk(9), JDK_Version::undefined(), JDK_Version::jdk(8) },
@@ -2287,12 +2289,12 @@
   if (TieredCompilation) {
     Arguments::_Tier3InvokeNotifyFreqLog = Tier3InvokeNotifyFreqLog;
     Arguments::_Tier4InvocationThreshold = Tier4InvocationThreshold;
   }
 
-  // CDS dumping always write the archive to the default value of SharedBaseAddress.
-  Arguments::_SharedBaseAddress = SharedBaseAddress;
+  // Remember the default value of SharedBaseAddress.
+  Arguments::_default_SharedBaseAddress = SharedBaseAddress;
 
   // Setup flags for mixed which is the default
   set_mode_flags(_mixed);
 
   // Parse args structure generated from java.base vm options resource
@@ -3048,10 +3050,14 @@
         jio_fprintf(defaultStream::error_stream(),
                   "-XX:-EnableJVMCIProduct cannot come after -XX:+EnableJVMCIProduct\n");
         return JNI_EINVAL;
       }
     } else if (match_option(option, "-XX:+EnableJVMCIProduct")) {
+      // Just continue, since "-XX:+EnableJVMCIProduct" has been specified before
+      if (EnableJVMCIProduct) {
+        continue;
+      }
       JVMFlag *jvmciFlag = JVMFlag::find_flag("EnableJVMCIProduct");
       // Allow this flag if it has been unlocked.
       if (jvmciFlag != NULL && jvmciFlag->is_unlocked()) {
         if (!JVMCIGlobals::enable_jvmci_product_mode(origin)) {
           jio_fprintf(defaultStream::error_stream(),
diff a/src/hotspot/share/runtime/globals.hpp b/src/hotspot/share/runtime/globals.hpp
--- a/src/hotspot/share/runtime/globals.hpp
+++ b/src/hotspot/share/runtime/globals.hpp
@@ -681,15 +681,25 @@
                                                                             \
   experimental(bool, DisablePrimordialThreadGuardPages, false,              \
                "Disable the use of stack guard pages if the JVM is loaded " \
                "on the primordial process thread")                          \
                                                                             \
+  diagnostic(bool, AsyncDeflateIdleMonitors, true,                          \
+          "Deflate idle monitors using the ServiceThread.")                 \
+                                                                            \
+  /* notice: the max range value here is max_jint, not max_intx  */         \
+  /* because of overflow issue                                   */         \
+  diagnostic(intx, AsyncDeflationInterval, 250,                             \
+          "Async deflate idle monitors every so many milliseconds when "    \
+          "MonitorUsedDeflationThreshold is exceeded (0 is off).")          \
+          range(0, max_jint)                                                \
+                                                                            \
   experimental(intx, MonitorUsedDeflationThreshold, 90,                     \
-                "Percentage of used monitors before triggering cleanup "    \
-                "safepoint which deflates monitors (0 is off). "            \
-                "The check is performed on GuaranteedSafepointInterval.")   \
-                range(0, 100)                                               \
+          "Percentage of used monitors before triggering deflation (0 is "  \
+          "off). The check is performed on GuaranteedSafepointInterval "    \
+          "or AsyncDeflationInterval.")                                     \
+          range(0, 100)                                                     \
                                                                             \
   experimental(intx, hashCode, 5,                                           \
                "(Unstable) select hashCode generation algorithm")           \
                                                                             \
   product(bool, FilterSpuriousWakeups, true,                                \
@@ -1698,10 +1708,15 @@
           "Exit the VM if we fill the code cache")                          \
                                                                             \
   product(bool, UseCodeCacheFlushing, true,                                 \
           "Remove cold/old nmethods from the code cache")                   \
                                                                             \
+  product(double, SweeperThreshold, 0.5,                                    \
+          "Threshold controlling when code cache sweeper is invoked."       \
+          "Value is percentage of ReservedCodeCacheSize.")                  \
+          range(0.0, 100.0)                                                 \
+                                                                            \
   product(uintx, StartAggressiveSweepingAt, 10,                             \
           "Start aggressive sweeping if X[%] of the code cache is free."    \
           "Segmented code cache: X[%] of the non-profiled heap."            \
           "Non-segmented code cache: X[%] of the total code cache")         \
           range(0, 100)                                                     \
diff a/src/hotspot/share/runtime/init.cpp b/src/hotspot/share/runtime/init.cpp
--- a/src/hotspot/share/runtime/init.cpp
+++ b/src/hotspot/share/runtime/init.cpp
@@ -170,12 +170,16 @@
   if (!destructorsCalled) {
     destructorsCalled = true;
     if (log_is_enabled(Info, monitorinflation)) {
       // The ObjectMonitor subsystem uses perf counters so
       // do this before perfMemory_exit().
-      // ObjectSynchronizer::finish_deflate_idle_monitors()'s call
-      // to audit_and_print_stats() is done at the Debug level.
+      // These other two audit_and_print_stats() calls are done at the
+      // Debug level at a safepoint:
+      // - for safepoint based deflation auditing:
+      //   ObjectSynchronizer::finish_deflate_idle_monitors()
+      // - for async deflation auditing:
+      //   ObjectSynchronizer::do_safepoint_work()
       ObjectSynchronizer::audit_and_print_stats(true /* on_exit */);
     }
     perfMemory_exit();
     SafepointTracing::statistics_exit_log();
     if (PrintStringTableStatistics) {
diff a/src/hotspot/share/runtime/safepoint.cpp b/src/hotspot/share/runtime/safepoint.cpp
--- a/src/hotspot/share/runtime/safepoint.cpp
+++ b/src/hotspot/share/runtime/safepoint.cpp
@@ -489,12 +489,13 @@
 
   post_safepoint_end_event(event, safepoint_id());
 }
 
 bool SafepointSynchronize::is_cleanup_needed() {
-  // Need a safepoint if there are many monitors to deflate.
-  if (ObjectSynchronizer::is_cleanup_needed()) return true;
+  // Need a cleanup safepoint if there are too many monitors in use
+  // and the monitor deflation needs to be done at a safepoint.
+  if (ObjectSynchronizer::is_safepoint_deflation_needed()) return true;
   // Need a safepoint if some inline cache buffers is non-empty
   if (!InlineCacheBuffer::is_empty()) return true;
   if (StringTable::needs_rehashing()) return true;
   if (SymbolTable::needs_rehashing()) return true;
   return false;
@@ -509,10 +510,14 @@
   ParallelSPCleanupThreadClosure(DeflateMonitorCounters* counters) :
     _nmethod_cl(UseCodeAging ? NMethodSweeper::prepare_reset_hotness_counters() : NULL),
     _counters(counters) {}
 
   void do_thread(Thread* thread) {
+    // deflate_thread_local_monitors() handles or requests deflation of
+    // this thread's idle monitors. If !AsyncDeflateIdleMonitors or if
+    // there is a special cleanup request, deflation is handled now.
+    // Otherwise, async deflation is requested via a flag.
     ObjectSynchronizer::deflate_thread_local_monitors(thread, _counters);
     if (_nmethod_cl != NULL && thread->is_Java_thread() &&
         ! thread->is_Code_cache_sweeper_thread()) {
       JavaThread* jt = (JavaThread*) thread;
       jt->nmethods_do(_nmethod_cl);
@@ -541,11 +546,15 @@
 
     if (_subtasks.try_claim_task(SafepointSynchronize::SAFEPOINT_CLEANUP_DEFLATE_MONITORS)) {
       const char* name = "deflating global idle monitors";
       EventSafepointCleanupTask event;
       TraceTime timer(name, TRACETIME_LOG(Info, safepoint, cleanup));
-      ObjectSynchronizer::deflate_idle_monitors(_counters);
+      // AsyncDeflateIdleMonitors only uses DeflateMonitorCounters
+      // when a special cleanup has been requested.
+      // Note: This logging output will include global idle monitor
+      // elapsed times, but not global idle monitor deflation count.
+      ObjectSynchronizer::do_safepoint_work(_counters);
 
       post_safepoint_cleanup_task_event(event, safepoint_id, name);
     }
 
     if (_subtasks.try_claim_task(SafepointSynchronize::SAFEPOINT_CLEANUP_UPDATE_INLINE_CACHES)) {
diff a/src/hotspot/share/runtime/sharedRuntime.cpp b/src/hotspot/share/runtime/sharedRuntime.cpp
--- a/src/hotspot/share/runtime/sharedRuntime.cpp
+++ b/src/hotspot/share/runtime/sharedRuntime.cpp
@@ -68,10 +68,11 @@
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/java.hpp"
 #include "runtime/javaCalls.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
+#include "runtime/synchronizer.hpp"
 #include "runtime/vframe.inline.hpp"
 #include "runtime/vframeArray.hpp"
 #include "utilities/copy.hpp"
 #include "utilities/dtrace.hpp"
 #include "utilities/events.hpp"
@@ -3420,14 +3421,19 @@
   for (BasicObjectLock *kptr2 = fr.interpreter_frame_monitor_end();
        kptr2 < fr.interpreter_frame_monitor_begin();
        kptr2 = fr.next_monitor_in_interpreter_frame(kptr2) ) {
     if (kptr2->obj() != NULL) {         // Avoid 'holes' in the monitor array
       BasicLock *lock = kptr2->lock();
-      // Inflate so the displaced header becomes position-independent
-      if (lock->displaced_header().is_unlocked())
+      // Inflate so the object's header no longer refers to the BasicLock.
+      if (lock->displaced_header().is_unlocked()) {
+        // The object is locked and the resulting ObjectMonitor* will also be
+        // locked so it can't be async deflated until ownership is dropped.
+        // See the big comment in basicLock.cpp: BasicLock::move_to().
         ObjectSynchronizer::inflate_helper(kptr2->obj());
-      // Now the displaced header is free to move
+      }
+      // Now the displaced header is free to move because the
+      // object's header no longer refers to it.
       buf[i++] = (intptr_t)lock->displaced_header().value();
       buf[i++] = cast_from_oop<intptr_t>(kptr2->obj());
     }
   }
   assert(i - max_locals == active_monitor_count*2, "found the expected number of monitors");
diff a/src/hotspot/share/runtime/synchronizer.cpp b/src/hotspot/share/runtime/synchronizer.cpp
--- a/src/hotspot/share/runtime/synchronizer.cpp
+++ b/src/hotspot/share/runtime/synchronizer.cpp
@@ -35,15 +35,17 @@
 #include "oops/markWord.hpp"
 #include "oops/oop.inline.hpp"
 #include "runtime/atomic.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/handles.inline.hpp"
+#include "runtime/handshake.hpp"
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/mutexLocker.hpp"
 #include "runtime/objectMonitor.hpp"
 #include "runtime/objectMonitor.inline.hpp"
 #include "runtime/osThread.hpp"
+#include "runtime/safepointMechanism.inline.hpp"
 #include "runtime/safepointVerifiers.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
 #include "runtime/synchronizer.hpp"
 #include "runtime/thread.inline.hpp"
@@ -116,10 +118,13 @@
 #define NINFLATIONLOCKS 256
 static volatile intptr_t gInflationLocks[NINFLATIONLOCKS];
 
 // global list of blocks of monitors
 PaddedObjectMonitor* ObjectSynchronizer::g_block_list = NULL;
+bool volatile ObjectSynchronizer::_is_async_deflation_requested = false;
+bool volatile ObjectSynchronizer::_is_special_deflation_requested = false;
+jlong ObjectSynchronizer::_last_async_deflation_time_ns = 0;
 
 struct ObjectMonitorListGlobals {
   char         _pad_prefix[OM_CACHE_LINE_SIZE];
   // These are highly shared list related variables.
   // To avoid false-sharing they need to be the sole occupants of a cache line.
@@ -132,18 +137,28 @@
   // Global ObjectMonitor in-use list. When a JavaThread is exiting,
   // ObjectMonitors on its per-thread in-use list are prepended here.
   ObjectMonitor* _in_use_list;
   DEFINE_PAD_MINUS_SIZE(2, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));
 
+  // Global ObjectMonitor wait list. Deflated ObjectMonitors wait on
+  // this list until after a handshake or a safepoint for platforms
+  // that don't support handshakes. After the handshake or safepoint,
+  // the deflated ObjectMonitors are prepended to free_list.
+  ObjectMonitor* _wait_list;
+  DEFINE_PAD_MINUS_SIZE(3, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));
+
   int _free_count;    // # on free_list
-  DEFINE_PAD_MINUS_SIZE(3, OM_CACHE_LINE_SIZE, sizeof(int));
+  DEFINE_PAD_MINUS_SIZE(4, OM_CACHE_LINE_SIZE, sizeof(int));
 
   int _in_use_count;  // # on in_use_list
-  DEFINE_PAD_MINUS_SIZE(4, OM_CACHE_LINE_SIZE, sizeof(int));
+  DEFINE_PAD_MINUS_SIZE(5, OM_CACHE_LINE_SIZE, sizeof(int));
 
   int _population;    // # Extant -- in circulation
-  DEFINE_PAD_MINUS_SIZE(5, OM_CACHE_LINE_SIZE, sizeof(int));
+  DEFINE_PAD_MINUS_SIZE(6, OM_CACHE_LINE_SIZE, sizeof(int));
+
+  int _wait_count;    // # on wait_list
+  DEFINE_PAD_MINUS_SIZE(7, OM_CACHE_LINE_SIZE, sizeof(int));
 };
 static ObjectMonitorListGlobals om_list_globals;
 
 #define CHECK_THROW_NOSYNC_IMSE(obj)  \
   if ((obj)->mark().is_always_locked()) {  \
@@ -310,10 +325,19 @@
                                              ObjectMonitor* tail, int count) {
   prepend_list_to_common(list, tail, count, &om_list_globals._free_list,
                          &om_list_globals._free_count);
 }
 
+// Prepend a list of ObjectMonitors to om_list_globals._wait_list.
+// 'tail' is the last ObjectMonitor in the list and there are 'count'
+// on the list. Also updates om_list_globals._wait_count.
+static void prepend_list_to_global_wait_list(ObjectMonitor* list,
+                                             ObjectMonitor* tail, int count) {
+  prepend_list_to_common(list, tail, count, &om_list_globals._wait_list,
+                         &om_list_globals._wait_count);
+}
+
 // Prepend a list of ObjectMonitors to om_list_globals._in_use_list.
 // 'tail' is the last ObjectMonitor in the list and there are 'count'
 // on the list. Also updates om_list_globals._in_use_list.
 static void prepend_list_to_global_in_use_list(ObjectMonitor* list,
                                                ObjectMonitor* tail, int count) {
@@ -327,11 +351,11 @@
                               int* count_p) {
   while (true) {
     om_lock(m);  // Lock m so we can safely update its next field.
     ObjectMonitor* cur = NULL;
     // Lock the list head to guard against races with a list walker
-    // thread:
+    // or async deflater thread (which only races in om_in_use_list):
     if ((cur = get_list_head_locked(list_p)) != NULL) {
       // List head is now locked so we can safely switch it.
       m->set_next_om(cur);  // m now points to cur (and unlocks m)
       Atomic::store(list_p, m);  // Switch list head to unlocked m.
       om_unlock(cur);
@@ -365,11 +389,11 @@
 // decrements the specified counter. Returns NULL if none are available.
 static ObjectMonitor* take_from_start_of_common(ObjectMonitor** list_p,
                                                 int* count_p) {
   ObjectMonitor* take = NULL;
   // Lock the list head to guard against races with a list walker
-  // thread:
+  // or async deflater thread (which only races in om_list_globals._free_list):
   if ((take = get_list_head_locked(list_p)) == NULL) {
     return NULL;  // None are available.
   }
   ObjectMonitor* next = unmarked_next(take);
   // Switch locked list head to next (which unlocks the list head, but
@@ -480,11 +504,20 @@
   assert(!EnableValhalla || !obj->klass()->is_value(), "monitor op on value type");
   const markWord mark = obj->mark();
 
   if (mark.has_monitor()) {
     ObjectMonitor* const m = mark.monitor();
-    assert(m->object() == obj, "invariant");
+    if (AsyncDeflateIdleMonitors) {
+      // An async deflation can race us before we manage to make the
+      // ObjectMonitor busy by setting the owner below. If we detect
+      // that race we just bail out to the slow-path here.
+      if (m->object() == NULL) {
+        return false;
+      }
+    } else {
+      assert(m->object() == obj, "invariant");
+    }
     Thread* const owner = (Thread *) m->_owner;
 
     // Lock contention and Transactional Lock Elision (TLE) diagnostics
     // and observability
     // Case: light contention possibly amenable to TLE
@@ -561,11 +594,19 @@
   // The object header will never be displaced to this lock,
   // so it does not matter what the value is, except that it
   // must be non-zero to avoid looking like a re-entrant lock,
   // and must not look locked either.
   lock->set_displaced_header(markWord::unused_mark());
-  inflate(THREAD, obj(), inflate_cause_monitor_enter)->enter(THREAD);
+  // An async deflation can race after the inflate() call and before
+  // enter() can make the ObjectMonitor busy. enter() returns false if
+  // we have lost the race to async deflation and we simply try again.
+  while (true) {
+    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_monitor_enter);
+    if (monitor->enter(THREAD)) {
+      return;
+    }
+  }
 }
 
 void ObjectSynchronizer::exit(oop object, BasicLock* lock, TRAPS) {
   markWord mark = object->mark();
   if (EnableValhalla && mark.is_always_locked()) {
@@ -614,11 +655,14 @@
       return;
     }
   }
 
   // We have to take the slow-path of possible inflation and then exit.
-  inflate(THREAD, object, inflate_cause_vm_internal)->exit(true, THREAD);
+  // The ObjectMonitor* can't be async deflated until ownership is
+  // dropped inside exit() and the ObjectMonitor* must be !is_busy().
+  ObjectMonitor* monitor = inflate(THREAD, object, inflate_cause_vm_internal);
+  monitor->exit(true, THREAD);
 }
 
 // -----------------------------------------------------------------------------
 // Class Loader  support to workaround deadlocks on the class loader lock objects
 // Also used by GC
@@ -636,27 +680,37 @@
   if (UseBiasedLocking) {
     BiasedLocking::revoke(obj, THREAD);
     assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
   }
 
+  // The ObjectMonitor* can't be async deflated until ownership is
+  // dropped inside exit() and the ObjectMonitor* must be !is_busy().
   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
-
-  return monitor->complete_exit(THREAD);
+  intptr_t ret_code = monitor->complete_exit(THREAD);
+  return ret_code;
 }
 
 // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
 void ObjectSynchronizer::reenter(Handle obj, intx recursions, TRAPS) {
   assert(!EnableValhalla || !obj->klass()->is_value(), "monitor op on value type");
   if (UseBiasedLocking) {
     BiasedLocking::revoke(obj, THREAD);
     assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
   }
 
-  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
-
-  monitor->reenter(recursions, THREAD);
+  // An async deflation can race after the inflate() call and before
+  // reenter() -> enter() can make the ObjectMonitor busy. reenter() ->
+  // enter() returns false if we have lost the race to async deflation
+  // and we simply try again.
+  while (true) {
+    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
+    if (monitor->reenter(recursions, THREAD)) {
+      return;
+    }
+  }
 }
+
 // -----------------------------------------------------------------------------
 // JNI locks on java objects
 // NOTE: must use heavy weight monitor to handle jni monitor enter
 void ObjectSynchronizer::jni_enter(Handle obj, TRAPS) {
   // the current locking is from JNI instead of Java code
@@ -664,11 +718,19 @@
   if (UseBiasedLocking) {
     BiasedLocking::revoke(obj, THREAD);
     assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
   }
   THREAD->set_current_pending_monitor_is_from_java(false);
-  inflate(THREAD, obj(), inflate_cause_jni_enter)->enter(THREAD);
+  // An async deflation can race after the inflate() call and before
+  // enter() can make the ObjectMonitor busy. enter() returns false if
+  // we have lost the race to async deflation and we simply try again.
+  while (true) {
+    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_jni_enter);
+    if (monitor->enter(THREAD)) {
+      break;
+    }
+  }
   THREAD->set_current_pending_monitor_is_from_java(true);
 }
 
 // NOTE: must use heavy weight monitor to handle jni monitor exit
 void ObjectSynchronizer::jni_exit(oop obj, Thread* THREAD) {
@@ -678,10 +740,12 @@
     BiasedLocking::revoke(h_obj, THREAD);
     obj = h_obj();
   }
   assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
 
+  // The ObjectMonitor* can't be async deflated until ownership is
+  // dropped inside exit() and the ObjectMonitor* must be !is_busy().
   ObjectMonitor* monitor = inflate(THREAD, obj, inflate_cause_jni_exit);
   // If this thread has locked the object, exit the monitor. We
   // intentionally do not use CHECK here because we must exit the
   // monitor even if an exception is pending.
   if (monitor->check_owner(THREAD)) {
@@ -720,20 +784,24 @@
     assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
   }
   if (millis < 0) {
     THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), "timeout value is negative");
   }
+  // The ObjectMonitor* can't be async deflated because the _waiters
+  // field is incremented before ownership is dropped and decremented
+  // after ownership is regained.
   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);
 
   DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis);
   monitor->wait(millis, true, THREAD);
 
   // This dummy call is in place to get around dtrace bug 6254741.  Once
   // that's fixed we can uncomment the following line, remove the call
   // and change this function back into a "void" func.
   // DTRACE_MONITOR_PROBE(waited, monitor, obj(), THREAD);
-  return dtrace_waited_probe(monitor, obj, THREAD);
+  int ret_code = dtrace_waited_probe(monitor, obj, THREAD);
+  return ret_code;
 }
 
 void ObjectSynchronizer::wait_uninterruptibly(Handle obj, jlong millis, TRAPS) {
   CHECK_THROW_NOSYNC_IMSE(obj);
   if (UseBiasedLocking) {
@@ -741,11 +809,15 @@
     assert(!obj->mark().has_bias_pattern(), "biases should be revoked by now");
   }
   if (millis < 0) {
     THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), "timeout value is negative");
   }
-  inflate(THREAD, obj(), inflate_cause_wait)->wait(millis, false, THREAD);
+  // The ObjectMonitor* can't be async deflated because the _waiters
+  // field is incremented before ownership is dropped and decremented
+  // after ownership is regained.
+  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);
+  monitor->wait(millis, false, THREAD);
 }
 
 void ObjectSynchronizer::notify(Handle obj, TRAPS) {
   CHECK_THROW_NOSYNC_IMSE(obj);
   if (UseBiasedLocking) {
@@ -755,11 +827,14 @@
 
   markWord mark = obj->mark();
   if (mark.has_locker() && THREAD->is_lock_owned((address)mark.locker())) {
     return;
   }
-  inflate(THREAD, obj(), inflate_cause_notify)->notify(THREAD);
+  // The ObjectMonitor* can't be async deflated until ownership is
+  // dropped by the calling thread.
+  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);
+  monitor->notify(THREAD);
 }
 
 // NOTE: see comment of notify()
 void ObjectSynchronizer::notifyall(Handle obj, TRAPS) {
   CHECK_THROW_NOSYNC_IMSE(obj);
@@ -770,11 +845,14 @@
 
   markWord mark = obj->mark();
   if (mark.has_locker() && THREAD->is_lock_owned((address)mark.locker())) {
     return;
   }
-  inflate(THREAD, obj(), inflate_cause_notify)->notifyAll(THREAD);
+  // The ObjectMonitor* can't be async deflated until ownership is
+  // dropped by the calling thread.
+  ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);
+  monitor->notifyAll(THREAD);
 }
 
 // -----------------------------------------------------------------------------
 // Hash Code handling
 //
@@ -970,88 +1048,120 @@
   assert(Universe::verify_in_progress() || DumpSharedSpaces ||
          self->is_Java_thread() , "invariant");
   assert(Universe::verify_in_progress() || DumpSharedSpaces ||
          ((JavaThread *)self)->thread_state() != _thread_blocked, "invariant");
 
-  ObjectMonitor* monitor = NULL;
-  markWord temp, test;
-  intptr_t hash;
-  markWord mark = read_stable_mark(obj);
+  while (true) {
+    ObjectMonitor* monitor = NULL;
+    markWord temp, test;
+    intptr_t hash;
+    markWord mark = read_stable_mark(obj);
+
+    // object should remain ineligible for biased locking
+    assert(!mark.has_bias_pattern(), "invariant");
+
+    if (mark.is_neutral()) {            // if this is a normal header
+      hash = mark.hash();
+      if (hash != 0) {                  // if it has a hash, just return it
+        return hash;
+      }
+      hash = get_next_hash(self, obj);  // get a new hash
+      temp = mark.copy_set_hash(hash);  // merge the hash into header
+                                        // try to install the hash
+      test = obj->cas_set_mark(temp, mark);
+      if (test == mark) {               // if the hash was installed, return it
+        return hash;
+      }
+      // Failed to install the hash. It could be that another thread
+      // installed the hash just before our attempt or inflation has
+      // occurred or... so we fall thru to inflate the monitor for
+      // stability and then install the hash.
+    } else if (mark.has_monitor()) {
+      monitor = mark.monitor();
+      temp = monitor->header();
+      assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
+      hash = temp.hash();
+      if (hash != 0) {
+        // It has a hash.
+
+        // Separate load of dmw/header above from the loads in
+        // is_being_async_deflated().
+        if (support_IRIW_for_not_multiple_copy_atomic_cpu) {
+          // A non-multiple copy atomic (nMCA) machine needs a bigger
+          // hammer to separate the load above and the loads below.
+          OrderAccess::fence();
+        } else {
+          OrderAccess::loadload();
+        }
+        if (monitor->is_being_async_deflated()) {
+          // But we can't safely use the hash if we detect that async
+          // deflation has occurred. So we attempt to restore the
+          // header/dmw to the object's header so that we only retry
+          // once if the deflater thread happens to be slow.
+          monitor->install_displaced_markword_in_object(obj);
+          continue;
+        }
+        return hash;
+      }
+      // Fall thru so we only have one place that installs the hash in
+      // the ObjectMonitor.
+    } else if (self->is_lock_owned((address)mark.locker())) {
+      // This is a stack lock owned by the calling thread so fetch the
+      // displaced markWord from the BasicLock on the stack.
+      temp = mark.displaced_mark_helper();
+      assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
+      hash = temp.hash();
+      if (hash != 0) {                  // if it has a hash, just return it
+        return hash;
+      }
+      // WARNING:
+      // The displaced header in the BasicLock on a thread's stack
+      // is strictly immutable. It CANNOT be changed in ANY cases.
+      // So we have to inflate the stack lock into an ObjectMonitor
+      // even if the current thread owns the lock. The BasicLock on
+      // a thread's stack can be asynchronously read by other threads
+      // during an inflate() call so any change to that stack memory
+      // may not propagate to other threads correctly.
+    }
 
-  // object should remain ineligible for biased locking
-  assert(!mark.has_bias_pattern(), "invariant");
+    // Inflate the monitor to set the hash.
 
-  if (mark.is_neutral()) {            // if this is a normal header
+    // An async deflation can race after the inflate() call and before we
+    // can update the ObjectMonitor's header with the hash value below.
+    monitor = inflate(self, obj, inflate_cause_hash_code);
+    // Load ObjectMonitor's header/dmw field and see if it has a hash.
+    mark = monitor->header();
+    assert(mark.is_neutral(), "invariant: header=" INTPTR_FORMAT, mark.value());
     hash = mark.hash();
-    if (hash != 0) {                  // if it has a hash, just return it
-      return hash;
-    }
-    hash = get_next_hash(self, obj);  // get a new hash
-    temp = mark.copy_set_hash(hash);  // merge the hash into header
-                                      // try to install the hash
-    test = obj->cas_set_mark(temp, mark);
-    if (test == mark) {               // if the hash was installed, return it
-      return hash;
-    }
-    // Failed to install the hash. It could be that another thread
-    // installed the hash just before our attempt or inflation has
-    // occurred or... so we fall thru to inflate the monitor for
-    // stability and then install the hash.
-  } else if (mark.has_monitor()) {
-    monitor = mark.monitor();
-    temp = monitor->header();
-    assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
-    hash = temp.hash();
-    if (hash != 0) {                  // if it has a hash, just return it
-      return hash;
-    }
-    // Fall thru so we only have one place that installs the hash in
-    // the ObjectMonitor.
-  } else if (self->is_lock_owned((address)mark.locker())) {
-    // This is a stack lock owned by the calling thread so fetch the
-    // displaced markWord from the BasicLock on the stack.
-    temp = mark.displaced_mark_helper();
-    assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
-    hash = temp.hash();
-    if (hash != 0) {                  // if it has a hash, just return it
-      return hash;
-    }
-    // WARNING:
-    // The displaced header in the BasicLock on a thread's stack
-    // is strictly immutable. It CANNOT be changed in ANY cases.
-    // So we have to inflate the stack lock into an ObjectMonitor
-    // even if the current thread owns the lock. The BasicLock on
-    // a thread's stack can be asynchronously read by other threads
-    // during an inflate() call so any change to that stack memory
-    // may not propagate to other threads correctly.
-  }
-
-  // Inflate the monitor to set the hash.
-  monitor = inflate(self, obj, inflate_cause_hash_code);
-  // Load ObjectMonitor's header/dmw field and see if it has a hash.
-  mark = monitor->header();
-  assert(mark.is_neutral(), "invariant: header=" INTPTR_FORMAT, mark.value());
-  hash = mark.hash();
-  if (hash == 0) {                    // if it does not have a hash
-    hash = get_next_hash(self, obj);  // get a new hash
-    temp = mark.copy_set_hash(hash);  // merge the hash into header
-    assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
-    uintptr_t v = Atomic::cmpxchg((volatile uintptr_t*)monitor->header_addr(), mark.value(), temp.value());
-    test = markWord(v);
-    if (test != mark) {
-      // The attempt to update the ObjectMonitor's header/dmw field
-      // did not work. This can happen if another thread managed to
-      // merge in the hash just before our cmpxchg().
-      // If we add any new usages of the header/dmw field, this code
-      // will need to be updated.
-      hash = test.hash();
-      assert(test.is_neutral(), "invariant: header=" INTPTR_FORMAT, test.value());
-      assert(hash != 0, "should only have lost the race to a thread that set a non-zero hash");
-    }
-  }
-  // We finally get the hash.
-  return hash;
+    if (hash == 0) {                    // if it does not have a hash
+      hash = get_next_hash(self, obj);  // get a new hash
+      temp = mark.copy_set_hash(hash);  // merge the hash into header
+      assert(temp.is_neutral(), "invariant: header=" INTPTR_FORMAT, temp.value());
+      uintptr_t v = Atomic::cmpxchg((volatile uintptr_t*)monitor->header_addr(), mark.value(), temp.value());
+      test = markWord(v);
+      if (test != mark) {
+        // The attempt to update the ObjectMonitor's header/dmw field
+        // did not work. This can happen if another thread managed to
+        // merge in the hash just before our cmpxchg().
+        // If we add any new usages of the header/dmw field, this code
+        // will need to be updated.
+        hash = test.hash();
+        assert(test.is_neutral(), "invariant: header=" INTPTR_FORMAT, test.value());
+        assert(hash != 0, "should only have lost the race to a thread that set a non-zero hash");
+      }
+      if (monitor->is_being_async_deflated()) {
+        // If we detect that async deflation has occurred, then we
+        // attempt to restore the header/dmw to the object's header
+        // so that we only retry once if the deflater thread happens
+        // to be slow.
+        monitor->install_displaced_markword_in_object(obj);
+        continue;
+      }
+    }
+    // We finally get the hash.
+    return hash;
+  }
 }
 
 
 bool ObjectSynchronizer::current_thread_holds_lock(JavaThread* thread,
                                                    Handle h_obj) {
@@ -1072,10 +1182,12 @@
   if (mark.has_locker()) {
     return thread->is_lock_owned((address)mark.locker());
   }
   // Contended case, header points to ObjectMonitor (tagged pointer)
   if (mark.has_monitor()) {
+    // The first stage of async deflation does not affect any field
+    // used by this comparison so the ObjectMonitor* is usable here.
     ObjectMonitor* monitor = mark.monitor();
     return monitor->is_entered(thread) != 0;
   }
   // Unlocked case, header in place
   assert(mark.is_neutral(), "sanity check");
@@ -1113,13 +1225,16 @@
       owner_self : owner_other;
   }
 
   // CASE: inflated. Mark (tagged pointer) points to an ObjectMonitor.
   // The Object:ObjectMonitor relationship is stable as long as we're
-  // not at a safepoint.
+  // not at a safepoint and AsyncDeflateIdleMonitors is false.
   if (mark.has_monitor()) {
-    void* owner = mark.monitor()->_owner;
+    // The first stage of async deflation does not affect any field
+    // used by this comparison so the ObjectMonitor* is usable here.
+    ObjectMonitor* monitor = mark.monitor();
+    void* owner = monitor->owner();
     if (owner == NULL) return owner_none;
     return (owner == self ||
             self->is_lock_owned((address)owner)) ? owner_self : owner_other;
   }
 
@@ -1149,10 +1264,12 @@
     owner = (address) mark.locker();
   }
 
   // Contended case, header points to ObjectMonitor (tagged pointer)
   else if (mark.has_monitor()) {
+    // The first stage of async deflation does not affect any field
+    // used by this comparison so the ObjectMonitor* is usable here.
     ObjectMonitor* monitor = mark.monitor();
     assert(monitor != NULL, "monitor should be non-null");
     owner = (address) monitor->owner();
   }
 
@@ -1175,13 +1292,19 @@
   PaddedObjectMonitor* block = Atomic::load(&g_block_list);
   while (block != NULL) {
     assert(block->object() == CHAINMARKER, "must be a block header");
     for (int i = _BLOCKSIZE - 1; i > 0; i--) {
       ObjectMonitor* mid = (ObjectMonitor *)(block + i);
-      oop object = (oop)mid->object();
-      if (object != NULL) {
+      if (mid->object() != NULL) {
         // Only process with closure if the object is set.
+
+        // monitors_iterate() is only called at a safepoint or when the
+        // target thread is suspended or when the target thread is
+        // operating on itself. The current closures in use today are
+        // only interested in an owned ObjectMonitor and ownership
+        // cannot be dropped under the calling contexts so the
+        // ObjectMonitor cannot be async deflated.
         closure->do_monitor(mid);
       }
     }
     // unmarked_next() is not needed with g_block_list (no locking
     // used with block linkage _next_om fields).
@@ -1193,19 +1316,57 @@
   int population = Atomic::load(&om_list_globals._population);
   if (population == 0) {
     return false;
   }
   if (MonitorUsedDeflationThreshold > 0) {
-    int monitors_used = population - Atomic::load(&om_list_globals._free_count);
+    int monitors_used = population - Atomic::load(&om_list_globals._free_count) -
+                        Atomic::load(&om_list_globals._wait_count);
     int monitor_usage = (monitors_used * 100LL) / population;
     return monitor_usage > MonitorUsedDeflationThreshold;
   }
   return false;
 }
 
-bool ObjectSynchronizer::is_cleanup_needed() {
-  return monitors_used_above_threshold();
+bool ObjectSynchronizer::is_async_deflation_needed() {
+  if (!AsyncDeflateIdleMonitors) {
+    return false;
+  }
+  if (is_async_deflation_requested()) {
+    // Async deflation request.
+    return true;
+  }
+  if (AsyncDeflationInterval > 0 &&
+      time_since_last_async_deflation_ms() > AsyncDeflationInterval &&
+      monitors_used_above_threshold()) {
+    // It's been longer than our specified deflate interval and there
+    // are too many monitors in use. We don't deflate more frequently
+    // than AsyncDeflationInterval (unless is_async_deflation_requested)
+    // in order to not swamp the ServiceThread.
+    _last_async_deflation_time_ns = os::javaTimeNanos();
+    return true;
+  }
+  return false;
+}
+
+bool ObjectSynchronizer::is_safepoint_deflation_needed() {
+  if (!AsyncDeflateIdleMonitors) {
+    if (monitors_used_above_threshold()) {
+      // Too many monitors in use.
+      return true;
+    }
+    return false;
+  }
+  if (is_special_deflation_requested()) {
+    // For AsyncDeflateIdleMonitors only do a safepoint deflation
+    // if there is a special deflation request.
+    return true;
+  }
+  return false;
+}
+
+jlong ObjectSynchronizer::time_since_last_async_deflation_ms() {
+  return (os::javaTimeNanos() - _last_async_deflation_time_ns) / (NANOUNITS / MILLIUNITS);
 }
 
 void ObjectSynchronizer::oops_do(OopClosure* f) {
   // We only scan the global used list here (for moribund threads), and
   // the thread-local monitors in Thread::oops_do().
@@ -1237,11 +1398,11 @@
 // -----------------------------------------------------------------------------
 // ObjectMonitor Lifecycle
 // -----------------------
 // Inflation unlinks monitors from om_list_globals._free_list or a per-thread
 // free list and associates them with objects. Deflation -- which occurs at
-// STW-time -- disassociates idle monitors from objects.
+// STW-time or asynchronously -- disassociates idle monitors from objects.
 // Such scavenged monitors are returned to the om_list_globals._free_list.
 //
 // ObjectMonitors reside in type-stable memory (TSM) and are immortal.
 //
 // Lifecycle:
@@ -1269,10 +1430,11 @@
     // improve allocation latency, as well as reducing coherency traffic
     // on the shared global list.
     m = take_from_start_of_om_free_list(self);
     if (m != NULL) {
       guarantee(m->object() == NULL, "invariant");
+      m->set_allocation_state(ObjectMonitor::New);
       prepend_to_om_in_use_list(self, m);
       return m;
     }
 
     // 2: try to allocate from the global om_list_globals._free_list
@@ -1286,11 +1448,33 @@
         ObjectMonitor* take = take_from_start_of_global_free_list();
         if (take == NULL) {
           break;  // No more are available.
         }
         guarantee(take->object() == NULL, "invariant");
+        if (AsyncDeflateIdleMonitors) {
+          // We allowed 3 field values to linger during async deflation.
+          // Clear or restore them as appropriate.
+          take->set_header(markWord::zero());
+          // DEFLATER_MARKER is the only non-NULL value we should see here.
+          take->try_set_owner_from(DEFLATER_MARKER, NULL);
+          if (take->contentions() < 0) {
+            // Add back max_jint to restore the contentions field to its
+            // proper value.
+            take->add_to_contentions(max_jint);
+
+#ifdef ASSERT
+            jint l_contentions = take->contentions();
+#endif
+            assert(l_contentions >= 0, "must not be negative: l_contentions=%d, contentions=%d",
+                   l_contentions, take->contentions());
+          }
+        }
         take->Recycle();
+        // Since we're taking from the global free-list, take must be Free.
+        // om_release() also sets the allocation state to Free because it
+        // is called from other code paths.
+        assert(take->is_free(), "invariant");
         om_release(self, take, false);
       }
       self->om_free_provision += 1 + (self->om_free_provision / 2);
       if (self->om_free_provision > MAXPRIVATE) self->om_free_provision = MAXPRIVATE;
       continue;
@@ -1320,10 +1504,11 @@
     // linkage should be reconsidered.  A better implementation would
     // look like: class Block { Block * next; int N; ObjectMonitor Body [N] ; }
 
     for (int i = 1; i < _BLOCKSIZE; i++) {
       temp[i].set_next_om((ObjectMonitor*)&temp[i + 1]);
+      assert(temp[i].is_free(), "invariant");
     }
 
     // terminate the last monitor as the end of list
     temp[_BLOCKSIZE - 1].set_next_om((ObjectMonitor*)NULL);
 
@@ -1345,12 +1530,12 @@
 // a CAS attempt failed. This doesn't allow unbounded #s of monitors to
 // accumulate on a thread's free list.
 //
 // Key constraint: all ObjectMonitors on a thread's free list and the global
 // free list must have their object field set to null. This prevents the
-// scavenger -- deflate_monitor_list() -- from reclaiming them while we
-// are trying to release them.
+// scavenger -- deflate_monitor_list() or deflate_monitor_list_using_JT()
+// -- from reclaiming them while we are trying to release them.
 
 void ObjectSynchronizer::om_release(Thread* self, ObjectMonitor* m,
                                     bool from_per_thread_alloc) {
   guarantee(m->header().value() == 0, "invariant");
   guarantee(m->object() == NULL, "invariant");
@@ -1359,23 +1544,24 @@
   if ((m->is_busy() | m->_recursions) != 0) {
     stringStream ss;
     fatal("freeing in-use monitor: %s, recursions=" INTX_FORMAT,
           m->is_busy_to_string(&ss), m->_recursions);
   }
+  m->set_allocation_state(ObjectMonitor::Free);
   // _next_om is used for both per-thread in-use and free lists so
   // we have to remove 'm' from the in-use list first (as needed).
   if (from_per_thread_alloc) {
     // Need to remove 'm' from om_in_use_list.
     ObjectMonitor* mid = NULL;
     ObjectMonitor* next = NULL;
 
-    // This list walk can only race with another list walker since
-    // deflation can only happen at a safepoint so we don't have to
-    // worry about an ObjectMonitor being removed from this list
-    // while we are walking it.
+    // This list walk can race with another list walker or with async
+    // deflation so we have to worry about an ObjectMonitor being
+    // removed from this list while we are walking it.
 
-    // Lock the list head to avoid racing with another list walker.
+    // Lock the list head to avoid racing with another list walker
+    // or with async deflation.
     if ((mid = get_list_head_locked(&self->om_in_use_list)) == NULL) {
       fatal("thread=" INTPTR_FORMAT " in-use list must not be empty.", p2i(self));
     }
     next = unmarked_next(mid);
     if (m == mid) {
@@ -1387,37 +1573,48 @@
     } else if (m == next) {
       // Second special case:
       // 'm' matches next after the list head and we already have the list
       // head locked so set mid to what we are extracting:
       mid = next;
-      // Lock mid to prevent races with a list walker:
+      // Lock mid to prevent races with a list walker or an async
+      // deflater thread that's ahead of us. The locked list head
+      // prevents races from behind us.
       om_lock(mid);
       // Update next to what follows mid (if anything):
       next = unmarked_next(mid);
       // Switch next after the list head to new next which unlocks the
       // list head, but leaves the extracted mid locked:
       self->om_in_use_list->set_next_om(next);
     } else {
       // We have to search the list to find 'm'.
-      om_unlock(mid);  // unlock the list head
       guarantee(next != NULL, "thread=" INTPTR_FORMAT ": om_in_use_list=" INTPTR_FORMAT
                 " is too short.", p2i(self), p2i(self->om_in_use_list));
       // Our starting anchor is next after the list head which is the
       // last ObjectMonitor we checked:
       ObjectMonitor* anchor = next;
+      // Lock anchor to prevent races with a list walker or an async
+      // deflater thread that's ahead of us. The locked list head
+      // prevents races from behind us.
+      om_lock(anchor);
+      om_unlock(mid);  // Unlock the list head now that anchor is locked.
       while ((mid = unmarked_next(anchor)) != NULL) {
         if (m == mid) {
           // We found 'm' on the per-thread in-use list so extract it.
-          om_lock(anchor);  // Lock the anchor so we can safely modify it.
           // Update next to what follows mid (if anything):
           next = unmarked_next(mid);
           // Switch next after the anchor to new next which unlocks the
           // anchor, but leaves the extracted mid locked:
           anchor->set_next_om(next);
           break;
         } else {
-          anchor = mid;
+          // Lock the next anchor to prevent races with a list walker
+          // or an async deflater thread that's ahead of us. The locked
+          // current anchor prevents races from behind us.
+          om_lock(mid);
+          // Unlock current anchor now that next anchor is locked:
+          om_unlock(anchor);
+          anchor = mid;  // Advance to new anchor and try again.
         }
       }
     }
 
     if (mid == NULL) {
@@ -1434,10 +1631,11 @@
     // the thread's free list:
     om_unlock(mid);
   }
 
   prepend_to_om_free_list(self, m);
+  guarantee(m->is_free(), "invariant");
 }
 
 // Return ObjectMonitors on a moribund thread's free and in-use
 // lists to the appropriate global lists. The ObjectMonitors on the
 // per-thread in-use list may still be in use by other threads.
@@ -1448,20 +1646,28 @@
 // a safepoint and interleave with deflate_idle_monitors(). In
 // particular, this ensures that the thread's in-use monitors are
 // scanned by a GC safepoint, either via Thread::oops_do() (before
 // om_flush() is called) or via ObjectSynchronizer::oops_do() (after
 // om_flush() is called).
+//
+// With AsyncDeflateIdleMonitors, deflate_global_idle_monitors_using_JT()
+// and deflate_per_thread_idle_monitors_using_JT() (in another thread) can
+// run at the same time as om_flush() so we have to follow a careful
+// protocol to prevent list corruption.
 
 void ObjectSynchronizer::om_flush(Thread* self) {
   // Process the per-thread in-use list first to be consistent.
   int in_use_count = 0;
   ObjectMonitor* in_use_list = NULL;
   ObjectMonitor* in_use_tail = NULL;
   NoSafepointVerifier nsv;
 
-  // This function can race with a list walker thread so we lock the
-  // list head to prevent confusion.
+  // This function can race with a list walker or with an async
+  // deflater thread so we lock the list head to prevent confusion.
+  // An async deflater thread checks to see if the target thread
+  // is exiting, but if it has made it past that check before we
+  // started exiting, then it is racing to get to the in-use list.
   if ((in_use_list = get_list_head_locked(&self->om_in_use_list)) != NULL) {
     // At this point, we have locked the in-use list head so a racing
     // thread cannot come in after us. However, a racing thread could
     // be ahead of us; we'll detect that and delay to let it finish.
     //
@@ -1472,25 +1678,37 @@
     //
     // Account for the in-use list head before the loop since it is
     // already locked (by this thread):
     in_use_tail = in_use_list;
     in_use_count++;
-    for (ObjectMonitor* cur_om = unmarked_next(in_use_list); cur_om != NULL; cur_om = unmarked_next(cur_om)) {
+    for (ObjectMonitor* cur_om = unmarked_next(in_use_list); cur_om != NULL;) {
       if (is_locked(cur_om)) {
-        // cur_om is locked so there must be a racing walker thread ahead
-        // of us so we'll give it a chance to finish.
+        // cur_om is locked so there must be a racing walker or async
+        // deflater thread ahead of us so we'll give it a chance to finish.
         while (is_locked(cur_om)) {
           os::naked_short_sleep(1);
         }
+        // Refetch the possibly changed next field and try again.
+        cur_om = unmarked_next(in_use_tail);
+        continue;
+      }
+      if (cur_om->object() == NULL) {
+        // cur_om was deflated and the object ref was cleared while it
+        // was locked. We happened to see it just after it was unlocked
+        // (and added to the free list). Refetch the possibly changed
+        // next field and try again.
+        cur_om = unmarked_next(in_use_tail);
+        continue;
       }
       in_use_tail = cur_om;
       in_use_count++;
+      cur_om = unmarked_next(cur_om);
     }
     guarantee(in_use_tail != NULL, "invariant");
     int l_om_in_use_count = Atomic::load(&self->om_in_use_count);
-    assert(l_om_in_use_count == in_use_count, "in-use counts don't match: "
-          "l_om_in_use_count=%d, in_use_count=%d", l_om_in_use_count, in_use_count);
+    ADIM_guarantee(l_om_in_use_count == in_use_count, "in-use counts don't match: "
+                   "l_om_in_use_count=%d, in_use_count=%d", l_om_in_use_count, in_use_count);
     Atomic::store(&self->om_in_use_count, 0);
     // Clear the in-use list head (which also unlocks it):
     Atomic::store(&self->om_in_use_list, (ObjectMonitor*)NULL);
     om_unlock(in_use_list);
   }
@@ -1528,12 +1746,12 @@
         fatal("must be !is_busy: %s", s->is_busy_to_string(&ss));
       }
     }
     guarantee(free_tail != NULL, "invariant");
     int l_om_free_count = Atomic::load(&self->om_free_count);
-    assert(l_om_free_count == free_count, "free counts don't match: "
-           "l_om_free_count=%d, free_count=%d", l_om_free_count, free_count);
+    ADIM_guarantee(l_om_free_count == free_count, "free counts don't match: "
+                   "l_om_free_count=%d, free_count=%d", l_om_free_count, free_count);
     Atomic::store(&self->om_free_count, 0);
     Atomic::store(&self->om_free_list, (ObjectMonitor*)NULL);
     om_unlock(free_list);
   }
 
@@ -1574,19 +1792,21 @@
 
 // Fast path code shared by multiple functions
 void ObjectSynchronizer::inflate_helper(oop obj) {
   markWord mark = obj->mark();
   if (mark.has_monitor()) {
-    assert(ObjectSynchronizer::verify_objmon_isinpool(mark.monitor()), "monitor is invalid");
-    assert(mark.monitor()->header().is_neutral(), "monitor must record a good object header");
+    ObjectMonitor* monitor = mark.monitor();
+    assert(ObjectSynchronizer::verify_objmon_isinpool(monitor), "monitor=" INTPTR_FORMAT " is invalid", p2i(monitor));
+    markWord dmw = monitor->header();
+    assert(dmw.is_neutral(), "sanity check: header=" INTPTR_FORMAT, dmw.value());
     return;
   }
-  inflate(Thread::current(), obj, inflate_cause_vm_internal);
+  (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);
 }
 
-ObjectMonitor* ObjectSynchronizer::inflate(Thread* self,
-                                           oop object, const InflateCause cause) {
+ObjectMonitor* ObjectSynchronizer::inflate(Thread* self, oop object,
+                                           const InflateCause cause) {
   // Inflate mutates the heap ...
   // Relaxing assertion for bug 6320749.
   assert(Universe::verify_in_progress() ||
          !SafepointSynchronize::is_at_safepoint(), "invariant");
 
@@ -1610,11 +1830,11 @@
     // CASE: inflated
     if (mark.has_monitor()) {
       ObjectMonitor* inf = mark.monitor();
       markWord dmw = inf->header();
       assert(dmw.is_neutral(), "invariant: header=" INTPTR_FORMAT, dmw.value());
-      assert(inf->object() == object, "invariant");
+      assert(AsyncDeflateIdleMonitors || inf->object() == object, "invariant");
       assert(ObjectSynchronizer::verify_objmon_isinpool(inf), "monitor is invalid");
       return inf;
     }
 
     // CASE: inflation in progress - inflating over a stack-lock.
@@ -1658,10 +1878,11 @@
       m->_Responsible  = NULL;
       m->_SpinDuration = ObjectMonitor::Knob_SpinLimit;   // Consider: maintain by type/class
 
       markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);
       if (cmp != mark) {
+        // om_release() will reset the allocation state from New to Free.
         om_release(self, m, true);
         continue;       // Interference -- just retry
       }
 
       // We've successfully installed INFLATING (0) into the mark-word.
@@ -1695,29 +1916,38 @@
       // object is in the mark.  Furthermore the owner can't complete
       // an unlock on the object, either.
       markWord dmw = mark.displaced_mark_helper();
       // Catch if the object's header is not neutral (not locked and
       // not marked is what we care about here).
-      assert(dmw.is_neutral(), "invariant: header=" INTPTR_FORMAT, dmw.value());
+      ADIM_guarantee(dmw.is_neutral(), "invariant: header=" INTPTR_FORMAT, dmw.value());
 
       // Setup monitor fields to proper values -- prepare the monitor
       m->set_header(dmw);
 
       // Optimization: if the mark.locker stack address is associated
       // with this thread we could simply set m->_owner = self.
       // Note that a thread can inflate an object
       // that it has stack-locked -- as might happen in wait() -- directly
       // with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.
-      m->set_owner_from(NULL, mark.locker());
+      if (AsyncDeflateIdleMonitors) {
+        m->set_owner_from(NULL, DEFLATER_MARKER, mark.locker());
+      } else {
+        m->set_owner_from(NULL, mark.locker());
+      }
       m->set_object(object);
       // TODO-FIXME: assert BasicLock->dhw != 0.
 
       // Must preserve store ordering. The monitor state must
       // be stable at the time of publishing the monitor address.
       guarantee(object->mark() == markWord::INFLATING(), "invariant");
       object->release_set_mark(markWord::encode(m));
 
+      // Once ObjectMonitor is configured and the object is associated
+      // with the ObjectMonitor, it is safe to allow async deflation:
+      assert(m->is_new(), "freshly allocated monitor must be new");
+      m->set_allocation_state(ObjectMonitor::Old);
+
       // Hopefully the performance counters are allocated on distinct cache lines
       // to avoid false sharing on MP systems ...
       OM_PERFDATA_OP(Inflations, inc());
       if (log_is_enabled(Trace, monitorinflation)) {
         ResourceMark rm(self);
@@ -1740,31 +1970,41 @@
     // to inflate and then CAS() again to try to swing _owner from NULL to self.
     // An inflateTry() method that we could call from enter() would be useful.
 
     // Catch if the object's header is not neutral (not locked and
     // not marked is what we care about here).
-    assert(mark.is_neutral(), "invariant: header=" INTPTR_FORMAT, mark.value());
+    ADIM_guarantee(mark.is_neutral(), "invariant: header=" INTPTR_FORMAT, mark.value());
     ObjectMonitor* m = om_alloc(self);
     // prepare m for installation - set monitor to initial state
     m->Recycle();
     m->set_header(mark);
+    if (AsyncDeflateIdleMonitors) {
+      // DEFLATER_MARKER is the only non-NULL value we should see here.
+      m->try_set_owner_from(DEFLATER_MARKER, NULL);
+    }
     m->set_object(object);
     m->_Responsible  = NULL;
     m->_SpinDuration = ObjectMonitor::Knob_SpinLimit;       // consider: keep metastats by type/class
 
     if (object->cas_set_mark(markWord::encode(m), mark) != mark) {
       m->set_header(markWord::zero());
       m->set_object(NULL);
       m->Recycle();
+      // om_release() will reset the allocation state from New to Free.
       om_release(self, m, true);
       m = NULL;
       continue;
       // interference - the markword changed - just retry.
       // The state-transitions are one-way, so there's no chance of
       // live-lock -- "Inflated" is an absorbing state.
     }
 
+    // Once the ObjectMonitor is configured and object is associated
+    // with the ObjectMonitor, it is safe to allow async deflation:
+    assert(m->is_new(), "freshly allocated monitor must be new");
+    m->set_allocation_state(ObjectMonitor::Old);
+
     // Hopefully the performance counters are allocated on distinct
     // cache lines to avoid false sharing on MP systems ...
     OM_PERFDATA_OP(Inflations, inc());
     if (log_is_enabled(Trace, monitorinflation)) {
       ResourceMark rm(self);
@@ -1780,10 +2020,11 @@
 }
 
 
 // We maintain a list of in-use monitors for each thread.
 //
+// For safepoint based deflation:
 // deflate_thread_local_monitors() scans a single thread's in-use list, while
 // deflate_idle_monitors() scans only a global list of in-use monitors which
 // is populated only as a thread dies (see om_flush()).
 //
 // These operations are called at all safepoints, immediately after mutators
@@ -1798,10 +2039,44 @@
 //
 // Perversely, the heap size -- and thus the STW safepoint rate --
 // typically drives the scavenge rate.  Large heaps can mean infrequent GC,
 // which in turn can mean large(r) numbers of ObjectMonitors in circulation.
 // This is an unfortunate aspect of this design.
+//
+// For async deflation:
+// If a special deflation request is made, then the safepoint based
+// deflation mechanism is used. Otherwise, an async deflation request
+// is registered with the ServiceThread and it is notified.
+
+void ObjectSynchronizer::do_safepoint_work(DeflateMonitorCounters* counters) {
+  assert(SafepointSynchronize::is_at_safepoint(), "must be at safepoint");
+
+  // The per-thread in-use lists are handled in
+  // ParallelSPCleanupThreadClosure::do_thread().
+
+  if (!AsyncDeflateIdleMonitors || is_special_deflation_requested()) {
+    // Use the older mechanism for the global in-use list or if a
+    // special deflation has been requested before the safepoint.
+    ObjectSynchronizer::deflate_idle_monitors(counters);
+    return;
+  }
+
+  log_debug(monitorinflation)("requesting async deflation of idle monitors.");
+  // Request deflation of idle monitors by the ServiceThread:
+  set_is_async_deflation_requested(true);
+  MonitorLocker ml(Service_lock, Mutex::_no_safepoint_check_flag);
+  ml.notify_all();
+
+  if (log_is_enabled(Debug, monitorinflation)) {
+    // exit_globals()'s call to audit_and_print_stats() is done
+    // at the Info level and not at a safepoint.
+    // For safepoint based deflation, audit_and_print_stats() is called
+    // in ObjectSynchronizer::finish_deflate_idle_monitors() at the
+    // Debug level at a safepoint.
+    ObjectSynchronizer::audit_and_print_stats(false /* on_exit */);
+  }
+}
 
 // Deflate a single monitor if not in-use
 // Return true if deflated, false if in-use
 bool ObjectSynchronizer::deflate_monitor(ObjectMonitor* mid, oop obj,
                                          ObjectMonitor** free_head_p,
@@ -1833,14 +2108,20 @@
                                   mark.value(), obj->klass()->external_name());
     }
 
     // Restore the header back to obj
     obj->release_set_mark(dmw);
+    if (AsyncDeflateIdleMonitors) {
+      // clear() expects the owner field to be NULL.
+      // DEFLATER_MARKER is the only non-NULL value we should see here.
+      mid->try_set_owner_from(DEFLATER_MARKER, NULL);
+    }
     mid->clear();
 
     assert(mid->object() == NULL, "invariant: object=" INTPTR_FORMAT,
            p2i(mid->object()));
+    assert(mid->is_free(), "invariant");
 
     // Move the deflated ObjectMonitor to the working free list
     // defined by free_head_p and free_tail_p.
     if (*free_head_p == NULL) *free_head_p = mid;
     if (*free_tail_p != NULL) {
@@ -1865,10 +2146,132 @@
     deflated = true;
   }
   return deflated;
 }
 
+// Deflate the specified ObjectMonitor if not in-use using a JavaThread.
+// Returns true if it was deflated and false otherwise.
+//
+// The async deflation protocol sets owner to DEFLATER_MARKER and
+// makes contentions negative as signals to contending threads that
+// an async deflation is in progress. There are a number of checks
+// as part of the protocol to make sure that the calling thread has
+// not lost the race to a contending thread.
+//
+// The ObjectMonitor has been successfully async deflated when:
+//   (contentions < 0)
+// Contending threads that see that condition know to retry their operation.
+//
+bool ObjectSynchronizer::deflate_monitor_using_JT(ObjectMonitor* mid,
+                                                  ObjectMonitor** free_head_p,
+                                                  ObjectMonitor** free_tail_p) {
+  assert(AsyncDeflateIdleMonitors, "sanity check");
+  assert(Thread::current()->is_Java_thread(), "precondition");
+  // A newly allocated ObjectMonitor should not be seen here so we
+  // avoid an endless inflate/deflate cycle.
+  assert(mid->is_old(), "must be old: allocation_state=%d",
+         (int) mid->allocation_state());
+
+  if (mid->is_busy()) {
+    // Easy checks are first - the ObjectMonitor is busy so no deflation.
+    return false;
+  }
+
+  // Set a NULL owner to DEFLATER_MARKER to force any contending thread
+  // through the slow path. This is just the first part of the async
+  // deflation dance.
+  if (mid->try_set_owner_from(NULL, DEFLATER_MARKER) != NULL) {
+    // The owner field is no longer NULL so we lost the race since the
+    // ObjectMonitor is now busy.
+    return false;
+  }
+
+  if (mid->contentions() > 0 || mid->_waiters != 0) {
+    // Another thread has raced to enter the ObjectMonitor after
+    // mid->is_busy() above or has already entered and waited on
+    // it which makes it busy so no deflation. Restore owner to
+    // NULL if it is still DEFLATER_MARKER.
+    if (mid->try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {
+      // Deferred decrement for the JT EnterI() that cancelled the async deflation.
+      mid->add_to_contentions(-1);
+    }
+    return false;
+  }
+
+  // Make a zero contentions field negative to force any contending threads
+  // to retry. This is the second part of the async deflation dance.
+  if (Atomic::cmpxchg(&mid->_contentions, (jint)0, -max_jint) != 0) {
+    // Contentions was no longer 0 so we lost the race since the
+    // ObjectMonitor is now busy. Restore owner to NULL if it is
+    // still DEFLATER_MARKER:
+    if (mid->try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {
+      // Deferred decrement for the JT EnterI() that cancelled the async deflation.
+      mid->add_to_contentions(-1);
+    }
+    return false;
+  }
+
+  // Sanity checks for the races:
+  guarantee(mid->owner_is_DEFLATER_MARKER(), "must be deflater marker");
+  guarantee(mid->contentions() < 0, "must be negative: contentions=%d",
+            mid->contentions());
+  guarantee(mid->_waiters == 0, "must be 0: waiters=%d", mid->_waiters);
+  guarantee(mid->_cxq == NULL, "must be no contending threads: cxq="
+            INTPTR_FORMAT, p2i(mid->_cxq));
+  guarantee(mid->_EntryList == NULL,
+            "must be no entering threads: EntryList=" INTPTR_FORMAT,
+            p2i(mid->_EntryList));
+
+  const oop obj = (oop) mid->object();
+  if (log_is_enabled(Trace, monitorinflation)) {
+    ResourceMark rm;
+    log_trace(monitorinflation)("deflate_monitor_using_JT: "
+                                "object=" INTPTR_FORMAT ", mark="
+                                INTPTR_FORMAT ", type='%s'",
+                                p2i(obj), obj->mark().value(),
+                                obj->klass()->external_name());
+  }
+
+  // Install the old mark word if nobody else has already done it.
+  mid->install_displaced_markword_in_object(obj);
+  mid->clear_common();
+
+  assert(mid->object() == NULL, "must be NULL: object=" INTPTR_FORMAT,
+         p2i(mid->object()));
+  assert(mid->is_free(), "must be free: allocation_state=%d",
+         (int)mid->allocation_state());
+
+  // Move the deflated ObjectMonitor to the working free list
+  // defined by free_head_p and free_tail_p.
+  if (*free_head_p == NULL) {
+    // First one on the list.
+    *free_head_p = mid;
+  }
+  if (*free_tail_p != NULL) {
+    // We append to the list so the caller can use mid->_next_om
+    // to fix the linkages in its context.
+    ObjectMonitor* prevtail = *free_tail_p;
+    // prevtail should have been cleaned up by the caller:
+#ifdef ASSERT
+    ObjectMonitor* l_next_om = unmarked_next(prevtail);
+#endif
+    assert(l_next_om == NULL, "must be NULL: _next_om=" INTPTR_FORMAT, p2i(l_next_om));
+    om_lock(prevtail);
+    prevtail->set_next_om(mid);  // prevtail now points to mid (and is unlocked)
+  }
+  *free_tail_p = mid;
+
+  // At this point, mid->_next_om still refers to its current
+  // value and another ObjectMonitor's _next_om field still
+  // refers to this ObjectMonitor. Those linkages have to be
+  // cleaned up by the caller who has the complete context.
+
+  // We leave owner == DEFLATER_MARKER and contentions < 0
+  // to force any racing threads to retry.
+  return true;  // Success, ObjectMonitor has been deflated.
+}
+
 // Walk a given monitor list, and deflate idle monitors.
 // The given list could be a per-thread list or a global list.
 //
 // In the case of parallel processing of thread local monitor lists,
 // work is done by Threads::parallel_threads_do() which ensures that
@@ -1915,20 +2318,170 @@
     }
   }
   return deflated_count;
 }
 
+// Walk a given ObjectMonitor list and deflate idle ObjectMonitors using
+// a JavaThread. Returns the number of deflated ObjectMonitors. The given
+// list could be a per-thread in-use list or the global in-use list.
+// If a safepoint has started, then we save state via saved_mid_in_use_p
+// and return to the caller to honor the safepoint.
+//
+int ObjectSynchronizer::deflate_monitor_list_using_JT(ObjectMonitor** list_p,
+                                                      int* count_p,
+                                                      ObjectMonitor** free_head_p,
+                                                      ObjectMonitor** free_tail_p,
+                                                      ObjectMonitor** saved_mid_in_use_p) {
+  assert(AsyncDeflateIdleMonitors, "sanity check");
+  JavaThread* self = JavaThread::current();
+
+  ObjectMonitor* cur_mid_in_use = NULL;
+  ObjectMonitor* mid = NULL;
+  ObjectMonitor* next = NULL;
+  ObjectMonitor* next_next = NULL;
+  int deflated_count = 0;
+  NoSafepointVerifier nsv;
+
+  // We use the more complicated lock-cur_mid_in_use-and-mid-as-we-go
+  // protocol because om_release() can do list deletions in parallel;
+  // this also prevents races with a list walker thread. We also
+  // lock-next-next-as-we-go to prevent an om_flush() that is behind
+  // this thread from passing us.
+  if (*saved_mid_in_use_p == NULL) {
+    // No saved state so start at the beginning.
+    // Lock the list head so we can possibly deflate it:
+    if ((mid = get_list_head_locked(list_p)) == NULL) {
+      return 0;  // The list is empty so nothing to deflate.
+    }
+    next = unmarked_next(mid);
+  } else {
+    // We're restarting after a safepoint so restore the necessary state
+    // before we resume.
+    cur_mid_in_use = *saved_mid_in_use_p;
+    // Lock cur_mid_in_use so we can possibly update its
+    // next field to extract a deflated ObjectMonitor.
+    om_lock(cur_mid_in_use);
+    mid = unmarked_next(cur_mid_in_use);
+    if (mid == NULL) {
+      om_unlock(cur_mid_in_use);
+      *saved_mid_in_use_p = NULL;
+      return 0;  // The remainder is empty so nothing more to deflate.
+    }
+    // Lock mid so we can possibly deflate it:
+    om_lock(mid);
+    next = unmarked_next(mid);
+  }
+
+  while (true) {
+    // The current mid is locked at this point. If we have a
+    // cur_mid_in_use, then it is also locked at this point.
+
+    if (next != NULL) {
+      // We lock next so that an om_flush() thread that is behind us
+      // cannot pass us when we unlock the current mid.
+      om_lock(next);
+      next_next = unmarked_next(next);
+    }
+
+    // Only try to deflate if there is an associated Java object and if
+    // mid is old (is not newly allocated and is not newly freed).
+    if (mid->object() != NULL && mid->is_old() &&
+        deflate_monitor_using_JT(mid, free_head_p, free_tail_p)) {
+      // Deflation succeeded and already updated free_head_p and
+      // free_tail_p as needed. Finish the move to the local free list
+      // by unlinking mid from the global or per-thread in-use list.
+      if (cur_mid_in_use == NULL) {
+        // mid is the list head and it is locked. Switch the list head
+        // to next which is also locked (if not NULL) and also leave
+        // mid locked:
+        Atomic::store(list_p, next);
+      } else {
+        ObjectMonitor* locked_next = mark_om_ptr(next);
+        // mid and cur_mid_in_use are locked. Switch cur_mid_in_use's
+        // next field to locked_next and also leave mid locked:
+        cur_mid_in_use->set_next_om(locked_next);
+      }
+      // At this point mid is disconnected from the in-use list so
+      // its lock longer has any effects on in-use list.
+      deflated_count++;
+      Atomic::dec(count_p);
+      // mid is current tail in the free_head_p list so NULL terminate it
+      // (which also unlocks it):
+      mid->set_next_om(NULL);
+
+      // All the list management is done so move on to the next one:
+      mid = next;  // mid keeps non-NULL next's locked state
+      next = next_next;
+    } else {
+      // mid is considered in-use if it does not have an associated
+      // Java object or mid is not old or deflation did not succeed.
+      // A mid->is_new() node can be seen here when it is freshly
+      // returned by om_alloc() (and skips the deflation code path).
+      // A mid->is_old() node can be seen here when deflation failed.
+      // A mid->is_free() node can be seen here when a fresh node from
+      // om_alloc() is released by om_release() due to losing the race
+      // in inflate().
+
+      // All the list management is done so move on to the next one:
+      if (cur_mid_in_use != NULL) {
+        om_unlock(cur_mid_in_use);
+      }
+      // The next cur_mid_in_use keeps mid's lock state so
+      // that it is stable for a possible next field change. It
+      // cannot be modified by om_release() while it is locked.
+      cur_mid_in_use = mid;
+      mid = next;  // mid keeps non-NULL next's locked state
+      next = next_next;
+
+      if (SafepointMechanism::should_block(self) &&
+          cur_mid_in_use != Atomic::load(list_p) && cur_mid_in_use->is_old()) {
+        // If a safepoint has started and cur_mid_in_use is not the list
+        // head and is old, then it is safe to use as saved state. Return
+        // to the caller before blocking.
+        *saved_mid_in_use_p = cur_mid_in_use;
+        om_unlock(cur_mid_in_use);
+        if (mid != NULL) {
+          om_unlock(mid);
+        }
+        return deflated_count;
+      }
+    }
+    if (mid == NULL) {
+      if (cur_mid_in_use != NULL) {
+        om_unlock(cur_mid_in_use);
+      }
+      break;  // Reached end of the list so nothing more to deflate.
+    }
+
+    // The current mid's next field is locked at this point. If we have
+    // a cur_mid_in_use, then it is also locked at this point.
+  }
+  // We finished the list without a safepoint starting so there's
+  // no need to save state.
+  *saved_mid_in_use_p = NULL;
+  return deflated_count;
+}
+
 void ObjectSynchronizer::prepare_deflate_idle_monitors(DeflateMonitorCounters* counters) {
   counters->n_in_use = 0;              // currently associated with objects
   counters->n_in_circulation = 0;      // extant
   counters->n_scavenged = 0;           // reclaimed (global and per-thread)
   counters->per_thread_scavenged = 0;  // per-thread scavenge total
   counters->per_thread_times = 0.0;    // per-thread scavenge times
 }
 
 void ObjectSynchronizer::deflate_idle_monitors(DeflateMonitorCounters* counters) {
   assert(SafepointSynchronize::is_at_safepoint(), "must be at safepoint");
+
+  if (AsyncDeflateIdleMonitors) {
+    // Nothing to do when global idle ObjectMonitors are deflated using
+    // a JavaThread unless a special deflation has been requested.
+    if (!is_special_deflation_requested()) {
+      return;
+    }
+  }
+
   bool deflated = false;
 
   ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged monitors
   ObjectMonitor* free_tail_p = NULL;
   elapsedTimer timer;
@@ -1977,39 +2530,257 @@
   if (ls != NULL) {
     ls->print_cr("deflating global idle monitors, %3.7f secs, %d monitors", timer.seconds(), deflated_count);
   }
 }
 
+class HandshakeForDeflation : public HandshakeClosure {
+ public:
+  HandshakeForDeflation() : HandshakeClosure("HandshakeForDeflation") {}
+
+  void do_thread(Thread* thread) {
+    log_trace(monitorinflation)("HandshakeForDeflation::do_thread: thread="
+                                INTPTR_FORMAT, p2i(thread));
+  }
+};
+
+void ObjectSynchronizer::deflate_idle_monitors_using_JT() {
+  assert(AsyncDeflateIdleMonitors, "sanity check");
+
+  // Deflate any global idle monitors.
+  deflate_global_idle_monitors_using_JT();
+
+  int count = 0;
+  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {
+    if (Atomic::load(&jt->om_in_use_count) > 0 && !jt->is_exiting()) {
+      // This JavaThread is using ObjectMonitors so deflate any that
+      // are idle unless this JavaThread is exiting; do not race with
+      // ObjectSynchronizer::om_flush().
+      deflate_per_thread_idle_monitors_using_JT(jt);
+      count++;
+    }
+  }
+  if (count > 0) {
+    log_debug(monitorinflation)("did async deflation of idle monitors for %d thread(s).", count);
+  }
+
+  log_info(monitorinflation)("async global_population=%d, global_in_use_count=%d, "
+                             "global_free_count=%d, global_wait_count=%d",
+                             Atomic::load(&om_list_globals._population),
+                             Atomic::load(&om_list_globals._in_use_count),
+                             Atomic::load(&om_list_globals._free_count),
+                             Atomic::load(&om_list_globals._wait_count));
+
+  // The ServiceThread's async deflation request has been processed.
+  set_is_async_deflation_requested(false);
+
+  if (Atomic::load(&om_list_globals._wait_count) > 0) {
+    // There are deflated ObjectMonitors waiting for a handshake
+    // (or a safepoint) for safety.
+
+    ObjectMonitor* list = Atomic::load(&om_list_globals._wait_list);
+    ADIM_guarantee(list != NULL, "om_list_globals._wait_list must not be NULL");
+    int count = Atomic::load(&om_list_globals._wait_count);
+    Atomic::store(&om_list_globals._wait_count, 0);
+    Atomic::store(&om_list_globals._wait_list, (ObjectMonitor*)NULL);
+
+    // Find the tail for prepend_list_to_common(). No need to mark
+    // ObjectMonitors for this list walk since only the deflater
+    // thread manages the wait list.
+    int l_count = 0;
+    ObjectMonitor* tail = NULL;
+    for (ObjectMonitor* n = list; n != NULL; n = unmarked_next(n)) {
+      tail = n;
+      l_count++;
+    }
+    ADIM_guarantee(count == l_count, "count=%d != l_count=%d", count, l_count);
+
+    // Will execute a safepoint if !ThreadLocalHandshakes:
+    HandshakeForDeflation hfd_hc;
+    Handshake::execute(&hfd_hc);
+
+    prepend_list_to_common(list, tail, count, &om_list_globals._free_list,
+                           &om_list_globals._free_count);
+
+    log_info(monitorinflation)("moved %d idle monitors from global waiting list to global free list", count);
+  }
+}
+
+// Deflate global idle ObjectMonitors using a JavaThread.
+//
+void ObjectSynchronizer::deflate_global_idle_monitors_using_JT() {
+  assert(AsyncDeflateIdleMonitors, "sanity check");
+  assert(Thread::current()->is_Java_thread(), "precondition");
+  JavaThread* self = JavaThread::current();
+
+  deflate_common_idle_monitors_using_JT(true /* is_global */, self);
+}
+
+// Deflate the specified JavaThread's idle ObjectMonitors using a JavaThread.
+//
+void ObjectSynchronizer::deflate_per_thread_idle_monitors_using_JT(JavaThread* target) {
+  assert(AsyncDeflateIdleMonitors, "sanity check");
+  assert(Thread::current()->is_Java_thread(), "precondition");
+
+  deflate_common_idle_monitors_using_JT(false /* !is_global */, target);
+}
+
+// Deflate global or per-thread idle ObjectMonitors using a JavaThread.
+//
+void ObjectSynchronizer::deflate_common_idle_monitors_using_JT(bool is_global, JavaThread* target) {
+  JavaThread* self = JavaThread::current();
+
+  int deflated_count = 0;
+  ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged ObjectMonitors
+  ObjectMonitor* free_tail_p = NULL;
+  ObjectMonitor* saved_mid_in_use_p = NULL;
+  elapsedTimer timer;
+
+  if (log_is_enabled(Info, monitorinflation)) {
+    timer.start();
+  }
+
+  if (is_global) {
+    OM_PERFDATA_OP(MonExtant, set_value(Atomic::load(&om_list_globals._in_use_count)));
+  } else {
+    OM_PERFDATA_OP(MonExtant, inc(Atomic::load(&target->om_in_use_count)));
+  }
+
+  do {
+    if (saved_mid_in_use_p != NULL) {
+      // We looped around because deflate_monitor_list_using_JT()
+      // detected a pending safepoint. Honoring the safepoint is good,
+      // but as long as is_special_deflation_requested() is supported,
+      // we can't safely restart using saved_mid_in_use_p. That saved
+      // ObjectMonitor could have been deflated by safepoint based
+      // deflation and would no longer be on the in-use list where we
+      // originally found it.
+      saved_mid_in_use_p = NULL;
+    }
+    int local_deflated_count;
+    if (is_global) {
+      local_deflated_count =
+          deflate_monitor_list_using_JT(&om_list_globals._in_use_list,
+                                        &om_list_globals._in_use_count,
+                                        &free_head_p, &free_tail_p,
+                                        &saved_mid_in_use_p);
+    } else {
+      local_deflated_count =
+          deflate_monitor_list_using_JT(&target->om_in_use_list,
+                                        &target->om_in_use_count, &free_head_p,
+                                        &free_tail_p, &saved_mid_in_use_p);
+    }
+    deflated_count += local_deflated_count;
+
+    if (free_head_p != NULL) {
+      // Move the deflated ObjectMonitors to the global free list.
+      guarantee(free_tail_p != NULL && local_deflated_count > 0, "free_tail_p=" INTPTR_FORMAT ", local_deflated_count=%d", p2i(free_tail_p), local_deflated_count);
+      // Note: The target thread can be doing an om_alloc() that
+      // is trying to prepend an ObjectMonitor on its in-use list
+      // at the same time that we have deflated the current in-use
+      // list head and put it on the local free list. prepend_to_common()
+      // will detect the race and retry which avoids list corruption,
+      // but the next field in free_tail_p can flicker to marked
+      // and then unmarked while prepend_to_common() is sorting it
+      // all out.
+#ifdef ASSERT
+      ObjectMonitor* l_next_om = unmarked_next(free_tail_p);
+#endif
+      assert(l_next_om == NULL, "must be NULL: _next_om=" INTPTR_FORMAT, p2i(l_next_om));
+
+      prepend_list_to_global_wait_list(free_head_p, free_tail_p, local_deflated_count);
+
+      OM_PERFDATA_OP(Deflations, inc(local_deflated_count));
+    }
+
+    if (saved_mid_in_use_p != NULL) {
+      // deflate_monitor_list_using_JT() detected a safepoint starting.
+      timer.stop();
+      {
+        if (is_global) {
+          log_debug(monitorinflation)("pausing deflation of global idle monitors for a safepoint.");
+        } else {
+          log_debug(monitorinflation)("jt=" INTPTR_FORMAT ": pausing deflation of per-thread idle monitors for a safepoint.", p2i(target));
+        }
+        assert(SafepointMechanism::should_block(self), "sanity check");
+        ThreadBlockInVM blocker(self);
+      }
+      // Prepare for another loop after the safepoint.
+      free_head_p = NULL;
+      free_tail_p = NULL;
+      if (log_is_enabled(Info, monitorinflation)) {
+        timer.start();
+      }
+    }
+  } while (saved_mid_in_use_p != NULL);
+  timer.stop();
+
+  LogStreamHandle(Debug, monitorinflation) lsh_debug;
+  LogStreamHandle(Info, monitorinflation) lsh_info;
+  LogStream* ls = NULL;
+  if (log_is_enabled(Debug, monitorinflation)) {
+    ls = &lsh_debug;
+  } else if (deflated_count != 0 && log_is_enabled(Info, monitorinflation)) {
+    ls = &lsh_info;
+  }
+  if (ls != NULL) {
+    if (is_global) {
+      ls->print_cr("async-deflating global idle monitors, %3.7f secs, %d monitors", timer.seconds(), deflated_count);
+    } else {
+      ls->print_cr("jt=" INTPTR_FORMAT ": async-deflating per-thread idle monitors, %3.7f secs, %d monitors", p2i(target), timer.seconds(), deflated_count);
+    }
+  }
+}
+
 void ObjectSynchronizer::finish_deflate_idle_monitors(DeflateMonitorCounters* counters) {
   // Report the cumulative time for deflating each thread's idle
   // monitors. Note: if the work is split among more than one
   // worker thread, then the reported time will likely be more
   // than a beginning to end measurement of the phase.
   log_info(safepoint, cleanup)("deflating per-thread idle monitors, %3.7f secs, monitors=%d", counters->per_thread_times, counters->per_thread_scavenged);
 
+  bool needs_special_deflation = is_special_deflation_requested();
+  if (AsyncDeflateIdleMonitors && !needs_special_deflation) {
+    // Nothing to do when idle ObjectMonitors are deflated using
+    // a JavaThread unless a special deflation has been requested.
+    return;
+  }
+
   if (log_is_enabled(Debug, monitorinflation)) {
     // exit_globals()'s call to audit_and_print_stats() is done
     // at the Info level and not at a safepoint.
+    // For async deflation, audit_and_print_stats() is called in
+    // ObjectSynchronizer::do_safepoint_work() at the Debug level
+    // at a safepoint.
     ObjectSynchronizer::audit_and_print_stats(false /* on_exit */);
   } else if (log_is_enabled(Info, monitorinflation)) {
     log_info(monitorinflation)("global_population=%d, global_in_use_count=%d, "
-                               "global_free_count=%d",
+                               "global_free_count=%d, global_wait_count=%d",
                                Atomic::load(&om_list_globals._population),
                                Atomic::load(&om_list_globals._in_use_count),
-                               Atomic::load(&om_list_globals._free_count));
+                               Atomic::load(&om_list_globals._free_count),
+                               Atomic::load(&om_list_globals._wait_count));
   }
 
   OM_PERFDATA_OP(Deflations, inc(counters->n_scavenged));
   OM_PERFDATA_OP(MonExtant, set_value(counters->n_in_circulation));
 
   GVars.stw_random = os::random();
   GVars.stw_cycle++;
+
+  if (needs_special_deflation) {
+    set_is_special_deflation_requested(false);  // special deflation is done
+  }
 }
 
 void ObjectSynchronizer::deflate_thread_local_monitors(Thread* thread, DeflateMonitorCounters* counters) {
   assert(SafepointSynchronize::is_at_safepoint(), "must be at safepoint");
 
+  if (AsyncDeflateIdleMonitors && !is_special_deflation_requested()) {
+    // Nothing to do if a special deflation has NOT been requested.
+    return;
+  }
+
   ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged monitors
   ObjectMonitor* free_tail_p = NULL;
   elapsedTimer timer;
 
   if (log_is_enabled(Info, safepoint, cleanup) ||
@@ -2179,10 +2950,13 @@
   chk_global_in_use_list_and_count(ls, &error_cnt);
 
   // Check om_list_globals._free_list and om_list_globals._free_count:
   chk_global_free_list_and_count(ls, &error_cnt);
 
+  // Check om_list_globals._wait_list and om_list_globals._wait_count:
+  chk_global_wait_list_and_count(ls, &error_cnt);
+
   ls->print_cr("Checking per-thread lists:");
 
   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {
     // Check om_in_use_list and om_in_use_count:
     chk_per_thread_in_use_list_and_count(jt, ls, &error_cnt);
@@ -2229,16 +3003,17 @@
     if (jt != NULL) {
       out->print_cr("ERROR: jt=" INTPTR_FORMAT ", monitor=" INTPTR_FORMAT
                     ": free per-thread monitor must have NULL _header "
                     "field: _header=" INTPTR_FORMAT, p2i(jt), p2i(n),
                     n->header().value());
-    } else {
+      *error_cnt_p = *error_cnt_p + 1;
+    } else if (!AsyncDeflateIdleMonitors) {
       out->print_cr("ERROR: monitor=" INTPTR_FORMAT ": free global monitor "
                     "must have NULL _header field: _header=" INTPTR_FORMAT,
                     p2i(n), n->header().value());
+      *error_cnt_p = *error_cnt_p + 1;
     }
-    *error_cnt_p = *error_cnt_p + 1;
   }
   if (n->object() != NULL) {
     if (jt != NULL) {
       out->print_cr("ERROR: jt=" INTPTR_FORMAT ", monitor=" INTPTR_FORMAT
                     ": free per-thread monitor must have NULL _object "
@@ -2301,10 +3076,40 @@
     out->print_cr("WARNING: global_free_count=%d is not equal to "
                   "chk_om_free_count=%d", l_free_count, chk_om_free_count);
   }
 }
 
+// Check the global wait list and count; log the results of the checks.
+void ObjectSynchronizer::chk_global_wait_list_and_count(outputStream * out,
+                                                        int *error_cnt_p) {
+  int chk_om_wait_count = 0;
+  ObjectMonitor* cur = NULL;
+  if ((cur = get_list_head_locked(&om_list_globals._wait_list)) != NULL) {
+    // Marked the global wait list head so process the list.
+    while (true) {
+      // Rules for om_list_globals._wait_list are the same as for
+      // om_list_globals._free_list:
+      chk_free_entry(NULL /* jt */, cur, out, error_cnt_p);
+      chk_om_wait_count++;
+
+      cur = lock_next_for_traversal(cur);
+      if (cur == NULL) {
+        break;
+      }
+    }
+  }
+  if (Atomic::load(&om_list_globals._wait_count) == chk_om_wait_count) {
+    out->print_cr("global_wait_count=%d equals chk_om_wait_count=%d",
+                  Atomic::load(&om_list_globals._wait_count), chk_om_wait_count);
+  } else {
+    out->print_cr("ERROR: global_wait_count=%d is not equal to "
+                  "chk_om_wait_count=%d",
+                  Atomic::load(&om_list_globals._wait_count), chk_om_wait_count);
+    *error_cnt_p = *error_cnt_p + 1;
+  }
+}
+
 // Check the global in-use list and count; log the results of the checks.
 void ObjectSynchronizer::chk_global_in_use_list_and_count(outputStream * out,
                                                           int *error_cnt_p) {
   int chk_om_in_use_count = 0;
   ObjectMonitor* cur = NULL;
@@ -2524,18 +3329,20 @@
 
 // Log counts for the global and per-thread monitor lists and return
 // the population count.
 int ObjectSynchronizer::log_monitor_list_counts(outputStream * out) {
   int pop_count = 0;
-  out->print_cr("%18s  %10s  %10s  %10s",
-                "Global Lists:", "InUse", "Free", "Total");
-  out->print_cr("==================  ==========  ==========  ==========");
+  out->print_cr("%18s  %10s  %10s  %10s  %10s",
+                "Global Lists:", "InUse", "Free", "Wait", "Total");
+  out->print_cr("==================  ==========  ==========  ==========  ==========");
   int l_in_use_count = Atomic::load(&om_list_globals._in_use_count);
   int l_free_count = Atomic::load(&om_list_globals._free_count);
-  out->print_cr("%18s  %10d  %10d  %10d", "", l_in_use_count,
-                l_free_count, Atomic::load(&om_list_globals._population));
-  pop_count += l_in_use_count + l_free_count;
+  int l_wait_count = Atomic::load(&om_list_globals._wait_count);
+  out->print_cr("%18s  %10d  %10d  %10d  %10d", "", l_in_use_count,
+                l_free_count, l_wait_count,
+                Atomic::load(&om_list_globals._population));
+  pop_count += l_in_use_count + l_free_count + l_wait_count;
 
   out->print_cr("%18s  %10s  %10s  %10s",
                 "Per-Thread Lists:", "InUse", "Free", "Provision");
   out->print_cr("==================  ==========  ==========  ==========");
 
diff a/src/hotspot/share/runtime/synchronizer.hpp b/src/hotspot/share/runtime/synchronizer.hpp
--- a/src/hotspot/share/runtime/synchronizer.hpp
+++ b/src/hotspot/share/runtime/synchronizer.hpp
@@ -41,15 +41,15 @@
 #endif
 
 typedef PaddedEnd<ObjectMonitor, OM_CACHE_LINE_SIZE> PaddedObjectMonitor;
 
 struct DeflateMonitorCounters {
-  int n_in_use;              // currently associated with objects
-  int n_in_circulation;      // extant
-  int n_scavenged;           // reclaimed (global and per-thread)
-  int per_thread_scavenged;  // per-thread scavenge total
-  double per_thread_times;   // per-thread scavenge times
+  volatile int n_in_use;              // currently associated with objects
+  volatile int n_in_circulation;      // extant
+  volatile int n_scavenged;           // reclaimed (global and per-thread)
+  volatile int per_thread_scavenged;  // per-thread scavenge total
+           double per_thread_times;   // per-thread scavenge times
 };
 
 class ObjectSynchronizer : AllStatic {
   friend class VMStructs;
  public:
@@ -130,33 +130,55 @@
 
   // GC: we current use aggressive monitor deflation policy
   // Basically we deflate all monitors that are not busy.
   // An adaptive profile-based deflation policy could be used if needed
   static void deflate_idle_monitors(DeflateMonitorCounters* counters);
+  static void deflate_idle_monitors_using_JT();
+  static void deflate_global_idle_monitors_using_JT();
+  static void deflate_per_thread_idle_monitors_using_JT(JavaThread* target);
+  static void deflate_common_idle_monitors_using_JT(bool is_global, JavaThread* target);
   static void deflate_thread_local_monitors(Thread* thread, DeflateMonitorCounters* counters);
   static void prepare_deflate_idle_monitors(DeflateMonitorCounters* counters);
   static void finish_deflate_idle_monitors(DeflateMonitorCounters* counters);
 
   // For a given monitor list: global or per-thread, deflate idle monitors
   static int deflate_monitor_list(ObjectMonitor** list_p,
                                   int* count_p,
                                   ObjectMonitor** free_head_p,
                                   ObjectMonitor** free_tail_p);
+  // For a given in-use monitor list: global or per-thread, deflate idle
+  // monitors using a JavaThread.
+  static int deflate_monitor_list_using_JT(ObjectMonitor** list_p,
+                                           int* count_p,
+                                           ObjectMonitor** free_head_p,
+                                           ObjectMonitor** free_tail_p,
+                                           ObjectMonitor** saved_mid_in_use_p);
   static bool deflate_monitor(ObjectMonitor* mid, oop obj,
                               ObjectMonitor** free_head_p,
                               ObjectMonitor** free_tail_p);
-  static bool is_cleanup_needed();
+  static bool deflate_monitor_using_JT(ObjectMonitor* mid,
+                                       ObjectMonitor** free_head_p,
+                                       ObjectMonitor** free_tail_p);
+  static bool is_async_deflation_needed();
+  static bool is_safepoint_deflation_needed();
+  static bool is_async_deflation_requested() { return _is_async_deflation_requested; }
+  static bool is_special_deflation_requested() { return _is_special_deflation_requested; }
+  static void set_is_async_deflation_requested(bool new_value) { _is_async_deflation_requested = new_value; }
+  static void set_is_special_deflation_requested(bool new_value) { _is_special_deflation_requested = new_value; }
+  static jlong time_since_last_async_deflation_ms();
   static void oops_do(OopClosure* f);
   // Process oops in thread local used monitors
   static void thread_local_used_oops_do(Thread* thread, OopClosure* f);
 
   // debugging
   static void audit_and_print_stats(bool on_exit);
   static void chk_free_entry(JavaThread* jt, ObjectMonitor* n,
                              outputStream * out, int *error_cnt_p);
   static void chk_global_free_list_and_count(outputStream * out,
                                              int *error_cnt_p);
+  static void chk_global_wait_list_and_count(outputStream * out,
+                                             int *error_cnt_p);
   static void chk_global_in_use_list_and_count(outputStream * out,
                                                int *error_cnt_p);
   static void chk_in_use_entry(JavaThread* jt, ObjectMonitor* n,
                                outputStream * out, int *error_cnt_p);
   static void chk_per_thread_in_use_list_and_count(JavaThread *jt,
@@ -167,16 +189,21 @@
                                                  int *error_cnt_p);
   static void log_in_use_monitor_details(outputStream * out);
   static int  log_monitor_list_counts(outputStream * out);
   static int  verify_objmon_isinpool(ObjectMonitor *addr) PRODUCT_RETURN0;
 
+  static void do_safepoint_work(DeflateMonitorCounters* counters);
+
  private:
   friend class SynchronizerTest;
 
   enum { _BLOCKSIZE = 128 };
   // global list of blocks of monitors
   static PaddedObjectMonitor* g_block_list;
+  static volatile bool _is_async_deflation_requested;
+  static volatile bool _is_special_deflation_requested;
+  static jlong         _last_async_deflation_time_ns;
 
   // Function to prepend new blocks to the appropriate lists:
   static void prepend_block_to_lists(PaddedObjectMonitor* new_blk);
 
   // Process oops in all global used monitors (i.e. moribund thread's monitors)
diff a/src/hotspot/share/runtime/thread.cpp b/src/hotspot/share/runtime/thread.cpp
--- a/src/hotspot/share/runtime/thread.cpp
+++ b/src/hotspot/share/runtime/thread.cpp
@@ -4695,10 +4695,12 @@
 
   int i = 0;
   DO_JAVA_THREADS(t_list, p) {
     if (!p->can_call_java()) continue;
 
+    // The first stage of async deflation does not affect any field
+    // used by this comparison so the ObjectMonitor* is usable here.
     address pending = (address)p->current_pending_monitor();
     if (pending == monitor) {             // found a match
       if (i < count) result->append(p);   // save the first count matches
       i++;
     }
@@ -4841,12 +4843,14 @@
 
   st->print_cr("Other Threads:");
   print_on_error(VMThread::vm_thread(), st, current, buf, buflen, &found_current);
   print_on_error(WatcherThread::watcher_thread(), st, current, buf, buflen, &found_current);
 
-  PrintOnErrorClosure print_closure(st, current, buf, buflen, &found_current);
-  Universe::heap()->gc_threads_do(&print_closure);
+  if (Universe::heap() != NULL) {
+    PrintOnErrorClosure print_closure(st, current, buf, buflen, &found_current);
+    Universe::heap()->gc_threads_do(&print_closure);
+  }
 
   if (!found_current) {
     st->cr();
     st->print("=>" PTR_FORMAT " (exited) ", p2i(current));
     current->print_on_error(st, buf, buflen);
diff a/src/hotspot/share/runtime/vmOperations.cpp b/src/hotspot/share/runtime/vmOperations.cpp
--- a/src/hotspot/share/runtime/vmOperations.cpp
+++ b/src/hotspot/share/runtime/vmOperations.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -39,10 +39,11 @@
 #include "runtime/arguments.hpp"
 #include "runtime/deoptimization.hpp"
 #include "runtime/frame.inline.hpp"
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/sweeper.hpp"
+#include "runtime/synchronizer.hpp"
 #include "runtime/thread.inline.hpp"
 #include "runtime/threadSMR.inline.hpp"
 #include "runtime/vmOperations.hpp"
 #include "services/threadService.hpp"
 
@@ -91,14 +92,10 @@
   } else {
     CodeCache::clear_inline_caches();
   }
 }
 
-void VM_MarkActiveNMethods::doit() {
-  NMethodSweeper::mark_active_nmethods();
-}
-
 VM_DeoptimizeFrame::VM_DeoptimizeFrame(JavaThread* thread, intptr_t* id, int reason) {
   _thread = thread;
   _id     = id;
   _reason = reason;
 }
@@ -431,10 +428,21 @@
     MonitorLocker ml(&timer, Mutex::_no_safepoint_check_flag);
     ml.wait(10);
   }
 }
 
+bool VM_Exit::doit_prologue() {
+  if (AsyncDeflateIdleMonitors && log_is_enabled(Info, monitorinflation)) {
+    // AsyncDeflateIdleMonitors does a special deflation at the VM_Exit
+    // safepoint in order to reduce the in-use monitor population that
+    // is reported by ObjectSynchronizer::log_in_use_monitor_details()
+    // at VM exit.
+    ObjectSynchronizer::set_is_special_deflation_requested(true);
+  }
+  return true;
+}
+
 void VM_Exit::doit() {
 
   if (VerifyBeforeExit) {
     HandleMark hm(VMThread::vm_thread());
     // Among other things, this ensures that Eden top is correct.
diff a/src/hotspot/share/runtime/vmOperations.hpp b/src/hotspot/share/runtime/vmOperations.hpp
--- a/src/hotspot/share/runtime/vmOperations.hpp
+++ b/src/hotspot/share/runtime/vmOperations.hpp
@@ -247,18 +247,10 @@
 
  protected:
   VM_GTestExecuteAtSafepoint() {}
 };
 
-class VM_MarkActiveNMethods: public VM_Operation {
- public:
-  VM_MarkActiveNMethods() {}
-  VMOp_Type type() const                         { return VMOp_MarkActiveNMethods; }
-  void doit();
-  bool allow_nested_vm_operations() const        { return true; }
-};
-
 // Deopt helper that can deoptimize frames in threads other than the
 // current thread.  Only used through Deoptimization::deoptimize_frame.
 class VM_DeoptimizeFrame: public VM_Operation {
   friend class Deoptimization;
 
@@ -419,10 +411,11 @@
     if (_vm_exited) {
       wait_if_vm_exited();
     }
   }
   VMOp_Type type() const { return VMOp_Exit; }
+  bool doit_prologue();
   void doit();
 };
 
 class VM_PrintCompileQueue: public VM_Operation {
  private:
diff a/src/hotspot/share/runtime/vmStructs.cpp b/src/hotspot/share/runtime/vmStructs.cpp
--- a/src/hotspot/share/runtime/vmStructs.cpp
+++ b/src/hotspot/share/runtime/vmStructs.cpp
@@ -92,10 +92,11 @@
 #include "runtime/os.hpp"
 #include "runtime/perfMemory.hpp"
 #include "runtime/serviceThread.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
+#include "runtime/synchronizer.hpp"
 #include "runtime/thread.inline.hpp"
 #include "runtime/threadSMR.hpp"
 #include "runtime/vframeArray.hpp"
 #include "runtime/vmStructs.hpp"
 #include "utilities/globalDefinitions.hpp"
@@ -897,18 +898,18 @@
   /************/                                                                                                                     \
                                                                                                                                      \
   volatile_nonstatic_field(ObjectMonitor,      _header,                                       markWord)                              \
   unchecked_nonstatic_field(ObjectMonitor,     _object,                                       sizeof(void *)) /* NOTE: no type */    \
   unchecked_nonstatic_field(ObjectMonitor,     _owner,                                        sizeof(void *)) /* NOTE: no type */    \
-  volatile_nonstatic_field(ObjectMonitor,      _contentions,                                  jint)                                  \
+  volatile_nonstatic_field(ObjectMonitor,      _next_om,                                      ObjectMonitor*)                        \
+  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \
+  nonstatic_field(ObjectMonitor,               _contentions,                                  jint)                                  \
   volatile_nonstatic_field(ObjectMonitor,      _waiters,                                      jint)                                  \
   volatile_nonstatic_field(ObjectMonitor,      _recursions,                                   intx)                                  \
-  nonstatic_field(ObjectMonitor,               _next_om,                                      ObjectMonitor*)                        \
-  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \
   nonstatic_field(BasicObjectLock,             _lock,                                         BasicLock)                             \
   nonstatic_field(BasicObjectLock,             _obj,                                          oop)                                   \
-  static_ptr_volatile_field(ObjectSynchronizer, g_block_list,                                 PaddedObjectMonitor*)                  \
+  static_field(ObjectSynchronizer,             g_block_list,                                  PaddedObjectMonitor*)                  \
                                                                                                                                      \
   /*********************/                                                                                                            \
   /* Matcher (C2 only) */                                                                                                            \
   /*********************/                                                                                                            \
                                                                                                                                      \
diff a/src/java.base/share/classes/java/lang/Class.java b/src/java.base/share/classes/java/lang/Class.java
--- a/src/java.base/share/classes/java/lang/Class.java
+++ b/src/java.base/share/classes/java/lang/Class.java
@@ -200,10 +200,12 @@
     private static final int ANNOTATION = 0x00002000;
     private static final int ENUM       = 0x00004000;
     private static final int SYNTHETIC  = 0x00001000;
     private static final int INLINE     = 0x00000100;
 
+    private static final ClassDesc[] EMPTY_CLASS_DESC_ARRAY = new ClassDesc[0];
+
     private static native void registerNatives();
     static {
         registerNatives();
     }
 
@@ -4446,6 +4448,71 @@
      * @see MethodHandles.Lookup#defineHiddenClass
      */
     @HotSpotIntrinsicCandidate
     public native boolean isHidden();
 
+    /**
+     * {@preview Associated with sealed classes, a preview feature of the Java language.
+     *
+     *           This method is associated with <i>sealed classes</i>, a preview
+     *           feature of the Java language. Preview features
+     *           may be removed in a future release, or upgraded to permanent
+     *           features of the Java language.}
+     *
+     * Returns an array containing {@code ClassDesc} objects representing all the
+     * direct subclasses or direct implementation classes permitted to extend or implement this class or interface
+     * if it is sealed. If this {@code Class} object represents a primitive type, {@code void}, an array type,
+     * or a class or interface that is not sealed, an empty array is returned.
+     *
+     * @return an array of class descriptors of all the permitted subclasses of this class or interface
+     *
+     * @jls 8.1 Class Declarations
+     * @jls 9.1 Interface Declarations
+     * @since 15
+     */
+    @jdk.internal.PreviewFeature(feature=jdk.internal.PreviewFeature.Feature.SEALED_CLASSES, essentialAPI=false)
+    public ClassDesc[] permittedSubclasses() {
+        String[] subclassNames;
+        if (isArray() || isPrimitive() || (subclassNames = getPermittedSubclasses0()).length == 0) {
+            return EMPTY_CLASS_DESC_ARRAY;
+        }
+        ClassDesc[] constants = new ClassDesc[subclassNames.length];
+        int i = 0;
+        for (String subclassName : subclassNames) {
+            try {
+                constants[i++] = ClassDesc.of(subclassName.replace('/', '.'));
+            } catch (IllegalArgumentException iae) {
+                throw new InternalError("Invalid type in permitted subclasses information: " + subclassName, iae);
+            }
+        }
+        return constants;
+    }
+
+    /**
+     * * {@preview Associated with sealed classes, a preview feature of the Java language.
+     *
+     *           This method is associated with <i>sealed classes</i>, a preview
+     *           feature of the Java language. Preview features
+     *           may be removed in a future release, or upgraded to permanent
+     *           features of the Java language.}
+     *
+     * Returns {@code true} if and only if this {@code Class} object represents a sealed class or interface.
+     * If this {@code Class} object represents a primitive type, {@code void}, or an array type, this method returns
+     * {@code false}.
+     *
+     * @return {@code true} if and only if this {@code Class} object represents a sealed class or interface.
+     *
+     * @jls 8.1 Class Declarations
+     * @jls 9.1 Interface Declarations
+     * @since 15
+     */
+    @jdk.internal.PreviewFeature(feature=jdk.internal.PreviewFeature.Feature.SEALED_CLASSES, essentialAPI=false)
+    @SuppressWarnings("preview")
+    public boolean isSealed() {
+        if (isArray() || isPrimitive()) {
+            return false;
+        }
+        return permittedSubclasses().length != 0;
+    }
+
+    private native String[] getPermittedSubclasses0();
 }
diff a/src/java.base/share/classes/java/lang/invoke/InvokerBytecodeGenerator.java b/src/java.base/share/classes/java/lang/invoke/InvokerBytecodeGenerator.java
--- a/src/java.base/share/classes/java/lang/invoke/InvokerBytecodeGenerator.java
+++ b/src/java.base/share/classes/java/lang/invoke/InvokerBytecodeGenerator.java
@@ -312,11 +312,11 @@
 
     /**
      * Extract the MemberName of a newly-defined method.
      */
     private MemberName loadMethod(byte[] classFile) {
-        Class<?> invokerClass = LOOKUP.makeHiddenClassDefiner(classFile)
+        Class<?> invokerClass = LOOKUP.makeHiddenClassDefiner(className(), classFile)
                                       .defineClass(true, classDataValues());
         return resolveInvokerMember(invokerClass, invokerName, invokerType);
     }
 
     private static MemberName resolveInvokerMember(Class<?> invokerClass, String name, MethodType type) {
diff a/src/java.base/share/classes/java/lang/invoke/LambdaFormEditor.java b/src/java.base/share/classes/java/lang/invoke/LambdaFormEditor.java
--- a/src/java.base/share/classes/java/lang/invoke/LambdaFormEditor.java
+++ b/src/java.base/share/classes/java/lang/invoke/LambdaFormEditor.java
@@ -60,48 +60,182 @@
         // Always use uncustomized version for editing.
         // It helps caching and customized LambdaForms reuse transformCache field to keep a link to uncustomized version.
         return new LambdaFormEditor(lambdaForm.uncustomize());
     }
 
-    /** A description of a cached transform, possibly associated with the result of the transform.
-     *  The logical content is a sequence of byte values, starting with a kind value.
-     *  The sequence is unterminated, ending with an indefinite number of zero bytes.
-     *  Sequences that are simple (short enough and with small enough values) pack into a 64-bit long.
+    // Transform types
+    // maybe add more for guard with test, catch exception, pointwise type conversions
+    private static final byte
+            BIND_ARG = 1,
+            ADD_ARG = 2,
+            DUP_ARG = 3,
+            SPREAD_ARGS = 4,
+            FILTER_ARG = 5,
+            FILTER_RETURN = 6,
+            FILTER_RETURN_TO_ZERO = 7,
+            COLLECT_ARGS = 8,
+            COLLECT_ARGS_TO_VOID = 9,
+            COLLECT_ARGS_TO_ARRAY = 10,
+            FOLD_ARGS = 11,
+            FOLD_ARGS_TO_VOID = 12,
+            PERMUTE_ARGS = 13,
+            LOCAL_TYPES = 14,
+            FOLD_SELECT_ARGS = 15,
+            FOLD_SELECT_ARGS_TO_VOID = 16,
+            FILTER_SELECT_ARGS = 17,
+            REPEAT_FILTER_ARGS = 18;
+
+    /**
+     * A description of a cached transform, possibly associated with the result of the transform.
+     * The logical content is a sequence of byte values, starting with a kind value.
+     * The sequence is unterminated, ending with an indefinite number of zero bytes.
+     * Sequences that are simple (short enough and with small enough values) pack into a 64-bit long.
+     *
+     * Tightly coupled with the TransformKey class, which is used to lookup existing
+     * Transforms.
      */
     private static final class Transform extends SoftReference<LambdaForm> {
         final long packedBytes;
         final byte[] fullBytes;
 
-        // maybe add more for guard with test, catch exception, pointwise type conversions
-        private static final byte
-                BIND_ARG = 1,
-                ADD_ARG = 2,
-                DUP_ARG = 3,
-                SPREAD_ARGS = 4,
-                FILTER_ARG = 5,
-                FILTER_RETURN = 6,
-                FILTER_RETURN_TO_ZERO = 7,
-                COLLECT_ARGS = 8,
-                COLLECT_ARGS_TO_VOID = 9,
-                COLLECT_ARGS_TO_ARRAY = 10,
-                FOLD_ARGS = 11,
-                FOLD_ARGS_TO_VOID = 12,
-                PERMUTE_ARGS = 13,
-                LOCAL_TYPES = 14,
-                FOLD_SELECT_ARGS = 15,
-                FOLD_SELECT_ARGS_TO_VOID = 16,
-                FILTER_SELECT_ARGS = 17,
-                REPEAT_FILTER_ARGS = 18;
+        private Transform(long packedBytes, byte[] fullBytes, LambdaForm result) {
+            super(result);
+            this.packedBytes = packedBytes;
+            this.fullBytes = fullBytes;
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (obj instanceof TransformKey) {
+                return equals((TransformKey) obj);
+            }
+            return obj instanceof Transform && equals((Transform)obj);
+        }
+
+        private boolean equals(TransformKey that) {
+            return this.packedBytes == that.packedBytes && Arrays.equals(this.fullBytes, that.fullBytes);
+        }
+
+        private boolean equals(Transform that) {
+            return this.packedBytes == that.packedBytes && Arrays.equals(this.fullBytes, that.fullBytes);
+        }
+
+        @Override
+        public int hashCode() {
+            if (packedBytes != 0) {
+                assert(fullBytes == null);
+                return Long.hashCode(packedBytes);
+            }
+            return Arrays.hashCode(fullBytes);
+        }
+
+        @Override
+        public String toString() {
+            StringBuilder buf = new StringBuilder();
+            buf.append(new TransformKey(packedBytes, fullBytes).toString());
+            LambdaForm result = get();
+            if (result != null) {
+                buf.append(" result=");
+                buf.append(result);
+            }
+            return buf.toString();
+        }
+    }
+
+    /**
+     * Used as a lookup key to find existing Transforms
+     */
+    private static final class TransformKey {
+        final long packedBytes;
+        final byte[] fullBytes;
+
+        private TransformKey(long packedBytes) {
+            this.packedBytes = packedBytes;
+            this.fullBytes = null;
+        }
+
+        private TransformKey(byte[] fullBytes) {
+            this.fullBytes = fullBytes;
+            this.packedBytes = 0;
+        }
+
+        private TransformKey(long packedBytes, byte[] fullBytes) {
+            this.fullBytes = fullBytes;
+            this.packedBytes = packedBytes;
+        }
+
+        private static byte bval(int b) {
+            assert((b & 0xFF) == b);  // incoming value must fit in *unsigned* byte
+            return (byte)b;
+        }
+        static TransformKey of(byte k, int b1) {
+            byte b0 = bval(k);
+            if (inRange(b0 | b1))
+                return new TransformKey(packedBytes(b0, b1));
+            else
+                return new TransformKey(fullBytes(b0, b1));
+        }
+        static TransformKey of(byte b0, int b1, int b2) {
+            if (inRange(b0 | b1 | b2))
+                return new TransformKey(packedBytes(b0, b1, b2));
+            else
+                return new TransformKey(fullBytes(b0, b1, b2));
+        }
+        static TransformKey of(byte b0, int b1, int b2, int b3) {
+            if (inRange(b0 | b1 | b2 | b3))
+                return new TransformKey(packedBytes(b0, b1, b2, b3));
+            else
+                return new TransformKey(fullBytes(b0, b1, b2, b3));
+        }
+        private static final byte[] NO_BYTES = {};
+        static TransformKey of(byte kind, int... b123) {
+            return ofBothArrays(kind, b123, NO_BYTES);
+        }
+
+        static TransformKey of(byte kind, int b1, int[] b23456) {
+            byte[] fullBytes = new byte[b23456.length + 2];
+            fullBytes[0] = kind;
+            fullBytes[1] = bval(b1);
+            for (int i = 0; i < b23456.length; i++) {
+                fullBytes[i + 2] = TransformKey.bval(b23456[i]);
+            }
+            long packedBytes = packedBytes(fullBytes);
+            if (packedBytes != 0)
+                return new TransformKey(packedBytes);
+            else
+                return new TransformKey(fullBytes);
+        }
+
+        static TransformKey of(byte kind, int b1, int b2, byte[] b345) {
+            return ofBothArrays(kind, new int[]{ b1, b2 }, b345);
+        }
+        private static TransformKey ofBothArrays(byte kind, int[] b123, byte[] b456) {
+            byte[] fullBytes = new byte[1 + b123.length + b456.length];
+            int i = 0;
+            fullBytes[i++] = bval(kind);
+            for (int bv : b123) {
+                fullBytes[i++] = bval(bv);
+            }
+            for (byte bv : b456) {
+                fullBytes[i++] = bv;
+            }
+            long packedBytes = packedBytes(fullBytes);
+            if (packedBytes != 0)
+                return new TransformKey(packedBytes);
+            else
+                return new TransformKey(fullBytes);
+        }
 
         private static final boolean STRESS_TEST = false; // turn on to disable most packing
         private static final int
                 PACKED_BYTE_SIZE = (STRESS_TEST ? 2 : 4),
                 PACKED_BYTE_MASK = (1 << PACKED_BYTE_SIZE) - 1,
                 PACKED_BYTE_MAX_LENGTH = (STRESS_TEST ? 3 : 64 / PACKED_BYTE_SIZE);
 
         private static long packedBytes(byte[] bytes) {
-            if (bytes.length > PACKED_BYTE_MAX_LENGTH)  return 0;
+            if (!inRange(bytes[0]) || bytes.length > PACKED_BYTE_MAX_LENGTH)
+                return 0;
             long pb = 0;
             int bitset = 0;
             for (int i = 0; i < bytes.length; i++) {
                 int b = bytes[i] & 0xFF;
                 bitset |= b;
@@ -141,92 +275,14 @@
             }
             assert(packedBytes(bytes) == 0);
             return bytes;
         }
 
-        private Transform(long packedBytes, byte[] fullBytes, LambdaForm result) {
-            super(result);
-            this.packedBytes = packedBytes;
-            this.fullBytes = fullBytes;
-        }
-        private Transform(long packedBytes) {
-            this(packedBytes, null, null);
-            assert(packedBytes != 0);
-        }
-        private Transform(byte[] fullBytes) {
-            this(0, fullBytes, null);
-        }
-
-        private static byte bval(int b) {
-            assert((b & 0xFF) == b);  // incoming value must fit in *unsigned* byte
-            return (byte)b;
-        }
-        static Transform of(byte k, int b1) {
-            byte b0 = bval(k);
-            if (inRange(b0 | b1))
-                return new Transform(packedBytes(b0, b1));
-            else
-                return new Transform(fullBytes(b0, b1));
-        }
-        static Transform of(byte b0, int b1, int b2) {
-            if (inRange(b0 | b1 | b2))
-                return new Transform(packedBytes(b0, b1, b2));
-            else
-                return new Transform(fullBytes(b0, b1, b2));
-        }
-        static Transform of(byte b0, int b1, int b2, int b3) {
-            if (inRange(b0 | b1 | b2 | b3))
-                return new Transform(packedBytes(b0, b1, b2, b3));
-            else
-                return new Transform(fullBytes(b0, b1, b2, b3));
-        }
-        private static final byte[] NO_BYTES = {};
-        static Transform of(byte kind, int... b123) {
-            return ofBothArrays(kind, b123, NO_BYTES);
-        }
-        static Transform of(byte kind, int b1, byte[] b234) {
-            return ofBothArrays(kind, new int[]{ b1 }, b234);
-        }
-        static Transform of(byte kind, int b1, int b2, byte[] b345) {
-            return ofBothArrays(kind, new int[]{ b1, b2 }, b345);
-        }
-        private static Transform ofBothArrays(byte kind, int[] b123, byte[] b456) {
-            byte[] fullBytes = new byte[1 + b123.length + b456.length];
-            int i = 0;
-            fullBytes[i++] = bval(kind);
-            for (int bv : b123) {
-                fullBytes[i++] = bval(bv);
-            }
-            for (byte bv : b456) {
-                fullBytes[i++] = bv;
-            }
-            long packedBytes = packedBytes(fullBytes);
-            if (packedBytes != 0)
-                return new Transform(packedBytes);
-            else
-                return new Transform(fullBytes);
-        }
-
         Transform withResult(LambdaForm result) {
             return new Transform(this.packedBytes, this.fullBytes, result);
         }
 
-        @Override
-        public boolean equals(Object obj) {
-            return obj instanceof Transform && equals((Transform)obj);
-        }
-        public boolean equals(Transform that) {
-            return this.packedBytes == that.packedBytes && Arrays.equals(this.fullBytes, that.fullBytes);
-        }
-        @Override
-        public int hashCode() {
-            if (packedBytes != 0) {
-                assert(fullBytes == null);
-                return Long.hashCode(packedBytes);
-            }
-            return Arrays.hashCode(fullBytes);
-        }
         @Override
         public String toString() {
             StringBuilder buf = new StringBuilder();
             long bits = packedBytes;
             if (bits != 0) {
@@ -240,22 +296,41 @@
             }
             if (fullBytes != null) {
                 buf.append("unpacked");
                 buf.append(Arrays.toString(fullBytes));
             }
-            LambdaForm result = get();
-            if (result != null) {
-                buf.append(" result=");
-                buf.append(result);
-            }
             return buf.toString();
         }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (obj instanceof TransformKey) {
+                return equals((TransformKey) obj);
+            }
+            return obj instanceof Transform && equals((Transform)obj);
+        }
+
+        private boolean equals(TransformKey that) {
+            return this.packedBytes == that.packedBytes && Arrays.equals(this.fullBytes, that.fullBytes);
+        }
+
+        private boolean equals(Transform that) {
+            return this.packedBytes == that.packedBytes && Arrays.equals(this.fullBytes, that.fullBytes);
+        }
+
+        @Override
+        public int hashCode() {
+            if (packedBytes != 0) {
+                assert(fullBytes == null);
+                return Long.hashCode(packedBytes);
+            }
+            return Arrays.hashCode(fullBytes);
+        }
     }
 
     /** Find a previously cached transform equivalent to the given one, and return its result. */
-    private LambdaForm getInCache(Transform key) {
-        assert(key.get() == null);
+    private LambdaForm getInCache(TransformKey key) {
         // The transformCache is one of null, Transform, Transform[], or ConcurrentHashMap.
         Object c = lambdaForm.transformCache;
         Transform k = null;
         if (c instanceof ConcurrentHashMap) {
             @SuppressWarnings("unchecked")
@@ -283,24 +358,24 @@
     private static final int MIN_CACHE_ARRAY_SIZE = 4, MAX_CACHE_ARRAY_SIZE = 16;
 
     /** Cache a transform with its result, and return that result.
      *  But if an equivalent transform has already been cached, return its result instead.
      */
-    private LambdaForm putInCache(Transform key, LambdaForm form) {
-        key = key.withResult(form);
+    private LambdaForm putInCache(TransformKey key, LambdaForm form) {
+        Transform transform = key.withResult(form);
         for (int pass = 0; ; pass++) {
             Object c = lambdaForm.transformCache;
             if (c instanceof ConcurrentHashMap) {
                 @SuppressWarnings("unchecked")
                 ConcurrentHashMap<Transform,Transform> m = (ConcurrentHashMap<Transform,Transform>) c;
-                Transform k = m.putIfAbsent(key, key);
+                Transform k = m.putIfAbsent(transform, transform);
                 if (k == null) return form;
                 LambdaForm result = k.get();
                 if (result != null) {
                     return result;
                 } else {
-                    if (m.replace(key, k, key)) {
+                    if (m.replace(transform, k, transform)) {
                         return form;
                     } else {
                         continue;
                     }
                 }
@@ -309,26 +384,26 @@
             synchronized (lambdaForm) {
                 c = lambdaForm.transformCache;
                 if (c instanceof ConcurrentHashMap)
                     continue;
                 if (c == null) {
-                    lambdaForm.transformCache = key;
+                    lambdaForm.transformCache = transform;
                     return form;
                 }
                 Transform[] ta;
                 if (c instanceof Transform) {
                     Transform k = (Transform)c;
                     if (k.equals(key)) {
                         LambdaForm result = k.get();
                         if (result == null) {
-                            lambdaForm.transformCache = key;
+                            lambdaForm.transformCache = transform;
                             return form;
                         } else {
                             return result;
                         }
                     } else if (k.get() == null) { // overwrite stale entry
-                        lambdaForm.transformCache = key;
+                        lambdaForm.transformCache = transform;
                         return form;
                     }
                     // expand one-element cache to small array
                     ta = new Transform[MIN_CACHE_ARRAY_SIZE];
                     ta[0] = k;
@@ -343,14 +418,14 @@
                 for (i = 0; i < len; i++) {
                     Transform k = ta[i];
                     if (k == null) {
                         break;
                     }
-                    if (k.equals(key)) {
+                    if (k.equals(transform)) {
                         LambdaForm result = k.get();
                         if (result == null) {
-                            ta[i] = key;
+                            ta[i] = transform;
                             return form;
                         } else {
                             return result;
                         }
                     } else if (stale < 0 && k.get() == null) {
@@ -371,11 +446,11 @@
                     lambdaForm.transformCache = m;
                     // The second iteration will update for this query, concurrently.
                     continue;
                 }
                 int idx = (stale >= 0) ? stale : i;
-                ta[idx] = key;
+                ta[idx] = transform;
                 return form;
             }
         }
     }
 
@@ -441,11 +516,11 @@
 
     /// Editing methods for lambda forms.
     // Each editing method can (potentially) cache the edited LF so that it can be reused later.
 
     LambdaForm bindArgumentForm(int pos) {
-        Transform key = Transform.of(Transform.BIND_ARG, pos);
+        TransformKey key = TransformKey.of(BIND_ARG, pos);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.parameterConstraint(0) == newSpeciesData(lambdaForm.parameterType(pos)));
             return form;
         }
@@ -476,11 +551,11 @@
         form = buf.endEdit();
         return putInCache(key, form);
     }
 
     LambdaForm addArgumentForm(int pos, BasicType type) {
-        Transform key = Transform.of(Transform.ADD_ARG, pos, type.ordinal());
+        TransformKey key = TransformKey.of(ADD_ARG, pos, type.ordinal());
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity+1);
             assert(form.parameterType(pos) == type);
             return form;
@@ -493,11 +568,11 @@
         form = buf.endEdit();
         return putInCache(key, form);
     }
 
     LambdaForm dupArgumentForm(int srcPos, int dstPos) {
-        Transform key = Transform.of(Transform.DUP_ARG, srcPos, dstPos);
+        TransformKey key = TransformKey.of(DUP_ARG, srcPos, dstPos);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity-1);
             return form;
         }
@@ -522,11 +597,11 @@
         if (bt.basicTypeClass() != elementType) {
             if (elementType.isPrimitive()) {
                 elementTypeKey = TYPE_LIMIT + Wrapper.forPrimitiveType(elementType).ordinal();
             }
         }
-        Transform key = Transform.of(Transform.SPREAD_ARGS, pos, elementTypeKey, arrayLength);
+        TransformKey key = TransformKey.of(SPREAD_ARGS, pos, elementTypeKey, arrayLength);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity - arrayLength + 1);
             return form;
         }
@@ -561,16 +636,14 @@
         int collectorArity = collectorType.parameterCount();
         boolean dropResult = (collectorType.returnType() == void.class);
         if (collectorArity == 1 && !dropResult) {
             return filterArgumentForm(pos, basicType(collectorType.parameterType(0)));
         }
-        byte[] newTypes = BasicType.basicTypesOrd(collectorType.parameterArray());
-        byte kind = (dropResult
-                ? Transform.COLLECT_ARGS_TO_VOID
-                : Transform.COLLECT_ARGS);
+        byte[] newTypes = BasicType.basicTypesOrd(collectorType.ptypes());
+        byte kind = (dropResult ? COLLECT_ARGS_TO_VOID : COLLECT_ARGS);
         if (dropResult && collectorArity == 0)  pos = 1;  // pure side effect
-        Transform key = Transform.of(kind, pos, collectorArity, newTypes);
+        TransformKey key = TransformKey.of(kind, pos, collectorArity, newTypes);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity - (dropResult ? 0 : 1) + collectorArity);
             return form;
         }
@@ -591,12 +664,12 @@
             if (!elementType.isPrimitive())
                 return null;
             argTypeKey = TYPE_LIMIT + Wrapper.forPrimitiveType(elementType).ordinal();
         }
         assert(collectorType.parameterList().equals(Collections.nCopies(collectorArity, elementType)));
-        byte kind = Transform.COLLECT_ARGS_TO_ARRAY;
-        Transform key = Transform.of(kind, pos, collectorArity, argTypeKey);
+        byte kind = COLLECT_ARGS_TO_ARRAY;
+        TransformKey key = TransformKey.of(kind, pos, collectorArity, argTypeKey);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity - 1 + collectorArity);
             return form;
         }
@@ -628,11 +701,11 @@
         form = buf.endEdit();
         return putInCache(key, form);
     }
 
     LambdaForm filterArgumentForm(int pos, BasicType newType) {
-        Transform key = Transform.of(Transform.FILTER_ARG, pos, newType.ordinal());
+        TransformKey key = TransformKey.of(FILTER_ARG, pos, newType.ordinal());
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity);
             assert(form.parameterType(pos) == newType);
             return form;
@@ -652,17 +725,11 @@
      * by reapplying of {@code filterArgumentForm(int,BasicType)}, and should do
      * no worse in the worst case.
      */
     LambdaForm filterRepeatedArgumentForm(BasicType newType, int... argPositions) {
         assert (argPositions.length > 1);
-        byte[] keyArgs = new byte[argPositions.length + 2];
-        keyArgs[0] = Transform.REPEAT_FILTER_ARGS;
-        keyArgs[argPositions.length + 1] = (byte)newType.ordinal();
-        for (int i = 0; i < argPositions.length; i++) {
-            keyArgs[i + 1] = (byte)argPositions[i];
-        }
-        Transform key = new Transform(keyArgs);
+        TransformKey key = TransformKey.of(REPEAT_FILTER_ARGS, newType.ordinal(), argPositions);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity &&
                     formParametersMatch(form, newType, argPositions));
             return form;
@@ -871,12 +938,12 @@
 
         return buf.endEdit();
     }
 
     LambdaForm filterReturnForm(BasicType newType, boolean constantZero) {
-        byte kind = (constantZero ? Transform.FILTER_RETURN_TO_ZERO : Transform.FILTER_RETURN);
-        Transform key = Transform.of(kind, newType.ordinal());
+        byte kind = (constantZero ? FILTER_RETURN_TO_ZERO : FILTER_RETURN);
+        TransformKey key = TransformKey.of(kind, newType.ordinal());
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity);
             assert(form.returnType() == newType);
             return form;
@@ -921,43 +988,88 @@
 
         form = buf.endEdit();
         return putInCache(key, form);
     }
 
+    LambdaForm collectReturnValueForm(MethodType combinerType) {
+        LambdaFormBuffer buf = buffer();
+        buf.startEdit();
+        int combinerArity = combinerType.parameterCount();
+        int argPos = lambdaForm.arity();
+        int exprPos = lambdaForm.names.length;
+
+        BoundMethodHandle.SpeciesData oldData = oldSpeciesData();
+        BoundMethodHandle.SpeciesData newData = newSpeciesData(L_TYPE);
+
+        // The newly created LF will run with a different BMH.
+        // Switch over any pre-existing BMH field references to the new BMH class.
+        Name oldBaseAddress = lambdaForm.parameter(0);  // BMH holding the values
+        buf.replaceFunctions(oldData.getterFunctions(), newData.getterFunctions(), oldBaseAddress);
+        Name newBaseAddress = oldBaseAddress.withConstraint(newData);
+        buf.renameParameter(0, newBaseAddress);
+
+        // Now we set up the call to the filter
+        Name getCombiner = new Name(newData.getterFunction(oldData.fieldCount()), newBaseAddress);
+
+        Object[] combinerArgs = new Object[combinerArity + 1];
+        combinerArgs[0] = getCombiner; // first (synthetic) argument should be the MH that acts as a target of the invoke
+
+        // set up additional adapter parameters (in case the combiner is not a unary function)
+        Name[] newParams = new Name[combinerArity - 1]; // last combiner parameter is the return adapter
+        for (int i = 0; i < newParams.length; i++) {
+            newParams[i] = new Name(argPos + i, basicType(combinerType.parameterType(i)));
+        }
+
+        // set up remaining filter parameters to point to the corresponding adapter parameters (see above)
+        System.arraycopy(newParams, 0,
+                combinerArgs, 1, combinerArity - 1);
+
+        // the last filter argument is set to point at the result of the target method handle
+        combinerArgs[combinerArity] = buf.name(lambdaForm.names.length - 1);
+        Name callCombiner = new Name(combinerType, combinerArgs);
+
+        // insert the two new expressions
+        buf.insertExpression(exprPos, getCombiner);
+        buf.insertExpression(exprPos + 1, callCombiner);
+
+        // insert additional arguments
+        int insPos = argPos;
+        for (Name newParam : newParams) {
+            buf.insertParameter(insPos++, newParam);
+        }
+
+        buf.setResult(callCombiner);
+        return buf.endEdit();
+    }
+
     LambdaForm foldArgumentsForm(int foldPos, boolean dropResult, MethodType combinerType) {
         int combinerArity = combinerType.parameterCount();
-        byte kind = (dropResult ? Transform.FOLD_ARGS_TO_VOID : Transform.FOLD_ARGS);
-        Transform key = Transform.of(kind, foldPos, combinerArity);
+        byte kind = (dropResult ? FOLD_ARGS_TO_VOID : FOLD_ARGS);
+        TransformKey key = TransformKey.of(kind, foldPos, combinerArity);
         LambdaForm form = getInCache(key);
         if (form != null) {
-            assert(form.arity == lambdaForm.arity - (kind == Transform.FOLD_ARGS ? 1 : 0));
+            assert(form.arity == lambdaForm.arity - (kind == FOLD_ARGS ? 1 : 0));
             return form;
         }
         form = makeArgumentCombinationForm(foldPos, combinerType, true, dropResult);
         return putInCache(key, form);
     }
 
     LambdaForm foldArgumentsForm(int foldPos, boolean dropResult, MethodType combinerType, int ... argPositions) {
-        byte kind = (dropResult ? Transform.FOLD_SELECT_ARGS_TO_VOID
-                                : Transform.FOLD_SELECT_ARGS);
-        int[] keyArgs = Arrays.copyOf(argPositions, argPositions.length + 1);
-        keyArgs[argPositions.length] = foldPos;
-        Transform key = Transform.of(kind, keyArgs);
+        byte kind = (dropResult ? FOLD_SELECT_ARGS_TO_VOID : FOLD_SELECT_ARGS);
+        TransformKey key = TransformKey.of(kind, foldPos, argPositions);
         LambdaForm form = getInCache(key);
         if (form != null) {
-            assert(form.arity == lambdaForm.arity - (kind == Transform.FOLD_SELECT_ARGS ? 1 : 0));
+            assert(form.arity == lambdaForm.arity - (kind == FOLD_SELECT_ARGS ? 1 : 0));
             return form;
         }
         form = makeArgumentCombinationForm(foldPos, combinerType, argPositions, true, dropResult);
         return putInCache(key, form);
     }
 
     LambdaForm filterArgumentsForm(int filterPos, MethodType combinerType, int ... argPositions) {
-        byte kind = Transform.FILTER_SELECT_ARGS;
-        int[] keyArgs = Arrays.copyOf(argPositions, argPositions.length + 1);
-        keyArgs[argPositions.length] = filterPos;
-        Transform key = Transform.of(kind, keyArgs);
+        TransformKey key = TransformKey.of(FILTER_SELECT_ARGS, filterPos, argPositions);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == lambdaForm.arity);
             return form;
         }
@@ -976,11 +1088,11 @@
             if (inArg != i)  nullPerm = false;
             inTypes = Math.max(inTypes, inArg+1);
         }
         assert(skip + reorder.length == lambdaForm.arity);
         if (nullPerm)  return lambdaForm;  // do not bother to cache
-        Transform key = Transform.of(Transform.PERMUTE_ARGS, reorder);
+        TransformKey key = TransformKey.of(PERMUTE_ARGS, reorder);
         LambdaForm form = getInCache(key);
         if (form != null) {
             assert(form.arity == skip+inTypes) : form;
             return form;
         }
@@ -1045,11 +1157,11 @@
     LambdaForm noteLoopLocalTypesForm(int pos, BasicType[] localTypes) {
         assert(lambdaForm.isLoop(pos));
         int[] desc = BasicType.basicTypeOrds(localTypes);
         desc = Arrays.copyOf(desc, desc.length + 1);
         desc[desc.length - 1] = pos;
-        Transform key = Transform.of(Transform.LOCAL_TYPES, desc);
+        TransformKey key = TransformKey.of(LOCAL_TYPES, desc);
         LambdaForm form = getInCache(key);
         if (form != null) {
             return form;
         }
 
diff a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
@@ -29,10 +29,11 @@
 import jdk.internal.access.SharedSecrets;
 import jdk.internal.misc.VM;
 import jdk.internal.module.IllegalAccessLogger;
 import jdk.internal.org.objectweb.asm.ClassReader;
 import jdk.internal.org.objectweb.asm.Opcodes;
+import jdk.internal.org.objectweb.asm.Type;
 import jdk.internal.reflect.CallerSensitive;
 import jdk.internal.reflect.Reflection;
 import jdk.internal.vm.annotation.ForceInline;
 import sun.invoke.util.ValueConversions;
 import sun.invoke.util.VerifyAccess;
@@ -1659,12 +1660,13 @@
          *
          * @param bytes the class bytes
          * @return the {@code Class} object for the class
          * @throws IllegalAccessException if this lookup does not have {@code PACKAGE} access
          * @throws ClassFormatError if {@code bytes} is not a {@code ClassFile} structure
-         * @throws IllegalArgumentException the bytes are for a class in a different package
-         * to the lookup class
+         * @throws IllegalArgumentException if {@code bytes} denotes a class in a different package
+         * than the lookup class or {@code bytes} is not a class or interface
+         * ({@code ACC_MODULE} flag is set in the value of the {@code access_flags} item)
          * @throws VerifyError if the newly created class cannot be verified
          * @throws LinkageError if the newly created class cannot be linked for any other reason
          * @throws SecurityException if a security manager is present and it
          *                           <a href="MethodHandles.Lookup.html#secmgr">refuses access</a>
          * @throws NullPointerException if {@code bytes} is {@code null}
@@ -1921,12 +1923,13 @@
          * {@linkplain #hasFullPrivilegeAccess() full privilege} access
          * @throws SecurityException if a security manager is present and it
          * <a href="MethodHandles.Lookup.html#secmgr">refuses access</a>
          * @throws ClassFormatError if {@code bytes} is not a {@code ClassFile} structure
          * @throws UnsupportedClassVersionError if {@code bytes} is not of a supported major or minor version
-         * @throws IllegalArgumentException if {@code bytes} is not a class or interface or
-         * {@bytes} denotes a class in a different package than the lookup class
+         * @throws IllegalArgumentException if {@code bytes} denotes a class in a different package
+         * than the lookup class or {@code bytes} is not a class or interface
+         * ({@code ACC_MODULE} flag is set in the value of the {@code access_flags} item)
          * @throws IncompatibleClassChangeError if the class or interface named as
          * the direct superclass of {@code C} is in fact an interface, or if any of the classes
          * or interfaces named as direct superinterfaces of {@code C} are not in fact interfaces
          * @throws ClassCircularityError if any of the superclasses or superinterfaces of
          * {@code C} is {@code C} itself
@@ -1985,12 +1988,13 @@
          * {@linkplain #hasFullPrivilegeAccess() full privilege} access
          * @throws SecurityException if a security manager is present and it
          * <a href="MethodHandles.Lookup.html#secmgr">refuses access</a>
          * @throws ClassFormatError if {@code bytes} is not a {@code ClassFile} structure
          * @throws UnsupportedClassVersionError if {@code bytes} is not of a supported major or minor version
-         * @throws IllegalArgumentException if {@code bytes} is not a class or interface or
-         * {@bytes} denotes a class in a different package than the lookup class
+         * @throws IllegalArgumentException if {@code bytes} denotes a class in a different package
+         * than the lookup class or {@code bytes} is not a class or interface
+         * ({@code ACC_MODULE} flag is set in the value of the {@code access_flags} item)
          * @throws IncompatibleClassChangeError if the class or interface named as
          * the direct superclass of {@code C} is in fact an interface, or if any of the classes
          * or interfaces named as direct superinterfaces of {@code C} are not in fact interfaces
          * @throws ClassCircularityError if any of the superclasses or superinterfaces of
          * {@code C} is {@code C} itself
@@ -2016,39 +2020,98 @@
 
             return makeHiddenClassDefiner(bytes.clone(), Set.of(options), false)
                        .defineClassAsLookup(true, classData);
         }
 
-        /*
-         * Validates the given bytes to be a class or interface and the class name
-         * is in the same package as the lookup class.
-         *
-         * This method returns the class name.
-         */
-        private String validateAndGetClassName(byte[] bytes) {
-            try {
-                ClassReader reader = new ClassReader(bytes);
-                if ((reader.getAccess() & Opcodes.ACC_MODULE) != 0) {
+        static class ClassFile {
+            final String name;
+            final int accessFlags;
+            final byte[] bytes;
+            ClassFile(String name, int accessFlags, byte[] bytes) {
+                this.name = name;
+                this.accessFlags = accessFlags;
+                this.bytes = bytes;
+            }
+
+            static ClassFile newInstanceNoCheck(String name, byte[] bytes) {
+                return new ClassFile(name, 0, bytes);
+            }
+
+            /**
+             * This method checks the class file version and the structure of `this_class`.
+             * and checks if the bytes is a class or interface (ACC_MODULE flag not set)
+             * that is in the named package.
+             *
+             * @throws IllegalArgumentException if ACC_MODULE flag is set in access flags
+             * or the class is not in the given package name.
+             */
+            static ClassFile newInstance(byte[] bytes, String pkgName) {
+                int magic = readInt(bytes, 0);
+                if (magic != 0xCAFEBABE) {
+                    throw new ClassFormatError("Incompatible magic value: " + magic);
+                }
+                int minor = readUnsignedShort(bytes, 4);
+                int major = readUnsignedShort(bytes, 6);
+                if (!VM.isSupportedClassFileVersion(major, minor)) {
+                    throw new UnsupportedClassVersionError("Unsupported class file version " + major + "." + minor);
+                }
+
+                String name;
+                int accessFlags;
+                try {
+                    ClassReader reader = new ClassReader(bytes);
+                    // ClassReader::getClassName does not check if `this_class` is CONSTANT_Class_info
+                    // workaround to read `this_class` using readConst and validate the value
+                    int thisClass = reader.readUnsignedShort(reader.header + 2);
+                    Object constant = reader.readConst(thisClass, new char[reader.getMaxStringLength()]);
+                    if (!(constant instanceof Type)) {
+                        throw new ClassFormatError("this_class item: #" + thisClass + " not a CONSTANT_Class_info");
+                    }
+                    Type type = ((Type) constant);
+                    if (!type.getDescriptor().startsWith("L")) {
+                        throw new ClassFormatError("this_class item: #" + thisClass + " not a CONSTANT_Class_info");
+                    }
+                    name = type.getClassName();
+                    accessFlags = reader.readUnsignedShort(reader.header);
+                } catch (RuntimeException e) {
+                    // ASM exceptions are poorly specified
+                    ClassFormatError cfe = new ClassFormatError();
+                    cfe.initCause(e);
+                    throw cfe;
+                }
+
+                // must be a class or interface
+                if ((accessFlags & Opcodes.ACC_MODULE) != 0) {
                     throw newIllegalArgumentException("Not a class or interface: ACC_MODULE flag is set");
                 }
-                String name = reader.getClassName().replace('/', '.');
+
+                // check if it's in the named package
                 int index = name.lastIndexOf('.');
                 String pn = (index == -1) ? "" : name.substring(0, index);
-                if (!pn.equals(lookupClass.getPackageName())) {
-                    throw newIllegalArgumentException(name + " not in same package as lookup class: " +
-                            lookupClass.getName());
+                if (!pn.equals(pkgName)) {
+                    throw newIllegalArgumentException(name + " not in same package as lookup class");
                 }
-                return name;
-            } catch (IllegalArgumentException e) {
-                throw e;
-            } catch (RuntimeException e) {
-                // ASM exceptions are poorly specified
-                ClassFormatError cfe = new ClassFormatError();
-                cfe.initCause(e);
-                throw cfe;
+
+                return new ClassFile(name, accessFlags, bytes);
+            }
+
+            private static int readInt(byte[] bytes, int offset) {
+                if ((offset+4) > bytes.length) {
+                    throw new ClassFormatError("Invalid ClassFile structure");
+                }
+                return ((bytes[offset] & 0xFF) << 24)
+                        | ((bytes[offset + 1] & 0xFF) << 16)
+                        | ((bytes[offset + 2] & 0xFF) << 8)
+                        | (bytes[offset + 3] & 0xFF);
             }
-        }
+
+            private static int readUnsignedShort(byte[] bytes, int offset) {
+                if ((offset+2) > bytes.length) {
+                    throw new ClassFormatError("Invalid ClassFile structure");
+                }
+                return ((bytes[offset] & 0xFF) << 8) | (bytes[offset + 1] & 0xFF);
+            }
 
 
         /*
          * Returns a ClassDefiner that creates a {@code Class} object of a normal class
          * from the given bytes.
@@ -2058,11 +2121,12 @@
          *
          * @throws IllegalArgumentException if {@code bytes} is not a class or interface or
          * {@bytes} denotes a class in a different package than the lookup class
          */
         private ClassDefiner makeClassDefiner(byte[] bytes) {
-            return new ClassDefiner(this, validateAndGetClassName(bytes), bytes, STRONG_LOADER_LINK);
+            ClassFile cf = ClassFile.newInstance(bytes, lookupClass().getPackageName());
+            return new ClassDefiner(this, cf, STRONG_LOADER_LINK);
         }
 
         /**
          * Returns a ClassDefiner that creates a {@code Class} object of a hidden class
          * from the given bytes.  The name must be in the same package as the lookup class.
@@ -2075,11 +2139,12 @@
          *
          * @throws IllegalArgumentException if {@code bytes} is not a class or interface or
          * {@bytes} denotes a class in a different package than the lookup class
          */
         ClassDefiner makeHiddenClassDefiner(byte[] bytes) {
-            return makeHiddenClassDefiner(validateAndGetClassName(bytes), bytes, Set.of(), false);
+            ClassFile cf = ClassFile.newInstance(bytes, lookupClass().getPackageName());
+            return makeHiddenClassDefiner(cf, Set.of(), false);
         }
 
         /**
          * Returns a ClassDefiner that creates a {@code Class} object of a hidden class
          * from the given bytes and options.
@@ -2097,11 +2162,12 @@
          * {@bytes} denotes a class in a different package than the lookup class
          */
         ClassDefiner makeHiddenClassDefiner(byte[] bytes,
                                             Set<ClassOption> options,
                                             boolean accessVmAnnotations) {
-            return makeHiddenClassDefiner(validateAndGetClassName(bytes), bytes, options, accessVmAnnotations);
+            ClassFile cf = ClassFile.newInstance(bytes, lookupClass().getPackageName());
+            return makeHiddenClassDefiner(cf, options, accessVmAnnotations);
         }
 
         /**
          * Returns a ClassDefiner that creates a {@code Class} object of a hidden class
          * from the given bytes.  No package name check on the given name.
@@ -2109,48 +2175,47 @@
          * @param name    fully-qualified name that specifies the prefix of the hidden class
          * @param bytes   class bytes
          * @return ClassDefiner that defines a hidden class of the given bytes.
          */
         ClassDefiner makeHiddenClassDefiner(String name, byte[] bytes) {
-            return makeHiddenClassDefiner(name, bytes, Set.of(), false);
+            // skip name and access flags validation
+            return makeHiddenClassDefiner(ClassFile.newInstanceNoCheck(name, bytes), Set.of(), false);
         }
 
         /**
          * Returns a ClassDefiner that creates a {@code Class} object of a hidden class
-         * from the given bytes and options.  No package name check on the given name.
+         * from the given class file and options.
          *
-         * @param name the name of the class and the name in the class bytes is ignored.
-         * @param bytes class bytes
+         * @param cf ClassFile
          * @param options class options
          * @param accessVmAnnotations true to give the hidden class access to VM annotations
          */
-        ClassDefiner makeHiddenClassDefiner(String name,
-                                            byte[] bytes,
-                                            Set<ClassOption> options,
-                                            boolean accessVmAnnotations) {
+        private ClassDefiner makeHiddenClassDefiner(ClassFile cf,
+                                                    Set<ClassOption> options,
+                                                    boolean accessVmAnnotations) {
             int flags = HIDDEN_CLASS | ClassOption.optionsToFlag(options);
             if (accessVmAnnotations | VM.isSystemDomainLoader(lookupClass.getClassLoader())) {
                 // jdk.internal.vm.annotations are permitted for classes
                 // defined to boot loader and platform loader
                 flags |= ACCESS_VM_ANNOTATIONS;
             }
 
-            return new ClassDefiner(this, name, bytes, flags);
+            return new ClassDefiner(this, cf, flags);
         }
 
         static class ClassDefiner {
             private final Lookup lookup;
             private final String name;
             private final byte[] bytes;
             private final int classFlags;
 
-            private ClassDefiner(Lookup lookup, String name, byte[] bytes, int flags) {
+            private ClassDefiner(Lookup lookup, ClassFile cf, int flags) {
                 assert ((flags & HIDDEN_CLASS) != 0 || (flags & STRONG_LOADER_LINK) == STRONG_LOADER_LINK);
                 this.lookup = lookup;
-                this.bytes = bytes;
+                this.bytes = cf.bytes;
+                this.name = cf.name;
                 this.classFlags = flags;
-                this.name = name;
             }
 
             String className() {
                 return name;
             }
@@ -5507,10 +5572,44 @@
                 ? (rtype != void.class)
                 : (rtype != filterType.parameterType(0) || filterValues != 1))
             throw newIllegalArgumentException("target and filter types do not match", targetType, filterType);
     }
 
+    /**
+     * Filter the return value of a target method handle with a filter function. The filter function is
+     * applied to the return value of the original handle; if the filter specifies more than one parameters,
+     * then any remaining parameter is appended to the adapter handle. In other words, the adaptation works
+     * as follows:
+     * <blockquote><pre>{@code
+     * T target(A...)
+     * V filter(B... , T)
+     * V adapter(A... a, B... b) {
+     *     T t = target(a...);
+     *     return filter(b..., t);
+     * }</pre></blockquote>
+     * <p>
+     * If the filter handle is a unary function, then this method behaves like {@link #filterReturnValue(MethodHandle, MethodHandle)}.
+     *
+     * @param target the target method handle
+     * @param filter the filter method handle
+     * @return the adapter method handle
+     */
+    /* package */ static MethodHandle collectReturnValue(MethodHandle target, MethodHandle filter) {
+        MethodType targetType = target.type();
+        MethodType filterType = filter.type();
+        BoundMethodHandle result = target.rebind();
+        LambdaForm lform = result.editor().collectReturnValueForm(filterType.basicType());
+        MethodType newType = targetType.changeReturnType(filterType.returnType());
+        if (filterType.parameterList().size() > 1) {
+            for (int i = 0 ; i < filterType.parameterList().size() - 1 ; i++) {
+                newType = newType.appendParameterTypes(filterType.parameterType(i));
+            }
+        }
+        result = result.copyWithExtendL(newType, lform, filter);
+        return result;
+    }
+
     /**
      * Adapts a target method handle by pre-processing
      * some of its arguments, and then calling the target with
      * the result of the pre-processing, inserted into the original
      * sequence of arguments.
diff a/src/java.base/share/classes/java/lang/invoke/VarHandles.java b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/VarHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
@@ -372,47 +372,101 @@
         Objects.nonNull(filterFromTarget);
         //check that from/to filters do not throw checked exceptions
         noCheckedExceptions(filterToTarget);
         noCheckedExceptions(filterFromTarget);
 
+        List<Class<?>> newCoordinates = new ArrayList<>();
+        List<Class<?>> additionalCoordinates = new ArrayList<>();
+        newCoordinates.addAll(target.coordinateTypes());
+
         //check that from/to filters have right signatures
-        if (filterFromTarget.type().parameterCount() != 1) {
+        if (filterFromTarget.type().parameterCount() != filterToTarget.type().parameterCount()) {
+            throw newIllegalArgumentException("filterFromTarget and filterToTarget have different arity", filterFromTarget.type(), filterToTarget.type());
+        } else if (filterFromTarget.type().parameterCount() < 1) {
             throw newIllegalArgumentException("filterFromTarget filter type has wrong arity", filterFromTarget.type());
-        } else if (filterToTarget.type().parameterCount() != 1) {
+        } else if (filterToTarget.type().parameterCount() < 1) {
             throw newIllegalArgumentException("filterToTarget filter type has wrong arity", filterFromTarget.type());
-        } else if (filterFromTarget.type().parameterType(0) != filterToTarget.type().returnType() ||
-                filterToTarget.type().parameterType(0) != filterFromTarget.type().returnType()) {
+        } else if (filterFromTarget.type().lastParameterType() != filterToTarget.type().returnType() ||
+                filterToTarget.type().lastParameterType() != filterFromTarget.type().returnType()) {
             throw newIllegalArgumentException("filterFromTarget and filterToTarget filter types do not match", filterFromTarget.type(), filterToTarget.type());
-        } else if (target.varType() != filterFromTarget.type().parameterType(0)) {
+        } else if (target.varType() != filterFromTarget.type().lastParameterType()) {
             throw newIllegalArgumentException("filterFromTarget filter type does not match target var handle type", filterFromTarget.type(), target.varType());
         } else if (target.varType() != filterToTarget.type().returnType()) {
             throw newIllegalArgumentException("filterFromTarget filter type does not match target var handle type", filterToTarget.type(), target.varType());
+        } else if (filterFromTarget.type().parameterCount() > 1) {
+            for (int i = 0 ; i < filterFromTarget.type().parameterCount() - 1 ; i++) {
+                if (filterFromTarget.type().parameterType(i) != filterToTarget.type().parameterType(i)) {
+                    throw newIllegalArgumentException("filterFromTarget and filterToTarget filter types do not match", filterFromTarget.type(), filterToTarget.type());
+                } else {
+                    newCoordinates.add(filterFromTarget.type().parameterType(i));
+                    additionalCoordinates.add((filterFromTarget.type().parameterType(i)));
+                }
+            }
         }
 
-        return new IndirectVarHandle(target, filterFromTarget.type().returnType(), target.coordinateTypes().toArray(new Class<?>[0]),
+        return new IndirectVarHandle(target, filterFromTarget.type().returnType(), newCoordinates.toArray(new Class<?>[0]),
                 (mode, modeHandle) -> {
                     int lastParameterPos = modeHandle.type().parameterCount() - 1;
                     return switch (mode.at) {
-                        case GET -> MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
-                        case SET -> MethodHandles.filterArgument(modeHandle, lastParameterPos, filterToTarget);
+                        case GET -> MethodHandles.collectReturnValue(modeHandle, filterFromTarget);
+                        case SET -> MethodHandles.collectArguments(modeHandle, lastParameterPos, filterToTarget);
                         case GET_AND_UPDATE -> {
-                            MethodHandle adapter = MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
-                            yield MethodHandles.filterArgument(adapter, lastParameterPos, filterToTarget);
+                            MethodHandle adapter = MethodHandles.collectReturnValue(modeHandle, filterFromTarget);
+                            MethodHandle res = MethodHandles.collectArguments(adapter, lastParameterPos, filterToTarget);
+                            if (additionalCoordinates.size() > 0) {
+                                res = joinDuplicateArgs(res, lastParameterPos,
+                                        lastParameterPos + additionalCoordinates.size() + 1,
+                                        additionalCoordinates.size());
+                            }
+                            yield res;
                         }
                         case COMPARE_AND_EXCHANGE -> {
-                            MethodHandle adapter = MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
-                            adapter = MethodHandles.filterArgument(adapter, lastParameterPos, filterToTarget);
-                            yield MethodHandles.filterArgument(adapter, lastParameterPos - 1, filterToTarget);
+                            MethodHandle adapter = MethodHandles.collectReturnValue(modeHandle, filterFromTarget);
+                            adapter = MethodHandles.collectArguments(adapter, lastParameterPos, filterToTarget);
+                            if (additionalCoordinates.size() > 0) {
+                                adapter = joinDuplicateArgs(adapter, lastParameterPos,
+                                        lastParameterPos + additionalCoordinates.size() + 1,
+                                        additionalCoordinates.size());
+                            }
+                            MethodHandle res = MethodHandles.collectArguments(adapter, lastParameterPos - 1, filterToTarget);
+                            if (additionalCoordinates.size() > 0) {
+                                res = joinDuplicateArgs(res, lastParameterPos - 1,
+                                        lastParameterPos + additionalCoordinates.size(),
+                                        additionalCoordinates.size());
+                            }
+                            yield res;
                         }
                         case COMPARE_AND_SET -> {
-                            MethodHandle adapter = MethodHandles.filterArgument(modeHandle, lastParameterPos, filterToTarget);
-                            yield MethodHandles.filterArgument(adapter, lastParameterPos - 1, filterToTarget);
+                            MethodHandle adapter = MethodHandles.collectArguments(modeHandle, lastParameterPos, filterToTarget);
+                            MethodHandle res = MethodHandles.collectArguments(adapter, lastParameterPos - 1, filterToTarget);
+                            if (additionalCoordinates.size() > 0) {
+                                res = joinDuplicateArgs(res, lastParameterPos - 1,
+                                        lastParameterPos + additionalCoordinates.size(),
+                                        additionalCoordinates.size());
+                            }
+                            yield res;
                         }
                     };
                 });
     }
 
+    private static MethodHandle joinDuplicateArgs(MethodHandle handle, int originalStart, int dropStart, int length) {
+        int[] perms = new int[handle.type().parameterCount()];
+        for (int i = 0 ; i < dropStart; i++) {
+            perms[i] = i;
+        }
+        for (int i = 0 ; i < length ; i++) {
+            perms[dropStart + i] = originalStart + i;
+        }
+        for (int i = dropStart + length ; i < perms.length ; i++) {
+            perms[i] = i - length;
+        }
+        return MethodHandles.permuteArguments(handle,
+                handle.type().dropParameterTypes(dropStart, dropStart + length),
+                perms);
+    }
+
     public static VarHandle filterCoordinates(VarHandle target, int pos, MethodHandle... filters) {
         Objects.nonNull(target);
         Objects.nonNull(filters);
 
         List<Class<?>> targetCoordinates = target.coordinateTypes();
@@ -558,21 +612,27 @@
     }
 
     private static void noCheckedExceptions(MethodHandle handle) {
         if (handle instanceof DirectMethodHandle) {
             DirectMethodHandle directHandle = (DirectMethodHandle)handle;
-            MethodHandleInfo info = MethodHandles.Lookup.IMPL_LOOKUP.revealDirect(directHandle);
-            Class<?>[] exceptionTypes = switch (info.getReferenceKind()) {
-                case MethodHandleInfo.REF_invokeInterface, MethodHandleInfo.REF_invokeSpecial,
-                        MethodHandleInfo.REF_invokeStatic, MethodHandleInfo.REF_invokeVirtual ->
-                        info.reflectAs(Method.class, MethodHandles.Lookup.IMPL_LOOKUP).getExceptionTypes();
-                case MethodHandleInfo.REF_newInvokeSpecial ->
-                        info.reflectAs(Constructor.class, MethodHandles.Lookup.IMPL_LOOKUP).getExceptionTypes();
-                case MethodHandleInfo.REF_getField, MethodHandleInfo.REF_getStatic,
-                        MethodHandleInfo.REF_putField, MethodHandleInfo.REF_putStatic -> null;
-                default -> throw new AssertionError("Cannot get here");
-            };
+            byte refKind = directHandle.member.getReferenceKind();
+            MethodHandleInfo info = new InfoFromMemberName(
+                    MethodHandles.Lookup.IMPL_LOOKUP,
+                    directHandle.member,
+                    refKind);
+            final Class<?>[] exceptionTypes;
+            if (MethodHandleNatives.refKindIsMethod(refKind)) {
+                exceptionTypes = info.reflectAs(Method.class, MethodHandles.Lookup.IMPL_LOOKUP)
+                        .getExceptionTypes();
+            } else if (MethodHandleNatives.refKindIsField(refKind)) {
+                exceptionTypes = null;
+            } else if (MethodHandleNatives.refKindIsObjectConstructor(refKind)) {
+                exceptionTypes = info.reflectAs(Constructor.class, MethodHandles.Lookup.IMPL_LOOKUP)
+                        .getExceptionTypes();
+            } else {
+                throw new AssertionError("Cannot get here");
+            }
             if (exceptionTypes != null) {
                 if (Stream.of(exceptionTypes).anyMatch(VarHandles::isCheckedException)) {
                     throw newIllegalArgumentException("Cannot adapt a var handle with a method handle which throws checked exceptions");
                 }
             }
diff a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/ClassReader.java b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/ClassReader.java
--- a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/ClassReader.java
+++ b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/ClassReader.java
@@ -497,12 +497,12 @@
         String moduleMainClass = null;
         // - The string corresponding to the NestHost attribute, or null.
         String nestHostClass = null;
         // - The offset of the NestMembers attribute, or 0.
         int nestMembersOffset = 0;
-        // - The offset of the PermittedSubtypes attribute, or 0
-        int permittedSubtypesOffset = 0;
+        // - The offset of the PermittedSubclasses attribute, or 0
+        int permittedSubclassesOffset = 0;
         // - The offset of the Record attribute, or 0.
         int recordOffset = 0;
         // - The non standard attributes (linked with their {@link Attribute#nextAttribute} field).
         //   This list in the <i>reverse order</i> or their order in the ClassFile structure.
         Attribute attributes = null;
@@ -523,12 +523,12 @@
                 enclosingMethodOffset = currentAttributeOffset;
             } else if (Constants.NEST_HOST.equals(attributeName)) {
                 nestHostClass = readClass(currentAttributeOffset, charBuffer);
             } else if (Constants.NEST_MEMBERS.equals(attributeName)) {
                 nestMembersOffset = currentAttributeOffset;
-            } else if (Constants.PERMITTED_SUBTYPES.equals(attributeName)) {
-                permittedSubtypesOffset = currentAttributeOffset;
+            } else if (Constants.PERMITTED_SUBCLASSES.equals(attributeName)) {
+                permittedSubclassesOffset = currentAttributeOffset;
             } else if (Constants.SIGNATURE.equals(attributeName)) {
                 signature = readUTF8(currentAttributeOffset, charBuffer);
             } else if (Constants.RUNTIME_VISIBLE_ANNOTATIONS.equals(attributeName)) {
                 runtimeVisibleAnnotationsOffset = currentAttributeOffset;
             } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {
@@ -702,18 +702,18 @@
                 classVisitor.visitNestMember(readClass(currentNestMemberOffset, charBuffer));
                 currentNestMemberOffset += 2;
             }
         }
 
-        // Visit the PermittedSubtypes attribute.
-        if (permittedSubtypesOffset != 0) {
-            int numberOfPermittedSubtypes = readUnsignedShort(permittedSubtypesOffset);
-            int currentPermittedSubtypeOffset = permittedSubtypesOffset + 2;
-            while (numberOfPermittedSubtypes-- > 0) {
-                classVisitor.visitPermittedSubtypeExperimental(
-                        readClass(currentPermittedSubtypeOffset, charBuffer));
-                currentPermittedSubtypeOffset += 2;
+        // Visit the PermittedSubclasses attribute.
+        if (permittedSubclassesOffset != 0) {
+            int numberOfPermittedSubclasses = readUnsignedShort(permittedSubclassesOffset);
+            int currentPermittedSubclassOffset = permittedSubclassesOffset + 2;
+            while (numberOfPermittedSubclasses-- > 0) {
+                classVisitor.visitPermittedSubclassExperimental(
+                        readClass(currentPermittedSubclassOffset, charBuffer));
+                currentPermittedSubclassOffset += 2;
             }
         }
 
         // Visit the InnerClasses attribute.
         if (innerClassesOffset != 0) {
diff a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/Constants.java b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/Constants.java
--- a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/Constants.java
+++ b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/Constants.java
@@ -102,11 +102,11 @@
     static final String MODULE = "Module";
     static final String MODULE_PACKAGES = "ModulePackages";
     static final String MODULE_MAIN_CLASS = "ModuleMainClass";
     static final String NEST_HOST = "NestHost";
     static final String NEST_MEMBERS = "NestMembers";
-    static final String PERMITTED_SUBTYPES = "PermittedSubtypes";
+    static final String PERMITTED_SUBCLASSES = "PermittedSubclasses";
     static final String RECORD = "Record";
 
     // ASM specific access flags.
     // WARNING: the 16 least significant bits must NOT be used, to avoid conflicts with standard
     // access flags, and also to make sure that these flags are automatically filtered out when
diff a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/util/CheckClassAdapter.java b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/util/CheckClassAdapter.java
--- a/src/java.base/share/classes/jdk/internal/org/objectweb/asm/util/CheckClassAdapter.java
+++ b/src/java.base/share/classes/jdk/internal/org/objectweb/asm/util/CheckClassAdapter.java
@@ -354,19 +354,19 @@
     }
 
     /**
       * <b>Experimental, use at your own risk.</b>.
       *
-      * @param permittedSubtype the internal name of a permitted subtype.
+      * @param permittedSubclass the internal name of a permitted subclass.
       * @deprecated this API is experimental.
       */
     @Override
     @Deprecated
-    public void visitPermittedSubtypeExperimental(final String permittedSubtype) {
+    public void visitPermittedSubclassExperimental(final String permittedSubclass) {
         checkState();
-        CheckMethodAdapter.checkInternalName(version, permittedSubtype, "permittedSubtype");
-        super.visitPermittedSubtypeExperimental(permittedSubtype);
+        CheckMethodAdapter.checkInternalName(version, permittedSubclass, "permittedSubclass");
+        super.visitPermittedSubclassExperimental(permittedSubclass);
     }
 
     @Override
     public void visitOuterClass(final String owner, final String name, final String descriptor) {
         checkState();
diff a/src/java.base/share/classes/module-info.java b/src/java.base/share/classes/module-info.java
--- a/src/java.base/share/classes/module-info.java
+++ b/src/java.base/share/classes/module-info.java
@@ -228,10 +228,12 @@
         jdk.management.agent;
     exports jdk.internal.vm.annotation to
         jdk.internal.vm.ci,
         jdk.incubator.foreign,
         jdk.unsupported;
+    exports jdk.internal.util to
+            jdk.incubator.foreign;
     exports jdk.internal.util.jar to
         jdk.jartool;
     exports jdk.internal.util.xml to
         jdk.jfr;
     exports jdk.internal.util.xml.impl to
diff a/src/java.compiler/share/classes/javax/lang/model/element/Modifier.java b/src/java.compiler/share/classes/javax/lang/model/element/Modifier.java
--- a/src/java.compiler/share/classes/javax/lang/model/element/Modifier.java
+++ b/src/java.compiler/share/classes/javax/lang/model/element/Modifier.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2013, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -36,20 +36,25 @@
  * order as the constants listed in the detail section below.
  *
  * <p>Note that it is possible additional modifiers will be added in
  * future versions of the platform.
  *
+ * @jls 8.1.1 Class Modifiers
+ * @jls 8.3.1 Field Modifiers
+ * @jls 8.4.3 Method Modifiers
+ * @jls 8.8.3 Constructor Modifiers
+ * @jls 9.1.1 Interface Modifiers
+ *
  * @author Joseph D. Darcy
  * @author Scott Seligman
  * @author Peter von der Ah&eacute;
  * @since 1.6
  */
 
 public enum Modifier {
 
-    // See JLS sections 8.1.1, 8.3.1, 8.4.3, 8.8.3, and 9.1.1.
-    // java.lang.reflect.Modifier includes INTERFACE, but that's a VMism.
+    // Note java.lang.reflect.Modifier includes INTERFACE, but that's a VMism.
 
     /** The modifier {@code public} */          PUBLIC,
     /** The modifier {@code protected} */       PROTECTED,
     /** The modifier {@code private} */         PRIVATE,
     /** The modifier {@code abstract} */        ABSTRACT,
@@ -63,19 +68,59 @@
      * @since 1.11
      */
     VALUE,
 
     /** The modifier {@code static} */          STATIC,
+
+    /**
+     * {@preview Associated with sealed classes, a preview feature of the Java language.
+     *
+     *           This enum constant is associated with <i>sealed classes</i>, a preview
+     *           feature of the Java language. Preview features
+     *           may be removed in a future release, or upgraded to permanent
+     *           features of the Java language.}
+     *
+     * The modifier {@code sealed}
+     * @since 15
+     */
+    @jdk.internal.PreviewFeature(feature=jdk.internal.PreviewFeature.Feature.SEALED_CLASSES,
+                                             essentialAPI=false)
+    SEALED,
+
+    /**
+     * {@preview Associated with sealed classes, a preview feature of the Java language.
+     *
+     *           This enum constant is associated with <i>sealed classes</i>, a preview
+     *           feature of the Java language. Preview features
+     *           may be removed in a future release, or upgraded to permanent
+     *           features of the Java language.}
+     *
+     * The modifier {@code non-sealed}
+     * @since 15
+     */
+    @jdk.internal.PreviewFeature(feature=jdk.internal.PreviewFeature.Feature.SEALED_CLASSES,
+            essentialAPI=false)
+    NON_SEALED {
+        public String toString() {
+            return "non-sealed";
+        }
+    },
     /** The modifier {@code final} */           FINAL,
     /** The modifier {@code transient} */       TRANSIENT,
     /** The modifier {@code volatile} */        VOLATILE,
     /** The modifier {@code synchronized} */    SYNCHRONIZED,
     /** The modifier {@code native} */          NATIVE,
     /** The modifier {@code strictfp} */        STRICTFP;
 
     /**
-     * Returns this modifier's name in lowercase.
+     * Returns this modifier's name as defined in <cite>The
+     * Java&trade; Language Specification</cite>.
+     * The modifier name is the {@linkplain #name() name of the enum
+     * constant} in lowercase and with any underscores ("{@code _}")
+     * replaced with hyphens ("{@code -}").
+     * @return the modifier's name
      */
+    @Override
     public String toString() {
         return name().toLowerCase(java.util.Locale.US);
     }
 }
diff a/src/jdk.compiler/share/classes/com/sun/source/util/TreeScanner.java b/src/jdk.compiler/share/classes/com/sun/source/util/TreeScanner.java
--- a/src/jdk.compiler/share/classes/com/sun/source/util/TreeScanner.java
+++ b/src/jdk.compiler/share/classes/com/sun/source/util/TreeScanner.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -176,16 +176,18 @@
      *
      * @param node  {@inheritDoc}
      * @param p  {@inheritDoc}
      * @return the result of scanning
      */
+    @SuppressWarnings("preview")
     @Override
     public R visitClass(ClassTree node, P p) {
         R r = scan(node.getModifiers(), p);
         r = scanAndReduce(node.getTypeParameters(), p, r);
         r = scanAndReduce(node.getExtendsClause(), p, r);
         r = scanAndReduce(node.getImplementsClause(), p, r);
+        r = scanAndReduce(node.getPermitsClause(), p, r);
         r = scanAndReduce(node.getMembers(), p, r);
         return r;
     }
 
     /**
diff a/src/jdk.compiler/share/classes/com/sun/tools/doclint/Checker.java b/src/jdk.compiler/share/classes/com/sun/tools/doclint/Checker.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/doclint/Checker.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/doclint/Checker.java
@@ -913,18 +913,13 @@
         return super.visitProvides(tree, ignore);
     }
 
     @Override @DefinedBy(Api.COMPILER_TREE)
     public Void visitReference(ReferenceTree tree, Void ignore) {
-        String sig = tree.getSignature();
-        if (sig.contains("<") || sig.contains(">")) {
-            env.messages.error(REFERENCE, tree, "dc.type.arg.not.allowed");
-        } else {
-            Element e = env.trees.getElement(getCurrentPath());
-            if (e == null)
-                env.messages.error(REFERENCE, tree, "dc.ref.not.found");
-        }
+        Element e = env.trees.getElement(getCurrentPath());
+        if (e == null)
+            env.messages.error(REFERENCE, tree, "dc.ref.not.found");
         return super.visitReference(tree, ignore);
     }
 
     @Override @DefinedBy(Api.COMPILER_TREE)
     public Void visitReturn(ReturnTree tree, Void ignore) {
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Flags.java
@@ -383,10 +383,20 @@
     /** Flag is set for compiler-generated record members, it could be applied to
      *  accessors and fields
      */
     public static final int GENERATED_MEMBER = 1<<24; // MethodSymbols and VarSymbols
 
+    /**
+     * Flag to indicate sealed class/interface declaration.
+     */
+    public static final long SEALED = 1L<<62; // ClassSymbols
+
+    /**
+     * Flag to indicate that the class/interface was declared with the non-sealed modifier.
+     */
+    public static final long NON_SEALED = 1L<<63; // ClassSymbols
+
     /** Modifier masks.
      */
     public static final int
         AccessFlags           = PUBLIC | PROTECTED | PRIVATE,
         LocalClassFlags       = FINAL | ABSTRACT | STRICTFP | ENUM | SYNTHETIC | VALUE,
@@ -400,29 +410,34 @@
         MethodFlags           = AccessFlags | ABSTRACT | STATIC | NATIVE |
                                 SYNCHRONIZED | FINAL | STRICTFP,
         RecordMethodFlags     = AccessFlags | ABSTRACT | STATIC |
                                 SYNCHRONIZED | FINAL | STRICTFP;
     public static final long
-        ExtendedStandardFlags       = (long)StandardFlags | DEFAULT | VALUE,
-        ModifierFlags               = ((long)StandardFlags & ~INTERFACE) | DEFAULT,
+        ExtendedStandardFlags       = (long)StandardFlags | DEFAULT | SEALED | NON_SEALED | VALUE,
+        ExtendedMemberClassFlags    = (long)MemberClassFlags | SEALED | NON_SEALED,
+        ExtendedClassFlags          = (long)ClassFlags | SEALED | NON_SEALED,
+        ModifierFlags               = ((long)StandardFlags & ~INTERFACE) | DEFAULT | SEALED | NON_SEALED,
         InterfaceMethodMask         = ABSTRACT | PRIVATE | STATIC | PUBLIC | STRICTFP | DEFAULT,
         AnnotationTypeElementMask   = ABSTRACT | PUBLIC,
         LocalVarFlags               = FINAL | PARAMETER,
         VarFlags              = AccessFlags | FINAL | STATIC |
                                 VOLATILE | TRANSIENT | ENUM,
         ReceiverParamFlags          = PARAMETER;
 
-
+    @SuppressWarnings("preview")
     public static Set<Modifier> asModifierSet(long flags) {
         Set<Modifier> modifiers = modifierSets.get(flags);
         if (modifiers == null) {
             modifiers = java.util.EnumSet.noneOf(Modifier.class);
             if (0 != (flags & PUBLIC))    modifiers.add(Modifier.PUBLIC);
             if (0 != (flags & PROTECTED)) modifiers.add(Modifier.PROTECTED);
             if (0 != (flags & PRIVATE))   modifiers.add(Modifier.PRIVATE);
             if (0 != (flags & ABSTRACT))  modifiers.add(Modifier.ABSTRACT);
             if (0 != (flags & STATIC))    modifiers.add(Modifier.STATIC);
+            if (0 != (flags & SEALED))    modifiers.add(Modifier.SEALED);
+            if (0 != (flags & NON_SEALED))
+                                          modifiers.add(Modifier.NON_SEALED);
             if (0 != (flags & FINAL))     modifiers.add(Modifier.FINAL);
             if (0 != (flags & TRANSIENT)) modifiers.add(Modifier.TRANSIENT);
             if (0 != (flags & VOLATILE))  modifiers.add(Modifier.VOLATILE);
             if (0 != (flags & SYNCHRONIZED))
                                           modifiers.add(Modifier.SYNCHRONIZED);
@@ -514,11 +529,18 @@
         NAME_FILLED(Flags.NAME_FILLED),
         PREVIEW_API(Flags.PREVIEW_API),
         PREVIEW_ESSENTIAL_API(Flags.PREVIEW_ESSENTIAL_API),
         MATCH_BINDING(Flags.MATCH_BINDING),
         MATCH_BINDING_TO_OUTER(Flags.MATCH_BINDING_TO_OUTER),
-        RECORD(Flags.RECORD);
+        RECORD(Flags.RECORD),
+        SEALED(Flags.SEALED),
+        NON_SEALED(Flags.NON_SEALED) {
+            @Override
+            public String toString() {
+                return "non-sealed";
+            }
+        };
 
         Flag(long flag) {
             this.value = flag;
             this.lowercaseName = StringUtils.toLowerCase(name());
         }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Source.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Source.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Source.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Source.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2002, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2002, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -208,10 +208,11 @@
         TEXT_BLOCKS(JDK15, Fragments.FeatureTextBlocks, DiagKind.PLURAL),
         PATTERN_MATCHING_IN_INSTANCEOF(JDK15, Fragments.FeaturePatternMatchingInstanceof, DiagKind.NORMAL),
         REIFIABLE_TYPES_INSTANCEOF(JDK15, Fragments.FeatureReifiableTypesInstanceof, DiagKind.PLURAL),
         RECORDS(JDK15, Fragments.FeatureRecords, DiagKind.PLURAL),
         INLINE_TYPES(JDK15, Fragments.FeatureInlineType, DiagKind.NORMAL),
+        SEALED_CLASSES(JDK15, Fragments.FeatureSealedClasses, DiagKind.PLURAL),
         ;
 
         enum DiagKind {
             NORMAL,
             PLURAL;
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Symbol.java
@@ -447,10 +447,18 @@
 
     public boolean isEnum() {
         return (flags() & ENUM) != 0;
     }
 
+    public boolean isSealed() {
+        return (flags_field & SEALED) != 0;
+    }
+
+    public boolean isNonSealed() {
+        return (flags_field & NON_SEALED) != 0;
+    }
+
     public boolean isFinal() {
         return (flags_field & FINAL) != 0;
     }
 
    /** Is this symbol declared (directly or indirectly) local
@@ -1324,18 +1332,26 @@
            and vice versa.
          */
         public ClassSymbol projection;
 
 
+        // sealed classes related fields
+        /** The classes, or interfaces, permitted to extend this class, or interface
+         */
+        public List<Symbol> permitted;
+
+        public boolean isPermittedExplicit = false;
+
         public ClassSymbol(long flags, Name name, Type type, Symbol owner) {
             super(TYP, flags, name, type, owner);
             this.members_field = null;
             this.fullname = formFullName(name, owner);
             this.flatname = formFlatName(name, owner);
             this.sourcefile = null;
             this.classfile = null;
             this.annotationTypeMetadata = AnnotationTypeMetadata.notAnAnnotationType();
+            this.permitted = List.nil();
         }
 
         public ClassSymbol(long flags, Name name, Symbol owner) {
             this(
                 flags,
@@ -1695,10 +1711,15 @@
             projection.flatname = this.flatname.append('$', this.name.table.names.ref);
             projection.projection = this;
             projectedType.tsym = projection;
             return projection;
         }
+
+        @DefinedBy(Api.LANGUAGE_MODEL)
+        public List<Type> getPermittedSubclasses() {
+            return permitted.map(s -> s.type);
+        }
     }
 
 
     /** A class for variable symbols
      */
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Types.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Types.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Types.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/code/Types.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -741,11 +741,11 @@
         /**
          * Compute the function descriptor associated with a given functional interface
          */
         public FunctionDescriptor findDescriptorInternal(TypeSymbol origin,
                 CompoundScope membersCache) throws FunctionDescriptorLookupError {
-            if (!origin.isInterface() || (origin.flags() & ANNOTATION) != 0) {
+            if (!origin.isInterface() || (origin.flags() & ANNOTATION) != 0 || origin.isSealed()) {
                 //t must be an interface
                 throw failure("not.a.functional.intf", origin);
             }
 
             final ListBuffer<Symbol> abstracts = new ListBuffer<>();
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Attr.java
@@ -5179,10 +5179,94 @@
             c.flags_field &= ~UNATTRIBUTED;
 
             // Get environment current at the point of class definition.
             Env<AttrContext> env = typeEnvs.get(c);
 
+            if (c.isSealed() &&
+                    !c.isEnum() &&
+                    !c.isPermittedExplicit &&
+                    c.permitted.isEmpty()) {
+                log.error(TreeInfo.diagnosticPositionFor(c, env.tree), Errors.SealedClassMustHaveSubclasses);
+            }
+
+            if (c.isSealed()) {
+                Set<Symbol> permittedTypes = new HashSet<>();
+                boolean sealedInUnnamed = c.packge().modle == syms.unnamedModule || c.packge().modle == syms.noModule;
+                for (Symbol subTypeSym : c.permitted) {
+                    boolean isTypeVar = false;
+                    if (subTypeSym.type.getTag() == TYPEVAR) {
+                        isTypeVar = true; //error recovery
+                        log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),
+                                Errors.InvalidPermitsClause(Fragments.IsATypeVariable(subTypeSym.type)));
+                    }
+                    if (subTypeSym.isAnonymous() && !c.isEnum()) {
+                        log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree), Errors.CantInheritFromSealed(c));
+                    }
+                    if (permittedTypes.contains(subTypeSym)) {
+                        DiagnosticPosition pos =
+                                env.enclClass.permitting.stream()
+                                        .filter(permittedExpr -> TreeInfo.diagnosticPositionFor(subTypeSym, permittedExpr, true) != null)
+                                        .limit(2).collect(List.collector()).get(1);
+                        log.error(pos, Errors.InvalidPermitsClause(Fragments.IsDuplicated(subTypeSym.type)));
+                    } else {
+                        permittedTypes.add(subTypeSym);
+                    }
+                    if (sealedInUnnamed) {
+                        if (subTypeSym.packge() != c.packge()) {
+                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree), Errors.CantInheritFromSealed(c));
+                        }
+                    } else if (subTypeSym.packge().modle != c.packge().modle) {
+                        log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree), Errors.CantInheritFromSealed(c));
+                    }
+                    if (subTypeSym == c.type.tsym || types.isSuperType(subTypeSym.type, c.type)) {
+                        log.error(TreeInfo.diagnosticPositionFor(subTypeSym, ((JCClassDecl)env.tree).permitting),
+                                Errors.InvalidPermitsClause(
+                                        subTypeSym == c.type.tsym ?
+                                                Fragments.MustNotBeSameClass :
+                                                Fragments.MustNotBeSupertype(subTypeSym.type)
+                                )
+                        );
+                    } else if (!isTypeVar) {
+                        boolean thisIsASuper = types.directSupertypes(subTypeSym.type)
+                                                    .stream()
+                                                    .anyMatch(d -> d.tsym == c);
+                        if (!thisIsASuper) {
+                            log.error(TreeInfo.diagnosticPositionFor(subTypeSym, env.tree),
+                                    Errors.InvalidPermitsClause(Fragments.DoesntExtendSealed(subTypeSym.type)));
+                        }
+                    }
+                }
+            }
+
+            List<ClassSymbol> sealedSupers = types.directSupertypes(c.type)
+                                                  .stream()
+                                                  .filter(s -> s.tsym.isSealed())
+                                                  .map(s -> (ClassSymbol) s.tsym)
+                                                  .collect(List.collector());
+
+            if (sealedSupers.isEmpty()) {
+                if ((c.flags_field & Flags.NON_SEALED) != 0) {
+                    log.error(TreeInfo.diagnosticPositionFor(c, env.tree), Errors.NonSealedWithNoSealedSupertype(c));
+                }
+            } else {
+                if (c.isLocal() && !c.isEnum()) {
+                    log.error(TreeInfo.diagnosticPositionFor(c, env.tree), Errors.LocalClassesCantExtendSealed);
+                }
+
+                for (ClassSymbol supertypeSym : sealedSupers) {
+                    if (!supertypeSym.permitted.contains(c.type.tsym)) {
+                        log.error(TreeInfo.diagnosticPositionFor(c.type.tsym, env.tree), Errors.CantInheritFromSealed(supertypeSym));
+                    }
+                }
+                if (!c.isNonSealed() && !c.isFinal() && !c.isSealed()) {
+                    log.error(TreeInfo.diagnosticPositionFor(c, env.tree),
+                            c.isInterface() ?
+                                    Errors.NonSealedOrSealedExpected :
+                                    Errors.NonSealedSealedOrFinalExpected);
+                }
+            }
+
             // The info.lint field in the envs stored in typeEnvs is deliberately uninitialized,
             // because the annotations were not available at the time the env was created. Therefore,
             // we look up the environment chain for the first enclosing environment for which the
             // lint value is set. Typically, this is the parent env, but might be further if there
             // are any envs created as a result of TypeParameter nodes.
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
@@ -159,10 +159,12 @@
 
         deferredLintHandler = DeferredLintHandler.instance(context);
 
         allowRecords = (!preview.isPreview(Feature.RECORDS) || preview.isEnabled()) &&
                 Feature.RECORDS.allowedInSource(source);
+        allowSealed = (!preview.isPreview(Feature.SEALED_CLASSES) || preview.isEnabled()) &&
+                Feature.SEALED_CLASSES.allowedInSource(source);
     }
 
     /** Character for synthetic names
      */
     char syntheticNameChar;
@@ -194,10 +196,14 @@
 
     /** Are records allowed
      */
     private final boolean allowRecords;
 
+    /** Are sealed classes allowed
+     */
+    private final boolean allowSealed;
+
 /* *************************************************************************
  * Errors and Warnings
  **************************************************************************/
 
     Lint setLint(Lint newLint) {
@@ -1380,28 +1386,28 @@
                     if (sym.owner.kind == TYP) {
                         log.error(pos, Errors.StaticDeclarationNotAllowedInInnerClasses);
                     }
                 }
             } else if (sym.owner.kind == TYP) {
-                mask = (flags & RECORD) != 0 ? MemberRecordFlags : MemberClassFlags;
+                mask = (flags & RECORD) != 0 ? MemberRecordFlags : ExtendedMemberClassFlags;
                 if (sym.owner.owner.kind == PCK ||
                     (sym.owner.flags_field & STATIC) != 0)
                     mask |= STATIC;
                 else if ((flags & ENUM) != 0 || (flags & RECORD) != 0) {
                     log.error(pos, Errors.StaticDeclarationNotAllowedInInnerClasses);
                 }
                 // Nested interfaces and enums are always STATIC (Spec ???)
                 if ((flags & (INTERFACE | ENUM | RECORD)) != 0 ) implicit = STATIC;
             } else {
-                mask = ClassFlags;
+                mask = ExtendedClassFlags;
             }
             // Interfaces are always ABSTRACT
             if ((flags & INTERFACE) != 0) implicit |= ABSTRACT;
 
             if ((flags & ENUM) != 0) {
-                // enums can't be declared abstract or final or value type
-                mask &= ~(ABSTRACT | FINAL | VALUE);
+                // enums can't be declared abstract, final, sealed or non-sealed or value type
+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | VALUE);
                 implicit |= implicitEnumFinalFlag(tree);
             }
             if ((flags & RECORD) != 0) {
                 // records can't be declared abstract
                 mask &= ~ABSTRACT;
@@ -1452,11 +1458,17 @@
                                VOLATILE)
                  &&
                  (sym.kind == TYP ||
                   checkDisjoint(pos, flags,
                                 ABSTRACT | NATIVE,
-                                STRICTFP))) {
+                                STRICTFP))
+                 && checkDisjoint(pos, flags,
+                                FINAL,
+                           SEALED | NON_SEALED)
+                 && checkDisjoint(pos, flags,
+                                SEALED,
+                           FINAL | NON_SEALED)) {
             // skip
         }
         return flags & (mask | ~ExtendedStandardFlags) | implicit;
     }
 
@@ -1492,11 +1504,11 @@
 
         SpecialTreeVisitor sts = new SpecialTreeVisitor();
         JCClassDecl cdef = (JCClassDecl) tree;
         for (JCTree defs: cdef.defs) {
             defs.accept(sts);
-            if (sts.specialized) return 0;
+            if (sts.specialized) return allowSealed ? SEALED : 0;
         }
         return FINAL;
     }
 
 /* *************************************************************************
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/TypeEnter.java
@@ -23,13 +23,15 @@
  * questions.
  */
 
 package com.sun.tools.javac.comp;
 
+import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.Set;
 import java.util.function.BiConsumer;
+import java.util.stream.Collectors;
 
 import javax.tools.JavaFileObject;
 
 import com.sun.tools.javac.code.*;
 import com.sun.tools.javac.code.Lint.LintCategory;
@@ -711,10 +713,19 @@
                         all_interfaces = new ListBuffer<Type>().appendList(interfaces);
                     all_interfaces.append(modelMissingTypes(baseEnv, it, iface, true));
                 }
             }
 
+            // Determine permits.
+            ListBuffer<Symbol> permittedSubtypeSymbols = new ListBuffer<>();
+            List<JCExpression> permittedTrees = tree.permitting;
+            for (JCExpression permitted : permittedTrees) {
+                permitted = clearTypeParams(permitted);
+                Type pt = attr.attribBase(permitted, baseEnv, false, false, false);
+                permittedSubtypeSymbols.append(pt.tsym);
+            }
+
             if ((sym.flags_field & ANNOTATION) != 0) {
                 ct.interfaces_field = List.of(syms.annotationType);
                 ct.all_interfaces_field = ct.interfaces_field;
             }  else {
                 ct.interfaces_field = interfaces.toList();
@@ -728,21 +739,24 @@
                     projectedType.supertype_field = ct.supertype_field;
                     projectedType.interfaces_field = ct.interfaces_field;
                     projectedType.all_interfaces_field = ct.all_interfaces_field;
                 }
             }
+
+            sym.permitted = permittedSubtypeSymbols.toList();
+            sym.isPermittedExplicit = !permittedSubtypeSymbols.isEmpty();
         }
             //where:
             protected JCExpression clearTypeParams(JCExpression superType) {
                 return superType;
             }
     }
 
     private final class HierarchyPhase extends AbstractHeaderPhase implements Completer {
 
         public HierarchyPhase() {
-            super(CompletionCause.HIERARCHY_PHASE, new HeaderPhase());
+            super(CompletionCause.HIERARCHY_PHASE, new PermitsPhase());
         }
 
         @Override
         protected void doCompleteEnvs(List<Env<AttrContext>> envs) {
             //The ClassSymbols in the envs list may not be in the dependency order.
@@ -812,10 +826,37 @@
             super.doCompleteEnvs(List.of(env));
         }
 
     }
 
+    private final class PermitsPhase extends AbstractHeaderPhase {
+
+        public PermitsPhase() {
+            super(CompletionCause.HIERARCHY_PHASE, new HeaderPhase());
+        }
+
+        @Override
+        protected void runPhase(Env<AttrContext> env) {
+            JCClassDecl tree = env.enclClass;
+            if (!tree.sym.isAnonymous() || tree.sym.isEnum()) {
+                for (Type supertype : types.directSupertypes(tree.sym.type)) {
+                    if (supertype.tsym.kind == TYP) {
+                        ClassSymbol supClass = (ClassSymbol) supertype.tsym;
+                        Env<AttrContext> supClassEnv = enter.getEnv(supClass);
+                        if (supClass.isSealed() &&
+                            !supClass.isPermittedExplicit &&
+                            supClassEnv != null &&
+                            supClassEnv.toplevel == env.toplevel) {
+                            supClass.permitted = supClass.permitted.append(tree.sym);
+                        }
+                    }
+                }
+            }
+        }
+
+    }
+
     private final class HeaderPhase extends AbstractHeaderPhase {
 
         public HeaderPhase() {
             super(CompletionCause.HEADER_PHASE, new RecordPhase());
         }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassReader.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassReader.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassReader.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassReader.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -107,10 +107,14 @@
 
     /** Switch: allow inline types.
      */
     boolean allowInlineTypes;
 
+    /** Switch: allow sealed
+     */
+    boolean allowSealedTypes;
+
     /** Switch: allow records
      */
     boolean allowRecords;
 
    /** Lint option: warn about classfile issues
@@ -277,10 +281,12 @@
         preview = Preview.instance(context);
         allowModules     = Feature.MODULES.allowedInSource(source);
         allowInlineTypes = Feature.INLINE_TYPES.allowedInSource(source);
         allowRecords = (!preview.isPreview(Feature.RECORDS) || preview.isEnabled()) &&
                 Feature.RECORDS.allowedInSource(source);
+        allowSealedTypes = (!preview.isPreview(Feature.SEALED_CLASSES) || preview.isEnabled()) &&
+                Feature.SEALED_CLASSES.allowedInSource(source);
 
         saveParameterNames = options.isSet(PARAMETERS);
         allowValueBasedClasses = options.isSet("allowValueBasedClasses");
 
         profile = Profile.instance(context);
@@ -1222,11 +1228,27 @@
                     if (sym.kind == TYP) {
                         sym.flags_field |= RECORD;
                     }
                     bp = bp + attrLen;
                 }
-            }
+            },
+            new AttributeReader(names.PermittedSubclasses, V59, CLASS_ATTRIBUTE) {
+                @Override
+                protected boolean accepts(AttributeKind kind) {
+                    return super.accepts(kind) && allowSealedTypes;
+                }
+                protected void read(Symbol sym, int attrLen) {
+                    if (sym.kind == TYP) {
+                        ListBuffer<Symbol> subtypes = new ListBuffer<>();
+                        int numberOfPermittedSubtypes = nextChar();
+                        for (int i = 0; i < numberOfPermittedSubtypes; i++) {
+                            subtypes.add(poolReader.getClass(nextChar()));
+                        }
+                        ((ClassSymbol)sym).permitted = subtypes.toList();
+                    }
+                }
+            },
         };
 
         for (AttributeReader r: readers)
             attributeReaders.put(r.name, r);
     }
@@ -2499,10 +2521,14 @@
         for (int i = 0; i < fieldCount; i++) skipMember();
         char methodCount = nextChar();
         for (int i = 0; i < methodCount; i++) skipMember();
         readClassAttrs(c);
 
+        if (c.permitted != null && !c.permitted.isEmpty()) {
+            c.flags_field |= SEALED;
+        }
+
         // reset and read rest of classinfo
         bp = startbp;
         int n = nextChar();
         if ((flags & MODULE) != 0 && n > 0) {
             throw badClassFile("module.info.invalid.super.class");
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassWriter.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassWriter.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassWriter.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/jvm/ClassWriter.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -913,10 +913,25 @@
                 listNested(s, seen);
             }
         }
     }
 
+    /** Write "PermittedSubclasses" attribute.
+     */
+    int writePermittedSubclassesIfNeeded(ClassSymbol csym) {
+        if (csym.permitted.nonEmpty()) {
+            int alenIdx = writeAttr(names.PermittedSubclasses);
+            databuf.appendChar(csym.permitted.size());
+            for (Symbol c : csym.permitted) {
+                databuf.appendChar(poolWriter.putClass((ClassSymbol) c));
+            }
+            endAttr(alenIdx);
+            return 1;
+        }
+        return 0;
+    }
+
     /** Write "bootstrapMethods" attribute.
      */
     void writeBootstrapMethods() {
         int alenIdx = writeAttr(names.BootstrapMethods);
         databuf.appendChar(poolWriter.bootstrapMethods.size());
@@ -1666,10 +1681,14 @@
 
         if (c.isRecord()) {
             acount += writeRecordAttribute(c);
         }
 
+        if (target.hasSealedClasses()) {
+            acount += writePermittedSubclassesIfNeeded(c);
+        }
+
         if (!poolWriter.bootstrapMethods.isEmpty()) {
             writeBootstrapMethods();
             acount++;
         }
 
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/parser/JavacParser.java
@@ -188,10 +188,12 @@
         this.allowYieldStatement = (!preview.isPreview(Feature.SWITCH_EXPRESSION) || preview.isEnabled()) &&
                 Feature.SWITCH_EXPRESSION.allowedInSource(source);
         this.allowWithFieldOperator = fac.options.isSet("allowWithFieldOperator");
         this.allowRecords = (!preview.isPreview(Feature.RECORDS) || preview.isEnabled()) &&
                 Feature.RECORDS.allowedInSource(source);
+        this.allowSealedTypes = (!preview.isPreview(Feature.SEALED_CLASSES) || preview.isEnabled()) &&
+                Feature.SEALED_CLASSES.allowedInSource(source);
     }
 
     protected AbstractEndPosTable newEndPosTable(boolean keepEndPositions) {
         return  keepEndPositions
                 ? new SimpleEndPosTable(this)
@@ -229,10 +231,14 @@
 
     /** Switch: are records allowed in this source level?
      */
     boolean allowRecords;
 
+    /** Switch: are sealed types allowed in this source level?
+     */
+    boolean allowSealedTypes;
+
     /** The type of the method receiver, as specified by a first "this" parameter.
      */
     JCVariableDecl receiverParam;
 
     /** When terms are parsed, the mode determines which is expected:
@@ -2702,10 +2708,23 @@
                     accept(SEMI);
                     return List.of(toP(F.at(pos).Yield(t)));
                 }
 
                 //else intentional fall-through
+            } else {
+                if (isNonSealedClassStart(true)) {
+                    log.error(token.pos, Errors.SealedOrNonSealedLocalClassesNotAllowed);
+                    nextToken();
+                    nextToken();
+                    nextToken();
+                    return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), token.comment(CommentStyle.JAVADOC)));
+                } else if (isSealedClassStart(true)) {
+                    checkSourceLevel(Feature.SEALED_CLASSES);
+                    log.error(token.pos, Errors.SealedOrNonSealedLocalClassesNotAllowed);
+                    nextToken();
+                    return List.of(classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(), token.comment(CommentStyle.JAVADOC)));
+                }
             }
         }
         if (isRecordStart() && allowRecords) {
             dc = token.comment(CommentStyle.JAVADOC);
             return List.of(recordDeclaration(F.at(pos).Modifiers(0), dc));
@@ -3156,10 +3175,24 @@
             case SYNCHRONIZED: flag = Flags.SYNCHRONIZED; break;
             case STRICTFP    : flag = Flags.STRICTFP; break;
             case MONKEYS_AT  : flag = Flags.ANNOTATION; break;
             case DEFAULT     : checkSourceLevel(Feature.DEFAULT_METHODS); flag = Flags.DEFAULT; break;
             case ERROR       : flag = 0; nextToken(); break;
+            case IDENTIFIER  : {
+                if (isNonSealedClassStart(false)) {
+                    flag = Flags.NON_SEALED;
+                    nextToken();
+                    nextToken();
+                    break;
+                }
+                if (isSealedClassStart(false)) {
+                    checkSourceLevel(Feature.SEALED_CLASSES);
+                    flag = Flags.SEALED;
+                    break;
+                }
+                break loop;
+            }
             default: break loop;
             }
             if ((flags & flag) != 0) log.error(DiagnosticFlag.SYNTAX, token.pos, Errors.RepeatedModifier);
             lastPos = token.pos;
             nextToken();
@@ -3450,10 +3483,17 @@
                 return Source.JDK14;
             } else if (shouldWarn) {
                 log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK14));
             }
         }
+        if (name == names.sealed) {
+            if (allowSealedTypes) {
+                return Source.JDK15;
+            } else if (shouldWarn) {
+                log.warning(pos, Warnings.RestrictedTypeNotAllowedPreview(name, Source.JDK15));
+            }
+        }
         return null;
     }
 
     /** VariableDeclaratorId = Ident BracketsOpt
      */
@@ -3844,13 +3884,22 @@
         List<JCExpression> implementing = List.nil();
         if (token.kind == IMPLEMENTS) {
             nextToken();
             implementing = typeList();
         }
+        List<JCExpression> permitting = List.nil();
+        if (allowSealedTypes && token.kind == IDENTIFIER && token.name() == names.permits) {
+            checkSourceLevel(Feature.SEALED_CLASSES);
+            if ((mods.flags & Flags.SEALED) == 0) {
+                log.error(token.pos, Errors.InvalidPermitsClause(Fragments.ClassIsNotSealed("class")));
+            }
+            nextToken();
+            permitting = qualidentList(false);
+        }
         List<JCTree> defs = classInterfaceOrRecordBody(name, false, false);
         JCClassDecl result = toP(F.at(pos).ClassDef(
-            mods, name, typarams, extending, implementing, defs));
+            mods, name, typarams, extending, implementing, permitting, defs));
         attach(result, dc);
         return result;
     }
 
     protected JCClassDecl recordDeclaration(JCModifiers mods, Comment dc) {
@@ -3923,13 +3972,23 @@
         List<JCExpression> extending = List.nil();
         if (token.kind == EXTENDS) {
             nextToken();
             extending = typeList();
         }
-        List<JCTree> defs = classInterfaceOrRecordBody(name, true, false);
+        List<JCExpression> permitting = List.nil();
+        if (allowSealedTypes && token.kind == IDENTIFIER && token.name() == names.permits) {
+            checkSourceLevel(Feature.SEALED_CLASSES);
+            if ((mods.flags & Flags.SEALED) == 0) {
+                log.error(token.pos, Errors.InvalidPermitsClause(Fragments.ClassIsNotSealed("interface")));
+            }
+            nextToken();
+            permitting = typeList();
+        }
+        List<JCTree> defs;
+        defs = classInterfaceOrRecordBody(name, true, false);
         JCClassDecl result = toP(F.at(pos).ClassDef(
-            mods, name, typarams, null, extending, defs));
+            mods, name, typarams, null, extending, permitting, defs));
         attach(result, dc);
         return result;
     }
 
     /** EnumDeclaration = ENUM Ident [IMPLEMENTS TypeList] EnumBody
@@ -4271,20 +4330,66 @@
             }
         }
     }
 
     protected boolean isRecordStart() {
-     if (token.kind == IDENTIFIER && token.name() == names.record &&
+        if (token.kind == IDENTIFIER && token.name() == names.record &&
             (peekToken(TokenKind.IDENTIFIER, TokenKind.LPAREN) ||
              peekToken(TokenKind.IDENTIFIER, TokenKind.EOF) ||
              peekToken(TokenKind.IDENTIFIER, TokenKind.LT))) {
-          checkSourceLevel(Feature.RECORDS);
-          return true;
-    } else {
-       return false;
-   }
-}
+             checkSourceLevel(Feature.RECORDS);
+            return true;
+        } else {
+            return false;
+        }
+    }
+
+    protected boolean isNonSealedClassStart(boolean local) {
+        if (isNonSealedIdentifier(token, 0)) {
+            Token next = S.token(3);
+            return allowedAfterSealedOrNonSealed(next, local, true);
+        }
+        return false;
+    }
+
+    protected boolean isNonSealedIdentifier(Token someToken, int lookAheadOffset) {
+        if (someToken.name() == names.non && peekToken(lookAheadOffset, TokenKind.SUB, TokenKind.IDENTIFIER)) {
+            Token tokenSub = S.token(lookAheadOffset + 1);
+            Token tokenSealed = S.token(lookAheadOffset + 2);
+            if (someToken.endPos == tokenSub.pos &&
+                    tokenSub.endPos == tokenSealed.pos &&
+                    tokenSealed.name() == names.sealed) {
+                checkSourceLevel(Feature.SEALED_CLASSES);
+                return true;
+            }
+        }
+        return false;
+    }
+
+    protected boolean isSealedClassStart(boolean local) {
+        if (token.name() == names.sealed) {
+            Token next = S.token(1);
+            if (allowedAfterSealedOrNonSealed(next, local, false)) {
+                checkSourceLevel(Feature.SEALED_CLASSES);
+                return true;
+            }
+        }
+        return false;
+    }
+
+    private boolean allowedAfterSealedOrNonSealed(Token next, boolean local, boolean currentIsNonSealed) {
+        return local ?
+            switch (next.kind) {
+                case MONKEYS_AT, ABSTRACT, FINAL, STRICTFP, CLASS, INTERFACE, ENUM -> true;
+                default -> false;
+            } :
+            switch (next.kind) {
+                case MONKEYS_AT, PUBLIC, PROTECTED, PRIVATE, ABSTRACT, STATIC, FINAL, STRICTFP, CLASS, INTERFACE, ENUM -> true;
+                case IDENTIFIER -> isNonSealedIdentifier(next, currentIsNonSealed ? 3 : 1) || next.name() == names.sealed;
+                default -> false;
+            };
+    }
 
     /** MethodDeclaratorRest =
      *      FormalParameters BracketsOpt [THROWS TypeList] ( MethodBody | [DEFAULT AnnotationValue] ";")
      *  VoidMethodDeclaratorRest =
      *      FormalParameters [THROWS TypeList] ( MethodBody | ";")
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties b/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/resources/compiler.properties
@@ -2941,10 +2941,13 @@
     inline type
 
 compiler.misc.feature.records=\
     records
 
+compiler.misc.feature.sealed.classes=\
+    sealed classes
+
 compiler.warn.underscore.as.identifier=\
     as of release 9, ''_'' is a keyword, and may not be used as an identifier
 
 compiler.err.underscore.as.identifier=\
     as of release 9, ''_'' is a keyword, and may not be used as an identifier
@@ -3443,10 +3446,69 @@
     unexpected statement in case, expected is an expression, a block or a throw statement
 
 compiler.err.switch.mixing.case.types=\
     different case kinds used in the switch
 
+###
+# errors related to sealed classes
+
+# permits clause
+# 0: fragment
+compiler.err.invalid.permits.clause=\
+    invalid permits clause\n\
+    ({0})
+
+# 0: string
+compiler.misc.class.is.not.sealed=\
+    {0} must be sealed
+
+# 0: type
+compiler.misc.is.a.type.variable=\
+    must not include type variables: {0}
+
+# 0: type
+compiler.misc.is.duplicated=\
+    must not contain duplicates: {0}
+
+# 0: type
+compiler.misc.doesnt.extend.sealed=\
+    subclass {0} must extend sealed class
+
+compiler.misc.must.not.be.same.class=\
+    illegal self-reference in permits clause
+
+# 0: type
+compiler.misc.must.not.be.supertype=\
+    illegal reference to supertype {0}
+
+# other sealed types related errors
+
+compiler.err.sealed.class.must.have.subclasses=\
+    sealed class must have subclasses
+
+# errors in subclasses of sealed classes
+# 0: symbol
+compiler.err.cant.inherit.from.sealed=\
+    class is not allowed to extend sealed class: {0}
+
+# 0: symbol
+compiler.err.non.sealed.with.no.sealed.supertype=\
+    non-sealed modifier not allowed here\n\
+    (class {0} does not have any sealed supertypes)
+
+compiler.err.non.sealed.sealed.or.final.expected=\
+    sealed, non-sealed or final modifiers expected
+
+compiler.err.non.sealed.or.sealed.expected=\
+    sealed or non-sealed modifiers expected
+
+compiler.err.sealed.or.non.sealed.local.classes.not.allowed=\
+    sealed or non-sealed local classes are not allowed
+
+compiler.err.local.classes.cant.extend.sealed=\
+    local classes must not extend sealed classes
+
 ###
 # errors related to records
 
 # record components
 compiler.err.record.cant.declare.field.modifiers=\
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/JCTree.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/JCTree.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/JCTree.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/JCTree.java
@@ -763,27 +763,31 @@
         public List<JCTypeParameter> typarams;
         /** the classes this class extends */
         public JCExpression extending;
         /** the interfaces implemented by this class */
         public List<JCExpression> implementing;
+        /** the subclasses allowed to extend this class, if sealed */
+        public List<JCExpression> permitting;
         /** all variables and methods defined in this class */
         public List<JCTree> defs;
         /** the symbol */
         public ClassSymbol sym;
         protected JCClassDecl(JCModifiers mods,
                            Name name,
                            List<JCTypeParameter> typarams,
                            JCExpression extending,
                            List<JCExpression> implementing,
+                           List<JCExpression> permitting,
                            List<JCTree> defs,
                            ClassSymbol sym)
         {
             this.mods = mods;
             this.name = name;
             this.typarams = typarams;
             this.extending = extending;
             this.implementing = implementing;
+            this.permitting = permitting;
             this.defs = defs;
             this.sym = sym;
         }
         @Override
         public void accept(Visitor v) { v.visitClassDef(this); }
@@ -815,10 +819,15 @@
         public JCExpression getExtendsClause() { return extending; }
         @DefinedBy(Api.COMPILER_TREE)
         public List<JCExpression> getImplementsClause() {
             return implementing;
         }
+        @SuppressWarnings("removal")
+        @DefinedBy(Api.COMPILER_TREE)
+        public List<JCExpression> getPermitsClause() {
+            return permitting;
+        }
         @DefinedBy(Api.COMPILER_TREE)
         public List<JCTree> getMembers() {
             return defs;
         }
         @Override @DefinedBy(Api.COMPILER_TREE)
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/Pretty.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/Pretty.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/Pretty.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/Pretty.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -562,10 +562,14 @@
                 printTypeParameters(tree.typarams);
                 if (tree.implementing.nonEmpty()) {
                     print(" extends ");
                     printExprs(tree.implementing);
                 }
+                if (tree.permitting.nonEmpty()) {
+                    print(" permits ");
+                    printExprs(tree.permitting);
+                }
             } else {
                 if ((tree.mods.flags & ENUM) != 0)
                     print("enum " + tree.name);
                 else
                     print("class " + tree.name);
@@ -576,10 +580,14 @@
                 }
                 if (tree.implementing.nonEmpty()) {
                     print(" implements ");
                     printExprs(tree.implementing);
                 }
+                if (tree.permitting.nonEmpty()) {
+                    print(" permits ");
+                    printExprs(tree.permitting);
+                }
             }
             print(" ");
             if ((tree.mods.flags & ENUM) != 0) {
                 printEnumBody(tree.defs);
             } else {
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeInfo.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeInfo.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeInfo.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeInfo.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -695,53 +695,85 @@
     }
 
     /** Find the position for reporting an error about a symbol, where
      *  that symbol is defined somewhere in the given tree. */
     public static DiagnosticPosition diagnosticPositionFor(final Symbol sym, final JCTree tree) {
-        JCTree decl = declarationFor(sym, tree);
-        return ((decl != null) ? decl : tree).pos();
+        return diagnosticPositionFor(sym, tree, false);
     }
 
-    /** Find the declaration for a symbol, where
-     *  that symbol is defined somewhere in the given tree. */
-    public static JCTree declarationFor(final Symbol sym, final JCTree tree) {
-        class DeclScanner extends TreeScanner {
-            JCTree result = null;
-            public void scan(JCTree tree) {
-                if (tree!=null && result==null)
-                    tree.accept(this);
-            }
-            public void visitTopLevel(JCCompilationUnit that) {
-                if (that.packge == sym) result = that;
-                else super.visitTopLevel(that);
-            }
-            public void visitModuleDef(JCModuleDecl that) {
-                if (that.sym == sym) result = that;
-                // no need to scan within module declaration
-            }
-            public void visitPackageDef(JCPackageDecl that) {
-                if (that.packge == sym) result = that;
-                else super.visitPackageDef(that);
+    public static DiagnosticPosition diagnosticPositionFor(final Symbol sym, final JCTree tree, boolean returnNullIfNotFound) {
+        class DiagScanner extends DeclScanner {
+            DiagScanner(Symbol sym) {
+                super(sym);
             }
-            public void visitClassDef(JCClassDecl that) {
-                if (that.sym == sym) result = that;
-                else super.visitClassDef(that);
-            }
-            public void visitMethodDef(JCMethodDecl that) {
+
+            public void visitIdent(JCIdent that) {
                 if (that.sym == sym) result = that;
-                else super.visitMethodDef(that);
+                else super.visitIdent(that);
             }
-            public void visitVarDef(JCVariableDecl that) {
+            public void visitSelect(JCFieldAccess that) {
                 if (that.sym == sym) result = that;
-                else super.visitVarDef(that);
-            }
-            public void visitTypeParameter(JCTypeParameter that) {
-                if (that.type != null && that.type.tsym == sym) result = that;
-                else super.visitTypeParameter(that);
+                else super.visitSelect(that);
             }
         }
-        DeclScanner s = new DeclScanner();
+        DiagScanner s = new DiagScanner(sym);
+        tree.accept(s);
+        JCTree decl = s.result;
+        if (decl == null && returnNullIfNotFound) { return null; }
+        return ((decl != null) ? decl : tree).pos();
+    }
+
+    public static DiagnosticPosition diagnosticPositionFor(final Symbol sym, final List<? extends JCTree> trees) {
+        return trees.stream().map(t -> TreeInfo.diagnosticPositionFor(sym, t)).filter(t -> t != null).findFirst().get();
+    }
+
+    private static class DeclScanner extends TreeScanner {
+        final Symbol sym;
+
+        DeclScanner(final Symbol sym) {
+            this.sym = sym;
+        }
+
+        JCTree result = null;
+        public void scan(JCTree tree) {
+            if (tree!=null && result==null)
+                tree.accept(this);
+        }
+        public void visitTopLevel(JCCompilationUnit that) {
+            if (that.packge == sym) result = that;
+            else super.visitTopLevel(that);
+        }
+        public void visitModuleDef(JCModuleDecl that) {
+            if (that.sym == sym) result = that;
+            // no need to scan within module declaration
+        }
+        public void visitPackageDef(JCPackageDecl that) {
+            if (that.packge == sym) result = that;
+            else super.visitPackageDef(that);
+        }
+        public void visitClassDef(JCClassDecl that) {
+            if (that.sym == sym) result = that;
+            else super.visitClassDef(that);
+        }
+        public void visitMethodDef(JCMethodDecl that) {
+            if (that.sym == sym) result = that;
+            else super.visitMethodDef(that);
+        }
+        public void visitVarDef(JCVariableDecl that) {
+            if (that.sym == sym) result = that;
+            else super.visitVarDef(that);
+        }
+        public void visitTypeParameter(JCTypeParameter that) {
+            if (that.type != null && that.type.tsym == sym) result = that;
+            else super.visitTypeParameter(that);
+        }
+    }
+
+    /** Find the declaration for a symbol, where
+     *  that symbol is defined somewhere in the given tree. */
+    public static JCTree declarationFor(final Symbol sym, final JCTree tree) {
+        DeclScanner s = new DeclScanner(sym);
         tree.accept(s);
         return s.result;
     }
 
     public static Env<AttrContext> scopeFor(JCTree node, JCCompilationUnit unit) {
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeMaker.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeMaker.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeMaker.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeMaker.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -158,16 +158,28 @@
                                 Name name,
                                 List<JCTypeParameter> typarams,
                                 JCExpression extending,
                                 List<JCExpression> implementing,
                                 List<JCTree> defs)
+    {
+        return ClassDef(mods, name, typarams, extending, implementing, List.nil(), defs);
+    }
+
+    public JCClassDecl ClassDef(JCModifiers mods,
+                                Name name,
+                                List<JCTypeParameter> typarams,
+                                JCExpression extending,
+                                List<JCExpression> implementing,
+                                List<JCExpression> permitting,
+                                List<JCTree> defs)
     {
         JCClassDecl tree = new JCClassDecl(mods,
                                      name,
                                      typarams,
                                      extending,
                                      implementing,
+                                     permitting,
                                      defs,
                                      null);
         tree.pos = pos;
         return tree;
     }
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeScanner.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeScanner.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeScanner.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/tree/TreeScanner.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -113,10 +113,11 @@
     public void visitClassDef(JCClassDecl tree) {
         scan(tree.mods);
         scan(tree.typarams);
         scan(tree.extending);
         scan(tree.implementing);
+        scan(tree.permitting);
         scan(tree.defs);
     }
 
     public void visitMethodDef(JCMethodDecl tree) {
         scan(tree.mods);
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/util/Names.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/util/Names.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/util/Names.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/util/Names.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -23,12 +23,10 @@
  * questions.
  */
 
 package com.sun.tools.javac.util;
 
-import java.util.Set;
-
 /**
  * Access to the compiler's name table.  Standard names are defined,
  * as well as methods to create new names.
  *
  *  <p><b>This is NOT part of any supported API.
@@ -165,10 +163,11 @@
     public final Name StackMap;
     public final Name StackMapTable;
     public final Name Synthetic;
     public final Name Value;
     public final Name Varargs;
+    public final Name PermittedSubclasses;
 
     // members of java.lang.annotation.ElementType
     public final Name ANNOTATION_TYPE;
     public final Name CONSTRUCTOR;
     public final Name FIELD;
@@ -213,17 +212,22 @@
     // record related
     // members of java.lang.runtime.ObjectMethods
     public final Name bootstrap;
 
     public final Name record;
+    public final Name non;
 
     // serialization members, used by records too
     public final Name serialPersistentFields;
     public final Name writeObject;
     public final Name writeReplace;
     public final Name readObjectNoData;
 
+    // sealed types
+    public final Name permits;
+    public final Name sealed;
+
     public final Name.Table table;
 
     public Names(Context context) {
         Options options = Options.instance(context);
         table = createTable(options);
@@ -345,10 +349,11 @@
         StackMap = fromString("StackMap");
         StackMapTable = fromString("StackMapTable");
         Synthetic = fromString("Synthetic");
         Value = fromString("Value");
         Varargs = fromString("Varargs");
+        PermittedSubclasses = fromString("PermittedSubclasses");
 
         // members of java.lang.annotation.ElementType
         ANNOTATION_TYPE = fromString("ANNOTATION_TYPE");
         CONSTRUCTOR = fromString("CONSTRUCTOR");
         FIELD = fromString("FIELD");
@@ -388,15 +393,20 @@
         ref = fromString("ref");
         val = fromString("val");
 
         bootstrap = fromString("bootstrap");
         record = fromString("record");
+        non = fromString("non");
 
         serialPersistentFields = fromString("serialPersistentFields");
         writeObject = fromString("writeObject");
         writeReplace = fromString("writeReplace");
         readObjectNoData = fromString("readObjectNoData");
+
+        // sealed types
+        permits = fromString("permits");
+        sealed = fromString("sealed");
     }
 
     protected Name.Table createTable(Options options) {
         boolean useUnsharedTable = options.isSet("useUnsharedTable");
         if (useUnsharedTable)
diff a/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java b/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
--- a/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
+++ b/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
@@ -502,12 +502,22 @@
                 if (modifiers.contains(STATIC)) {
                     append("static");
                 }
             }
 
+            void addSealed(TypeElement e) {
+                if (e.getModifiers().contains(Modifier.SEALED)) {
+                    append("sealed");
+                } else if (e.getModifiers().contains(Modifier.NON_SEALED)) {
+                    append("non-sealed");
+                }
+            }
+
             void addModifiers(Set<Modifier> modifiers) {
-                modifiers.stream().map(Modifier::toString).forEachOrdered(this::append);
+                modifiers.stream()
+                        .map(Modifier::toString)
+                        .forEachOrdered(this::append);
             }
 
             void append(String s) {
                 if (sb.length() > 0) {
                     sb.append(" ");
@@ -525,10 +535,11 @@
 
             @Override
             public String visitTypeAsInterface(TypeElement e, SortedSet<Modifier> mods) {
                 addVisibilityModifier(mods);
                 addStatic(mods);
+                addSealed(e);
                 return finalString("interface");
             }
 
             @Override
             public String visitTypeAsEnum(TypeElement e, SortedSet<Modifier> mods) {
diff a/src/jdk.jdwp.agent/share/native/libjdwp/util.c b/src/jdk.jdwp.agent/share/native/libjdwp/util.c
--- a/src/jdk.jdwp.agent/share/native/libjdwp/util.c
+++ b/src/jdk.jdwp.agent/share/native/libjdwp/util.c
@@ -24,10 +24,11 @@
  */
 
 #include <ctype.h>
 
 #include "util.h"
+#include "utf_util.h"
 #include "transport.h"
 #include "eventHandler.h"
 #include "threadControl.h"
 #include "outStream.h"
 #include "inStream.h"
@@ -1650,17 +1651,30 @@
     }
 
     /* Create jstrings for property name and value */
     nameString = JNI_FUNC_PTR(env,NewStringUTF)(env, propertyName);
     if (nameString != NULL) {
-        valueString = JNU_NewStringPlatform(env, propertyValue);
-        if (valueString != NULL) {
-            /* invoke Properties.setProperty */
-            JNI_FUNC_PTR(env,CallObjectMethod)
-                (env, gdata->agent_properties,
-                 gdata->setProperty,
-                 nameString, valueString);
+        /* convert the value to UTF8 */
+        int len;
+        char *utf8value;
+        int utf8maxSize;
+
+        len = (int)strlen(propertyValue);
+        utf8maxSize = len * 4 + 1;
+        utf8value = (char *)jvmtiAllocate(utf8maxSize);
+        if (utf8value != NULL) {
+            utf8FromPlatform(propertyValue, len, (jbyte *)utf8value, utf8maxSize);
+            valueString = JNI_FUNC_PTR(env, NewStringUTF)(env, utf8value);
+            jvmtiDeallocate(utf8value);
+
+            if (valueString != NULL) {
+                /* invoke Properties.setProperty */
+                JNI_FUNC_PTR(env,CallObjectMethod)
+                    (env, gdata->agent_properties,
+                     gdata->setProperty,
+                     nameString, valueString);
+            }
         }
     }
     if (JNI_FUNC_PTR(env,ExceptionOccurred)(env)) {
         JNI_FUNC_PTR(env,ExceptionClear)(env);
     }
