<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/runtime/synchronizer.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="sharedRuntime.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="synchronizer.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/synchronizer.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -35,15 +35,17 @@</span>
  #include &quot;oops/markWord.hpp&quot;
  #include &quot;oops/oop.inline.hpp&quot;
  #include &quot;runtime/atomic.hpp&quot;
  #include &quot;runtime/biasedLocking.hpp&quot;
  #include &quot;runtime/handles.inline.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/handshake.hpp&quot;</span>
  #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  #include &quot;runtime/mutexLocker.hpp&quot;
  #include &quot;runtime/objectMonitor.hpp&quot;
  #include &quot;runtime/objectMonitor.inline.hpp&quot;
  #include &quot;runtime/osThread.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/safepointMechanism.inline.hpp&quot;</span>
  #include &quot;runtime/safepointVerifiers.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
  #include &quot;runtime/stubRoutines.hpp&quot;
  #include &quot;runtime/synchronizer.hpp&quot;
  #include &quot;runtime/thread.inline.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -116,10 +118,13 @@</span>
  #define NINFLATIONLOCKS 256
  static volatile intptr_t gInflationLocks[NINFLATIONLOCKS];
  
  // global list of blocks of monitors
  PaddedObjectMonitor* ObjectSynchronizer::g_block_list = NULL;
<span class="udiff-line-added">+ bool volatile ObjectSynchronizer::_is_async_deflation_requested = false;</span>
<span class="udiff-line-added">+ bool volatile ObjectSynchronizer::_is_special_deflation_requested = false;</span>
<span class="udiff-line-added">+ jlong ObjectSynchronizer::_last_async_deflation_time_ns = 0;</span>
  
  struct ObjectMonitorListGlobals {
    char         _pad_prefix[OM_CACHE_LINE_SIZE];
    // These are highly shared list related variables.
    // To avoid false-sharing they need to be the sole occupants of a cache line.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -132,18 +137,28 @@</span>
    // Global ObjectMonitor in-use list. When a JavaThread is exiting,
    // ObjectMonitors on its per-thread in-use list are prepended here.
    ObjectMonitor* _in_use_list;
    DEFINE_PAD_MINUS_SIZE(2, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));
  
<span class="udiff-line-added">+   // Global ObjectMonitor wait list. Deflated ObjectMonitors wait on</span>
<span class="udiff-line-added">+   // this list until after a handshake or a safepoint for platforms</span>
<span class="udiff-line-added">+   // that don&#39;t support handshakes. After the handshake or safepoint,</span>
<span class="udiff-line-added">+   // the deflated ObjectMonitors are prepended to free_list.</span>
<span class="udiff-line-added">+   ObjectMonitor* _wait_list;</span>
<span class="udiff-line-added">+   DEFINE_PAD_MINUS_SIZE(3, OM_CACHE_LINE_SIZE, sizeof(ObjectMonitor*));</span>
<span class="udiff-line-added">+ </span>
    int _free_count;    // # on free_list
<span class="udiff-line-modified-removed">-   DEFINE_PAD_MINUS_SIZE(3, OM_CACHE_LINE_SIZE, sizeof(int));</span>
<span class="udiff-line-modified-added">+   DEFINE_PAD_MINUS_SIZE(4, OM_CACHE_LINE_SIZE, sizeof(int));</span>
  
    int _in_use_count;  // # on in_use_list
<span class="udiff-line-modified-removed">-   DEFINE_PAD_MINUS_SIZE(4, OM_CACHE_LINE_SIZE, sizeof(int));</span>
<span class="udiff-line-modified-added">+   DEFINE_PAD_MINUS_SIZE(5, OM_CACHE_LINE_SIZE, sizeof(int));</span>
  
    int _population;    // # Extant -- in circulation
<span class="udiff-line-modified-removed">-   DEFINE_PAD_MINUS_SIZE(5, OM_CACHE_LINE_SIZE, sizeof(int));</span>
<span class="udiff-line-modified-added">+   DEFINE_PAD_MINUS_SIZE(6, OM_CACHE_LINE_SIZE, sizeof(int));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int _wait_count;    // # on wait_list</span>
<span class="udiff-line-added">+   DEFINE_PAD_MINUS_SIZE(7, OM_CACHE_LINE_SIZE, sizeof(int));</span>
  };
  static ObjectMonitorListGlobals om_list_globals;
  
  #define CHECK_THROW_NOSYNC_IMSE(obj)  \
    if ((obj)-&gt;mark().is_always_locked()) {  \
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -310,10 +325,19 @@</span>
                                               ObjectMonitor* tail, int count) {
    prepend_list_to_common(list, tail, count, &amp;om_list_globals._free_list,
                           &amp;om_list_globals._free_count);
  }
  
<span class="udiff-line-added">+ // Prepend a list of ObjectMonitors to om_list_globals._wait_list.</span>
<span class="udiff-line-added">+ // &#39;tail&#39; is the last ObjectMonitor in the list and there are &#39;count&#39;</span>
<span class="udiff-line-added">+ // on the list. Also updates om_list_globals._wait_count.</span>
<span class="udiff-line-added">+ static void prepend_list_to_global_wait_list(ObjectMonitor* list,</span>
<span class="udiff-line-added">+                                              ObjectMonitor* tail, int count) {</span>
<span class="udiff-line-added">+   prepend_list_to_common(list, tail, count, &amp;om_list_globals._wait_list,</span>
<span class="udiff-line-added">+                          &amp;om_list_globals._wait_count);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // Prepend a list of ObjectMonitors to om_list_globals._in_use_list.
  // &#39;tail&#39; is the last ObjectMonitor in the list and there are &#39;count&#39;
  // on the list. Also updates om_list_globals._in_use_list.
  static void prepend_list_to_global_in_use_list(ObjectMonitor* list,
                                                 ObjectMonitor* tail, int count) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -327,11 +351,11 @@</span>
                                int* count_p) {
    while (true) {
      om_lock(m);  // Lock m so we can safely update its next field.
      ObjectMonitor* cur = NULL;
      // Lock the list head to guard against races with a list walker
<span class="udiff-line-modified-removed">-     // thread:</span>
<span class="udiff-line-modified-added">+     // or async deflater thread (which only races in om_in_use_list):</span>
      if ((cur = get_list_head_locked(list_p)) != NULL) {
        // List head is now locked so we can safely switch it.
        m-&gt;set_next_om(cur);  // m now points to cur (and unlocks m)
        Atomic::store(list_p, m);  // Switch list head to unlocked m.
        om_unlock(cur);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -365,11 +389,11 @@</span>
  // decrements the specified counter. Returns NULL if none are available.
  static ObjectMonitor* take_from_start_of_common(ObjectMonitor** list_p,
                                                  int* count_p) {
    ObjectMonitor* take = NULL;
    // Lock the list head to guard against races with a list walker
<span class="udiff-line-modified-removed">-   // thread:</span>
<span class="udiff-line-modified-added">+   // or async deflater thread (which only races in om_list_globals._free_list):</span>
    if ((take = get_list_head_locked(list_p)) == NULL) {
      return NULL;  // None are available.
    }
    ObjectMonitor* next = unmarked_next(take);
    // Switch locked list head to next (which unlocks the list head, but
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -480,11 +504,20 @@</span>
    assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);
    const markWord mark = obj-&gt;mark();
  
    if (mark.has_monitor()) {
      ObjectMonitor* const m = mark.monitor();
<span class="udiff-line-modified-removed">-     assert(m-&gt;object() == obj, &quot;invariant&quot;);</span>
<span class="udiff-line-modified-added">+     if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+       // An async deflation can race us before we manage to make the</span>
<span class="udiff-line-added">+       // ObjectMonitor busy by setting the owner below. If we detect</span>
<span class="udiff-line-added">+       // that race we just bail out to the slow-path here.</span>
<span class="udiff-line-added">+       if (m-&gt;object() == NULL) {</span>
<span class="udiff-line-added">+         return false;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       assert(m-&gt;object() == obj, &quot;invariant&quot;);</span>
<span class="udiff-line-added">+     }</span>
      Thread* const owner = (Thread *) m-&gt;_owner;
  
      // Lock contention and Transactional Lock Elision (TLE) diagnostics
      // and observability
      // Case: light contention possibly amenable to TLE
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -561,11 +594,19 @@</span>
    // The object header will never be displaced to this lock,
    // so it does not matter what the value is, except that it
    // must be non-zero to avoid looking like a re-entrant lock,
    // and must not look locked either.
    lock-&gt;set_displaced_header(markWord::unused_mark());
<span class="udiff-line-modified-removed">-   inflate(THREAD, obj(), inflate_cause_monitor_enter)-&gt;enter(THREAD);</span>
<span class="udiff-line-modified-added">+   // An async deflation can race after the inflate() call and before</span>
<span class="udiff-line-added">+   // enter() can make the ObjectMonitor busy. enter() returns false if</span>
<span class="udiff-line-added">+   // we have lost the race to async deflation and we simply try again.</span>
<span class="udiff-line-added">+   while (true) {</span>
<span class="udiff-line-added">+     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_monitor_enter);</span>
<span class="udiff-line-added">+     if (monitor-&gt;enter(THREAD)) {</span>
<span class="udiff-line-added">+       return;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
  }
  
  void ObjectSynchronizer::exit(oop object, BasicLock* lock, TRAPS) {
    markWord mark = object-&gt;mark();
    if (EnableValhalla &amp;&amp; mark.is_always_locked()) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -614,11 +655,14 @@</span>
        return;
      }
    }
  
    // We have to take the slow-path of possible inflation and then exit.
<span class="udiff-line-modified-removed">-   inflate(THREAD, object, inflate_cause_vm_internal)-&gt;exit(true, THREAD);</span>
<span class="udiff-line-modified-added">+   // The ObjectMonitor* can&#39;t be async deflated until ownership is</span>
<span class="udiff-line-added">+   // dropped inside exit() and the ObjectMonitor* must be !is_busy().</span>
<span class="udiff-line-added">+   ObjectMonitor* monitor = inflate(THREAD, object, inflate_cause_vm_internal);</span>
<span class="udiff-line-added">+   monitor-&gt;exit(true, THREAD);</span>
  }
  
  // -----------------------------------------------------------------------------
  // Class Loader  support to workaround deadlocks on the class loader lock objects
  // Also used by GC
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -636,27 +680,37 @@</span>
    if (UseBiasedLocking) {
      BiasedLocking::revoke(obj, THREAD);
      assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
    }
  
<span class="udiff-line-added">+   // The ObjectMonitor* can&#39;t be async deflated until ownership is</span>
<span class="udiff-line-added">+   // dropped inside exit() and the ObjectMonitor* must be !is_busy().</span>
    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   return monitor-&gt;complete_exit(THREAD);</span>
<span class="udiff-line-modified-added">+   intptr_t ret_code = monitor-&gt;complete_exit(THREAD);</span>
<span class="udiff-line-modified-added">+   return ret_code;</span>
  }
  
  // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
  void ObjectSynchronizer::reenter(Handle obj, intx recursions, TRAPS) {
    assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);
    if (UseBiasedLocking) {
      BiasedLocking::revoke(obj, THREAD);
      assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
    }
  
<span class="udiff-line-modified-removed">-   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   monitor-&gt;reenter(recursions, THREAD);</span>
<span class="udiff-line-modified-added">+   // An async deflation can race after the inflate() call and before</span>
<span class="udiff-line-modified-added">+   // reenter() -&gt; enter() can make the ObjectMonitor busy. reenter() -&gt;</span>
<span class="udiff-line-modified-added">+   // enter() returns false if we have lost the race to async deflation</span>
<span class="udiff-line-added">+   // and we simply try again.</span>
<span class="udiff-line-added">+   while (true) {</span>
<span class="udiff-line-added">+     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);</span>
<span class="udiff-line-added">+     if (monitor-&gt;reenter(recursions, THREAD)) {</span>
<span class="udiff-line-added">+       return;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
  }
<span class="udiff-line-added">+ </span>
  // -----------------------------------------------------------------------------
  // JNI locks on java objects
  // NOTE: must use heavy weight monitor to handle jni monitor enter
  void ObjectSynchronizer::jni_enter(Handle obj, TRAPS) {
    // the current locking is from JNI instead of Java code
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -664,11 +718,19 @@</span>
    if (UseBiasedLocking) {
      BiasedLocking::revoke(obj, THREAD);
      assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
    }
    THREAD-&gt;set_current_pending_monitor_is_from_java(false);
<span class="udiff-line-modified-removed">-   inflate(THREAD, obj(), inflate_cause_jni_enter)-&gt;enter(THREAD);</span>
<span class="udiff-line-modified-added">+   // An async deflation can race after the inflate() call and before</span>
<span class="udiff-line-added">+   // enter() can make the ObjectMonitor busy. enter() returns false if</span>
<span class="udiff-line-added">+   // we have lost the race to async deflation and we simply try again.</span>
<span class="udiff-line-added">+   while (true) {</span>
<span class="udiff-line-added">+     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_jni_enter);</span>
<span class="udiff-line-added">+     if (monitor-&gt;enter(THREAD)) {</span>
<span class="udiff-line-added">+       break;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
    THREAD-&gt;set_current_pending_monitor_is_from_java(true);
  }
  
  // NOTE: must use heavy weight monitor to handle jni monitor exit
  void ObjectSynchronizer::jni_exit(oop obj, Thread* THREAD) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -678,10 +740,12 @@</span>
      BiasedLocking::revoke(h_obj, THREAD);
      obj = h_obj();
    }
    assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
  
<span class="udiff-line-added">+   // The ObjectMonitor* can&#39;t be async deflated until ownership is</span>
<span class="udiff-line-added">+   // dropped inside exit() and the ObjectMonitor* must be !is_busy().</span>
    ObjectMonitor* monitor = inflate(THREAD, obj, inflate_cause_jni_exit);
    // If this thread has locked the object, exit the monitor. We
    // intentionally do not use CHECK here because we must exit the
    // monitor even if an exception is pending.
    if (monitor-&gt;check_owner(THREAD)) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -720,20 +784,24 @@</span>
      assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
    }
    if (millis &lt; 0) {
      THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), &quot;timeout value is negative&quot;);
    }
<span class="udiff-line-added">+   // The ObjectMonitor* can&#39;t be async deflated because the _waiters</span>
<span class="udiff-line-added">+   // field is incremented before ownership is dropped and decremented</span>
<span class="udiff-line-added">+   // after ownership is regained.</span>
    ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);
  
    DTRACE_MONITOR_WAIT_PROBE(monitor, obj(), THREAD, millis);
    monitor-&gt;wait(millis, true, THREAD);
  
    // This dummy call is in place to get around dtrace bug 6254741.  Once
    // that&#39;s fixed we can uncomment the following line, remove the call
    // and change this function back into a &quot;void&quot; func.
    // DTRACE_MONITOR_PROBE(waited, monitor, obj(), THREAD);
<span class="udiff-line-modified-removed">-   return dtrace_waited_probe(monitor, obj, THREAD);</span>
<span class="udiff-line-modified-added">+   int ret_code = dtrace_waited_probe(monitor, obj, THREAD);</span>
<span class="udiff-line-added">+   return ret_code;</span>
  }
  
  void ObjectSynchronizer::wait_uninterruptibly(Handle obj, jlong millis, TRAPS) {
    CHECK_THROW_NOSYNC_IMSE(obj);
    if (UseBiasedLocking) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -741,11 +809,15 @@</span>
      assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
    }
    if (millis &lt; 0) {
      THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), &quot;timeout value is negative&quot;);
    }
<span class="udiff-line-modified-removed">-   inflate(THREAD, obj(), inflate_cause_wait)-&gt;wait(millis, false, THREAD);</span>
<span class="udiff-line-modified-added">+   // The ObjectMonitor* can&#39;t be async deflated because the _waiters</span>
<span class="udiff-line-added">+   // field is incremented before ownership is dropped and decremented</span>
<span class="udiff-line-added">+   // after ownership is regained.</span>
<span class="udiff-line-added">+   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_wait);</span>
<span class="udiff-line-added">+   monitor-&gt;wait(millis, false, THREAD);</span>
  }
  
  void ObjectSynchronizer::notify(Handle obj, TRAPS) {
    CHECK_THROW_NOSYNC_IMSE(obj);
    if (UseBiasedLocking) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -755,11 +827,14 @@</span>
  
    markWord mark = obj-&gt;mark();
    if (mark.has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark.locker())) {
      return;
    }
<span class="udiff-line-modified-removed">-   inflate(THREAD, obj(), inflate_cause_notify)-&gt;notify(THREAD);</span>
<span class="udiff-line-modified-added">+   // The ObjectMonitor* can&#39;t be async deflated until ownership is</span>
<span class="udiff-line-added">+   // dropped by the calling thread.</span>
<span class="udiff-line-added">+   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);</span>
<span class="udiff-line-added">+   monitor-&gt;notify(THREAD);</span>
  }
  
  // NOTE: see comment of notify()
  void ObjectSynchronizer::notifyall(Handle obj, TRAPS) {
    CHECK_THROW_NOSYNC_IMSE(obj);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -770,11 +845,14 @@</span>
  
    markWord mark = obj-&gt;mark();
    if (mark.has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark.locker())) {
      return;
    }
<span class="udiff-line-modified-removed">-   inflate(THREAD, obj(), inflate_cause_notify)-&gt;notifyAll(THREAD);</span>
<span class="udiff-line-modified-added">+   // The ObjectMonitor* can&#39;t be async deflated until ownership is</span>
<span class="udiff-line-added">+   // dropped by the calling thread.</span>
<span class="udiff-line-added">+   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_notify);</span>
<span class="udiff-line-added">+   monitor-&gt;notifyAll(THREAD);</span>
  }
  
  // -----------------------------------------------------------------------------
  // Hash Code handling
  //
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -970,88 +1048,120 @@</span>
    assert(Universe::verify_in_progress() || DumpSharedSpaces ||
           self-&gt;is_Java_thread() , &quot;invariant&quot;);
    assert(Universe::verify_in_progress() || DumpSharedSpaces ||
           ((JavaThread *)self)-&gt;thread_state() != _thread_blocked, &quot;invariant&quot;);
  
<span class="udiff-line-modified-removed">-   ObjectMonitor* monitor = NULL;</span>
<span class="udiff-line-modified-removed">-   markWord temp, test;</span>
<span class="udiff-line-modified-removed">-   intptr_t hash;</span>
<span class="udiff-line-modified-removed">-   markWord mark = read_stable_mark(obj);</span>
<span class="udiff-line-modified-added">+   while (true) {</span>
<span class="udiff-line-modified-added">+     ObjectMonitor* monitor = NULL;</span>
<span class="udiff-line-modified-added">+     markWord temp, test;</span>
<span class="udiff-line-modified-added">+     intptr_t hash;</span>
<span class="udiff-line-added">+     markWord mark = read_stable_mark(obj);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // object should remain ineligible for biased locking</span>
<span class="udiff-line-added">+     assert(!mark.has_bias_pattern(), &quot;invariant&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (mark.is_neutral()) {            // if this is a normal header</span>
<span class="udiff-line-added">+       hash = mark.hash();</span>
<span class="udiff-line-added">+       if (hash != 0) {                  // if it has a hash, just return it</span>
<span class="udiff-line-added">+         return hash;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       hash = get_next_hash(self, obj);  // get a new hash</span>
<span class="udiff-line-added">+       temp = mark.copy_set_hash(hash);  // merge the hash into header</span>
<span class="udiff-line-added">+                                         // try to install the hash</span>
<span class="udiff-line-added">+       test = obj-&gt;cas_set_mark(temp, mark);</span>
<span class="udiff-line-added">+       if (test == mark) {               // if the hash was installed, return it</span>
<span class="udiff-line-added">+         return hash;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // Failed to install the hash. It could be that another thread</span>
<span class="udiff-line-added">+       // installed the hash just before our attempt or inflation has</span>
<span class="udiff-line-added">+       // occurred or... so we fall thru to inflate the monitor for</span>
<span class="udiff-line-added">+       // stability and then install the hash.</span>
<span class="udiff-line-added">+     } else if (mark.has_monitor()) {</span>
<span class="udiff-line-added">+       monitor = mark.monitor();</span>
<span class="udiff-line-added">+       temp = monitor-&gt;header();</span>
<span class="udiff-line-added">+       assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-added">+       hash = temp.hash();</span>
<span class="udiff-line-added">+       if (hash != 0) {</span>
<span class="udiff-line-added">+         // It has a hash.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         // Separate load of dmw/header above from the loads in</span>
<span class="udiff-line-added">+         // is_being_async_deflated().</span>
<span class="udiff-line-added">+         if (support_IRIW_for_not_multiple_copy_atomic_cpu) {</span>
<span class="udiff-line-added">+           // A non-multiple copy atomic (nMCA) machine needs a bigger</span>
<span class="udiff-line-added">+           // hammer to separate the load above and the loads below.</span>
<span class="udiff-line-added">+           OrderAccess::fence();</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           OrderAccess::loadload();</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         if (monitor-&gt;is_being_async_deflated()) {</span>
<span class="udiff-line-added">+           // But we can&#39;t safely use the hash if we detect that async</span>
<span class="udiff-line-added">+           // deflation has occurred. So we attempt to restore the</span>
<span class="udiff-line-added">+           // header/dmw to the object&#39;s header so that we only retry</span>
<span class="udiff-line-added">+           // once if the deflater thread happens to be slow.</span>
<span class="udiff-line-added">+           monitor-&gt;install_displaced_markword_in_object(obj);</span>
<span class="udiff-line-added">+           continue;</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         return hash;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // Fall thru so we only have one place that installs the hash in</span>
<span class="udiff-line-added">+       // the ObjectMonitor.</span>
<span class="udiff-line-added">+     } else if (self-&gt;is_lock_owned((address)mark.locker())) {</span>
<span class="udiff-line-added">+       // This is a stack lock owned by the calling thread so fetch the</span>
<span class="udiff-line-added">+       // displaced markWord from the BasicLock on the stack.</span>
<span class="udiff-line-added">+       temp = mark.displaced_mark_helper();</span>
<span class="udiff-line-added">+       assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-added">+       hash = temp.hash();</span>
<span class="udiff-line-added">+       if (hash != 0) {                  // if it has a hash, just return it</span>
<span class="udiff-line-added">+         return hash;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // WARNING:</span>
<span class="udiff-line-added">+       // The displaced header in the BasicLock on a thread&#39;s stack</span>
<span class="udiff-line-added">+       // is strictly immutable. It CANNOT be changed in ANY cases.</span>
<span class="udiff-line-added">+       // So we have to inflate the stack lock into an ObjectMonitor</span>
<span class="udiff-line-added">+       // even if the current thread owns the lock. The BasicLock on</span>
<span class="udiff-line-added">+       // a thread&#39;s stack can be asynchronously read by other threads</span>
<span class="udiff-line-added">+       // during an inflate() call so any change to that stack memory</span>
<span class="udiff-line-added">+       // may not propagate to other threads correctly.</span>
<span class="udiff-line-added">+     }</span>
  
<span class="udiff-line-modified-removed">-   // object should remain ineligible for biased locking</span>
<span class="udiff-line-removed">-   assert(!mark.has_bias_pattern(), &quot;invariant&quot;);</span>
<span class="udiff-line-modified-added">+     // Inflate the monitor to set the hash.</span>
  
<span class="udiff-line-modified-removed">-   if (mark.is_neutral()) {            // if this is a normal header</span>
<span class="udiff-line-modified-added">+     // An async deflation can race after the inflate() call and before we</span>
<span class="udiff-line-added">+     // can update the ObjectMonitor&#39;s header with the hash value below.</span>
<span class="udiff-line-added">+     monitor = inflate(self, obj, inflate_cause_hash_code);</span>
<span class="udiff-line-added">+     // Load ObjectMonitor&#39;s header/dmw field and see if it has a hash.</span>
<span class="udiff-line-added">+     mark = monitor-&gt;header();</span>
<span class="udiff-line-added">+     assert(mark.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, mark.value());</span>
      hash = mark.hash();
<span class="udiff-line-modified-removed">-     if (hash != 0) {                  // if it has a hash, just return it</span>
<span class="udiff-line-modified-removed">-       return hash;</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-modified-removed">-     hash = get_next_hash(self, obj);  // get a new hash</span>
<span class="udiff-line-modified-removed">-     temp = mark.copy_set_hash(hash);  // merge the hash into header</span>
<span class="udiff-line-modified-removed">-                                       // try to install the hash</span>
<span class="udiff-line-modified-removed">-     test = obj-&gt;cas_set_mark(temp, mark);</span>
<span class="udiff-line-modified-removed">-     if (test == mark) {               // if the hash was installed, return it</span>
<span class="udiff-line-modified-removed">-       return hash;</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-modified-removed">-     // Failed to install the hash. It could be that another thread</span>
<span class="udiff-line-modified-removed">-     // installed the hash just before our attempt or inflation has</span>
<span class="udiff-line-modified-removed">-     // occurred or... so we fall thru to inflate the monitor for</span>
<span class="udiff-line-modified-removed">-     // stability and then install the hash.</span>
<span class="udiff-line-modified-removed">-   } else if (mark.has_monitor()) {</span>
<span class="udiff-line-modified-removed">-     monitor = mark.monitor();</span>
<span class="udiff-line-modified-removed">-     temp = monitor-&gt;header();</span>
<span class="udiff-line-modified-removed">-     assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-modified-removed">-     hash = temp.hash();</span>
<span class="udiff-line-modified-removed">-     if (hash != 0) {                  // if it has a hash, just return it</span>
<span class="udiff-line-modified-removed">-       return hash;</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-modified-removed">-     // Fall thru so we only have one place that installs the hash in</span>
<span class="udiff-line-modified-removed">-     // the ObjectMonitor.</span>
<span class="udiff-line-modified-removed">-   } else if (self-&gt;is_lock_owned((address)mark.locker())) {</span>
<span class="udiff-line-modified-removed">-     // This is a stack lock owned by the calling thread so fetch the</span>
<span class="udiff-line-modified-removed">-     // displaced markWord from the BasicLock on the stack.</span>
<span class="udiff-line-modified-removed">-     temp = mark.displaced_mark_helper();</span>
<span class="udiff-line-removed">-     assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-removed">-     hash = temp.hash();</span>
<span class="udiff-line-removed">-     if (hash != 0) {                  // if it has a hash, just return it</span>
<span class="udiff-line-removed">-       return hash;</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-     // WARNING:</span>
<span class="udiff-line-removed">-     // The displaced header in the BasicLock on a thread&#39;s stack</span>
<span class="udiff-line-removed">-     // is strictly immutable. It CANNOT be changed in ANY cases.</span>
<span class="udiff-line-removed">-     // So we have to inflate the stack lock into an ObjectMonitor</span>
<span class="udiff-line-removed">-     // even if the current thread owns the lock. The BasicLock on</span>
<span class="udiff-line-removed">-     // a thread&#39;s stack can be asynchronously read by other threads</span>
<span class="udiff-line-removed">-     // during an inflate() call so any change to that stack memory</span>
<span class="udiff-line-removed">-     // may not propagate to other threads correctly.</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-   // Inflate the monitor to set the hash.</span>
<span class="udiff-line-removed">-   monitor = inflate(self, obj, inflate_cause_hash_code);</span>
<span class="udiff-line-removed">-   // Load ObjectMonitor&#39;s header/dmw field and see if it has a hash.</span>
<span class="udiff-line-removed">-   mark = monitor-&gt;header();</span>
<span class="udiff-line-removed">-   assert(mark.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, mark.value());</span>
<span class="udiff-line-removed">-   hash = mark.hash();</span>
<span class="udiff-line-removed">-   if (hash == 0) {                    // if it does not have a hash</span>
<span class="udiff-line-removed">-     hash = get_next_hash(self, obj);  // get a new hash</span>
<span class="udiff-line-removed">-     temp = mark.copy_set_hash(hash);  // merge the hash into header</span>
<span class="udiff-line-removed">-     assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-removed">-     uintptr_t v = Atomic::cmpxchg((volatile uintptr_t*)monitor-&gt;header_addr(), mark.value(), temp.value());</span>
<span class="udiff-line-removed">-     test = markWord(v);</span>
<span class="udiff-line-removed">-     if (test != mark) {</span>
<span class="udiff-line-removed">-       // The attempt to update the ObjectMonitor&#39;s header/dmw field</span>
<span class="udiff-line-removed">-       // did not work. This can happen if another thread managed to</span>
<span class="udiff-line-removed">-       // merge in the hash just before our cmpxchg().</span>
<span class="udiff-line-removed">-       // If we add any new usages of the header/dmw field, this code</span>
<span class="udiff-line-removed">-       // will need to be updated.</span>
<span class="udiff-line-removed">-       hash = test.hash();</span>
<span class="udiff-line-removed">-       assert(test.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, test.value());</span>
<span class="udiff-line-removed">-       assert(hash != 0, &quot;should only have lost the race to a thread that set a non-zero hash&quot;);</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">-   // We finally get the hash.</span>
<span class="udiff-line-removed">-   return hash;</span>
<span class="udiff-line-modified-added">+     if (hash == 0) {                    // if it does not have a hash</span>
<span class="udiff-line-modified-added">+       hash = get_next_hash(self, obj);  // get a new hash</span>
<span class="udiff-line-modified-added">+       temp = mark.copy_set_hash(hash);  // merge the hash into header</span>
<span class="udiff-line-modified-added">+       assert(temp.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, temp.value());</span>
<span class="udiff-line-modified-added">+       uintptr_t v = Atomic::cmpxchg((volatile uintptr_t*)monitor-&gt;header_addr(), mark.value(), temp.value());</span>
<span class="udiff-line-modified-added">+       test = markWord(v);</span>
<span class="udiff-line-modified-added">+       if (test != mark) {</span>
<span class="udiff-line-modified-added">+         // The attempt to update the ObjectMonitor&#39;s header/dmw field</span>
<span class="udiff-line-modified-added">+         // did not work. This can happen if another thread managed to</span>
<span class="udiff-line-modified-added">+         // merge in the hash just before our cmpxchg().</span>
<span class="udiff-line-modified-added">+         // If we add any new usages of the header/dmw field, this code</span>
<span class="udiff-line-modified-added">+         // will need to be updated.</span>
<span class="udiff-line-modified-added">+         hash = test.hash();</span>
<span class="udiff-line-modified-added">+         assert(test.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, test.value());</span>
<span class="udiff-line-modified-added">+         assert(hash != 0, &quot;should only have lost the race to a thread that set a non-zero hash&quot;);</span>
<span class="udiff-line-modified-added">+       }</span>
<span class="udiff-line-modified-added">+       if (monitor-&gt;is_being_async_deflated()) {</span>
<span class="udiff-line-modified-added">+         // If we detect that async deflation has occurred, then we</span>
<span class="udiff-line-modified-added">+         // attempt to restore the header/dmw to the object&#39;s header</span>
<span class="udiff-line-modified-added">+         // so that we only retry once if the deflater thread happens</span>
<span class="udiff-line-modified-added">+         // to be slow.</span>
<span class="udiff-line-modified-added">+         monitor-&gt;install_displaced_markword_in_object(obj);</span>
<span class="udiff-line-modified-added">+         continue;</span>
<span class="udiff-line-modified-added">+       }</span>
<span class="udiff-line-modified-added">+     }</span>
<span class="udiff-line-modified-added">+     // We finally get the hash.</span>
<span class="udiff-line-modified-added">+     return hash;</span>
<span class="udiff-line-modified-added">+   }</span>
  }
  
  
  bool ObjectSynchronizer::current_thread_holds_lock(JavaThread* thread,
                                                     Handle h_obj) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1072,10 +1182,12 @@</span>
    if (mark.has_locker()) {
      return thread-&gt;is_lock_owned((address)mark.locker());
    }
    // Contended case, header points to ObjectMonitor (tagged pointer)
    if (mark.has_monitor()) {
<span class="udiff-line-added">+     // The first stage of async deflation does not affect any field</span>
<span class="udiff-line-added">+     // used by this comparison so the ObjectMonitor* is usable here.</span>
      ObjectMonitor* monitor = mark.monitor();
      return monitor-&gt;is_entered(thread) != 0;
    }
    // Unlocked case, header in place
    assert(mark.is_neutral(), &quot;sanity check&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1113,13 +1225,16 @@</span>
        owner_self : owner_other;
    }
  
    // CASE: inflated. Mark (tagged pointer) points to an ObjectMonitor.
    // The Object:ObjectMonitor relationship is stable as long as we&#39;re
<span class="udiff-line-modified-removed">-   // not at a safepoint.</span>
<span class="udiff-line-modified-added">+   // not at a safepoint and AsyncDeflateIdleMonitors is false.</span>
    if (mark.has_monitor()) {
<span class="udiff-line-modified-removed">-     void* owner = mark.monitor()-&gt;_owner;</span>
<span class="udiff-line-modified-added">+     // The first stage of async deflation does not affect any field</span>
<span class="udiff-line-added">+     // used by this comparison so the ObjectMonitor* is usable here.</span>
<span class="udiff-line-added">+     ObjectMonitor* monitor = mark.monitor();</span>
<span class="udiff-line-added">+     void* owner = monitor-&gt;owner();</span>
      if (owner == NULL) return owner_none;
      return (owner == self ||
              self-&gt;is_lock_owned((address)owner)) ? owner_self : owner_other;
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1149,10 +1264,12 @@</span>
      owner = (address) mark.locker();
    }
  
    // Contended case, header points to ObjectMonitor (tagged pointer)
    else if (mark.has_monitor()) {
<span class="udiff-line-added">+     // The first stage of async deflation does not affect any field</span>
<span class="udiff-line-added">+     // used by this comparison so the ObjectMonitor* is usable here.</span>
      ObjectMonitor* monitor = mark.monitor();
      assert(monitor != NULL, &quot;monitor should be non-null&quot;);
      owner = (address) monitor-&gt;owner();
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1175,13 +1292,19 @@</span>
    PaddedObjectMonitor* block = Atomic::load(&amp;g_block_list);
    while (block != NULL) {
      assert(block-&gt;object() == CHAINMARKER, &quot;must be a block header&quot;);
      for (int i = _BLOCKSIZE - 1; i &gt; 0; i--) {
        ObjectMonitor* mid = (ObjectMonitor *)(block + i);
<span class="udiff-line-modified-removed">-       oop object = (oop)mid-&gt;object();</span>
<span class="udiff-line-removed">-       if (object != NULL) {</span>
<span class="udiff-line-modified-added">+       if (mid-&gt;object() != NULL) {</span>
          // Only process with closure if the object is set.
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         // monitors_iterate() is only called at a safepoint or when the</span>
<span class="udiff-line-added">+         // target thread is suspended or when the target thread is</span>
<span class="udiff-line-added">+         // operating on itself. The current closures in use today are</span>
<span class="udiff-line-added">+         // only interested in an owned ObjectMonitor and ownership</span>
<span class="udiff-line-added">+         // cannot be dropped under the calling contexts so the</span>
<span class="udiff-line-added">+         // ObjectMonitor cannot be async deflated.</span>
          closure-&gt;do_monitor(mid);
        }
      }
      // unmarked_next() is not needed with g_block_list (no locking
      // used with block linkage _next_om fields).
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1193,19 +1316,57 @@</span>
    int population = Atomic::load(&amp;om_list_globals._population);
    if (population == 0) {
      return false;
    }
    if (MonitorUsedDeflationThreshold &gt; 0) {
<span class="udiff-line-modified-removed">-     int monitors_used = population - Atomic::load(&amp;om_list_globals._free_count);</span>
<span class="udiff-line-modified-added">+     int monitors_used = population - Atomic::load(&amp;om_list_globals._free_count) -</span>
<span class="udiff-line-added">+                         Atomic::load(&amp;om_list_globals._wait_count);</span>
      int monitor_usage = (monitors_used * 100LL) / population;
      return monitor_usage &gt; MonitorUsedDeflationThreshold;
    }
    return false;
  }
  
<span class="udiff-line-modified-removed">- bool ObjectSynchronizer::is_cleanup_needed() {</span>
<span class="udiff-line-modified-removed">-   return monitors_used_above_threshold();</span>
<span class="udiff-line-modified-added">+ bool ObjectSynchronizer::is_async_deflation_needed() {</span>
<span class="udiff-line-modified-added">+   if (!AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (is_async_deflation_requested()) {</span>
<span class="udiff-line-added">+     // Async deflation request.</span>
<span class="udiff-line-added">+     return true;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (AsyncDeflationInterval &gt; 0 &amp;&amp;</span>
<span class="udiff-line-added">+       time_since_last_async_deflation_ms() &gt; AsyncDeflationInterval &amp;&amp;</span>
<span class="udiff-line-added">+       monitors_used_above_threshold()) {</span>
<span class="udiff-line-added">+     // It&#39;s been longer than our specified deflate interval and there</span>
<span class="udiff-line-added">+     // are too many monitors in use. We don&#39;t deflate more frequently</span>
<span class="udiff-line-added">+     // than AsyncDeflationInterval (unless is_async_deflation_requested)</span>
<span class="udiff-line-added">+     // in order to not swamp the ServiceThread.</span>
<span class="udiff-line-added">+     _last_async_deflation_time_ns = os::javaTimeNanos();</span>
<span class="udiff-line-added">+     return true;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   return false;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ bool ObjectSynchronizer::is_safepoint_deflation_needed() {</span>
<span class="udiff-line-added">+   if (!AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+     if (monitors_used_above_threshold()) {</span>
<span class="udiff-line-added">+       // Too many monitors in use.</span>
<span class="udiff-line-added">+       return true;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (is_special_deflation_requested()) {</span>
<span class="udiff-line-added">+     // For AsyncDeflateIdleMonitors only do a safepoint deflation</span>
<span class="udiff-line-added">+     // if there is a special deflation request.</span>
<span class="udiff-line-added">+     return true;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   return false;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ jlong ObjectSynchronizer::time_since_last_async_deflation_ms() {</span>
<span class="udiff-line-added">+   return (os::javaTimeNanos() - _last_async_deflation_time_ns) / (NANOUNITS / MILLIUNITS);</span>
  }
  
  void ObjectSynchronizer::oops_do(OopClosure* f) {
    // We only scan the global used list here (for moribund threads), and
    // the thread-local monitors in Thread::oops_do().
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1237,11 +1398,11 @@</span>
  // -----------------------------------------------------------------------------
  // ObjectMonitor Lifecycle
  // -----------------------
  // Inflation unlinks monitors from om_list_globals._free_list or a per-thread
  // free list and associates them with objects. Deflation -- which occurs at
<span class="udiff-line-modified-removed">- // STW-time -- disassociates idle monitors from objects.</span>
<span class="udiff-line-modified-added">+ // STW-time or asynchronously -- disassociates idle monitors from objects.</span>
  // Such scavenged monitors are returned to the om_list_globals._free_list.
  //
  // ObjectMonitors reside in type-stable memory (TSM) and are immortal.
  //
  // Lifecycle:
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1269,10 +1430,11 @@</span>
      // improve allocation latency, as well as reducing coherency traffic
      // on the shared global list.
      m = take_from_start_of_om_free_list(self);
      if (m != NULL) {
        guarantee(m-&gt;object() == NULL, &quot;invariant&quot;);
<span class="udiff-line-added">+       m-&gt;set_allocation_state(ObjectMonitor::New);</span>
        prepend_to_om_in_use_list(self, m);
        return m;
      }
  
      // 2: try to allocate from the global om_list_globals._free_list
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1286,11 +1448,33 @@</span>
          ObjectMonitor* take = take_from_start_of_global_free_list();
          if (take == NULL) {
            break;  // No more are available.
          }
          guarantee(take-&gt;object() == NULL, &quot;invariant&quot;);
<span class="udiff-line-added">+         if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+           // We allowed 3 field values to linger during async deflation.</span>
<span class="udiff-line-added">+           // Clear or restore them as appropriate.</span>
<span class="udiff-line-added">+           take-&gt;set_header(markWord::zero());</span>
<span class="udiff-line-added">+           // DEFLATER_MARKER is the only non-NULL value we should see here.</span>
<span class="udiff-line-added">+           take-&gt;try_set_owner_from(DEFLATER_MARKER, NULL);</span>
<span class="udiff-line-added">+           if (take-&gt;contentions() &lt; 0) {</span>
<span class="udiff-line-added">+             // Add back max_jint to restore the contentions field to its</span>
<span class="udiff-line-added">+             // proper value.</span>
<span class="udiff-line-added">+             take-&gt;add_to_contentions(max_jint);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+             jint l_contentions = take-&gt;contentions();</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+             assert(l_contentions &gt;= 0, &quot;must not be negative: l_contentions=%d, contentions=%d&quot;,</span>
<span class="udiff-line-added">+                    l_contentions, take-&gt;contentions());</span>
<span class="udiff-line-added">+           }</span>
<span class="udiff-line-added">+         }</span>
          take-&gt;Recycle();
<span class="udiff-line-added">+         // Since we&#39;re taking from the global free-list, take must be Free.</span>
<span class="udiff-line-added">+         // om_release() also sets the allocation state to Free because it</span>
<span class="udiff-line-added">+         // is called from other code paths.</span>
<span class="udiff-line-added">+         assert(take-&gt;is_free(), &quot;invariant&quot;);</span>
          om_release(self, take, false);
        }
        self-&gt;om_free_provision += 1 + (self-&gt;om_free_provision / 2);
        if (self-&gt;om_free_provision &gt; MAXPRIVATE) self-&gt;om_free_provision = MAXPRIVATE;
        continue;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1320,10 +1504,11 @@</span>
      // linkage should be reconsidered.  A better implementation would
      // look like: class Block { Block * next; int N; ObjectMonitor Body [N] ; }
  
      for (int i = 1; i &lt; _BLOCKSIZE; i++) {
        temp[i].set_next_om((ObjectMonitor*)&amp;temp[i + 1]);
<span class="udiff-line-added">+       assert(temp[i].is_free(), &quot;invariant&quot;);</span>
      }
  
      // terminate the last monitor as the end of list
      temp[_BLOCKSIZE - 1].set_next_om((ObjectMonitor*)NULL);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1345,12 +1530,12 @@</span>
  // a CAS attempt failed. This doesn&#39;t allow unbounded #s of monitors to
  // accumulate on a thread&#39;s free list.
  //
  // Key constraint: all ObjectMonitors on a thread&#39;s free list and the global
  // free list must have their object field set to null. This prevents the
<span class="udiff-line-modified-removed">- // scavenger -- deflate_monitor_list() -- from reclaiming them while we</span>
<span class="udiff-line-modified-removed">- // are trying to release them.</span>
<span class="udiff-line-modified-added">+ // scavenger -- deflate_monitor_list() or deflate_monitor_list_using_JT()</span>
<span class="udiff-line-modified-added">+ // -- from reclaiming them while we are trying to release them.</span>
  
  void ObjectSynchronizer::om_release(Thread* self, ObjectMonitor* m,
                                      bool from_per_thread_alloc) {
    guarantee(m-&gt;header().value() == 0, &quot;invariant&quot;);
    guarantee(m-&gt;object() == NULL, &quot;invariant&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1359,23 +1544,24 @@</span>
    if ((m-&gt;is_busy() | m-&gt;_recursions) != 0) {
      stringStream ss;
      fatal(&quot;freeing in-use monitor: %s, recursions=&quot; INTX_FORMAT,
            m-&gt;is_busy_to_string(&amp;ss), m-&gt;_recursions);
    }
<span class="udiff-line-added">+   m-&gt;set_allocation_state(ObjectMonitor::Free);</span>
    // _next_om is used for both per-thread in-use and free lists so
    // we have to remove &#39;m&#39; from the in-use list first (as needed).
    if (from_per_thread_alloc) {
      // Need to remove &#39;m&#39; from om_in_use_list.
      ObjectMonitor* mid = NULL;
      ObjectMonitor* next = NULL;
  
<span class="udiff-line-modified-removed">-     // This list walk can only race with another list walker since</span>
<span class="udiff-line-modified-removed">-     // deflation can only happen at a safepoint so we don&#39;t have to</span>
<span class="udiff-line-modified-removed">-     // worry about an ObjectMonitor being removed from this list</span>
<span class="udiff-line-removed">-     // while we are walking it.</span>
<span class="udiff-line-modified-added">+     // This list walk can race with another list walker or with async</span>
<span class="udiff-line-modified-added">+     // deflation so we have to worry about an ObjectMonitor being</span>
<span class="udiff-line-modified-added">+     // removed from this list while we are walking it.</span>
  
<span class="udiff-line-modified-removed">-     // Lock the list head to avoid racing with another list walker.</span>
<span class="udiff-line-modified-added">+     // Lock the list head to avoid racing with another list walker</span>
<span class="udiff-line-added">+     // or with async deflation.</span>
      if ((mid = get_list_head_locked(&amp;self-&gt;om_in_use_list)) == NULL) {
        fatal(&quot;thread=&quot; INTPTR_FORMAT &quot; in-use list must not be empty.&quot;, p2i(self));
      }
      next = unmarked_next(mid);
      if (m == mid) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1387,37 +1573,48 @@</span>
      } else if (m == next) {
        // Second special case:
        // &#39;m&#39; matches next after the list head and we already have the list
        // head locked so set mid to what we are extracting:
        mid = next;
<span class="udiff-line-modified-removed">-       // Lock mid to prevent races with a list walker:</span>
<span class="udiff-line-modified-added">+       // Lock mid to prevent races with a list walker or an async</span>
<span class="udiff-line-added">+       // deflater thread that&#39;s ahead of us. The locked list head</span>
<span class="udiff-line-added">+       // prevents races from behind us.</span>
        om_lock(mid);
        // Update next to what follows mid (if anything):
        next = unmarked_next(mid);
        // Switch next after the list head to new next which unlocks the
        // list head, but leaves the extracted mid locked:
        self-&gt;om_in_use_list-&gt;set_next_om(next);
      } else {
        // We have to search the list to find &#39;m&#39;.
<span class="udiff-line-removed">-       om_unlock(mid);  // unlock the list head</span>
        guarantee(next != NULL, &quot;thread=&quot; INTPTR_FORMAT &quot;: om_in_use_list=&quot; INTPTR_FORMAT
                  &quot; is too short.&quot;, p2i(self), p2i(self-&gt;om_in_use_list));
        // Our starting anchor is next after the list head which is the
        // last ObjectMonitor we checked:
        ObjectMonitor* anchor = next;
<span class="udiff-line-added">+       // Lock anchor to prevent races with a list walker or an async</span>
<span class="udiff-line-added">+       // deflater thread that&#39;s ahead of us. The locked list head</span>
<span class="udiff-line-added">+       // prevents races from behind us.</span>
<span class="udiff-line-added">+       om_lock(anchor);</span>
<span class="udiff-line-added">+       om_unlock(mid);  // Unlock the list head now that anchor is locked.</span>
        while ((mid = unmarked_next(anchor)) != NULL) {
          if (m == mid) {
            // We found &#39;m&#39; on the per-thread in-use list so extract it.
<span class="udiff-line-removed">-           om_lock(anchor);  // Lock the anchor so we can safely modify it.</span>
            // Update next to what follows mid (if anything):
            next = unmarked_next(mid);
            // Switch next after the anchor to new next which unlocks the
            // anchor, but leaves the extracted mid locked:
            anchor-&gt;set_next_om(next);
            break;
          } else {
<span class="udiff-line-modified-removed">-           anchor = mid;</span>
<span class="udiff-line-modified-added">+           // Lock the next anchor to prevent races with a list walker</span>
<span class="udiff-line-added">+           // or an async deflater thread that&#39;s ahead of us. The locked</span>
<span class="udiff-line-added">+           // current anchor prevents races from behind us.</span>
<span class="udiff-line-added">+           om_lock(mid);</span>
<span class="udiff-line-added">+           // Unlock current anchor now that next anchor is locked:</span>
<span class="udiff-line-added">+           om_unlock(anchor);</span>
<span class="udiff-line-added">+           anchor = mid;  // Advance to new anchor and try again.</span>
          }
        }
      }
  
      if (mid == NULL) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1434,10 +1631,11 @@</span>
      // the thread&#39;s free list:
      om_unlock(mid);
    }
  
    prepend_to_om_free_list(self, m);
<span class="udiff-line-added">+   guarantee(m-&gt;is_free(), &quot;invariant&quot;);</span>
  }
  
  // Return ObjectMonitors on a moribund thread&#39;s free and in-use
  // lists to the appropriate global lists. The ObjectMonitors on the
  // per-thread in-use list may still be in use by other threads.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1448,20 +1646,28 @@</span>
  // a safepoint and interleave with deflate_idle_monitors(). In
  // particular, this ensures that the thread&#39;s in-use monitors are
  // scanned by a GC safepoint, either via Thread::oops_do() (before
  // om_flush() is called) or via ObjectSynchronizer::oops_do() (after
  // om_flush() is called).
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // With AsyncDeflateIdleMonitors, deflate_global_idle_monitors_using_JT()</span>
<span class="udiff-line-added">+ // and deflate_per_thread_idle_monitors_using_JT() (in another thread) can</span>
<span class="udiff-line-added">+ // run at the same time as om_flush() so we have to follow a careful</span>
<span class="udiff-line-added">+ // protocol to prevent list corruption.</span>
  
  void ObjectSynchronizer::om_flush(Thread* self) {
    // Process the per-thread in-use list first to be consistent.
    int in_use_count = 0;
    ObjectMonitor* in_use_list = NULL;
    ObjectMonitor* in_use_tail = NULL;
    NoSafepointVerifier nsv;
  
<span class="udiff-line-modified-removed">-   // This function can race with a list walker thread so we lock the</span>
<span class="udiff-line-modified-removed">-   // list head to prevent confusion.</span>
<span class="udiff-line-modified-added">+   // This function can race with a list walker or with an async</span>
<span class="udiff-line-modified-added">+   // deflater thread so we lock the list head to prevent confusion.</span>
<span class="udiff-line-added">+   // An async deflater thread checks to see if the target thread</span>
<span class="udiff-line-added">+   // is exiting, but if it has made it past that check before we</span>
<span class="udiff-line-added">+   // started exiting, then it is racing to get to the in-use list.</span>
    if ((in_use_list = get_list_head_locked(&amp;self-&gt;om_in_use_list)) != NULL) {
      // At this point, we have locked the in-use list head so a racing
      // thread cannot come in after us. However, a racing thread could
      // be ahead of us; we&#39;ll detect that and delay to let it finish.
      //
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1472,25 +1678,37 @@</span>
      //
      // Account for the in-use list head before the loop since it is
      // already locked (by this thread):
      in_use_tail = in_use_list;
      in_use_count++;
<span class="udiff-line-modified-removed">-     for (ObjectMonitor* cur_om = unmarked_next(in_use_list); cur_om != NULL; cur_om = unmarked_next(cur_om)) {</span>
<span class="udiff-line-modified-added">+     for (ObjectMonitor* cur_om = unmarked_next(in_use_list); cur_om != NULL;) {</span>
        if (is_locked(cur_om)) {
<span class="udiff-line-modified-removed">-         // cur_om is locked so there must be a racing walker thread ahead</span>
<span class="udiff-line-modified-removed">-         // of us so we&#39;ll give it a chance to finish.</span>
<span class="udiff-line-modified-added">+         // cur_om is locked so there must be a racing walker or async</span>
<span class="udiff-line-modified-added">+         // deflater thread ahead of us so we&#39;ll give it a chance to finish.</span>
          while (is_locked(cur_om)) {
            os::naked_short_sleep(1);
          }
<span class="udiff-line-added">+         // Refetch the possibly changed next field and try again.</span>
<span class="udiff-line-added">+         cur_om = unmarked_next(in_use_tail);</span>
<span class="udiff-line-added">+         continue;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       if (cur_om-&gt;object() == NULL) {</span>
<span class="udiff-line-added">+         // cur_om was deflated and the object ref was cleared while it</span>
<span class="udiff-line-added">+         // was locked. We happened to see it just after it was unlocked</span>
<span class="udiff-line-added">+         // (and added to the free list). Refetch the possibly changed</span>
<span class="udiff-line-added">+         // next field and try again.</span>
<span class="udiff-line-added">+         cur_om = unmarked_next(in_use_tail);</span>
<span class="udiff-line-added">+         continue;</span>
        }
        in_use_tail = cur_om;
        in_use_count++;
<span class="udiff-line-added">+       cur_om = unmarked_next(cur_om);</span>
      }
      guarantee(in_use_tail != NULL, &quot;invariant&quot;);
      int l_om_in_use_count = Atomic::load(&amp;self-&gt;om_in_use_count);
<span class="udiff-line-modified-removed">-     assert(l_om_in_use_count == in_use_count, &quot;in-use counts don&#39;t match: &quot;</span>
<span class="udiff-line-modified-removed">-           &quot;l_om_in_use_count=%d, in_use_count=%d&quot;, l_om_in_use_count, in_use_count);</span>
<span class="udiff-line-modified-added">+     ADIM_guarantee(l_om_in_use_count == in_use_count, &quot;in-use counts don&#39;t match: &quot;</span>
<span class="udiff-line-modified-added">+                    &quot;l_om_in_use_count=%d, in_use_count=%d&quot;, l_om_in_use_count, in_use_count);</span>
      Atomic::store(&amp;self-&gt;om_in_use_count, 0);
      // Clear the in-use list head (which also unlocks it):
      Atomic::store(&amp;self-&gt;om_in_use_list, (ObjectMonitor*)NULL);
      om_unlock(in_use_list);
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1528,12 +1746,12 @@</span>
          fatal(&quot;must be !is_busy: %s&quot;, s-&gt;is_busy_to_string(&amp;ss));
        }
      }
      guarantee(free_tail != NULL, &quot;invariant&quot;);
      int l_om_free_count = Atomic::load(&amp;self-&gt;om_free_count);
<span class="udiff-line-modified-removed">-     assert(l_om_free_count == free_count, &quot;free counts don&#39;t match: &quot;</span>
<span class="udiff-line-modified-removed">-            &quot;l_om_free_count=%d, free_count=%d&quot;, l_om_free_count, free_count);</span>
<span class="udiff-line-modified-added">+     ADIM_guarantee(l_om_free_count == free_count, &quot;free counts don&#39;t match: &quot;</span>
<span class="udiff-line-modified-added">+                    &quot;l_om_free_count=%d, free_count=%d&quot;, l_om_free_count, free_count);</span>
      Atomic::store(&amp;self-&gt;om_free_count, 0);
      Atomic::store(&amp;self-&gt;om_free_list, (ObjectMonitor*)NULL);
      om_unlock(free_list);
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1574,19 +1792,21 @@</span>
  
  // Fast path code shared by multiple functions
  void ObjectSynchronizer::inflate_helper(oop obj) {
    markWord mark = obj-&gt;mark();
    if (mark.has_monitor()) {
<span class="udiff-line-modified-removed">-     assert(ObjectSynchronizer::verify_objmon_isinpool(mark.monitor()), &quot;monitor is invalid&quot;);</span>
<span class="udiff-line-modified-removed">-     assert(mark.monitor()-&gt;header().is_neutral(), &quot;monitor must record a good object header&quot;);</span>
<span class="udiff-line-modified-added">+     ObjectMonitor* monitor = mark.monitor();</span>
<span class="udiff-line-modified-added">+     assert(ObjectSynchronizer::verify_objmon_isinpool(monitor), &quot;monitor=&quot; INTPTR_FORMAT &quot; is invalid&quot;, p2i(monitor));</span>
<span class="udiff-line-added">+     markWord dmw = monitor-&gt;header();</span>
<span class="udiff-line-added">+     assert(dmw.is_neutral(), &quot;sanity check: header=&quot; INTPTR_FORMAT, dmw.value());</span>
      return;
    }
<span class="udiff-line-modified-removed">-   inflate(Thread::current(), obj, inflate_cause_vm_internal);</span>
<span class="udiff-line-modified-added">+   (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);</span>
  }
  
<span class="udiff-line-modified-removed">- ObjectMonitor* ObjectSynchronizer::inflate(Thread* self,</span>
<span class="udiff-line-modified-removed">-                                            oop object, const InflateCause cause) {</span>
<span class="udiff-line-modified-added">+ ObjectMonitor* ObjectSynchronizer::inflate(Thread* self, oop object,</span>
<span class="udiff-line-modified-added">+                                            const InflateCause cause) {</span>
    // Inflate mutates the heap ...
    // Relaxing assertion for bug 6320749.
    assert(Universe::verify_in_progress() ||
           !SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1610,11 +1830,11 @@</span>
      // CASE: inflated
      if (mark.has_monitor()) {
        ObjectMonitor* inf = mark.monitor();
        markWord dmw = inf-&gt;header();
        assert(dmw.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, dmw.value());
<span class="udiff-line-modified-removed">-       assert(inf-&gt;object() == object, &quot;invariant&quot;);</span>
<span class="udiff-line-modified-added">+       assert(AsyncDeflateIdleMonitors || inf-&gt;object() == object, &quot;invariant&quot;);</span>
        assert(ObjectSynchronizer::verify_objmon_isinpool(inf), &quot;monitor is invalid&quot;);
        return inf;
      }
  
      // CASE: inflation in progress - inflating over a stack-lock.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1658,10 +1878,11 @@</span>
        m-&gt;_Responsible  = NULL;
        m-&gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit;   // Consider: maintain by type/class
  
        markWord cmp = object-&gt;cas_set_mark(markWord::INFLATING(), mark);
        if (cmp != mark) {
<span class="udiff-line-added">+         // om_release() will reset the allocation state from New to Free.</span>
          om_release(self, m, true);
          continue;       // Interference -- just retry
        }
  
        // We&#39;ve successfully installed INFLATING (0) into the mark-word.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1695,29 +1916,38 @@</span>
        // object is in the mark.  Furthermore the owner can&#39;t complete
        // an unlock on the object, either.
        markWord dmw = mark.displaced_mark_helper();
        // Catch if the object&#39;s header is not neutral (not locked and
        // not marked is what we care about here).
<span class="udiff-line-modified-removed">-       assert(dmw.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, dmw.value());</span>
<span class="udiff-line-modified-added">+       ADIM_guarantee(dmw.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, dmw.value());</span>
  
        // Setup monitor fields to proper values -- prepare the monitor
        m-&gt;set_header(dmw);
  
        // Optimization: if the mark.locker stack address is associated
        // with this thread we could simply set m-&gt;_owner = self.
        // Note that a thread can inflate an object
        // that it has stack-locked -- as might happen in wait() -- directly
        // with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.
<span class="udiff-line-modified-removed">-       m-&gt;set_owner_from(NULL, mark.locker());</span>
<span class="udiff-line-modified-added">+       if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+         m-&gt;set_owner_from(NULL, DEFLATER_MARKER, mark.locker());</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         m-&gt;set_owner_from(NULL, mark.locker());</span>
<span class="udiff-line-added">+       }</span>
        m-&gt;set_object(object);
        // TODO-FIXME: assert BasicLock-&gt;dhw != 0.
  
        // Must preserve store ordering. The monitor state must
        // be stable at the time of publishing the monitor address.
        guarantee(object-&gt;mark() == markWord::INFLATING(), &quot;invariant&quot;);
        object-&gt;release_set_mark(markWord::encode(m));
  
<span class="udiff-line-added">+       // Once ObjectMonitor is configured and the object is associated</span>
<span class="udiff-line-added">+       // with the ObjectMonitor, it is safe to allow async deflation:</span>
<span class="udiff-line-added">+       assert(m-&gt;is_new(), &quot;freshly allocated monitor must be new&quot;);</span>
<span class="udiff-line-added">+       m-&gt;set_allocation_state(ObjectMonitor::Old);</span>
<span class="udiff-line-added">+ </span>
        // Hopefully the performance counters are allocated on distinct cache lines
        // to avoid false sharing on MP systems ...
        OM_PERFDATA_OP(Inflations, inc());
        if (log_is_enabled(Trace, monitorinflation)) {
          ResourceMark rm(self);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1740,31 +1970,41 @@</span>
      // to inflate and then CAS() again to try to swing _owner from NULL to self.
      // An inflateTry() method that we could call from enter() would be useful.
  
      // Catch if the object&#39;s header is not neutral (not locked and
      // not marked is what we care about here).
<span class="udiff-line-modified-removed">-     assert(mark.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, mark.value());</span>
<span class="udiff-line-modified-added">+     ADIM_guarantee(mark.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, mark.value());</span>
      ObjectMonitor* m = om_alloc(self);
      // prepare m for installation - set monitor to initial state
      m-&gt;Recycle();
      m-&gt;set_header(mark);
<span class="udiff-line-added">+     if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+       // DEFLATER_MARKER is the only non-NULL value we should see here.</span>
<span class="udiff-line-added">+       m-&gt;try_set_owner_from(DEFLATER_MARKER, NULL);</span>
<span class="udiff-line-added">+     }</span>
      m-&gt;set_object(object);
      m-&gt;_Responsible  = NULL;
      m-&gt;_SpinDuration = ObjectMonitor::Knob_SpinLimit;       // consider: keep metastats by type/class
  
      if (object-&gt;cas_set_mark(markWord::encode(m), mark) != mark) {
        m-&gt;set_header(markWord::zero());
        m-&gt;set_object(NULL);
        m-&gt;Recycle();
<span class="udiff-line-added">+       // om_release() will reset the allocation state from New to Free.</span>
        om_release(self, m, true);
        m = NULL;
        continue;
        // interference - the markword changed - just retry.
        // The state-transitions are one-way, so there&#39;s no chance of
        // live-lock -- &quot;Inflated&quot; is an absorbing state.
      }
  
<span class="udiff-line-added">+     // Once the ObjectMonitor is configured and object is associated</span>
<span class="udiff-line-added">+     // with the ObjectMonitor, it is safe to allow async deflation:</span>
<span class="udiff-line-added">+     assert(m-&gt;is_new(), &quot;freshly allocated monitor must be new&quot;);</span>
<span class="udiff-line-added">+     m-&gt;set_allocation_state(ObjectMonitor::Old);</span>
<span class="udiff-line-added">+ </span>
      // Hopefully the performance counters are allocated on distinct
      // cache lines to avoid false sharing on MP systems ...
      OM_PERFDATA_OP(Inflations, inc());
      if (log_is_enabled(Trace, monitorinflation)) {
        ResourceMark rm(self);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1780,10 +2020,11 @@</span>
  }
  
  
  // We maintain a list of in-use monitors for each thread.
  //
<span class="udiff-line-added">+ // For safepoint based deflation:</span>
  // deflate_thread_local_monitors() scans a single thread&#39;s in-use list, while
  // deflate_idle_monitors() scans only a global list of in-use monitors which
  // is populated only as a thread dies (see om_flush()).
  //
  // These operations are called at all safepoints, immediately after mutators
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1798,10 +2039,44 @@</span>
  //
  // Perversely, the heap size -- and thus the STW safepoint rate --
  // typically drives the scavenge rate.  Large heaps can mean infrequent GC,
  // which in turn can mean large(r) numbers of ObjectMonitors in circulation.
  // This is an unfortunate aspect of this design.
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // For async deflation:</span>
<span class="udiff-line-added">+ // If a special deflation request is made, then the safepoint based</span>
<span class="udiff-line-added">+ // deflation mechanism is used. Otherwise, an async deflation request</span>
<span class="udiff-line-added">+ // is registered with the ServiceThread and it is notified.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void ObjectSynchronizer::do_safepoint_work(DeflateMonitorCounters* counters) {</span>
<span class="udiff-line-added">+   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at safepoint&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // The per-thread in-use lists are handled in</span>
<span class="udiff-line-added">+   // ParallelSPCleanupThreadClosure::do_thread().</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (!AsyncDeflateIdleMonitors || is_special_deflation_requested()) {</span>
<span class="udiff-line-added">+     // Use the older mechanism for the global in-use list or if a</span>
<span class="udiff-line-added">+     // special deflation has been requested before the safepoint.</span>
<span class="udiff-line-added">+     ObjectSynchronizer::deflate_idle_monitors(counters);</span>
<span class="udiff-line-added">+     return;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   log_debug(monitorinflation)(&quot;requesting async deflation of idle monitors.&quot;);</span>
<span class="udiff-line-added">+   // Request deflation of idle monitors by the ServiceThread:</span>
<span class="udiff-line-added">+   set_is_async_deflation_requested(true);</span>
<span class="udiff-line-added">+   MonitorLocker ml(Service_lock, Mutex::_no_safepoint_check_flag);</span>
<span class="udiff-line-added">+   ml.notify_all();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (log_is_enabled(Debug, monitorinflation)) {</span>
<span class="udiff-line-added">+     // exit_globals()&#39;s call to audit_and_print_stats() is done</span>
<span class="udiff-line-added">+     // at the Info level and not at a safepoint.</span>
<span class="udiff-line-added">+     // For safepoint based deflation, audit_and_print_stats() is called</span>
<span class="udiff-line-added">+     // in ObjectSynchronizer::finish_deflate_idle_monitors() at the</span>
<span class="udiff-line-added">+     // Debug level at a safepoint.</span>
<span class="udiff-line-added">+     ObjectSynchronizer::audit_and_print_stats(false /* on_exit */);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
  
  // Deflate a single monitor if not in-use
  // Return true if deflated, false if in-use
  bool ObjectSynchronizer::deflate_monitor(ObjectMonitor* mid, oop obj,
                                           ObjectMonitor** free_head_p,
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1833,14 +2108,20 @@</span>
                                    mark.value(), obj-&gt;klass()-&gt;external_name());
      }
  
      // Restore the header back to obj
      obj-&gt;release_set_mark(dmw);
<span class="udiff-line-added">+     if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+       // clear() expects the owner field to be NULL.</span>
<span class="udiff-line-added">+       // DEFLATER_MARKER is the only non-NULL value we should see here.</span>
<span class="udiff-line-added">+       mid-&gt;try_set_owner_from(DEFLATER_MARKER, NULL);</span>
<span class="udiff-line-added">+     }</span>
      mid-&gt;clear();
  
      assert(mid-&gt;object() == NULL, &quot;invariant: object=&quot; INTPTR_FORMAT,
             p2i(mid-&gt;object()));
<span class="udiff-line-added">+     assert(mid-&gt;is_free(), &quot;invariant&quot;);</span>
  
      // Move the deflated ObjectMonitor to the working free list
      // defined by free_head_p and free_tail_p.
      if (*free_head_p == NULL) *free_head_p = mid;
      if (*free_tail_p != NULL) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1865,10 +2146,132 @@</span>
      deflated = true;
    }
    return deflated;
  }
  
<span class="udiff-line-added">+ // Deflate the specified ObjectMonitor if not in-use using a JavaThread.</span>
<span class="udiff-line-added">+ // Returns true if it was deflated and false otherwise.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // The async deflation protocol sets owner to DEFLATER_MARKER and</span>
<span class="udiff-line-added">+ // makes contentions negative as signals to contending threads that</span>
<span class="udiff-line-added">+ // an async deflation is in progress. There are a number of checks</span>
<span class="udiff-line-added">+ // as part of the protocol to make sure that the calling thread has</span>
<span class="udiff-line-added">+ // not lost the race to a contending thread.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // The ObjectMonitor has been successfully async deflated when:</span>
<span class="udiff-line-added">+ //   (contentions &lt; 0)</span>
<span class="udiff-line-added">+ // Contending threads that see that condition know to retry their operation.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ bool ObjectSynchronizer::deflate_monitor_using_JT(ObjectMonitor* mid,</span>
<span class="udiff-line-added">+                                                   ObjectMonitor** free_head_p,</span>
<span class="udiff-line-added">+                                                   ObjectMonitor** free_tail_p) {</span>
<span class="udiff-line-added">+   assert(AsyncDeflateIdleMonitors, &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+   assert(Thread::current()-&gt;is_Java_thread(), &quot;precondition&quot;);</span>
<span class="udiff-line-added">+   // A newly allocated ObjectMonitor should not be seen here so we</span>
<span class="udiff-line-added">+   // avoid an endless inflate/deflate cycle.</span>
<span class="udiff-line-added">+   assert(mid-&gt;is_old(), &quot;must be old: allocation_state=%d&quot;,</span>
<span class="udiff-line-added">+          (int) mid-&gt;allocation_state());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (mid-&gt;is_busy()) {</span>
<span class="udiff-line-added">+     // Easy checks are first - the ObjectMonitor is busy so no deflation.</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Set a NULL owner to DEFLATER_MARKER to force any contending thread</span>
<span class="udiff-line-added">+   // through the slow path. This is just the first part of the async</span>
<span class="udiff-line-added">+   // deflation dance.</span>
<span class="udiff-line-added">+   if (mid-&gt;try_set_owner_from(NULL, DEFLATER_MARKER) != NULL) {</span>
<span class="udiff-line-added">+     // The owner field is no longer NULL so we lost the race since the</span>
<span class="udiff-line-added">+     // ObjectMonitor is now busy.</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (mid-&gt;contentions() &gt; 0 || mid-&gt;_waiters != 0) {</span>
<span class="udiff-line-added">+     // Another thread has raced to enter the ObjectMonitor after</span>
<span class="udiff-line-added">+     // mid-&gt;is_busy() above or has already entered and waited on</span>
<span class="udiff-line-added">+     // it which makes it busy so no deflation. Restore owner to</span>
<span class="udiff-line-added">+     // NULL if it is still DEFLATER_MARKER.</span>
<span class="udiff-line-added">+     if (mid-&gt;try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {</span>
<span class="udiff-line-added">+       // Deferred decrement for the JT EnterI() that cancelled the async deflation.</span>
<span class="udiff-line-added">+       mid-&gt;add_to_contentions(-1);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Make a zero contentions field negative to force any contending threads</span>
<span class="udiff-line-added">+   // to retry. This is the second part of the async deflation dance.</span>
<span class="udiff-line-added">+   if (Atomic::cmpxchg(&amp;mid-&gt;_contentions, (jint)0, -max_jint) != 0) {</span>
<span class="udiff-line-added">+     // Contentions was no longer 0 so we lost the race since the</span>
<span class="udiff-line-added">+     // ObjectMonitor is now busy. Restore owner to NULL if it is</span>
<span class="udiff-line-added">+     // still DEFLATER_MARKER:</span>
<span class="udiff-line-added">+     if (mid-&gt;try_set_owner_from(DEFLATER_MARKER, NULL) != DEFLATER_MARKER) {</span>
<span class="udiff-line-added">+       // Deferred decrement for the JT EnterI() that cancelled the async deflation.</span>
<span class="udiff-line-added">+       mid-&gt;add_to_contentions(-1);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     return false;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Sanity checks for the races:</span>
<span class="udiff-line-added">+   guarantee(mid-&gt;owner_is_DEFLATER_MARKER(), &quot;must be deflater marker&quot;);</span>
<span class="udiff-line-added">+   guarantee(mid-&gt;contentions() &lt; 0, &quot;must be negative: contentions=%d&quot;,</span>
<span class="udiff-line-added">+             mid-&gt;contentions());</span>
<span class="udiff-line-added">+   guarantee(mid-&gt;_waiters == 0, &quot;must be 0: waiters=%d&quot;, mid-&gt;_waiters);</span>
<span class="udiff-line-added">+   guarantee(mid-&gt;_cxq == NULL, &quot;must be no contending threads: cxq=&quot;</span>
<span class="udiff-line-added">+             INTPTR_FORMAT, p2i(mid-&gt;_cxq));</span>
<span class="udiff-line-added">+   guarantee(mid-&gt;_EntryList == NULL,</span>
<span class="udiff-line-added">+             &quot;must be no entering threads: EntryList=&quot; INTPTR_FORMAT,</span>
<span class="udiff-line-added">+             p2i(mid-&gt;_EntryList));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   const oop obj = (oop) mid-&gt;object();</span>
<span class="udiff-line-added">+   if (log_is_enabled(Trace, monitorinflation)) {</span>
<span class="udiff-line-added">+     ResourceMark rm;</span>
<span class="udiff-line-added">+     log_trace(monitorinflation)(&quot;deflate_monitor_using_JT: &quot;</span>
<span class="udiff-line-added">+                                 &quot;object=&quot; INTPTR_FORMAT &quot;, mark=&quot;</span>
<span class="udiff-line-added">+                                 INTPTR_FORMAT &quot;, type=&#39;%s&#39;&quot;,</span>
<span class="udiff-line-added">+                                 p2i(obj), obj-&gt;mark().value(),</span>
<span class="udiff-line-added">+                                 obj-&gt;klass()-&gt;external_name());</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Install the old mark word if nobody else has already done it.</span>
<span class="udiff-line-added">+   mid-&gt;install_displaced_markword_in_object(obj);</span>
<span class="udiff-line-added">+   mid-&gt;clear_common();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   assert(mid-&gt;object() == NULL, &quot;must be NULL: object=&quot; INTPTR_FORMAT,</span>
<span class="udiff-line-added">+          p2i(mid-&gt;object()));</span>
<span class="udiff-line-added">+   assert(mid-&gt;is_free(), &quot;must be free: allocation_state=%d&quot;,</span>
<span class="udiff-line-added">+          (int)mid-&gt;allocation_state());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Move the deflated ObjectMonitor to the working free list</span>
<span class="udiff-line-added">+   // defined by free_head_p and free_tail_p.</span>
<span class="udiff-line-added">+   if (*free_head_p == NULL) {</span>
<span class="udiff-line-added">+     // First one on the list.</span>
<span class="udiff-line-added">+     *free_head_p = mid;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (*free_tail_p != NULL) {</span>
<span class="udiff-line-added">+     // We append to the list so the caller can use mid-&gt;_next_om</span>
<span class="udiff-line-added">+     // to fix the linkages in its context.</span>
<span class="udiff-line-added">+     ObjectMonitor* prevtail = *free_tail_p;</span>
<span class="udiff-line-added">+     // prevtail should have been cleaned up by the caller:</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+     ObjectMonitor* l_next_om = unmarked_next(prevtail);</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+     assert(l_next_om == NULL, &quot;must be NULL: _next_om=&quot; INTPTR_FORMAT, p2i(l_next_om));</span>
<span class="udiff-line-added">+     om_lock(prevtail);</span>
<span class="udiff-line-added">+     prevtail-&gt;set_next_om(mid);  // prevtail now points to mid (and is unlocked)</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   *free_tail_p = mid;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // At this point, mid-&gt;_next_om still refers to its current</span>
<span class="udiff-line-added">+   // value and another ObjectMonitor&#39;s _next_om field still</span>
<span class="udiff-line-added">+   // refers to this ObjectMonitor. Those linkages have to be</span>
<span class="udiff-line-added">+   // cleaned up by the caller who has the complete context.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // We leave owner == DEFLATER_MARKER and contentions &lt; 0</span>
<span class="udiff-line-added">+   // to force any racing threads to retry.</span>
<span class="udiff-line-added">+   return true;  // Success, ObjectMonitor has been deflated.</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // Walk a given monitor list, and deflate idle monitors.
  // The given list could be a per-thread list or a global list.
  //
  // In the case of parallel processing of thread local monitor lists,
  // work is done by Threads::parallel_threads_do() which ensures that
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1915,20 +2318,170 @@</span>
      }
    }
    return deflated_count;
  }
  
<span class="udiff-line-added">+ // Walk a given ObjectMonitor list and deflate idle ObjectMonitors using</span>
<span class="udiff-line-added">+ // a JavaThread. Returns the number of deflated ObjectMonitors. The given</span>
<span class="udiff-line-added">+ // list could be a per-thread in-use list or the global in-use list.</span>
<span class="udiff-line-added">+ // If a safepoint has started, then we save state via saved_mid_in_use_p</span>
<span class="udiff-line-added">+ // and return to the caller to honor the safepoint.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ int ObjectSynchronizer::deflate_monitor_list_using_JT(ObjectMonitor** list_p,</span>
<span class="udiff-line-added">+                                                       int* count_p,</span>
<span class="udiff-line-added">+                                                       ObjectMonitor** free_head_p,</span>
<span class="udiff-line-added">+                                                       ObjectMonitor** free_tail_p,</span>
<span class="udiff-line-added">+                                                       ObjectMonitor** saved_mid_in_use_p) {</span>
<span class="udiff-line-added">+   assert(AsyncDeflateIdleMonitors, &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+   JavaThread* self = JavaThread::current();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   ObjectMonitor* cur_mid_in_use = NULL;</span>
<span class="udiff-line-added">+   ObjectMonitor* mid = NULL;</span>
<span class="udiff-line-added">+   ObjectMonitor* next = NULL;</span>
<span class="udiff-line-added">+   ObjectMonitor* next_next = NULL;</span>
<span class="udiff-line-added">+   int deflated_count = 0;</span>
<span class="udiff-line-added">+   NoSafepointVerifier nsv;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // We use the more complicated lock-cur_mid_in_use-and-mid-as-we-go</span>
<span class="udiff-line-added">+   // protocol because om_release() can do list deletions in parallel;</span>
<span class="udiff-line-added">+   // this also prevents races with a list walker thread. We also</span>
<span class="udiff-line-added">+   // lock-next-next-as-we-go to prevent an om_flush() that is behind</span>
<span class="udiff-line-added">+   // this thread from passing us.</span>
<span class="udiff-line-added">+   if (*saved_mid_in_use_p == NULL) {</span>
<span class="udiff-line-added">+     // No saved state so start at the beginning.</span>
<span class="udiff-line-added">+     // Lock the list head so we can possibly deflate it:</span>
<span class="udiff-line-added">+     if ((mid = get_list_head_locked(list_p)) == NULL) {</span>
<span class="udiff-line-added">+       return 0;  // The list is empty so nothing to deflate.</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     next = unmarked_next(mid);</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     // We&#39;re restarting after a safepoint so restore the necessary state</span>
<span class="udiff-line-added">+     // before we resume.</span>
<span class="udiff-line-added">+     cur_mid_in_use = *saved_mid_in_use_p;</span>
<span class="udiff-line-added">+     // Lock cur_mid_in_use so we can possibly update its</span>
<span class="udiff-line-added">+     // next field to extract a deflated ObjectMonitor.</span>
<span class="udiff-line-added">+     om_lock(cur_mid_in_use);</span>
<span class="udiff-line-added">+     mid = unmarked_next(cur_mid_in_use);</span>
<span class="udiff-line-added">+     if (mid == NULL) {</span>
<span class="udiff-line-added">+       om_unlock(cur_mid_in_use);</span>
<span class="udiff-line-added">+       *saved_mid_in_use_p = NULL;</span>
<span class="udiff-line-added">+       return 0;  // The remainder is empty so nothing more to deflate.</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     // Lock mid so we can possibly deflate it:</span>
<span class="udiff-line-added">+     om_lock(mid);</span>
<span class="udiff-line-added">+     next = unmarked_next(mid);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   while (true) {</span>
<span class="udiff-line-added">+     // The current mid is locked at this point. If we have a</span>
<span class="udiff-line-added">+     // cur_mid_in_use, then it is also locked at this point.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (next != NULL) {</span>
<span class="udiff-line-added">+       // We lock next so that an om_flush() thread that is behind us</span>
<span class="udiff-line-added">+       // cannot pass us when we unlock the current mid.</span>
<span class="udiff-line-added">+       om_lock(next);</span>
<span class="udiff-line-added">+       next_next = unmarked_next(next);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Only try to deflate if there is an associated Java object and if</span>
<span class="udiff-line-added">+     // mid is old (is not newly allocated and is not newly freed).</span>
<span class="udiff-line-added">+     if (mid-&gt;object() != NULL &amp;&amp; mid-&gt;is_old() &amp;&amp;</span>
<span class="udiff-line-added">+         deflate_monitor_using_JT(mid, free_head_p, free_tail_p)) {</span>
<span class="udiff-line-added">+       // Deflation succeeded and already updated free_head_p and</span>
<span class="udiff-line-added">+       // free_tail_p as needed. Finish the move to the local free list</span>
<span class="udiff-line-added">+       // by unlinking mid from the global or per-thread in-use list.</span>
<span class="udiff-line-added">+       if (cur_mid_in_use == NULL) {</span>
<span class="udiff-line-added">+         // mid is the list head and it is locked. Switch the list head</span>
<span class="udiff-line-added">+         // to next which is also locked (if not NULL) and also leave</span>
<span class="udiff-line-added">+         // mid locked:</span>
<span class="udiff-line-added">+         Atomic::store(list_p, next);</span>
<span class="udiff-line-added">+       } else {</span>
<span class="udiff-line-added">+         ObjectMonitor* locked_next = mark_om_ptr(next);</span>
<span class="udiff-line-added">+         // mid and cur_mid_in_use are locked. Switch cur_mid_in_use&#39;s</span>
<span class="udiff-line-added">+         // next field to locked_next and also leave mid locked:</span>
<span class="udiff-line-added">+         cur_mid_in_use-&gt;set_next_om(locked_next);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // At this point mid is disconnected from the in-use list so</span>
<span class="udiff-line-added">+       // its lock longer has any effects on in-use list.</span>
<span class="udiff-line-added">+       deflated_count++;</span>
<span class="udiff-line-added">+       Atomic::dec(count_p);</span>
<span class="udiff-line-added">+       // mid is current tail in the free_head_p list so NULL terminate it</span>
<span class="udiff-line-added">+       // (which also unlocks it):</span>
<span class="udiff-line-added">+       mid-&gt;set_next_om(NULL);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // All the list management is done so move on to the next one:</span>
<span class="udiff-line-added">+       mid = next;  // mid keeps non-NULL next&#39;s locked state</span>
<span class="udiff-line-added">+       next = next_next;</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       // mid is considered in-use if it does not have an associated</span>
<span class="udiff-line-added">+       // Java object or mid is not old or deflation did not succeed.</span>
<span class="udiff-line-added">+       // A mid-&gt;is_new() node can be seen here when it is freshly</span>
<span class="udiff-line-added">+       // returned by om_alloc() (and skips the deflation code path).</span>
<span class="udiff-line-added">+       // A mid-&gt;is_old() node can be seen here when deflation failed.</span>
<span class="udiff-line-added">+       // A mid-&gt;is_free() node can be seen here when a fresh node from</span>
<span class="udiff-line-added">+       // om_alloc() is released by om_release() due to losing the race</span>
<span class="udiff-line-added">+       // in inflate().</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // All the list management is done so move on to the next one:</span>
<span class="udiff-line-added">+       if (cur_mid_in_use != NULL) {</span>
<span class="udiff-line-added">+         om_unlock(cur_mid_in_use);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // The next cur_mid_in_use keeps mid&#39;s lock state so</span>
<span class="udiff-line-added">+       // that it is stable for a possible next field change. It</span>
<span class="udiff-line-added">+       // cannot be modified by om_release() while it is locked.</span>
<span class="udiff-line-added">+       cur_mid_in_use = mid;</span>
<span class="udiff-line-added">+       mid = next;  // mid keeps non-NULL next&#39;s locked state</span>
<span class="udiff-line-added">+       next = next_next;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       if (SafepointMechanism::should_block(self) &amp;&amp;</span>
<span class="udiff-line-added">+           cur_mid_in_use != Atomic::load(list_p) &amp;&amp; cur_mid_in_use-&gt;is_old()) {</span>
<span class="udiff-line-added">+         // If a safepoint has started and cur_mid_in_use is not the list</span>
<span class="udiff-line-added">+         // head and is old, then it is safe to use as saved state. Return</span>
<span class="udiff-line-added">+         // to the caller before blocking.</span>
<span class="udiff-line-added">+         *saved_mid_in_use_p = cur_mid_in_use;</span>
<span class="udiff-line-added">+         om_unlock(cur_mid_in_use);</span>
<span class="udiff-line-added">+         if (mid != NULL) {</span>
<span class="udiff-line-added">+           om_unlock(mid);</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         return deflated_count;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     if (mid == NULL) {</span>
<span class="udiff-line-added">+       if (cur_mid_in_use != NULL) {</span>
<span class="udiff-line-added">+         om_unlock(cur_mid_in_use);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       break;  // Reached end of the list so nothing more to deflate.</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // The current mid&#39;s next field is locked at this point. If we have</span>
<span class="udiff-line-added">+     // a cur_mid_in_use, then it is also locked at this point.</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   // We finished the list without a safepoint starting so there&#39;s</span>
<span class="udiff-line-added">+   // no need to save state.</span>
<span class="udiff-line-added">+   *saved_mid_in_use_p = NULL;</span>
<span class="udiff-line-added">+   return deflated_count;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void ObjectSynchronizer::prepare_deflate_idle_monitors(DeflateMonitorCounters* counters) {
    counters-&gt;n_in_use = 0;              // currently associated with objects
    counters-&gt;n_in_circulation = 0;      // extant
    counters-&gt;n_scavenged = 0;           // reclaimed (global and per-thread)
    counters-&gt;per_thread_scavenged = 0;  // per-thread scavenge total
    counters-&gt;per_thread_times = 0.0;    // per-thread scavenge times
  }
  
  void ObjectSynchronizer::deflate_idle_monitors(DeflateMonitorCounters* counters) {
    assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at safepoint&quot;);
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (AsyncDeflateIdleMonitors) {</span>
<span class="udiff-line-added">+     // Nothing to do when global idle ObjectMonitors are deflated using</span>
<span class="udiff-line-added">+     // a JavaThread unless a special deflation has been requested.</span>
<span class="udiff-line-added">+     if (!is_special_deflation_requested()) {</span>
<span class="udiff-line-added">+       return;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    bool deflated = false;
  
    ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged monitors
    ObjectMonitor* free_tail_p = NULL;
    elapsedTimer timer;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1977,39 +2530,257 @@</span>
    if (ls != NULL) {
      ls-&gt;print_cr(&quot;deflating global idle monitors, %3.7f secs, %d monitors&quot;, timer.seconds(), deflated_count);
    }
  }
  
<span class="udiff-line-added">+ class HandshakeForDeflation : public HandshakeClosure {</span>
<span class="udiff-line-added">+  public:</span>
<span class="udiff-line-added">+   HandshakeForDeflation() : HandshakeClosure(&quot;HandshakeForDeflation&quot;) {}</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   void do_thread(Thread* thread) {</span>
<span class="udiff-line-added">+     log_trace(monitorinflation)(&quot;HandshakeForDeflation::do_thread: thread=&quot;</span>
<span class="udiff-line-added">+                                 INTPTR_FORMAT, p2i(thread));</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ };</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void ObjectSynchronizer::deflate_idle_monitors_using_JT() {</span>
<span class="udiff-line-added">+   assert(AsyncDeflateIdleMonitors, &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // Deflate any global idle monitors.</span>
<span class="udiff-line-added">+   deflate_global_idle_monitors_using_JT();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int count = 0;</span>
<span class="udiff-line-added">+   for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {</span>
<span class="udiff-line-added">+     if (Atomic::load(&amp;jt-&gt;om_in_use_count) &gt; 0 &amp;&amp; !jt-&gt;is_exiting()) {</span>
<span class="udiff-line-added">+       // This JavaThread is using ObjectMonitors so deflate any that</span>
<span class="udiff-line-added">+       // are idle unless this JavaThread is exiting; do not race with</span>
<span class="udiff-line-added">+       // ObjectSynchronizer::om_flush().</span>
<span class="udiff-line-added">+       deflate_per_thread_idle_monitors_using_JT(jt);</span>
<span class="udiff-line-added">+       count++;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (count &gt; 0) {</span>
<span class="udiff-line-added">+     log_debug(monitorinflation)(&quot;did async deflation of idle monitors for %d thread(s).&quot;, count);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   log_info(monitorinflation)(&quot;async global_population=%d, global_in_use_count=%d, &quot;</span>
<span class="udiff-line-added">+                              &quot;global_free_count=%d, global_wait_count=%d&quot;,</span>
<span class="udiff-line-added">+                              Atomic::load(&amp;om_list_globals._population),</span>
<span class="udiff-line-added">+                              Atomic::load(&amp;om_list_globals._in_use_count),</span>
<span class="udiff-line-added">+                              Atomic::load(&amp;om_list_globals._free_count),</span>
<span class="udiff-line-added">+                              Atomic::load(&amp;om_list_globals._wait_count));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   // The ServiceThread&#39;s async deflation request has been processed.</span>
<span class="udiff-line-added">+   set_is_async_deflation_requested(false);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (Atomic::load(&amp;om_list_globals._wait_count) &gt; 0) {</span>
<span class="udiff-line-added">+     // There are deflated ObjectMonitors waiting for a handshake</span>
<span class="udiff-line-added">+     // (or a safepoint) for safety.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     ObjectMonitor* list = Atomic::load(&amp;om_list_globals._wait_list);</span>
<span class="udiff-line-added">+     ADIM_guarantee(list != NULL, &quot;om_list_globals._wait_list must not be NULL&quot;);</span>
<span class="udiff-line-added">+     int count = Atomic::load(&amp;om_list_globals._wait_count);</span>
<span class="udiff-line-added">+     Atomic::store(&amp;om_list_globals._wait_count, 0);</span>
<span class="udiff-line-added">+     Atomic::store(&amp;om_list_globals._wait_list, (ObjectMonitor*)NULL);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Find the tail for prepend_list_to_common(). No need to mark</span>
<span class="udiff-line-added">+     // ObjectMonitors for this list walk since only the deflater</span>
<span class="udiff-line-added">+     // thread manages the wait list.</span>
<span class="udiff-line-added">+     int l_count = 0;</span>
<span class="udiff-line-added">+     ObjectMonitor* tail = NULL;</span>
<span class="udiff-line-added">+     for (ObjectMonitor* n = list; n != NULL; n = unmarked_next(n)) {</span>
<span class="udiff-line-added">+       tail = n;</span>
<span class="udiff-line-added">+       l_count++;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     ADIM_guarantee(count == l_count, &quot;count=%d != l_count=%d&quot;, count, l_count);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Will execute a safepoint if !ThreadLocalHandshakes:</span>
<span class="udiff-line-added">+     HandshakeForDeflation hfd_hc;</span>
<span class="udiff-line-added">+     Handshake::execute(&amp;hfd_hc);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     prepend_list_to_common(list, tail, count, &amp;om_list_globals._free_list,</span>
<span class="udiff-line-added">+                            &amp;om_list_globals._free_count);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     log_info(monitorinflation)(&quot;moved %d idle monitors from global waiting list to global free list&quot;, count);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Deflate global idle ObjectMonitors using a JavaThread.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ void ObjectSynchronizer::deflate_global_idle_monitors_using_JT() {</span>
<span class="udiff-line-added">+   assert(AsyncDeflateIdleMonitors, &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+   assert(Thread::current()-&gt;is_Java_thread(), &quot;precondition&quot;);</span>
<span class="udiff-line-added">+   JavaThread* self = JavaThread::current();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   deflate_common_idle_monitors_using_JT(true /* is_global */, self);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Deflate the specified JavaThread&#39;s idle ObjectMonitors using a JavaThread.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ void ObjectSynchronizer::deflate_per_thread_idle_monitors_using_JT(JavaThread* target) {</span>
<span class="udiff-line-added">+   assert(AsyncDeflateIdleMonitors, &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+   assert(Thread::current()-&gt;is_Java_thread(), &quot;precondition&quot;);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   deflate_common_idle_monitors_using_JT(false /* !is_global */, target);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // Deflate global or per-thread idle ObjectMonitors using a JavaThread.</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ void ObjectSynchronizer::deflate_common_idle_monitors_using_JT(bool is_global, JavaThread* target) {</span>
<span class="udiff-line-added">+   JavaThread* self = JavaThread::current();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   int deflated_count = 0;</span>
<span class="udiff-line-added">+   ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged ObjectMonitors</span>
<span class="udiff-line-added">+   ObjectMonitor* free_tail_p = NULL;</span>
<span class="udiff-line-added">+   ObjectMonitor* saved_mid_in_use_p = NULL;</span>
<span class="udiff-line-added">+   elapsedTimer timer;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (log_is_enabled(Info, monitorinflation)) {</span>
<span class="udiff-line-added">+     timer.start();</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (is_global) {</span>
<span class="udiff-line-added">+     OM_PERFDATA_OP(MonExtant, set_value(Atomic::load(&amp;om_list_globals._in_use_count)));</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     OM_PERFDATA_OP(MonExtant, inc(Atomic::load(&amp;target-&gt;om_in_use_count)));</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   do {</span>
<span class="udiff-line-added">+     if (saved_mid_in_use_p != NULL) {</span>
<span class="udiff-line-added">+       // We looped around because deflate_monitor_list_using_JT()</span>
<span class="udiff-line-added">+       // detected a pending safepoint. Honoring the safepoint is good,</span>
<span class="udiff-line-added">+       // but as long as is_special_deflation_requested() is supported,</span>
<span class="udiff-line-added">+       // we can&#39;t safely restart using saved_mid_in_use_p. That saved</span>
<span class="udiff-line-added">+       // ObjectMonitor could have been deflated by safepoint based</span>
<span class="udiff-line-added">+       // deflation and would no longer be on the in-use list where we</span>
<span class="udiff-line-added">+       // originally found it.</span>
<span class="udiff-line-added">+       saved_mid_in_use_p = NULL;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     int local_deflated_count;</span>
<span class="udiff-line-added">+     if (is_global) {</span>
<span class="udiff-line-added">+       local_deflated_count =</span>
<span class="udiff-line-added">+           deflate_monitor_list_using_JT(&amp;om_list_globals._in_use_list,</span>
<span class="udiff-line-added">+                                         &amp;om_list_globals._in_use_count,</span>
<span class="udiff-line-added">+                                         &amp;free_head_p, &amp;free_tail_p,</span>
<span class="udiff-line-added">+                                         &amp;saved_mid_in_use_p);</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       local_deflated_count =</span>
<span class="udiff-line-added">+           deflate_monitor_list_using_JT(&amp;target-&gt;om_in_use_list,</span>
<span class="udiff-line-added">+                                         &amp;target-&gt;om_in_use_count, &amp;free_head_p,</span>
<span class="udiff-line-added">+                                         &amp;free_tail_p, &amp;saved_mid_in_use_p);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     deflated_count += local_deflated_count;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (free_head_p != NULL) {</span>
<span class="udiff-line-added">+       // Move the deflated ObjectMonitors to the global free list.</span>
<span class="udiff-line-added">+       guarantee(free_tail_p != NULL &amp;&amp; local_deflated_count &gt; 0, &quot;free_tail_p=&quot; INTPTR_FORMAT &quot;, local_deflated_count=%d&quot;, p2i(free_tail_p), local_deflated_count);</span>
<span class="udiff-line-added">+       // Note: The target thread can be doing an om_alloc() that</span>
<span class="udiff-line-added">+       // is trying to prepend an ObjectMonitor on its in-use list</span>
<span class="udiff-line-added">+       // at the same time that we have deflated the current in-use</span>
<span class="udiff-line-added">+       // list head and put it on the local free list. prepend_to_common()</span>
<span class="udiff-line-added">+       // will detect the race and retry which avoids list corruption,</span>
<span class="udiff-line-added">+       // but the next field in free_tail_p can flicker to marked</span>
<span class="udiff-line-added">+       // and then unmarked while prepend_to_common() is sorting it</span>
<span class="udiff-line-added">+       // all out.</span>
<span class="udiff-line-added">+ #ifdef ASSERT</span>
<span class="udiff-line-added">+       ObjectMonitor* l_next_om = unmarked_next(free_tail_p);</span>
<span class="udiff-line-added">+ #endif</span>
<span class="udiff-line-added">+       assert(l_next_om == NULL, &quot;must be NULL: _next_om=&quot; INTPTR_FORMAT, p2i(l_next_om));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       prepend_list_to_global_wait_list(free_head_p, free_tail_p, local_deflated_count);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       OM_PERFDATA_OP(Deflations, inc(local_deflated_count));</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (saved_mid_in_use_p != NULL) {</span>
<span class="udiff-line-added">+       // deflate_monitor_list_using_JT() detected a safepoint starting.</span>
<span class="udiff-line-added">+       timer.stop();</span>
<span class="udiff-line-added">+       {</span>
<span class="udiff-line-added">+         if (is_global) {</span>
<span class="udiff-line-added">+           log_debug(monitorinflation)(&quot;pausing deflation of global idle monitors for a safepoint.&quot;);</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+           log_debug(monitorinflation)(&quot;jt=&quot; INTPTR_FORMAT &quot;: pausing deflation of per-thread idle monitors for a safepoint.&quot;, p2i(target));</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         assert(SafepointMechanism::should_block(self), &quot;sanity check&quot;);</span>
<span class="udiff-line-added">+         ThreadBlockInVM blocker(self);</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // Prepare for another loop after the safepoint.</span>
<span class="udiff-line-added">+       free_head_p = NULL;</span>
<span class="udiff-line-added">+       free_tail_p = NULL;</span>
<span class="udiff-line-added">+       if (log_is_enabled(Info, monitorinflation)) {</span>
<span class="udiff-line-added">+         timer.start();</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   } while (saved_mid_in_use_p != NULL);</span>
<span class="udiff-line-added">+   timer.stop();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   LogStreamHandle(Debug, monitorinflation) lsh_debug;</span>
<span class="udiff-line-added">+   LogStreamHandle(Info, monitorinflation) lsh_info;</span>
<span class="udiff-line-added">+   LogStream* ls = NULL;</span>
<span class="udiff-line-added">+   if (log_is_enabled(Debug, monitorinflation)) {</span>
<span class="udiff-line-added">+     ls = &amp;lsh_debug;</span>
<span class="udiff-line-added">+   } else if (deflated_count != 0 &amp;&amp; log_is_enabled(Info, monitorinflation)) {</span>
<span class="udiff-line-added">+     ls = &amp;lsh_info;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (ls != NULL) {</span>
<span class="udiff-line-added">+     if (is_global) {</span>
<span class="udiff-line-added">+       ls-&gt;print_cr(&quot;async-deflating global idle monitors, %3.7f secs, %d monitors&quot;, timer.seconds(), deflated_count);</span>
<span class="udiff-line-added">+     } else {</span>
<span class="udiff-line-added">+       ls-&gt;print_cr(&quot;jt=&quot; INTPTR_FORMAT &quot;: async-deflating per-thread idle monitors, %3.7f secs, %d monitors&quot;, p2i(target), timer.seconds(), deflated_count);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  void ObjectSynchronizer::finish_deflate_idle_monitors(DeflateMonitorCounters* counters) {
    // Report the cumulative time for deflating each thread&#39;s idle
    // monitors. Note: if the work is split among more than one
    // worker thread, then the reported time will likely be more
    // than a beginning to end measurement of the phase.
    log_info(safepoint, cleanup)(&quot;deflating per-thread idle monitors, %3.7f secs, monitors=%d&quot;, counters-&gt;per_thread_times, counters-&gt;per_thread_scavenged);
  
<span class="udiff-line-added">+   bool needs_special_deflation = is_special_deflation_requested();</span>
<span class="udiff-line-added">+   if (AsyncDeflateIdleMonitors &amp;&amp; !needs_special_deflation) {</span>
<span class="udiff-line-added">+     // Nothing to do when idle ObjectMonitors are deflated using</span>
<span class="udiff-line-added">+     // a JavaThread unless a special deflation has been requested.</span>
<span class="udiff-line-added">+     return;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    if (log_is_enabled(Debug, monitorinflation)) {
      // exit_globals()&#39;s call to audit_and_print_stats() is done
      // at the Info level and not at a safepoint.
<span class="udiff-line-added">+     // For async deflation, audit_and_print_stats() is called in</span>
<span class="udiff-line-added">+     // ObjectSynchronizer::do_safepoint_work() at the Debug level</span>
<span class="udiff-line-added">+     // at a safepoint.</span>
      ObjectSynchronizer::audit_and_print_stats(false /* on_exit */);
    } else if (log_is_enabled(Info, monitorinflation)) {
      log_info(monitorinflation)(&quot;global_population=%d, global_in_use_count=%d, &quot;
<span class="udiff-line-modified-removed">-                                &quot;global_free_count=%d&quot;,</span>
<span class="udiff-line-modified-added">+                                &quot;global_free_count=%d, global_wait_count=%d&quot;,</span>
                                 Atomic::load(&amp;om_list_globals._population),
                                 Atomic::load(&amp;om_list_globals._in_use_count),
<span class="udiff-line-modified-removed">-                                Atomic::load(&amp;om_list_globals._free_count));</span>
<span class="udiff-line-modified-added">+                                Atomic::load(&amp;om_list_globals._free_count),</span>
<span class="udiff-line-added">+                                Atomic::load(&amp;om_list_globals._wait_count));</span>
    }
  
    OM_PERFDATA_OP(Deflations, inc(counters-&gt;n_scavenged));
    OM_PERFDATA_OP(MonExtant, set_value(counters-&gt;n_in_circulation));
  
    GVars.stw_random = os::random();
    GVars.stw_cycle++;
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   if (needs_special_deflation) {</span>
<span class="udiff-line-added">+     set_is_special_deflation_requested(false);  // special deflation is done</span>
<span class="udiff-line-added">+   }</span>
  }
  
  void ObjectSynchronizer::deflate_thread_local_monitors(Thread* thread, DeflateMonitorCounters* counters) {
    assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at safepoint&quot;);
  
<span class="udiff-line-added">+   if (AsyncDeflateIdleMonitors &amp;&amp; !is_special_deflation_requested()) {</span>
<span class="udiff-line-added">+     // Nothing to do if a special deflation has NOT been requested.</span>
<span class="udiff-line-added">+     return;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    ObjectMonitor* free_head_p = NULL;  // Local SLL of scavenged monitors
    ObjectMonitor* free_tail_p = NULL;
    elapsedTimer timer;
  
    if (log_is_enabled(Info, safepoint, cleanup) ||
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2179,10 +2950,13 @@</span>
    chk_global_in_use_list_and_count(ls, &amp;error_cnt);
  
    // Check om_list_globals._free_list and om_list_globals._free_count:
    chk_global_free_list_and_count(ls, &amp;error_cnt);
  
<span class="udiff-line-added">+   // Check om_list_globals._wait_list and om_list_globals._wait_count:</span>
<span class="udiff-line-added">+   chk_global_wait_list_and_count(ls, &amp;error_cnt);</span>
<span class="udiff-line-added">+ </span>
    ls-&gt;print_cr(&quot;Checking per-thread lists:&quot;);
  
    for (JavaThreadIteratorWithHandle jtiwh; JavaThread *jt = jtiwh.next(); ) {
      // Check om_in_use_list and om_in_use_count:
      chk_per_thread_in_use_list_and_count(jt, ls, &amp;error_cnt);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2229,16 +3003,17 @@</span>
      if (jt != NULL) {
        out-&gt;print_cr(&quot;ERROR: jt=&quot; INTPTR_FORMAT &quot;, monitor=&quot; INTPTR_FORMAT
                      &quot;: free per-thread monitor must have NULL _header &quot;
                      &quot;field: _header=&quot; INTPTR_FORMAT, p2i(jt), p2i(n),
                      n-&gt;header().value());
<span class="udiff-line-modified-removed">-     } else {</span>
<span class="udiff-line-modified-added">+       *error_cnt_p = *error_cnt_p + 1;</span>
<span class="udiff-line-added">+     } else if (!AsyncDeflateIdleMonitors) {</span>
        out-&gt;print_cr(&quot;ERROR: monitor=&quot; INTPTR_FORMAT &quot;: free global monitor &quot;
                      &quot;must have NULL _header field: _header=&quot; INTPTR_FORMAT,
                      p2i(n), n-&gt;header().value());
<span class="udiff-line-added">+       *error_cnt_p = *error_cnt_p + 1;</span>
      }
<span class="udiff-line-removed">-     *error_cnt_p = *error_cnt_p + 1;</span>
    }
    if (n-&gt;object() != NULL) {
      if (jt != NULL) {
        out-&gt;print_cr(&quot;ERROR: jt=&quot; INTPTR_FORMAT &quot;, monitor=&quot; INTPTR_FORMAT
                      &quot;: free per-thread monitor must have NULL _object &quot;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2301,10 +3076,40 @@</span>
      out-&gt;print_cr(&quot;WARNING: global_free_count=%d is not equal to &quot;
                    &quot;chk_om_free_count=%d&quot;, l_free_count, chk_om_free_count);
    }
  }
  
<span class="udiff-line-added">+ // Check the global wait list and count; log the results of the checks.</span>
<span class="udiff-line-added">+ void ObjectSynchronizer::chk_global_wait_list_and_count(outputStream * out,</span>
<span class="udiff-line-added">+                                                         int *error_cnt_p) {</span>
<span class="udiff-line-added">+   int chk_om_wait_count = 0;</span>
<span class="udiff-line-added">+   ObjectMonitor* cur = NULL;</span>
<span class="udiff-line-added">+   if ((cur = get_list_head_locked(&amp;om_list_globals._wait_list)) != NULL) {</span>
<span class="udiff-line-added">+     // Marked the global wait list head so process the list.</span>
<span class="udiff-line-added">+     while (true) {</span>
<span class="udiff-line-added">+       // Rules for om_list_globals._wait_list are the same as for</span>
<span class="udiff-line-added">+       // om_list_globals._free_list:</span>
<span class="udiff-line-added">+       chk_free_entry(NULL /* jt */, cur, out, error_cnt_p);</span>
<span class="udiff-line-added">+       chk_om_wait_count++;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       cur = lock_next_for_traversal(cur);</span>
<span class="udiff-line-added">+       if (cur == NULL) {</span>
<span class="udiff-line-added">+         break;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   if (Atomic::load(&amp;om_list_globals._wait_count) == chk_om_wait_count) {</span>
<span class="udiff-line-added">+     out-&gt;print_cr(&quot;global_wait_count=%d equals chk_om_wait_count=%d&quot;,</span>
<span class="udiff-line-added">+                   Atomic::load(&amp;om_list_globals._wait_count), chk_om_wait_count);</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     out-&gt;print_cr(&quot;ERROR: global_wait_count=%d is not equal to &quot;</span>
<span class="udiff-line-added">+                   &quot;chk_om_wait_count=%d&quot;,</span>
<span class="udiff-line-added">+                   Atomic::load(&amp;om_list_globals._wait_count), chk_om_wait_count);</span>
<span class="udiff-line-added">+     *error_cnt_p = *error_cnt_p + 1;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
  // Check the global in-use list and count; log the results of the checks.
  void ObjectSynchronizer::chk_global_in_use_list_and_count(outputStream * out,
                                                            int *error_cnt_p) {
    int chk_om_in_use_count = 0;
    ObjectMonitor* cur = NULL;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2524,18 +3329,20 @@</span>
  
  // Log counts for the global and per-thread monitor lists and return
  // the population count.
  int ObjectSynchronizer::log_monitor_list_counts(outputStream * out) {
    int pop_count = 0;
<span class="udiff-line-modified-removed">-   out-&gt;print_cr(&quot;%18s  %10s  %10s  %10s&quot;,</span>
<span class="udiff-line-modified-removed">-                 &quot;Global Lists:&quot;, &quot;InUse&quot;, &quot;Free&quot;, &quot;Total&quot;);</span>
<span class="udiff-line-modified-removed">-   out-&gt;print_cr(&quot;==================  ==========  ==========  ==========&quot;);</span>
<span class="udiff-line-modified-added">+   out-&gt;print_cr(&quot;%18s  %10s  %10s  %10s  %10s&quot;,</span>
<span class="udiff-line-modified-added">+                 &quot;Global Lists:&quot;, &quot;InUse&quot;, &quot;Free&quot;, &quot;Wait&quot;, &quot;Total&quot;);</span>
<span class="udiff-line-modified-added">+   out-&gt;print_cr(&quot;==================  ==========  ==========  ==========  ==========&quot;);</span>
    int l_in_use_count = Atomic::load(&amp;om_list_globals._in_use_count);
    int l_free_count = Atomic::load(&amp;om_list_globals._free_count);
<span class="udiff-line-modified-removed">-   out-&gt;print_cr(&quot;%18s  %10d  %10d  %10d&quot;, &quot;&quot;, l_in_use_count,</span>
<span class="udiff-line-modified-removed">-                 l_free_count, Atomic::load(&amp;om_list_globals._population));</span>
<span class="udiff-line-modified-removed">-   pop_count += l_in_use_count + l_free_count;</span>
<span class="udiff-line-modified-added">+   int l_wait_count = Atomic::load(&amp;om_list_globals._wait_count);</span>
<span class="udiff-line-modified-added">+   out-&gt;print_cr(&quot;%18s  %10d  %10d  %10d  %10d&quot;, &quot;&quot;, l_in_use_count,</span>
<span class="udiff-line-modified-added">+                 l_free_count, l_wait_count,</span>
<span class="udiff-line-added">+                 Atomic::load(&amp;om_list_globals._population));</span>
<span class="udiff-line-added">+   pop_count += l_in_use_count + l_free_count + l_wait_count;</span>
  
    out-&gt;print_cr(&quot;%18s  %10s  %10s  %10s&quot;,
                  &quot;Per-Thread Lists:&quot;, &quot;InUse&quot;, &quot;Free&quot;, &quot;Provision&quot;);
    out-&gt;print_cr(&quot;==================  ==========  ==========  ==========&quot;);
  
</pre>
<center><a href="sharedRuntime.cpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="synchronizer.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>