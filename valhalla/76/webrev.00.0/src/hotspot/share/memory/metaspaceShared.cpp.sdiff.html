<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/memory/metaspaceShared.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="dynamicArchive.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="universe.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspaceShared.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  73 #include &quot;utilities/bitMap.inline.hpp&quot;
  74 #include &quot;utilities/ostream.hpp&quot;
  75 #include &quot;utilities/defaultStream.hpp&quot;
  76 #include &quot;utilities/hashtable.inline.hpp&quot;
  77 #if INCLUDE_G1GC
  78 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
  79 #endif
  80 
  81 ReservedSpace MetaspaceShared::_shared_rs;
  82 VirtualSpace MetaspaceShared::_shared_vs;
  83 ReservedSpace MetaspaceShared::_symbol_rs;
  84 VirtualSpace MetaspaceShared::_symbol_vs;
  85 MetaspaceSharedStats MetaspaceShared::_stats;
  86 bool MetaspaceShared::_has_error_classes;
  87 bool MetaspaceShared::_archive_loading_failed = false;
  88 bool MetaspaceShared::_remapped_readwrite = false;
  89 address MetaspaceShared::_i2i_entry_code_buffers = NULL;
  90 size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;
  91 void* MetaspaceShared::_shared_metaspace_static_top = NULL;
  92 intx MetaspaceShared::_relocation_delta;

  93 
  94 // The CDS archive is divided into the following regions:
  95 //     mc  - misc code (the method entry trampolines, c++ vtables)
  96 //     rw  - read-write metadata
  97 //     ro  - read-only metadata and read-only tables
  98 //
  99 //     ca0 - closed archive heap space #0
 100 //     ca1 - closed archive heap space #1 (may be empty)
 101 //     oa0 - open archive heap space #0
 102 //     oa1 - open archive heap space #1 (may be empty)
 103 //
 104 // The mc, rw, and ro regions are linearly allocated, starting from
 105 // SharedBaseAddress, in the order of mc-&gt;rw-&gt;ro. The size of these 3 regions
 106 // are page-aligned, and there&#39;s no gap between any consecutive regions.
 107 //
 108 // These 3 regions are populated in the following steps:
 109 // [1] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are
 110 //     temporarily allocated outside of the shared regions. Only the method entry
 111 //     trampolines are written into the mc region.
 112 // [2] C++ vtables are copied into the mc region.
</pre>
<hr />
<pre>
 225 
 226 void MetaspaceShared::pack_dump_space(DumpRegion* current, DumpRegion* next,
 227                                       ReservedSpace* rs) {
 228   current-&gt;pack(next);
 229 }
 230 
 231 char* MetaspaceShared::symbol_space_alloc(size_t num_bytes) {
 232   return _symbol_region.allocate(num_bytes);
 233 }
 234 
 235 char* MetaspaceShared::misc_code_space_alloc(size_t num_bytes) {
 236   return _mc_region.allocate(num_bytes);
 237 }
 238 
 239 char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {
 240   return _ro_region.allocate(num_bytes);
 241 }
 242 
 243 size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 244 

 245 #ifdef _LP64
<span class="line-modified"> 246 // Check SharedBaseAddress for validity. At this point, os::init() must</span>
<span class="line-modified"> 247 //  have been ran.</span>
<span class="line-modified"> 248 static void check_SharedBaseAddress() {</span>
<span class="line-modified"> 249   SharedBaseAddress = align_up(SharedBaseAddress,</span>
<span class="line-modified"> 250                                MetaspaceShared::reserved_space_alignment());</span>
<span class="line-modified"> 251   if (!CompressedKlassPointers::is_valid_base((address)SharedBaseAddress)) {</span>
<span class="line-modified"> 252     log_warning(cds)(&quot;SharedBaseAddress=&quot; PTR_FORMAT &quot; is invalid for this &quot;</span>
<span class="line-modified"> 253                      &quot;platform, option will be ignored.&quot;,</span>
<span class="line-modified"> 254                      p2i((address)SharedBaseAddress));</span>























 255     SharedBaseAddress = Arguments::default_SharedBaseAddress();

 256   }


 257 }
<span class="line-removed"> 258 #endif</span>
 259 
 260 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
 261   assert(DumpSharedSpaces, &quot;should be called for dump time only&quot;);
 262 
<span class="line-removed"> 263 #ifdef _LP64</span>
<span class="line-removed"> 264   check_SharedBaseAddress();</span>
<span class="line-removed"> 265 #endif</span>
<span class="line-removed"> 266 </span>
<span class="line-removed"> 267   const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();</span>
 268   char* shared_base = (char*)align_up((char*)SharedBaseAddress, reserve_alignment);
 269 
 270 #ifdef _LP64
<span class="line-removed"> 271   assert(CompressedKlassPointers::is_valid_base((address)shared_base), &quot;Sanity&quot;);</span>
 272   // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
 273   //  will use that to house both the archives and the ccs. See below for
 274   //  details.
 275   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
 276   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
 277 #else
 278   // We don&#39;t support archives larger than 256MB on 32-bit due to limited
 279   //  virtual address space.
 280   size_t cds_total = align_down(256*M, reserve_alignment);
 281 #endif
 282 



 283   // Whether to use SharedBaseAddress as attach address.
 284   bool use_requested_base = true;
 285 
 286   if (shared_base == NULL) {
 287     use_requested_base = false;
 288   }
 289 
 290   if (ArchiveRelocationMode == 1) {
 291     log_info(cds)(&quot;ArchiveRelocationMode == 1: always allocate class space at an alternative address&quot;);
 292     use_requested_base = false;
 293   }
 294 
 295   // First try to reserve the space at the specified SharedBaseAddress.
 296   assert(!_shared_rs.is_reserved(), &quot;must be&quot;);
 297   if (use_requested_base) {
 298     _shared_rs = ReservedSpace(cds_total, reserve_alignment,
 299                                false /* large */, (char*)shared_base);
 300     if (_shared_rs.is_reserved()) {
 301       assert(_shared_rs.base() == shared_base, &quot;should match&quot;);
 302     } else {
</pre>
<hr />
<pre>
 383 
 384     log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 385                   p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 386 
 387     log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 388                   CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 389 
 390     assert(_shared_rs.end() == tmp_class_space.base() &amp;&amp;
 391            is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &amp;&amp;
 392            is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &amp;&amp;
 393            is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), &quot;Sanity&quot;);
 394   }
 395 
 396 #endif
 397 
 398   init_shared_dump_space(&amp;_mc_region);
 399   SharedBaseAddress = (size_t)_shared_rs.base();
 400   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 401                 _shared_rs.size(), p2i(_shared_rs.base()));
 402 




 403   size_t symbol_rs_size = LP64_ONLY(3 * G) NOT_LP64(128 * M);
 404   _symbol_rs = ReservedSpace(symbol_rs_size);
 405   if (!_symbol_rs.is_reserved()) {
 406     vm_exit_during_initialization(&quot;Unable to reserve memory for symbols&quot;,
 407                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, symbol_rs_size));
 408   }
 409   _symbol_region.init(&amp;_symbol_rs, &amp;_symbol_vs);
 410 }
 411 
 412 // Called by universe_post_init()
 413 void MetaspaceShared::post_initialize(TRAPS) {
 414   if (UseSharedSpaces) {
 415     int size = FileMapInfo::get_number_of_shared_paths();
 416     if (size &gt; 0) {
 417       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 418       if (!DynamicDumpSharedSpaces) {
 419         FileMapInfo* info;
 420         if (FileMapInfo::dynamic_info() == NULL) {
 421           info = FileMapInfo::current_info();
 422         } else {
</pre>
<hr />
<pre>
1189 
1190 class VM_PopulateDumpSharedSpace: public VM_Operation {
1191 private:
1192   GrowableArray&lt;MemRegion&gt; *_closed_archive_heap_regions;
1193   GrowableArray&lt;MemRegion&gt; *_open_archive_heap_regions;
1194 
1195   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_closed_archive_heap_oopmaps;
1196   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_open_archive_heap_oopmaps;
1197 
1198   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1199   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1200   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1201                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1202   void dump_symbols();
1203   char* dump_read_only_tables();
1204   void print_class_stats();
1205   void print_region_stats(FileMapInfo* map_info);
1206   void print_bitmap_region_stats(size_t size, size_t total_size);
1207   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1208                                const char *name, size_t total_size);
<span class="line-modified">1209   void relocate_to_default_base_address(CHeapBitMap* ptrmap);</span>
1210 
1211 public:
1212 
1213   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1214   void doit();   // outline because gdb sucks
1215   bool allow_nested_vm_operations() const { return true; }
1216 }; // class VM_PopulateDumpSharedSpace
1217 
1218 class SortedSymbolClosure: public SymbolClosure {
1219   GrowableArray&lt;Symbol*&gt; _symbols;
1220   virtual void do_symbol(Symbol** sym) {
1221     assert((*sym)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);
1222     _symbols.append(*sym);
1223   }
1224   static int compare_symbols_by_address(Symbol** a, Symbol** b) {
1225     if (a[0] &lt; b[0]) {
1226       return -1;
1227     } else if (a[0] == b[0]) {
1228       ResourceMark rm;
1229       log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());
</pre>
<hr />
<pre>
1571   log_info(cds)(&quot;Number of classes %d&quot;, _global_klass_objects-&gt;length());
1572   {
1573     int num_type_array = 0, num_obj_array = 0, num_inst = 0;
1574     for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1575       Klass* k = _global_klass_objects-&gt;at(i);
1576       if (k-&gt;is_instance_klass()) {
1577         num_inst ++;
1578       } else if (k-&gt;is_objArray_klass()) {
1579         num_obj_array ++;
1580       } else {
1581         assert(k-&gt;is_typeArray_klass(), &quot;sanity&quot;);
1582         num_type_array ++;
1583       }
1584     }
1585     log_info(cds)(&quot;    instance classes   = %5d&quot;, num_inst);
1586     log_info(cds)(&quot;    obj array classes  = %5d&quot;, num_obj_array);
1587     log_info(cds)(&quot;    type array classes = %5d&quot;, num_type_array);
1588   }
1589 }
1590 
<span class="line-modified">1591 void VM_PopulateDumpSharedSpace::relocate_to_default_base_address(CHeapBitMap* ptrmap) {</span>
1592   intx addr_delta = MetaspaceShared::final_delta();
1593   if (addr_delta == 0) {
1594     ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());
1595   } else {
<span class="line-modified">1596     // We are not able to reserve space at Arguments::default_SharedBaseAddress() (due to ASLR).</span>
1597     // This means that the current content of the archive is based on a random
1598     // address. Let&#39;s relocate all the pointers, so that it can be mapped to
<span class="line-modified">1599     // Arguments::default_SharedBaseAddress() without runtime relocation.</span>
1600     //
1601     // Note: both the base and dynamic archive are written with
<span class="line-modified">1602     // FileMapHeader::_shared_base_address == Arguments::default_SharedBaseAddress()</span>
1603 
1604     // Patch all pointers that are marked by ptrmap within this region,
1605     // where we have just dumped all the metaspace data.
1606     address patch_base = (address)SharedBaseAddress;
1607     address patch_end  = (address)_ro_region.top();
1608     size_t size = patch_end - patch_base;
1609 
1610     // the current value of the pointers to be patched must be within this
1611     // range (i.e., must point to valid metaspace objects)
1612     address valid_old_base = patch_base;
1613     address valid_old_end  = patch_end;
1614 
1615     // after patching, the pointers must point inside this range
1616     // (the requested location of the archive, as mapped at runtime).
<span class="line-modified">1617     address valid_new_base = (address)Arguments::default_SharedBaseAddress();</span>
1618     address valid_new_end  = valid_new_base + size;
1619 
1620     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1621                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1622                    p2i(valid_new_base), p2i(valid_new_end));
1623 
1624     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1625                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1626     ptrmap-&gt;iterate(&amp;patcher);
1627     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1628   }
1629 }
1630 
1631 void VM_PopulateDumpSharedSpace::doit() {
1632   CHeapBitMap ptrmap;
1633   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1634 
1635   // We should no longer allocate anything from the metaspace, so that:
1636   //
1637   // (1) Metaspace::allocate might trigger GC if we have run out of
</pre>
<hr />
<pre>
1684   ArchiveCompactor::copy_and_compact();
1685 
1686   dump_symbols();
1687 
1688   // Dump supported java heap objects
1689   _closed_archive_heap_regions = NULL;
1690   _open_archive_heap_regions = NULL;
1691   dump_java_heap_objects();
1692 
1693   ArchiveCompactor::relocate_well_known_klasses();
1694 
1695   char* serialized_data = dump_read_only_tables();
1696   _ro_region.pack();
1697 
1698   // The vtable clones contain addresses of the current process.
1699   // We don&#39;t want to write these addresses into the archive. Same for i2i buffer.
1700   MetaspaceShared::zero_cpp_vtable_clones_for_writing();
1701   memset(MetaspaceShared::i2i_entry_code_buffers(), 0,
1702          MetaspaceShared::i2i_entry_code_buffers_size());
1703 
<span class="line-modified">1704   // relocate the data so that it can be mapped to Arguments::default_SharedBaseAddress()</span>
1705   // without runtime relocation.
<span class="line-modified">1706   relocate_to_default_base_address(&amp;ptrmap);</span>
1707 
1708   // Create and write the archive file that maps the shared spaces.
1709 
1710   FileMapInfo* mapinfo = new FileMapInfo(true);
1711   mapinfo-&gt;populate_header(os::vm_allocation_granularity());
1712   mapinfo-&gt;set_serialized_data(serialized_data);
1713   mapinfo-&gt;set_cloned_vtables(cloned_vtables);
1714   mapinfo-&gt;set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers(),
1715                                       MetaspaceShared::i2i_entry_code_buffers_size());
1716   mapinfo-&gt;open_for_write();
1717   MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps, _open_archive_heap_oopmaps);
1718   _total_closed_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1719                                         _closed_archive_heap_regions,
1720                                         _closed_archive_heap_oopmaps,
1721                                         MetaspaceShared::first_closed_archive_heap_region,
1722                                         MetaspaceShared::max_closed_archive_heap_region);
1723   _total_open_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1724                                         _open_archive_heap_regions,
1725                                         _open_archive_heap_oopmaps,
1726                                         MetaspaceShared::first_open_archive_heap_region,
1727                                         MetaspaceShared::max_open_archive_heap_region);
1728 
<span class="line-modified">1729   mapinfo-&gt;set_final_requested_base((char*)Arguments::default_SharedBaseAddress());</span>
1730   mapinfo-&gt;set_header_crc(mapinfo-&gt;compute_header_crc());
1731   mapinfo-&gt;write_header();
1732   print_region_stats(mapinfo);
1733   mapinfo-&gt;close();
1734 
1735   if (log_is_enabled(Info, cds)) {
1736     ArchiveCompactor::alloc_stats()-&gt;print_stats(int(_ro_region.used()), int(_rw_region.used()),
1737                                                  int(_mc_region.used()));
1738   }
1739 
1740   if (PrintSystemDictionaryAtExit) {
1741     SystemDictionary::print();
1742   }
1743 
1744   if (AllowArchivingWithJavaAgent) {
1745     warning(&quot;This archive was created with AllowArchivingWithJavaAgent. It should be used &quot;
1746             &quot;for testing purposes only and should not be used in a production environment&quot;);
1747   }
1748 
1749   // There may be other pending VM operations that operate on the InstanceKlasses,
</pre>
<hr />
<pre>
2165     result = map_archives(static_mapinfo, dynamic_mapinfo, true);
2166     if (result == MAP_ARCHIVE_MMAP_FAILURE) {
2167       // Mapping has failed (probably due to ASLR). Let&#39;s map at an address chosen
2168       // by the OS.
2169       log_info(cds)(&quot;Try to map archive(s) at an alternative address&quot;);
2170       result = map_archives(static_mapinfo, dynamic_mapinfo, false);
2171     }
2172   }
2173 
2174   if (result == MAP_ARCHIVE_SUCCESS) {
2175     bool dynamic_mapped = (dynamic_mapinfo != NULL &amp;&amp; dynamic_mapinfo-&gt;is_mapped());
2176     char* cds_base = static_mapinfo-&gt;mapped_base();
2177     char* cds_end =  dynamic_mapped ? dynamic_mapinfo-&gt;mapped_end() : static_mapinfo-&gt;mapped_end();
2178     set_shared_metaspace_range(cds_base, static_mapinfo-&gt;mapped_end(), cds_end);
2179     _relocation_delta = static_mapinfo-&gt;relocation_delta();
2180     if (dynamic_mapped) {
2181       FileMapInfo::set_shared_path_table(dynamic_mapinfo);
2182     } else {
2183       FileMapInfo::set_shared_path_table(static_mapinfo);
2184     }

2185   } else {
2186     set_shared_metaspace_range(NULL, NULL, NULL);
2187     UseSharedSpaces = false;
2188     FileMapInfo::fail_continue(&quot;Unable to map shared spaces&quot;);
2189     if (PrintSharedArchiveAndExit) {
2190       vm_exit_during_initialization(&quot;Unable to use shared archive.&quot;);
2191     }
2192   }
2193 
2194   if (static_mapinfo != NULL &amp;&amp; !static_mapinfo-&gt;is_mapped()) {
2195     delete static_mapinfo;
2196   }
2197   if (dynamic_mapinfo != NULL &amp;&amp; !dynamic_mapinfo-&gt;is_mapped()) {
2198     delete dynamic_mapinfo;
2199   }
2200 }
2201 
2202 FileMapInfo* MetaspaceShared::open_static_archive() {
2203   FileMapInfo* mapinfo = new FileMapInfo(true);
2204   if (!mapinfo-&gt;initialize()) {
</pre>
<hr />
<pre>
2212   if (DynamicDumpSharedSpaces) {
2213     return NULL;
2214   }
2215   if (Arguments::GetSharedDynamicArchivePath() == NULL) {
2216     return NULL;
2217   }
2218 
2219   FileMapInfo* mapinfo = new FileMapInfo(false);
2220   if (!mapinfo-&gt;initialize()) {
2221     delete(mapinfo);
2222     return NULL;
2223   }
2224   return mapinfo;
2225 }
2226 
2227 // use_requested_addr:
2228 //  true  = map at FileMapHeader::_requested_base_address
2229 //  false = map at an alternative address picked by OS.
2230 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
2231                                                bool use_requested_addr) {





2232   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 &amp;&amp; use_requested_addr) {
2233       // For product build only -- this is for benchmarking the cost of doing relocation.
2234       // For debug builds, the check is done below, after reserving the space, for better test coverage
2235       // (see comment below).
2236       log_info(cds)(&quot;ArchiveRelocationMode == 1: always map archive(s) at an alternative address&quot;);
2237       return MAP_ARCHIVE_MMAP_FAILURE;
2238     });
2239 
2240   if (ArchiveRelocationMode == 2 &amp;&amp; !use_requested_addr) {
2241     log_info(cds)(&quot;ArchiveRelocationMode == 2: never map archive(s) at an alternative address&quot;);
2242     return MAP_ARCHIVE_MMAP_FAILURE;
2243   };
2244 
2245   if (dynamic_mapinfo != NULL) {
2246     // Ensure that the OS won&#39;t be able to allocate new memory spaces between the two
2247     // archives, or else it would mess up the simple comparision in MetaspaceObj::is_shared().
2248     assert(static_mapinfo-&gt;mapping_end_offset() == dynamic_mapinfo-&gt;mapping_base_offset(), &quot;no gap&quot;);
2249   }
2250 
2251   ReservedSpace archive_space_rs, class_space_rs;
</pre>
<hr />
<pre>
2663         return false;
2664       }
2665     }
2666     _remapped_readwrite = true;
2667   }
2668   return true;
2669 }
2670 
2671 void MetaspaceShared::report_out_of_space(const char* name, size_t needed_bytes) {
2672   // This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.
2673   // On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes
2674   // or so.
2675   _mc_region.print_out_of_space_msg(name, needed_bytes);
2676   _rw_region.print_out_of_space_msg(name, needed_bytes);
2677   _ro_region.print_out_of_space_msg(name, needed_bytes);
2678 
2679   vm_exit_during_initialization(err_msg(&quot;Unable to allocate from &#39;%s&#39; region&quot;, name),
2680                                 &quot;Please reduce the number of shared classes.&quot;);
2681 }
2682 
<span class="line-modified">2683 // This is used to relocate the pointers so that the archive can be mapped at</span>
<span class="line-modified">2684 // Arguments::default_SharedBaseAddress() without runtime relocation.</span>
2685 intx MetaspaceShared::final_delta() {
<span class="line-modified">2686   return intx(Arguments::default_SharedBaseAddress())  // We want the archive to be mapped to here at runtime</span>
<span class="line-modified">2687        - intx(SharedBaseAddress);                      // .. but the archive is mapped at here at dump time</span>
2688 }
2689 
2690 void MetaspaceShared::print_on(outputStream* st) {
2691   if (UseSharedSpaces || DumpSharedSpaces) {
2692     st-&gt;print(&quot;CDS archive(s) mapped at: &quot;);
2693     address base;
2694     address top;
2695     if (UseSharedSpaces) { // Runtime
2696       base = (address)MetaspaceObj::shared_metaspace_base();
2697       address static_top = (address)_shared_metaspace_static_top;
2698       top = (address)MetaspaceObj::shared_metaspace_top();
2699       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(static_top), p2i(top));
2700     } else if (DumpSharedSpaces) { // Dump Time
2701       base = (address)_shared_rs.base();
2702       top = (address)_shared_rs.end();
2703       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(top));
2704     }
2705     st-&gt;print(&quot;size &quot; SIZE_FORMAT &quot;, &quot;, top - base);
2706     st-&gt;print(&quot;SharedBaseAddress: &quot; PTR_FORMAT &quot;, ArchiveRelocationMode: %d.&quot;, SharedBaseAddress, (int)ArchiveRelocationMode);
2707   } else {
</pre>
</td>
<td>
<hr />
<pre>
  73 #include &quot;utilities/bitMap.inline.hpp&quot;
  74 #include &quot;utilities/ostream.hpp&quot;
  75 #include &quot;utilities/defaultStream.hpp&quot;
  76 #include &quot;utilities/hashtable.inline.hpp&quot;
  77 #if INCLUDE_G1GC
  78 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
  79 #endif
  80 
  81 ReservedSpace MetaspaceShared::_shared_rs;
  82 VirtualSpace MetaspaceShared::_shared_vs;
  83 ReservedSpace MetaspaceShared::_symbol_rs;
  84 VirtualSpace MetaspaceShared::_symbol_vs;
  85 MetaspaceSharedStats MetaspaceShared::_stats;
  86 bool MetaspaceShared::_has_error_classes;
  87 bool MetaspaceShared::_archive_loading_failed = false;
  88 bool MetaspaceShared::_remapped_readwrite = false;
  89 address MetaspaceShared::_i2i_entry_code_buffers = NULL;
  90 size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;
  91 void* MetaspaceShared::_shared_metaspace_static_top = NULL;
  92 intx MetaspaceShared::_relocation_delta;
<span class="line-added">  93 char* MetaspaceShared::_requested_base_address;</span>
  94 
  95 // The CDS archive is divided into the following regions:
  96 //     mc  - misc code (the method entry trampolines, c++ vtables)
  97 //     rw  - read-write metadata
  98 //     ro  - read-only metadata and read-only tables
  99 //
 100 //     ca0 - closed archive heap space #0
 101 //     ca1 - closed archive heap space #1 (may be empty)
 102 //     oa0 - open archive heap space #0
 103 //     oa1 - open archive heap space #1 (may be empty)
 104 //
 105 // The mc, rw, and ro regions are linearly allocated, starting from
 106 // SharedBaseAddress, in the order of mc-&gt;rw-&gt;ro. The size of these 3 regions
 107 // are page-aligned, and there&#39;s no gap between any consecutive regions.
 108 //
 109 // These 3 regions are populated in the following steps:
 110 // [1] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are
 111 //     temporarily allocated outside of the shared regions. Only the method entry
 112 //     trampolines are written into the mc region.
 113 // [2] C++ vtables are copied into the mc region.
</pre>
<hr />
<pre>
 226 
 227 void MetaspaceShared::pack_dump_space(DumpRegion* current, DumpRegion* next,
 228                                       ReservedSpace* rs) {
 229   current-&gt;pack(next);
 230 }
 231 
 232 char* MetaspaceShared::symbol_space_alloc(size_t num_bytes) {
 233   return _symbol_region.allocate(num_bytes);
 234 }
 235 
 236 char* MetaspaceShared::misc_code_space_alloc(size_t num_bytes) {
 237   return _mc_region.allocate(num_bytes);
 238 }
 239 
 240 char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {
 241   return _ro_region.allocate(num_bytes);
 242 }
 243 
 244 size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 245 
<span class="line-added"> 246 static bool shared_base_valid(char* shared_base) {</span>
 247 #ifdef _LP64
<span class="line-modified"> 248   return CompressedKlassPointers::is_valid_base((address)shared_base);</span>
<span class="line-modified"> 249 #else</span>
<span class="line-modified"> 250   return true;</span>
<span class="line-modified"> 251 #endif</span>
<span class="line-modified"> 252 }</span>
<span class="line-modified"> 253 </span>
<span class="line-modified"> 254 static bool shared_base_too_high(char* shared_base, size_t cds_total) {</span>
<span class="line-modified"> 255   if (SharedBaseAddress != 0 &amp;&amp; shared_base &lt; (char*)SharedBaseAddress) {</span>
<span class="line-modified"> 256     // SharedBaseAddress is very high (e.g., 0xffffffffffffff00) so</span>
<span class="line-added"> 257     // align_up(SharedBaseAddress, MetaspaceShared::reserved_space_alignment()) has wrapped around.</span>
<span class="line-added"> 258     return true;</span>
<span class="line-added"> 259   }</span>
<span class="line-added"> 260   if (max_uintx - uintx(shared_base) &lt; uintx(cds_total)) {</span>
<span class="line-added"> 261     // The end of the archive will wrap around</span>
<span class="line-added"> 262     return true;</span>
<span class="line-added"> 263   }</span>
<span class="line-added"> 264 </span>
<span class="line-added"> 265   return false;</span>
<span class="line-added"> 266 }</span>
<span class="line-added"> 267 </span>
<span class="line-added"> 268 static char* compute_shared_base(size_t cds_total) {</span>
<span class="line-added"> 269   char* shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());</span>
<span class="line-added"> 270   const char* err = NULL;</span>
<span class="line-added"> 271   if (shared_base_too_high(shared_base, cds_total)) {</span>
<span class="line-added"> 272     err = &quot;too high&quot;;</span>
<span class="line-added"> 273   } else if (!shared_base_valid(shared_base)) {</span>
<span class="line-added"> 274     err = &quot;invalid for this platform&quot;;</span>
<span class="line-added"> 275   }</span>
<span class="line-added"> 276   if (err) {</span>
<span class="line-added"> 277     log_warning(cds)(&quot;SharedBaseAddress (&quot; INTPTR_FORMAT &quot;) is %s. Reverted to &quot; INTPTR_FORMAT,</span>
<span class="line-added"> 278                      p2i((void*)SharedBaseAddress), err,</span>
<span class="line-added"> 279                      p2i((void*)Arguments::default_SharedBaseAddress()));</span>
 280     SharedBaseAddress = Arguments::default_SharedBaseAddress();
<span class="line-added"> 281     shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());</span>
 282   }
<span class="line-added"> 283   assert(!shared_base_too_high(shared_base, cds_total) &amp;&amp; shared_base_valid(shared_base), &quot;Sanity&quot;);</span>
<span class="line-added"> 284   return shared_base;</span>
 285 }

 286 
 287 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
 288   assert(DumpSharedSpaces, &quot;should be called for dump time only&quot;);
 289 





 290   const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();
 291 
 292 #ifdef _LP64

 293   // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
 294   //  will use that to house both the archives and the ccs. See below for
 295   //  details.
 296   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
 297   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
 298 #else
 299   // We don&#39;t support archives larger than 256MB on 32-bit due to limited
 300   //  virtual address space.
 301   size_t cds_total = align_down(256*M, reserve_alignment);
 302 #endif
 303 
<span class="line-added"> 304   char* shared_base = compute_shared_base(cds_total);</span>
<span class="line-added"> 305   _requested_base_address = shared_base;</span>
<span class="line-added"> 306 </span>
 307   // Whether to use SharedBaseAddress as attach address.
 308   bool use_requested_base = true;
 309 
 310   if (shared_base == NULL) {
 311     use_requested_base = false;
 312   }
 313 
 314   if (ArchiveRelocationMode == 1) {
 315     log_info(cds)(&quot;ArchiveRelocationMode == 1: always allocate class space at an alternative address&quot;);
 316     use_requested_base = false;
 317   }
 318 
 319   // First try to reserve the space at the specified SharedBaseAddress.
 320   assert(!_shared_rs.is_reserved(), &quot;must be&quot;);
 321   if (use_requested_base) {
 322     _shared_rs = ReservedSpace(cds_total, reserve_alignment,
 323                                false /* large */, (char*)shared_base);
 324     if (_shared_rs.is_reserved()) {
 325       assert(_shared_rs.base() == shared_base, &quot;should match&quot;);
 326     } else {
</pre>
<hr />
<pre>
 407 
 408     log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 409                   p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 410 
 411     log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 412                   CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 413 
 414     assert(_shared_rs.end() == tmp_class_space.base() &amp;&amp;
 415            is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &amp;&amp;
 416            is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &amp;&amp;
 417            is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), &quot;Sanity&quot;);
 418   }
 419 
 420 #endif
 421 
 422   init_shared_dump_space(&amp;_mc_region);
 423   SharedBaseAddress = (size_t)_shared_rs.base();
 424   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 425                 _shared_rs.size(), p2i(_shared_rs.base()));
 426 
<span class="line-added"> 427   // We don&#39;t want any valid object to be at the very bottom of the archive.</span>
<span class="line-added"> 428   // See ArchivePtrMarker::mark_pointer().</span>
<span class="line-added"> 429   MetaspaceShared::misc_code_space_alloc(16);</span>
<span class="line-added"> 430 </span>
 431   size_t symbol_rs_size = LP64_ONLY(3 * G) NOT_LP64(128 * M);
 432   _symbol_rs = ReservedSpace(symbol_rs_size);
 433   if (!_symbol_rs.is_reserved()) {
 434     vm_exit_during_initialization(&quot;Unable to reserve memory for symbols&quot;,
 435                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, symbol_rs_size));
 436   }
 437   _symbol_region.init(&amp;_symbol_rs, &amp;_symbol_vs);
 438 }
 439 
 440 // Called by universe_post_init()
 441 void MetaspaceShared::post_initialize(TRAPS) {
 442   if (UseSharedSpaces) {
 443     int size = FileMapInfo::get_number_of_shared_paths();
 444     if (size &gt; 0) {
 445       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 446       if (!DynamicDumpSharedSpaces) {
 447         FileMapInfo* info;
 448         if (FileMapInfo::dynamic_info() == NULL) {
 449           info = FileMapInfo::current_info();
 450         } else {
</pre>
<hr />
<pre>
1217 
1218 class VM_PopulateDumpSharedSpace: public VM_Operation {
1219 private:
1220   GrowableArray&lt;MemRegion&gt; *_closed_archive_heap_regions;
1221   GrowableArray&lt;MemRegion&gt; *_open_archive_heap_regions;
1222 
1223   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_closed_archive_heap_oopmaps;
1224   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_open_archive_heap_oopmaps;
1225 
1226   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1227   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1228   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1229                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1230   void dump_symbols();
1231   char* dump_read_only_tables();
1232   void print_class_stats();
1233   void print_region_stats(FileMapInfo* map_info);
1234   void print_bitmap_region_stats(size_t size, size_t total_size);
1235   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1236                                const char *name, size_t total_size);
<span class="line-modified">1237   void relocate_to_requested_base_address(CHeapBitMap* ptrmap);</span>
1238 
1239 public:
1240 
1241   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1242   void doit();   // outline because gdb sucks
1243   bool allow_nested_vm_operations() const { return true; }
1244 }; // class VM_PopulateDumpSharedSpace
1245 
1246 class SortedSymbolClosure: public SymbolClosure {
1247   GrowableArray&lt;Symbol*&gt; _symbols;
1248   virtual void do_symbol(Symbol** sym) {
1249     assert((*sym)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);
1250     _symbols.append(*sym);
1251   }
1252   static int compare_symbols_by_address(Symbol** a, Symbol** b) {
1253     if (a[0] &lt; b[0]) {
1254       return -1;
1255     } else if (a[0] == b[0]) {
1256       ResourceMark rm;
1257       log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());
</pre>
<hr />
<pre>
1599   log_info(cds)(&quot;Number of classes %d&quot;, _global_klass_objects-&gt;length());
1600   {
1601     int num_type_array = 0, num_obj_array = 0, num_inst = 0;
1602     for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1603       Klass* k = _global_klass_objects-&gt;at(i);
1604       if (k-&gt;is_instance_klass()) {
1605         num_inst ++;
1606       } else if (k-&gt;is_objArray_klass()) {
1607         num_obj_array ++;
1608       } else {
1609         assert(k-&gt;is_typeArray_klass(), &quot;sanity&quot;);
1610         num_type_array ++;
1611       }
1612     }
1613     log_info(cds)(&quot;    instance classes   = %5d&quot;, num_inst);
1614     log_info(cds)(&quot;    obj array classes  = %5d&quot;, num_obj_array);
1615     log_info(cds)(&quot;    type array classes = %5d&quot;, num_type_array);
1616   }
1617 }
1618 
<span class="line-modified">1619 void VM_PopulateDumpSharedSpace::relocate_to_requested_base_address(CHeapBitMap* ptrmap) {</span>
1620   intx addr_delta = MetaspaceShared::final_delta();
1621   if (addr_delta == 0) {
1622     ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());
1623   } else {
<span class="line-modified">1624     // We are not able to reserve space at MetaspaceShared::requested_base_address() (due to ASLR).</span>
1625     // This means that the current content of the archive is based on a random
1626     // address. Let&#39;s relocate all the pointers, so that it can be mapped to
<span class="line-modified">1627     // MetaspaceShared::requested_base_address() without runtime relocation.</span>
1628     //
1629     // Note: both the base and dynamic archive are written with
<span class="line-modified">1630     // FileMapHeader::_requested_base_address == MetaspaceShared::requested_base_address()</span>
1631 
1632     // Patch all pointers that are marked by ptrmap within this region,
1633     // where we have just dumped all the metaspace data.
1634     address patch_base = (address)SharedBaseAddress;
1635     address patch_end  = (address)_ro_region.top();
1636     size_t size = patch_end - patch_base;
1637 
1638     // the current value of the pointers to be patched must be within this
1639     // range (i.e., must point to valid metaspace objects)
1640     address valid_old_base = patch_base;
1641     address valid_old_end  = patch_end;
1642 
1643     // after patching, the pointers must point inside this range
1644     // (the requested location of the archive, as mapped at runtime).
<span class="line-modified">1645     address valid_new_base = (address)MetaspaceShared::requested_base_address();</span>
1646     address valid_new_end  = valid_new_base + size;
1647 
1648     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1649                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1650                    p2i(valid_new_base), p2i(valid_new_end));
1651 
1652     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1653                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1654     ptrmap-&gt;iterate(&amp;patcher);
1655     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1656   }
1657 }
1658 
1659 void VM_PopulateDumpSharedSpace::doit() {
1660   CHeapBitMap ptrmap;
1661   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1662 
1663   // We should no longer allocate anything from the metaspace, so that:
1664   //
1665   // (1) Metaspace::allocate might trigger GC if we have run out of
</pre>
<hr />
<pre>
1712   ArchiveCompactor::copy_and_compact();
1713 
1714   dump_symbols();
1715 
1716   // Dump supported java heap objects
1717   _closed_archive_heap_regions = NULL;
1718   _open_archive_heap_regions = NULL;
1719   dump_java_heap_objects();
1720 
1721   ArchiveCompactor::relocate_well_known_klasses();
1722 
1723   char* serialized_data = dump_read_only_tables();
1724   _ro_region.pack();
1725 
1726   // The vtable clones contain addresses of the current process.
1727   // We don&#39;t want to write these addresses into the archive. Same for i2i buffer.
1728   MetaspaceShared::zero_cpp_vtable_clones_for_writing();
1729   memset(MetaspaceShared::i2i_entry_code_buffers(), 0,
1730          MetaspaceShared::i2i_entry_code_buffers_size());
1731 
<span class="line-modified">1732   // relocate the data so that it can be mapped to MetaspaceShared::requested_base_address()</span>
1733   // without runtime relocation.
<span class="line-modified">1734   relocate_to_requested_base_address(&amp;ptrmap);</span>
1735 
1736   // Create and write the archive file that maps the shared spaces.
1737 
1738   FileMapInfo* mapinfo = new FileMapInfo(true);
1739   mapinfo-&gt;populate_header(os::vm_allocation_granularity());
1740   mapinfo-&gt;set_serialized_data(serialized_data);
1741   mapinfo-&gt;set_cloned_vtables(cloned_vtables);
1742   mapinfo-&gt;set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers(),
1743                                       MetaspaceShared::i2i_entry_code_buffers_size());
1744   mapinfo-&gt;open_for_write();
1745   MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps, _open_archive_heap_oopmaps);
1746   _total_closed_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1747                                         _closed_archive_heap_regions,
1748                                         _closed_archive_heap_oopmaps,
1749                                         MetaspaceShared::first_closed_archive_heap_region,
1750                                         MetaspaceShared::max_closed_archive_heap_region);
1751   _total_open_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1752                                         _open_archive_heap_regions,
1753                                         _open_archive_heap_oopmaps,
1754                                         MetaspaceShared::first_open_archive_heap_region,
1755                                         MetaspaceShared::max_open_archive_heap_region);
1756 
<span class="line-modified">1757   mapinfo-&gt;set_final_requested_base((char*)MetaspaceShared::requested_base_address());</span>
1758   mapinfo-&gt;set_header_crc(mapinfo-&gt;compute_header_crc());
1759   mapinfo-&gt;write_header();
1760   print_region_stats(mapinfo);
1761   mapinfo-&gt;close();
1762 
1763   if (log_is_enabled(Info, cds)) {
1764     ArchiveCompactor::alloc_stats()-&gt;print_stats(int(_ro_region.used()), int(_rw_region.used()),
1765                                                  int(_mc_region.used()));
1766   }
1767 
1768   if (PrintSystemDictionaryAtExit) {
1769     SystemDictionary::print();
1770   }
1771 
1772   if (AllowArchivingWithJavaAgent) {
1773     warning(&quot;This archive was created with AllowArchivingWithJavaAgent. It should be used &quot;
1774             &quot;for testing purposes only and should not be used in a production environment&quot;);
1775   }
1776 
1777   // There may be other pending VM operations that operate on the InstanceKlasses,
</pre>
<hr />
<pre>
2193     result = map_archives(static_mapinfo, dynamic_mapinfo, true);
2194     if (result == MAP_ARCHIVE_MMAP_FAILURE) {
2195       // Mapping has failed (probably due to ASLR). Let&#39;s map at an address chosen
2196       // by the OS.
2197       log_info(cds)(&quot;Try to map archive(s) at an alternative address&quot;);
2198       result = map_archives(static_mapinfo, dynamic_mapinfo, false);
2199     }
2200   }
2201 
2202   if (result == MAP_ARCHIVE_SUCCESS) {
2203     bool dynamic_mapped = (dynamic_mapinfo != NULL &amp;&amp; dynamic_mapinfo-&gt;is_mapped());
2204     char* cds_base = static_mapinfo-&gt;mapped_base();
2205     char* cds_end =  dynamic_mapped ? dynamic_mapinfo-&gt;mapped_end() : static_mapinfo-&gt;mapped_end();
2206     set_shared_metaspace_range(cds_base, static_mapinfo-&gt;mapped_end(), cds_end);
2207     _relocation_delta = static_mapinfo-&gt;relocation_delta();
2208     if (dynamic_mapped) {
2209       FileMapInfo::set_shared_path_table(dynamic_mapinfo);
2210     } else {
2211       FileMapInfo::set_shared_path_table(static_mapinfo);
2212     }
<span class="line-added">2213     _requested_base_address = static_mapinfo-&gt;requested_base_address();</span>
2214   } else {
2215     set_shared_metaspace_range(NULL, NULL, NULL);
2216     UseSharedSpaces = false;
2217     FileMapInfo::fail_continue(&quot;Unable to map shared spaces&quot;);
2218     if (PrintSharedArchiveAndExit) {
2219       vm_exit_during_initialization(&quot;Unable to use shared archive.&quot;);
2220     }
2221   }
2222 
2223   if (static_mapinfo != NULL &amp;&amp; !static_mapinfo-&gt;is_mapped()) {
2224     delete static_mapinfo;
2225   }
2226   if (dynamic_mapinfo != NULL &amp;&amp; !dynamic_mapinfo-&gt;is_mapped()) {
2227     delete dynamic_mapinfo;
2228   }
2229 }
2230 
2231 FileMapInfo* MetaspaceShared::open_static_archive() {
2232   FileMapInfo* mapinfo = new FileMapInfo(true);
2233   if (!mapinfo-&gt;initialize()) {
</pre>
<hr />
<pre>
2241   if (DynamicDumpSharedSpaces) {
2242     return NULL;
2243   }
2244   if (Arguments::GetSharedDynamicArchivePath() == NULL) {
2245     return NULL;
2246   }
2247 
2248   FileMapInfo* mapinfo = new FileMapInfo(false);
2249   if (!mapinfo-&gt;initialize()) {
2250     delete(mapinfo);
2251     return NULL;
2252   }
2253   return mapinfo;
2254 }
2255 
2256 // use_requested_addr:
2257 //  true  = map at FileMapHeader::_requested_base_address
2258 //  false = map at an alternative address picked by OS.
2259 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
2260                                                bool use_requested_addr) {
<span class="line-added">2261   if (use_requested_addr &amp;&amp; static_mapinfo-&gt;requested_base_address() == NULL) {</span>
<span class="line-added">2262     log_info(cds)(&quot;Archive(s) were created with -XX:SharedBaseAddress=0. Always map at os-selected address.&quot;);</span>
<span class="line-added">2263     return MAP_ARCHIVE_MMAP_FAILURE;</span>
<span class="line-added">2264   }</span>
<span class="line-added">2265 </span>
2266   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 &amp;&amp; use_requested_addr) {
2267       // For product build only -- this is for benchmarking the cost of doing relocation.
2268       // For debug builds, the check is done below, after reserving the space, for better test coverage
2269       // (see comment below).
2270       log_info(cds)(&quot;ArchiveRelocationMode == 1: always map archive(s) at an alternative address&quot;);
2271       return MAP_ARCHIVE_MMAP_FAILURE;
2272     });
2273 
2274   if (ArchiveRelocationMode == 2 &amp;&amp; !use_requested_addr) {
2275     log_info(cds)(&quot;ArchiveRelocationMode == 2: never map archive(s) at an alternative address&quot;);
2276     return MAP_ARCHIVE_MMAP_FAILURE;
2277   };
2278 
2279   if (dynamic_mapinfo != NULL) {
2280     // Ensure that the OS won&#39;t be able to allocate new memory spaces between the two
2281     // archives, or else it would mess up the simple comparision in MetaspaceObj::is_shared().
2282     assert(static_mapinfo-&gt;mapping_end_offset() == dynamic_mapinfo-&gt;mapping_base_offset(), &quot;no gap&quot;);
2283   }
2284 
2285   ReservedSpace archive_space_rs, class_space_rs;
</pre>
<hr />
<pre>
2697         return false;
2698       }
2699     }
2700     _remapped_readwrite = true;
2701   }
2702   return true;
2703 }
2704 
2705 void MetaspaceShared::report_out_of_space(const char* name, size_t needed_bytes) {
2706   // This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.
2707   // On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes
2708   // or so.
2709   _mc_region.print_out_of_space_msg(name, needed_bytes);
2710   _rw_region.print_out_of_space_msg(name, needed_bytes);
2711   _ro_region.print_out_of_space_msg(name, needed_bytes);
2712 
2713   vm_exit_during_initialization(err_msg(&quot;Unable to allocate from &#39;%s&#39; region&quot;, name),
2714                                 &quot;Please reduce the number of shared classes.&quot;);
2715 }
2716 
<span class="line-modified">2717 // This is used to relocate the pointers so that the base archive can be mapped at</span>
<span class="line-modified">2718 // MetaspaceShared::requested_base_address() without runtime relocation.</span>
2719 intx MetaspaceShared::final_delta() {
<span class="line-modified">2720   return intx(MetaspaceShared::requested_base_address())  // We want the base archive to be mapped to here at runtime</span>
<span class="line-modified">2721        - intx(SharedBaseAddress);                         // .. but the base archive is mapped at here at dump time</span>
2722 }
2723 
2724 void MetaspaceShared::print_on(outputStream* st) {
2725   if (UseSharedSpaces || DumpSharedSpaces) {
2726     st-&gt;print(&quot;CDS archive(s) mapped at: &quot;);
2727     address base;
2728     address top;
2729     if (UseSharedSpaces) { // Runtime
2730       base = (address)MetaspaceObj::shared_metaspace_base();
2731       address static_top = (address)_shared_metaspace_static_top;
2732       top = (address)MetaspaceObj::shared_metaspace_top();
2733       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(static_top), p2i(top));
2734     } else if (DumpSharedSpaces) { // Dump Time
2735       base = (address)_shared_rs.base();
2736       top = (address)_shared_rs.end();
2737       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(top));
2738     }
2739     st-&gt;print(&quot;size &quot; SIZE_FORMAT &quot;, &quot;, top - base);
2740     st-&gt;print(&quot;SharedBaseAddress: &quot; PTR_FORMAT &quot;, ArchiveRelocationMode: %d.&quot;, SharedBaseAddress, (int)ArchiveRelocationMode);
2741   } else {
</pre>
</td>
</tr>
</table>
<center><a href="dynamicArchive.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="universe.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>