diff a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
@@ -808,11 +808,11 @@
   __ mov(r1, r0);
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     Label is_flat_array, done;
 
     __ test_flattened_array_oop(r0, r8 /*temp*/, is_flat_array);
     __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
     do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);
@@ -1127,11 +1127,11 @@
 
   // do array store check - check for NULL value first
   __ cbz(r0, is_null);
 
   Label  is_flat_array;
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     __ test_flattened_array_oop(r3, r8 /*temp*/, is_flat_array);
   }
 
   // Move subklass into r1
   __ load_klass(r1, r0);
diff a/src/hotspot/cpu/x86/templateTable_x86.cpp b/src/hotspot/cpu/x86/templateTable_x86.cpp
--- a/src/hotspot/cpu/x86/templateTable_x86.cpp
+++ b/src/hotspot/cpu/x86/templateTable_x86.cpp
@@ -825,11 +825,11 @@
   Register array = rdx;
   Register index = rax;
 
   index_check(array, index); // kills rbx
   __ profile_array(rbx, array, rcx);
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     Label is_flat_array, done;
     __ test_flattened_array_oop(array, rbx, is_flat_array);
     do_oop_load(_masm,
                 Address(array, index,
                         UseCompressedOops ? Address::times_4 : Address::times_ptr,
@@ -1154,11 +1154,11 @@
   __ jcc(Assembler::zero, is_null);
 
   // Move array class to rdi
   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
   __ load_klass(rdi, rdx, tmp_load_klass);
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     __ movl(rbx, Address(rdi, Klass::layout_helper_offset()));
     __ test_flattened_array_layout(rbx, is_flat_array);
   }
 
   // Move subklass into rbx
diff a/src/hotspot/share/c1/c1_Instruction.cpp b/src/hotspot/share/c1/c1_Instruction.cpp
--- a/src/hotspot/share/c1/c1_Instruction.cpp
+++ b/src/hotspot/share/c1/c1_Instruction.cpp
@@ -125,19 +125,19 @@
   }
   return NULL;
 }
 
 bool Instruction::is_loaded_flattened_array() const {
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     ciType* type = declared_type();
     return type != NULL && type->is_value_array_klass();
   }
   return false;
 }
 
 bool Instruction::maybe_flattened_array() {
-  if (FlatArrayFlatten) {
+  if (UseFlatArray) {
     ciType* type = declared_type();
     if (type != NULL) {
       if (type->is_obj_array_klass()) {
         // Due to array covariance, the runtime type might be a flattened array.
         ciKlass* element_klass = type->as_obj_array_klass()->element_klass();
diff a/src/hotspot/share/ci/ciTypeFlow.hpp b/src/hotspot/share/ci/ciTypeFlow.hpp
--- a/src/hotspot/share/ci/ciTypeFlow.hpp
+++ b/src/hotspot/share/ci/ciTypeFlow.hpp
@@ -340,11 +340,11 @@
     // null is popped from the stack, we return NULL.  Caller beware.
     ciArrayKlass* pop_objOrValueArray() {
       ciType* array = pop_value();
       if (array == null_type())  return NULL;
       // Value type arrays may contain oop or flattened representation
-      assert(array->is_obj_array_klass() || (FlatArrayFlatten && array->is_value_array_klass()),
+      assert(array->is_obj_array_klass() || (UseFlatArray && array->is_value_array_klass()),
           "must be value or object array type");
       return array->as_array_klass();
     }
     ciTypeArrayKlass* pop_typeArray() {
       ciType* array = pop_value();
diff a/src/hotspot/share/ci/ciValueArrayKlass.cpp b/src/hotspot/share/ci/ciValueArrayKlass.cpp
--- a/src/hotspot/share/ci/ciValueArrayKlass.cpp
+++ b/src/hotspot/share/ci/ciValueArrayKlass.cpp
@@ -125,11 +125,11 @@
 // ------------------------------------------------------------------
 // ciValueArrayKlass::make_impl
 //
 // Implementation of make.
 ciValueArrayKlass* ciValueArrayKlass::make_impl(ciKlass* element_klass) {
-  assert(FlatArrayFlatten, "should only be used for flattened value type arrays");
+  assert(UseFlatArray, "should only be used for flattened value type arrays");
   assert(element_klass->is_valuetype(), "element type must be value type");
   assert(element_klass->is_loaded(), "unloaded Q klasses are represented by ciInstanceKlass");
   {
     EXCEPTION_CONTEXT;
     // The element klass is loaded
diff a/src/hotspot/share/oops/flatArrayKlass.cpp b/src/hotspot/share/oops/flatArrayKlass.cpp
--- a/src/hotspot/share/oops/flatArrayKlass.cpp
+++ b/src/hotspot/share/oops/flatArrayKlass.cpp
@@ -81,11 +81,11 @@
   _element_klass = k;
 }
 
 FlatArrayKlass* FlatArrayKlass::allocate_klass(Klass* element_klass, TRAPS) {
   guarantee((!Universe::is_bootstrapping() || SystemDictionary::Object_klass_loaded()), "Really ?!");
-  assert(FlatArrayFlatten, "Flatten array required");
+  assert(UseFlatArray, "Flatten array required");
   assert(InlineKlass::cast(element_klass)->is_naturally_atomic() || (!InlineArrayAtomicAccess), "Atomic by-default");
 
   /*
    *  MVT->LWorld, now need to allocate secondaries array types, just like objArrayKlass...
    *  ...so now we are trying out covariant array types, just copy objArrayKlass
diff a/src/hotspot/share/oops/inlineKlass.cpp b/src/hotspot/share/oops/inlineKlass.cpp
--- a/src/hotspot/share/oops/inlineKlass.cpp
+++ b/src/hotspot/share/oops/inlineKlass.cpp
@@ -176,11 +176,11 @@
 }
 
 // Arrays of...
 
 bool InlineKlass::flatten_array() {
-  if (!FlatArrayFlatten) {
+  if (!UseFlatArray) {
     return false;
   }
   // Too big
   int elem_bytes = raw_value_byte_size();
   if ((InlineArrayElemMaxFlatSize >= 0) && (elem_bytes > InlineArrayElemMaxFlatSize)) {
diff a/src/hotspot/share/opto/arraycopynode.cpp b/src/hotspot/share/opto/arraycopynode.cpp
--- a/src/hotspot/share/opto/arraycopynode.cpp
+++ b/src/hotspot/share/opto/arraycopynode.cpp
@@ -140,11 +140,11 @@
       // cloning an array we'll do it element by element. If the
       // length input to ArrayCopyNode is constant, length of input
       // array must be too.
 
       assert((get_length_if_constant(phase) == -1) == !ary_src->size()->is_con() ||
-             (FlatArrayFlatten && ary_src->elem()->make_oopptr() != NULL && ary_src->elem()->make_oopptr()->can_be_value_type()) ||
+             (UseFlatArray && ary_src->elem()->make_oopptr() != NULL && ary_src->elem()->make_oopptr()->can_be_value_type()) ||
              phase->is_IterGVN() || phase->C->inlining_incrementally() || StressReflectiveCode, "inconsistent");
       if (ary_src->size()->is_con()) {
         return ary_src->size()->get_con();
       }
       return -1;
diff a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -3486,11 +3486,11 @@
   // Return final merged results
   set_control( _gvn.transform(region) );
   record_for_igvn(region);
 
   bool not_null_free = !toop->can_be_value_type();
-  bool not_flattenable = !FlatArrayFlatten || not_null_free || (toop->is_valuetypeptr() && !toop->value_klass()->flatten_array());
+  bool not_flattenable = !UseFlatArray || not_null_free || (toop->is_valuetypeptr() && !toop->value_klass()->flatten_array());
   if (EnableValhalla && not_flattenable) {
     // Check if obj has been loaded from an array
     obj = obj->isa_DecodeN() ? obj->in(1) : obj;
     Node* array = NULL;
     if (obj->isa_Load()) {
@@ -3791,11 +3791,11 @@
   if (!StressReflectiveCode && inst_klass != NULL) {
     ciKlass* klass = inst_klass->klass();
     assert(klass != NULL, "klass should not be NULL");
     bool    xklass = inst_klass->klass_is_exact();
     bool can_be_flattened = false;
-    if (FlatArrayFlatten && klass->is_obj_array_klass()) {
+    if (UseFlatArray && klass->is_obj_array_klass()) {
       ciKlass* elem = klass->as_obj_array_klass()->element_klass();
       can_be_flattened = elem->can_be_value_klass() && (!elem->is_valuetype() || elem->as_value_klass()->flatten_array());
     }
     if (xklass || (klass->is_array_klass() && !can_be_flattened)) {
       jint lhelper = klass->layout_helper();
diff a/src/hotspot/share/opto/library_call.cpp b/src/hotspot/share/opto/library_call.cpp
--- a/src/hotspot/share/opto/library_call.cpp
+++ b/src/hotspot/share/opto/library_call.cpp
@@ -221,11 +221,11 @@
   }
   Node* generate_typeArray_guard(Node* kls, RegionNode* region) {
     return generate_array_guard_common(kls, region, TypeArray);
   }
   Node* generate_valueArray_guard(Node* kls, RegionNode* region) {
-    assert(FlatArrayFlatten, "can never be flattened");
+    assert(UseFlatArray, "can never be flattened");
     return generate_array_guard_common(kls, region, ValueArray);
   }
   Node* generate_array_guard_common(Node* kls, RegionNode* region, ArrayKind kind);
   Node* generate_virtual_guard(Node* obj_klass, RegionNode* slow_region);
   CallJavaNode* generate_method_call(vmIntrinsics::ID method_id,
@@ -3893,11 +3893,11 @@
   Node* end               = is_copyOfRange? argument(2): argument(1);
   Node* array_type_mirror = is_copyOfRange? argument(3): argument(2);
 
   const TypeAryPtr* original_t = _gvn.type(original)->isa_aryptr();
   const TypeInstPtr* mirror_t = _gvn.type(array_type_mirror)->isa_instptr();
-  if (EnableValhalla && FlatArrayFlatten &&
+  if (EnableValhalla && UseFlatArray &&
       (original_t == NULL || mirror_t == NULL ||
        (mirror_t->java_mirror_type() == NULL &&
         (original_t->elem()->isa_valuetype() ||
          (original_t->elem()->make_oopptr() != NULL &&
           original_t->elem()->make_oopptr()->can_be_value_type()))))) {
@@ -3963,11 +3963,11 @@
           original_kls = load_object_klass(original);
         }
       }
     }
 
-    if (FlatArrayFlatten) {
+    if (UseFlatArray) {
       // Either both or neither new array klass and original array
       // klass must be flattened
       Node* is_flat = generate_valueArray_guard(klass_node, NULL);
       if (!original_t->is_not_flat()) {
         generate_valueArray_guard(original_kls, bailout);
diff a/src/hotspot/share/opto/macroArrayCopy.cpp b/src/hotspot/share/opto/macroArrayCopy.cpp
--- a/src/hotspot/share/opto/macroArrayCopy.cpp
+++ b/src/hotspot/share/opto/macroArrayCopy.cpp
@@ -187,11 +187,11 @@
 
   return is_notp;
 }
 
 Node* PhaseMacroExpand::generate_flattened_array_guard(Node** ctrl, Node* mem, Node* obj_or_klass, RegionNode* region) {
-  assert(FlatArrayFlatten, "can never be flattened");
+  assert(UseFlatArray, "can never be flattened");
   return generate_array_guard(ctrl, mem, obj_or_klass, region, Klass::_lh_array_tag_vt_value);
 }
 
 Node* PhaseMacroExpand::generate_object_array_guard(Node** ctrl, Node* mem, Node* obj_or_klass, RegionNode* region) {
   return generate_array_guard(ctrl, mem, obj_or_klass, region, Klass::_lh_array_tag_obj_value);
@@ -1309,11 +1309,11 @@
     }
 
     RegionNode* slow_region = new RegionNode(1);
     transform_later(slow_region);
 
-    if (FlatArrayFlatten && (top_dest == NULL || !top_dest->is_not_flat())) {
+    if (UseFlatArray && (top_dest == NULL || !top_dest->is_not_flat())) {
       generate_flattened_array_guard(&ctrl, merge_mem, dest, slow_region);
     }
 
     // Call StubRoutines::generic_arraycopy stub.
     Node* mem = generate_arraycopy(ac, NULL, &ctrl, merge_mem, &io,
diff a/src/hotspot/share/opto/parse2.cpp b/src/hotspot/share/opto/parse2.cpp
--- a/src/hotspot/share/opto/parse2.cpp
+++ b/src/hotspot/share/opto/parse2.cpp
@@ -90,11 +90,11 @@
   } else if (elemptr != NULL && elemptr->is_valuetypeptr() && !elemptr->maybe_null()) {
     // Load from non-flattened but flattenable value type array (elements can never be null)
     bt = T_INLINE_TYPE;
   } else if (!ary_t->is_not_flat()) {
     // Cannot statically determine if array is flattened, emit runtime check
-    assert(FlatArrayFlatten && is_reference_type(bt) && elemptr->can_be_value_type() && !ary_t->klass_is_exact() && !ary_t->is_not_null_free() &&
+    assert(UseFlatArray && is_reference_type(bt) && elemptr->can_be_value_type() && !ary_t->klass_is_exact() && !ary_t->is_not_null_free() &&
            (!elemptr->is_valuetypeptr() || elemptr->value_klass()->flatten_array()), "array can't be flattened");
     IdealKit ideal(this);
     IdealVariable res(ideal);
     ideal.declarations_done();
     ideal.if_then(is_non_flattened_array(ary)); {
@@ -296,11 +296,11 @@
         if (stopped()) return;
         dec_sp(3);
       }
     } else if (!ary_t->is_not_flat()) {
       // Array might be flattened, emit runtime checks
-      assert(FlatArrayFlatten && !not_flattenable && elemtype->is_oopptr()->can_be_value_type() &&
+      assert(UseFlatArray && !not_flattenable && elemtype->is_oopptr()->can_be_value_type() &&
              !ary_t->klass_is_exact() && !ary_t->is_not_null_free(), "array can't be flattened");
       IdealKit ideal(this);
       ideal.if_then(is_non_flattened_array(ary)); {
         // non-flattened
         assert(ideal.ctrl()->in(0)->as_If()->is_non_flattened_array_check(&_gvn), "Should be found");
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -3477,11 +3477,11 @@
     if (etype->can_be_value_type()) {
       // Use exact type if element can be a value type
       exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ true, /* try_for_exact= */ true);
     }
     bool not_null_free = !exact_etype->can_be_value_type();
-    bool not_flat = !FlatArrayFlatten || not_null_free || (exact_etype->is_valuetypeptr() && !exact_etype->value_klass()->flatten_array());
+    bool not_flat = !UseFlatArray || not_null_free || (exact_etype->is_valuetypeptr() && !exact_etype->value_klass()->flatten_array());
 
     bool xk = etype->klass_is_exact();
     const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);
     // We used to pass NotNull in here, asserting that the sub-arrays
     // are all not-null.  This is not true in generally, as code can
diff a/src/hotspot/share/utilities/globalDefinitions.hpp b/src/hotspot/share/utilities/globalDefinitions.hpp
--- a/src/hotspot/share/utilities/globalDefinitions.hpp
+++ b/src/hotspot/share/utilities/globalDefinitions.hpp
@@ -1212,8 +1212,8 @@
 // TEMP!!!!
 // This should be removed after LW2 arrays are implemented (JDK-8220790).
 // It's an alias to (EnableValhalla && (InlineArrayElemMaxFlatSize != 0)),
 // which is actually not 100% correct, but works for the current set of C1/C2
 // implementation and test cases.
-#define FlatArrayFlatten (EnableValhalla && (InlineArrayElemMaxFlatSize != 0))
+#define UseFlatArray (EnableValhalla && (InlineArrayElemMaxFlatSize != 0))
 
 #endif // SHARE_UTILITIES_GLOBALDEFINITIONS_HPP
