<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/library_call.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="ifnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopUnswitch.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/library_call.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 177                                       RegionNode* region, int null_path,
 178                                       int offset);
 179   Node* load_klass_from_mirror(Node* mirror, bool never_see_null,
 180                                RegionNode* region, int null_path) {
 181     int offset = java_lang_Class::klass_offset_in_bytes();
 182     return load_klass_from_mirror_common(mirror, never_see_null,
 183                                          region, null_path,
 184                                          offset);
 185   }
 186   Node* load_array_klass_from_mirror(Node* mirror, bool never_see_null,
 187                                      RegionNode* region, int null_path) {
 188     int offset = java_lang_Class::array_klass_offset_in_bytes();
 189     return load_klass_from_mirror_common(mirror, never_see_null,
 190                                          region, null_path,
 191                                          offset);
 192   }
 193   Node* generate_access_flags_guard(Node* kls,
 194                                     int modifier_mask, int modifier_bits,
 195                                     RegionNode* region);
 196   Node* generate_interface_guard(Node* kls, RegionNode* region);

 197 
 198   enum ArrayKind {
 199     AnyArray,
 200     NonArray,
 201     ObjectArray,
 202     NonObjectArray,
 203     TypeArray,
 204     ValueArray
 205   };
 206 
 207   Node* generate_array_guard(Node* kls, RegionNode* region) {
 208     return generate_array_guard_common(kls, region, AnyArray);
 209   }
 210   Node* generate_non_array_guard(Node* kls, RegionNode* region) {
 211     return generate_array_guard_common(kls, region, NonArray);
 212   }
 213   Node* generate_objArray_guard(Node* kls, RegionNode* region) {
 214     return generate_array_guard_common(kls, region, ObjectArray);
 215   }
 216   Node* generate_non_objArray_guard(Node* kls, RegionNode* region) {
</pre>
<hr />
<pre>
 274 
 275   typedef enum { Relaxed, Opaque, Volatile, Acquire, Release } AccessKind;
 276   DecoratorSet mo_decorator_for_access_kind(AccessKind kind);
 277   bool inline_unsafe_access(bool is_store, BasicType type, AccessKind kind, bool is_unaligned);
 278   static bool klass_needs_init_guard(Node* kls);
 279   bool inline_unsafe_allocate();
 280   bool inline_unsafe_newArray(bool uninitialized);
 281   bool inline_unsafe_writeback0();
 282   bool inline_unsafe_writebackSync0(bool is_pre);
 283   bool inline_unsafe_copyMemory();
 284   bool inline_unsafe_make_private_buffer();
 285   bool inline_unsafe_finish_private_buffer();
 286   bool inline_native_currentThread();
 287 
 288   bool inline_native_time_funcs(address method, const char* funcName);
 289 #ifdef JFR_HAVE_INTRINSICS
 290   bool inline_native_classID();
 291   bool inline_native_getEventWriter();
 292 #endif
 293   bool inline_native_Class_query(vmIntrinsics::ID id);
<span class="line-removed"> 294   bool inline_value_Class_conversion(vmIntrinsics::ID id);</span>
 295   bool inline_native_subtype_check();
 296   bool inline_native_getLength();
 297   bool inline_array_copyOf(bool is_copyOfRange);
 298   bool inline_array_equals(StrIntrinsicNode::ArgEnc ae);
 299   bool inline_preconditions_checkIndex();
 300   void copy_to_clone(Node* obj, Node* alloc_obj, Node* obj_size, bool is_array);
 301   bool inline_native_clone(bool is_virtual);
 302   bool inline_native_Reflection_getCallerClass();
 303   // Helper function for inlining native object hash method
 304   bool inline_native_hashcode(bool is_virtual, bool is_static);
 305   bool inline_native_getClass();
 306 
 307   // Helper functions for inlining arraycopy
 308   bool inline_arraycopy();
 309   AllocateArrayNode* tightly_coupled_allocation(Node* ptr,
 310                                                 RegionNode* slow_region);
 311   JVMState* arraycopy_restore_alloc_state(AllocateArrayNode* alloc, int&amp; saved_reexecute_sp);
 312   void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms, int saved_reexecute_sp,
 313                                       uint new_idx);
 314 
</pre>
<hr />
<pre>
 800   case vmIntrinsics::_copyOf:                   return inline_array_copyOf(false);
 801   case vmIntrinsics::_copyOfRange:              return inline_array_copyOf(true);
 802   case vmIntrinsics::_equalsB:                  return inline_array_equals(StrIntrinsicNode::LL);
 803   case vmIntrinsics::_equalsC:                  return inline_array_equals(StrIntrinsicNode::UU);
 804   case vmIntrinsics::_Preconditions_checkIndex: return inline_preconditions_checkIndex();
 805   case vmIntrinsics::_clone:                    return inline_native_clone(intrinsic()-&gt;is_virtual());
 806 
 807   case vmIntrinsics::_allocateUninitializedArray: return inline_unsafe_newArray(true);
 808   case vmIntrinsics::_newArray:                   return inline_unsafe_newArray(false);
 809 
 810   case vmIntrinsics::_isAssignableFrom:         return inline_native_subtype_check();
 811 
 812   case vmIntrinsics::_isInstance:
 813   case vmIntrinsics::_getModifiers:
 814   case vmIntrinsics::_isInterface:
 815   case vmIntrinsics::_isArray:
 816   case vmIntrinsics::_isPrimitive:
 817   case vmIntrinsics::_getSuperclass:
 818   case vmIntrinsics::_getClassAccessFlags:      return inline_native_Class_query(intrinsic_id());
 819 
<span class="line-removed"> 820   case vmIntrinsics::_asPrimaryType:</span>
<span class="line-removed"> 821   case vmIntrinsics::_asIndirectType:           return inline_value_Class_conversion(intrinsic_id());</span>
<span class="line-removed"> 822 </span>
 823   case vmIntrinsics::_floatToRawIntBits:
 824   case vmIntrinsics::_floatToIntBits:
 825   case vmIntrinsics::_intBitsToFloat:
 826   case vmIntrinsics::_doubleToRawLongBits:
 827   case vmIntrinsics::_doubleToLongBits:
 828   case vmIntrinsics::_longBitsToDouble:         return inline_fp_conversions(intrinsic_id());
 829 
 830   case vmIntrinsics::_numberOfLeadingZeros_i:
 831   case vmIntrinsics::_numberOfLeadingZeros_l:
 832   case vmIntrinsics::_numberOfTrailingZeros_i:
 833   case vmIntrinsics::_numberOfTrailingZeros_l:
 834   case vmIntrinsics::_bitCount_i:
 835   case vmIntrinsics::_bitCount_l:
 836   case vmIntrinsics::_reverseBytes_i:
 837   case vmIntrinsics::_reverseBytes_l:
 838   case vmIntrinsics::_reverseBytes_s:
 839   case vmIntrinsics::_reverseBytes_c:           return inline_number_methods(intrinsic_id());
 840 
 841   case vmIntrinsics::_getCallerClass:           return inline_native_Reflection_getCallerClass();
 842 
</pre>
<hr />
<pre>
3272     assert(null_ctl == top(), &quot;no loose ends&quot;);
3273   }
3274   return kls;
3275 }
3276 
3277 //--------------------(inline_native_Class_query helpers)---------------------
3278 // Use this for JVM_ACC_INTERFACE, JVM_ACC_IS_CLONEABLE_FAST, JVM_ACC_HAS_FINALIZER.
3279 // Fall through if (mods &amp; mask) == bits, take the guard otherwise.
3280 Node* LibraryCallKit::generate_access_flags_guard(Node* kls, int modifier_mask, int modifier_bits, RegionNode* region) {
3281   // Branch around if the given klass has the given modifier bit set.
3282   // Like generate_guard, adds a new path onto the region.
3283   Node* modp = basic_plus_adr(kls, in_bytes(Klass::access_flags_offset()));
3284   Node* mods = make_load(NULL, modp, TypeInt::INT, T_INT, MemNode::unordered);
3285   Node* mask = intcon(modifier_mask);
3286   Node* bits = intcon(modifier_bits);
3287   Node* mbit = _gvn.transform(new AndINode(mods, mask));
3288   Node* cmp  = _gvn.transform(new CmpINode(mbit, bits));
3289   Node* bol  = _gvn.transform(new BoolNode(cmp, BoolTest::ne));
3290   return generate_fair_guard(bol, region);
3291 }

3292 Node* LibraryCallKit::generate_interface_guard(Node* kls, RegionNode* region) {
3293   return generate_access_flags_guard(kls, JVM_ACC_INTERFACE, 0, region);
3294 }
3295 




3296 //-------------------------inline_native_Class_query-------------------
3297 bool LibraryCallKit::inline_native_Class_query(vmIntrinsics::ID id) {
3298   const Type* return_type = TypeInt::BOOL;
3299   Node* prim_return_value = top();  // what happens if it&#39;s a primitive class?
3300   bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
3301   bool expect_prim = false;     // most of these guys expect to work on refs
3302 
3303   enum { _normal_path = 1, _prim_path = 2, PATH_LIMIT };
3304 
3305   Node* mirror = argument(0);
3306   Node* obj    = top();
3307 
3308   switch (id) {
3309   case vmIntrinsics::_isInstance:
3310     // nothing is an instance of a primitive type
3311     prim_return_value = intcon(0);
3312     obj = argument(1);
3313     break;
3314   case vmIntrinsics::_getModifiers:
3315     prim_return_value = intcon(JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC);
</pre>
<hr />
<pre>
3449 
3450   case vmIntrinsics::_getClassAccessFlags:
3451     p = basic_plus_adr(kls, in_bytes(Klass::access_flags_offset()));
3452     query_value = make_load(NULL, p, TypeInt::INT, T_INT, MemNode::unordered);
3453     break;
3454 
3455   default:
3456     fatal_unexpected_iid(id);
3457     break;
3458   }
3459 
3460   // Fall-through is the normal case of a query to a real class.
3461   phi-&gt;init_req(1, query_value);
3462   region-&gt;init_req(1, control());
3463 
3464   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
3465   set_result(region, phi);
3466   return true;
3467 }
3468 
<span class="line-removed">3469 //-------------------------inline_value_Class_conversion-------------------</span>
<span class="line-removed">3470 // public Class&lt;T&gt; java.lang.Class.asPrimaryType();</span>
<span class="line-removed">3471 // public Class&lt;T&gt; java.lang.Class.asIndirectType()</span>
<span class="line-removed">3472 bool LibraryCallKit::inline_value_Class_conversion(vmIntrinsics::ID id) {</span>
<span class="line-removed">3473   Node* mirror = argument(0); // Receiver Class</span>
<span class="line-removed">3474   const TypeInstPtr* mirror_con = _gvn.type(mirror)-&gt;isa_instptr();</span>
<span class="line-removed">3475   if (mirror_con == NULL) {</span>
<span class="line-removed">3476     return false;</span>
<span class="line-removed">3477   }</span>
<span class="line-removed">3478 </span>
<span class="line-removed">3479   bool is_indirect_type = true;</span>
<span class="line-removed">3480   ciType* tm = mirror_con-&gt;java_mirror_type(&amp;is_indirect_type);</span>
<span class="line-removed">3481   if (tm != NULL) {</span>
<span class="line-removed">3482     Node* result = mirror;</span>
<span class="line-removed">3483     if (tm-&gt;is_valuetype()) {</span>
<span class="line-removed">3484       if (id == vmIntrinsics::_asPrimaryType &amp;&amp; is_indirect_type) {</span>
<span class="line-removed">3485         result = _gvn.makecon(TypeInstPtr::make(tm-&gt;as_value_klass()-&gt;inline_mirror_instance()));</span>
<span class="line-removed">3486       } else if (id == vmIntrinsics::_asIndirectType &amp;&amp; !is_indirect_type) {</span>
<span class="line-removed">3487         result = _gvn.makecon(TypeInstPtr::make(tm-&gt;as_value_klass()-&gt;indirect_mirror_instance()));</span>
<span class="line-removed">3488       }</span>
<span class="line-removed">3489     }</span>
<span class="line-removed">3490     set_result(result);</span>
<span class="line-removed">3491     return true;</span>
<span class="line-removed">3492   }</span>
<span class="line-removed">3493   return false;</span>
<span class="line-removed">3494 }</span>
<span class="line-removed">3495 </span>
3496 //-------------------------inline_Class_cast-------------------
3497 bool LibraryCallKit::inline_Class_cast() {
3498   Node* mirror = argument(0); // Class
3499   Node* obj    = argument(1);
3500   const TypeInstPtr* mirror_con = _gvn.type(mirror)-&gt;isa_instptr();
3501   if (mirror_con == NULL) {
3502     return false;  // dead path (mirror-&gt;is_top()).
3503   }
3504   if (obj == NULL || obj-&gt;is_top()) {
3505     return false;  // dead path
3506   }
<span class="line-removed">3507 </span>
3508   ciKlass* obj_klass = NULL;

3509   if (obj-&gt;is_ValueType()) {
<span class="line-modified">3510     obj_klass = _gvn.type(obj)-&gt;value_klass();</span>
<span class="line-modified">3511   } else {</span>
<span class="line-modified">3512     const TypeOopPtr* tp = _gvn.type(obj)-&gt;isa_oopptr();</span>
<span class="line-removed">3513     if (tp != NULL) {</span>
<span class="line-removed">3514       obj_klass = tp-&gt;klass();</span>
<span class="line-removed">3515     }</span>
3516   }
3517 
3518   // First, see if Class.cast() can be folded statically.
3519   // java_mirror_type() returns non-null for compile-time Class constants.
<span class="line-modified">3520   bool is_indirect_type = true;</span>
<span class="line-removed">3521   ciType* tm = mirror_con-&gt;java_mirror_type(&amp;is_indirect_type);</span>
<span class="line-removed">3522   if (!obj-&gt;is_ValueType() &amp;&amp; !is_indirect_type) {</span>
<span class="line-removed">3523     obj = null_check(obj);</span>
<span class="line-removed">3524     if (stopped()) {</span>
<span class="line-removed">3525       return true;</span>
<span class="line-removed">3526     }</span>
<span class="line-removed">3527   }</span>
3528   if (tm != NULL &amp;&amp; tm-&gt;is_klass() &amp;&amp; obj_klass != NULL) {
3529     if (!obj_klass-&gt;is_loaded()) {
3530       // Don&#39;t use intrinsic when class is not loaded.
3531       return false;
3532     } else {







3533       int static_res = C-&gt;static_subtype_check(tm-&gt;as_klass(), obj_klass);
3534       if (static_res == Compile::SSC_always_true) {
3535         // isInstance() is true - fold the code.
3536         set_result(obj);
3537         return true;
3538       } else if (static_res == Compile::SSC_always_false) {
3539         // Don&#39;t use intrinsic, have to throw ClassCastException.
3540         // If the reference is null, the non-intrinsic bytecode will
3541         // be optimized appropriately.
3542         return false;
3543       }
3544     }
3545   }
3546 
3547   // Bailout intrinsic and do normal inlining if exception path is frequent.
3548   if (too_many_traps(Deoptimization::Reason_intrinsic)) {
3549     return false;
3550   }
3551 
3552   // Generate dynamic checks.
</pre>
<hr />
<pre>
3554   // Do checkcast (Parse::do_checkcast()) optimizations here.
3555 
3556   mirror = null_check(mirror);
3557   // If mirror is dead, only null-path is taken.
3558   if (stopped()) {
3559     return true;
3560   }
3561 
3562   // Not-subtype or the mirror&#39;s klass ptr is NULL (in case it is a primitive).
3563   enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };
3564   RegionNode* region = new RegionNode(PATH_LIMIT);
3565   record_for_igvn(region);
3566 
3567   // Now load the mirror&#39;s klass metaobject, and null-check it.
3568   // If kls is null, we have a primitive mirror and
3569   // nothing is an instance of a primitive type.
3570   Node* kls = load_klass_from_mirror(mirror, false, region, _prim_path);
3571 
3572   Node* res = top();
3573   if (!stopped()) {
<span class="line-modified">3574     if (EnableValhalla &amp;&amp; !obj-&gt;is_ValueType() &amp;&amp; is_indirect_type) {</span>
<span class="line-modified">3575       // Check if (mirror == inline_mirror &amp;&amp; obj == null)</span>
<span class="line-modified">3576       Node* is_val_mirror = generate_fair_guard(is_value_mirror(mirror), NULL);</span>
<span class="line-modified">3577       if (is_val_mirror != NULL) {</span>
3578         RegionNode* r = new RegionNode(3);
3579         record_for_igvn(r);
3580         r-&gt;init_req(1, control());
3581 
3582         // Casting to .val, check for null
<span class="line-modified">3583         set_control(is_val_mirror);</span>
<span class="line-modified">3584         Node *null_ctr = top();</span>
3585         null_check_oop(obj, &amp;null_ctr);
3586         region-&gt;init_req(_npe_path, null_ctr);
3587         r-&gt;init_req(2, control());
3588 
3589         set_control(_gvn.transform(r));
3590       }
3591     }
3592 
3593     Node* bad_type_ctrl = top();
3594     // Do checkcast optimizations.
3595     res = gen_checkcast(obj, kls, &amp;bad_type_ctrl);
3596     region-&gt;init_req(_bad_type_path, bad_type_ctrl);
3597   }
3598   if (region-&gt;in(_prim_path) != top() ||
3599       region-&gt;in(_bad_type_path) != top() ||
3600       region-&gt;in(_npe_path) != top()) {
3601     // Let Interpreter throw ClassCastException.
3602     PreserveJVMState pjvms(this);
3603     set_control(_gvn.transform(region));
3604     uncommon_trap(Deoptimization::Reason_intrinsic,
</pre>
<hr />
<pre>
3659   // Having loaded both klasses, test each for null.
3660   bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
3661   for (which_arg = 0; which_arg &lt;= 1; which_arg++) {
3662     Node* kls = klasses[which_arg];
3663     Node* null_ctl = top();
3664     kls = null_check_oop(kls, &amp;null_ctl, never_see_null);
3665     if (which_arg == 0) {
3666       prim_region-&gt;init_req(1, null_ctl);
3667     } else {
3668       region-&gt;init_req(_prim_1_path, null_ctl);
3669     }
3670     if (stopped())  break;
3671     klasses[which_arg] = kls;
3672   }
3673 
3674   if (!stopped()) {
3675     // now we have two reference types, in klasses[0..1]
3676     Node* subk   = klasses[1];  // the argument to isAssignableFrom
3677     Node* superk = klasses[0];  // the receiver
3678     region-&gt;set_req(_both_ref_path, gen_subtype_check(subk, superk));
<span class="line-removed">3679     // If superc is a value mirror, we also need to check if superc == subc because</span>
<span class="line-removed">3680     // V? is not a subtype of V but due to subk == superk the subtype check will pass.</span>
<span class="line-removed">3681     generate_fair_guard(is_value_mirror(args[0]), prim_region);</span>
3682     // now we have a successful reference subtype check
3683     region-&gt;set_req(_ref_subtype_path, control());
3684   }
3685 
3686   // If both operands are primitive (both klasses null), then
3687   // we must return true when they are identical primitives.
3688   // It is convenient to test this after the first null klass check.
3689   // This path is also used if superc is a value mirror.
3690   set_control(_gvn.transform(prim_region));
3691   if (!stopped()) {
3692     // Since superc is primitive, make a guard for the superc==subc case.
3693     Node* cmp_eq = _gvn.transform(new CmpPNode(args[0], args[1]));
3694     Node* bol_eq = _gvn.transform(new BoolNode(cmp_eq, BoolTest::eq));
3695     generate_fair_guard(bol_eq, region);
3696     if (region-&gt;req() == PATH_LIMIT+1) {
3697       // A guard was added.  If the added guard is taken, superc==subc.
3698       region-&gt;swap_edges(PATH_LIMIT, _prim_same_path);
3699       region-&gt;del_req(PATH_LIMIT);
3700     }
3701     region-&gt;set_req(_prim_0_path, control()); // Not equal after all.
</pre>
<hr />
<pre>
3824   if (!stopped()) {
3825     // Either the input type is void.class, or else the
3826     // array klass has not yet been cached.  Either the
3827     // ensuing call will throw an exception, or else it
3828     // will cache the array klass for next time.
3829     PreserveJVMState pjvms(this);
3830     CallJavaNode* slow_call = generate_method_call_static(vmIntrinsics::_newArray);
3831     Node* slow_result = set_results_for_java_call(slow_call);
3832     // this-&gt;control() comes from set_results_for_java_call
3833     result_reg-&gt;set_req(_slow_path, control());
3834     result_val-&gt;set_req(_slow_path, slow_result);
3835     result_io -&gt;set_req(_slow_path, i_o());
3836     result_mem-&gt;set_req(_slow_path, reset_memory());
3837   }
3838 
3839   set_control(normal_ctl);
3840   if (!stopped()) {
3841     // Normal case:  The array type has been cached in the java.lang.Class.
3842     // The following call works fine even if the array type is polymorphic.
3843     // It could be a dynamic mix of int[], boolean[], Object[], etc.
<span class="line-modified">3844     Node* obj = new_array(klass_node, count_val, 0, NULL, false, mirror);  // no arguments to push</span>
3845     result_reg-&gt;init_req(_normal_path, control());
3846     result_val-&gt;init_req(_normal_path, obj);
3847     result_io -&gt;init_req(_normal_path, i_o());
3848     result_mem-&gt;init_req(_normal_path, reset_memory());
3849 
3850     if (uninitialized) {
3851       // Mark the allocation so that zeroing is skipped
3852       AllocateArrayNode* alloc = AllocateArrayNode::Ideal_array_allocation(obj, &amp;_gvn);
3853       alloc-&gt;maybe_set_complete(&amp;_gvn);
3854     }
3855   }
3856 
3857   // Return the combined state.
3858   set_i_o(        _gvn.transform(result_io)  );
3859   set_all_memory( _gvn.transform(result_mem));
3860 
3861   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
3862   set_result(result_reg, result_val);
3863   return true;
3864 }
</pre>
<hr />
<pre>
4032       // Extreme case:  Arrays.copyOf((Integer[])x, 10, String[].class).
4033       // This will fail a store-check if x contains any non-nulls.
4034 
4035       bool validated = false;
4036       // Reason_class_check rather than Reason_intrinsic because we
4037       // want to intrinsify even if this traps.
4038       if (!too_many_traps(Deoptimization::Reason_class_check)) {
4039         Node* not_subtype_ctrl = gen_subtype_check(original, klass_node);
4040 
4041         if (not_subtype_ctrl != top()) {
4042           PreserveJVMState pjvms(this);
4043           set_control(not_subtype_ctrl);
4044           uncommon_trap(Deoptimization::Reason_class_check,
4045                         Deoptimization::Action_make_not_entrant);
4046           assert(stopped(), &quot;Should be stopped&quot;);
4047         }
4048         validated = true;
4049       }
4050 
4051       if (!stopped()) {
<span class="line-modified">4052         // Load element mirror</span>
<span class="line-removed">4053         Node* p = basic_plus_adr(array_type_mirror, java_lang_Class::component_mirror_offset_in_bytes());</span>
<span class="line-removed">4054         Node* elem_mirror = access_load_at(array_type_mirror, p, _gvn.type(p)-&gt;is_ptr(), TypeInstPtr::MIRROR, T_OBJECT, IN_HEAP);</span>
<span class="line-removed">4055 </span>
<span class="line-removed">4056         newcopy = new_array(klass_node, length, 0, NULL, false, elem_mirror);</span>
4057 
4058         ArrayCopyNode* ac = ArrayCopyNode::make(this, true, original, start, newcopy, intcon(0), moved, true, false,
4059                                                 original_kls, klass_node);
4060         if (!is_copyOfRange) {
4061           ac-&gt;set_copyof(validated);
4062         } else {
4063           ac-&gt;set_copyofrange(validated);
4064         }
4065         Node* n = _gvn.transform(ac);
4066         if (n == ac) {
4067           ac-&gt;connect_outputs(this);
4068         } else {
4069           assert(validated, &quot;shouldn&#39;t transform if all arguments not validated&quot;);
4070           set_all_memory(n);
4071         }
4072       }
4073     }
4074   } // original reexecute is set back here
4075 
4076   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
</pre>
<hr />
<pre>
4672     RegionNode* slow_region = new RegionNode(1);
4673     record_for_igvn(slow_region);
4674 
4675     Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)NULL);
4676     if (array_ctl != NULL) {
4677       // It&#39;s an array.
4678       PreserveJVMState pjvms(this);
4679       set_control(array_ctl);
4680 
4681       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
4682       if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing) &amp;&amp;
4683           (!obj_type-&gt;isa_aryptr() || !obj_type-&gt;is_aryptr()-&gt;is_not_flat())) {
4684         // Flattened value type array may have object field that would require a
4685         // write barrier. Conservatively, go to slow path.
4686         generate_valueArray_guard(obj_klass, slow_region);
4687       }
4688 
4689       if (!stopped()) {
4690         Node* obj_length = load_array_length(obj);
4691         Node* obj_size  = NULL;
<span class="line-modified">4692         // Load element mirror</span>
<span class="line-removed">4693         Node* array_type_mirror = load_mirror_from_klass(obj_klass);</span>
<span class="line-removed">4694         Node* p = basic_plus_adr(array_type_mirror, java_lang_Class::component_mirror_offset_in_bytes());</span>
<span class="line-removed">4695         Node* elem_mirror = access_load_at(array_type_mirror, p, _gvn.type(p)-&gt;is_ptr(), TypeInstPtr::MIRROR, T_OBJECT, IN_HEAP);</span>
<span class="line-removed">4696 </span>
<span class="line-removed">4697         Node* alloc_obj = new_array(obj_klass, obj_length, 0, &amp;obj_size, false, elem_mirror);</span>
4698 
4699         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
4700         if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {
4701           // If it is an oop array, it requires very special treatment,
4702           // because gc barriers are required when accessing the array.
4703           Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);
4704           if (is_obja != NULL) {
4705             PreserveJVMState pjvms2(this);
4706             set_control(is_obja);
4707             // Generate a direct call to the right arraycopy function(s).
4708             Node* alloc = tightly_coupled_allocation(alloc_obj, NULL);
4709             ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, alloc != NULL, false);
4710             ac-&gt;set_clone_oop_array();
4711             Node* n = _gvn.transform(ac);
4712             assert(n == ac, &quot;cannot disappear&quot;);
4713             ac-&gt;connect_outputs(this);
4714 
4715             result_reg-&gt;init_req(_objArray_path, control());
4716             result_val-&gt;init_req(_objArray_path, alloc_obj);
4717             result_i_o -&gt;set_req(_objArray_path, i_o());
</pre>
</td>
<td>
<hr />
<pre>
 177                                       RegionNode* region, int null_path,
 178                                       int offset);
 179   Node* load_klass_from_mirror(Node* mirror, bool never_see_null,
 180                                RegionNode* region, int null_path) {
 181     int offset = java_lang_Class::klass_offset_in_bytes();
 182     return load_klass_from_mirror_common(mirror, never_see_null,
 183                                          region, null_path,
 184                                          offset);
 185   }
 186   Node* load_array_klass_from_mirror(Node* mirror, bool never_see_null,
 187                                      RegionNode* region, int null_path) {
 188     int offset = java_lang_Class::array_klass_offset_in_bytes();
 189     return load_klass_from_mirror_common(mirror, never_see_null,
 190                                          region, null_path,
 191                                          offset);
 192   }
 193   Node* generate_access_flags_guard(Node* kls,
 194                                     int modifier_mask, int modifier_bits,
 195                                     RegionNode* region);
 196   Node* generate_interface_guard(Node* kls, RegionNode* region);
<span class="line-added"> 197   Node* generate_value_guard(Node* kls, RegionNode* region);</span>
 198 
 199   enum ArrayKind {
 200     AnyArray,
 201     NonArray,
 202     ObjectArray,
 203     NonObjectArray,
 204     TypeArray,
 205     ValueArray
 206   };
 207 
 208   Node* generate_array_guard(Node* kls, RegionNode* region) {
 209     return generate_array_guard_common(kls, region, AnyArray);
 210   }
 211   Node* generate_non_array_guard(Node* kls, RegionNode* region) {
 212     return generate_array_guard_common(kls, region, NonArray);
 213   }
 214   Node* generate_objArray_guard(Node* kls, RegionNode* region) {
 215     return generate_array_guard_common(kls, region, ObjectArray);
 216   }
 217   Node* generate_non_objArray_guard(Node* kls, RegionNode* region) {
</pre>
<hr />
<pre>
 275 
 276   typedef enum { Relaxed, Opaque, Volatile, Acquire, Release } AccessKind;
 277   DecoratorSet mo_decorator_for_access_kind(AccessKind kind);
 278   bool inline_unsafe_access(bool is_store, BasicType type, AccessKind kind, bool is_unaligned);
 279   static bool klass_needs_init_guard(Node* kls);
 280   bool inline_unsafe_allocate();
 281   bool inline_unsafe_newArray(bool uninitialized);
 282   bool inline_unsafe_writeback0();
 283   bool inline_unsafe_writebackSync0(bool is_pre);
 284   bool inline_unsafe_copyMemory();
 285   bool inline_unsafe_make_private_buffer();
 286   bool inline_unsafe_finish_private_buffer();
 287   bool inline_native_currentThread();
 288 
 289   bool inline_native_time_funcs(address method, const char* funcName);
 290 #ifdef JFR_HAVE_INTRINSICS
 291   bool inline_native_classID();
 292   bool inline_native_getEventWriter();
 293 #endif
 294   bool inline_native_Class_query(vmIntrinsics::ID id);

 295   bool inline_native_subtype_check();
 296   bool inline_native_getLength();
 297   bool inline_array_copyOf(bool is_copyOfRange);
 298   bool inline_array_equals(StrIntrinsicNode::ArgEnc ae);
 299   bool inline_preconditions_checkIndex();
 300   void copy_to_clone(Node* obj, Node* alloc_obj, Node* obj_size, bool is_array);
 301   bool inline_native_clone(bool is_virtual);
 302   bool inline_native_Reflection_getCallerClass();
 303   // Helper function for inlining native object hash method
 304   bool inline_native_hashcode(bool is_virtual, bool is_static);
 305   bool inline_native_getClass();
 306 
 307   // Helper functions for inlining arraycopy
 308   bool inline_arraycopy();
 309   AllocateArrayNode* tightly_coupled_allocation(Node* ptr,
 310                                                 RegionNode* slow_region);
 311   JVMState* arraycopy_restore_alloc_state(AllocateArrayNode* alloc, int&amp; saved_reexecute_sp);
 312   void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms, int saved_reexecute_sp,
 313                                       uint new_idx);
 314 
</pre>
<hr />
<pre>
 800   case vmIntrinsics::_copyOf:                   return inline_array_copyOf(false);
 801   case vmIntrinsics::_copyOfRange:              return inline_array_copyOf(true);
 802   case vmIntrinsics::_equalsB:                  return inline_array_equals(StrIntrinsicNode::LL);
 803   case vmIntrinsics::_equalsC:                  return inline_array_equals(StrIntrinsicNode::UU);
 804   case vmIntrinsics::_Preconditions_checkIndex: return inline_preconditions_checkIndex();
 805   case vmIntrinsics::_clone:                    return inline_native_clone(intrinsic()-&gt;is_virtual());
 806 
 807   case vmIntrinsics::_allocateUninitializedArray: return inline_unsafe_newArray(true);
 808   case vmIntrinsics::_newArray:                   return inline_unsafe_newArray(false);
 809 
 810   case vmIntrinsics::_isAssignableFrom:         return inline_native_subtype_check();
 811 
 812   case vmIntrinsics::_isInstance:
 813   case vmIntrinsics::_getModifiers:
 814   case vmIntrinsics::_isInterface:
 815   case vmIntrinsics::_isArray:
 816   case vmIntrinsics::_isPrimitive:
 817   case vmIntrinsics::_getSuperclass:
 818   case vmIntrinsics::_getClassAccessFlags:      return inline_native_Class_query(intrinsic_id());
 819 



 820   case vmIntrinsics::_floatToRawIntBits:
 821   case vmIntrinsics::_floatToIntBits:
 822   case vmIntrinsics::_intBitsToFloat:
 823   case vmIntrinsics::_doubleToRawLongBits:
 824   case vmIntrinsics::_doubleToLongBits:
 825   case vmIntrinsics::_longBitsToDouble:         return inline_fp_conversions(intrinsic_id());
 826 
 827   case vmIntrinsics::_numberOfLeadingZeros_i:
 828   case vmIntrinsics::_numberOfLeadingZeros_l:
 829   case vmIntrinsics::_numberOfTrailingZeros_i:
 830   case vmIntrinsics::_numberOfTrailingZeros_l:
 831   case vmIntrinsics::_bitCount_i:
 832   case vmIntrinsics::_bitCount_l:
 833   case vmIntrinsics::_reverseBytes_i:
 834   case vmIntrinsics::_reverseBytes_l:
 835   case vmIntrinsics::_reverseBytes_s:
 836   case vmIntrinsics::_reverseBytes_c:           return inline_number_methods(intrinsic_id());
 837 
 838   case vmIntrinsics::_getCallerClass:           return inline_native_Reflection_getCallerClass();
 839 
</pre>
<hr />
<pre>
3269     assert(null_ctl == top(), &quot;no loose ends&quot;);
3270   }
3271   return kls;
3272 }
3273 
3274 //--------------------(inline_native_Class_query helpers)---------------------
3275 // Use this for JVM_ACC_INTERFACE, JVM_ACC_IS_CLONEABLE_FAST, JVM_ACC_HAS_FINALIZER.
3276 // Fall through if (mods &amp; mask) == bits, take the guard otherwise.
3277 Node* LibraryCallKit::generate_access_flags_guard(Node* kls, int modifier_mask, int modifier_bits, RegionNode* region) {
3278   // Branch around if the given klass has the given modifier bit set.
3279   // Like generate_guard, adds a new path onto the region.
3280   Node* modp = basic_plus_adr(kls, in_bytes(Klass::access_flags_offset()));
3281   Node* mods = make_load(NULL, modp, TypeInt::INT, T_INT, MemNode::unordered);
3282   Node* mask = intcon(modifier_mask);
3283   Node* bits = intcon(modifier_bits);
3284   Node* mbit = _gvn.transform(new AndINode(mods, mask));
3285   Node* cmp  = _gvn.transform(new CmpINode(mbit, bits));
3286   Node* bol  = _gvn.transform(new BoolNode(cmp, BoolTest::ne));
3287   return generate_fair_guard(bol, region);
3288 }
<span class="line-added">3289 </span>
3290 Node* LibraryCallKit::generate_interface_guard(Node* kls, RegionNode* region) {
3291   return generate_access_flags_guard(kls, JVM_ACC_INTERFACE, 0, region);
3292 }
3293 
<span class="line-added">3294 Node* LibraryCallKit::generate_value_guard(Node* kls, RegionNode* region) {</span>
<span class="line-added">3295   return generate_access_flags_guard(kls, JVM_ACC_VALUE, 0, region);</span>
<span class="line-added">3296 }</span>
<span class="line-added">3297 </span>
3298 //-------------------------inline_native_Class_query-------------------
3299 bool LibraryCallKit::inline_native_Class_query(vmIntrinsics::ID id) {
3300   const Type* return_type = TypeInt::BOOL;
3301   Node* prim_return_value = top();  // what happens if it&#39;s a primitive class?
3302   bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
3303   bool expect_prim = false;     // most of these guys expect to work on refs
3304 
3305   enum { _normal_path = 1, _prim_path = 2, PATH_LIMIT };
3306 
3307   Node* mirror = argument(0);
3308   Node* obj    = top();
3309 
3310   switch (id) {
3311   case vmIntrinsics::_isInstance:
3312     // nothing is an instance of a primitive type
3313     prim_return_value = intcon(0);
3314     obj = argument(1);
3315     break;
3316   case vmIntrinsics::_getModifiers:
3317     prim_return_value = intcon(JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC);
</pre>
<hr />
<pre>
3451 
3452   case vmIntrinsics::_getClassAccessFlags:
3453     p = basic_plus_adr(kls, in_bytes(Klass::access_flags_offset()));
3454     query_value = make_load(NULL, p, TypeInt::INT, T_INT, MemNode::unordered);
3455     break;
3456 
3457   default:
3458     fatal_unexpected_iid(id);
3459     break;
3460   }
3461 
3462   // Fall-through is the normal case of a query to a real class.
3463   phi-&gt;init_req(1, query_value);
3464   region-&gt;init_req(1, control());
3465 
3466   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
3467   set_result(region, phi);
3468   return true;
3469 }
3470 



























3471 //-------------------------inline_Class_cast-------------------
3472 bool LibraryCallKit::inline_Class_cast() {
3473   Node* mirror = argument(0); // Class
3474   Node* obj    = argument(1);
3475   const TypeInstPtr* mirror_con = _gvn.type(mirror)-&gt;isa_instptr();
3476   if (mirror_con == NULL) {
3477     return false;  // dead path (mirror-&gt;is_top()).
3478   }
3479   if (obj == NULL || obj-&gt;is_top()) {
3480     return false;  // dead path
3481   }

3482   ciKlass* obj_klass = NULL;
<span class="line-added">3483   const Type* obj_t = _gvn.type(obj);</span>
3484   if (obj-&gt;is_ValueType()) {
<span class="line-modified">3485     obj_klass = obj_t-&gt;value_klass();</span>
<span class="line-modified">3486   } else if (obj_t-&gt;isa_oopptr()) {</span>
<span class="line-modified">3487     obj_klass = obj_t-&gt;is_oopptr()-&gt;klass();</span>



3488   }
3489 
3490   // First, see if Class.cast() can be folded statically.
3491   // java_mirror_type() returns non-null for compile-time Class constants.
<span class="line-modified">3492   ciType* tm = mirror_con-&gt;java_mirror_type();</span>







3493   if (tm != NULL &amp;&amp; tm-&gt;is_klass() &amp;&amp; obj_klass != NULL) {
3494     if (!obj_klass-&gt;is_loaded()) {
3495       // Don&#39;t use intrinsic when class is not loaded.
3496       return false;
3497     } else {
<span class="line-added">3498       if (!obj-&gt;is_ValueType() &amp;&amp; tm-&gt;as_klass()-&gt;is_valuetype()) {</span>
<span class="line-added">3499         // Casting to .val, check for null</span>
<span class="line-added">3500         obj = null_check(obj);</span>
<span class="line-added">3501         if (stopped()) {</span>
<span class="line-added">3502           return true;</span>
<span class="line-added">3503         }</span>
<span class="line-added">3504       }</span>
3505       int static_res = C-&gt;static_subtype_check(tm-&gt;as_klass(), obj_klass);
3506       if (static_res == Compile::SSC_always_true) {
3507         // isInstance() is true - fold the code.
3508         set_result(obj);
3509         return true;
3510       } else if (static_res == Compile::SSC_always_false) {
3511         // Don&#39;t use intrinsic, have to throw ClassCastException.
3512         // If the reference is null, the non-intrinsic bytecode will
3513         // be optimized appropriately.
3514         return false;
3515       }
3516     }
3517   }
3518 
3519   // Bailout intrinsic and do normal inlining if exception path is frequent.
3520   if (too_many_traps(Deoptimization::Reason_intrinsic)) {
3521     return false;
3522   }
3523 
3524   // Generate dynamic checks.
</pre>
<hr />
<pre>
3526   // Do checkcast (Parse::do_checkcast()) optimizations here.
3527 
3528   mirror = null_check(mirror);
3529   // If mirror is dead, only null-path is taken.
3530   if (stopped()) {
3531     return true;
3532   }
3533 
3534   // Not-subtype or the mirror&#39;s klass ptr is NULL (in case it is a primitive).
3535   enum { _bad_type_path = 1, _prim_path = 2, _npe_path = 3, PATH_LIMIT };
3536   RegionNode* region = new RegionNode(PATH_LIMIT);
3537   record_for_igvn(region);
3538 
3539   // Now load the mirror&#39;s klass metaobject, and null-check it.
3540   // If kls is null, we have a primitive mirror and
3541   // nothing is an instance of a primitive type.
3542   Node* kls = load_klass_from_mirror(mirror, false, region, _prim_path);
3543 
3544   Node* res = top();
3545   if (!stopped()) {
<span class="line-modified">3546     if (EnableValhalla &amp;&amp; !obj-&gt;is_ValueType()) {</span>
<span class="line-modified">3547       // Check if we are casting to .val</span>
<span class="line-modified">3548       Node* is_val_kls = generate_value_guard(kls, NULL);</span>
<span class="line-modified">3549       if (is_val_kls != NULL) {</span>
3550         RegionNode* r = new RegionNode(3);
3551         record_for_igvn(r);
3552         r-&gt;init_req(1, control());
3553 
3554         // Casting to .val, check for null
<span class="line-modified">3555         set_control(is_val_kls);</span>
<span class="line-modified">3556         Node* null_ctr = top();</span>
3557         null_check_oop(obj, &amp;null_ctr);
3558         region-&gt;init_req(_npe_path, null_ctr);
3559         r-&gt;init_req(2, control());
3560 
3561         set_control(_gvn.transform(r));
3562       }
3563     }
3564 
3565     Node* bad_type_ctrl = top();
3566     // Do checkcast optimizations.
3567     res = gen_checkcast(obj, kls, &amp;bad_type_ctrl);
3568     region-&gt;init_req(_bad_type_path, bad_type_ctrl);
3569   }
3570   if (region-&gt;in(_prim_path) != top() ||
3571       region-&gt;in(_bad_type_path) != top() ||
3572       region-&gt;in(_npe_path) != top()) {
3573     // Let Interpreter throw ClassCastException.
3574     PreserveJVMState pjvms(this);
3575     set_control(_gvn.transform(region));
3576     uncommon_trap(Deoptimization::Reason_intrinsic,
</pre>
<hr />
<pre>
3631   // Having loaded both klasses, test each for null.
3632   bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
3633   for (which_arg = 0; which_arg &lt;= 1; which_arg++) {
3634     Node* kls = klasses[which_arg];
3635     Node* null_ctl = top();
3636     kls = null_check_oop(kls, &amp;null_ctl, never_see_null);
3637     if (which_arg == 0) {
3638       prim_region-&gt;init_req(1, null_ctl);
3639     } else {
3640       region-&gt;init_req(_prim_1_path, null_ctl);
3641     }
3642     if (stopped())  break;
3643     klasses[which_arg] = kls;
3644   }
3645 
3646   if (!stopped()) {
3647     // now we have two reference types, in klasses[0..1]
3648     Node* subk   = klasses[1];  // the argument to isAssignableFrom
3649     Node* superk = klasses[0];  // the receiver
3650     region-&gt;set_req(_both_ref_path, gen_subtype_check(subk, superk));



3651     // now we have a successful reference subtype check
3652     region-&gt;set_req(_ref_subtype_path, control());
3653   }
3654 
3655   // If both operands are primitive (both klasses null), then
3656   // we must return true when they are identical primitives.
3657   // It is convenient to test this after the first null klass check.
3658   // This path is also used if superc is a value mirror.
3659   set_control(_gvn.transform(prim_region));
3660   if (!stopped()) {
3661     // Since superc is primitive, make a guard for the superc==subc case.
3662     Node* cmp_eq = _gvn.transform(new CmpPNode(args[0], args[1]));
3663     Node* bol_eq = _gvn.transform(new BoolNode(cmp_eq, BoolTest::eq));
3664     generate_fair_guard(bol_eq, region);
3665     if (region-&gt;req() == PATH_LIMIT+1) {
3666       // A guard was added.  If the added guard is taken, superc==subc.
3667       region-&gt;swap_edges(PATH_LIMIT, _prim_same_path);
3668       region-&gt;del_req(PATH_LIMIT);
3669     }
3670     region-&gt;set_req(_prim_0_path, control()); // Not equal after all.
</pre>
<hr />
<pre>
3793   if (!stopped()) {
3794     // Either the input type is void.class, or else the
3795     // array klass has not yet been cached.  Either the
3796     // ensuing call will throw an exception, or else it
3797     // will cache the array klass for next time.
3798     PreserveJVMState pjvms(this);
3799     CallJavaNode* slow_call = generate_method_call_static(vmIntrinsics::_newArray);
3800     Node* slow_result = set_results_for_java_call(slow_call);
3801     // this-&gt;control() comes from set_results_for_java_call
3802     result_reg-&gt;set_req(_slow_path, control());
3803     result_val-&gt;set_req(_slow_path, slow_result);
3804     result_io -&gt;set_req(_slow_path, i_o());
3805     result_mem-&gt;set_req(_slow_path, reset_memory());
3806   }
3807 
3808   set_control(normal_ctl);
3809   if (!stopped()) {
3810     // Normal case:  The array type has been cached in the java.lang.Class.
3811     // The following call works fine even if the array type is polymorphic.
3812     // It could be a dynamic mix of int[], boolean[], Object[], etc.
<span class="line-modified">3813     Node* obj = new_array(klass_node, count_val, 0);  // no arguments to push</span>
3814     result_reg-&gt;init_req(_normal_path, control());
3815     result_val-&gt;init_req(_normal_path, obj);
3816     result_io -&gt;init_req(_normal_path, i_o());
3817     result_mem-&gt;init_req(_normal_path, reset_memory());
3818 
3819     if (uninitialized) {
3820       // Mark the allocation so that zeroing is skipped
3821       AllocateArrayNode* alloc = AllocateArrayNode::Ideal_array_allocation(obj, &amp;_gvn);
3822       alloc-&gt;maybe_set_complete(&amp;_gvn);
3823     }
3824   }
3825 
3826   // Return the combined state.
3827   set_i_o(        _gvn.transform(result_io)  );
3828   set_all_memory( _gvn.transform(result_mem));
3829 
3830   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
3831   set_result(result_reg, result_val);
3832   return true;
3833 }
</pre>
<hr />
<pre>
4001       // Extreme case:  Arrays.copyOf((Integer[])x, 10, String[].class).
4002       // This will fail a store-check if x contains any non-nulls.
4003 
4004       bool validated = false;
4005       // Reason_class_check rather than Reason_intrinsic because we
4006       // want to intrinsify even if this traps.
4007       if (!too_many_traps(Deoptimization::Reason_class_check)) {
4008         Node* not_subtype_ctrl = gen_subtype_check(original, klass_node);
4009 
4010         if (not_subtype_ctrl != top()) {
4011           PreserveJVMState pjvms(this);
4012           set_control(not_subtype_ctrl);
4013           uncommon_trap(Deoptimization::Reason_class_check,
4014                         Deoptimization::Action_make_not_entrant);
4015           assert(stopped(), &quot;Should be stopped&quot;);
4016         }
4017         validated = true;
4018       }
4019 
4020       if (!stopped()) {
<span class="line-modified">4021         newcopy = new_array(klass_node, length, 0);  // no arguments to push</span>




4022 
4023         ArrayCopyNode* ac = ArrayCopyNode::make(this, true, original, start, newcopy, intcon(0), moved, true, false,
4024                                                 original_kls, klass_node);
4025         if (!is_copyOfRange) {
4026           ac-&gt;set_copyof(validated);
4027         } else {
4028           ac-&gt;set_copyofrange(validated);
4029         }
4030         Node* n = _gvn.transform(ac);
4031         if (n == ac) {
4032           ac-&gt;connect_outputs(this);
4033         } else {
4034           assert(validated, &quot;shouldn&#39;t transform if all arguments not validated&quot;);
4035           set_all_memory(n);
4036         }
4037       }
4038     }
4039   } // original reexecute is set back here
4040 
4041   C-&gt;set_has_split_ifs(true); // Has chance for split-if optimization
</pre>
<hr />
<pre>
4637     RegionNode* slow_region = new RegionNode(1);
4638     record_for_igvn(slow_region);
4639 
4640     Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)NULL);
4641     if (array_ctl != NULL) {
4642       // It&#39;s an array.
4643       PreserveJVMState pjvms(this);
4644       set_control(array_ctl);
4645 
4646       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
4647       if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing) &amp;&amp;
4648           (!obj_type-&gt;isa_aryptr() || !obj_type-&gt;is_aryptr()-&gt;is_not_flat())) {
4649         // Flattened value type array may have object field that would require a
4650         // write barrier. Conservatively, go to slow path.
4651         generate_valueArray_guard(obj_klass, slow_region);
4652       }
4653 
4654       if (!stopped()) {
4655         Node* obj_length = load_array_length(obj);
4656         Node* obj_size  = NULL;
<span class="line-modified">4657         Node* alloc_obj = new_array(obj_klass, obj_length, 0, &amp;obj_size);  // no arguments to push</span>





4658 
4659         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
4660         if (bs-&gt;array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {
4661           // If it is an oop array, it requires very special treatment,
4662           // because gc barriers are required when accessing the array.
4663           Node* is_obja = generate_objArray_guard(obj_klass, (RegionNode*)NULL);
4664           if (is_obja != NULL) {
4665             PreserveJVMState pjvms2(this);
4666             set_control(is_obja);
4667             // Generate a direct call to the right arraycopy function(s).
4668             Node* alloc = tightly_coupled_allocation(alloc_obj, NULL);
4669             ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, alloc != NULL, false);
4670             ac-&gt;set_clone_oop_array();
4671             Node* n = _gvn.transform(ac);
4672             assert(n == ac, &quot;cannot disappear&quot;);
4673             ac-&gt;connect_outputs(this);
4674 
4675             result_reg-&gt;init_req(_objArray_path, control());
4676             result_val-&gt;init_req(_objArray_path, alloc_obj);
4677             result_i_o -&gt;set_req(_objArray_path, i_o());
</pre>
</td>
</tr>
</table>
<center><a href="ifnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopUnswitch.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>