diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -1398,10 +1398,11 @@
     // Load barrier has not yet been applied, so ZGC can't verify the oop here
     if (!UseZGC) {
       __ verify_oop(dest->as_register());
     }
   } else if (type == T_ADDRESS && addr->disp() == oopDesc::klass_offset_in_bytes()) {
+    // TODO remove clear_prop_bits bits stuff once the runtime does not set it anymore
 #ifdef _LP64
     if (UseCompressedClassPointers) {
       __ andl(dest->as_register(), oopDesc::compressed_klass_mask());
       __ decode_klass_not_null(dest->as_register());
     } else {
@@ -1994,36 +1995,37 @@
       }
 
 }
 
 void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {
-  // We are loading/storing an array that *may* be a flattened array (the declared type
-  // Object[], interface[], or VT?[]). If this array is flattened, take slow path.
-
-  __ load_storage_props(op->tmp()->as_register(), op->array()->as_register());
-  __ testb(op->tmp()->as_register(), ArrayStorageProperties::flattened_value);
+  // We are loading/storing from/to an array that *may* be flattened (the
+  // declared type is Object[], abstract[], interface[] or VT.ref[]).
+  // If this array is flattened, take the slow path.
+  Register klass = op->tmp()->as_register();
+  __ load_klass(klass, op->array()->as_register());
+  __ movl(klass, Address(klass, Klass::layout_helper_offset()));
+  __ testl(klass, Klass::_lh_array_tag_vt_value_bit_inplace);
   __ jcc(Assembler::notZero, *op->stub()->entry());
   if (!op->value()->is_illegal()) {
-    // We are storing into the array.
+    // The array is not flattened, but it might be null-free. If we are storing
+    // a null into a null-free array, take the slow path (which will throw NPE).
     Label skip;
-    __ testb(op->tmp()->as_register(), ArrayStorageProperties::null_free_value);
-    __ jcc(Assembler::zero, skip);
-    // The array is not flattened, but it is null_free. If we are storing
-    // a null, take the slow path (which will throw NPE).
     __ cmpptr(op->value()->as_register(), (int32_t)NULL_WORD);
-    __ jcc(Assembler::zero, *op->stub()->entry());
+    __ jcc(Assembler::notEqual, skip);
+    __ testl(klass, Klass::_lh_null_free_bit_inplace);
+    __ jcc(Assembler::notZero, *op->stub()->entry());
     __ bind(skip);
   }
 }
 
 void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {
-  // This is called when we use aastore into a an array declared as "[LVT;",
-  // where we know VT is not flattenable (due to ValueArrayElemMaxFlatOops, etc).
-  // However, we need to do a NULL check if the actual array is a "[QVT;".
-
-  __ load_storage_props(op->tmp()->as_register(), op->array()->as_register());
-  __ testb(op->tmp()->as_register(), ArrayStorageProperties::null_free_value);
+  // We are storing into an array that *may* be null-free (the declared type is
+  // Object[], abstract[], interface[] or VT.ref[]).
+  Register klass = op->tmp()->as_register();
+  __ load_klass(klass, op->array()->as_register());
+  __ movl(klass, Address(klass, Klass::layout_helper_offset()));
+  __ testl(klass, Klass::_lh_null_free_bit_inplace);
 }
 
 void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {
   Label L_oops_equal;
   Label L_oops_not_equal;
@@ -3261,19 +3263,20 @@
 void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {
   if (null_check) {
     __ testptr(obj, obj);
     __ jcc(Assembler::zero, *slow_path->entry());
   }
-  __ load_storage_props(tmp, obj);
+  __ load_klass(tmp, obj);
+  __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));
   if (is_dest) {
     // We also take slow path if it's a null_free destination array, just in case the source array
     // contains NULLs.
-    __ testb(tmp, ArrayStorageProperties::flattened_value | ArrayStorageProperties::null_free_value);
+    __ testl(tmp, Klass::_lh_null_free_bit_inplace);
   } else {
-    __ testb(tmp, ArrayStorageProperties::flattened_value);
+    __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);
   }
-  __ jcc(Assembler::notEqual, *slow_path->entry());
+  __ jcc(Assembler::notZero, *slow_path->entry());
 }
 
 
 // This code replaces a call to arraycopy; no exception may
 // be thrown in this code, they must be thrown in the System.arraycopy
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -4608,19 +4608,10 @@
   } else {
     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
   }
 }
 
-void MacroAssembler::load_storage_props(Register dst, Register src) {
-  load_metadata(dst, src);
-  if (UseCompressedClassPointers) {
-    shrl(dst, oopDesc::narrow_storage_props_shift);
-  } else {
-    shrq(dst, oopDesc::wide_storage_props_shift);
-  }
-}
-
 void MacroAssembler::load_method_holder(Register holder, Register method) {
   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
 }
diff a/src/hotspot/cpu/x86/macroAssembler_x86.hpp b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
@@ -343,11 +343,10 @@
 
   void load_method_holder(Register holder, Register method);
 
   // oop manipulations
   void load_metadata(Register dst, Register src);
-  void load_storage_props(Register dst, Register src);
   void load_klass(Register dst, Register src);
   void store_klass(Register dst, Register src);
 
   void access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
                       Register tmp1, Register thread_tmp);
diff a/src/hotspot/share/c1/c1_Instruction.cpp b/src/hotspot/share/c1/c1_Instruction.cpp
--- a/src/hotspot/share/c1/c1_Instruction.cpp
+++ b/src/hotspot/share/c1/c1_Instruction.cpp
@@ -127,17 +127,12 @@
 }
 
 bool Instruction::is_loaded_flattened_array() const {
   if (ValueArrayFlatten) {
     ciType* type = declared_type();
-    if (type != NULL && type->is_value_array_klass()) {
-      ciValueArrayKlass* vak = type->as_value_array_klass();
-      ArrayStorageProperties props = vak->storage_properties();
-      return (!props.is_empty() && props.is_null_free() && props.is_flattened());
-    }
+    return type != NULL && type->is_value_array_klass();
   }
-
   return false;
 }
 
 bool Instruction::maybe_flattened_array() {
   if (ValueArrayFlatten) {
@@ -145,20 +140,16 @@
     if (type != NULL) {
       if (type->is_obj_array_klass()) {
         // Due to array covariance, the runtime type might be a flattened array.
         ciKlass* element_klass = type->as_obj_array_klass()->element_klass();
         if (element_klass->can_be_value_klass() && (!element_klass->is_valuetype() || element_klass->as_value_klass()->flatten_array())) {
-          // We will add a runtime check for flat-ness.
           return true;
         }
       } else if (type->is_value_array_klass()) {
         ciKlass* element_klass = type->as_value_array_klass()->element_klass();
-        if (!element_klass->is_loaded() ||
-            (element_klass->is_valuetype() && element_klass->as_value_klass()->flatten_array())) {
-          // We will add a runtime check for flat-ness.
-          return true;
-        }
+        assert(!element_klass->is_loaded() || element_klass->as_value_klass()->flatten_array(), "must be flattened");
+        return true;
       } else if (type->is_klass() && type->as_klass()->is_java_lang_Object()) {
         // This can happen as a parameter to System.arraycopy()
         return true;
       }
     } else {
@@ -175,12 +166,11 @@
   if (type != NULL) {
     if (type->is_obj_array_klass()) {
       // Due to array covariance, the runtime type might be a null-free array.
       ciKlass* element_klass = type->as_obj_array_klass()->element_klass();
       if (element_klass->can_be_value_klass()) {
-          // We will add a runtime check for null-free-ness.
-          return true;
+        return true;
       }
     }
   } else {
     // Type info gets lost during Phi merging (Phi, IfOp, etc), but we might be storing into a
     // null-free array, so we should do a runtime check.
@@ -296,20 +286,11 @@
 ciType* NewTypeArray::exact_type() const {
   return ciTypeArrayKlass::make(elt_type());
 }
 
 ciType* NewObjectArray::exact_type() const {
-  ciKlass* element_klass = klass();
-  if (is_never_null() && element_klass->is_valuetype()) {
-    if (element_klass->as_value_klass()->flatten_array()) {
-      return ciValueArrayKlass::make(element_klass);
-    } else {
-      return ciObjArrayKlass::make(element_klass, /*never_null =*/true);
-    }
-  } else {
-    return ciObjArrayKlass::make(element_klass);
-  }
+  return ciArrayKlass::make(klass());
 }
 
 ciType* NewMultiArray::exact_type() const {
   return _klass;
 }
diff a/src/hotspot/share/c1/c1_Runtime1.cpp b/src/hotspot/share/c1/c1_Runtime1.cpp
--- a/src/hotspot/share/c1/c1_Runtime1.cpp
+++ b/src/hotspot/share/c1/c1_Runtime1.cpp
@@ -1091,16 +1091,11 @@
         }
         break;
       case Bytecodes::_anewarray:
         { Bytecode_anewarray anew(caller_method(), caller_method->bcp_from(bci));
           Klass* ek = caller_method->constants()->klass_at(anew.index(), CHECK);
-          if (ek->is_value() && caller_method->constants()->klass_at_noresolve(anew.index())->is_Q_signature()) {
-            k = ek->array_klass(1, CHECK);
-            assert(k->is_null_free_array_klass(), "Expect a null-free array class here");
-          } else {
-            k = ek->array_klass(CHECK);
-          }
+          k = ek->array_klass(CHECK);
         }
         break;
       case Bytecodes::_ldc:
       case Bytecodes::_ldc_w:
         {
diff a/src/hotspot/share/ci/ciArrayKlass.cpp b/src/hotspot/share/ci/ciArrayKlass.cpp
--- a/src/hotspot/share/ci/ciArrayKlass.cpp
+++ b/src/hotspot/share/ci/ciArrayKlass.cpp
@@ -99,28 +99,24 @@
 
 // ------------------------------------------------------------------
 // ciArrayKlass::base_element_type
 //
 // What type is obtained when this array is indexed as many times as possible?
-ciArrayKlass* ciArrayKlass::make(ciType* element_type, bool never_null) {
+ciArrayKlass* ciArrayKlass::make(ciType* element_type) {
   if (element_type->is_primitive_type()) {
     return ciTypeArrayKlass::make(element_type->basic_type());
-  } else if (element_type->is_valuetype() && element_type->as_value_klass()->flatten_array() && never_null) {
+  } else if (element_type->is_valuetype() && element_type->as_value_klass()->flatten_array()) {
     return ciValueArrayKlass::make(element_type->as_klass());
   } else {
-    return ciObjArrayKlass::make(element_type->as_klass(), never_null);
+    return ciObjArrayKlass::make(element_type->as_klass());
   }
 }
 
 int ciArrayKlass::array_header_in_bytes() {
   return get_ArrayKlass()->array_header_in_bytes();
 }
 
-ArrayStorageProperties ciArrayKlass::storage_properties() {
-  return get_ArrayKlass()->storage_properties();
-}
-
 ciInstance* ciArrayKlass::component_mirror_instance() const {
   GUARDED_VM_ENTRY(
     oop component_mirror = ArrayKlass::cast(get_Klass())->component_mirror();
     return CURRENT_ENV->get_instance(component_mirror);
   )
diff a/src/hotspot/share/ci/ciArrayKlass.hpp b/src/hotspot/share/ci/ciArrayKlass.hpp
--- a/src/hotspot/share/ci/ciArrayKlass.hpp
+++ b/src/hotspot/share/ci/ciArrayKlass.hpp
@@ -57,13 +57,12 @@
   bool is_java_klass() const  { return true; }
 
   // The one-level type of the array elements.
   virtual ciKlass* element_klass() { return NULL; }
 
-  static ciArrayKlass* make(ciType* element_type, bool never_null = false);
+  static ciArrayKlass* make(ciType* element_type);
 
   int array_header_in_bytes();
-  ArrayStorageProperties storage_properties();
   ciInstance* component_mirror_instance() const;
 };
 
 #endif // SHARE_CI_CIARRAYKLASS_HPP
diff a/src/hotspot/share/ci/ciEnv.cpp b/src/hotspot/share/ci/ciEnv.cpp
--- a/src/hotspot/share/ci/ciEnv.cpp
+++ b/src/hotspot/share/ci/ciEnv.cpp
@@ -479,11 +479,11 @@
                              cpool,
                              get_symbol(ss.as_symbol()),
                              require_local);
     if (elem_klass != NULL && elem_klass->is_loaded()) {
       // Now make an array for it
-      return ciArrayKlass::make(elem_klass, sym->char_at(1) == JVM_SIGNATURE_VALUETYPE);
+      return ciArrayKlass::make(elem_klass);
     }
   }
 
   if (found_klass == NULL && !cpool.is_null() && cpool->has_preresolution()) {
     // Look inside the constant pool for pre-resolved class entries.
diff a/src/hotspot/share/ci/ciInstance.cpp b/src/hotspot/share/ci/ciInstance.cpp
--- a/src/hotspot/share/ci/ciInstance.cpp
+++ b/src/hotspot/share/ci/ciInstance.cpp
@@ -37,11 +37,11 @@
 // This class represents an instanceOop in the HotSpot virtual
 // machine.
 
 // ------------------------------------------------------------------
 // ciObject::java_mirror_type
-ciType* ciInstance::java_mirror_type(bool* is_indirect_type) {
+ciType* ciInstance::java_mirror_type() {
   VM_ENTRY_MARK;
   oop m = get_oop();
   // Return NULL if it is not java.lang.Class.
   if (m == NULL || m->klass() != SystemDictionary::Class_klass()) {
     return NULL;
@@ -50,13 +50,10 @@
   if (java_lang_Class::is_primitive(m)) {
     return ciType::make(java_lang_Class::primitive_type(m));
   } else {
     Klass* k = java_lang_Class::as_Klass(m);
     assert(k != NULL, "");
-    if (is_indirect_type != NULL) {
-      *is_indirect_type = java_lang_Class::is_indirect_type(m);
-    }
     return CURRENT_THREAD_ENV->get_klass(k);
   }
 }
 
 // ------------------------------------------------------------------
diff a/src/hotspot/share/ci/ciInstance.hpp b/src/hotspot/share/ci/ciInstance.hpp
--- a/src/hotspot/share/ci/ciInstance.hpp
+++ b/src/hotspot/share/ci/ciInstance.hpp
@@ -53,11 +53,11 @@
 
 public:
   // If this object is a java mirror, return the corresponding type.
   // Otherwise, return NULL.
   // (Remember that a java mirror is an instance of java.lang.Class.)
-  ciType* java_mirror_type(bool* is_indirect_type = NULL);
+  ciType* java_mirror_type();
 
   // What kind of ciObject is this?
   bool is_instance()     { return true; }
   bool is_java_object()  { return true; }
 
diff a/src/hotspot/share/ci/ciInstanceKlass.cpp b/src/hotspot/share/ci/ciInstanceKlass.cpp
--- a/src/hotspot/share/ci/ciInstanceKlass.cpp
+++ b/src/hotspot/share/ci/ciInstanceKlass.cpp
@@ -678,11 +678,11 @@
       is_valuetype() || // Known to be a value klass
       // Non-exact j.l.Object or interface klass
       ((is_java_lang_Object() || is_interface()) && !is_exact)) {
     return true;
   }
-  if (is_abstract() && !has_nonstatic_fields()) {
+  if (is_abstract() && !is_exact && !has_nonstatic_fields()) {
     // TODO Factor out and re-use similar code from the ClassFileParser
     // An abstract class can only be implemented by a value type if it has no instance
     // fields, no synchronized instance methods and an empty, no-arg constructor.
     VM_ENTRY_MARK;
     Array<Method*>* methods = get_instanceKlass()->methods();
diff a/src/hotspot/share/ci/ciObjArrayKlass.cpp b/src/hotspot/share/ci/ciObjArrayKlass.cpp
--- a/src/hotspot/share/ci/ciObjArrayKlass.cpp
+++ b/src/hotspot/share/ci/ciObjArrayKlass.cpp
@@ -132,18 +132,15 @@
 
 // ------------------------------------------------------------------
 // ciObjArrayKlass::make_impl
 //
 // Implementation of make.
-ciObjArrayKlass* ciObjArrayKlass::make_impl(ciKlass* element_klass, bool never_null) {
+ciObjArrayKlass* ciObjArrayKlass::make_impl(ciKlass* element_klass) {
   if (element_klass->is_loaded()) {
     EXCEPTION_CONTEXT;
     // The element klass is loaded
     Klass* array = element_klass->get_Klass()->array_klass(THREAD);
-    if (element_klass->is_valuetype()) {
-      assert(ObjArrayKlass::cast(array)->storage_properties().is_null_free() == never_null, "wrong nullability storage property");
-    }
     if (HAS_PENDING_EXCEPTION) {
       CLEAR_PENDING_EXCEPTION;
       CURRENT_THREAD_ENV->record_out_of_memory_failure();
       return ciEnv::unloaded_ciobjarrayklass();
     }
@@ -162,25 +159,16 @@
 
 // ------------------------------------------------------------------
 // ciObjArrayKlass::make
 //
 // Make an array klass corresponding to the specified primitive type.
-ciObjArrayKlass* ciObjArrayKlass::make(ciKlass* element_klass, bool never_null) {
-  GUARDED_VM_ENTRY(return make_impl(element_klass, never_null);)
+ciObjArrayKlass* ciObjArrayKlass::make(ciKlass* element_klass) {
+  GUARDED_VM_ENTRY(return make_impl(element_klass);)
 }
 
 ciKlass* ciObjArrayKlass::exact_klass() {
   ciType* base = base_element_type();
-
-  if (!is_loaded()) {
-    return NULL;
-  }
-
-  if (!storage_properties().is_null_free() && element_klass()->is_valuetype()) {
-    return NULL;
-  }
-
   if (base->is_instance_klass()) {
     ciInstanceKlass* ik = base->as_instance_klass();
     if (ik->exact_klass() != NULL) {
       return this;
     }
diff a/src/hotspot/share/ci/ciObjArrayKlass.hpp b/src/hotspot/share/ci/ciObjArrayKlass.hpp
--- a/src/hotspot/share/ci/ciObjArrayKlass.hpp
+++ b/src/hotspot/share/ci/ciObjArrayKlass.hpp
@@ -47,11 +47,11 @@
 
   ObjArrayKlass* get_ObjArrayKlass() {
     return (ObjArrayKlass*)get_Klass();
   }
 
-  static ciObjArrayKlass* make_impl(ciKlass* element_klass, bool never_null);
+  static ciObjArrayKlass* make_impl(ciKlass* element_klass);
   static ciSymbol* construct_array_name(ciSymbol* element_name,
                                         int       dimension);
 
   const char* type_string() { return "ciObjArrayKlass"; }
 
@@ -70,11 +70,11 @@
   ciKlass* base_element_klass() { return _base_element_klass; }
 
   // What kind of ciObject is this?
   bool is_obj_array_klass() const { return true; }
 
-  static ciObjArrayKlass* make(ciKlass* element_klass, bool never_null = false);
+  static ciObjArrayKlass* make(ciKlass* element_klass);
 
   virtual ciKlass* exact_klass();
 
   virtual bool can_be_value_array_klass() {
     return element_klass()->can_be_value_klass();
diff a/src/hotspot/share/ci/ciTypeFlow.cpp b/src/hotspot/share/ci/ciTypeFlow.cpp
--- a/src/hotspot/share/ci/ciTypeFlow.cpp
+++ b/src/hotspot/share/ci/ciTypeFlow.cpp
@@ -321,32 +321,28 @@
     return object_klass;
   } else if (k1->is_array_klass() || k2->is_array_klass()) {
     // When an array meets a non-array, we get Object.
     // When (obj/value)Array meets typeArray, we also get Object.
     // And when typeArray meets different typeArray, we again get Object.
-    // But when (obj/value)Array meets (obj/value)Array, we look carefully at element types and storage properties.
+    // But when (obj/value)Array meets (obj/value)Array, we look carefully at element types.
     if ((k1->is_obj_array_klass() || k1->is_value_array_klass()) &&
         (k2->is_obj_array_klass() || k2->is_value_array_klass())) {
-      bool prop_mismatch = k1->as_array_klass()->storage_properties().value() !=
-                           k2->as_array_klass()->storage_properties().value();
-      bool never_null = k1->as_array_klass()->storage_properties().is_null_free() &&
-                        k2->as_array_klass()->storage_properties().is_null_free();
       ciType* elem1 = k1->as_array_klass()->element_klass();
       ciType* elem2 = k2->as_array_klass()->element_klass();
       ciType* elem = elem1;
       if (elem1 != elem2) {
         elem = type_meet_internal(elem1, elem2, analyzer)->as_klass();
       }
       // Do an easy shortcut if one type is a super of the other.
-      if (elem == elem1 && !prop_mismatch) {
-        assert(k1 == ciArrayKlass::make(elem, never_null), "shortcut is OK");
+      if (elem == elem1) {
+        assert(k1 == ciArrayKlass::make(elem), "shortcut is OK");
         return k1;
-      } else if (elem == elem2 && !prop_mismatch) {
-        assert(k2 == ciArrayKlass::make(elem, never_null), "shortcut is OK");
+      } else if (elem == elem2) {
+        assert(k2 == ciArrayKlass::make(elem), "shortcut is OK");
         return k2;
       } else {
-        return ciArrayKlass::make(elem, never_null);
+        return ciArrayKlass::make(elem);
       }
     } else {
       return object_klass;
     }
   } else {
@@ -609,13 +605,12 @@
     trap(str, element_klass,
          Deoptimization::make_trap_request
          (Deoptimization::Reason_unloaded,
           Deoptimization::Action_reinterpret));
   } else {
-    if (array_klass->storage_properties().is_null_free()) {
+    if (element_klass->is_valuetype()) {
       // Value type array elements are never null
-      assert(element_klass->is_valuetype(), "must be a value type array");
       push(outer()->mark_as_never_null(element_klass));
     } else {
       push_object(element_klass);
     }
   }
@@ -1000,12 +995,11 @@
       bool will_link;
       ciKlass* element_klass = str->get_klass(will_link);
       if (!will_link) {
         trap(str, element_klass, str->get_klass_index());
       } else {
-        bool never_null = str->is_klass_never_null();
-        push_object(ciArrayKlass::make(element_klass, never_null));
+        push_object(ciArrayKlass::make(element_klass));
       }
       break;
     }
   case Bytecodes::_areturn:
   case Bytecodes::_ifnonnull:
diff a/src/hotspot/share/ci/ciValueArrayKlass.cpp b/src/hotspot/share/ci/ciValueArrayKlass.cpp
--- a/src/hotspot/share/ci/ciValueArrayKlass.cpp
+++ b/src/hotspot/share/ci/ciValueArrayKlass.cpp
@@ -131,12 +131,11 @@
   assert(element_klass->is_valuetype(), "element type must be value type");
   assert(element_klass->is_loaded(), "unloaded Q klasses are represented by ciInstanceKlass");
   {
     EXCEPTION_CONTEXT;
     // The element klass is loaded
-    Klass* array = element_klass->get_Klass()->array_klass(1, THREAD);
-    assert(ValueArrayKlass::cast(array)->storage_properties().is_null_free(), "should be null free");
+    Klass* array = element_klass->get_Klass()->array_klass(THREAD);
     if (HAS_PENDING_EXCEPTION) {
       CLEAR_PENDING_EXCEPTION;
       CURRENT_THREAD_ENV->record_out_of_memory_failure();
       // TODO handle this
       guarantee(false, "out of memory");
diff a/src/hotspot/share/ci/ciValueKlass.cpp b/src/hotspot/share/ci/ciValueKlass.cpp
--- a/src/hotspot/share/ci/ciValueKlass.cpp
+++ b/src/hotspot/share/ci/ciValueKlass.cpp
@@ -107,24 +107,10 @@
     oop default_value = to_ValueKlass()->default_value();
     return CURRENT_ENV->get_instance(default_value);
   )
 }
 
-ciInstance* ciValueKlass::inline_mirror_instance() const {
-  GUARDED_VM_ENTRY(
-    oop value_mirror = to_ValueKlass()->value_mirror();
-    return CURRENT_ENV->get_instance(value_mirror);
-  )
-}
-
-ciInstance* ciValueKlass::indirect_mirror_instance() const {
-  GUARDED_VM_ENTRY(
-    oop mirror = to_ValueKlass()->indirect_mirror();
-    return CURRENT_ENV->get_instance(mirror);
-  )
-}
-
 bool ciValueKlass::contains_oops() const {
   GUARDED_VM_ENTRY(return get_ValueKlass()->contains_oops();)
 }
 
 Array<SigEntry>* ciValueKlass::extended_sig() const {
diff a/src/hotspot/share/ci/ciValueKlass.hpp b/src/hotspot/share/ci/ciValueKlass.hpp
--- a/src/hotspot/share/ci/ciValueKlass.hpp
+++ b/src/hotspot/share/ci/ciValueKlass.hpp
@@ -81,12 +81,10 @@
   bool can_be_returned_as_fields() const;
   bool is_scalarizable() const;
   int value_arg_slots();
   int default_value_offset() const;
   ciInstance* default_value_instance() const;
-  ciInstance* inline_mirror_instance() const;
-  ciInstance* indirect_mirror_instance() const;
   bool contains_oops() const;
   Array<SigEntry>* extended_sig() const;
   address pack_handler() const;
   address unpack_handler() const;
   ValueKlass* get_ValueKlass() const;
diff a/src/hotspot/share/classfile/vmSymbols.cpp b/src/hotspot/share/classfile/vmSymbols.cpp
--- a/src/hotspot/share/classfile/vmSymbols.cpp
+++ b/src/hotspot/share/classfile/vmSymbols.cpp
@@ -538,12 +538,10 @@
       return true;
     }
   }
 
   switch (id) {
-  case vmIntrinsics::_asPrimaryType:
-  case vmIntrinsics::_asIndirectType:
   case vmIntrinsics::_isInstance:
   case vmIntrinsics::_isAssignableFrom:
   case vmIntrinsics::_getModifiers:
   case vmIntrinsics::_isInterface:
   case vmIntrinsics::_isArray:
diff a/src/hotspot/share/classfile/vmSymbols.hpp b/src/hotspot/share/classfile/vmSymbols.hpp
--- a/src/hotspot/share/classfile/vmSymbols.hpp
+++ b/src/hotspot/share/classfile/vmSymbols.hpp
@@ -880,14 +880,10 @@
   do_intrinsic(_currentThread,            java_lang_Thread,       currentThread_name, currentThread_signature,   F_S)   \
    do_name(     currentThread_name,                              "currentThread")                                       \
    do_signature(currentThread_signature,                         "()Ljava/lang/Thread;")                                \
                                                                                                                         \
   /* reflective intrinsics, for java/lang/Class, etc. */                                                                \
-  do_intrinsic(_asPrimaryType,           java_lang_Class,         asPrimaryType_name, void_class_signature,     F_R)    \
-   do_name(     asPrimaryType_name,                              "asPrimaryType")                                       \
-  do_intrinsic(_asIndirectType,          java_lang_Class,         asIndirectType_name, void_class_signature,    F_R)    \
-   do_name(     asIndirectType_name,                             "asIndirectType")                                      \
   do_intrinsic(_isAssignableFrom,         java_lang_Class,        isAssignableFrom_name, class_boolean_signature, F_RN) \
    do_name(     isAssignableFrom_name,                           "isAssignableFrom")                                    \
   do_intrinsic(_isInstance,               java_lang_Class,        isInstance_name, object_boolean_signature,     F_RN)  \
    do_name(     isInstance_name,                                 "isInstance")                                          \
   do_intrinsic(_getModifiers,             java_lang_Class,        getModifiers_name, void_int_signature,         F_RN)  \
diff a/src/hotspot/share/oops/klass.hpp b/src/hotspot/share/oops/klass.hpp
--- a/src/hotspot/share/oops/klass.hpp
+++ b/src/hotspot/share/oops/klass.hpp
@@ -497,11 +497,11 @@
 
   // array class with specific rank
   Klass* array_klass(int rank, TRAPS)         {  return array_klass_impl(false, rank, THREAD); }
 
   // array class with this klass as element type
-   Klass* array_klass(TRAPS)                   {  return array_klass_impl(false, THREAD); }
+  Klass* array_klass(TRAPS)                   {  return array_klass_impl(false, THREAD); }
 
   // These will return NULL instead of allocating on the heap:
   // NB: these can block for a mutex, like other functions with TRAPS arg.
   Klass* array_klass_or_null(int rank);
   Klass* array_klass_or_null();
diff a/src/hotspot/share/opto/c2compiler.cpp b/src/hotspot/share/opto/c2compiler.cpp
--- a/src/hotspot/share/opto/c2compiler.cpp
+++ b/src/hotspot/share/opto/c2compiler.cpp
@@ -614,12 +614,10 @@
   case vmIntrinsics::_doubleToRawLongBits:
   case vmIntrinsics::_doubleToLongBits:
   case vmIntrinsics::_longBitsToDouble:
   case vmIntrinsics::_Reference_get:
   case vmIntrinsics::_Class_cast:
-  case vmIntrinsics::_asPrimaryType:
-  case vmIntrinsics::_asIndirectType:
   case vmIntrinsics::_aescrypt_encryptBlock:
   case vmIntrinsics::_aescrypt_decryptBlock:
   case vmIntrinsics::_cipherBlockChaining_encryptAESCrypt:
   case vmIntrinsics::_cipherBlockChaining_decryptAESCrypt:
   case vmIntrinsics::_electronicCodeBook_encryptAESCrypt:
diff a/src/hotspot/share/opto/callnode.cpp b/src/hotspot/share/opto/callnode.cpp
--- a/src/hotspot/share/opto/callnode.cpp
+++ b/src/hotspot/share/opto/callnode.cpp
@@ -1625,11 +1625,10 @@
   init_req( InitialTest        , initial_test);
   init_req( ALength            , topnode);
   init_req( ValueNode          , value_node);
   // DefaultValue defaults to NULL
   // RawDefaultValue defaults to NULL
-  // StorageProperties defaults to NULL
   C->add_macro_node(this);
 }
 
 void AllocateNode::compute_MemBar_redundancy(ciMethod* initializer)
 {
diff a/src/hotspot/share/opto/callnode.hpp b/src/hotspot/share/opto/callnode.hpp
--- a/src/hotspot/share/opto/callnode.hpp
+++ b/src/hotspot/share/opto/callnode.hpp
@@ -880,11 +880,10 @@
     InitialTest,                      // slow-path test (may be constant)
     ALength,                          // array length (or TOP if none)
     ValueNode,
     DefaultValue,                     // default value in case of non flattened value array
     RawDefaultValue,                  // same as above but as raw machine word
-    StorageProperties,                // storage properties for arrays
     ParmLimit
   };
 
   static const TypeFunc* alloc_type(const Type* t) {
     const Type** fields = TypeTuple::fields(ParmLimit - TypeFunc::Parms);
@@ -893,11 +892,10 @@
     fields[InitialTest] = TypeInt::BOOL;
     fields[ALength]     = t;  // length (can be a bad length)
     fields[ValueNode]   = Type::BOTTOM;
     fields[DefaultValue] = TypeInstPtr::NOTNULL;
     fields[RawDefaultValue] = TypeX_X;
-    fields[StorageProperties] = TypeX_X;
 
     const TypeTuple *domain = TypeTuple::make(ParmLimit, fields);
 
     // create result type (range)
     fields = TypeTuple::fields(1);
@@ -999,18 +997,17 @@
 //
 class AllocateArrayNode : public AllocateNode {
 public:
   AllocateArrayNode(Compile* C, const TypeFunc *atype, Node *ctrl, Node *mem, Node *abio,
                     Node* size, Node* klass_node, Node* initial_test,
-                    Node* count_val, Node* default_value, Node* raw_default_value, Node* storage_properties)
+                    Node* count_val, Node* default_value, Node* raw_default_value)
     : AllocateNode(C, atype, ctrl, mem, abio, size, klass_node, initial_test)
   {
     init_class_id(Class_AllocateArray);
     set_req(AllocateNode::ALength,        count_val);
     init_req(AllocateNode::DefaultValue,  default_value);
     init_req(AllocateNode::RawDefaultValue, raw_default_value);
-    init_req(AllocateNode::StorageProperties, storage_properties);
   }
   virtual int Opcode() const;
   virtual Node *Ideal(PhaseGVN *phase, bool can_reshape);
 
   // Dig the length operand out of a array allocation site.
diff a/src/hotspot/share/opto/cfgnode.hpp b/src/hotspot/share/opto/cfgnode.hpp
--- a/src/hotspot/share/opto/cfgnode.hpp
+++ b/src/hotspot/share/opto/cfgnode.hpp
@@ -401,11 +401,11 @@
   // Takes the type of val and filters it through the test represented
   // by if_proj and returns a more refined type if one is produced.
   // Returns NULL is it couldn't improve the type.
   static const TypeInt* filtered_int_type(PhaseGVN* phase, Node* val, Node* if_proj);
 
-  bool is_flattened_array_check(PhaseTransform* phase, Node*& array);
+  bool is_non_flattened_array_check(PhaseTransform* phase, Node** array = NULL);
 
 #ifndef PRODUCT
   virtual void dump_spec(outputStream *st) const;
   virtual void related(GrowableArray <Node *> *in_rel, GrowableArray <Node *> *out_rel, bool compact) const;
 #endif
diff a/src/hotspot/share/opto/classes.hpp b/src/hotspot/share/opto/classes.hpp
--- a/src/hotspot/share/opto/classes.hpp
+++ b/src/hotspot/share/opto/classes.hpp
@@ -417,7 +417,5 @@
 macro(ExtractD)
 macro(Digit)
 macro(LowerCase)
 macro(UpperCase)
 macro(Whitespace)
-macro(GetNullFreeProperty)
-macro(GetFlattenedProperty)
diff a/src/hotspot/share/opto/compile.cpp b/src/hotspot/share/opto/compile.cpp
--- a/src/hotspot/share/opto/compile.cpp
+++ b/src/hotspot/share/opto/compile.cpp
@@ -3385,20 +3385,19 @@
       // Check to see if address types have grounded out somehow.
       const TypeInstPtr *tp = mem->in(MemNode::Address)->bottom_type()->isa_instptr();
       assert( !tp || oop_offset_is_sane(tp), "" );
     }
 #endif
+    // TODO remove clear_prop_bits bits stuff once the runtime does not set it anymore
     if (EnableValhalla &&
         ((nop == Op_LoadKlass && ((LoadKlassNode*)n)->clear_prop_bits()) ||
          (nop == Op_LoadNKlass && ((LoadNKlassNode*)n)->clear_prop_bits()))) {
       const TypeKlassPtr* tk = n->bottom_type()->make_ptr()->is_klassptr();
       assert(!tk->klass_is_exact(), "should have been folded");
       assert(n->as_Mem()->adr_type()->offset() == oopDesc::klass_offset_in_bytes(), "unexpected LoadKlass");
       if (tk->klass()->can_be_value_array_klass()) {
-        // Array load klass needs to filter out property bits (but not
-        // GetNullFreePropertyNode or GetFlattenedPropertyNode which
-        // needs to extract the storage property bits)
+        // Array load klass needs to filter out property bits
         uint last = unique();
         Node* pointer = NULL;
         if (nop == Op_LoadKlass) {
           Node* cast = new CastP2XNode(NULL, n);
           Node* masked = new LShiftXNode(cast, new ConINode(TypeInt::make(oopDesc::storage_props_nof_bits)));
@@ -3410,11 +3409,11 @@
           Node* masked = new AndINode(cast, new ConINode(TypeInt::make(oopDesc::compressed_klass_mask())));
           pointer = new CastI2NNode(masked, n->bottom_type());
         }
         for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {
           Node* u = n->fast_out(i);
-          if (u->_idx < last && u->Opcode() != Op_GetNullFreeProperty && u->Opcode() != Op_GetFlattenedProperty) {
+          if (u->_idx < last) {
             // If user is a comparison with a klass that can't be a value type
             // array klass, we don't need to clear the storage property bits.
             Node* cmp = (u->is_DecodeNKlass() && u->outcnt() == 1) ? u->unique_out() : u;
             if (cmp->is_Cmp()) {
               const TypeKlassPtr* kp1 = cmp->in(1)->bottom_type()->make_ptr()->isa_klassptr();
@@ -3952,27 +3951,10 @@
     n->dump(-1);
     assert(false, "value type node was not removed");
     break;
   }
 #endif
-  case Op_GetNullFreeProperty:
-  case Op_GetFlattenedProperty: {
-    // Extract the null free bits
-    uint last = unique();
-    Node* null_free = NULL;
-    int bit = nop == Op_GetNullFreeProperty ? ArrayStorageProperties::null_free_bit : ArrayStorageProperties::flattened_bit;
-    if (n->in(1)->Opcode() == Op_LoadKlass) {
-      Node* cast = new CastP2XNode(NULL, n->in(1));
-      null_free = new AndLNode(cast, new ConLNode(TypeLong::make(((jlong)1)<<(oopDesc::wide_storage_props_shift + bit))));
-    } else {
-      assert(n->in(1)->Opcode() == Op_LoadNKlass, "not a compressed klass?");
-      Node* cast = new CastN2INode(n->in(1));
-      null_free = new AndINode(cast, new ConINode(TypeInt::make(1<<(oopDesc::narrow_storage_props_shift + bit))));
-    }
-    n->subsume_by(null_free, this);
-    break;
-  }
   default:
     assert(!n->is_Call(), "");
     assert(!n->is_Mem(), "");
     assert(nop != Op_ProfileBoolean, "should be eliminated during IGVN");
     break;
@@ -4472,15 +4454,10 @@
         !superk->is_subtype_of(subk)) {
       return SSC_always_false;
     }
   }
 
-  // Do not fold the subtype check to an array klass pointer comparison for [V? arrays.
-  // [V is a subtype of [V? but the klass for [V is not equal to the klass for [V?. Perform a full test.
-  if (superk->is_obj_array_klass() && !superk->as_array_klass()->storage_properties().is_null_free() && superk->as_array_klass()->element_klass()->is_valuetype()) {
-    return SSC_full_test;
-  }
   // If casting to an instance klass, it must have no subtypes
   if (superk->is_interface()) {
     // Cannot trust interfaces yet.
     // %%% S.B. superk->nof_implementors() == 1
   } else if (superelem->is_instance_klass()) {
diff a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -1180,10 +1180,11 @@
 Node* GraphKit::load_object_klass(Node* obj, bool clear_prop_bits) {
   // Special-case a fresh allocation to avoid building nodes:
   Node* akls = AllocateNode::Ideal_klass(obj, &_gvn);
   if (akls != NULL)  return akls;
   Node* k_adr = basic_plus_adr(obj, oopDesc::klass_offset_in_bytes());
+  // TODO remove clear_prop_bits bits stuff once the runtime does not set it anymore
   return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT, clear_prop_bits));
 }
 
 //-------------------------load_array_length-----------------------------------
 Node* GraphKit::load_array_length(Node* array) {
@@ -3500,14 +3501,15 @@
       if (address->isa_AddP()) {
         array = address->as_AddP()->in(AddPNode::Base);
       }
     } else if (obj->is_Phi()) {
       Node* region = obj->in(0);
-      if (region->req() == 3 && region->in(1) != NULL && region->in(1)->in(0) != NULL) {
-        IfNode* iff = region->in(1)->in(0)->isa_If();
+      // TODO make this more robust (see JDK-8231346)
+      if (region->req() == 3 && region->in(2) != NULL && region->in(2)->in(0) != NULL) {
+        IfNode* iff = region->in(2)->in(0)->isa_If();
         if (iff != NULL) {
-          iff->is_flattened_array_check(&_gvn, array);
+          iff->is_non_flattened_array_check(&_gvn, &array);
         }
       }
     }
     if (array != NULL) {
       const TypeAryPtr* ary_t = _gvn.type(array)->isa_aryptr();
@@ -3532,62 +3534,39 @@
     }
   }
   return res;
 }
 
-Node* GraphKit::is_always_locked(Node* obj) {
+// Check if 'obj' is a value type by checking if it has the always_locked markWord pattern set.
+Node* GraphKit::is_value_type(Node* obj) {
   Node* mark_addr = basic_plus_adr(obj, oopDesc::mark_offset_in_bytes());
   Node* mark = make_load(NULL, mark_addr, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);
   Node* mask = _gvn.MakeConX(markWord::always_locked_pattern);
   Node* andx = _gvn.transform(new AndXNode(mark, mask));
   Node* cmp = _gvn.transform(new CmpXNode(andx, mask));
   return _gvn.transform(new BoolNode(cmp, BoolTest::eq));
 }
 
-Node* GraphKit::is_value_mirror(Node* mirror) {
-  Node* p = basic_plus_adr(mirror, java_lang_Class::inline_mirror_offset_in_bytes());
-  Node* inline_mirror = access_load_at(mirror, p, _gvn.type(p)->is_ptr(), TypeInstPtr::MIRROR->cast_to_ptr_type(TypePtr::BotPTR), T_OBJECT, IN_HEAP);
-  Node* cmp = _gvn.transform(new CmpPNode(mirror, inline_mirror));
-  return _gvn.transform(new BoolNode(cmp, BoolTest::eq));
+// Check if 'ary' is a non-flattened array
+Node* GraphKit::is_non_flattened_array(Node* ary) {
+  Node* kls = load_object_klass(ary);
+  Node* tag = load_lh_array_tag(kls);
+  Node* cmp = gen_lh_array_test(kls, Klass::_lh_array_tag_vt_value);
+  return _gvn.transform(new BoolNode(cmp, BoolTest::ne));
 }
 
-// Check if 'ary' is a null-free value type array
-Node* GraphKit::gen_null_free_array_check(Node* ary) {
-  assert(EnableValhalla, "should only be used if value types are enabled");
-  // Extract null free property from klass pointer
-  Node* k_adr = basic_plus_adr(ary, oopDesc::klass_offset_in_bytes());
-  const TypePtr* k_adr_type = k_adr->bottom_type()->isa_ptr();
-  Node* klass = NULL;
-  if (k_adr_type->is_ptr_to_narrowklass()) {
-    klass = _gvn.transform(new LoadNKlassNode(NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT->make_narrowklass(), MemNode::unordered, true));
-  } else {
-    klass = _gvn.transform(new LoadKlassNode(NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT, MemNode::unordered, true));
-  }
-  Node* null_free = _gvn.transform(new GetNullFreePropertyNode(klass));
-  Node* cmp = NULL;
-  if (_gvn.type(klass)->isa_klassptr()) {
-    cmp = _gvn.transform(new CmpLNode(null_free, zerocon(T_LONG)));
-  } else {
-    cmp = _gvn.transform(new CmpINode(null_free, zerocon(T_INT)));
-  }
+// Check if 'ary' is a nullable array
+Node* GraphKit::is_nullable_array(Node* ary) {
+  Node* kls = load_object_klass(ary);
+  Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
+  Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));
+  Node* null_free = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_null_free_shift)));
+  null_free = _gvn.transform(new AndINode(null_free, intcon(Klass::_lh_null_free_mask)));
+  Node* cmp = _gvn.transform(new CmpINode(null_free, intcon(0)));
   return _gvn.transform(new BoolNode(cmp, BoolTest::eq));
 }
 
-Node* GraphKit::gen_flattened_array_test(Node* ary) {
-  assert(EnableValhalla, "should only be used if value types are enabled");
-  // Extract flattened property from klass pointer
-  Node* k_adr = basic_plus_adr(ary, oopDesc::klass_offset_in_bytes());
-  const TypePtr* k_adr_type = k_adr->bottom_type()->isa_ptr();
-  Node* klass = NULL;
-  if (k_adr_type->is_ptr_to_narrowklass()) {
-    klass = _gvn.transform(new LoadNKlassNode(NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT->make_narrowklass(), MemNode::unordered, true));
-  } else {
-    klass = _gvn.transform(new LoadKlassNode(NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT, MemNode::unordered, true));
-  }
-  return _gvn.transform(new GetFlattenedPropertyNode(klass));
-}
-
 // Deoptimize if 'ary' is a null-free value type array and 'val' is null
 Node* GraphKit::gen_value_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace) {
   const Type* val_t = _gvn.type(val);
   if (val->is_ValueType() || !TypePtr::NULL_PTR->higher_equal(val_t)) {
     return ary; // Never null
@@ -3596,13 +3575,13 @@
   Node* null_ctl = top();
   null_check_oop(val, &null_ctl);
   if (null_ctl != top()) {
     PreserveJVMState pjvms(this);
     set_control(null_ctl);
-    // Deoptimize if null-free array
-    Node* bol = gen_null_free_array_check(ary);
-    { BuildCutout unless(this, bol, PROB_MAX);
+    {
+      // Deoptimize if null-free array
+      BuildCutout unless(this, is_nullable_array(ary), PROB_MAX);
       inc_sp(nargs);
       uncommon_trap(Deoptimization::Reason_null_check,
                     Deoptimization::Action_none);
     }
     region->init_req(1, control());
@@ -3624,22 +3603,19 @@
 }
 
 Node* GraphKit::load_lh_array_tag(Node* kls) {
   Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
   Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));
-
   return _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_array_tag_shift)));
 }
 
-
 Node* GraphKit::gen_lh_array_test(Node* kls, unsigned int lh_value) {
   Node* layout_val = load_lh_array_tag(kls);
   Node* cmp = _gvn.transform(new CmpINode(layout_val, intcon(lh_value)));
   return cmp;
 }
 
-
 //------------------------------next_monitor-----------------------------------
 // What number should be given to the next monitor?
 int GraphKit::next_monitor() {
   int current = jvms()->monitor_depth()* C->sync_stack_slots();
   int next = current + C->sync_stack_slots();
@@ -4057,12 +4033,11 @@
 // See comments on new_instance for the meaning of the other arguments.
 Node* GraphKit::new_array(Node* klass_node,     // array klass (maybe variable)
                           Node* length,         // number of array elements
                           int   nargs,          // number of arguments to push back for uncommon trap
                           Node* *return_size_val,
-                          bool deoptimize_on_exception,
-                          Node* elem_mirror) {
+                          bool deoptimize_on_exception) {
   jint  layout_con = Klass::_lh_neutral_value;
   Node* layout_val = get_layout_helper(klass_node, layout_con);
   bool  layout_is_con = (layout_val == NULL);
 
   if (!layout_is_con && !StressReflectiveCode &&
@@ -4205,94 +4180,82 @@
   if (initial_slow_test->is_Bool()) {
     // Hide it behind a CMoveI, or else PhaseIdealLoop::split_up will get sick.
     initial_slow_test = initial_slow_test->as_Bool()->as_int_value(&_gvn);
   }
 
-  const TypeOopPtr* ary_type = _gvn.type(klass_node)->is_klassptr()->as_instance_type();
+  const TypeKlassPtr* ary_klass = _gvn.type(klass_node)->isa_klassptr();
+  const TypeOopPtr* ary_type = ary_klass->as_instance_type();
   const TypeAryPtr* ary_ptr = ary_type->isa_aryptr();
-  const Type* elem = NULL;
-  ciKlass* elem_klass = NULL;
-
-  // Compute default value and storage properties for value type arrays:
-  // - null-ok:              MyValue.box[] (ciObjArrayKlass "[LMyValue")
-  // - null-free:            MyValue.val[] (ciObjArrayKlass "[QMyValue")
-  // - null-free, flattened: MyValue.val[] (ciValueArrayKlass "[QMyValue")
-  Node* storage_properties = NULL;
+
+  // Value type array variants:
+  // - null-ok:              MyValue.ref[] (ciObjArrayKlass "[LMyValue$ref")
+  // - null-free:            MyValue.val[] (ciObjArrayKlass "[QMyValue$val")
+  // - null-free, flattened: MyValue.val[] (ciValueArrayKlass "[QMyValue$val")
+  // Check if array is a null-free, non-flattened value type array
+  // that needs to be initialized with the default value type.
   Node* default_value = NULL;
   Node* raw_default_value = NULL;
-  int props_shift = UseCompressedClassPointers ? oopDesc::narrow_storage_props_shift : oopDesc::wide_storage_props_shift;
   if (ary_ptr != NULL && ary_ptr->klass_is_exact()) {
     // Array type is known
-    elem = ary_ptr->elem();
-    ciArrayKlass* ary_klass = ary_ptr->klass()->as_array_klass();
-    elem_klass = ary_klass->element_klass();
-
-    ArrayStorageProperties props = ary_klass->storage_properties();
-    if (!props.is_empty() && elem_klass->is_valuetype()) {
-      if (props.is_null_free() && !props.is_flattened()) {
-        default_value = ValueTypeNode::default_oop(gvn(), elem_klass->as_value_klass());
-        if (elem->isa_narrowoop()) {
-          default_value = _gvn.transform(new EncodePNode(default_value, elem));
+    ciKlass* elem_klass = ary_ptr->klass()->as_array_klass()->element_klass();
+    if (elem_klass != NULL && elem_klass->is_valuetype()) {
+      ciValueKlass* vk = elem_klass->as_value_klass();
+      if (!vk->flatten_array()) {
+        default_value = ValueTypeNode::default_oop(gvn(), vk);
+        if (UseCompressedOops) {
+          default_value = _gvn.transform(new EncodePNode(default_value, default_value->bottom_type()->make_narrowoop()));
           raw_default_value = raw_default_for_coops(default_value, *this);
         } else {
           raw_default_value = _gvn.transform(new CastP2XNode(control(), default_value));
         }
       }
-      storage_properties = MakeConX(props.encode<NOT_LP64(jint) LP64_ONLY(jlong)>(props_shift));
     }
-  }
-
-  if (EnableValhalla && (elem == NULL || (elem_klass != NULL && (elem_klass->is_java_lang_Object() || elem_klass->is_valuetype()) &&
-                                          !ary_type->klass_is_exact()))) {
-    // Array type is not known, compute default value and storage properties for initialization.
-    assert(default_value == NULL && raw_default_value == NULL && storage_properties == NULL, "shouldn't be set yet");
-    assert(elem_mirror != NULL, "should not be null");
-
+  } else if (ary_klass->klass()->can_be_value_array_klass()) {
+    // Array type is not known, add runtime checks
+    assert(!ary_klass->klass_is_exact(), "unexpected exact type");
     Node* r = new RegionNode(4);
     default_value = new PhiNode(r, TypeInstPtr::BOTTOM);
-    storage_properties = new PhiNode(r, TypeX_X);
-
-    Node* empty     = MakeConX(ArrayStorageProperties::empty.encode<NOT_LP64(jint) LP64_ONLY(jlong)>(props_shift));
-    Node* null_free = MakeConX(ArrayStorageProperties::null_free.encode<NOT_LP64(jint) LP64_ONLY(jlong)>(props_shift));
-    Node* flat      = MakeConX(ArrayStorageProperties::flattened_and_null_free.encode<NOT_LP64(jint) LP64_ONLY(jlong)>(props_shift));
 
-    // Check if element mirror is a value mirror
-    IfNode* iff = create_and_map_if(control(), is_value_mirror(elem_mirror), PROB_FAIR, COUNT_UNKNOWN);
+    // Check if array is an object array
+    Node* cmp = gen_lh_array_test(klass_node, Klass::_lh_array_tag_obj_value);
+    Node* bol = _gvn.transform(new BoolNode(cmp, BoolTest::eq));
+    IfNode* iff = create_and_map_if(control(), bol, PROB_FAIR, COUNT_UNKNOWN);
 
-    // Not a value mirror but a box mirror or not a value type array, initialize with all zero
+    // Not an object array, initialize with all zero
     r->init_req(1, _gvn.transform(new IfFalseNode(iff)));
     default_value->init_req(1, null());
-    storage_properties->init_req(1, empty);
 
-    // Value mirror (= null-free), check if flattened
+    // Object array, check if null-free
     set_control(_gvn.transform(new IfTrueNode(iff)));
-    Node* cmp = gen_lh_array_test(klass_node, Klass::_lh_array_tag_vt_value);
-    Node* bol = _gvn.transform(new BoolNode(cmp, BoolTest::eq));
+    Node* lhp = basic_plus_adr(klass_node, in_bytes(Klass::layout_helper_offset()));
+    Node* layout_val = _gvn.transform(LoadNode::make(_gvn, NULL, immutable_memory(), lhp, lhp->bottom_type()->is_ptr(), TypeInt::INT, T_INT, MemNode::unordered));
+    Node* null_free = _gvn.transform(new RShiftINode(layout_val, intcon(Klass::_lh_null_free_shift)));
+    null_free = _gvn.transform(new AndINode(null_free, intcon(Klass::_lh_null_free_mask)));
+    cmp = _gvn.transform(new CmpINode(null_free, intcon(0)));
+    bol = _gvn.transform(new BoolNode(cmp, BoolTest::ne));
     iff = create_and_map_if(control(), bol, PROB_FAIR, COUNT_UNKNOWN);
 
-    // Flattened, initialize with all zero
-    r->init_req(2, _gvn.transform(new IfTrueNode(iff)));
+    // Not null-free, initialize with all zero
+    r->init_req(2, _gvn.transform(new IfFalseNode(iff)));
     default_value->init_req(2, null());
-    storage_properties->init_req(2, flat);
 
-    // Non-flattened, initialize with the default value
-    set_control(_gvn.transform(new IfFalseNode(iff)));
+    // Null-free, non-flattened value array, initialize with the default value
+    set_control(_gvn.transform(new IfTrueNode(iff)));
     Node* p = basic_plus_adr(klass_node, in_bytes(ArrayKlass::element_klass_offset()));
     Node* eklass = _gvn.transform(LoadKlassNode::make(_gvn, control(), immutable_memory(), p, TypeInstPtr::KLASS));
     Node* adr_fixed_block_addr = basic_plus_adr(eklass, in_bytes(InstanceKlass::adr_valueklass_fixed_block_offset()));
     Node* adr_fixed_block = make_load(control(), adr_fixed_block_addr, TypeRawPtr::NOTNULL, T_ADDRESS, MemNode::unordered);
     Node* default_value_offset_addr = basic_plus_adr(adr_fixed_block, in_bytes(ValueKlass::default_value_offset_offset()));
     Node* default_value_offset = make_load(control(), default_value_offset_addr, TypeInt::INT, T_INT, MemNode::unordered);
+    Node* elem_mirror = load_mirror_from_klass(eklass);
     Node* default_value_addr = basic_plus_adr(elem_mirror, ConvI2X(default_value_offset));
     Node* val = access_load_at(elem_mirror, default_value_addr, _gvn.type(default_value_addr)->is_ptr(), TypeInstPtr::BOTTOM, T_OBJECT, IN_HEAP);
     r->init_req(3, control());
     default_value->init_req(3, val);
-    storage_properties->init_req(3, null_free);
 
     set_control(_gvn.transform(r));
     default_value = _gvn.transform(default_value);
-    storage_properties = _gvn.transform(storage_properties);
     if (UseCompressedOops) {
       default_value = _gvn.transform(new EncodePNode(default_value, default_value->bottom_type()->make_narrowoop()));
       raw_default_value = raw_default_for_coops(default_value, *this);
     } else {
       raw_default_value = _gvn.transform(new CastP2XNode(control(), default_value));
@@ -4303,12 +4266,11 @@
   AllocateArrayNode* alloc = new AllocateArrayNode(C, AllocateArrayNode::alloc_type(TypeInt::INT),
                                                    control(), mem, i_o(),
                                                    size, klass_node,
                                                    initial_slow_test,
                                                    length, default_value,
-                                                   raw_default_value,
-                                                   storage_properties);
+                                                   raw_default_value);
 
   // Cast to correct type.  Note that the klass_node may be constant or not,
   // and in the latter case the actual array type will be inexact also.
   // (This happens via a non-constant argument to inline_native_newArray.)
   // In any case, the value of klass_node provides the desired array type.
diff a/src/hotspot/share/opto/graphKit.hpp b/src/hotspot/share/opto/graphKit.hpp
--- a/src/hotspot/share/opto/graphKit.hpp
+++ b/src/hotspot/share/opto/graphKit.hpp
@@ -851,14 +851,13 @@
 
   // Generate a check-cast idiom.  Used by both the check-cast bytecode
   // and the array-store bytecode
   Node* gen_checkcast(Node *subobj, Node* superkls, Node* *failure_control = NULL, bool never_null = false);
 
-  Node* is_always_locked(Node* obj);
-  Node* is_value_mirror(Node* mirror);
-  Node* gen_null_free_array_check(Node* ary);
-  Node* gen_flattened_array_test(Node* ary);
+  Node* is_value_type(Node* obj);
+  Node* is_non_flattened_array(Node* ary);
+  Node* is_nullable_array(Node* ary);
   Node* gen_value_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace = false);
   Node* load_lh_array_tag(Node* kls);
   Node* gen_lh_array_test(Node* kls, unsigned int lh_value);
 
   Node* gen_subtype_check(Node* obj, Node* superklass);
@@ -884,12 +883,11 @@
                      Node* *return_size_val = NULL,
                      bool deoptimize_on_exception = false,
                      ValueTypeBaseNode* value_node = NULL);
   Node* new_array(Node* klass_node, Node* count_val, int nargs,
                   Node* *return_size_val = NULL,
-                  bool deoptimize_on_exception = false,
-                  Node* elem_mirror = NULL);
+                  bool deoptimize_on_exception = false);
 
   // java.lang.String helpers
   Node* load_String_length(Node* str, bool set_ctrl);
   Node* load_String_value(Node* str, bool set_ctrl);
   Node* load_String_coder(Node* str, bool set_ctrl);
diff a/src/hotspot/share/opto/idealKit.cpp b/src/hotspot/share/opto/idealKit.cpp
--- a/src/hotspot/share/opto/idealKit.cpp
+++ b/src/hotspot/share/opto/idealKit.cpp
@@ -77,14 +77,17 @@
       bol = Bool(CmpI(left, right), relop);
     } else {
       assert(left->bottom_type()->isa_long() != NULL, "what else?");
       bol = Bool(CmpL(left, right), relop);
     }
-
   } else {
     bol = Bool(CmpP(left, right), relop);
   }
+  if_then(bol, prob, cnt, push_new_state);
+}
+
+void IdealKit::if_then(Node* bol, float prob, float cnt, bool push_new_state) {
   // Delay gvn.tranform on if-nodes until construction is finished
   // to prevent a constant bool input from discarding a control output.
   IfNode* iff = delay_transform(new IfNode(ctrl(), bol, prob, cnt))->as_If();
   Node* then  = IfTrue(iff);
   Node* elsen = IfFalse(iff);
diff a/src/hotspot/share/opto/idealKit.hpp b/src/hotspot/share/opto/idealKit.hpp
--- a/src/hotspot/share/opto/idealKit.hpp
+++ b/src/hotspot/share/opto/idealKit.hpp
@@ -161,10 +161,11 @@
   Node* value(IdealVariable& v)         { return _cvstate->in(first_var + v.id()); }
   void dead(IdealVariable& v)           { set(v, (Node*)NULL); }
   void if_then(Node* left, BoolTest::mask relop, Node* right,
                float prob = PROB_FAIR, float cnt = COUNT_UNKNOWN,
                bool push_new_state = true);
+  void if_then(Node* bol, float prob = PROB_FAIR, float cnt = COUNT_UNKNOWN, bool push_new_state = true);
   void else_();
   void end_if();
   void loop(GraphKit* gkit, int nargs, IdealVariable& iv, Node* init, BoolTest::mask cmp, Node* limit,
             float prob = PROB_LIKELY(0.9), float cnt = COUNT_UNKNOWN);
   void end_loop();
diff a/src/hotspot/share/opto/ifnode.cpp b/src/hotspot/share/opto/ifnode.cpp
--- a/src/hotspot/share/opto/ifnode.cpp
+++ b/src/hotspot/share/opto/ifnode.cpp
@@ -1176,45 +1176,55 @@
     return true;
   }
   return false;
 }
 
-// Returns true if this IfNode belongs to a flattened array check
+// Returns true if this IfNode belongs to a non-flattened array check
 // and returns the corresponding array in the 'array' parameter.
-bool IfNode::is_flattened_array_check(PhaseTransform* phase, Node*& array) {
+bool IfNode::is_non_flattened_array_check(PhaseTransform* phase, Node** array) {
   Node* bol = in(1);
-  if (!bol->is_Bool() || bol->as_Bool()->_test._test != BoolTest::ne) {
+  if (!bol->is_Bool()) {
     return false;
   }
   Node* cmp = bol->in(1);
-  if (cmp->Opcode() != Op_CmpI && cmp->Opcode() != Op_CmpL) {
+  if (cmp->Opcode() != Op_CmpI) {
     return false;
   }
   Node* cmp_in1 = cmp->in(1);
   Node* cmp_in2 = cmp->in(2);
-  
-  if (cmp_in1->Opcode() != Op_GetFlattenedProperty) {
+  if ((unsigned int)cmp_in2->find_int_con(0) != Klass::_lh_array_tag_vt_value) {
     return false;
   }
-
-  jlong in2 = -1;
-  if (cmp->Opcode() == Op_CmpI) {
-    in2 = cmp_in2->find_int_con(-1);
-  } else {
-    in2 = cmp_in2->find_long_con(-1);
+  if (cmp_in1->Opcode() != Op_RShiftI) {
+    return false;
   }
-  
-  if (in2 != 0) {
+  Node* shift_in1 = cmp_in1->in(1);
+  Node* shift_in2 = cmp_in1->in(2);
+  if ((unsigned int)shift_in2->find_int_con(0) != Klass::_lh_array_tag_shift) {
     return false;
   }
-
-  Node* klass_load = cmp_in1->in(1);
-
-  if (klass_load->is_Load()) {
+  if (shift_in1->Opcode() != Op_LoadI) {
+    return false;
+  }
+  intptr_t offset;
+  Node* ptr = shift_in1->in(MemNode::Address);
+  Node* addr = AddPNode::Ideal_base_and_offset(ptr, phase, offset);
+  if (addr == NULL || offset != in_bytes(Klass::layout_helper_offset())) {
+    return false;
+  }
+  if (!phase->type(addr)->isa_klassptr()) {
+    return false;
+  }
+  Node* klass_load = ptr->as_AddP()->in(AddPNode::Base)->uncast();
+  if (klass_load->is_DecodeNKlass()) {
+    klass_load = klass_load->in(1);
+  }
+  if (array != NULL && klass_load->is_Load()) {
     Node* address = klass_load->in(MemNode::Address);
-    array = address->as_AddP()->in(AddPNode::Base);
+    *array = address->as_AddP()->in(AddPNode::Base);
   }
+  assert(bol->isa_Bool()->_test._test == BoolTest::ne, "IfTrue proj must point to non-flattened array");
   return true;
 }
 
 // Check that the If that is in between the 2 integer comparisons has
 // no side effect
diff a/src/hotspot/share/opto/library_call.cpp b/src/hotspot/share/opto/library_call.cpp
--- a/src/hotspot/share/opto/library_call.cpp
+++ b/src/hotspot/share/opto/library_call.cpp
@@ -192,10 +192,11 @@
   }
   Node* generate_access_flags_guard(Node* kls,
                                     int modifier_mask, int modifier_bits,
                                     RegionNode* region);
   Node* generate_interface_guard(Node* kls, RegionNode* region);
+  Node* generate_value_guard(Node* kls, RegionNode* region);
 
   enum ArrayKind {
     AnyArray,
     NonArray,
     ObjectArray,
@@ -289,11 +290,10 @@
 #ifdef JFR_HAVE_INTRINSICS
   bool inline_native_classID();
   bool inline_native_getEventWriter();
 #endif
   bool inline_native_Class_query(vmIntrinsics::ID id);
-  bool inline_value_Class_conversion(vmIntrinsics::ID id);
   bool inline_native_subtype_check();
   bool inline_native_getLength();
   bool inline_array_copyOf(bool is_copyOfRange);
   bool inline_array_equals(StrIntrinsicNode::ArgEnc ae);
   bool inline_preconditions_checkIndex();
@@ -815,13 +815,10 @@
   case vmIntrinsics::_isArray:
   case vmIntrinsics::_isPrimitive:
   case vmIntrinsics::_getSuperclass:
   case vmIntrinsics::_getClassAccessFlags:      return inline_native_Class_query(intrinsic_id());
 
-  case vmIntrinsics::_asPrimaryType:
-  case vmIntrinsics::_asIndirectType:           return inline_value_Class_conversion(intrinsic_id());
-
   case vmIntrinsics::_floatToRawIntBits:
   case vmIntrinsics::_floatToIntBits:
   case vmIntrinsics::_intBitsToFloat:
   case vmIntrinsics::_doubleToRawLongBits:
   case vmIntrinsics::_doubleToLongBits:
@@ -3287,14 +3284,19 @@
   Node* mbit = _gvn.transform(new AndINode(mods, mask));
   Node* cmp  = _gvn.transform(new CmpINode(mbit, bits));
   Node* bol  = _gvn.transform(new BoolNode(cmp, BoolTest::ne));
   return generate_fair_guard(bol, region);
 }
+
 Node* LibraryCallKit::generate_interface_guard(Node* kls, RegionNode* region) {
   return generate_access_flags_guard(kls, JVM_ACC_INTERFACE, 0, region);
 }
 
+Node* LibraryCallKit::generate_value_guard(Node* kls, RegionNode* region) {
+  return generate_access_flags_guard(kls, JVM_ACC_VALUE, 0, region);
+}
+
 //-------------------------inline_native_Class_query-------------------
 bool LibraryCallKit::inline_native_Class_query(vmIntrinsics::ID id) {
   const Type* return_type = TypeInt::BOOL;
   Node* prim_return_value = top();  // what happens if it's a primitive class?
   bool never_see_null = !too_many_traps(Deoptimization::Reason_null_check);
@@ -3464,37 +3466,10 @@
   C->set_has_split_ifs(true); // Has chance for split-if optimization
   set_result(region, phi);
   return true;
 }
 
-//-------------------------inline_value_Class_conversion-------------------
-// public Class<T> java.lang.Class.asPrimaryType();
-// public Class<T> java.lang.Class.asIndirectType()
-bool LibraryCallKit::inline_value_Class_conversion(vmIntrinsics::ID id) {
-  Node* mirror = argument(0); // Receiver Class
-  const TypeInstPtr* mirror_con = _gvn.type(mirror)->isa_instptr();
-  if (mirror_con == NULL) {
-    return false;
-  }
-
-  bool is_indirect_type = true;
-  ciType* tm = mirror_con->java_mirror_type(&is_indirect_type);
-  if (tm != NULL) {
-    Node* result = mirror;
-    if (tm->is_valuetype()) {
-      if (id == vmIntrinsics::_asPrimaryType && is_indirect_type) {
-        result = _gvn.makecon(TypeInstPtr::make(tm->as_value_klass()->inline_mirror_instance()));
-      } else if (id == vmIntrinsics::_asIndirectType && !is_indirect_type) {
-        result = _gvn.makecon(TypeInstPtr::make(tm->as_value_klass()->indirect_mirror_instance()));
-      }
-    }
-    set_result(result);
-    return true;
-  }
-  return false;
-}
-
 //-------------------------inline_Class_cast-------------------
 bool LibraryCallKit::inline_Class_cast() {
   Node* mirror = argument(0); // Class
   Node* obj    = argument(1);
   const TypeInstPtr* mirror_con = _gvn.type(mirror)->isa_instptr();
@@ -3502,36 +3477,33 @@
     return false;  // dead path (mirror->is_top()).
   }
   if (obj == NULL || obj->is_top()) {
     return false;  // dead path
   }
-
   ciKlass* obj_klass = NULL;
+  const Type* obj_t = _gvn.type(obj);
   if (obj->is_ValueType()) {
-    obj_klass = _gvn.type(obj)->value_klass();
-  } else {
-    const TypeOopPtr* tp = _gvn.type(obj)->isa_oopptr();
-    if (tp != NULL) {
-      obj_klass = tp->klass();
-    }
+    obj_klass = obj_t->value_klass();
+  } else if (obj_t->isa_oopptr()) {
+    obj_klass = obj_t->is_oopptr()->klass();
   }
 
   // First, see if Class.cast() can be folded statically.
   // java_mirror_type() returns non-null for compile-time Class constants.
-  bool is_indirect_type = true;
-  ciType* tm = mirror_con->java_mirror_type(&is_indirect_type);
-  if (!obj->is_ValueType() && !is_indirect_type) {
-    obj = null_check(obj);
-    if (stopped()) {
-      return true;
-    }
-  }
+  ciType* tm = mirror_con->java_mirror_type();
   if (tm != NULL && tm->is_klass() && obj_klass != NULL) {
     if (!obj_klass->is_loaded()) {
       // Don't use intrinsic when class is not loaded.
       return false;
     } else {
+      if (!obj->is_ValueType() && tm->as_klass()->is_valuetype()) {
+        // Casting to .val, check for null
+        obj = null_check(obj);
+        if (stopped()) {
+          return true;
+        }
+      }
       int static_res = C->static_subtype_check(tm->as_klass(), obj_klass);
       if (static_res == Compile::SSC_always_true) {
         // isInstance() is true - fold the code.
         set_result(obj);
         return true;
@@ -3569,21 +3541,21 @@
   // nothing is an instance of a primitive type.
   Node* kls = load_klass_from_mirror(mirror, false, region, _prim_path);
 
   Node* res = top();
   if (!stopped()) {
-    if (EnableValhalla && !obj->is_ValueType() && is_indirect_type) {
-      // Check if (mirror == inline_mirror && obj == null)
-      Node* is_val_mirror = generate_fair_guard(is_value_mirror(mirror), NULL);
-      if (is_val_mirror != NULL) {
+    if (EnableValhalla && !obj->is_ValueType()) {
+      // Check if we are casting to .val
+      Node* is_val_kls = generate_value_guard(kls, NULL);
+      if (is_val_kls != NULL) {
         RegionNode* r = new RegionNode(3);
         record_for_igvn(r);
         r->init_req(1, control());
 
         // Casting to .val, check for null
-        set_control(is_val_mirror);
-        Node *null_ctr = top();
+        set_control(is_val_kls);
+        Node* null_ctr = top();
         null_check_oop(obj, &null_ctr);
         region->init_req(_npe_path, null_ctr);
         r->init_req(2, control());
 
         set_control(_gvn.transform(r));
@@ -3674,13 +3646,10 @@
   if (!stopped()) {
     // now we have two reference types, in klasses[0..1]
     Node* subk   = klasses[1];  // the argument to isAssignableFrom
     Node* superk = klasses[0];  // the receiver
     region->set_req(_both_ref_path, gen_subtype_check(subk, superk));
-    // If superc is a value mirror, we also need to check if superc == subc because
-    // V? is not a subtype of V but due to subk == superk the subtype check will pass.
-    generate_fair_guard(is_value_mirror(args[0]), prim_region);
     // now we have a successful reference subtype check
     region->set_req(_ref_subtype_path, control());
   }
 
   // If both operands are primitive (both klasses null), then
@@ -3839,11 +3808,11 @@
   set_control(normal_ctl);
   if (!stopped()) {
     // Normal case:  The array type has been cached in the java.lang.Class.
     // The following call works fine even if the array type is polymorphic.
     // It could be a dynamic mix of int[], boolean[], Object[], etc.
-    Node* obj = new_array(klass_node, count_val, 0, NULL, false, mirror);  // no arguments to push
+    Node* obj = new_array(klass_node, count_val, 0);  // no arguments to push
     result_reg->init_req(_normal_path, control());
     result_val->init_req(_normal_path, obj);
     result_io ->init_req(_normal_path, i_o());
     result_mem->init_req(_normal_path, reset_memory());
 
@@ -4047,15 +4016,11 @@
         }
         validated = true;
       }
 
       if (!stopped()) {
-        // Load element mirror
-        Node* p = basic_plus_adr(array_type_mirror, java_lang_Class::component_mirror_offset_in_bytes());
-        Node* elem_mirror = access_load_at(array_type_mirror, p, _gvn.type(p)->is_ptr(), TypeInstPtr::MIRROR, T_OBJECT, IN_HEAP);
-
-        newcopy = new_array(klass_node, length, 0, NULL, false, elem_mirror);
+        newcopy = new_array(klass_node, length, 0);  // no arguments to push
 
         ArrayCopyNode* ac = ArrayCopyNode::make(this, true, original, start, newcopy, intcon(0), moved, true, false,
                                                 original_kls, klass_node);
         if (!is_copyOfRange) {
           ac->set_copyof(validated);
@@ -4687,16 +4652,11 @@
       }
 
       if (!stopped()) {
         Node* obj_length = load_array_length(obj);
         Node* obj_size  = NULL;
-        // Load element mirror
-        Node* array_type_mirror = load_mirror_from_klass(obj_klass);
-        Node* p = basic_plus_adr(array_type_mirror, java_lang_Class::component_mirror_offset_in_bytes());
-        Node* elem_mirror = access_load_at(array_type_mirror, p, _gvn.type(p)->is_ptr(), TypeInstPtr::MIRROR, T_OBJECT, IN_HEAP);
-
-        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size, false, elem_mirror);
+        Node* alloc_obj = new_array(obj_klass, obj_length, 0, &obj_size);  // no arguments to push
 
         BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
         if (bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Parsing)) {
           // If it is an oop array, it requires very special treatment,
           // because gc barriers are required when accessing the array.
diff a/src/hotspot/share/opto/loopUnswitch.cpp b/src/hotspot/share/opto/loopUnswitch.cpp
--- a/src/hotspot/share/opto/loopUnswitch.cpp
+++ b/src/hotspot/share/opto/loopUnswitch.cpp
@@ -80,22 +80,22 @@
 
   if (head->is_flattened_arrays()) {
     return false;
   }
 
-  Node_List flattened_checks;
-  if (phase->find_unswitching_candidate(this, flattened_checks) == NULL && flattened_checks.size() == 0) {
+  Node_List unswitch_iffs;
+  if (phase->find_unswitching_candidate(this, unswitch_iffs) == NULL) {
     return false;
   }
 
   // Too speculative if running low on nodes.
   return phase->may_require_nodes(est_loop_clone_sz(2));
 }
 
 //------------------------------find_unswitching_candidate-----------------------------
 // Find candidate "if" for unswitching
-IfNode* PhaseIdealLoop::find_unswitching_candidate(const IdealLoopTree *loop, Node_List& flattened_checks) const {
+IfNode* PhaseIdealLoop::find_unswitching_candidate(const IdealLoopTree *loop, Node_List& unswitch_iffs) const {
 
   // Find first invariant test that doesn't exit the loop
   LoopNode *head = loop->_head->as_Loop();
   IfNode* unswitch_iff = NULL;
   Node* n = head->in(LoopNode::LoopBackControl);
@@ -116,29 +116,28 @@
         }
       }
     }
     n = n_dom;
   }
+  if (unswitch_iff != NULL) {
+    unswitch_iffs.push(unswitch_iff);
+  }
 
-  Node* array;
-  if (unswitch_iff == NULL || unswitch_iff->is_flattened_array_check(&_igvn, array)) {
-    // collect all flattened array checks
+  // Collect all non-flattened array checks for unswitching to create a fast loop
+  // without checks (only non-flattened array accesses) and a slow loop with checks.
+  if (unswitch_iff == NULL || unswitch_iff->is_non_flattened_array_check(&_igvn)) {
     for (uint i = 0; i < loop->_body.size(); i++) {
-      Node* n = loop->_body.at(i);
-      if (n->is_If() && n->as_If()->is_flattened_array_check(&_igvn, array) &&
-          loop->is_invariant(n->in(1)) &&
-          !loop->is_loop_exit(n)) {
-        flattened_checks.push(n);
+      IfNode* n = loop->_body.at(i)->isa_If();
+      if (n != NULL && n != unswitch_iff && n->is_non_flattened_array_check(&_igvn) &&
+          loop->is_invariant(n->in(1)) && !loop->is_loop_exit(n)) {
+        unswitch_iffs.push(n);
+        if (unswitch_iff == NULL) {
+          unswitch_iff = n;
+        }
       }
     }
-    if (flattened_checks.size() > 1) {
-      unswitch_iff = NULL;
-    } else {
-      flattened_checks.clear();
-    }
   }
-
   return unswitch_iff;
 }
 
 //------------------------------do_unswitching-----------------------------
 // Clone loop with an invariant test (that does not exit) and
@@ -158,21 +157,22 @@
       // to wrong execution. Remove this bailout, once this is fixed.
       return;
     }
   }
   // Find first invariant test that doesn't exit the loop
-  Node_List flattened_checks;
-  IfNode* unswitch_iff = find_unswitching_candidate((const IdealLoopTree *)loop, flattened_checks);
-  assert(unswitch_iff != NULL || flattened_checks.size() > 0, "should be at least one");
-  if (unswitch_iff == NULL) {
-    unswitch_iff = flattened_checks.at(0)->as_If();
-  }
+  Node_List unswitch_iffs;
+  IfNode* unswitch_iff = find_unswitching_candidate((const IdealLoopTree *)loop, unswitch_iffs);
+  assert(unswitch_iff != NULL && unswitch_iffs.size() > 0, "should be at least one");
 
 #ifndef PRODUCT
   if (TraceLoopOpts) {
     tty->print("Unswitch   %d ", head->unswitch_count()+1);
     loop->dump_head();
+    for (uint i = 0; i < unswitch_iffs.size(); i++) {
+      unswitch_iffs.at(i)->dump(3);
+      tty->cr();
+    }
   }
 #endif
 
   // Need to revert back to normal loop
   if (head->is_CountedLoop() && !head->as_CountedLoop()->is_normal_loop()) {
@@ -212,65 +212,53 @@
   // Increment unswitch count
   LoopNode* head_clone = old_new[head->_idx]->as_Loop();
   int nct = head->unswitch_count() + 1;
   head->set_unswitch_count(nct);
   head_clone->set_unswitch_count(nct);
-  if (flattened_checks.size() > 0) {
-    head->mark_flattened_arrays();
-  }
 
   // Add test to new "if" outside of loop
   IfNode* invar_iff   = proj_true->in(0)->as_If();
   Node* invar_iff_c   = invar_iff->in(0);
   invar_iff->_prob    = unswitch_iff->_prob;
-  if (flattened_checks.size() > 0) {
-    // Flattened array checks are used in
-    // Parse::array_store()/Parse::array_load() to switch between a
-    // legacy object array access and a flattened value array
+  BoolNode* bol       = unswitch_iff->in(1)->as_Bool();
+  if (unswitch_iffs.size() > 1) {
+    // Flattened array checks are used on array access to switch between
+    // a legacy object array access and a flattened value type array
     // access. We want the performance impact on legacy accesses to be
-    // as small as possible so we make 2 copies of the loops: a fast
+    // as small as possible so we make two copies of the loop: a fast
     // one where all accesses are known to be legacy, a slow one where
     // some accesses are to flattened arrays. Flattened array checks
-    // can be removed from the first one but not from the second one
+    // can be removed from the fast loop but not from the slow loop
     // as it can have a mix of flattened/legacy accesses.
-    BoolNode* bol       = unswitch_iff->in(1)->clone()->as_Bool();
+    bol = bol->clone()->as_Bool();
     register_new_node(bol, invar_iff->in(0));
     Node* cmp = bol->in(1)->clone();
     register_new_node(cmp, invar_iff->in(0));
     bol->set_req(1, cmp);
+    // Combine all checks into a single one that fails if one array is flattened
     Node* in1 = NULL;
-    for (uint i = 0; i < flattened_checks.size(); i++) {
-      Node* v = flattened_checks.at(i)->in(1)->in(1)->in(1);
+    for (uint i = 0; i < unswitch_iffs.size(); i++) {
+      Node* array_tag = unswitch_iffs.at(i)->in(1)->in(1)->in(1);
+      array_tag = new AndINode(array_tag, _igvn.intcon(Klass::_lh_array_tag_vt_value));
+      register_new_node(array_tag, invar_iff->in(0));
       if (in1 == NULL) {
-        in1 = v;
+        in1 = array_tag;
       } else {
-        if (cmp->Opcode() == Op_CmpL) {
-          in1 = new OrLNode(in1, v);
-        } else {
-          in1 = new OrINode(in1, v);
-        }
+        in1 = new OrINode(in1, array_tag);
         register_new_node(in1, invar_iff->in(0));
       }
     }
     cmp->set_req(1, in1);
-    invar_iff->set_req(1, bol);
-  } else {
-    BoolNode* bol       = unswitch_iff->in(1)->as_Bool();
-    invar_iff->set_req(1, bol);
   }
+  invar_iff->set_req(1, bol);
 
-  ProjNode* proj_false = invar_iff->proj_out(0)->as_Proj();
-
-  // Hoist invariant casts out of each loop to the appropriate
-  // control projection.
-
+  // Hoist invariant casts out of each loop to the appropriate control projection.
   Node_List worklist;
-
-  if (flattened_checks.size() > 0) {
-    for (uint i = 0; i < flattened_checks.size(); i++) {
-      IfNode* iff = flattened_checks.at(i)->as_If();
-      ProjNode* proj= iff->proj_out(0)->as_Proj();
+  for (uint i = 0; i < unswitch_iffs.size(); i++) {
+    IfNode* iff = unswitch_iffs.at(i)->as_If();
+    for (DUIterator_Fast imax, i = iff->fast_outs(imax); i < imax; i++) {
+      ProjNode* proj = iff->fast_out(i)->as_Proj();
       // Copy to a worklist for easier manipulation
       for (DUIterator_Fast jmax, j = proj->fast_outs(jmax); j < jmax; j++) {
         Node* use = proj->fast_out(j);
         if (use->Opcode() == Op_CheckCastPP && loop->is_invariant(use->in(1))) {
           worklist.push(use);
@@ -281,54 +269,34 @@
         Node* use = worklist.pop();
         Node* nuse = use->clone();
         nuse->set_req(0, invar_proj);
         _igvn.replace_input_of(use, 1, nuse);
         register_new_node(nuse, invar_proj);
-        // Same for the clone
-        Node* use_clone = old_new[use->_idx];
-        _igvn.replace_input_of(use_clone, 1, nuse);
-      }
-    }
-  } else {
-    for (DUIterator_Fast imax, i = unswitch_iff->fast_outs(imax); i < imax; i++) {
-      ProjNode* proj= unswitch_iff->fast_out(i)->as_Proj();
-      // Copy to a worklist for easier manipulation
-      for (DUIterator_Fast jmax, j = proj->fast_outs(jmax); j < jmax; j++) {
-        Node* use = proj->fast_out(j);
-        if (use->Opcode() == Op_CheckCastPP && loop->is_invariant(use->in(1))) {
-          worklist.push(use);
+        // Same for the clone if we are removing checks from the slow loop
+        if (unswitch_iffs.size() == 1) {
+          Node* use_clone = old_new[use->_idx];
+          _igvn.replace_input_of(use_clone, 1, nuse);
         }
       }
-      ProjNode* invar_proj = invar_iff->proj_out(proj->_con)->as_Proj();
-      while (worklist.size() > 0) {
-        Node* use = worklist.pop();
-        Node* nuse = use->clone();
-        nuse->set_req(0, invar_proj);
-        _igvn.replace_input_of(use, 1, nuse);
-        register_new_node(nuse, invar_proj);
-        // Same for the clone
-        Node* use_clone = old_new[use->_idx];
-        _igvn.replace_input_of(use_clone, 1, nuse);
-      }
     }
   }
 
+  // Hardwire the control paths in the loops into if(true) and if(false)
+  for (uint i = 0; i < unswitch_iffs.size(); i++) {
+    IfNode* iff = unswitch_iffs.at(i)->as_If();
+    _igvn.rehash_node_delayed(iff);
+    dominated_by(proj_true, iff, false, false);
+  }
   IfNode* unswitch_iff_clone = old_new[unswitch_iff->_idx]->as_If();
-  if (flattened_checks.size() > 0) {
-    for (uint i = 0; i < flattened_checks.size(); i++) {
-      IfNode* iff = flattened_checks.at(i)->as_If();
-      _igvn.rehash_node_delayed(iff);
-      dominated_by(proj_false, old_new[iff->_idx]->as_If(), false, false);
-    }
-  } else {
-    // Hardwire the control paths in the loops into if(true) and if(false)
-    _igvn.rehash_node_delayed(unswitch_iff);
-    dominated_by(proj_true, unswitch_iff, false, false);
-
-    IfNode* unswitch_iff_clone = old_new[unswitch_iff->_idx]->as_If();
+  if (unswitch_iffs.size() == 1) {
+    ProjNode* proj_false = invar_iff->proj_out(0)->as_Proj();
     _igvn.rehash_node_delayed(unswitch_iff_clone);
     dominated_by(proj_false, unswitch_iff_clone, false, false);
+  } else {
+    // Leave the flattened array checks in the slow loop and
+    // prevent it from being unswitched again based on these checks.
+    head_clone->mark_flattened_arrays();
   }
 
   // Reoptimize loops
   loop->record_for_igvn();
   for(int i = loop->_body.size() - 1; i >= 0 ; i--) {
@@ -337,13 +305,15 @@
     _igvn._worklist.push(n_clone);
   }
 
 #ifndef PRODUCT
   if (TraceLoopUnswitching) {
-    tty->print_cr("Loop unswitching orig: %d @ %d  new: %d @ %d",
-                  head->_idx,                unswitch_iff->_idx,
-                  old_new[head->_idx]->_idx, unswitch_iff_clone->_idx);
+    for (uint i = 0; i < unswitch_iffs.size(); i++) {
+      tty->print_cr("Loop unswitching orig: %d @ %d  new: %d @ %d",
+                    head->_idx,                unswitch_iffs.at(i)->_idx,
+                    old_new[head->_idx]->_idx, old_new[unswitch_iffs.at(i)->_idx]->_idx);
+    }
   }
 #endif
 
   C->set_major_progress();
 }
diff a/src/hotspot/share/opto/loopnode.hpp b/src/hotspot/share/opto/loopnode.hpp
--- a/src/hotspot/share/opto/loopnode.hpp
+++ b/src/hotspot/share/opto/loopnode.hpp
@@ -1222,11 +1222,11 @@
   // insert a clone of the test that selects which version to
   // execute.
   void do_unswitching (IdealLoopTree *loop, Node_List &old_new);
 
   // Find candidate "if" for unswitching
-  IfNode* find_unswitching_candidate(const IdealLoopTree *loop, Node_List& flattened_checks) const;
+  IfNode* find_unswitching_candidate(const IdealLoopTree *loop, Node_List& unswitch_iffs) const;
 
   // Range Check Elimination uses this function!
   // Constrain the main loop iterations so the affine function:
   //    low_limit <= scale_con * I + offset  <  upper_limit
   // always holds true.  That is, either increase the number of iterations in
diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -1798,30 +1798,11 @@
   if (!mark_node->is_Con()) {
     transform_later(mark_node);
   }
   rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X->basic_type());
 
-  BasicType bt = T_METADATA;
-  Node* metadata = klass_node;
-  Node* properties = alloc->in(AllocateNode::StorageProperties);
-  if (properties != NULL) {
-    // Encode array storage properties into klass pointer
-    assert(EnableValhalla, "array storage properties not supported");
-    if (UseCompressedClassPointers) {
-      // Compress the klass pointer before inserting the storage properties value
-      metadata = transform_later(new EncodePKlassNode(metadata, metadata->bottom_type()->make_narrowklass()));
-      metadata = transform_later(new CastN2INode(metadata));
-      metadata = transform_later(new OrINode(metadata, transform_later(new ConvL2INode(properties))));
-      bt = T_INT;
-    } else {
-      metadata = transform_later(new CastP2XNode(NULL, metadata));
-      metadata = transform_later(new OrXNode(metadata, properties));
-      bt = T_LONG;
-    }
-  }
-  rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), metadata, bt);
-
+  rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);
   int header_size = alloc->minimum_header_size();  // conservatively small
 
   // Array length
   if (length != NULL) {         // Arrays need length field
     rawmem = make_store(control, rawmem, object, arrayOopDesc::length_offset_in_bytes(), length, T_INT);
diff a/src/hotspot/share/opto/macroArrayCopy.cpp b/src/hotspot/share/opto/macroArrayCopy.cpp
--- a/src/hotspot/share/opto/macroArrayCopy.cpp
+++ b/src/hotspot/share/opto/macroArrayCopy.cpp
@@ -1274,21 +1274,21 @@
     src_elem = T_OBJECT;
   } else if (src_elem == T_VALUETYPE && top_src->klass()->is_obj_array_klass()) {
     if (top_src->klass_is_exact()) {
       src_elem = T_OBJECT;
     } else {
-      assert(!top_src->klass()->as_obj_array_klass()->storage_properties().is_null_free(), "klass should be exact");
+      assert(!top_src->klass()->is_valuetype(), "klass should be exact");
       src_elem = T_CONFLICT; // either flattened or not
     }
   }
   if (dest_elem == T_ARRAY) {
     dest_elem = T_OBJECT;
   } else if (dest_elem == T_VALUETYPE && top_dest->klass()->is_obj_array_klass()) {
     if (top_dest->klass_is_exact()) {
       dest_elem = T_OBJECT;
     } else {
-      assert(!top_dest->klass()->as_obj_array_klass()->storage_properties().is_null_free(), "klass should be exact");
+      assert(!top_dest->klass()->is_valuetype(), "klass should be exact");
       dest_elem = T_CONFLICT; // either flattened or not
     }
   }
 
   if (ac->is_arraycopy_validated() &&
diff a/src/hotspot/share/opto/memnode.cpp b/src/hotspot/share/opto/memnode.cpp
--- a/src/hotspot/share/opto/memnode.cpp
+++ b/src/hotspot/share/opto/memnode.cpp
@@ -1884,26 +1884,10 @@
     // For oop loads, we expect the _type to be precise.
 
     const TypeInstPtr* tinst = tp->is_instptr();
     BasicType bt = memory_type();
 
-    // Fold component and value mirror loads
-    ciInstanceKlass* ik = tinst->klass()->as_instance_klass();
-    if (ik == phase->C->env()->Class_klass() && (off == java_lang_Class::component_mirror_offset_in_bytes() ||
-                                                 off == java_lang_Class::inline_mirror_offset_in_bytes())) {
-      ciType* mirror_type = tinst->java_mirror_type();
-      if (mirror_type != NULL) {
-        const Type* const_oop = TypePtr::NULL_PTR;
-        if (mirror_type->is_array_klass()) {
-          const_oop = TypeInstPtr::make(mirror_type->as_array_klass()->component_mirror_instance());
-        } else if (mirror_type->is_valuetype()) {
-          const_oop = TypeInstPtr::make(mirror_type->as_value_klass()->inline_mirror_instance());
-        }
-        return (bt == T_NARROWOOP) ? const_oop->make_narrowoop() : const_oop;
-      }
-    }
-
     // Optimize loads from constant fields.
     ciObject* const_oop = tinst->const_oop();
     if (!is_mismatched_access() && off != Type::OffsetBot && const_oop != NULL && const_oop->is_instance()) {
       ciType* mirror_type = const_oop->as_instance()->java_mirror_type();
       if (mirror_type != NULL && mirror_type->is_valuetype()) {
@@ -2245,22 +2229,21 @@
     if (ik == phase->C->env()->Class_klass()
         && (offset == java_lang_Class::klass_offset_in_bytes() ||
             offset == java_lang_Class::array_klass_offset_in_bytes())) {
       // We are loading a special hidden field from a Class mirror object,
       // the field which points to the VM's Klass metaobject.
-      bool is_indirect_type = true;
-      ciType* t = tinst->java_mirror_type(&is_indirect_type);
+      ciType* t = tinst->java_mirror_type();
       // java_mirror_type returns non-null for compile-time Class constants.
       if (t != NULL) {
         // constant oop => constant klass
         if (offset == java_lang_Class::array_klass_offset_in_bytes()) {
           if (t->is_void()) {
             // We cannot create a void array.  Since void is a primitive type return null
             // klass.  Users of this result need to do a null check on the returned klass.
             return TypePtr::NULL_PTR;
           }
-          return TypeKlassPtr::make(ciArrayKlass::make(t, /* never_null */ !is_indirect_type));
+          return TypeKlassPtr::make(ciArrayKlass::make(t));
         }
         if (!t->is_klass()) {
           // a primitive Class (e.g., int.class) has NULL for a klass field
           return TypePtr::NULL_PTR;
         }
@@ -2297,26 +2280,23 @@
   const TypeAryPtr *tary = tp->isa_aryptr();
   if (tary != NULL) {
     ciKlass *tary_klass = tary->klass();
     if (tary_klass != NULL   // can be NULL when at BOTTOM or TOP
         && tary->offset() == oopDesc::klass_offset_in_bytes()) {
-      ciArrayKlass* ak = tary_klass->as_array_klass();
-      // Do not fold klass loads from [V?. The runtime type might be [V due to [V <: [V?
-      // and the klass for [V is not equal to the klass for [V?.
       if (tary->klass_is_exact()) {
         return TypeKlassPtr::make(tary_klass);
       }
-
+      ciArrayKlass* ak = tary_klass->as_array_klass();
       // If the klass is an object array, we defer the question to the
       // array component klass.
       if (ak->is_obj_array_klass()) {
         assert(ak->is_loaded(), "");
         ciKlass *base_k = ak->as_obj_array_klass()->base_element_klass();
         if (base_k->is_loaded() && base_k->is_instance_klass()) {
           ciInstanceKlass *ik = base_k->as_instance_klass();
           // See if we can become precise: no subklasses and no interface
-          if (!ik->is_interface() && !ik->has_subklass() && (!ik->is_valuetype() || ak->storage_properties().is_null_free())) {
+          if (!ik->is_interface() && !ik->has_subklass()) {
             //assert(!UseExactTypes, "this code should be useless with exact types");
             // Add a dependence; if any subclass added we need to recompile
             if (!ik->is_final()) {
               phase->C->dependencies()->assert_leaf_type(ik);
             }
@@ -2350,11 +2330,11 @@
       // according to the element type's subclassing.
       return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), elem->flatten_array());
     } else if (klass->is_value_array_klass() &&
                tkls->offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {
       ciKlass* elem = klass->as_value_array_klass()->element_klass();
-      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), true);
+      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), /* flat_array= */ true);
     }
     if( klass->is_instance_klass() && tkls->klass_is_exact() &&
         tkls->offset() == in_bytes(Klass::super_offset())) {
       ciKlass* sup = klass->as_instance_klass()->super();
       // The field is Klass::_super.  Return its (constant) value.
@@ -2372,56 +2352,10 @@
 // Also feed through the klass in Allocate(...klass...)._klass.
 Node* LoadKlassNode::Identity(PhaseGVN* phase) {
   return klass_identity_common(phase);
 }
 
-const Type* GetStoragePropertyNode::Value(PhaseGVN* phase) const {
-  if (in(1) != NULL) {
-    const Type* in1_t = phase->type(in(1));
-    if (in1_t == Type::TOP) {
-      return Type::TOP;
-    }
-    const TypeKlassPtr* tk = in1_t->make_ptr()->is_klassptr();
-    ciArrayKlass* ak = tk->klass()->as_array_klass();
-    ciKlass* elem = ak->element_klass();
-    if (tk->klass_is_exact() || !elem->can_be_value_klass()) {
-      int props_shift = in1_t->isa_narrowklass() ? oopDesc::narrow_storage_props_shift : oopDesc::wide_storage_props_shift;
-      ArrayStorageProperties props = ak->storage_properties();
-      intptr_t storage_properties = 0;
-      if ((Opcode() == Op_GetFlattenedProperty && props.is_flattened()) ||
-          (Opcode() == Op_GetNullFreeProperty && props.is_null_free())) {
-        storage_properties = 1;
-      }
-      if (in1_t->isa_narrowklass()) {
-        return TypeInt::make((int)storage_properties);
-      }
-      return TypeX::make(storage_properties);
-    }
-  }
-  return bottom_type();
-}
-
-Node* GetStoragePropertyNode::Ideal(PhaseGVN *phase, bool can_reshape) {
-  if (!can_reshape) {
-    return NULL;
-  }
-  if (in(1) != NULL && in(1)->is_Phi()) {
-    Node* phi = in(1);
-    Node* r = phi->in(0);
-    Node* new_phi = new PhiNode(r, bottom_type());
-    for (uint i = 1; i < r->req(); i++) {
-      Node* in = phi->in(i);
-      if (in == NULL) continue;
-      Node* n = clone();
-      n->set_req(1, in);
-      new_phi->init_req(i, phase->transform(n));
-    }
-    return new_phi;
-  }
-  return NULL;
-}
-
 Node* LoadNode::klass_identity_common(PhaseGVN* phase) {
   Node* x = LoadNode::Identity(phase);
   if (x != this)  return x;
 
   // Take apart the address into an oop and and offset.
diff a/src/hotspot/share/opto/memnode.hpp b/src/hotspot/share/opto/memnode.hpp
--- a/src/hotspot/share/opto/memnode.hpp
+++ b/src/hotspot/share/opto/memnode.hpp
@@ -562,51 +562,10 @@
   virtual Node* Identity(PhaseGVN* phase);
   virtual bool depends_only_on_test() const { return true; }
   bool clear_prop_bits() const { return _clear_prop_bits; }
 };
 
-// Retrieve the null free/flattened property from an array klass. This
-// is treated a bit like a field that would be read from the klass
-// structure at runtime except, the implementation encodes the
-// property as a bit in the klass header field of the array. This
-// implementation detail is hidden under this node so it doesn't make
-// a difference for high level optimizations. At final graph reshaping
-// time, this node is turned into the actual logical operations that
-// extract the property from the klass pointer. For this to work
-// correctly, GeStoragePropertyNodes must take a LoadKlass/LoadNKlass
-// input. The Ideal transformation splits the GetStoragePropertyNode
-// through phis, Value returns a constant if the node's input is a
-// constant. These 2 should guarantee GetStoragePropertyNode does
-// indeed have a LoadKlass/LoadNKlass input at final graph reshaping
-// time.
-class GetStoragePropertyNode : public Node {
-protected:
-  GetStoragePropertyNode(Node* klass) : Node(NULL, klass) {}
-public:
-  virtual const Type* Value(PhaseGVN* phase) const;
-  virtual Node* Ideal(PhaseGVN *phase, bool can_reshape);
-  virtual const Type* bottom_type() const {
-    if (in(1)->bottom_type()->isa_klassptr()) {
-      return TypeLong::LONG;
-    }
-    return TypeInt::INT;
-  }
-};
-
-
-class GetNullFreePropertyNode : public GetStoragePropertyNode {
-public:
-  GetNullFreePropertyNode(Node* klass) : GetStoragePropertyNode(klass) {}
-  virtual int Opcode() const;
-};
-
-class GetFlattenedPropertyNode : public GetStoragePropertyNode {
-public:
-  GetFlattenedPropertyNode(Node* klass) : GetStoragePropertyNode(klass) {}
-  virtual int Opcode() const;
-};
-
 //------------------------------StoreNode--------------------------------------
 // Store value; requires Store, Address and Value
 class StoreNode : public MemNode {
 private:
   // On platforms with weak memory ordering (e.g., PPC, Ia64) we distinguish
diff a/src/hotspot/share/opto/parse2.cpp b/src/hotspot/share/opto/parse2.cpp
--- a/src/hotspot/share/opto/parse2.cpp
+++ b/src/hotspot/share/opto/parse2.cpp
@@ -96,19 +96,27 @@
            (!elemptr->is_valuetypeptr() || elemptr->value_klass()->flatten_array()), "array can't be flattened");
     Node* ctl = control();
     IdealKit ideal(this);
     IdealVariable res(ideal);
     ideal.declarations_done();
-    Node* flattened = gen_flattened_array_test(ary);
-    ideal.if_then(flattened, BoolTest::ne, zerocon(flattened->bottom_type()->basic_type())); {
+    ideal.if_then(is_non_flattened_array(ary)); {
+      // non-flattened
+      assert(ideal.ctrl()->in(0)->as_If()->is_non_flattened_array_check(&_gvn), "Should be found");
+      sync_kit(ideal);
+      const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
+      Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
+                                IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD, ctl);
+      ideal.sync_kit(this);
+      ideal.set(res, ld);
+    } ideal.else_(); {
       // flattened
       sync_kit(ideal);
       if (elemptr->is_valuetypeptr()) {
         // Element type is known, cast and load from flattened representation
         ciValueKlass* vk = elemptr->value_klass();
         assert(vk->flatten_array() && elemptr->maybe_null(), "must be a flattenable and nullable array");
-        ciArrayKlass* array_klass = ciArrayKlass::make(vk, /* never_null */ true);
+        ciArrayKlass* array_klass = ciArrayKlass::make(vk);
         const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)->isa_aryptr();
         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));
         Node* casted_adr = array_element_address(cast, idx, T_VALUETYPE, ary_t->size(), control());
         // Re-execute flattened array load if buffering triggers deoptimization
         PreserveReexecuteState preexecs(this);
@@ -116,12 +124,12 @@
         inc_sp(2);
         Node* vt = ValueTypeNode::make_from_flattened(this, vk, cast, casted_adr)->allocate(this, false)->get_oop();
         ideal.set(res, vt);
         ideal.sync_kit(this);
       } else {
-        Node* kls = load_object_klass(ary);
         // Element type is unknown, emit runtime call
+        Node* kls = load_object_klass(ary);
         Node* k_adr = basic_plus_adr(kls, in_bytes(ArrayKlass::element_klass_offset()));
         Node* elem_klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));
         Node* obj_size  = NULL;
         kill_dead_locals();
         // Re-execute flattened array load if buffering triggers deoptimization
@@ -187,18 +195,10 @@
         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));
 
         ideal.sync_kit(this);
         ideal.set(res, alloc_obj);
       }
-    } ideal.else_(); {
-      // non-flattened
-      sync_kit(ideal);
-      const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
-      Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
-                                IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD, ctl);
-      ideal.sync_kit(this);
-      ideal.set(res, ld);
     } ideal.end_if();
     sync_kit(ideal);
     Node* ld = _gvn.transform(ideal.value(res));
     ld = record_profile_for_speculation_at_array_load(ld);
     push_node(bt, ld);
@@ -300,12 +300,20 @@
     } else if (!ary_t->is_not_flat()) {
       // Array might be flattened, emit runtime checks
       assert(ValueArrayFlatten && !not_flattenable && elemtype->is_oopptr()->can_be_value_type() &&
              !ary_t->klass_is_exact() && !ary_t->is_not_null_free(), "array can't be flattened");
       IdealKit ideal(this);
-      Node* flattened = gen_flattened_array_test(ary);
-      ideal.if_then(flattened, BoolTest::ne, zerocon(flattened->bottom_type()->basic_type())); {
+      ideal.if_then(is_non_flattened_array(ary)); {
+        // non-flattened
+        assert(ideal.ctrl()->in(0)->as_If()->is_non_flattened_array_check(&_gvn), "Should be found");
+        sync_kit(ideal);
+        gen_value_array_null_guard(ary, cast_val, 3);
+        inc_sp(3);
+        access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);
+        dec_sp(3);
+        ideal.sync_kit(this);
+      } ideal.else_(); {
         Node* val = cast_val;
         // flattened
         if (!val->is_ValueType() && tval->maybe_null()) {
           // Add null check
           sync_kit(ideal);
@@ -332,11 +340,11 @@
         Node* casted_ary = ary;
         if (vk != NULL && !stopped()) {
           // Element type is known, cast and store to flattened representation
           sync_kit(ideal);
           assert(vk->flatten_array() && elemtype->maybe_null(), "must be a flattenable and nullable array");
-          ciArrayKlass* array_klass = ciArrayKlass::make(vk, /* never_null */ true);
+          ciArrayKlass* array_klass = ciArrayKlass::make(vk);
           const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)->isa_aryptr();
           casted_ary = _gvn.transform(new CheckCastPPNode(control(), casted_ary, arytype));
           Node* casted_adr = array_element_address(casted_ary, idx, T_OBJECT, arytype->size(), control());
           if (!val->is_ValueType()) {
             assert(!gvn().type(val)->maybe_null(), "value type array elements should never be null");
@@ -369,20 +377,10 @@
           // flattened array accesses.
           insert_mem_bar_volatile(Op_MemBarCPUOrder, C->get_alias_index(TypeAryPtr::VALUES));
           ideal.sync_kit(this);
         }
       }
-      ideal.else_();
-      {
-        // non-flattened
-        sync_kit(ideal);
-        gen_value_array_null_guard(ary, cast_val, 3);
-        inc_sp(3);
-        access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);
-        dec_sp(3);
-        ideal.sync_kit(this);
-      }
       ideal.end_if();
       sync_kit(ideal);
       return;
     } else if (!ary_t->is_not_null_free()) {
       // Array is not flattened but may be null free
@@ -570,19 +568,18 @@
       bool flat_array = true;
       method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);
       reason = Deoptimization::Reason_class_check;
     }
     if (!null_free_array) {
-      Node* tst = gen_null_free_array_check(ary);
-      {
-        BuildCutout unless(this, tst, PROB_MAX);
+      { // Deoptimize if null-free array
+        BuildCutout unless(this, is_nullable_array(ary), PROB_MAX);
         uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);
       }
       Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_null_free()));
       replace_in_map(ary, better_ary);
       ary = better_ary;
-      arytype  = _gvn.type(ary)->is_aryptr();
+      arytype = _gvn.type(ary)->is_aryptr();
     }
   }
 
   if (!arytype->is_not_flat() && elemtype->isa_valuetype() == NULL) {
     assert(is_reference_type(type), "");
@@ -600,27 +597,18 @@
       bool null_free_array = true;
       method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);
       reason = Deoptimization::Reason_class_check;
     }
     if (!flat_array) {
-      Node* flattened = gen_flattened_array_test(ary);
-      Node* chk = NULL;
-      if (_gvn.type(flattened)->isa_int()) {
-        chk = _gvn.transform(new CmpINode(flattened, intcon(0)));
-      } else {
-        assert(_gvn.type(flattened)->isa_long(), "flattened property is int or long");
-        chk = _gvn.transform(new CmpLNode(flattened, longcon(0)));
-      }
-      Node* tst = _gvn.transform(new BoolNode(chk, BoolTest::eq));
-      {
-        BuildCutout unless(this, tst, PROB_MAX);
+      { // Deoptimize if flat array
+        BuildCutout unless(this, is_non_flattened_array(ary), PROB_MAX);
         uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);
       }
       Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_flat()));
       replace_in_map(ary, better_ary);
       ary = better_ary;
-      arytype  = _gvn.type(ary)->is_aryptr();
+      arytype = _gvn.type(ary)->is_aryptr();
     }
   }
 
   // Make array address computation control dependent to prevent it
   // from floating above the range check during loop optimizations.
@@ -2145,11 +2133,11 @@
     }
     return;
   }
 
   // First operand is non-null, check if it is a value type
-  Node* is_value = is_always_locked(not_null_a);
+  Node* is_value = is_value_type(not_null_a);
   IfNode* is_value_iff = create_and_map_if(control(), is_value, PROB_FAIR, COUNT_UNKNOWN);
   Node* not_value = _gvn.transform(new IfFalseNode(is_value_iff));
   ne_region->init_req(2, not_value);
   set_control(_gvn.transform(new IfTrueNode(is_value_iff)));
 
diff a/src/hotspot/share/opto/parse3.cpp b/src/hotspot/share/opto/parse3.cpp
--- a/src/hotspot/share/opto/parse3.cpp
+++ b/src/hotspot/share/opto/parse3.cpp
@@ -316,18 +316,17 @@
 //=============================================================================
 
 void Parse::do_newarray() {
   bool will_link;
   ciKlass* klass = iter().get_klass(will_link);
-  bool never_null = iter().is_klass_never_null();
 
   // Uncommon Trap when class that array contains is not loaded
   // we need the loaded class for the rest of graph; do not
   // initialize the container class (see Java spec)!!!
   assert(will_link, "newarray: typeflow responsibility");
 
-  ciArrayKlass* array_klass = ciArrayKlass::make(klass, never_null);
+  ciArrayKlass* array_klass = ciArrayKlass::make(klass);
 
   // Check that array_klass object is loaded
   if (!array_klass->is_loaded()) {
     // Generate uncommon_trap for unloaded array_class
     uncommon_trap(Deoptimization::Reason_unloaded,
diff a/src/hotspot/share/opto/subnode.cpp b/src/hotspot/share/opto/subnode.cpp
--- a/src/hotspot/share/opto/subnode.cpp
+++ b/src/hotspot/share/opto/subnode.cpp
@@ -1083,20 +1083,10 @@
 
   // Verify that we understand the situation
   if (con2 != (intptr_t) superklass->super_check_offset())
     return NULL;                // Might be element-klass loading from array klass
 
-  // Do not fold the subtype check to an array klass pointer comparison for [V? arrays.
-  // [V is a subtype of [V? but the klass for [V is not equal to the klass for [V?. Perform a full test.
-  if (superklass->is_obj_array_klass()) {
-    ciObjArrayKlass* ak = superklass->as_obj_array_klass();
-    if (!ak->storage_properties().is_null_free() && ak->element_klass()->is_valuetype()) {
-      // Do not bypass the klass load from the primary supertype array
-      return NULL;
-    }
-  }
-
   // If 'superklass' has no subklasses and is not an interface, then we are
   // assured that the only input which will pass the type check is
   // 'superklass' itself.
   //
   // We could be more liberal here, and allow the optimization on interfaces
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -2390,20 +2390,12 @@
   const TypeInstPtr* tinst;
   if (_elem->isa_narrowoop())
     tinst = _elem->make_ptr()->isa_instptr();
   else
     tinst = _elem->isa_instptr();
-  if (tinst) {
-    // [V? has a subtype: [V. So even though V is final, [V? is not exact.
-    if (tklass->as_instance_klass()->is_final()) {
-      if (tinst->is_valuetypeptr() && (tinst->ptr() == TypePtr::BotPTR || tinst->ptr() == TypePtr::TopPTR)) {
-        return false;
-      }
-      return true;
-    }
-    return false;
-  }
+  if (tinst)
+    return tklass->as_instance_klass()->is_final();
   const TypeAryPtr*  tap;
   if (_elem->isa_narrowoop())
     tap = _elem->make_ptr()->isa_aryptr();
   else
     tap = _elem->isa_aryptr();
@@ -3481,24 +3473,23 @@
     }
     return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, Offset(0), klass->flatten_array());
   } else if (klass->is_obj_array_klass()) {
     // Element is an object or value array. Recursively call ourself.
     const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ false, try_for_exact);
-    bool null_free = klass->is_loaded() && klass->as_array_klass()->storage_properties().is_null_free();
-    if (null_free) {
-      assert(etype->is_valuetypeptr(), "must be a valuetypeptr");
+    if (etype->is_valuetypeptr()) {
       etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();
     }
-    // [V? has a subtype: [V. So even though V is final, [V? is not exact.
-    bool xk = etype->klass_is_exact() && (!etype->is_valuetypeptr() || null_free);
-
-    // Use exact element type to determine null-free/flattened properties
-    const TypeOopPtr* exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ true, try_for_exact);
+    // Determine null-free/flattened properties
+    const TypeOopPtr* exact_etype = etype;
+    if (etype->can_be_value_type()) {
+      // Use exact type if element can be a value type
+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ true, /* try_for_exact= */ true);
+    }
     bool not_null_free = !exact_etype->can_be_value_type();
-    assert(!(not_null_free && null_free), "inconsistent null-free information");
     bool not_flat = !ValueArrayFlatten || not_null_free || (exact_etype->is_valuetypeptr() && !exact_etype->value_klass()->flatten_array());
 
+    bool xk = etype->klass_is_exact();
     const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);
     // We used to pass NotNull in here, asserting that the sub-arrays
     // are all not-null.  This is not true in generally, as code can
     // slam NULLs down in the subarrays.
     const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, Offset(0));
@@ -3539,13 +3530,13 @@
       return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, Offset(0), klass->flatten_array());
     }
   } else if (klass->is_obj_array_klass()) {
     // Element is an object array. Recursively call ourself.
     const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass());
-    bool null_free = klass->is_loaded() && klass->as_array_klass()->storage_properties().is_null_free();
-    if (null_free) {
-      assert(etype->is_valuetypeptr(), "must be a valuetypeptr");
+    bool null_free = false;
+    if (etype->is_valuetypeptr()) {
+      null_free = true;
       etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();
     }
     const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),
                                         /* stable= */ false, /* not_flat= */ true, /* not_null_free= */ !null_free);
     // We used to pass NotNull in here, asserting that the sub-arrays
@@ -3979,11 +3970,11 @@
     case TopPTR:
     case AnyNull:                // Fall 'down' to dual of object klass
       // For instances when a subclass meets a superclass we fall
       // below the centerline when the superclass is exact. We need to
       // do the same here.
-      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {
+      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flat_array()) {
         return TypeAryPtr::make(ptr, tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);
       } else {
         // cannot subclass, so the meet has to fall badly below the centerline
         ptr = NotNull;
         instance_id = InstanceBot;
@@ -3997,11 +3988,11 @@
         // If 'this' (InstPtr) is above the centerline and it is Object class
         // then we can subclass in the Java class hierarchy.
         // For instances when a subclass meets a superclass we fall
         // below the centerline when the superclass is exact. We need
         // to do the same here.
-        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {
+        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flat_array()) {
           // that is, tp's array type is a subtype of my klass
           return TypeAryPtr::make(ptr, (ptr == Constant ? tp->const_oop() : NULL),
                                   tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);
         }
       }
@@ -4292,18 +4283,17 @@
   return this;                  // Return the double constant
 }
 
 
 //------------------------java_mirror_type--------------------------------------
-ciType* TypeInstPtr::java_mirror_type(bool* is_indirect_type) const {
+ciType* TypeInstPtr::java_mirror_type() const {
   // must be a singleton type
   if( const_oop() == NULL )  return NULL;
 
   // must be of type java.lang.Class
   if( klass() != ciEnv::current()->Class_klass() )  return NULL;
-
-  return const_oop()->as_instance()->java_mirror_type(is_indirect_type);
+  return const_oop()->as_instance()->java_mirror_type();
 }
 
 
 //------------------------------xdual------------------------------------------
 // Dual: do NOT dual on klasses.  This means I do NOT understand the Java
@@ -4720,13 +4710,12 @@
            (this->_klass_is_exact && !klass()->is_subtype_of(tap->klass())))) {
       if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr))) {
         tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);
       }
       return make(NotNull, NULL, tary, lazy_klass, false, off, field_off, InstanceBot, speculative, depth);
-    } else if (klass() != NULL && tap->klass() != NULL &&
-               klass()->as_array_klass()->storage_properties().value() != tap->klass()->as_array_klass()->storage_properties().value()) {
-      // Meeting value type arrays with conflicting storage properties
+    } else if (klass() != NULL && tap->klass() != NULL && klass()->is_value_array_klass() != tap->klass()->is_value_array_klass()) {
+      // Meeting flattened value type array with non-flattened array. Adjust (field) offset accordingly.
       if (tary->_elem->isa_valuetype()) {
         // Result is flattened
         off = Offset(elem()->isa_valuetype() ? offset() : tap->offset());
         field_off = elem()->isa_valuetype() ? field_offset() : tap->field_offset();
       } else if (tary->_elem->make_oopptr() != NULL && tary->_elem->make_oopptr()->isa_instptr() && below_centerline(ptr)) {
@@ -4791,11 +4780,11 @@
     case TopPTR:
     case AnyNull:                // Fall 'down' to dual of object klass
       // For instances when a subclass meets a superclass we fall
       // below the centerline when the superclass is exact. We need to
       // do the same here.
-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {
+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flat_array()) {
         return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
       } else {
         // cannot subclass, so the meet has to fall badly below the centerline
         ptr = NotNull;
         instance_id = InstanceBot;
@@ -4809,11 +4798,11 @@
         // If 'tp'  is above the centerline and it is Object class
         // then we can subclass in the Java class hierarchy.
         // For instances when a subclass meets a superclass we fall
         // below the centerline when the superclass is exact. We need
         // to do the same here.
-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {
+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flat_array()) {
           // that is, my array type is a subtype of 'tp' klass
           return make(ptr, (ptr == Constant ? const_oop() : NULL),
                       _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
         }
       }
@@ -5437,15 +5426,15 @@
   }
 
   // Get element klass
   if (el->isa_instptr()) {
     // Compute object array klass from element klass
-    bool null_free = el->is_valuetypeptr() && el->isa_instptr()->ptr() != TypePtr::TopPTR && !el->isa_instptr()->maybe_null();
-    k_ary = ciArrayKlass::make(el->is_oopptr()->klass(), null_free);
+    k_ary = ciArrayKlass::make(el->is_oopptr()->klass());
   } else if (el->isa_valuetype()) {
+    // If element type is TypeValueType::BOTTOM, value_klass() will be null.
     if (el->value_klass() != NULL) {
-      k_ary = ciArrayKlass::make(el->value_klass(), /* null_free */ true);
+      k_ary = ciArrayKlass::make(el->value_klass());
     }
   } else if ((tary = el->isa_aryptr()) != NULL) {
     // Compute array klass from element klass
     ciKlass* k_elem = tary->klass();
     // If element type is something like bottom[], k_elem will be null.
diff a/src/hotspot/share/opto/type.hpp b/src/hotspot/share/opto/type.hpp
--- a/src/hotspot/share/opto/type.hpp
+++ b/src/hotspot/share/opto/type.hpp
@@ -1148,14 +1148,10 @@
   virtual int  hash() const;             // Type specific hashing
 
   ciSymbol*  _name;        // class name
   bool _flat_array;
 
-  bool meet_flat_array(bool other_flat_array) const {
-    return (_flat_array && other_flat_array) ? true : false;
-  }
-
  public:
   ciSymbol* name()         const { return _name; }
 
   bool  is_loaded() const { return _klass->is_loaded(); }
 
@@ -1194,11 +1190,11 @@
   const Type* get_const_boxed_value() const;
 
   // If this is a java.lang.Class constant, return the type for it or NULL.
   // Pass to Type::get_const_type to turn it to a type, which will usually
   // be a TypeInstPtr, but may also be a TypeInt::INT for int.class, etc.
-  ciType* java_mirror_type(bool* is_indirect_type = NULL) const;
+  ciType* java_mirror_type() const;
 
   virtual const Type *cast_to_ptr_type(PTR ptr) const;
 
   virtual const Type *cast_to_exactness(bool klass_is_exact) const;
 
diff a/src/java.base/share/classes/java/lang/Class.java b/src/java.base/share/classes/java/lang/Class.java
--- a/src/java.base/share/classes/java/lang/Class.java
+++ b/src/java.base/share/classes/java/lang/Class.java
@@ -534,11 +534,10 @@
      * that primitive type is its primary type, for example {@code int.class}.
      *
      * @return the {@code Class} object representing the primary type of
      *         this class
      */
-    @HotSpotIntrinsicCandidate
     public Class<T> asPrimaryType() {
         return isInlineClass() ? inlineType : this;
     }
 
     /**
@@ -554,11 +553,10 @@
      * is also its nullable projection type.
      *
      * @return the {@code Class} object representing the indirect projection type of
      *         this class if this class is an inline class; otherwise, this class.
      */
-    @HotSpotIntrinsicCandidate
     public Class<T> asIndirectType() {
         return isInlineClass() ? indirectType : this;
     }
 
     /**
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
@@ -1866,11 +1866,11 @@
         private final Object o4 = null;
         private final Object o5 = null;
         private final Object o6 = null;
     }
 
-    // Same as test80 but with not-flattenable inline type
+    // Same as test79 but with not-flattenable inline type
     @Test(valid = ValueTypeArrayFlattenOn, match = { ALLOC_G, LOAD_UNKNOWN_VALUE }, matchCount = { 1, 1 })
     @Test(valid = ValueTypeArrayFlattenOff, failOn = ALLOC_G + ALLOCA_G + LOAD_UNKNOWN_VALUE)
     public Object test80(Object[] array, int i) {
         NotFlattenable vt = (NotFlattenable)array[0];
         Object o = array[1];
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestIntrinsics.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestIntrinsics.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestIntrinsics.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestIntrinsics.java
@@ -66,33 +66,33 @@
         return supercls.isAssignableFrom(subcls);
     }
 
     public void test1_verifier(boolean warmup) {
         Asserts.assertTrue(test1(java.util.AbstractList.class, java.util.ArrayList.class), "test1_1 failed");
-        Asserts.assertTrue(test1(MyValue1.class.asIndirectType(), MyValue1.class.asIndirectType()), "test1_2 failed");
+        Asserts.assertTrue(test1(MyValue1.ref.class, MyValue1.ref.class), "test1_2 failed");
         Asserts.assertTrue(test1(MyValue1.class, MyValue1.class), "test1_3 failed");
-        Asserts.assertTrue(test1(MyValue1.class.asIndirectType(), MyValue1.class), "test1_4 failed");
-        Asserts.assertFalse(test1(MyValue1.class, MyValue1.class.asIndirectType()), "test1_5 failed");
+        Asserts.assertTrue(test1(MyValue1.ref.class, MyValue1.class), "test1_4 failed");
+        Asserts.assertFalse(test1(MyValue1.class, MyValue1.ref.class), "test1_5 failed");
         Asserts.assertTrue(test1(Object.class, java.util.ArrayList.class), "test1_6 failed");
-        Asserts.assertTrue(test1(Object.class, MyValue1.class.asIndirectType()), "test1_7 failed");
+        Asserts.assertTrue(test1(Object.class, MyValue1.ref.class), "test1_7 failed");
         Asserts.assertTrue(test1(Object.class, MyValue1.class), "test1_8 failed");
-        Asserts.assertTrue(!test1(MyValue1.class.asIndirectType(), Object.class), "test1_9 failed");
+        Asserts.assertTrue(!test1(MyValue1.ref.class, Object.class), "test1_9 failed");
         Asserts.assertTrue(!test1(MyValue1.class, Object.class), "test1_10 failed");
     }
 
     // Verify that Class::isAssignableFrom checks with statically known classes are folded
     @Test(failOn = LOADK)
     public boolean test2() {
         boolean check1 = java.util.AbstractList.class.isAssignableFrom(java.util.ArrayList.class);
-        boolean check2 = MyValue1.class.asIndirectType().isAssignableFrom(MyValue1.class.asIndirectType());
+        boolean check2 = MyValue1.ref.class.isAssignableFrom(MyValue1.ref.class);
         boolean check3 = MyValue1.class.isAssignableFrom(MyValue1.class);
-        boolean check4 = MyValue1.class.asIndirectType().isAssignableFrom(MyValue1.class);
-        boolean check5 = !MyValue1.class.isAssignableFrom(MyValue1.class.asIndirectType());
+        boolean check4 = MyValue1.ref.class.isAssignableFrom(MyValue1.class);
+        boolean check5 = !MyValue1.class.isAssignableFrom(MyValue1.ref.class);
         boolean check6 = Object.class.isAssignableFrom(java.util.ArrayList.class);
-        boolean check7 = Object.class.isAssignableFrom(MyValue1.class.asIndirectType());
+        boolean check7 = Object.class.isAssignableFrom(MyValue1.ref.class);
         boolean check8 = Object.class.isAssignableFrom(MyValue1.class);
-        boolean check9 = !MyValue1.class.asIndirectType().isAssignableFrom(Object.class);
+        boolean check9 = !MyValue1.ref.class.isAssignableFrom(Object.class);
         boolean check10 = !MyValue1.class.isAssignableFrom(Object.class);
         return check1 && check2 && check3 && check4 && check5 && check6 && check7 && check8 && check9 && check10;
     }
 
     public void test2_verifier(boolean warmup) {
@@ -105,23 +105,23 @@
         return cls.getSuperclass();
     }
 
     public void test3_verifier(boolean warmup) {
         Asserts.assertTrue(test3(Object.class) == null, "test3_1 failed");
-        Asserts.assertTrue(test3(MyValue1.class.asIndirectType()) == MyValue1.ref.class, "test3_2 failed");
-        Asserts.assertTrue(test3(MyValue1.class.asPrimaryType()) == MyValue1.ref.class, "test3_3 failed");
+        Asserts.assertTrue(test3(MyValue1.ref.class) == MyAbstract.class, "test3_2 failed");
+        Asserts.assertTrue(test3(MyValue1.val.class) == MyValue1.ref.class, "test3_3 failed");
         Asserts.assertTrue(test3(Class.class) == Object.class, "test3_4 failed");
     }
 
     // Verify that Class::getSuperclass checks with statically known classes are folded
     @Test(failOn = LOADK)
     public boolean test4() {
         boolean check1 = Object.class.getSuperclass() == null;
         // TODO Remove cast as workaround once javac is fixed
-        boolean check2 = (Class<?>)MyValue1.class.asIndirectType().getSuperclass() == MyValue1.ref.class;
+        boolean check2 = (Class<?>)MyValue1.ref.class.getSuperclass() == MyAbstract.class;
         // TODO Remove cast as workaround once javac is fixed
-        boolean check3 = (Class<?>)MyValue1.class.asPrimaryType().getSuperclass() == MyValue1.ref.class;
+        boolean check3 = (Class<?>)MyValue1.val.class.getSuperclass() == MyValue1.ref.class;
         boolean check4 = Class.class.getSuperclass() == Object.class;
         return check1 && check2 && check3 && check4;
     }
 
     public void test4_verifier(boolean warmup) {
@@ -179,11 +179,11 @@
     @DontCompile
     public void test8_verifier(boolean warmup) {
         MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);
         boolean result = test8(MyValue1.class, vt);
         Asserts.assertTrue(result);
-        result = test8(MyValue1.class.asIndirectType(), vt);
+        result = test8(MyValue1.ref.class, vt);
         Asserts.assertTrue(result);
     }
 
     @Test()
     public boolean test9(Class c, MyValue1 vt) {
@@ -193,11 +193,11 @@
     @DontCompile
     public void test9_verifier(boolean warmup) {
         MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);
         boolean result = test9(MyValue2.class, vt);
         Asserts.assertFalse(result);
-        result = test9(MyValue2.class.asIndirectType(), vt);
+        result = test9(MyValue2.ref.class, vt);
         Asserts.assertFalse(result);
     }
 
     // Class.cast
     @Test()
@@ -255,11 +255,11 @@
     }
 
     // value type array creation via reflection
     @Test()
     public void test14(int len, long hash) {
-        Object[] va = (Object[])Array.newInstance(MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType(), len);
+        Object[] va = (Object[])Array.newInstance(MyValue1.val.class, len);
         for (int i = 0; i < len; ++i) {
             Asserts.assertEQ(((MyValue1)va[i]).hashPrimitive(), hash);
         }
     }
 
@@ -451,11 +451,11 @@
     @Test
     public Object test26() {
         Class<?>[] ca = new Class<?>[1];
         for (int i = 0; i < 1; ++i) {
           // Folds during loop opts
-          ca[i] = MyValue1.class.asPrimaryType();
+          ca[i] = MyValue1.val.class;
         }
         return Array.newInstance(ca[0], 1);
     }
 
     @DontCompile
@@ -536,11 +536,11 @@
 
     // getValue to retrieve flattened field from value
     @Test(failOn=CALL_Unsafe)
     public MyValue2 test30(MyValue1 v) {
         if (V1_FLATTENED) {
-            return U.getValue(v, V1_OFFSET, MyValue2.class.asPrimaryType().asIndirectType().asPrimaryType());
+            return U.getValue(v, V1_OFFSET, MyValue2.val.class);
         }
         return (MyValue2)U.getReference(v, V1_OFFSET);
     }
 
     @DontCompile
@@ -565,11 +565,11 @@
 
     // getValue to retrieve flattened field from object
     @Test(failOn=CALL_Unsafe)
     public MyValue1 test31() {
         if (TEST31_VT_FLATTENED) {
-            return U.getValue(this, TEST31_VT_OFFSET, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType());
+            return U.getValue(this, TEST31_VT_OFFSET, MyValue1.val.class);
         }
         return (MyValue1)U.getReference(this, TEST31_VT_OFFSET);
     }
 
     @DontCompile
@@ -581,11 +581,11 @@
 
     // putValue to set flattened field in object
     @Test(failOn=CALL_Unsafe)
     public void test32(MyValue1 vt) {
         if (TEST31_VT_FLATTENED) {
-            U.putValue(this, TEST31_VT_OFFSET, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType(), vt);
+            U.putValue(this, TEST31_VT_OFFSET, MyValue1.val.class, vt);
         } else {
             U.putReference(this, TEST31_VT_OFFSET, vt);
         }
     }
 
@@ -611,11 +611,11 @@
     }
     // getValue to retrieve flattened field from array
     @Test(failOn=CALL_Unsafe)
     public MyValue1 test33(MyValue1[] arr) {
         if (TEST33_FLATTENED_ARRAY) {
-            return U.getValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType());
+            return U.getValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.val.class);
         }
         return (MyValue1)U.getReference(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE);
     }
 
     @DontCompile
@@ -629,11 +629,11 @@
 
     // putValue to set flattened field in array
     @Test(failOn=CALL_Unsafe)
     public void test34(MyValue1[] arr, MyValue1 vt) {
         if (TEST33_FLATTENED_ARRAY) {
-            U.putValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType(), vt);
+            U.putValue(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, MyValue1.val.class, vt);
         } else {
             U.putReference(arr, TEST33_BASE_OFFSET + TEST33_INDEX_SCALE, vt);
         }
     }
 
@@ -648,11 +648,11 @@
     // getValue to retrieve flattened field from object with unknown
     // container type
     @Test(failOn=CALL_Unsafe)
     public MyValue1 test35(Object o) {
         if (TEST31_VT_FLATTENED) {
-            return U.getValue(o, TEST31_VT_OFFSET, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType());
+            return U.getValue(o, TEST31_VT_OFFSET, MyValue1.val.class);
         }
         return (MyValue1)U.getReference(o, TEST31_VT_OFFSET);
     }
 
     @DontCompile
@@ -665,11 +665,11 @@
     // getValue to retrieve flattened field from object at unknown
     // offset
     @Test(failOn=CALL_Unsafe)
     public MyValue1 test36(long offset) {
         if (TEST31_VT_FLATTENED) {
-            return U.getValue(this, offset, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType());
+            return U.getValue(this, offset, MyValue1.val.class);
         }
         return (MyValue1)U.getReference(this, offset);
     }
 
     @DontCompile
@@ -682,11 +682,11 @@
     // putValue to set flattened field in object with unknown
     // container
     @Test(failOn=CALL_Unsafe)
     public void test37(Object o, MyValue1 vt) {
         if (TEST31_VT_FLATTENED) {
-            U.putValue(o, TEST31_VT_OFFSET, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType(), vt);
+            U.putValue(o, TEST31_VT_OFFSET, MyValue1.val.class, vt);
         } else {
             U.putReference(o, TEST31_VT_OFFSET, vt);
         }
     }
 
@@ -701,11 +701,11 @@
     // putValue to set flattened field in object, non value argument
     // to store
     @Test(match = { CALL_Unsafe }, matchCount = { 1 })
     public void test38(Object o) {
         if (TEST31_VT_FLATTENED) {
-            U.putValue(this, TEST31_VT_OFFSET, MyValue1.class.asPrimaryType().asIndirectType().asPrimaryType(), o);
+            U.putValue(this, TEST31_VT_OFFSET, MyValue1.val.class, o);
         } else {
             U.putReference(this, TEST31_VT_OFFSET, o);
         }
     }
 
@@ -740,11 +740,11 @@
     }
 
     @DontCompile
     public void test40_verifier(boolean warmup) {
         int len = Math.abs(rI) % 42;
-        Object[] va = test40(MyValue1.class.asIndirectType(), len);
+        Object[] va = test40(MyValue1.ref.class, len);
         for (int i = 0; i < len; ++i) {
             Asserts.assertEQ(va[i], null);
         }
     }
 
@@ -755,11 +755,11 @@
     }
 
     @DontCompile
     public void test41_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
-        boolean result = test41(MyValue1.class.asIndirectType(), vt);
+        boolean result = test41(MyValue1.ref.class, vt);
         Asserts.assertTrue(result);
         result = test41(MyValue1.class, vt);
         Asserts.assertTrue(result);
     }
 
@@ -769,11 +769,11 @@
     }
 
     @DontCompile
     public void test42_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
-        boolean result = test42(MyValue2.class.asIndirectType(), vt);
+        boolean result = test42(MyValue2.ref.class, vt);
         Asserts.assertFalse(result);
         result = test42(MyValue2.class, vt);
         Asserts.assertFalse(result);
     }
 
@@ -784,13 +784,13 @@
     }
 
     @DontCompile
     public void test43_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
-        Object result = test43(MyValue1.class.asIndirectType(), vt);
+        Object result = test43(MyValue1.ref.class, vt);
         Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());
-        result = test43(MyValue1.class.asIndirectType(), null);
+        result = test43(MyValue1.ref.class, null);
         Asserts.assertEQ(result, null);
     }
 
     @Test()
     public Object test44(Class c, MyValue1.ref vt) {
@@ -799,19 +799,19 @@
 
     @DontCompile
     public void test44_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
         try {
-            test44(MyValue2.class.asIndirectType(), vt);
+            test44(MyValue2.ref.class, vt);
             throw new RuntimeException("should have thrown");
         } catch (ClassCastException cce) {
         }
     }
 
     @Test()
     public Object test45(MyValue1.ref vt) {
-        return MyValue1.class.asIndirectType().cast(vt);
+        return MyValue1.ref.class.cast(vt);
     }
 
     @DontCompile
     public void test45_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
@@ -821,11 +821,11 @@
         Asserts.assertEQ(result, null);
     }
 
     @Test()
     public Object test46(MyValue1.ref vt) {
-        return MyValue2.class.asIndirectType().cast(vt);
+        return MyValue2.ref.class.cast(vt);
     }
 
     @DontCompile
     public void test46_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
@@ -837,11 +837,11 @@
         }
     }
 
     @Test()
     public Object test47(MyValue1.ref vt) {
-        return MyValue1.class.asPrimaryType().cast(vt);
+        return MyValue1.val.class.cast(vt);
     }
 
     @DontCompile
     public void test47_verifier(boolean warmup) {
         MyValue1.ref vt = MyValue1.createWithFieldsInline(rI, rL);
@@ -871,11 +871,11 @@
         }
     }
 
     @Test()
     public Object test49(MyValue1 vt) {
-        return MyValue1.class.asIndirectType().cast(vt);
+        return MyValue1.ref.class.cast(vt);
     }
 
     @DontCompile
     public void test49_verifier(boolean warmup) {
         MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);
@@ -893,11 +893,11 @@
         MyValue1 vt = MyValue1.createWithFieldsInline(rI, rL);
         MyValue1[] va  = new MyValue1[42];
         MyValue1.ref[] vba = new MyValue1.ref[42];
         Object result = test50(MyValue1.class, vt);
         Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());
-        result = test50(MyValue1.class.asIndirectType(), vt);
+        result = test50(MyValue1.ref.class, vt);
         Asserts.assertEQ(((MyValue1)result).hash(), vt.hash());
         result = test50(MyValue1[].class, va);
         Asserts.assertEQ(result, va);
         result = test50(MyValue1.ref[].class, vba);
         Asserts.assertEQ(result, vba);
@@ -916,11 +916,11 @@
     }
 
     // value type array creation via reflection
     @Test()
     public void test51(int len) {
-        Object[] va = (Object[])Array.newInstance(MyValue1.class.asIndirectType().asPrimaryType().asIndirectType(), len);
+        Object[] va = (Object[])Array.newInstance(MyValue1.ref.class, len);
         for (int i = 0; i < len; ++i) {
             Asserts.assertEQ(va[i], null);
         }
     }
 
@@ -1003,57 +1003,27 @@
         test53(MyValue1[].class, MyValue1.ref[].class, len, 2);
         test53(MyValue1[].class, MyValue1.ref[].class, len, 3);
         test53(MyValue1[].class, MyValue1.ref[].class, len, 4);
     }
 
-    // Test asIndirectType intrinsic with non-value mirror
-    @Test()
-    public Class<?> test54(Class<?> c) {
-        if (c.asIndirectType() != Integer.class) {
-            throw new RuntimeException("Unexpected class");
-        }
-        return Integer.class.asIndirectType();
-    }
-
-    @DontCompile
-    public void test54_verifier(boolean warmup) {
-        Class<?> result = test54(Integer.class);
-        Asserts.assertEQ(result, Integer.class);
-    }
-
-    // Test asPrimaryType intrinsic with non-value mirror
-    @Test()
-    public Class<?> test55(Class<?> c) {
-        if (c.asPrimaryType() != Integer.class) {
-            throw new RuntimeException("Unexpected class");
-        }
-        return Integer.class.asPrimaryType();
-    }
-
-    @DontCompile
-    public void test55_verifier(boolean warmup) {
-        Class<?> result = test55(Integer.class);
-        Asserts.assertEQ(result, Integer.class);
-    }
-
     // Same as test39 but Unsafe.putInt to buffer is not intrinsified/compiled
     @DontCompile
-    public void test56_callee(MyValue1.ref v) { // Use .ref here to make sure the argument is not scalarized (otherwise larval information is lost)
+    public void test54_callee(MyValue1.ref v) { // Use .ref here to make sure the argument is not scalarized (otherwise larval information is lost)
         U.putInt(v, X_OFFSET, rI);
     }
 
     @Test()
     @Warmup(10000) // Fill up the TLAB to trigger slow path allocation
-    public MyValue1 test56(MyValue1 v) {
+    public MyValue1 test54(MyValue1 v) {
         v = U.makePrivateBuffer(v);
-        test56_callee(v);
+        test54_callee(v);
         v = U.finishPrivateBuffer(v);
         return v;
     }
 
     @DontCompile
-    public void test56_verifier(boolean warmup) {
+    public void test54_verifier(boolean warmup) {
         MyValue1 v = MyValue1.createWithFieldsInline(rI, rL);
-        MyValue1 res = test56(v.setX(v, 0));
+        MyValue1 res = test54(v.setX(v, 0));
         Asserts.assertEQ(res.hash(), v.hash());
     }
 }
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
@@ -1376,11 +1376,11 @@
     }
 
     // Tests writing an array element with a (statically known) incompatible type
     private static final MethodHandle setArrayElementIncompatible = MethodHandleBuilder.loadCode(MethodHandles.lookup(),
         "setArrayElementIncompatible",
-        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class, MyValue2.class.asPrimaryType()),
+        MethodType.methodType(void.class, TestLWorld.class, MyValue1[].class, int.class, MyValue2.class),
         CODE -> {
             CODE.
             aload_1().
             iload_2().
             aload_3().
@@ -2255,13 +2255,12 @@
                 enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             }
         }
     }
 
-
-    // Following: should make 2 copies of the loop, one for non
-    // flattened arrays, one for other cases
+    // Tests for the Loop Unswitching optimization
+    // Should make 2 copies of the loop, one for non flattened arrays, one for other cases.
     @Test(match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )
     @Warmup(0)
     public void test84(Object[] src, Object[] dst) {
         for (int i = 0; i < src.length; i++) {
             dst[i] = src[i];
@@ -2312,11 +2311,11 @@
     @DontCompile
     public void test86_verifier(boolean warmup) {
         MyValue2[] src = new MyValue2[100];
         Arrays.fill(src, testValue2);
         Object[] dst = new Object[100];
-        rerun_and_recompile_for("TestLWorld::test85", 10,
+        rerun_and_recompile_for("TestLWorld::test86", 10,
                                 () -> { test86(src, dst);
                                         Asserts.assertTrue(Arrays.equals(src, dst)); });
     }
 
     @Test(match = { COUNTEDLOOP_MAIN }, matchCount = { 2 } )
@@ -2855,6 +2854,63 @@
         Asserts.assertEquals(array2[0], v);
         Asserts.assertEquals(array2[1], v);
         Asserts.assertEquals(array2[2], v);
         Asserts.assertEquals(result, v);
     }
+
+    // More tests for the Loop Unswitching optimization (similar to test84 and following)
+    Object oFld1, oFld2;
+
+    @Test(valid = G1GCOn, failOn = STORE_UNKNOWN_VALUE + VALUE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, LOAD_UNKNOWN_VALUE }, matchCount = { 2, 2 } )
+    @Test(valid = G1GCOff, failOn = STORE_UNKNOWN_VALUE + VALUE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, LOAD_UNKNOWN_VALUE }, matchCount = { 3, 2 } )
+    @Warmup(0)
+    public void test107(Object[] src1, Object[] src2) {
+        for (int i = 0; i < src1.length; i++) {
+            oFld1 = src1[i];
+            oFld2 = src2[i];
+        }
+    }
+
+    @DontCompile
+    public void test107_verifier(boolean warmup) {
+        MyValue2[] src1 = new MyValue2[100];
+        Arrays.fill(src1, testValue2);
+        Object[] src2 = new Object[100];
+        Object obj = new Object();
+        Arrays.fill(src2, obj);
+        rerun_and_recompile_for("TestLWorld::test107", 10,
+                                () -> { test107(src1, src2);
+                                        Asserts.assertEquals(oFld1, testValue2);
+                                        Asserts.assertEquals(oFld2, obj);
+                                        test107(src2, src1);
+                                        Asserts.assertEquals(oFld1, obj);
+                                        Asserts.assertEquals(oFld2, testValue2);  });
+    }
+
+    @Test(valid = G1GCOn, failOn = LOAD_UNKNOWN_VALUE + VALUE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, STORE_UNKNOWN_VALUE }, matchCount = { 4, 9 } )
+    @Test(valid = G1GCOff, failOn = LOAD_UNKNOWN_VALUE + VALUE_ARRAY_NULL_GUARD, match = { COUNTEDLOOP, STORE_UNKNOWN_VALUE }, matchCount = { 4, 12 } )
+    @Warmup(0)
+    public void test108(Object[] dst1, Object[] dst2, Object o1, Object o2) {
+        for (int i = 0; i < dst1.length; i++) {
+            dst1[i] = o1;
+            dst2[i] = o2;
+        }
+    }
+
+    @DontCompile
+    public void test108_verifier(boolean warmup) {
+        MyValue2[] dst1 = new MyValue2[100];
+        Object[] dst2 = new Object[100];
+        Object o1 = new Object();
+        rerun_and_recompile_for("TestLWorld::test108", 10,
+                                () -> { test108(dst1, dst2, testValue2, o1);
+                                        for (int i = 0; i < dst1.length; i++) {
+                                            Asserts.assertEquals(dst1[i], testValue2);
+                                            Asserts.assertEquals(dst2[i], o1);
+                                        }
+                                        test108(dst2, dst1, o1, testValue2);
+                                        for (int i = 0; i < dst1.length; i++) {
+                                            Asserts.assertEquals(dst1[i], testValue2);
+                                            Asserts.assertEquals(dst2[i], o1);
+                                        } });
+    }
 }
