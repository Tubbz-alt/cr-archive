diff a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
@@ -520,12 +520,12 @@
 
   __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
   __ ret(lr);
 }
 
-int LIR_Assembler::store_value_type_fields_to_buf(ciValueKlass* vk) {
-  return (__ store_value_type_fields_to_buf(vk, false));
+int LIR_Assembler::store_inline_type_fields_to_buf(ciValueKlass* vk) {
+  return (__ store_inline_type_fields_to_buf(vk, false));
 }
 
 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
   guarantee(info != NULL, "Shouldn't be NULL");
   __ get_polling_page(rscratch1, relocInfo::poll_type);
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -5262,13 +5262,13 @@
   if (VerifyStackAtCalls) {
     Unimplemented();
   }
 }
 
-int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {
-  // A value type might be returned. If fields are in registers we
-  // need to allocate a value type instance and initialize it with
+int MacroAssembler::store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {
+  // An inline type might be returned. If fields are in registers we
+  // need to allocate an inline type instance and initialize it with
   // the value of the fields.
   Label skip;
   // We only need a new buffered value if a new one is not returned
   cmp(r0, (u1) 1);
   br(Assembler::EQ, skip);
@@ -5342,13 +5342,13 @@
   // tell. That runtime call will take care of preserving them
   // across a GC if there's one.
 
 
   if (from_interpreter) {
-    super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());
+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
   } else {
-    ldr(rscratch1, RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));
+    ldr(rscratch1, RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
     blr(rscratch1);
     call_offset = offset();
   }
 
   bind(skip);
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
@@ -1197,11 +1197,11 @@
      reg_written
   };
 
   void verified_entry(Compile* C, int sp_inc);
 
-  int store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
+  int store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
 
 // Unpack all value type arguments passed as oops
   void unpack_value_args(Compile* C, bool receiver_only);
   bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);
   bool unpack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to, int& to_index,
diff a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
@@ -5940,14 +5940,14 @@
 
     if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos)) {
       StubRoutines::_dcos = generate_dsin_dcos(/* isCos = */ true);
     }
 
-    StubRoutines::_load_value_type_fields_in_regs =
-         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_value_type_fields_in_regs), "load_value_type_fields_in_regs", false);
-    StubRoutines::_store_value_type_fields_to_buf =
-         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_value_type_fields_to_buf), "store_value_type_fields_to_buf", true);
+    StubRoutines::_load_inline_type_fields_in_regs =
+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), "load_inline_type_fields_in_regs", false);
+    StubRoutines::_store_inline_type_fields_to_buf =
+         generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), "store_inline_type_fields_to_buf", true);
 
     // Safefetch stubs.
     generate_safefetch("SafeFetch32", sizeof(int),     &StubRoutines::_safefetch32_entry,
                                                        &StubRoutines::_safefetch32_fault_pc,
                                                        &StubRoutines::_safefetch32_continuation_pc);
diff a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
@@ -436,11 +436,11 @@
   __ ldr(esp, Address(rfp, frame::interpreter_frame_last_sp_offset * wordSize));
   // and NULL it as marker that esp is now tos until next java call
   __ str(zr, Address(rfp, frame::interpreter_frame_last_sp_offset * wordSize));
 
   if (state == atos && InlineTypeReturnedAsFields) {
-    __ store_value_type_fields_to_buf(NULL, true);
+    __ store_inline_type_fields_to_buf(NULL, true);
   }
 
   __ restore_bcp();
   __ restore_locals();
   __ restore_constant_pool_cache();
diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -570,12 +570,12 @@
   __ testl(rax, Address(poll_addr, 0));
   __ ret(0);
 }
 
 
-int LIR_Assembler::store_value_type_fields_to_buf(ciValueKlass* vk) {
-  return (__ store_value_type_fields_to_buf(vk, false));
+int LIR_Assembler::store_inline_type_fields_to_buf(ciValueKlass* vk) {
+  return (__ store_inline_type_fields_to_buf(vk, false));
 }
 
 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
   guarantee(info != NULL, "Shouldn't be NULL");
   int offset = __ offset();
diff a/src/hotspot/cpu/x86/interp_masm_x86.cpp b/src/hotspot/cpu/x86/interp_masm_x86.cpp
--- a/src/hotspot/cpu/x86/interp_masm_x86.cpp
+++ b/src/hotspot/cpu/x86/interp_masm_x86.cpp
@@ -1161,13 +1161,13 @@
     movptr(rdi, Address(rdi, Method::const_offset()));
     load_unsigned_byte(rdi, Address(rdi, ConstMethod::result_type_offset()));
     cmpl(rdi, T_INLINE_TYPE);
     jcc(Assembler::notEqual, skip);
 
-    // We are returning a value type, load its fields into registers
+    // We are returning an inline type, load its fields into registers
 #ifndef _LP64
-    super_call_VM_leaf(StubRoutines::load_value_type_fields_in_regs());
+    super_call_VM_leaf(StubRoutines::load_inline_type_fields_in_regs());
 #else
     // Load fields from a buffered value with a value class specific handler
     Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
     load_klass(rdi, rax, tmp_load_klass);
     movptr(rdi, Address(rdi, InstanceKlass::adr_inlineklass_fixed_block_offset()));
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -5203,13 +5203,13 @@
   decrement(cnt);
   jccb(Assembler::greaterEqual, L_sloop);
   BIND(L_end);
 }
 
-int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {
-  // A value type might be returned. If fields are in registers we
-  // need to allocate a value type instance and initialize it with
+int MacroAssembler::store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {
+  // An inline type might be returned. If fields are in registers we
+  // need to allocate an inline type instance and initialize it with
   // the value of the fields.
   Label skip;
   // We only need a new buffered value if a new one is not returned
   testptr(rax, 1);
   jcc(Assembler::zero, skip);
@@ -5272,13 +5272,13 @@
   // tell. That runtime call will take care of preserving them
   // across a GC if there's one.
 #endif
 
   if (from_interpreter) {
-    super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());
+    super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
   } else {
-    call(RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));
+    call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
     call_offset = offset();
   }
 
   bind(skip);
   return call_offset;
diff a/src/hotspot/cpu/x86/macroAssembler_x86.hpp b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
@@ -1652,11 +1652,11 @@
     reg_readonly,
     reg_writable,
     reg_written
   };
 
-  int store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
+  int store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
 
   // Unpack all value type arguments passed as oops
   void unpack_value_args(Compile* C, bool receiver_only);
   bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);
   bool unpack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to, int& to_index,
diff a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
--- a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
+++ b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
@@ -6479,12 +6479,12 @@
     // stubRoutines.hpp.
 
     StubRoutines::_forward_exception_entry = generate_forward_exception();
 
     // Generate these first because they are called from other stubs
-    StubRoutines::_load_value_type_fields_in_regs = generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_value_type_fields_in_regs), "load_value_type_fields_in_regs", false);
-    StubRoutines::_store_value_type_fields_to_buf = generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_value_type_fields_to_buf), "store_value_type_fields_to_buf", true);
+    StubRoutines::_load_inline_type_fields_in_regs = generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::load_inline_type_fields_in_regs), "load_inline_type_fields_in_regs", false);
+    StubRoutines::_store_inline_type_fields_to_buf = generate_return_value_stub(CAST_FROM_FN_PTR(address, SharedRuntime::store_inline_type_fields_to_buf), "store_inline_type_fields_to_buf", true);
 
     StubRoutines::_call_stub_entry = generate_call_stub(StubRoutines::_call_stub_return_address);
 
     // is referenced by megamorphic call
     StubRoutines::_catch_exception_entry = generate_catch_exception();
diff a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
@@ -205,11 +205,11 @@
   __ movptr(rsp, Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize));
   // and NULL it as marker that esp is now tos until next java call
   __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), (int32_t)NULL_WORD);
 
   if (state == atos && InlineTypeReturnedAsFields) {
-    __ store_value_type_fields_to_buf(NULL);
+    __ store_inline_type_fields_to_buf(NULL);
   }
 
   __ restore_bcp();
   __ restore_locals();
 
diff a/src/hotspot/share/c1/c1_LIRAssembler.cpp b/src/hotspot/share/c1/c1_LIRAssembler.cpp
--- a/src/hotspot/share/c1/c1_LIRAssembler.cpp
+++ b/src/hotspot/share/c1/c1_LIRAssembler.cpp
@@ -485,11 +485,11 @@
     compilation()->set_has_method_handle_invokes(true);
   }
 
   ciValueKlass* vk;
   if (op->maybe_return_as_fields(&vk)) {
-    int offset = store_value_type_fields_to_buf(vk);
+    int offset = store_inline_type_fields_to_buf(vk);
     add_call_info(offset, op->info(), true);
   }
 
 #if defined(IA32) && defined(TIERED)
   // C2 leave fpu stack dirty clean it
diff a/src/hotspot/share/c1/c1_LIRAssembler.hpp b/src/hotspot/share/c1/c1_LIRAssembler.hpp
--- a/src/hotspot/share/c1/c1_LIRAssembler.hpp
+++ b/src/hotspot/share/c1/c1_LIRAssembler.hpp
@@ -233,11 +233,11 @@
   void cmove(LIR_Condition code, LIR_Opr left, LIR_Opr right, LIR_Opr result, BasicType type);
 
   void call(        LIR_OpJavaCall* op, relocInfo::relocType rtype);
   void ic_call(     LIR_OpJavaCall* op);
   void vtable_call( LIR_OpJavaCall* op);
-  int  store_value_type_fields_to_buf(ciValueKlass* vk);
+  int  store_inline_type_fields_to_buf(ciValueKlass* vk);
 
   void osr_entry();
 
   void build_frame();
 
diff a/src/hotspot/share/opto/callnode.cpp b/src/hotspot/share/opto/callnode.cpp
--- a/src/hotspot/share/opto/callnode.cpp
+++ b/src/hotspot/share/opto/callnode.cpp
@@ -696,11 +696,11 @@
   return tf()->range_cc();
 }
 
 //------------------------------calling_convention-----------------------------
 void CallNode::calling_convention(BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt) const {
-  if (_entry_point == StubRoutines::store_value_type_fields_to_buf()) {
+  if (_entry_point == StubRoutines::store_inline_type_fields_to_buf()) {
     // The call to that stub is a special case: its inputs are
     // multiple values returned from a call and so it should follow
     // the return convention.
     SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);
     return;
diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -2725,11 +2725,11 @@
 
   Node* slowpath_true = new IfTrueNode(slowpath_iff);
   transform_later(slowpath_true);
 
   CallStaticJavaNode* slow_call = new CallStaticJavaNode(OptoRuntime::store_value_type_fields_Type(),
-                                                         StubRoutines::store_value_type_fields_to_buf(),
+                                                         StubRoutines::store_inline_type_fields_to_buf(),
                                                          "store_value_type_fields",
                                                          call->jvms()->bci(),
                                                          TypePtr::BOTTOM);
   slow_call->init_req(TypeFunc::Control, slowpath_true);
   slow_call->init_req(TypeFunc::Memory, mem);
diff a/src/hotspot/share/runtime/sharedRuntime.cpp b/src/hotspot/share/runtime/sharedRuntime.cpp
--- a/src/hotspot/share/runtime/sharedRuntime.cpp
+++ b/src/hotspot/share/runtime/sharedRuntime.cpp
@@ -3659,11 +3659,11 @@
 }
 JRT_END
 
 // We're returning from an interpreted method: load each field into a
 // register following the calling convention
-JRT_LEAF(void, SharedRuntime::load_value_type_fields_in_regs(JavaThread* thread, oopDesc* res))
+JRT_LEAF(void, SharedRuntime::load_inline_type_fields_in_regs(JavaThread* thread, oopDesc* res))
 {
   assert(res->klass()->is_inline_klass(), "only inline types here");
   ResourceMark rm;
   RegisterMap reg_map(thread);
   frame stubFrame = thread->last_frame();
@@ -3674,11 +3674,11 @@
 
   const Array<SigEntry>* sig_vk = vk->extended_sig();
   const Array<VMRegPair>* regs = vk->return_regs();
 
   if (regs == NULL) {
-    // The fields of the value klass don't fit in registers, bail out
+    // The fields of the inline klass don't fit in registers, bail out
     return;
   }
 
   int j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
@@ -3748,13 +3748,13 @@
   thread->set_vm_result(res);
 }
 JRT_END
 
 // We've returned to an interpreted method, the interpreter needs a
-// reference to a value type instance. Allocate it and initialize it
+// reference to an inline type instance. Allocate it and initialize it
 // from field's values in registers.
-JRT_BLOCK_ENTRY(void, SharedRuntime::store_value_type_fields_to_buf(JavaThread* thread, intptr_t res))
+JRT_BLOCK_ENTRY(void, SharedRuntime::store_inline_type_fields_to_buf(JavaThread* thread, intptr_t res))
 {
   ResourceMark rm;
   RegisterMap reg_map(thread);
   frame stubFrame = thread->last_frame();
   frame callerFrame = stubFrame.sender(&reg_map);
@@ -3762,12 +3762,12 @@
 #ifdef ASSERT
   InlineKlass* verif_vk = InlineKlass::returned_inline_klass(reg_map);
 #endif
 
   if (!is_set_nth_bit(res, 0)) {
-    // We're not returning with value type fields in registers (the
-    // calling convention didn't allow it for this value klass)
+    // We're not returning with inline type fields in registers (the
+    // calling convention didn't allow it for this inline klass)
     assert(!Metaspace::contains((void*)res), "should be oop or pointer in buffer area");
     thread->set_vm_result((oopDesc*)res);
     assert(verif_vk == NULL, "broken calling convention");
     return;
   }
diff a/src/hotspot/share/runtime/sharedRuntime.hpp b/src/hotspot/share/runtime/sharedRuntime.hpp
--- a/src/hotspot/share/runtime/sharedRuntime.hpp
+++ b/src/hotspot/share/runtime/sharedRuntime.hpp
@@ -533,12 +533,12 @@
   // Resolving of calls
   static address resolve_static_call_C     (JavaThread *thread);
   static address resolve_virtual_call_C    (JavaThread *thread);
   static address resolve_opt_virtual_call_C(JavaThread *thread);
 
-  static void load_value_type_fields_in_regs(JavaThread *thread, oopDesc* res);
-  static void store_value_type_fields_to_buf(JavaThread *thread, intptr_t res);
+  static void load_inline_type_fields_in_regs(JavaThread *thread, oopDesc* res);
+  static void store_inline_type_fields_to_buf(JavaThread *thread, intptr_t res);
 
   // arraycopy, the non-leaf version.  (See StubRoutines for all the leaf calls.)
   static void slow_arraycopy_C(oopDesc* src,  jint src_pos,
                                oopDesc* dest, jint dest_pos,
                                jint length, JavaThread* thread);
diff a/src/hotspot/share/runtime/stubRoutines.cpp b/src/hotspot/share/runtime/stubRoutines.cpp
--- a/src/hotspot/share/runtime/stubRoutines.cpp
+++ b/src/hotspot/share/runtime/stubRoutines.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -178,12 +178,12 @@
 address StubRoutines::_safefetch32_continuation_pc       = NULL;
 address StubRoutines::_safefetchN_entry                  = NULL;
 address StubRoutines::_safefetchN_fault_pc               = NULL;
 address StubRoutines::_safefetchN_continuation_pc        = NULL;
 
-address StubRoutines::_load_value_type_fields_in_regs = NULL;
-address StubRoutines::_store_value_type_fields_to_buf = NULL;
+address StubRoutines::_load_inline_type_fields_in_regs = NULL;
+address StubRoutines::_store_inline_type_fields_to_buf = NULL;
 
 // Initialization
 //
 // Note: to break cycle with universe initialization, stubs are generated in two phases.
 // The first one generates stubs needed during universe init (e.g., _handle_must_compile_first_entry).
diff a/src/hotspot/share/runtime/stubRoutines.hpp b/src/hotspot/share/runtime/stubRoutines.hpp
--- a/src/hotspot/share/runtime/stubRoutines.hpp
+++ b/src/hotspot/share/runtime/stubRoutines.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -261,12 +261,12 @@
   static address _safefetch32_continuation_pc;
   static address _safefetchN_entry;
   static address _safefetchN_fault_pc;
   static address _safefetchN_continuation_pc;
 
-  static address _load_value_type_fields_in_regs;
-  static address _store_value_type_fields_to_buf;
+  static address _load_inline_type_fields_in_regs;
+  static address _store_inline_type_fields_to_buf;
 
  public:
   // Initialization/Testing
   static void    initialize1();                            // must happen before universe::genesis
   static void    initialize2();                            // must happen after  universe::genesis
@@ -483,12 +483,12 @@
   static void arrayof_jint_copy      (HeapWord* src, HeapWord* dest, size_t count);
   static void arrayof_jlong_copy     (HeapWord* src, HeapWord* dest, size_t count);
   static void arrayof_oop_copy       (HeapWord* src, HeapWord* dest, size_t count);
   static void arrayof_oop_copy_uninit(HeapWord* src, HeapWord* dest, size_t count);
 
-  static address load_value_type_fields_in_regs() { return _load_value_type_fields_in_regs; }
-  static address store_value_type_fields_to_buf() { return _store_value_type_fields_to_buf; }
+  static address load_inline_type_fields_in_regs() { return _load_inline_type_fields_in_regs; }
+  static address store_inline_type_fields_to_buf() { return _store_inline_type_fields_to_buf; }
 };
 
 // Safefetch allows to load a value from a location that's not known
 // to be valid. If the load causes a fault, the error value is returned.
 inline int SafeFetch32(int* adr, int errValue) {
