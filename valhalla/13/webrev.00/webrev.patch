diff a/src/hotspot/cpu/x86/gc/g1/g1BarrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/g1/g1BarrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/g1/g1BarrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/g1/g1BarrierSetAssembler_x86.cpp
@@ -187,11 +187,10 @@
   __ jcc(Assembler::equal, done);
 
   // Can we store original value in the thread's buffer?
   // Is index == 0?
   // (The index field is typed as size_t.)
-
   __ movptr(tmp, index);                   // tmp := *index_adr
   __ cmpptr(tmp, 0);                       // tmp == 0?
   __ jcc(Assembler::equal, runtime);       // If yes, goto runtime
 
   __ subptr(tmp, wordSize);                // tmp := tmp - wordSize
@@ -201,18 +200,14 @@
   // Record the previous value
   __ movptr(Address(tmp, 0), pre_val);
   __ jmp(done);
 
   __ bind(runtime);
-  // save the live input values
-  if(tosca_live) __ push(rax);
-
-  if (obj != noreg && obj != rax)
-    __ push(obj);
-
-  if (pre_val != rax)
-    __ push(pre_val);
+  // FIXME
+  // Barriers might be emitted when converting between (scalarized) calling conventions for inline
+  // types. Save all registers until JDK-8232094 is fixed to avoid overwriting argument registers.
+  __ pusha();
 
   // Calling the runtime using the regular call_VM_leaf mechanism generates
   // code (generated by InterpreterMacroAssember::call_VM_leaf_base)
   // that checks that the *(ebp+frame::interpreter_frame_last_sp) == NULL.
   //
@@ -222,12 +217,10 @@
   //
   // Expanding the call directly bypasses the generation of the check.
   // So when we do not have have a full interpreter frame on the stack
   // expand_call should be passed true.
 
-  NOT_LP64( __ push(thread); )
-
   if (expand_call) {
     LP64_ONLY( assert(pre_val != c_rarg1, "smashed arg"); )
 #ifdef _LP64
     if (c_rarg1 != thread) {
       __ mov(c_rarg1, thread);
@@ -242,21 +235,11 @@
     __ MacroAssembler::call_VM_leaf_base(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_pre_entry), 2);
   } else {
     __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_pre_entry), pre_val, thread);
   }
 
-  NOT_LP64( __ pop(thread); )
-
-  // save the live input values
-  if (pre_val != rax)
-    __ pop(pre_val);
-
-  if (obj != noreg && obj != rax)
-    __ pop(obj);
-
-  if(tosca_live) __ pop(rax);
-
+  __ popa();
   __ bind(done);
 }
 
 void G1BarrierSetAssembler::g1_write_barrier_post(MacroAssembler* masm,
                                                   Register store_addr,
@@ -327,30 +310,24 @@
   __ movl(Address(tmp2, 0), card_addr);
 #endif
   __ jmp(done);
 
   __ bind(runtime);
-  // save the live input values
-  __ push(store_addr);
-  __ push(new_val);
-  // Save caller saved registers until JDK-8232094 is fixed (TODO).
-  __ push(rax);
-  __ push(rcx);
-  __ push(rdx);
+  // FIXME
+  // Barriers might be emitted when converting between (scalarized) calling conventions for inline
+  // types. Save all registers until JDK-8232094 is fixed to avoid overwriting argument registers.
+  __ pusha();
+
 #ifdef _LP64
   __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), card_addr, r15_thread);
 #else
   __ push(thread);
   __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry), card_addr, thread);
   __ pop(thread);
 #endif
-  __ pop(rdx);
-  __ pop(rcx);
-  __ pop(rax);
-  __ pop(new_val);
-  __ pop(store_addr);
 
+  __ popa();
   __ bind(done);
 }
 
 void G1BarrierSetAssembler::oop_store_at(MacroAssembler* masm, DecoratorSet decorators, BasicType type,
                                          Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {
diff a/src/hotspot/share/ci/ciReplay.cpp b/src/hotspot/share/ci/ciReplay.cpp
--- a/src/hotspot/share/ci/ciReplay.cpp
+++ b/src/hotspot/share/ci/ciReplay.cpp
@@ -850,12 +850,11 @@
         bool res = _replay->process_staticfield_reference(string_value, _vt, fd, THREAD);
         assert(res, "should succeed for arrays & objects");
         break;
       }
       case T_VALUETYPE: {
-        SignatureStream ss(fd->signature(), false);
-        ValueKlass* vk = ss.as_value_klass(fd->field_holder());
+        ValueKlass* vk = ValueKlass::cast(fd->field_holder()->get_value_field_klass(fd->index()));
         if (fd->is_flattened()) {
           int field_offset = fd->offset() - vk->first_field_offset();
           oop obj = (oop)(cast_from_oop<address>(_vt) + field_offset);
           ValueTypeFieldInitializer init_fields(obj, _replay);
           vk->do_nonstatic_fields(&init_fields);
diff a/src/hotspot/share/runtime/deoptimization.cpp b/src/hotspot/share/runtime/deoptimization.cpp
--- a/src/hotspot/share/runtime/deoptimization.cpp
+++ b/src/hotspot/share/runtime/deoptimization.cpp
@@ -222,11 +222,16 @@
     JRT_END
 #ifndef PRODUCT
     if (TraceDeoptimization) {
       ttyLocker ttyl;
       tty->print_cr("REALLOC OBJECTS in thread " INTPTR_FORMAT, p2i(thread));
-      Deoptimization::print_objects(objects, realloc_failures);
+      if (objects != NULL) {
+        Deoptimization::print_objects(objects, realloc_failures);
+      } else {
+        Handle obj = realloc_failures ? Handle() : return_oops.first();
+        Deoptimization::print_object(vk, obj, realloc_failures);
+      }
     }
 #endif
   }
   if (save_oop_result || vk != NULL) {
     // Restore result.
@@ -1402,29 +1407,30 @@
 
 #ifndef PRODUCT
 // print information about reallocated objects
 void Deoptimization::print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures) {
   fieldDescriptor fd;
-
   for (int i = 0; i < objects->length(); i++) {
     ObjectValue* sv = (ObjectValue*) objects->at(i);
     Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());
-    Handle obj = sv->value();
+    print_object(k, sv->value(), realloc_failures);
+  }
+}
 
-    tty->print("     object <" INTPTR_FORMAT "> of type ", p2i(sv->value()()));
-    k->print_value();
-    assert(obj.not_null() || realloc_failures, "reallocation was missed");
-    if (obj.is_null()) {
-      tty->print(" allocation failed");
-    } else {
-      tty->print(" allocated (%d bytes)", obj->size() * HeapWordSize);
-    }
-    tty->cr();
+void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {
+  tty->print("     object <" INTPTR_FORMAT "> of type ", p2i(obj()));
+  k->print_value();
+  assert(obj.not_null() || realloc_failures, "reallocation was missed");
+  if (obj.is_null()) {
+    tty->print(" allocation failed");
+  } else {
+    tty->print(" allocated (%d bytes)", obj->size() * HeapWordSize);
+  }
+  tty->cr();
 
-    if (Verbose && !obj.is_null()) {
-      k->oop_print_on(obj(), tty);
-    }
+  if (Verbose && !obj.is_null()) {
+    k->oop_print_on(obj(), tty);
   }
 }
 #endif
 #endif // COMPILER2_OR_JVMCI
 
diff a/src/hotspot/share/runtime/deoptimization.hpp b/src/hotspot/share/runtime/deoptimization.hpp
--- a/src/hotspot/share/runtime/deoptimization.hpp
+++ b/src/hotspot/share/runtime/deoptimization.hpp
@@ -170,11 +170,14 @@
   static void reassign_object_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, objArrayOop obj);
   static void reassign_value_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, valueArrayOop obj, ValueArrayKlass* vak, TRAPS);
   static void reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS);
   static void relock_objects(GrowableArray<MonitorInfo*>* monitors, JavaThread* thread, bool realloc_failures);
   static void pop_frames_failed_reallocs(JavaThread* thread, vframeArray* array);
-  NOT_PRODUCT(static void print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures);)
+#ifndef PRODUCT
+  static void print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures);
+  static void print_object(Klass* k, Handle obj, bool realloc_failures);
+#endif
 #endif // COMPILER2_OR_JVMCI
 
   public:
   static vframeArray* create_vframeArray(JavaThread* thread, frame fr, RegisterMap *reg_map, GrowableArray<compiledVFrame*>* chunk, bool realloc_failures);
 
diff a/src/hotspot/share/runtime/fieldDescriptor.cpp b/src/hotspot/share/runtime/fieldDescriptor.cpp
--- a/src/hotspot/share/runtime/fieldDescriptor.cpp
+++ b/src/hotspot/share/runtime/fieldDescriptor.cpp
@@ -29,11 +29,11 @@
 #include "oops/annotations.hpp"
 #include "oops/constantPool.hpp"
 #include "oops/instanceKlass.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/fieldStreams.inline.hpp"
-#include "oops/valueKlass.hpp"
+#include "oops/valueKlass.inline.hpp"
 #include "runtime/fieldDescriptor.inline.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/signature.hpp"
 
 
@@ -188,45 +188,30 @@
       break;
     case T_BOOLEAN:
       as_int = obj->bool_field(offset());
       st->print(" %s", obj->bool_field(offset()) ? "true" : "false");
       break;
-    case T_ARRAY:
-      st->print(" ");
-      NOT_LP64(as_int = obj->int_field(offset()));
-      if (obj->obj_field(offset()) != NULL) {
-        obj->obj_field(offset())->print_value_on(st);
-      } else {
-        st->print_cr("NULL");
-      }
-      break;
-    case T_OBJECT:
-      st->print(" ");
-      NOT_LP64(as_int = obj->int_field(offset()));
-      if (obj->obj_field(offset()) != NULL) {
-        obj->obj_field(offset())->print_value_on(st);
-      } else {
-        st->print_cr("NULL");
-      }
-      break;
     case T_VALUETYPE:
       if (is_flattened()) {
-        // Resolve klass of flattened value type field
-        ResourceMark rm(Thread::current());
-        SignatureStream ss(signature(), false);
-        ValueKlass* vk = ss.as_value_klass(field_holder());
+        // Print fields of flattened value type field
+        ValueKlass* vk = ValueKlass::cast(field_holder()->get_value_field_klass(index()));
         int field_offset = offset() - vk->first_field_offset();
         obj = (oop)(cast_from_oop<address>(obj) + field_offset);
-        // Print flattened fields of the value type field
         st->print_cr("Flattened value type '%s':", vk->name()->as_C_string());
         FieldPrinter print_field(st, obj);
         vk->do_nonstatic_fields(&print_field);
         return; // Do not print underlying representation
-      } else {
-        st->print(" ");
-        NOT_LP64(as_int = obj->int_field(offset()));
+      }
+      // Non-flattened field, fall through
+    case T_ARRAY:
+    case T_OBJECT:
+      st->print(" ");
+      NOT_LP64(as_int = obj->int_field(offset()));
+      if (obj->obj_field(offset()) != NULL) {
         obj->obj_field(offset())->print_value_on(st);
+      } else {
+        st->print_cr("NULL");
       }
       break;
     default:
       ShouldNotReachHere();
       break;
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestArrays.java
@@ -48,11 +48,11 @@
             CompLevel_simple            = 1,         // C1
             CompLevel_limited_profile   = 2,         // C1, invocation & backedge counters
             CompLevel_full_profile      = 3,         // C1, invocation & backedge counters + mdo
             CompLevel_full_optimization = 4;         // C2 or JVMCI
 
-        if (USE_COMPILER && !XCOMP && WHITE_BOX.isMethodCompiled(m, false) &&
+        if (USE_COMPILER && !XCOMP && !STRESS_CC && WHITE_BOX.isMethodCompiled(m, false) &&
             WHITE_BOX.getMethodCompilationLevel(m, false) >= CompLevel_full_optimization) {
             throw new RuntimeException("Type check should have caused it to deoptimize");
         }
     }
 
@@ -875,11 +875,11 @@
 
     static boolean compile_and_run_again_if_deoptimized(boolean warmup, String test) {
         if (!warmup) {
             Method m = tests.get(test);
             if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false)) {
-                if (!ValueTypeArrayFlatten && !XCOMP) {
+                if (!ValueTypeArrayFlatten && !XCOMP && !STRESS_CC) {
                     throw new RuntimeException("Unexpected deoptimization");
                 }
                 enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
                 return true;
             }
@@ -971,11 +971,11 @@
             Method m = tests.get("TestArrays::test38");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test38(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1020,11 +1020,11 @@
             Method m = tests.get("TestArrays::test40");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test40(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1064,11 +1064,11 @@
         }
         test42(src, dst);
         verify(src, dst);
         if (!warmup) {
             Method m = tests.get("TestArrays::test42");
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1152,11 +1152,11 @@
             Method m = tests.get("TestArrays::test46");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test46(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1199,11 +1199,11 @@
             Method m = tests.get("TestArrays::test48");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test48(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1241,11 +1241,11 @@
         }
         test50(src, dst);
         verify(src, dst);
         if (!warmup) {
             Method m = tests.get("TestArrays::test50");
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorld.java
@@ -2322,11 +2322,11 @@
                         test93(array);
                     } catch (ClassCastException cce) {
                     }
                 }
                 boolean compiled = isCompiledByC2(m);
-                Asserts.assertTrue(!USE_COMPILER || XCOMP || TEST_C1 || compiled || (j != extra-1));
+                Asserts.assertTrue(!USE_COMPILER || XCOMP || STRESS_CC || TEST_C1 || compiled || (j != extra-1));
                 if (!compiled) {
                     enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
                 }
             }
         }
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorldProfiling.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorldProfiling.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorldProfiling.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestLWorldProfiling.java
@@ -353,16 +353,14 @@
                 test14(testIntegerArray, 42);
                 if (!WHITE_BOX.isMethodCompiled(m, false)) {
                     deopt = true;
                 }
             }
-            if (!TieredCompilation && (deopt && (UseArrayLoadStoreProfile || TypeProfileLevel == 222))) {
+            if (!TieredCompilation && !STRESS_CC && (deopt && (UseArrayLoadStoreProfile || TypeProfileLevel == 222))) {
                 throw new RuntimeException("Monomorphic array check should rely on profiling and be accurate");
             }
-
         }
-
     }
 
     // null free array profiling
 
     inline static class NotFlattenable {
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestNullableArrays.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestNullableArrays.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestNullableArrays.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/TestNullableArrays.java
@@ -1077,11 +1077,11 @@
 
     static boolean compile_and_run_again_if_deoptimized(boolean warmup, String test) {
         if (!warmup) {
             Method m = tests.get(test);
             if (USE_COMPILER &&  !WHITE_BOX.isMethodCompiled(m, false)) {
-                if (!ValueTypeArrayFlatten && !XCOMP) {
+                if (!ValueTypeArrayFlatten && !XCOMP && !STRESS_CC) {
                     throw new RuntimeException("Unexpected deoptimization");
                 }
                 enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
                 return true;
             }
@@ -1173,11 +1173,11 @@
             Method m = tests.get("TestNullableArrays::test38");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test38(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1222,11 +1222,11 @@
             Method m = tests.get("TestNullableArrays::test40");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test40(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1266,11 +1266,11 @@
         }
         test42(src, dst);
         verify(src, dst);
         if (!warmup) {
             Method m = tests.get("TestNullableArrays::test42");
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1354,11 +1354,11 @@
             Method m = tests.get("TestNullableArrays::test46");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test46(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1401,11 +1401,11 @@
             Method m = tests.get("TestNullableArrays::test48");
             assertDeoptimizedByC2(m);
             enqueueMethodForCompilation(m, COMP_LEVEL_FULL_OPTIMIZATION);
             test48(src, dst);
             verify(dst, src);
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
@@ -1443,11 +1443,11 @@
         }
         test50(src, dst);
         verify(src, dst);
         if (!warmup) {
             Method m = tests.get("TestNullableArrays::test50");
-            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP) {
+            if (USE_COMPILER && !WHITE_BOX.isMethodCompiled(m, false) && !XCOMP && !STRESS_CC) {
                 throw new RuntimeException("unexpected deoptimization");
             }
         }
     }
 
diff a/test/hotspot/jtreg/compiler/valhalla/valuetypes/ValueTypeTest.java b/test/hotspot/jtreg/compiler/valhalla/valuetypes/ValueTypeTest.java
--- a/test/hotspot/jtreg/compiler/valhalla/valuetypes/ValueTypeTest.java
+++ b/test/hotspot/jtreg/compiler/valhalla/valuetypes/ValueTypeTest.java
@@ -140,10 +140,11 @@
     private static final int WARMUP = Integer.parseInt(System.getProperty("Warmup", "251"));
     private static final boolean DUMP_REPLAY = Boolean.parseBoolean(System.getProperty("DumpReplay", "false"));
     private static final boolean FLIP_C1_C2 = Boolean.parseBoolean(System.getProperty("FlipC1C2", "false"));
     private static final boolean GC_AFTER = Boolean.parseBoolean(System.getProperty("GCAfter", "false"));
     private static final int OSR_TEST_TIMEOUT = Integer.parseInt(System.getProperty("OSRTestTimeOut", "5000"));
+    protected static final boolean STRESS_CC = Boolean.parseBoolean(System.getProperty("StressCC", "false"));
 
     // "jtreg -DXcomp=true" runs all the scenarios with -Xcomp. This is faster than "jtreg -javaoptions:-Xcomp".
     protected static final boolean RUN_SCENARIOS_WITH_XCOMP = Boolean.parseBoolean(System.getProperty("Xcomp", "false"));
 
     // Pre-defined settings
@@ -623,10 +624,17 @@
             }
             if (m.isAnnotationPresent(DontInline.class)) {
                 Asserts.assertFalse(m.isAnnotationPresent(ForceInline.class), "Method " + m.getName() + " has contradicting ForceInline annotation");
                 WHITE_BOX.testSetDontInlineMethod(m, true);
             }
+            if (STRESS_CC) {
+                // Exclude some methods from compilation with C2 to stress test the calling convention
+                if (Utils.getRandomInstance().nextBoolean()) {
+                    System.out.println("Excluding from C2 compilation: " + m);
+                    WHITE_BOX.makeMethodNotCompilable(m, COMP_LEVEL_FULL_OPTIMIZATION, false);
+                }
+            }
         }
         // Only force compilation now because above annotations affect inlining
         for (Method m : methods) {
             if (m.isAnnotationPresent(ForceCompile.class)) {
                 Asserts.assertFalse(m.isAnnotationPresent(DontCompile.class), "Method " + m.getName() + " has contradicting DontCompile annotation");
@@ -638,11 +646,11 @@
         int compLevel = getCompLevel(null);
         WHITE_BOX.enqueueInitializerForCompilation(clazz, compLevel);
     }
 
     private void run(Class<?>... classes) throws Exception {
-        if (USE_COMPILER && PRINT_IDEAL && !XCOMP) {
+        if (USE_COMPILER && PRINT_IDEAL && !XCOMP && !STRESS_CC) {
             System.out.println("PrintIdeal enabled");
         }
         System.out.format("rI = %d, rL = %d\n", rI, rL);
 
         setup(getClass());
@@ -699,19 +707,17 @@
 
                     boolean b = WHITE_BOX.isMethodCompiled(test, false);
                     if (VERBOSE) {
                         System.out.println("Is " + test.getName() + " compiled? " + b);
                     }
-                    if (b || XCOMP || !USE_COMPILER) {
+                    if (b || XCOMP || STRESS_CC || !USE_COMPILER) {
                         // Don't control compilation if -Xcomp is enabled, or if compiler is disabled
                         break;
                     }
                     Asserts.assertTrue(OSR_TEST_TIMEOUT < 0 || elapsed < OSR_TEST_TIMEOUT, test + " not compiled after " + OSR_TEST_TIMEOUT + " ms");
                 }
-                if (!XCOMP) {
-                    Asserts.assertTrue(!USE_COMPILER || WHITE_BOX.isMethodCompiled(test, false), test + " not compiled");
-                }
+                Asserts.assertTrue(XCOMP || STRESS_CC || !USE_COMPILER || WHITE_BOX.isMethodCompiled(test, false), test + " not compiled");
             } else {
                 int compLevel = getCompLevel(test.getAnnotation(Test.class));
                 // Trigger compilation
                 enqueueMethodForCompilation(test, compLevel);
                 if (maybeCodeBufferOverflow && !WHITE_BOX.isMethodCompiled(test, false)) {
@@ -719,11 +725,11 @@
                     WHITE_BOX.setBooleanVMFlag("VerifyOops", false);
                     WHITE_BOX.clearMethodState(test);
                     enqueueMethodForCompilation(test, compLevel);
                     WHITE_BOX.setBooleanVMFlag("VerifyOops", true);
                 }
-                Asserts.assertTrue(!USE_COMPILER || WHITE_BOX.isMethodCompiled(test, false), test + " not compiled");
+                Asserts.assertTrue(STRESS_CC || !USE_COMPILER || WHITE_BOX.isMethodCompiled(test, false), test + " not compiled");
                 // Check result
                 verifier.invoke(this, false);
             }
             if (PRINT_TIMES || VERBOSE) {
                 long endTime = System.nanoTime();
