<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/deoptimization.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../prims/jvmtiRedefineClasses.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="fieldDescriptor.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/deoptimization.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  32 #include &quot;code/codeCache.hpp&quot;
  33 #include &quot;code/debugInfoRec.hpp&quot;
  34 #include &quot;code/nmethod.hpp&quot;
  35 #include &quot;code/pcDesc.hpp&quot;
  36 #include &quot;code/scopeDesc.hpp&quot;
  37 #include &quot;compiler/compilationPolicy.hpp&quot;
  38 #include &quot;interpreter/bytecode.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;interpreter/oopMapCache.hpp&quot;
  41 #include &quot;memory/allocation.inline.hpp&quot;
  42 #include &quot;memory/oopFactory.hpp&quot;
  43 #include &quot;memory/resourceArea.hpp&quot;
  44 #include &quot;memory/universe.hpp&quot;
  45 #include &quot;oops/constantPool.hpp&quot;
  46 #include &quot;oops/method.hpp&quot;
  47 #include &quot;oops/objArrayKlass.hpp&quot;
  48 #include &quot;oops/objArrayOop.inline.hpp&quot;
  49 #include &quot;oops/oop.inline.hpp&quot;
  50 #include &quot;oops/fieldStreams.inline.hpp&quot;
  51 #include &quot;oops/typeArrayOop.inline.hpp&quot;



  52 #include &quot;oops/verifyOopClosure.hpp&quot;
  53 #include &quot;prims/jvmtiThreadState.hpp&quot;
  54 #include &quot;runtime/atomic.hpp&quot;
  55 #include &quot;runtime/biasedLocking.hpp&quot;
  56 #include &quot;runtime/deoptimization.hpp&quot;
  57 #include &quot;runtime/fieldDescriptor.hpp&quot;
  58 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  59 #include &quot;runtime/frame.inline.hpp&quot;
  60 #include &quot;runtime/handles.inline.hpp&quot;
  61 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  62 #include &quot;runtime/jniHandles.inline.hpp&quot;
  63 #include &quot;runtime/safepointVerifiers.hpp&quot;
  64 #include &quot;runtime/sharedRuntime.hpp&quot;
  65 #include &quot;runtime/signature.hpp&quot;
  66 #include &quot;runtime/stubRoutines.hpp&quot;
  67 #include &quot;runtime/thread.hpp&quot;
  68 #include &quot;runtime/threadSMR.hpp&quot;
  69 #include &quot;runtime/vframe.hpp&quot;
  70 #include &quot;runtime/vframeArray.hpp&quot;
  71 #include &quot;runtime/vframe_hp.hpp&quot;
</pre>
<hr />
<pre>
 165   return fetch_unroll_info_helper(thread, exec_mode);
 166 JRT_END
 167 
 168 #if COMPILER2_OR_JVMCI
 169 static bool eliminate_allocations(JavaThread* thread, int exec_mode, CompiledMethod* compiled_method,
 170                                   frame&amp; deoptee, RegisterMap&amp; map, GrowableArray&lt;compiledVFrame*&gt;* chunk) {
 171   bool realloc_failures = false;
 172   assert (chunk-&gt;at(0)-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 173 
 174   GrowableArray&lt;ScopeValue*&gt;* objects = chunk-&gt;at(0)-&gt;scope()-&gt;objects();
 175 
 176   // The flag return_oop() indicates call sites which return oop
 177   // in compiled code. Such sites include java method calls,
 178   // runtime calls (for example, used to allocate new objects/arrays
 179   // on slow code path) and any other calls generated in compiled code.
 180   // It is not guaranteed that we can get such information here only
 181   // by analyzing bytecode in deoptimized frames. This is why this flag
 182   // is set during method compilation (see Compile::Process_OopMap_Node()).
 183   // If the previous frame was popped or if we are dispatching an exception,
 184   // we don&#39;t have an oop result.
<span class="line-modified"> 185   bool save_oop_result = chunk-&gt;at(0)-&gt;scope()-&gt;return_oop() &amp;&amp; !thread-&gt;popframe_forcing_deopt_reexecution() &amp;&amp; (exec_mode == Deoptimization::Unpack_deopt);</span>
<span class="line-modified"> 186   Handle return_value;</span>











 187   if (save_oop_result) {
 188     // Reallocation may trigger GC. If deoptimization happened on return from
 189     // call which returns oop we need to save it since it is not in oopmap.
 190     oop result = deoptee.saved_oop_result(&amp;map);
 191     assert(oopDesc::is_oop_or_null(result), &quot;must be oop&quot;);
<span class="line-modified"> 192     return_value = Handle(thread, result);</span>
 193     assert(Universe::heap()-&gt;is_in_or_null(result), &quot;must be heap pointer&quot;);
 194     if (TraceDeoptimization) {
 195       ttyLocker ttyl;
 196       tty-&gt;print_cr(&quot;SAVED OOP RESULT &quot; INTPTR_FORMAT &quot; in thread &quot; INTPTR_FORMAT, p2i(result), p2i(thread));
 197     }
 198   }
<span class="line-modified"> 199   if (objects != NULL) {</span>

 200     JRT_BLOCK
<span class="line-modified"> 201       realloc_failures = Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);</span>






 202     JRT_END
<span class="line-removed"> 203     bool skip_internal = (compiled_method != NULL) &amp;&amp; !compiled_method-&gt;is_compiled_by_jvmci();</span>
<span class="line-removed"> 204     Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal);</span>
 205 #ifndef PRODUCT
 206     if (TraceDeoptimization) {
 207       ttyLocker ttyl;
 208       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
<span class="line-modified"> 209       Deoptimization::print_objects(objects, realloc_failures);</span>





 210     }
 211 #endif
 212   }
<span class="line-modified"> 213   if (save_oop_result) {</span>
 214     // Restore result.
<span class="line-modified"> 215     deoptee.set_saved_oop_result(&amp;map, return_value());</span>

 216   }
 217   return realloc_failures;
 218 }
 219 
 220 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 221 #ifndef PRODUCT
 222   bool first = true;
 223 #endif
 224   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 225     compiledVFrame* cvf = chunk-&gt;at(i);
 226     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 227     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 228     if (monitors-&gt;is_nonempty()) {
 229       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 230 #ifndef PRODUCT
 231       if (PrintDeoptimizationDetails) {
 232         ttyLocker ttyl;
 233         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 234           MonitorInfo* mi = monitors-&gt;at(j);
 235           if (mi-&gt;eliminated()) {
</pre>
<hr />
<pre>
 496   // its caller&#39;s stack by. If the caller is a compiled frame then
 497   // we pretend that the callee has no parameters so that the
 498   // extension counts for the full amount of locals and not just
 499   // locals-parms. This is because without a c2i adapter the parm
 500   // area as created by the compiled frame will not be usable by
 501   // the interpreter. (Depending on the calling convention there
 502   // may not even be enough space).
 503 
 504   // QQQ I&#39;d rather see this pushed down into last_frame_adjust
 505   // and have it take the sender (aka caller).
 506 
 507   if (deopt_sender.is_compiled_frame() || caller_was_method_handle) {
 508     caller_adjustment = last_frame_adjust(0, callee_locals);
 509   } else if (callee_locals &gt; callee_parameters) {
 510     // The caller frame may need extending to accommodate
 511     // non-parameter locals of the first unpacked interpreted frame.
 512     // Compute that adjustment.
 513     caller_adjustment = last_frame_adjust(callee_parameters, callee_locals);
 514   }
 515 
<span class="line-modified"> 516   // If the sender is deoptimized the we must retrieve the address of the handler</span>
 517   // since the frame will &quot;magically&quot; show the original pc before the deopt
 518   // and we&#39;d undo the deopt.
 519 
 520   frame_pcs[0] = deopt_sender.raw_pc();
 521 
 522   assert(CodeCache::find_blob_unsafe(frame_pcs[0]) != NULL, &quot;bad pc&quot;);
 523 
 524 #if INCLUDE_JVMCI
 525   if (exceptionObject() != NULL) {
 526     thread-&gt;set_exception_oop(exceptionObject());
 527     exec_mode = Unpack_exception;
 528   }
 529 #endif
 530 
 531   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0 &amp;&amp; exec_mode != Unpack_uncommon_trap) {
 532     assert(thread-&gt;has_pending_exception(), &quot;should have thrown OOME&quot;);
 533     thread-&gt;set_exception_oop(thread-&gt;pending_exception());
 534     thread-&gt;clear_pending_exception();
 535     exec_mode = Unpack_exception;
 536   }
</pre>
<hr />
<pre>
 994 
 995     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
 996     oop obj = NULL;
 997 
 998     if (k-&gt;is_instance_klass()) {
 999 #if INCLUDE_JVMCI || INCLUDE_AOT
1000       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
1001       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
1002         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
1003         obj = get_cached_box(abv, fr, reg_map, THREAD);
1004         if (obj != NULL) {
1005           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
1006           abv-&gt;set_cached(true);
1007         }
1008       }
1009 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1010       InstanceKlass* ik = InstanceKlass::cast(k);
1011       if (obj == NULL) {
1012         obj = ik-&gt;allocate_instance(THREAD);
1013       }




1014     } else if (k-&gt;is_typeArray_klass()) {
1015       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1016       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1017       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1018       obj = ak-&gt;allocate(len, THREAD);
1019     } else if (k-&gt;is_objArray_klass()) {
1020       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1021       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1022     }
1023 
1024     if (obj == NULL) {
1025       failures = true;
1026     }
1027 
1028     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1029     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1030     CLEAR_PENDING_EXCEPTION;
1031     sv-&gt;set_value(obj);
1032   }
1033 
1034   if (failures) {
1035     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), failures);
1036   } else if (pending_exception.not_null()) {
1037     thread-&gt;set_pending_exception(pending_exception(), exception_file, exception_line);
1038   }
1039 
1040   return failures;
1041 }
1042 















1043 #if INCLUDE_JVMCI
1044 /**
1045  * For primitive types whose kind gets &quot;erased&quot; at runtime (shorts become stack ints),
1046  * we need to somehow be able to recover the actual kind to be able to write the correct
1047  * amount of bytes.
1048  * For that purpose, this method assumes that, for an entry spanning n bytes at index i,
1049  * the entries at index n + 1 to n + i are &#39;markers&#39;.
1050  * For example, if we were writing a short at index 4 of a byte array of size 8, the
1051  * expected form of the array would be:
1052  *
1053  * {b0, b1, b2, b3, INT, marker, b6, b7}
1054  *
1055  * Thus, in order to get back the size of the entry, we simply need to count the number
1056  * of marked entries
1057  *
1058  * @param virtualArray the virtualized byte array
1059  * @param i index of the virtual entry we are recovering
1060  * @return The number of bytes the entry spans
1061  */
1062 static int count_number_of_bytes_for_entry(ObjectValue *virtualArray, int i) {
</pre>
<hr />
<pre>
1195       default:
1196         ShouldNotReachHere();
1197     }
1198     index++;
1199   }
1200 }
1201 
1202 // restore fields of an eliminated object array
1203 void Deoptimization::reassign_object_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, objArrayOop obj) {
1204   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {
1205     StackValue* value = StackValue::create_stack_value(fr, reg_map, sv-&gt;field_at(i));
1206     assert(value-&gt;type() == T_OBJECT, &quot;object element expected&quot;);
1207     obj-&gt;obj_at_put(i, value-&gt;get_obj()());
1208   }
1209 }
1210 
1211 class ReassignedField {
1212 public:
1213   int _offset;
1214   BasicType _type;

1215 public:
1216   ReassignedField() {
1217     _offset = 0;
1218     _type = T_ILLEGAL;

1219   }
1220 };
1221 
1222 int compare(ReassignedField* left, ReassignedField* right) {
1223   return left-&gt;_offset - right-&gt;_offset;
1224 }
1225 
1226 // Restore fields of an eliminated instance object using the same field order
1227 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
<span class="line-modified">1228 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {</span>

1229   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1230   InstanceKlass* ik = klass;
1231   while (ik != NULL) {
1232     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1233       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1234         ReassignedField field;
1235         field._offset = fs.offset();
1236         field._type = Signature::basic_type(fs.signature());









1237         fields-&gt;append(field);
1238       }
1239     }
1240     ik = ik-&gt;superklass();
1241   }
1242   fields-&gt;sort(compare);
1243   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1244     intptr_t val;
1245     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1246     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
<span class="line-modified">1247     int offset = fields-&gt;at(i)._offset;</span>
1248     BasicType type = fields-&gt;at(i)._type;
1249     switch (type) {
<span class="line-modified">1250       case T_OBJECT: case T_ARRAY:</span>

1251         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1252         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1253         break;
1254 









1255       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1256       case T_INT: case T_FLOAT: { // 4 bytes.
1257         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1258         bool big_value = false;
1259         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1260           if (scope_field-&gt;is_location()) {
1261             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1262             if (type == Location::dbl || type == Location::lng) {
1263               big_value = true;
1264             }
1265           }
1266           if (scope_field-&gt;is_constant_int()) {
1267             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
1268             if (next_scope_field-&gt;is_constant_long() || next_scope_field-&gt;is_constant_double()) {
1269               big_value = true;
1270             }
1271           }
1272         }
1273 
1274         if (big_value) {
</pre>
<hr />
<pre>
1310       case T_BYTE:
1311         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1312         val = value-&gt;get_int();
1313         obj-&gt;byte_field_put(offset, (jbyte)*((jint*)&amp;val));
1314         break;
1315 
1316       case T_BOOLEAN:
1317         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1318         val = value-&gt;get_int();
1319         obj-&gt;bool_field_put(offset, (jboolean)*((jint*)&amp;val));
1320         break;
1321 
1322       default:
1323         ShouldNotReachHere();
1324     }
1325     svIndex++;
1326   }
1327   return svIndex;
1328 }
1329 














1330 // restore fields of all eliminated objects and arrays
<span class="line-modified">1331 void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures, bool skip_internal) {</span>
1332   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1333     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1334     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1335     Handle obj = sv-&gt;value();
1336     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);
1337     if (PrintDeoptimizationDetails) {
1338       tty-&gt;print_cr(&quot;reassign fields for object of type %s!&quot;, k-&gt;name()-&gt;as_C_string());
1339     }
1340     if (obj.is_null()) {
1341       continue;
1342     }
1343 #if INCLUDE_JVMCI || INCLUDE_AOT
1344     // Don&#39;t reassign fields of boxes that came from a cache. Caches may be in CDS.
1345     if (sv-&gt;is_auto_box() &amp;&amp; ((AutoBoxObjectValue*) sv)-&gt;is_cached()) {
1346       continue;
1347     }
1348 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1349     if (k-&gt;is_instance_klass()) {
1350       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1351       reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);</span>



1352     } else if (k-&gt;is_typeArray_klass()) {
1353       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1354       reassign_type_array_elements(fr, reg_map, sv, (typeArrayOop) obj(), ak-&gt;element_type());
1355     } else if (k-&gt;is_objArray_klass()) {
1356       reassign_object_array_elements(fr, reg_map, sv, (objArrayOop) obj());
1357     }
1358   }
1359 }
1360 
1361 
1362 // relock objects for which synchronization was eliminated
1363 void Deoptimization::relock_objects(GrowableArray&lt;MonitorInfo*&gt;* monitors, JavaThread* thread, bool realloc_failures) {
1364   for (int i = 0; i &lt; monitors-&gt;length(); i++) {
1365     MonitorInfo* mon_info = monitors-&gt;at(i);
1366     if (mon_info-&gt;eliminated()) {
1367       assert(!mon_info-&gt;owner_is_scalar_replaced() || realloc_failures, &quot;reallocation was missed&quot;);
1368       if (!mon_info-&gt;owner_is_scalar_replaced()) {
1369         Handle obj(thread, mon_info-&gt;owner());
1370         markWord mark = obj-&gt;mark();
1371         if (UseBiasedLocking &amp;&amp; mark.has_bias_pattern()) {
</pre>
<hr />
<pre>
1374           // where the thread-local object is bias locked to the current thread.
1375           assert(mark.is_biased_anonymously() ||
1376                  mark.biased_locker() == thread, &quot;should be locked to current thread&quot;);
1377           // Reset mark word to unbiased prototype.
1378           markWord unbiased_prototype = markWord::prototype().set_age(mark.age());
1379           obj-&gt;set_mark(unbiased_prototype);
1380         }
1381         BasicLock* lock = mon_info-&gt;lock();
1382         ObjectSynchronizer::enter(obj, lock, thread);
1383         assert(mon_info-&gt;owner()-&gt;is_locked(), &quot;object must be locked now&quot;);
1384       }
1385     }
1386   }
1387 }
1388 
1389 
1390 #ifndef PRODUCT
1391 // print information about reallocated objects
1392 void Deoptimization::print_objects(GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures) {
1393   fieldDescriptor fd;
<span class="line-removed">1394 </span>
1395   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1396     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1397     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
<span class="line-modified">1398     Handle obj = sv-&gt;value();</span>


1399 
<span class="line-modified">1400     tty-&gt;print(&quot;     object &lt;&quot; INTPTR_FORMAT &quot;&gt; of type &quot;, p2i(sv-&gt;value()()));</span>
<span class="line-modified">1401     k-&gt;print_value();</span>
<span class="line-modified">1402     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);</span>
<span class="line-modified">1403     if (obj.is_null()) {</span>
<span class="line-modified">1404       tty-&gt;print(&quot; allocation failed&quot;);</span>
<span class="line-modified">1405     } else {</span>
<span class="line-modified">1406       tty-&gt;print(&quot; allocated (%d bytes)&quot;, obj-&gt;size() * HeapWordSize);</span>
<span class="line-modified">1407     }</span>
<span class="line-modified">1408     tty-&gt;cr();</span>

1409 
<span class="line-modified">1410     if (Verbose &amp;&amp; !obj.is_null()) {</span>
<span class="line-modified">1411       k-&gt;oop_print_on(obj(), tty);</span>
<span class="line-removed">1412     }</span>
1413   }
1414 }
1415 #endif
1416 #endif // COMPILER2_OR_JVMCI
1417 
1418 vframeArray* Deoptimization::create_vframeArray(JavaThread* thread, frame fr, RegisterMap *reg_map, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
1419   Events::log_deopt_message(thread, &quot;DEOPT PACKING pc=&quot; INTPTR_FORMAT &quot; sp=&quot; INTPTR_FORMAT, p2i(fr.pc()), p2i(fr.sp()));
1420 
1421 #ifndef PRODUCT
1422   if (PrintDeoptimizationDetails) {
1423     ttyLocker ttyl;
1424     tty-&gt;print(&quot;DEOPT PACKING thread &quot; INTPTR_FORMAT &quot; &quot;, p2i(thread));
1425     fr.print_on(tty);
1426     tty-&gt;print_cr(&quot;     Virtual frames (innermost first):&quot;);
1427     for (int index = 0; index &lt; chunk-&gt;length(); index++) {
1428       compiledVFrame* vf = chunk-&gt;at(index);
1429       tty-&gt;print(&quot;       %2d - &quot;, index);
1430       vf-&gt;print_value();
1431       int bci = chunk-&gt;at(index)-&gt;raw_bci();
1432       const char* code_name;
</pre>
<hr />
<pre>
1565 
1566     ttyLocker ttyl;
1567     xtty-&gt;begin_head(&quot;deoptimized thread=&#39;&quot; UINTX_FORMAT &quot;&#39; reason=&#39;%s&#39; pc=&#39;&quot; INTPTR_FORMAT &quot;&#39;&quot;,(uintx)thread-&gt;osthread()-&gt;thread_id(), trap_reason_name(reason), p2i(fr.pc()));
1568     cm-&gt;log_identity(xtty);
1569     xtty-&gt;end_head();
1570     for (ScopeDesc* sd = cm-&gt;scope_desc_at(fr.pc()); ; sd = sd-&gt;sender()) {
1571       xtty-&gt;begin_elem(&quot;jvms bci=&#39;%d&#39;&quot;, sd-&gt;bci());
1572       xtty-&gt;method(sd-&gt;method());
1573       xtty-&gt;end_elem();
1574       if (sd-&gt;is_top())  break;
1575     }
1576     xtty-&gt;tail(&quot;deoptimized&quot;);
1577   }
1578 
1579   // Patch the compiled method so that when execution returns to it we will
1580   // deopt the execution state and return to the interpreter.
1581   fr.deoptimize(thread);
1582 }
1583 
1584 void Deoptimization::deoptimize(JavaThread* thread, frame fr, DeoptReason reason) {
<span class="line-modified">1585   // Deoptimize only if the frame comes from compile code.</span>
1586   // Do not deoptimize the frame which is already patched
1587   // during the execution of the loops below.
1588   if (!fr.is_compiled_frame() || fr.is_deoptimized_frame()) {
1589     return;
1590   }
1591   ResourceMark rm;
1592   DeoptimizationMarker dm;
1593   deoptimize_single_frame(thread, fr, reason);
1594 }
1595 
1596 #if INCLUDE_JVMCI
1597 address Deoptimization::deoptimize_for_missing_exception_handler(CompiledMethod* cm) {
1598   // there is no exception handler for this pc =&gt; deoptimize
1599   cm-&gt;make_not_entrant();
1600 
1601   // Use Deoptimization::deoptimize for all of its side-effects:
1602   // gathering traps statistics, logging...
1603   // it also patches the return pc but we do not care about that
1604   // since we return a continuation to the deopt_blob below.
1605   JavaThread* thread = JavaThread::current();
</pre>
</td>
<td>
<hr />
<pre>
  32 #include &quot;code/codeCache.hpp&quot;
  33 #include &quot;code/debugInfoRec.hpp&quot;
  34 #include &quot;code/nmethod.hpp&quot;
  35 #include &quot;code/pcDesc.hpp&quot;
  36 #include &quot;code/scopeDesc.hpp&quot;
  37 #include &quot;compiler/compilationPolicy.hpp&quot;
  38 #include &quot;interpreter/bytecode.hpp&quot;
  39 #include &quot;interpreter/interpreter.hpp&quot;
  40 #include &quot;interpreter/oopMapCache.hpp&quot;
  41 #include &quot;memory/allocation.inline.hpp&quot;
  42 #include &quot;memory/oopFactory.hpp&quot;
  43 #include &quot;memory/resourceArea.hpp&quot;
  44 #include &quot;memory/universe.hpp&quot;
  45 #include &quot;oops/constantPool.hpp&quot;
  46 #include &quot;oops/method.hpp&quot;
  47 #include &quot;oops/objArrayKlass.hpp&quot;
  48 #include &quot;oops/objArrayOop.inline.hpp&quot;
  49 #include &quot;oops/oop.inline.hpp&quot;
  50 #include &quot;oops/fieldStreams.inline.hpp&quot;
  51 #include &quot;oops/typeArrayOop.inline.hpp&quot;
<span class="line-added">  52 #include &quot;oops/valueArrayKlass.hpp&quot;</span>
<span class="line-added">  53 #include &quot;oops/valueArrayOop.hpp&quot;</span>
<span class="line-added">  54 #include &quot;oops/valueKlass.inline.hpp&quot;</span>
  55 #include &quot;oops/verifyOopClosure.hpp&quot;
  56 #include &quot;prims/jvmtiThreadState.hpp&quot;
  57 #include &quot;runtime/atomic.hpp&quot;
  58 #include &quot;runtime/biasedLocking.hpp&quot;
  59 #include &quot;runtime/deoptimization.hpp&quot;
  60 #include &quot;runtime/fieldDescriptor.hpp&quot;
  61 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  62 #include &quot;runtime/frame.inline.hpp&quot;
  63 #include &quot;runtime/handles.inline.hpp&quot;
  64 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  65 #include &quot;runtime/jniHandles.inline.hpp&quot;
  66 #include &quot;runtime/safepointVerifiers.hpp&quot;
  67 #include &quot;runtime/sharedRuntime.hpp&quot;
  68 #include &quot;runtime/signature.hpp&quot;
  69 #include &quot;runtime/stubRoutines.hpp&quot;
  70 #include &quot;runtime/thread.hpp&quot;
  71 #include &quot;runtime/threadSMR.hpp&quot;
  72 #include &quot;runtime/vframe.hpp&quot;
  73 #include &quot;runtime/vframeArray.hpp&quot;
  74 #include &quot;runtime/vframe_hp.hpp&quot;
</pre>
<hr />
<pre>
 168   return fetch_unroll_info_helper(thread, exec_mode);
 169 JRT_END
 170 
 171 #if COMPILER2_OR_JVMCI
 172 static bool eliminate_allocations(JavaThread* thread, int exec_mode, CompiledMethod* compiled_method,
 173                                   frame&amp; deoptee, RegisterMap&amp; map, GrowableArray&lt;compiledVFrame*&gt;* chunk) {
 174   bool realloc_failures = false;
 175   assert (chunk-&gt;at(0)-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 176 
 177   GrowableArray&lt;ScopeValue*&gt;* objects = chunk-&gt;at(0)-&gt;scope()-&gt;objects();
 178 
 179   // The flag return_oop() indicates call sites which return oop
 180   // in compiled code. Such sites include java method calls,
 181   // runtime calls (for example, used to allocate new objects/arrays
 182   // on slow code path) and any other calls generated in compiled code.
 183   // It is not guaranteed that we can get such information here only
 184   // by analyzing bytecode in deoptimized frames. This is why this flag
 185   // is set during method compilation (see Compile::Process_OopMap_Node()).
 186   // If the previous frame was popped or if we are dispatching an exception,
 187   // we don&#39;t have an oop result.
<span class="line-modified"> 188   ScopeDesc* scope = chunk-&gt;at(0)-&gt;scope();</span>
<span class="line-modified"> 189   bool save_oop_result = scope-&gt;return_oop() &amp;&amp; !thread-&gt;popframe_forcing_deopt_reexecution() &amp;&amp; (exec_mode == Deoptimization::Unpack_deopt);</span>
<span class="line-added"> 190   // In case of the return of multiple values, we must take care</span>
<span class="line-added"> 191   // of all oop return values.</span>
<span class="line-added"> 192   GrowableArray&lt;Handle&gt; return_oops;</span>
<span class="line-added"> 193   ValueKlass* vk = NULL;</span>
<span class="line-added"> 194   if (save_oop_result &amp;&amp; scope-&gt;return_vt()) {</span>
<span class="line-added"> 195     vk = ValueKlass::returned_value_klass(map);</span>
<span class="line-added"> 196     if (vk != NULL) {</span>
<span class="line-added"> 197       vk-&gt;save_oop_fields(map, return_oops);</span>
<span class="line-added"> 198       save_oop_result = false;</span>
<span class="line-added"> 199     }</span>
<span class="line-added"> 200   }</span>
 201   if (save_oop_result) {
 202     // Reallocation may trigger GC. If deoptimization happened on return from
 203     // call which returns oop we need to save it since it is not in oopmap.
 204     oop result = deoptee.saved_oop_result(&amp;map);
 205     assert(oopDesc::is_oop_or_null(result), &quot;must be oop&quot;);
<span class="line-modified"> 206     return_oops.push(Handle(thread, result));</span>
 207     assert(Universe::heap()-&gt;is_in_or_null(result), &quot;must be heap pointer&quot;);
 208     if (TraceDeoptimization) {
 209       ttyLocker ttyl;
 210       tty-&gt;print_cr(&quot;SAVED OOP RESULT &quot; INTPTR_FORMAT &quot; in thread &quot; INTPTR_FORMAT, p2i(result), p2i(thread));
 211     }
 212   }
<span class="line-modified"> 213   if (objects != NULL || vk != NULL) {</span>
<span class="line-added"> 214     bool skip_internal = (compiled_method != NULL) &amp;&amp; !compiled_method-&gt;is_compiled_by_jvmci();</span>
 215     JRT_BLOCK
<span class="line-modified"> 216       if (vk != NULL) {</span>
<span class="line-added"> 217         realloc_failures = Deoptimization::realloc_value_type_result(vk, map, return_oops, THREAD);</span>
<span class="line-added"> 218       }</span>
<span class="line-added"> 219       if (objects != NULL) {</span>
<span class="line-added"> 220         realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);</span>
<span class="line-added"> 221         Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal, THREAD);</span>
<span class="line-added"> 222       }</span>
 223     JRT_END


 224 #ifndef PRODUCT
 225     if (TraceDeoptimization) {
 226       ttyLocker ttyl;
 227       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
<span class="line-modified"> 228       if (objects != NULL) {</span>
<span class="line-added"> 229         Deoptimization::print_objects(objects, realloc_failures);</span>
<span class="line-added"> 230       } else {</span>
<span class="line-added"> 231         Handle obj = realloc_failures ? Handle() : return_oops.first();</span>
<span class="line-added"> 232         Deoptimization::print_object(vk, obj, realloc_failures);</span>
<span class="line-added"> 233       }</span>
 234     }
 235 #endif
 236   }
<span class="line-modified"> 237   if (save_oop_result || vk != NULL) {</span>
 238     // Restore result.
<span class="line-modified"> 239     assert(return_oops.length() == 1, &quot;no value type&quot;);</span>
<span class="line-added"> 240     deoptee.set_saved_oop_result(&amp;map, return_oops.pop()());</span>
 241   }
 242   return realloc_failures;
 243 }
 244 
 245 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 246 #ifndef PRODUCT
 247   bool first = true;
 248 #endif
 249   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 250     compiledVFrame* cvf = chunk-&gt;at(i);
 251     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 252     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 253     if (monitors-&gt;is_nonempty()) {
 254       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 255 #ifndef PRODUCT
 256       if (PrintDeoptimizationDetails) {
 257         ttyLocker ttyl;
 258         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 259           MonitorInfo* mi = monitors-&gt;at(j);
 260           if (mi-&gt;eliminated()) {
</pre>
<hr />
<pre>
 521   // its caller&#39;s stack by. If the caller is a compiled frame then
 522   // we pretend that the callee has no parameters so that the
 523   // extension counts for the full amount of locals and not just
 524   // locals-parms. This is because without a c2i adapter the parm
 525   // area as created by the compiled frame will not be usable by
 526   // the interpreter. (Depending on the calling convention there
 527   // may not even be enough space).
 528 
 529   // QQQ I&#39;d rather see this pushed down into last_frame_adjust
 530   // and have it take the sender (aka caller).
 531 
 532   if (deopt_sender.is_compiled_frame() || caller_was_method_handle) {
 533     caller_adjustment = last_frame_adjust(0, callee_locals);
 534   } else if (callee_locals &gt; callee_parameters) {
 535     // The caller frame may need extending to accommodate
 536     // non-parameter locals of the first unpacked interpreted frame.
 537     // Compute that adjustment.
 538     caller_adjustment = last_frame_adjust(callee_parameters, callee_locals);
 539   }
 540 
<span class="line-modified"> 541   // If the sender is deoptimized we must retrieve the address of the handler</span>
 542   // since the frame will &quot;magically&quot; show the original pc before the deopt
 543   // and we&#39;d undo the deopt.
 544 
 545   frame_pcs[0] = deopt_sender.raw_pc();
 546 
 547   assert(CodeCache::find_blob_unsafe(frame_pcs[0]) != NULL, &quot;bad pc&quot;);
 548 
 549 #if INCLUDE_JVMCI
 550   if (exceptionObject() != NULL) {
 551     thread-&gt;set_exception_oop(exceptionObject());
 552     exec_mode = Unpack_exception;
 553   }
 554 #endif
 555 
 556   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0 &amp;&amp; exec_mode != Unpack_uncommon_trap) {
 557     assert(thread-&gt;has_pending_exception(), &quot;should have thrown OOME&quot;);
 558     thread-&gt;set_exception_oop(thread-&gt;pending_exception());
 559     thread-&gt;clear_pending_exception();
 560     exec_mode = Unpack_exception;
 561   }
</pre>
<hr />
<pre>
1019 
1020     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1021     oop obj = NULL;
1022 
1023     if (k-&gt;is_instance_klass()) {
1024 #if INCLUDE_JVMCI || INCLUDE_AOT
1025       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
1026       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
1027         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
1028         obj = get_cached_box(abv, fr, reg_map, THREAD);
1029         if (obj != NULL) {
1030           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
1031           abv-&gt;set_cached(true);
1032         }
1033       }
1034 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1035       InstanceKlass* ik = InstanceKlass::cast(k);
1036       if (obj == NULL) {
1037         obj = ik-&gt;allocate_instance(THREAD);
1038       }
<span class="line-added">1039     } else if (k-&gt;is_valueArray_klass()) {</span>
<span class="line-added">1040       ValueArrayKlass* ak = ValueArrayKlass::cast(k);</span>
<span class="line-added">1041       // Value type array must be zeroed because not all memory is reassigned</span>
<span class="line-added">1042       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);</span>
1043     } else if (k-&gt;is_typeArray_klass()) {
1044       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1045       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1046       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1047       obj = ak-&gt;allocate(len, THREAD);
1048     } else if (k-&gt;is_objArray_klass()) {
1049       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1050       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1051     }
1052 
1053     if (obj == NULL) {
1054       failures = true;
1055     }
1056 
1057     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1058     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1059     CLEAR_PENDING_EXCEPTION;
1060     sv-&gt;set_value(obj);
1061   }
1062 
1063   if (failures) {
1064     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), failures);
1065   } else if (pending_exception.not_null()) {
1066     thread-&gt;set_pending_exception(pending_exception(), exception_file, exception_line);
1067   }
1068 
1069   return failures;
1070 }
1071 
<span class="line-added">1072 // We&#39;re deoptimizing at the return of a call, value type fields are</span>
<span class="line-added">1073 // in registers. When we go back to the interpreter, it will expect a</span>
<span class="line-added">1074 // reference to a value type instance. Allocate and initialize it from</span>
<span class="line-added">1075 // the register values here.</span>
<span class="line-added">1076 bool Deoptimization::realloc_value_type_result(ValueKlass* vk, const RegisterMap&amp; map, GrowableArray&lt;Handle&gt;&amp; return_oops, TRAPS) {</span>
<span class="line-added">1077   oop new_vt = vk-&gt;realloc_result(map, return_oops, THREAD);</span>
<span class="line-added">1078   if (new_vt == NULL) {</span>
<span class="line-added">1079     CLEAR_PENDING_EXCEPTION;</span>
<span class="line-added">1080     THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);</span>
<span class="line-added">1081   }</span>
<span class="line-added">1082   return_oops.clear();</span>
<span class="line-added">1083   return_oops.push(Handle(THREAD, new_vt));</span>
<span class="line-added">1084   return false;</span>
<span class="line-added">1085 }</span>
<span class="line-added">1086 </span>
1087 #if INCLUDE_JVMCI
1088 /**
1089  * For primitive types whose kind gets &quot;erased&quot; at runtime (shorts become stack ints),
1090  * we need to somehow be able to recover the actual kind to be able to write the correct
1091  * amount of bytes.
1092  * For that purpose, this method assumes that, for an entry spanning n bytes at index i,
1093  * the entries at index n + 1 to n + i are &#39;markers&#39;.
1094  * For example, if we were writing a short at index 4 of a byte array of size 8, the
1095  * expected form of the array would be:
1096  *
1097  * {b0, b1, b2, b3, INT, marker, b6, b7}
1098  *
1099  * Thus, in order to get back the size of the entry, we simply need to count the number
1100  * of marked entries
1101  *
1102  * @param virtualArray the virtualized byte array
1103  * @param i index of the virtual entry we are recovering
1104  * @return The number of bytes the entry spans
1105  */
1106 static int count_number_of_bytes_for_entry(ObjectValue *virtualArray, int i) {
</pre>
<hr />
<pre>
1239       default:
1240         ShouldNotReachHere();
1241     }
1242     index++;
1243   }
1244 }
1245 
1246 // restore fields of an eliminated object array
1247 void Deoptimization::reassign_object_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, objArrayOop obj) {
1248   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {
1249     StackValue* value = StackValue::create_stack_value(fr, reg_map, sv-&gt;field_at(i));
1250     assert(value-&gt;type() == T_OBJECT, &quot;object element expected&quot;);
1251     obj-&gt;obj_at_put(i, value-&gt;get_obj()());
1252   }
1253 }
1254 
1255 class ReassignedField {
1256 public:
1257   int _offset;
1258   BasicType _type;
<span class="line-added">1259   InstanceKlass* _klass;</span>
1260 public:
1261   ReassignedField() {
1262     _offset = 0;
1263     _type = T_ILLEGAL;
<span class="line-added">1264     _klass = NULL;</span>
1265   }
1266 };
1267 
1268 int compare(ReassignedField* left, ReassignedField* right) {
1269   return left-&gt;_offset - right-&gt;_offset;
1270 }
1271 
1272 // Restore fields of an eliminated instance object using the same field order
1273 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
<span class="line-modified">1274 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {</span>
<span class="line-added">1275 </span>
1276   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1277   InstanceKlass* ik = klass;
1278   while (ik != NULL) {
1279     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1280       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1281         ReassignedField field;
1282         field._offset = fs.offset();
1283         field._type = Signature::basic_type(fs.signature());
<span class="line-added">1284         if (field._type == T_VALUETYPE) {</span>
<span class="line-added">1285           field._type = T_OBJECT;</span>
<span class="line-added">1286         }</span>
<span class="line-added">1287         if (fs.is_flattened()) {</span>
<span class="line-added">1288           // Resolve klass of flattened value type field</span>
<span class="line-added">1289           Klass* vk = klass-&gt;get_value_field_klass(fs.index());</span>
<span class="line-added">1290           field._klass = ValueKlass::cast(vk);</span>
<span class="line-added">1291           field._type = T_VALUETYPE;</span>
<span class="line-added">1292         }</span>
1293         fields-&gt;append(field);
1294       }
1295     }
1296     ik = ik-&gt;superklass();
1297   }
1298   fields-&gt;sort(compare);
1299   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1300     intptr_t val;
1301     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1302     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
<span class="line-modified">1303     int offset = base_offset + fields-&gt;at(i)._offset;</span>
1304     BasicType type = fields-&gt;at(i)._type;
1305     switch (type) {
<span class="line-modified">1306       case T_OBJECT:</span>
<span class="line-added">1307       case T_ARRAY:</span>
1308         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1309         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1310         break;
1311 
<span class="line-added">1312       case T_VALUETYPE: {</span>
<span class="line-added">1313         // Recursively re-assign flattened value type fields</span>
<span class="line-added">1314         InstanceKlass* vk = fields-&gt;at(i)._klass;</span>
<span class="line-added">1315         assert(vk != NULL, &quot;must be resolved&quot;);</span>
<span class="line-added">1316         offset -= ValueKlass::cast(vk)-&gt;first_field_offset(); // Adjust offset to omit oop header</span>
<span class="line-added">1317         svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);</span>
<span class="line-added">1318         continue; // Continue because we don&#39;t need to increment svIndex</span>
<span class="line-added">1319       }</span>
<span class="line-added">1320 </span>
1321       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1322       case T_INT: case T_FLOAT: { // 4 bytes.
1323         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1324         bool big_value = false;
1325         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1326           if (scope_field-&gt;is_location()) {
1327             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1328             if (type == Location::dbl || type == Location::lng) {
1329               big_value = true;
1330             }
1331           }
1332           if (scope_field-&gt;is_constant_int()) {
1333             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
1334             if (next_scope_field-&gt;is_constant_long() || next_scope_field-&gt;is_constant_double()) {
1335               big_value = true;
1336             }
1337           }
1338         }
1339 
1340         if (big_value) {
</pre>
<hr />
<pre>
1376       case T_BYTE:
1377         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1378         val = value-&gt;get_int();
1379         obj-&gt;byte_field_put(offset, (jbyte)*((jint*)&amp;val));
1380         break;
1381 
1382       case T_BOOLEAN:
1383         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1384         val = value-&gt;get_int();
1385         obj-&gt;bool_field_put(offset, (jboolean)*((jint*)&amp;val));
1386         break;
1387 
1388       default:
1389         ShouldNotReachHere();
1390     }
1391     svIndex++;
1392   }
1393   return svIndex;
1394 }
1395 
<span class="line-added">1396 // restore fields of an eliminated value type array</span>
<span class="line-added">1397 void Deoptimization::reassign_value_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, valueArrayOop obj, ValueArrayKlass* vak, TRAPS) {</span>
<span class="line-added">1398   ValueKlass* vk = vak-&gt;element_klass();</span>
<span class="line-added">1399   assert(vk-&gt;flatten_array(), &quot;should only be used for flattened value type arrays&quot;);</span>
<span class="line-added">1400   // Adjust offset to omit oop header</span>
<span class="line-added">1401   int base_offset = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE) - ValueKlass::cast(vk)-&gt;first_field_offset();</span>
<span class="line-added">1402   // Initialize all elements of the flattened value type array</span>
<span class="line-added">1403   for (int i = 0; i &lt; sv-&gt;field_size(); i++) {</span>
<span class="line-added">1404     ScopeValue* val = sv-&gt;field_at(i);</span>
<span class="line-added">1405     int offset = base_offset + (i &lt;&lt; Klass::layout_helper_log2_element_size(vak-&gt;layout_helper()));</span>
<span class="line-added">1406     reassign_fields_by_klass(vk, fr, reg_map, val-&gt;as_ObjectValue(), 0, (oop)obj, false /* skip_internal */, offset, CHECK);</span>
<span class="line-added">1407   }</span>
<span class="line-added">1408 }</span>
<span class="line-added">1409 </span>
1410 // restore fields of all eliminated objects and arrays
<span class="line-modified">1411 void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures, bool skip_internal, TRAPS) {</span>
1412   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1413     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1414     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
1415     Handle obj = sv-&gt;value();
1416     assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);
1417     if (PrintDeoptimizationDetails) {
1418       tty-&gt;print_cr(&quot;reassign fields for object of type %s!&quot;, k-&gt;name()-&gt;as_C_string());
1419     }
1420     if (obj.is_null()) {
1421       continue;
1422     }
1423 #if INCLUDE_JVMCI || INCLUDE_AOT
1424     // Don&#39;t reassign fields of boxes that came from a cache. Caches may be in CDS.
1425     if (sv-&gt;is_auto_box() &amp;&amp; ((AutoBoxObjectValue*) sv)-&gt;is_cached()) {
1426       continue;
1427     }
1428 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1429     if (k-&gt;is_instance_klass()) {
1430       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1431       reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);</span>
<span class="line-added">1432     } else if (k-&gt;is_valueArray_klass()) {</span>
<span class="line-added">1433       ValueArrayKlass* vak = ValueArrayKlass::cast(k);</span>
<span class="line-added">1434       reassign_value_array_elements(fr, reg_map, sv, (valueArrayOop) obj(), vak, CHECK);</span>
1435     } else if (k-&gt;is_typeArray_klass()) {
1436       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1437       reassign_type_array_elements(fr, reg_map, sv, (typeArrayOop) obj(), ak-&gt;element_type());
1438     } else if (k-&gt;is_objArray_klass()) {
1439       reassign_object_array_elements(fr, reg_map, sv, (objArrayOop) obj());
1440     }
1441   }
1442 }
1443 
1444 
1445 // relock objects for which synchronization was eliminated
1446 void Deoptimization::relock_objects(GrowableArray&lt;MonitorInfo*&gt;* monitors, JavaThread* thread, bool realloc_failures) {
1447   for (int i = 0; i &lt; monitors-&gt;length(); i++) {
1448     MonitorInfo* mon_info = monitors-&gt;at(i);
1449     if (mon_info-&gt;eliminated()) {
1450       assert(!mon_info-&gt;owner_is_scalar_replaced() || realloc_failures, &quot;reallocation was missed&quot;);
1451       if (!mon_info-&gt;owner_is_scalar_replaced()) {
1452         Handle obj(thread, mon_info-&gt;owner());
1453         markWord mark = obj-&gt;mark();
1454         if (UseBiasedLocking &amp;&amp; mark.has_bias_pattern()) {
</pre>
<hr />
<pre>
1457           // where the thread-local object is bias locked to the current thread.
1458           assert(mark.is_biased_anonymously() ||
1459                  mark.biased_locker() == thread, &quot;should be locked to current thread&quot;);
1460           // Reset mark word to unbiased prototype.
1461           markWord unbiased_prototype = markWord::prototype().set_age(mark.age());
1462           obj-&gt;set_mark(unbiased_prototype);
1463         }
1464         BasicLock* lock = mon_info-&gt;lock();
1465         ObjectSynchronizer::enter(obj, lock, thread);
1466         assert(mon_info-&gt;owner()-&gt;is_locked(), &quot;object must be locked now&quot;);
1467       }
1468     }
1469   }
1470 }
1471 
1472 
1473 #ifndef PRODUCT
1474 // print information about reallocated objects
1475 void Deoptimization::print_objects(GrowableArray&lt;ScopeValue*&gt;* objects, bool realloc_failures) {
1476   fieldDescriptor fd;

1477   for (int i = 0; i &lt; objects-&gt;length(); i++) {
1478     ObjectValue* sv = (ObjectValue*) objects-&gt;at(i);
1479     Klass* k = java_lang_Class::as_Klass(sv-&gt;klass()-&gt;as_ConstantOopReadValue()-&gt;value()());
<span class="line-modified">1480     print_object(k, sv-&gt;value(), realloc_failures);</span>
<span class="line-added">1481   }</span>
<span class="line-added">1482 }</span>
1483 
<span class="line-modified">1484 void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {</span>
<span class="line-modified">1485   tty-&gt;print(&quot;     object &lt;&quot; INTPTR_FORMAT &quot;&gt; of type &quot;, p2i(obj()));</span>
<span class="line-modified">1486   k-&gt;print_value();</span>
<span class="line-modified">1487   assert(obj.not_null() || realloc_failures, &quot;reallocation was missed&quot;);</span>
<span class="line-modified">1488   if (obj.is_null()) {</span>
<span class="line-modified">1489     tty-&gt;print(&quot; allocation failed&quot;);</span>
<span class="line-modified">1490   } else {</span>
<span class="line-modified">1491     tty-&gt;print(&quot; allocated (%d bytes)&quot;, obj-&gt;size() * HeapWordSize);</span>
<span class="line-modified">1492   }</span>
<span class="line-added">1493   tty-&gt;cr();</span>
1494 
<span class="line-modified">1495   if (Verbose &amp;&amp; !obj.is_null()) {</span>
<span class="line-modified">1496     k-&gt;oop_print_on(obj(), tty);</span>

1497   }
1498 }
1499 #endif
1500 #endif // COMPILER2_OR_JVMCI
1501 
1502 vframeArray* Deoptimization::create_vframeArray(JavaThread* thread, frame fr, RegisterMap *reg_map, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
1503   Events::log_deopt_message(thread, &quot;DEOPT PACKING pc=&quot; INTPTR_FORMAT &quot; sp=&quot; INTPTR_FORMAT, p2i(fr.pc()), p2i(fr.sp()));
1504 
1505 #ifndef PRODUCT
1506   if (PrintDeoptimizationDetails) {
1507     ttyLocker ttyl;
1508     tty-&gt;print(&quot;DEOPT PACKING thread &quot; INTPTR_FORMAT &quot; &quot;, p2i(thread));
1509     fr.print_on(tty);
1510     tty-&gt;print_cr(&quot;     Virtual frames (innermost first):&quot;);
1511     for (int index = 0; index &lt; chunk-&gt;length(); index++) {
1512       compiledVFrame* vf = chunk-&gt;at(index);
1513       tty-&gt;print(&quot;       %2d - &quot;, index);
1514       vf-&gt;print_value();
1515       int bci = chunk-&gt;at(index)-&gt;raw_bci();
1516       const char* code_name;
</pre>
<hr />
<pre>
1649 
1650     ttyLocker ttyl;
1651     xtty-&gt;begin_head(&quot;deoptimized thread=&#39;&quot; UINTX_FORMAT &quot;&#39; reason=&#39;%s&#39; pc=&#39;&quot; INTPTR_FORMAT &quot;&#39;&quot;,(uintx)thread-&gt;osthread()-&gt;thread_id(), trap_reason_name(reason), p2i(fr.pc()));
1652     cm-&gt;log_identity(xtty);
1653     xtty-&gt;end_head();
1654     for (ScopeDesc* sd = cm-&gt;scope_desc_at(fr.pc()); ; sd = sd-&gt;sender()) {
1655       xtty-&gt;begin_elem(&quot;jvms bci=&#39;%d&#39;&quot;, sd-&gt;bci());
1656       xtty-&gt;method(sd-&gt;method());
1657       xtty-&gt;end_elem();
1658       if (sd-&gt;is_top())  break;
1659     }
1660     xtty-&gt;tail(&quot;deoptimized&quot;);
1661   }
1662 
1663   // Patch the compiled method so that when execution returns to it we will
1664   // deopt the execution state and return to the interpreter.
1665   fr.deoptimize(thread);
1666 }
1667 
1668 void Deoptimization::deoptimize(JavaThread* thread, frame fr, DeoptReason reason) {
<span class="line-modified">1669   // Deoptimize only if the frame comes from compiled code.</span>
1670   // Do not deoptimize the frame which is already patched
1671   // during the execution of the loops below.
1672   if (!fr.is_compiled_frame() || fr.is_deoptimized_frame()) {
1673     return;
1674   }
1675   ResourceMark rm;
1676   DeoptimizationMarker dm;
1677   deoptimize_single_frame(thread, fr, reason);
1678 }
1679 
1680 #if INCLUDE_JVMCI
1681 address Deoptimization::deoptimize_for_missing_exception_handler(CompiledMethod* cm) {
1682   // there is no exception handler for this pc =&gt; deoptimize
1683   cm-&gt;make_not_entrant();
1684 
1685   // Use Deoptimization::deoptimize for all of its side-effects:
1686   // gathering traps statistics, logging...
1687   // it also patches the return pc but we do not care about that
1688   // since we return a continuation to the deopt_blob below.
1689   JavaThread* thread = JavaThread::current();
</pre>
</td>
</tr>
</table>
<center><a href="../prims/jvmtiRedefineClasses.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="fieldDescriptor.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>