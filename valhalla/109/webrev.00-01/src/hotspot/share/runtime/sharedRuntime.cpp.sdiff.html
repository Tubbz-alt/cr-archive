<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/sharedRuntime.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="deoptimization.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="signature.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/sharedRuntime.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
2816       //   VVEP(RO) -- &lt;this&gt; is passed as object
2817       //   VEP      -- &lt;this&gt; is passed as fields
2818       return CodeOffsets::Verified_Value_Entry_RO;
2819     }
2820   }
2821 
2822   // Either a static method, or &lt;this&gt; is not a value type
2823   if (args_on_stack_cc() != args_on_stack_cc_ro() || _has_reserved_entries) {
2824     // No sharing:
2825     // Some arguments are passed on the stack, and we have inserted reserved entries
2826     // into the VEP, but we never insert reserved entries into the VVEP(RO).
2827     return CodeOffsets::Verified_Value_Entry_RO;
2828   } else {
2829     // Share same entry for VEP and VVEP(RO).
2830     return CodeOffsets::Verified_Entry;
2831   }
2832 }
2833 
2834 
2835 void CompiledEntrySignature::compute_calling_conventions() {
<span class="line-modified">2836   // Get the (non-scalarized) signature and check for value type arguments</span>
2837   if (!_method-&gt;is_static()) {
2838     if (_method-&gt;method_holder()-&gt;is_inline_klass() &amp;&amp; InlineKlass::cast(_method-&gt;method_holder())-&gt;can_be_passed_as_fields()) {
2839       _has_value_recv = true;
2840       _num_value_args++;
2841     }
2842     SigEntry::add_entry(_sig, T_OBJECT);
2843   }
2844   for (SignatureStream ss(_method-&gt;signature()); !ss.at_return_type(); ss.next()) {
2845     BasicType bt = ss.type();
2846     if (bt == T_INLINE_TYPE) {
2847       if (ss.as_inline_klass(_method-&gt;method_holder())-&gt;can_be_passed_as_fields()) {
2848         _num_value_args++;
2849       }
2850       bt = T_OBJECT;
2851     }
2852     SigEntry::add_entry(_sig, bt);
2853   }
2854   if (_method-&gt;is_abstract() &amp;&amp; !has_value_arg()) {
2855     return;
2856   }
</pre>
<hr />
<pre>
2897         // TODO can we avoid wasting a stack slot here?
2898         //assert(ret_off != ret_off_ro, &quot;fail&quot;);
2899         if (ret_off &gt; ret_off_ro) {
2900           swap(ret_off, ret_off_ro); // Sort by offset
2901         }
2902         _args_on_stack_cc = insert_reserved_entry(ret_off);
2903         _args_on_stack_cc = insert_reserved_entry(ret_off_ro);
2904       } else {
2905         ret_off += 2; // Account for one reserved entry (2 slots)
2906         ret_off = align_up(ret_off, alignment);
2907         _args_on_stack_cc = insert_reserved_entry(ret_off);
2908       }
2909 
2910       _has_reserved_entries = true;
2911     }
2912 
2913     // Upper bound on stack arguments to avoid hitting the argument limit and
2914     // bailing out of compilation (&quot;unsupported incoming calling sequence&quot;).
2915     // TODO we need a reasonable limit (flag?) here
2916     if (_args_on_stack_cc &gt; 50) {
<span class="line-modified">2917       // Don&#39;t scalarize value type arguments</span>
2918       _sig_cc = _sig;
2919       _sig_cc_ro = _sig;
2920       _regs_cc = _regs;
2921       _regs_cc_ro = _regs;
2922       _args_on_stack_cc = _args_on_stack;
2923       _args_on_stack_cc_ro = _args_on_stack;
2924     } else {
2925       _c1_needs_stack_repair = (_args_on_stack_cc &lt; _args_on_stack) || (_args_on_stack_cc_ro &lt; _args_on_stack);
2926       _c2_needs_stack_repair = (_args_on_stack_cc &gt; _args_on_stack) || (_args_on_stack_cc &gt; _args_on_stack_cc_ro);
2927       _has_scalarized_args = true;
2928     }
2929   }
2930 }
2931 
2932 AdapterHandlerEntry* AdapterHandlerLibrary::get_adapter0(const methodHandle&amp; method) {
2933   // Use customized signature handler.  Need to lock around updates to
2934   // the AdapterHandlerTable (it is not safe for concurrent readers
2935   // and a single writer: this could be fixed if it becomes a
2936   // problem).
2937 
</pre>
<hr />
<pre>
2950     CompiledEntrySignature ces(method());
2951     {
2952        MutexUnlocker mul(AdapterHandlerLibrary_lock);
2953        ces.compute_calling_conventions();
2954     }
2955     GrowableArray&lt;SigEntry&gt;&amp; sig       = ces.sig();
2956     GrowableArray&lt;SigEntry&gt;&amp; sig_cc    = ces.sig_cc();
2957     GrowableArray&lt;SigEntry&gt;&amp; sig_cc_ro = ces.sig_cc_ro();
2958     VMRegPair* regs         = ces.regs();
2959     VMRegPair* regs_cc      = ces.regs_cc();
2960     VMRegPair* regs_cc_ro   = ces.regs_cc_ro();
2961 
2962     if (ces.has_scalarized_args()) {
2963       method-&gt;set_has_scalarized_args(true);
2964       method-&gt;set_c1_needs_stack_repair(ces.c1_needs_stack_repair());
2965       method-&gt;set_c2_needs_stack_repair(ces.c2_needs_stack_repair());
2966     }
2967 
2968     if (method-&gt;is_abstract()) {
2969       if (ces.has_scalarized_args()) {
<span class="line-modified">2970         // Save a C heap allocated version of the signature for abstract methods with scalarized value type arguments</span>
2971         address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();
2972         entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),
2973                                                  StubRoutines::throw_AbstractMethodError_entry(),
2974                                                  wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,
2975                                                  wrong_method_abstract, wrong_method_abstract);
2976         GrowableArray&lt;SigEntry&gt;* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;SigEntry&gt;(sig_cc_ro.length(), mtInternal);
2977         heap_sig-&gt;appendAll(&amp;sig_cc_ro);
2978         entry-&gt;set_sig_cc(heap_sig);
2979         return entry;
2980       } else {
2981         return _abstract_method_handler;
2982       }
2983     }
2984 
2985     // Lookup method signature&#39;s fingerprint
2986     entry = _adapters-&gt;lookup(&amp;sig_cc, regs_cc != regs_cc_ro);
2987 
2988 #ifdef ASSERT
2989     AdapterHandlerEntry* shared_entry = NULL;
2990     // Start adapter sharing verification only after the VM is booted.
</pre>
<hr />
<pre>
3572       fr = fr.java_sender();
3573     }
3574   }
3575   return activation;
3576 }
3577 
3578 void SharedRuntime::on_slowpath_allocation_exit(JavaThread* thread) {
3579   // After any safepoint, just before going back to compiled code,
3580   // we inform the GC that we will be doing initializing writes to
3581   // this object in the future without emitting card-marks, so
3582   // GC may take any compensating steps.
3583 
3584   oop new_obj = thread-&gt;vm_result();
3585   if (new_obj == NULL) return;
3586 
3587   BarrierSet *bs = BarrierSet::barrier_set();
3588   bs-&gt;on_slowpath_allocation_exit(thread, new_obj);
3589 }
3590 
3591 // We are at a compiled code to interpreter call. We need backing
<span class="line-modified">3592 // buffers for all value type arguments. Allocate an object array to</span>
3593 // hold them (convenient because once we&#39;re done with it we don&#39;t have
3594 // to worry about freeing it).
3595 oop SharedRuntime::allocate_value_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
3596   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);
3597   ResourceMark rm;
3598 
3599   int nb_slots = 0;
3600   InstanceKlass* holder = callee-&gt;method_holder();
3601   allocate_receiver &amp;= !callee-&gt;is_static() &amp;&amp; holder-&gt;is_inline_klass();
3602   if (allocate_receiver) {
3603     nb_slots++;
3604   }
3605   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3606     if (ss.type() == T_INLINE_TYPE) {
3607       nb_slots++;
3608     }
3609   }
3610   objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);
3611   objArrayHandle array(THREAD, array_oop);
3612   int i = 0;
</pre>
<hr />
<pre>
3619   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3620     if (ss.type() == T_INLINE_TYPE) {
3621       InlineKlass* vk = ss.as_inline_klass(holder);
3622       oop res = vk-&gt;allocate_instance(CHECK_NULL);
3623       array-&gt;obj_at_put(i, res);
3624       i++;
3625     }
3626   }
3627   return array();
3628 }
3629 
3630 JRT_ENTRY(void, SharedRuntime::allocate_value_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
3631   methodHandle callee(thread, callee_method);
3632   oop array = SharedRuntime::allocate_value_types_impl(thread, callee, allocate_receiver, CHECK);
3633   thread-&gt;set_vm_result(array);
3634   thread-&gt;set_vm_result_2(callee()); // TODO: required to keep callee live?
3635 JRT_END
3636 
3637 // TODO remove this once the AARCH64 dependency is gone
3638 // Iterate over the array of heap allocated value types and apply the GC post barrier to all reference fields.
<span class="line-modified">3639 // This is called from the C2I adapter after value type arguments are heap allocated and initialized.</span>
3640 JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))
3641 {
3642   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);
3643   assert(oopDesc::is_oop(array), &quot;should be oop&quot;);
3644   for (int i = 0; i &lt; array-&gt;length(); ++i) {
3645     instanceOop valueOop = (instanceOop)array-&gt;obj_at(i);
3646     InlineKlass* vk = InlineKlass::cast(valueOop-&gt;klass());
3647     if (vk-&gt;contains_oops()) {
3648       const address dst_oop_addr = ((address) (void*) valueOop);
3649       OopMapBlock* map = vk-&gt;start_of_nonstatic_oop_maps();
3650       OopMapBlock* const end = map + vk-&gt;nonstatic_oop_map_count();
3651       while (map != end) {
3652         address doop_address = dst_oop_addr + map-&gt;offset();
3653         barrier_set_cast&lt;ModRefBarrierSet&gt;(BarrierSet::barrier_set())-&gt;
3654           write_ref_array((HeapWord*) doop_address, map-&gt;count());
3655         map++;
3656       }
3657     }
3658   }
3659 }
</pre>
</td>
<td>
<hr />
<pre>
2816       //   VVEP(RO) -- &lt;this&gt; is passed as object
2817       //   VEP      -- &lt;this&gt; is passed as fields
2818       return CodeOffsets::Verified_Value_Entry_RO;
2819     }
2820   }
2821 
2822   // Either a static method, or &lt;this&gt; is not a value type
2823   if (args_on_stack_cc() != args_on_stack_cc_ro() || _has_reserved_entries) {
2824     // No sharing:
2825     // Some arguments are passed on the stack, and we have inserted reserved entries
2826     // into the VEP, but we never insert reserved entries into the VVEP(RO).
2827     return CodeOffsets::Verified_Value_Entry_RO;
2828   } else {
2829     // Share same entry for VEP and VVEP(RO).
2830     return CodeOffsets::Verified_Entry;
2831   }
2832 }
2833 
2834 
2835 void CompiledEntrySignature::compute_calling_conventions() {
<span class="line-modified">2836   // Get the (non-scalarized) signature and check for inline type arguments</span>
2837   if (!_method-&gt;is_static()) {
2838     if (_method-&gt;method_holder()-&gt;is_inline_klass() &amp;&amp; InlineKlass::cast(_method-&gt;method_holder())-&gt;can_be_passed_as_fields()) {
2839       _has_value_recv = true;
2840       _num_value_args++;
2841     }
2842     SigEntry::add_entry(_sig, T_OBJECT);
2843   }
2844   for (SignatureStream ss(_method-&gt;signature()); !ss.at_return_type(); ss.next()) {
2845     BasicType bt = ss.type();
2846     if (bt == T_INLINE_TYPE) {
2847       if (ss.as_inline_klass(_method-&gt;method_holder())-&gt;can_be_passed_as_fields()) {
2848         _num_value_args++;
2849       }
2850       bt = T_OBJECT;
2851     }
2852     SigEntry::add_entry(_sig, bt);
2853   }
2854   if (_method-&gt;is_abstract() &amp;&amp; !has_value_arg()) {
2855     return;
2856   }
</pre>
<hr />
<pre>
2897         // TODO can we avoid wasting a stack slot here?
2898         //assert(ret_off != ret_off_ro, &quot;fail&quot;);
2899         if (ret_off &gt; ret_off_ro) {
2900           swap(ret_off, ret_off_ro); // Sort by offset
2901         }
2902         _args_on_stack_cc = insert_reserved_entry(ret_off);
2903         _args_on_stack_cc = insert_reserved_entry(ret_off_ro);
2904       } else {
2905         ret_off += 2; // Account for one reserved entry (2 slots)
2906         ret_off = align_up(ret_off, alignment);
2907         _args_on_stack_cc = insert_reserved_entry(ret_off);
2908       }
2909 
2910       _has_reserved_entries = true;
2911     }
2912 
2913     // Upper bound on stack arguments to avoid hitting the argument limit and
2914     // bailing out of compilation (&quot;unsupported incoming calling sequence&quot;).
2915     // TODO we need a reasonable limit (flag?) here
2916     if (_args_on_stack_cc &gt; 50) {
<span class="line-modified">2917       // Don&#39;t scalarize inline type arguments</span>
2918       _sig_cc = _sig;
2919       _sig_cc_ro = _sig;
2920       _regs_cc = _regs;
2921       _regs_cc_ro = _regs;
2922       _args_on_stack_cc = _args_on_stack;
2923       _args_on_stack_cc_ro = _args_on_stack;
2924     } else {
2925       _c1_needs_stack_repair = (_args_on_stack_cc &lt; _args_on_stack) || (_args_on_stack_cc_ro &lt; _args_on_stack);
2926       _c2_needs_stack_repair = (_args_on_stack_cc &gt; _args_on_stack) || (_args_on_stack_cc &gt; _args_on_stack_cc_ro);
2927       _has_scalarized_args = true;
2928     }
2929   }
2930 }
2931 
2932 AdapterHandlerEntry* AdapterHandlerLibrary::get_adapter0(const methodHandle&amp; method) {
2933   // Use customized signature handler.  Need to lock around updates to
2934   // the AdapterHandlerTable (it is not safe for concurrent readers
2935   // and a single writer: this could be fixed if it becomes a
2936   // problem).
2937 
</pre>
<hr />
<pre>
2950     CompiledEntrySignature ces(method());
2951     {
2952        MutexUnlocker mul(AdapterHandlerLibrary_lock);
2953        ces.compute_calling_conventions();
2954     }
2955     GrowableArray&lt;SigEntry&gt;&amp; sig       = ces.sig();
2956     GrowableArray&lt;SigEntry&gt;&amp; sig_cc    = ces.sig_cc();
2957     GrowableArray&lt;SigEntry&gt;&amp; sig_cc_ro = ces.sig_cc_ro();
2958     VMRegPair* regs         = ces.regs();
2959     VMRegPair* regs_cc      = ces.regs_cc();
2960     VMRegPair* regs_cc_ro   = ces.regs_cc_ro();
2961 
2962     if (ces.has_scalarized_args()) {
2963       method-&gt;set_has_scalarized_args(true);
2964       method-&gt;set_c1_needs_stack_repair(ces.c1_needs_stack_repair());
2965       method-&gt;set_c2_needs_stack_repair(ces.c2_needs_stack_repair());
2966     }
2967 
2968     if (method-&gt;is_abstract()) {
2969       if (ces.has_scalarized_args()) {
<span class="line-modified">2970         // Save a C heap allocated version of the signature for abstract methods with scalarized inline type arguments</span>
2971         address wrong_method_abstract = SharedRuntime::get_handle_wrong_method_abstract_stub();
2972         entry = AdapterHandlerLibrary::new_entry(new AdapterFingerPrint(NULL),
2973                                                  StubRoutines::throw_AbstractMethodError_entry(),
2974                                                  wrong_method_abstract, wrong_method_abstract, wrong_method_abstract,
2975                                                  wrong_method_abstract, wrong_method_abstract);
2976         GrowableArray&lt;SigEntry&gt;* heap_sig = new (ResourceObj::C_HEAP, mtInternal) GrowableArray&lt;SigEntry&gt;(sig_cc_ro.length(), mtInternal);
2977         heap_sig-&gt;appendAll(&amp;sig_cc_ro);
2978         entry-&gt;set_sig_cc(heap_sig);
2979         return entry;
2980       } else {
2981         return _abstract_method_handler;
2982       }
2983     }
2984 
2985     // Lookup method signature&#39;s fingerprint
2986     entry = _adapters-&gt;lookup(&amp;sig_cc, regs_cc != regs_cc_ro);
2987 
2988 #ifdef ASSERT
2989     AdapterHandlerEntry* shared_entry = NULL;
2990     // Start adapter sharing verification only after the VM is booted.
</pre>
<hr />
<pre>
3572       fr = fr.java_sender();
3573     }
3574   }
3575   return activation;
3576 }
3577 
3578 void SharedRuntime::on_slowpath_allocation_exit(JavaThread* thread) {
3579   // After any safepoint, just before going back to compiled code,
3580   // we inform the GC that we will be doing initializing writes to
3581   // this object in the future without emitting card-marks, so
3582   // GC may take any compensating steps.
3583 
3584   oop new_obj = thread-&gt;vm_result();
3585   if (new_obj == NULL) return;
3586 
3587   BarrierSet *bs = BarrierSet::barrier_set();
3588   bs-&gt;on_slowpath_allocation_exit(thread, new_obj);
3589 }
3590 
3591 // We are at a compiled code to interpreter call. We need backing
<span class="line-modified">3592 // buffers for all inline type arguments. Allocate an object array to</span>
3593 // hold them (convenient because once we&#39;re done with it we don&#39;t have
3594 // to worry about freeing it).
3595 oop SharedRuntime::allocate_value_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
3596   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);
3597   ResourceMark rm;
3598 
3599   int nb_slots = 0;
3600   InstanceKlass* holder = callee-&gt;method_holder();
3601   allocate_receiver &amp;= !callee-&gt;is_static() &amp;&amp; holder-&gt;is_inline_klass();
3602   if (allocate_receiver) {
3603     nb_slots++;
3604   }
3605   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3606     if (ss.type() == T_INLINE_TYPE) {
3607       nb_slots++;
3608     }
3609   }
3610   objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);
3611   objArrayHandle array(THREAD, array_oop);
3612   int i = 0;
</pre>
<hr />
<pre>
3619   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3620     if (ss.type() == T_INLINE_TYPE) {
3621       InlineKlass* vk = ss.as_inline_klass(holder);
3622       oop res = vk-&gt;allocate_instance(CHECK_NULL);
3623       array-&gt;obj_at_put(i, res);
3624       i++;
3625     }
3626   }
3627   return array();
3628 }
3629 
3630 JRT_ENTRY(void, SharedRuntime::allocate_value_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
3631   methodHandle callee(thread, callee_method);
3632   oop array = SharedRuntime::allocate_value_types_impl(thread, callee, allocate_receiver, CHECK);
3633   thread-&gt;set_vm_result(array);
3634   thread-&gt;set_vm_result_2(callee()); // TODO: required to keep callee live?
3635 JRT_END
3636 
3637 // TODO remove this once the AARCH64 dependency is gone
3638 // Iterate over the array of heap allocated value types and apply the GC post barrier to all reference fields.
<span class="line-modified">3639 // This is called from the C2I adapter after inline type arguments are heap allocated and initialized.</span>
3640 JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))
3641 {
3642   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);
3643   assert(oopDesc::is_oop(array), &quot;should be oop&quot;);
3644   for (int i = 0; i &lt; array-&gt;length(); ++i) {
3645     instanceOop valueOop = (instanceOop)array-&gt;obj_at(i);
3646     InlineKlass* vk = InlineKlass::cast(valueOop-&gt;klass());
3647     if (vk-&gt;contains_oops()) {
3648       const address dst_oop_addr = ((address) (void*) valueOop);
3649       OopMapBlock* map = vk-&gt;start_of_nonstatic_oop_maps();
3650       OopMapBlock* const end = map + vk-&gt;nonstatic_oop_map_count();
3651       while (map != end) {
3652         address doop_address = dst_oop_addr + map-&gt;offset();
3653         barrier_set_cast&lt;ModRefBarrierSet&gt;(BarrierSet::barrier_set())-&gt;
3654           write_ref_array((HeapWord*) doop_address, map-&gt;count());
3655         map++;
3656       }
3657     }
3658   }
3659 }
</pre>
</td>
</tr>
</table>
<center><a href="deoptimization.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="signature.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>