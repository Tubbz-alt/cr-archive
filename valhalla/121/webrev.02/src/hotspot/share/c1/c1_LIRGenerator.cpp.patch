diff a/src/hotspot/share/c1/c1_LIRGenerator.cpp b/src/hotspot/share/c1/c1_LIRGenerator.cpp
--- a/src/hotspot/share/c1/c1_LIRGenerator.cpp
+++ b/src/hotspot/share/c1/c1_LIRGenerator.cpp
@@ -29,15 +29,15 @@
 #include "c1/c1_Instruction.hpp"
 #include "c1/c1_LIRAssembler.hpp"
 #include "c1/c1_LIRGenerator.hpp"
 #include "c1/c1_ValueStack.hpp"
 #include "ci/ciArrayKlass.hpp"
+#include "ci/ciFlatArrayKlass.hpp"
+#include "ci/ciInlineKlass.hpp"
 #include "ci/ciInstance.hpp"
 #include "ci/ciObjArray.hpp"
 #include "ci/ciUtilities.hpp"
-#include "ci/ciValueArrayKlass.hpp"
-#include "ci/ciValueKlass.hpp"
 #include "gc/shared/barrierSet.hpp"
 #include "gc/shared/c1/barrierSetC1.hpp"
 #include "oops/klass.inline.hpp"
 #include "runtime/arguments.hpp"
 #include "runtime/sharedRuntime.hpp"
@@ -793,14 +793,14 @@
 
   if (!src->is_loaded_flattened_array() && !dst->is_loaded_flattened_array()) {
     flags &= ~LIR_OpArrayCopy::always_slow_path;
   }
   if (!src->maybe_flattened_array()) {
-    flags &= ~LIR_OpArrayCopy::src_valuetype_check;
+    flags &= ~LIR_OpArrayCopy::src_inlinetype_check;
   }
   if (!dst->maybe_flattened_array() && !dst->maybe_null_free_array()) {
-    flags &= ~LIR_OpArrayCopy::dst_valuetype_check;
+    flags &= ~LIR_OpArrayCopy::dst_inlinetype_check;
   }
 
   if (!src_objarray)
     flags &= ~LIR_OpArrayCopy::src_objarray;
   if (!dst_objarray)
@@ -1596,16 +1596,16 @@
 };
 
 void LIRGenerator::access_flattened_array(bool is_load, LIRItem& array, LIRItem& index, LIRItem& obj_item) {
   // Find the starting address of the source (inside the array)
   ciType* array_type = array.value()->declared_type();
-  ciValueArrayKlass* value_array_klass = array_type->as_value_array_klass();
-  assert(value_array_klass->is_loaded(), "must be");
+  ciFlatArrayKlass* flat_array_klass = array_type->as_flat_array_klass();
+  assert(flat_array_klass->is_loaded(), "must be");
 
-  ciValueKlass* elem_klass = value_array_klass->element_klass()->as_value_klass();
-  int array_header_size = value_array_klass->array_header_in_bytes();
-  int shift = value_array_klass->log2_element_size();
+  ciInlineKlass* elem_klass = flat_array_klass->element_klass()->as_inline_klass();
+  int array_header_size = flat_array_klass->array_header_in_bytes();
+  int shift = flat_array_klass->log2_element_size();
 
 #ifndef _LP64
   LIR_Opr index_op = new_register(T_INT);
   // FIXME -- on 32-bit, the shift below can overflow, so we need to check that
   // the top (shift+1) bits of index_op must be zero, or
@@ -1690,11 +1690,11 @@
 bool LIRGenerator::needs_flattened_array_store_check(StoreIndexed* x) {
   if (x->elt_type() == T_OBJECT && x->array()->maybe_flattened_array()) {
     ciType* type = x->value()->declared_type();
     if (type != NULL && type->is_klass()) {
       ciKlass* klass = type->as_klass();
-      if (!klass->can_be_value_klass() || (klass->is_valuetype() && !klass->as_value_klass()->flatten_array())) {
+      if (!klass->can_be_inline_klass() || (klass->is_inlinetype() && !klass->as_inline_klass()->flatten_array())) {
         // This is known to be a non-flattened object. If the array is flattened,
         // it will be caught by the code generated by array_store_check().
         return false;
       }
     }
@@ -1948,13 +1948,13 @@
                                         Deoptimization::Reason_unloaded,
                                         Deoptimization::Action_make_not_entrant);
     __ branch(lir_cond_always, stub);
   } else if (need_default) {
     assert(!field_type_unloaded, "must be");
-    assert(field->type()->is_valuetype(), "must be");
-    ciValueKlass* value_klass = field->type()->as_value_klass();
-    assert(value_klass->is_loaded(), "must be");
+    assert(field->type()->is_inlinetype(), "must be");
+    ciInlineKlass* inline_klass = field->type()->as_inline_klass();
+    assert(inline_klass->is_loaded(), "must be");
 
     if (field->is_static() && holder->is_loaded()) {
       ciInstance* mirror = field->holder()->java_mirror();
       ciObject* val = mirror->field_value(field).as_object();
       if (val->is_null_object()) {
@@ -1965,11 +1965,11 @@
         need_default = false;
       }
     }
 
     if (need_default) {
-      default_value = new Constant(new InstanceConstant(value_klass->default_value_instance()));
+      default_value = new Constant(new InstanceConstant(inline_klass->default_instance()));
     }
   }
 
   return default_value;
 }
@@ -2167,11 +2167,11 @@
   }
 
   Value element;
   if (x->vt() != NULL) {
     assert(x->array()->is_loaded_flattened_array(), "must be");
-    // Find the destination address (of the NewValueTypeInstance).
+    // Find the destination address (of the NewInlineTypeInstance).
     LIR_Opr obj = x->vt()->operand();
     LIRItem obj_item(x->vt(), this);
 
     access_flattened_array(true, array, index, obj_item);
     set_no_result(x);
@@ -3115,11 +3115,11 @@
     profile_parameters(x);
     CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, SynchronizationEntryBCI), NULL, false);
     increment_invocation_counter(info);
   }
   if (method()->has_scalarized_args()) {
-    // Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized value type arguments
+    // Check if deoptimization was triggered (i.e. orig_pc was set) while buffering scalarized inline type arguments
     // in the entry point (see comments in frame::deoptimize). If so, deoptimize only now that we have the right state.
     CodeEmitInfo* info = new CodeEmitInfo(scope()->start()->state()->copy(ValueStack::StateBefore, 0), NULL, false);
     CodeStub* deopt_stub = new DeoptimizeStub(info, Deoptimization::Reason_none, Deoptimization::Action_none);
     __ append(new LIR_Op0(lir_check_orig_pc));
     __ branch(lir_cond_notEqual, deopt_stub);
@@ -3399,16 +3399,16 @@
 
   ciKlass* left_klass  = left_val ->as_loaded_klass_or_null();
   ciKlass* right_klass = right_val->as_loaded_klass_or_null();
 
   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
-      !left_klass->is_valuetype() || !right_klass->is_valuetype()) {
+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {
     init_temps_for_substitutability_check(tmp1, tmp2);
   }
 
-  if (left_klass != NULL && left_klass->is_valuetype() && left_klass == right_klass) {
-    // No need to load klass -- the operands are statically known to be the same value klass.
+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {
+    // No need to load klass -- the operands are statically known to be the same inline klass.
   } else {
     BasicType t_klass = UseCompressedOops ? T_INT : T_METADATA;
     left_klass_op = new_register(t_klass);
     right_klass_op = new_register(t_klass);
   }
