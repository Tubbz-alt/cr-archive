<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/c1_MacroAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRGenerator_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_MacroAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 71   int null_check_offset = -1;
 72 
 73   verify_oop(obj);
 74 
 75   // save object being locked into the BasicObjectLock
 76   str(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));
 77 
 78   if (UseBiasedLocking) {
 79     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
 80     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, false, done, &amp;slow_case);
 81   } else {
 82     null_check_offset = offset();
 83   }
 84 
 85   // Load object header
 86   ldr(hdr, Address(obj, hdr_offset));
 87   // and mark it as unlocked
 88   orr(hdr, hdr, markWord::unlocked_value);
 89 
 90   if (EnableValhalla &amp;&amp; !UseBiasedLocking) {
<span class="line-modified"> 91     // Mask always_locked bit such that we go to the slow path if object is a value type</span>
 92     andr(hdr, hdr, ~markWord::biased_lock_bit_in_place);
 93   }
 94 
 95   // save unlocked object header into the displaced header location on the stack
 96   str(hdr, Address(disp_hdr, 0));
 97   // test if object header is still the same (i.e. unlocked), and if so, store the
 98   // displaced header address in the object header - if it is not the same, get the
 99   // object header instead
100   lea(rscratch2, Address(obj, hdr_offset));
101   cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, /*fallthough*/NULL);
102   // if the object header was the same, we&#39;re done
103   // if the object header was not the same, it is now in the hdr register
104   // =&gt; test if it is a stack pointer into the same stack (recursive locking), i.e.:
105   //
106   // 1) (hdr &amp; aligned_mask) == 0
107   // 2) sp &lt;= hdr
108   // 3) hdr &lt;= sp + page_size
109   //
110   // these 3 tests can be done by evaluating the following expression:
111   //
</pre>
<hr />
<pre>
322 
323   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
324     assert(obj == r0, &quot;must be&quot;);
325     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
326   }
327 
328   verify_oop(obj);
329 }
330 
331 
332 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
333   verify_oop(receiver);
334   // explicit NULL check not needed since load from [klass_offset] causes a trap
335   // check against inline cache
336   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
337 
338   cmp_klass(receiver, iCache, rscratch1);
339 }
340 
341 
<span class="line-modified">342 void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes, bool needs_stack_repair, Label* verified_value_entry_label) {</span>
343   assert(bang_size_in_bytes &gt;= framesize, &quot;stack bang size incorrect&quot;);
344   // Make sure there is enough stack space for this method&#39;s activation.
345   // Note that we do this before doing an enter().
346   generate_stack_overflow_check(bang_size_in_bytes);
347 
348   guarantee(needs_stack_repair == false, &quot;Stack repair should not be true&quot;);
<span class="line-modified">349   if (verified_value_entry_label != NULL) {</span>
<span class="line-modified">350     bind(*verified_value_entry_label);</span>
351   }
352 
353   MacroAssembler::build_frame(framesize + 2 * wordSize);
354 
355   // Insert nmethod entry barrier into frame.
356   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
357   bs-&gt;nmethod_entry_barrier(this);
358 }
359 
360 void C1_MacroAssembler::remove_frame(int framesize, bool needs_stack_repair) {
361 
362   guarantee(needs_stack_repair == false, &quot;Stack repair should not be true&quot;);
363 
364   MacroAssembler::remove_frame(framesize + 2 * wordSize);
365 }
366 
<span class="line-modified">367 void C1_MacroAssembler::verified_value_entry() {</span>
368   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
369     // Verified Entry first instruction should be 5 bytes long for correct
370     // patching by patch_verified_entry().
371     //
372     // C1Breakpoint and VerifyFPU have one byte first instruction.
373     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
374     // code is not generated (see build_frame() above).
375     // For all these cases generate long instruction first.
376     nop();
377   }
378 
379   nop();
380   // build frame
381   // verify_FPU(0, &quot;method_entry&quot;);
382 }
383 
<span class="line-modified">384 int C1_MacroAssembler::scalarized_entry(const CompiledEntrySignature *ces, int frame_size_in_bytes, int bang_size_in_bytes, Label&amp; verified_value_entry_label, bool is_value_ro_entry) {</span>
385   // This function required to support for InlineTypePassFieldsAsArgs
386   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
387     // Verified Entry first instruction should be 5 bytes long for correct
388     // patching by patch_verified_entry().
389     //
390     // C1Breakpoint and VerifyFPU have one byte first instruction.
391     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
392     // code is not generated (see build_frame() above).
393     // For all these cases generate long instruction first.
394     nop();
395   }
396 
397   nop();
398   // verify_FPU(0, &quot;method_entry&quot;);
399 
400   assert(InlineTypePassFieldsAsArgs, &quot;sanity&quot;);
401 
402   GrowableArray&lt;SigEntry&gt;* sig   = &amp;ces-&gt;sig();
<span class="line-modified">403   GrowableArray&lt;SigEntry&gt;* sig_cc = is_value_ro_entry ? &amp;ces-&gt;sig_cc_ro() : &amp;ces-&gt;sig_cc();</span>
404   VMRegPair* regs      = ces-&gt;regs();
<span class="line-modified">405   VMRegPair* regs_cc   = is_value_ro_entry ? ces-&gt;regs_cc_ro() : ces-&gt;regs_cc();</span>
406   int args_on_stack    = ces-&gt;args_on_stack();
<span class="line-modified">407   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();</span>
408 
<span class="line-modified">409   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);</span>
410   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
411   int args_passed = sig-&gt;length();
412   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);
413 
414   int extra_stack_offset = wordSize; // tos is return address.
415 
416   // Create a temp frame so we can call into runtime. It must be properly set up to accomodate GC.
417   int sp_inc = (args_on_stack - args_on_stack_cc) * VMRegImpl::stack_slot_size;
418   if (sp_inc &gt; 0) {
419     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
420     sub(sp, sp, sp_inc);
421   } else {
422     sp_inc = 0;
423   }
424 
425   sub(sp, sp, frame_size_in_bytes);
426   if (sp_inc &gt; 0) {
427     int real_frame_size = frame_size_in_bytes +
428            + wordSize  // pushed rbp
429            + wordSize  // returned address pushed by the stack extension code
430            + sp_inc;   // stack extension
431     mov(rscratch1, real_frame_size);
432     str(rscratch1, Address(sp, frame_size_in_bytes - wordSize));
433   }
434 
<span class="line-modified">435   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.</span>
436   mov(r1, (intptr_t) ces-&gt;method());
<span class="line-modified">437   if (is_value_ro_entry) {</span>
<span class="line-modified">438     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));</span>
439   } else {
<span class="line-modified">440     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));</span>
441   }
442   int rt_call_offset = offset();
443 
444   // Remove the temp frame
445   add(sp, sp, frame_size_in_bytes);
446 
<span class="line-modified">447   int n = shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,</span>
<span class="line-modified">448                              args_passed_cc, args_on_stack_cc, regs_cc, // from</span>
<span class="line-modified">449                              args_passed, args_on_stack, regs);         // to</span>
450   assert(sp_inc == n, &quot;must be&quot;);
451 
452   if (sp_inc != 0) {
453     // Do the stack banging here, and skip over the stack repair code in the
<span class="line-modified">454     // verified_value_entry (which has a different real_frame_size).</span>
455     assert(sp_inc &gt; 0, &quot;stack should not shrink&quot;);
456     generate_stack_overflow_check(bang_size_in_bytes);
457     decrement(sp, frame_size_in_bytes);
458   }
459 
<span class="line-modified">460   b(verified_value_entry_label);</span>
461   return rt_call_offset;
462 }
463 
464 
465 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
466   // rbp, + 0: link
467   //     + 1: return address
468   //     + 2: argument with offset 0
469   //     + 3: argument with offset 1
470   //     + 4: ...
471 
472   ldr(reg, Address(rfp, (offset_in_words + 2) * BytesPerWord));
473 }
474 
475 #ifndef PRODUCT
476 
477 void C1_MacroAssembler::verify_stack_oop(int stack_offset) {
478   if (!VerifyOops) return;
479   verify_oop_addr(Address(sp, stack_offset), &quot;oop&quot;);
480 }
</pre>
</td>
<td>
<hr />
<pre>
 71   int null_check_offset = -1;
 72 
 73   verify_oop(obj);
 74 
 75   // save object being locked into the BasicObjectLock
 76   str(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));
 77 
 78   if (UseBiasedLocking) {
 79     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
 80     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, false, done, &amp;slow_case);
 81   } else {
 82     null_check_offset = offset();
 83   }
 84 
 85   // Load object header
 86   ldr(hdr, Address(obj, hdr_offset));
 87   // and mark it as unlocked
 88   orr(hdr, hdr, markWord::unlocked_value);
 89 
 90   if (EnableValhalla &amp;&amp; !UseBiasedLocking) {
<span class="line-modified"> 91     // Mask always_locked bit such that we go to the slow path if object is an inline type</span>
 92     andr(hdr, hdr, ~markWord::biased_lock_bit_in_place);
 93   }
 94 
 95   // save unlocked object header into the displaced header location on the stack
 96   str(hdr, Address(disp_hdr, 0));
 97   // test if object header is still the same (i.e. unlocked), and if so, store the
 98   // displaced header address in the object header - if it is not the same, get the
 99   // object header instead
100   lea(rscratch2, Address(obj, hdr_offset));
101   cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, /*fallthough*/NULL);
102   // if the object header was the same, we&#39;re done
103   // if the object header was not the same, it is now in the hdr register
104   // =&gt; test if it is a stack pointer into the same stack (recursive locking), i.e.:
105   //
106   // 1) (hdr &amp; aligned_mask) == 0
107   // 2) sp &lt;= hdr
108   // 3) hdr &lt;= sp + page_size
109   //
110   // these 3 tests can be done by evaluating the following expression:
111   //
</pre>
<hr />
<pre>
322 
323   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
324     assert(obj == r0, &quot;must be&quot;);
325     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
326   }
327 
328   verify_oop(obj);
329 }
330 
331 
332 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
333   verify_oop(receiver);
334   // explicit NULL check not needed since load from [klass_offset] causes a trap
335   // check against inline cache
336   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
337 
338   cmp_klass(receiver, iCache, rscratch1);
339 }
340 
341 
<span class="line-modified">342 void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes, bool needs_stack_repair, Label* verified_inline_entry_label) {</span>
343   assert(bang_size_in_bytes &gt;= framesize, &quot;stack bang size incorrect&quot;);
344   // Make sure there is enough stack space for this method&#39;s activation.
345   // Note that we do this before doing an enter().
346   generate_stack_overflow_check(bang_size_in_bytes);
347 
348   guarantee(needs_stack_repair == false, &quot;Stack repair should not be true&quot;);
<span class="line-modified">349   if (verified_inline_entry_label != NULL) {</span>
<span class="line-modified">350     bind(*verified_inline_entry_label);</span>
351   }
352 
353   MacroAssembler::build_frame(framesize + 2 * wordSize);
354 
355   // Insert nmethod entry barrier into frame.
356   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
357   bs-&gt;nmethod_entry_barrier(this);
358 }
359 
360 void C1_MacroAssembler::remove_frame(int framesize, bool needs_stack_repair) {
361 
362   guarantee(needs_stack_repair == false, &quot;Stack repair should not be true&quot;);
363 
364   MacroAssembler::remove_frame(framesize + 2 * wordSize);
365 }
366 
<span class="line-modified">367 void C1_MacroAssembler::verified_inline_entry() {</span>
368   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
369     // Verified Entry first instruction should be 5 bytes long for correct
370     // patching by patch_verified_entry().
371     //
372     // C1Breakpoint and VerifyFPU have one byte first instruction.
373     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
374     // code is not generated (see build_frame() above).
375     // For all these cases generate long instruction first.
376     nop();
377   }
378 
379   nop();
380   // build frame
381   // verify_FPU(0, &quot;method_entry&quot;);
382 }
383 
<span class="line-modified">384 int C1_MacroAssembler::scalarized_entry(const CompiledEntrySignature* ces, int frame_size_in_bytes, int bang_size_in_bytes, Label&amp; verified_inline_entry_label, bool is_inline_ro_entry) {</span>
385   // This function required to support for InlineTypePassFieldsAsArgs
386   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
387     // Verified Entry first instruction should be 5 bytes long for correct
388     // patching by patch_verified_entry().
389     //
390     // C1Breakpoint and VerifyFPU have one byte first instruction.
391     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
392     // code is not generated (see build_frame() above).
393     // For all these cases generate long instruction first.
394     nop();
395   }
396 
397   nop();
398   // verify_FPU(0, &quot;method_entry&quot;);
399 
400   assert(InlineTypePassFieldsAsArgs, &quot;sanity&quot;);
401 
402   GrowableArray&lt;SigEntry&gt;* sig   = &amp;ces-&gt;sig();
<span class="line-modified">403   GrowableArray&lt;SigEntry&gt;* sig_cc = is_inline_ro_entry ? &amp;ces-&gt;sig_cc_ro() : &amp;ces-&gt;sig_cc();</span>
404   VMRegPair* regs      = ces-&gt;regs();
<span class="line-modified">405   VMRegPair* regs_cc   = is_inline_ro_entry ? ces-&gt;regs_cc_ro() : ces-&gt;regs_cc();</span>
406   int args_on_stack    = ces-&gt;args_on_stack();
<span class="line-modified">407   int args_on_stack_cc = is_inline_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();</span>
408 
<span class="line-modified">409   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized inline class not allowed!&quot;);</span>
410   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
411   int args_passed = sig-&gt;length();
412   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);
413 
414   int extra_stack_offset = wordSize; // tos is return address.
415 
416   // Create a temp frame so we can call into runtime. It must be properly set up to accomodate GC.
417   int sp_inc = (args_on_stack - args_on_stack_cc) * VMRegImpl::stack_slot_size;
418   if (sp_inc &gt; 0) {
419     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
420     sub(sp, sp, sp_inc);
421   } else {
422     sp_inc = 0;
423   }
424 
425   sub(sp, sp, frame_size_in_bytes);
426   if (sp_inc &gt; 0) {
427     int real_frame_size = frame_size_in_bytes +
428            + wordSize  // pushed rbp
429            + wordSize  // returned address pushed by the stack extension code
430            + sp_inc;   // stack extension
431     mov(rscratch1, real_frame_size);
432     str(rscratch1, Address(sp, frame_size_in_bytes - wordSize));
433   }
434 
<span class="line-modified">435   // FIXME -- call runtime only if we cannot in-line allocate all the incoming inline type args.</span>
436   mov(r1, (intptr_t) ces-&gt;method());
<span class="line-modified">437   if (is_inline_ro_entry) {</span>
<span class="line-modified">438     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_inline_args_no_receiver_id)));</span>
439   } else {
<span class="line-modified">440     far_call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_inline_args_id)));</span>
441   }
442   int rt_call_offset = offset();
443 
444   // Remove the temp frame
445   add(sp, sp, frame_size_in_bytes);
446 
<span class="line-modified">447   int n = shuffle_inline_args(true, is_inline_ro_entry, extra_stack_offset, sig_bt, sig_cc,</span>
<span class="line-modified">448                               args_passed_cc, args_on_stack_cc, regs_cc, // from</span>
<span class="line-modified">449                               args_passed, args_on_stack, regs);         // to</span>
450   assert(sp_inc == n, &quot;must be&quot;);
451 
452   if (sp_inc != 0) {
453     // Do the stack banging here, and skip over the stack repair code in the
<span class="line-modified">454     // verified_inline_entry (which has a different real_frame_size).</span>
455     assert(sp_inc &gt; 0, &quot;stack should not shrink&quot;);
456     generate_stack_overflow_check(bang_size_in_bytes);
457     decrement(sp, frame_size_in_bytes);
458   }
459 
<span class="line-modified">460   b(verified_inline_entry_label);</span>
461   return rt_call_offset;
462 }
463 
464 
465 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
466   // rbp, + 0: link
467   //     + 1: return address
468   //     + 2: argument with offset 0
469   //     + 3: argument with offset 1
470   //     + 4: ...
471 
472   ldr(reg, Address(rfp, (offset_in_words + 2) * BytesPerWord));
473 }
474 
475 #ifndef PRODUCT
476 
477 void C1_MacroAssembler::verify_stack_oop(int stack_offset) {
478   if (!VerifyOops) return;
479   verify_oop_addr(Address(sp, stack_offset), &quot;oop&quot;);
480 }
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRGenerator_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>