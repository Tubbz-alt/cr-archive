diff a/src/hotspot/share/runtime/sharedRuntime.cpp b/src/hotspot/share/runtime/sharedRuntime.cpp
--- a/src/hotspot/share/runtime/sharedRuntime.cpp
+++ b/src/hotspot/share/runtime/sharedRuntime.cpp
@@ -1567,11 +1567,11 @@
     callee_method = SharedRuntime::resolve_helper(thread, false, false, &caller_is_c1, CHECK_NULL);
     thread->set_vm_result_2(callee_method());
   JRT_BLOCK_END
   // return compiled code entry point after potential safepoints
   address entry = caller_is_c1 ?
-    callee_method->verified_value_code_entry() : callee_method->verified_code_entry();
+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();
   assert(entry != NULL, "Jump to zero!");
   return entry;
 JRT_END
 
 
@@ -1583,11 +1583,11 @@
     callee_method = SharedRuntime::resolve_helper(thread, true, false, &caller_is_c1, CHECK_NULL);
     thread->set_vm_result_2(callee_method());
   JRT_BLOCK_END
   // return compiled code entry point after potential safepoints
   address entry = caller_is_c1 ?
-    callee_method->verified_value_code_entry() : callee_method->verified_value_ro_code_entry();
+    callee_method->verified_inline_code_entry() : callee_method->verified_inline_ro_code_entry();
   assert(entry != NULL, "Jump to zero!");
   return entry;
 JRT_END
 
 
@@ -1600,11 +1600,11 @@
     callee_method = SharedRuntime::resolve_helper(thread, true, true, &caller_is_c1, CHECK_NULL);
     thread->set_vm_result_2(callee_method());
   JRT_BLOCK_END
   // return compiled code entry point after potential safepoints
   address entry = caller_is_c1 ?
-    callee_method->verified_value_code_entry() : callee_method->verified_code_entry();
+    callee_method->verified_inline_code_entry() : callee_method->verified_code_entry();
   assert(entry != NULL, "Jump to zero!");
   return entry;
 JRT_END
 
 // The handle_ic_miss_helper_internal function returns false if it failed due
@@ -2354,17 +2354,17 @@
                // Otherwise _value._fingerprint is the array.
 
   // Remap BasicTypes that are handled equivalently by the adapters.
   // These are correct for the current system but someday it might be
   // necessary to make this mapping platform dependent.
-  static int adapter_encoding(BasicType in, bool is_valuetype) {
+  static int adapter_encoding(BasicType in, bool is_inlinetype) {
     switch (in) {
       case T_BOOLEAN:
       case T_BYTE:
       case T_SHORT:
       case T_CHAR: {
-        if (is_valuetype) {
+        if (is_inlinetype) {
           // Do not widen inline type field types
           assert(InlineTypePassFieldsAsArgs, "must be enabled");
           return in;
         } else {
           // They are all promoted to T_INT in the calling convention
@@ -2433,12 +2433,12 @@
           BasicType sbt = sig->at(sig_index++)._bt;
           if (InlineTypePassFieldsAsArgs && sbt == T_INLINE_TYPE) {
             // Found start of inline type in signature
             vt_count++;
             if (sig_index == 1 && has_ro_adapter) {
-              // With a ro_adapter, replace receiver value type delimiter by T_VOID to prevent matching
-              // with other adapters that have the same value type as first argument and no receiver.
+              // With a ro_adapter, replace receiver inline type delimiter by T_VOID to prevent matching
+              // with other adapters that have the same inline type as first argument and no receiver.
               sbt = T_VOID;
             }
           } else if (InlineTypePassFieldsAsArgs && sbt == T_VOID &&
                      prev_sbt != T_LONG && prev_sbt != T_DOUBLE) {
             // Found end of inline type in signature
@@ -2538,15 +2538,15 @@
   AdapterHandlerTable()
     : BasicHashtable<mtCode>(293, (DumpSharedSpaces ? sizeof(CDSAdapterHandlerEntry) : sizeof(AdapterHandlerEntry))) { }
 
   // Create a new entry suitable for insertion in the table
   AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint, address i2c_entry, address c2i_entry,
-                                 address c2i_value_entry, address c2i_value_ro_entry,
-                                 address c2i_unverified_entry, address c2i_unverified_value_entry, address c2i_no_clinit_check_entry) {
+                                 address c2i_inline_entry, address c2i_inline_ro_entry,
+                                 address c2i_unverified_entry, address c2i_unverified_inline_entry, address c2i_no_clinit_check_entry) {
     AdapterHandlerEntry* entry = (AdapterHandlerEntry*)BasicHashtable<mtCode>::new_entry(fingerprint->compute_hash());
-    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_value_entry, c2i_value_ro_entry,
-                c2i_unverified_entry, c2i_unverified_value_entry, c2i_no_clinit_check_entry);
+    entry->init(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry,
+                c2i_unverified_entry, c2i_unverified_inline_entry, c2i_no_clinit_check_entry);
     if (DumpSharedSpaces) {
       ((CDSAdapterHandlerEntry*)entry)->init();
     }
     return entry;
   }
@@ -2692,17 +2692,17 @@
 }
 
 AdapterHandlerEntry* AdapterHandlerLibrary::new_entry(AdapterFingerPrint* fingerprint,
                                                       address i2c_entry,
                                                       address c2i_entry,
-                                                      address c2i_value_entry,
-                                                      address c2i_value_ro_entry,
+                                                      address c2i_inline_entry,
+                                                      address c2i_inline_ro_entry,
                                                       address c2i_unverified_entry,
-                                                      address c2i_unverified_value_entry,
+                                                      address c2i_unverified_inline_entry,
                                                       address c2i_no_clinit_check_entry) {
-  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_value_entry, c2i_value_ro_entry, c2i_unverified_entry,
-                              c2i_unverified_value_entry, c2i_no_clinit_check_entry);
+  return _adapters->new_entry(fingerprint, i2c_entry, c2i_entry, c2i_inline_entry, c2i_inline_ro_entry, c2i_unverified_entry,
+                              c2i_unverified_inline_entry, c2i_no_clinit_check_entry);
 }
 
 static void generate_trampoline(address trampoline, address destination) {
   if (*(int*)trampoline == 0) {
     CodeBuffer buffer(trampoline, (int)SharedRuntime::trampoline_size());
@@ -2724,20 +2724,20 @@
     MutexLocker mu(AdapterHandlerLibrary_lock);
     if (method->adapter() == NULL) {
       method->update_adapter_trampoline(entry);
     }
     generate_trampoline(method->from_compiled_entry(),          entry->get_c2i_entry());
-    generate_trampoline(method->from_compiled_value_ro_entry(), entry->get_c2i_value_ro_entry());
-    generate_trampoline(method->from_compiled_value_entry(),    entry->get_c2i_value_entry());
+    generate_trampoline(method->from_compiled_inline_ro_entry(), entry->get_c2i_inline_ro_entry());
+    generate_trampoline(method->from_compiled_inline_entry(),    entry->get_c2i_inline_entry());
   }
 
   return entry;
 }
 
 
 CompiledEntrySignature::CompiledEntrySignature(Method* method) :
-  _method(method), _num_value_args(0), _has_value_recv(false),
+  _method(method), _num_inline_args(0), _has_inline_recv(false),
   _sig_cc(NULL), _sig_cc_ro(NULL), _regs(NULL), _regs_cc(NULL), _regs_cc_ro(NULL),
   _args_on_stack(0), _args_on_stack_cc(0), _args_on_stack_cc_ro(0),
   _c1_needs_stack_repair(false), _c2_needs_stack_repair(false), _has_scalarized_args(false) {
   _has_reserved_entries = false;
   _sig = new GrowableArray<SigEntry>(method->size_of_parameters());
@@ -2790,92 +2790,92 @@
   // Insert reserved entry and re-compute calling convention
   SigEntry::insert_reserved_entry(_sig_cc, i, bt);
   return SharedRuntime::java_calling_convention(_sig_cc, _regs_cc);
 }
 
-// See if we can save space by sharing the same entry for VVEP and VVEP(RO),
-// or the same entry for VEP and VVEP(RO).
-CodeOffsets::Entries CompiledEntrySignature::c1_value_ro_entry_type() const {
+// See if we can save space by sharing the same entry for VIEP and VIEP(RO),
+// or the same entry for VEP and VIEP(RO).
+CodeOffsets::Entries CompiledEntrySignature::c1_inline_ro_entry_type() const {
   if (!has_scalarized_args()) {
-    // VEP/VVEP/VVEP(RO) all share the same entry. There's no packing.
+    // VEP/VIEP/VIEP(RO) all share the same entry. There's no packing.
     return CodeOffsets::Verified_Entry;
   }
   if (_method->is_static()) {
-    // Static methods don't need VVEP(RO)
+    // Static methods don't need VIEP(RO)
     return CodeOffsets::Verified_Entry;
   }
 
-  if (has_value_recv()) {
-    if (num_value_args() == 1) {
-      // Share same entry for VVEP and VVEP(RO).
+  if (has_inline_recv()) {
+    if (num_inline_args() == 1) {
+      // Share same entry for VIEP and VIEP(RO).
       // This is quite common: we have an instance method in a InlineKlass that has
-      // no value args other than <this>.
-      return CodeOffsets::Verified_Value_Entry;
+      // no inline type args other than <this>.
+      return CodeOffsets::Verified_Inline_Entry;
     } else {
-      assert(num_value_args() > 1, "must be");
+      assert(num_inline_args() > 1, "must be");
       // No sharing:
-      //   VVEP(RO) -- <this> is passed as object
+      //   VIEP(RO) -- <this> is passed as object
       //   VEP      -- <this> is passed as fields
-      return CodeOffsets::Verified_Value_Entry_RO;
+      return CodeOffsets::Verified_Inline_Entry_RO;
     }
   }
 
-  // Either a static method, or <this> is not a value type
+  // Either a static method, or <this> is not an inline type
   if (args_on_stack_cc() != args_on_stack_cc_ro() || _has_reserved_entries) {
     // No sharing:
     // Some arguments are passed on the stack, and we have inserted reserved entries
-    // into the VEP, but we never insert reserved entries into the VVEP(RO).
-    return CodeOffsets::Verified_Value_Entry_RO;
+    // into the VEP, but we never insert reserved entries into the VIEP(RO).
+    return CodeOffsets::Verified_Inline_Entry_RO;
   } else {
-    // Share same entry for VEP and VVEP(RO).
+    // Share same entry for VEP and VIEP(RO).
     return CodeOffsets::Verified_Entry;
   }
 }
 
 
 void CompiledEntrySignature::compute_calling_conventions() {
   // Get the (non-scalarized) signature and check for inline type arguments
   if (!_method->is_static()) {
     if (_method->method_holder()->is_inline_klass() && InlineKlass::cast(_method->method_holder())->can_be_passed_as_fields()) {
-      _has_value_recv = true;
-      _num_value_args++;
+      _has_inline_recv = true;
+      _num_inline_args++;
     }
     SigEntry::add_entry(_sig, T_OBJECT);
   }
   for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {
     BasicType bt = ss.type();
     if (bt == T_INLINE_TYPE) {
       if (ss.as_inline_klass(_method->method_holder())->can_be_passed_as_fields()) {
-        _num_value_args++;
+        _num_inline_args++;
       }
       bt = T_OBJECT;
     }
     SigEntry::add_entry(_sig, bt);
   }
-  if (_method->is_abstract() && !has_value_arg()) {
+  if (_method->is_abstract() && !has_inline_arg()) {
     return;
   }
 
   // Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage
   _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig->length());
   _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);
 
-  // Now compute the scalarized calling convention if there are value types in the signature
+  // Now compute the scalarized calling convention if there are inline types in the signature
   _sig_cc = _sig;
   _sig_cc_ro = _sig;
   _regs_cc = _regs;
   _regs_cc_ro = _regs;
   _args_on_stack_cc = _args_on_stack;
   _args_on_stack_cc_ro = _args_on_stack;
 
-  if (has_value_arg() && !_method->is_native()) {
+  if (has_inline_arg() && !_method->is_native()) {
     _args_on_stack_cc = compute_scalarized_cc(_sig_cc, _regs_cc, /* scalar_receiver = */ true);
 
     _sig_cc_ro = _sig_cc;
     _regs_cc_ro = _regs_cc;
     _args_on_stack_cc_ro = _args_on_stack_cc;
-    if (_has_value_recv || _args_on_stack_cc > _args_on_stack) {
+    if (_has_inline_recv || _args_on_stack_cc > _args_on_stack) {
       // For interface calls, we need another entry point / adapter to unpack the receiver
       _args_on_stack_cc_ro = compute_scalarized_cc(_sig_cc_ro, _regs_cc_ro, /* scalar_receiver = */ false);
     }
 
     // Compute the stack extension that is required to convert between the calling conventions.
@@ -3103,14 +3103,14 @@
 
 address AdapterHandlerEntry::base_address() {
   address base = _i2c_entry;
   if (base == NULL)  base = _c2i_entry;
   assert(base <= _c2i_entry || _c2i_entry == NULL, "");
-  assert(base <= _c2i_value_entry || _c2i_value_entry == NULL, "");
-  assert(base <= _c2i_value_ro_entry || _c2i_value_ro_entry == NULL, "");
+  assert(base <= _c2i_inline_entry || _c2i_inline_entry == NULL, "");
+  assert(base <= _c2i_inline_ro_entry || _c2i_inline_ro_entry == NULL, "");
   assert(base <= _c2i_unverified_entry || _c2i_unverified_entry == NULL, "");
-  assert(base <= _c2i_unverified_value_entry || _c2i_unverified_value_entry == NULL, "");
+  assert(base <= _c2i_unverified_inline_entry || _c2i_unverified_inline_entry == NULL, "");
   assert(base <= _c2i_no_clinit_check_entry || _c2i_no_clinit_check_entry == NULL, "");
   return base;
 }
 
 void AdapterHandlerEntry::relocate(address new_base) {
@@ -3119,18 +3119,18 @@
   ptrdiff_t delta = new_base - old_base;
   if (_i2c_entry != NULL)
     _i2c_entry += delta;
   if (_c2i_entry != NULL)
     _c2i_entry += delta;
-  if (_c2i_value_entry != NULL)
-    _c2i_value_entry += delta;
-  if (_c2i_value_ro_entry != NULL)
-    _c2i_value_ro_entry += delta;
+  if (_c2i_inline_entry != NULL)
+    _c2i_inline_entry += delta;
+  if (_c2i_inline_ro_entry != NULL)
+    _c2i_inline_ro_entry += delta;
   if (_c2i_unverified_entry != NULL)
     _c2i_unverified_entry += delta;
-  if (_c2i_unverified_value_entry != NULL)
-    _c2i_unverified_value_entry += delta;
+  if (_c2i_unverified_inline_entry != NULL)
+    _c2i_unverified_inline_entry += delta;
   if (_c2i_no_clinit_check_entry != NULL)
     _c2i_no_clinit_check_entry += delta;
   assert(base_address() == new_base, "");
 }
 
@@ -3476,20 +3476,20 @@
   }
   if (get_c2i_entry() != NULL) {
     st->print(" c2i: " INTPTR_FORMAT, p2i(get_c2i_entry()));
   }
   if (get_c2i_entry() != NULL) {
-    st->print(" c2iVE: " INTPTR_FORMAT, p2i(get_c2i_value_entry()));
+    st->print(" c2iVE: " INTPTR_FORMAT, p2i(get_c2i_inline_entry()));
   }
   if (get_c2i_entry() != NULL) {
-    st->print(" c2iVROE: " INTPTR_FORMAT, p2i(get_c2i_value_ro_entry()));
+    st->print(" c2iVROE: " INTPTR_FORMAT, p2i(get_c2i_inline_ro_entry()));
   }
   if (get_c2i_unverified_entry() != NULL) {
     st->print(" c2iUE: " INTPTR_FORMAT, p2i(get_c2i_unverified_entry()));
   }
   if (get_c2i_unverified_entry() != NULL) {
-    st->print(" c2iUVE: " INTPTR_FORMAT, p2i(get_c2i_unverified_value_entry()));
+    st->print(" c2iUVE: " INTPTR_FORMAT, p2i(get_c2i_unverified_inline_entry()));
   }
   if (get_c2i_no_clinit_check_entry() != NULL) {
     st->print(" c2iNCI: " INTPTR_FORMAT, p2i(get_c2i_no_clinit_check_entry()));
   }
   st->cr();
@@ -3498,12 +3498,12 @@
 #if INCLUDE_CDS
 
 void CDSAdapterHandlerEntry::init() {
   assert(DumpSharedSpaces, "used during dump time only");
   _c2i_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());
-  _c2i_value_ro_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());
-  _c2i_value_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());
+  _c2i_inline_ro_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());
+  _c2i_inline_entry_trampoline = (address)MetaspaceShared::misc_code_space_alloc(SharedRuntime::trampoline_size());
   _adapter_trampoline = (AdapterHandlerEntry**)MetaspaceShared::misc_code_space_alloc(sizeof(AdapterHandlerEntry*));
 };
 
 #endif // INCLUDE_CDS
 
@@ -3590,11 +3590,11 @@
 
 // We are at a compiled code to interpreter call. We need backing
 // buffers for all inline type arguments. Allocate an object array to
 // hold them (convenient because once we're done with it we don't have
 // to worry about freeing it).
-oop SharedRuntime::allocate_value_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
+oop SharedRuntime::allocate_inline_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
   assert(InlineTypePassFieldsAsArgs, "no reason to call this");
   ResourceMark rm;
 
   int nb_slots = 0;
   InstanceKlass* holder = callee->method_holder();
@@ -3625,19 +3625,19 @@
     }
   }
   return array();
 }
 
-JRT_ENTRY(void, SharedRuntime::allocate_value_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
+JRT_ENTRY(void, SharedRuntime::allocate_inline_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
   methodHandle callee(thread, callee_method);
-  oop array = SharedRuntime::allocate_value_types_impl(thread, callee, allocate_receiver, CHECK);
+  oop array = SharedRuntime::allocate_inline_types_impl(thread, callee, allocate_receiver, CHECK);
   thread->set_vm_result(array);
   thread->set_vm_result_2(callee()); // TODO: required to keep callee live?
 JRT_END
 
 // TODO remove this once the AARCH64 dependency is gone
-// Iterate over the array of heap allocated value types and apply the GC post barrier to all reference fields.
+// Iterate over the array of heap allocated inline types and apply the GC post barrier to all reference fields.
 // This is called from the C2I adapter after inline type arguments are heap allocated and initialized.
 JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))
 {
   assert(InlineTypePassFieldsAsArgs, "no reason to call this");
   assert(oopDesc::is_oop(array), "should be oop");
