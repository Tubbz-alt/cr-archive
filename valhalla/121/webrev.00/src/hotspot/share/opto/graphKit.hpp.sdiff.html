<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/graphKit.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="graphKit.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="library_call.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/graphKit.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_GRAPHKIT_HPP
 26 #define SHARE_OPTO_GRAPHKIT_HPP
 27 
 28 #include &quot;ci/ciEnv.hpp&quot;
 29 #include &quot;ci/ciMethodData.hpp&quot;
 30 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
 31 #include &quot;opto/addnode.hpp&quot;
 32 #include &quot;opto/callnode.hpp&quot;
 33 #include &quot;opto/cfgnode.hpp&quot;
 34 #include &quot;opto/compile.hpp&quot;
 35 #include &quot;opto/divnode.hpp&quot;

 36 #include &quot;opto/mulnode.hpp&quot;
 37 #include &quot;opto/phaseX.hpp&quot;
 38 #include &quot;opto/subnode.hpp&quot;
 39 #include &quot;opto/type.hpp&quot;
<span class="line-removed"> 40 #include &quot;opto/valuetypenode.hpp&quot;</span>
 41 #include &quot;runtime/deoptimization.hpp&quot;
 42 
 43 class BarrierSetC2;
 44 class FastLockNode;
 45 class FastUnlockNode;
 46 class IdealKit;
 47 class LibraryCallKit;
 48 class Parse;
 49 class RootNode;
 50 
 51 //-----------------------------------------------------------------------------
 52 //----------------------------GraphKit-----------------------------------------
 53 // Toolkit for building the common sorts of subgraphs.
 54 // Does not know about bytecode parsing or type-flow results.
 55 // It is able to create graphs implementing the semantics of most
 56 // or all bytecodes, so that it can expand intrinsics and calls.
 57 // It may depend on JVMState structure, but it must not depend
 58 // on specific bytecode streams.
 59 class GraphKit : public Phase {
 60   friend class PreserveJVMState;
</pre>
<hr />
<pre>
361   Node* null_check_receiver() {
362     assert(argument(0)-&gt;bottom_type()-&gt;isa_ptr(), &quot;must be&quot;);
363     return null_check(argument(0));
364   }
365   Node* zero_check_int(Node* value) {
366     assert(value-&gt;bottom_type()-&gt;basic_type() == T_INT,
367            &quot;wrong type: %s&quot;, type2name(value-&gt;bottom_type()-&gt;basic_type()));
368     return null_check_common(value, T_INT);
369   }
370   Node* zero_check_long(Node* value) {
371     assert(value-&gt;bottom_type()-&gt;basic_type() == T_LONG,
372            &quot;wrong type: %s&quot;, type2name(value-&gt;bottom_type()-&gt;basic_type()));
373     return null_check_common(value, T_LONG);
374   }
375   // Throw an uncommon trap if a given value is __not__ null.
376   // Return the value cast to null, and be clever about dominating checks.
377   Node* null_assert(Node* value, BasicType type = T_OBJECT) {
378     return null_check_common(value, type, true, NULL, _gvn.type(value)-&gt;speculative_always_null());
379   }
380 
<span class="line-modified">381   Node* null2default(Node* value, ciValueKlass* vk = NULL);</span>
382 
383   // Check if value is null and abort if it is
384   Node* must_be_not_null(Node* value, bool do_replace_in_map);
385 
386   // Null check oop.  Return null-path control into (*null_control).
387   // Return a cast-not-null node which depends on the not-null control.
388   // If never_see_null, use an uncommon trap (*null_control sees a top).
389   // The cast is not valid along the null path; keep a copy of the original.
390   // If safe_for_replace, then we can replace the value with the cast
391   // in the parsing map (the cast is guaranteed to dominate the map)
392   Node* null_check_oop(Node* value, Node* *null_control,
393                        bool never_see_null = false,
394                        bool safe_for_replace = false,
395                        bool speculative = false);
396 
397   // Check the null_seen bit.
398   bool seems_never_null(Node* obj, ciProfileData* data, bool&amp; speculating);
399 
400   void guard_klass_being_initialized(Node* klass);
401   void guard_init_thread(Node* klass);
</pre>
<hr />
<pre>
668     make_dtrace_method_entry_exit(method, true);
669   }
670   void make_dtrace_method_exit(ciMethod* method) {
671     make_dtrace_method_entry_exit(method, false);
672   }
673 
674   //--------------- stub generation -------------------
675  public:
676   void gen_stub(address C_function,
677                 const char *name,
678                 int is_fancy_jump,
679                 bool pass_tls,
680                 bool return_pc);
681 
682   //---------- help for generating calls --------------
683 
684   // Do a null check on the receiver as it would happen before the call to
685   // callee (with all arguments still on the stack).
686   Node* null_check_receiver_before_call(ciMethod* callee, bool replace_value = true) {
687     assert(!callee-&gt;is_static(), &quot;must be a virtual method&quot;);
<span class="line-modified">688     if (argument(0)-&gt;is_ValueType()) {</span>
689       return argument(0);
690     }
691     // Callsite signature can be different from actual method being called (i.e _linkTo* sites).
692     // Use callsite signature always.
693     ciMethod* declared_method = method()-&gt;get_method_at_bci(bci());
694     const int nargs = declared_method-&gt;arg_size();
695     inc_sp(nargs);
696     Node* n = null_check_receiver();
697     dec_sp(nargs);
<span class="line-modified">698     // Scalarize value type receiver</span>
699     const Type* recv_type = gvn().type(n);
<span class="line-modified">700     if (recv_type-&gt;is_valuetypeptr() &amp;&amp; recv_type-&gt;value_klass()-&gt;is_scalarizable()) {</span>
701       assert(!recv_type-&gt;maybe_null(), &quot;should never be null&quot;);
<span class="line-modified">702       ValueTypeNode* vt = ValueTypeNode::make_from_oop(this, n, recv_type-&gt;value_klass());</span>
703       set_argument(0, vt);
704       if (replace_value &amp;&amp; !Compile::current()-&gt;inlining_incrementally()) {
705         // Only replace in map if we are not incrementally inlining because we
<span class="line-modified">706         // share a map with the caller which might expect the value type as oop.</span>
707         replace_in_map(n, vt);
708       }
709       n = vt;
710     }
711     return n;
712   }
713 
714   // Fill in argument edges for the call from argument(0), argument(1), ...
715   // (The next step is to call set_edges_for_java_call.)
716   void  set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline = false);
717 
718   // Fill in non-argument edges for the call.
719   // Transform the call, and update the basics: control, i_o, memory.
720   // (The next step is usually to call set_results_for_java_call.)
721   void set_edges_for_java_call(CallJavaNode* call,
722                                bool must_throw = false, bool separate_io_proj = false);
723 
724   // Finish up a java call that was started by set_edges_for_java_call.
725   // Call add_exception on any throw arising from the call.
726   // Return the call result (transformed).
</pre>
<hr />
<pre>
836 
837   // Helper functions to build synchronizations
838   int next_monitor();
839   Node* insert_mem_bar(int opcode, Node* precedent = NULL);
840   Node* insert_mem_bar_volatile(int opcode, int alias_idx, Node* precedent = NULL);
841   // Optional &#39;precedent&#39; is appended as an extra edge, to force ordering.
842   FastLockNode* shared_lock(Node* obj);
843   void shared_unlock(Node* box, Node* obj);
844 
845   // helper functions for the fast path/slow path idioms
846   Node* fast_and_slow(Node* in, const Type *result_type, Node* null_result, IfNode* fast_test, Node* fast_result, address slow_call, const TypeFunc *slow_call_type, Node* slow_arg, Klass* ex_klass, Node* slow_result);
847 
848   // Generate an instance-of idiom.  Used by both the instance-of bytecode
849   // and the reflective instance-of call.
850   Node* gen_instanceof(Node *subobj, Node* superkls, bool safe_for_replace = false);
851 
852   // Generate a check-cast idiom.  Used by both the check-cast bytecode
853   // and the array-store bytecode
854   Node* gen_checkcast(Node *subobj, Node* superkls, Node* *failure_control = NULL);
855 
<span class="line-modified">856   Node* is_value_type(Node* obj);</span>
857   Node* is_non_flattened_array(Node* ary);
858   Node* is_nullable_array(Node* ary);
<span class="line-modified">859   Node* gen_value_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace = false);</span>
860   Node* load_lh_array_tag(Node* kls);
861   Node* gen_lh_array_test(Node* kls, unsigned int lh_value);
862 
863   Node* gen_subtype_check(Node* obj, Node* superklass);
864 
865   // Exact type check used for predicted calls and casts.
866   // Rewrites (*casted_receiver) to be casted to the stronger type.
867   // (Caller is responsible for doing replace_in_map.)
868   Node* type_check_receiver(Node* receiver, ciKlass* klass, float prob,
869                             Node* *casted_receiver);
870   Node* type_check(Node* recv_klass, const TypeKlassPtr* tklass, float prob);
871 
872   // Inexact type check used for predicted calls.
873   Node* subtype_check_receiver(Node* receiver, ciKlass* klass,
874                                Node** casted_receiver);
875 
876   // implementation of object creation
877   Node* set_output_for_allocation(AllocateNode* alloc,
878                                   const TypeOopPtr* oop_type,
879                                   bool deoptimize_on_exception=false);
880   Node* get_layout_helper(Node* klass_node, jint&amp; constant_value);
881   Node* new_instance(Node* klass_node,
882                      Node* slow_test = NULL,
883                      Node* *return_size_val = NULL,
884                      bool deoptimize_on_exception = false,
<span class="line-modified">885                      ValueTypeBaseNode* value_node = NULL);</span>
886   Node* new_array(Node* klass_node, Node* count_val, int nargs,
887                   Node* *return_size_val = NULL,
888                   bool deoptimize_on_exception = false);
889 
890   // java.lang.String helpers
891   Node* load_String_length(Node* str, bool set_ctrl);
892   Node* load_String_value(Node* str, bool set_ctrl);
893   Node* load_String_coder(Node* str, bool set_ctrl);
894   void store_String_value(Node* str, Node* value);
895   void store_String_coder(Node* str, Node* value);
896   Node* capture_memory(const TypePtr* src_type, const TypePtr* dst_type);
897   Node* compress_string(Node* src, const TypeAryPtr* src_type, Node* dst, Node* count);
898   void inflate_string(Node* src, Node* dst, const TypeAryPtr* dst_type, Node* count);
899   void inflate_string_slow(Node* src, Node* dst, Node* start, Node* count);
900 
901   // Handy for making control flow
902   IfNode* create_and_map_if(Node* ctrl, Node* tst, float prob, float cnt) {
903     IfNode* iff = new IfNode(ctrl, tst, prob, cnt);// New IfNode&#39;s
904     _gvn.set_type(iff, iff-&gt;Value(&amp;_gvn)); // Value may be known at parse-time
905     // Place &#39;if&#39; on worklist if it will be in graph
</pre>
</td>
<td>
<hr />
<pre>
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_GRAPHKIT_HPP
 26 #define SHARE_OPTO_GRAPHKIT_HPP
 27 
 28 #include &quot;ci/ciEnv.hpp&quot;
 29 #include &quot;ci/ciMethodData.hpp&quot;
 30 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
 31 #include &quot;opto/addnode.hpp&quot;
 32 #include &quot;opto/callnode.hpp&quot;
 33 #include &quot;opto/cfgnode.hpp&quot;
 34 #include &quot;opto/compile.hpp&quot;
 35 #include &quot;opto/divnode.hpp&quot;
<span class="line-added"> 36 #include &quot;opto/inlinetypenode.hpp&quot;</span>
 37 #include &quot;opto/mulnode.hpp&quot;
 38 #include &quot;opto/phaseX.hpp&quot;
 39 #include &quot;opto/subnode.hpp&quot;
 40 #include &quot;opto/type.hpp&quot;

 41 #include &quot;runtime/deoptimization.hpp&quot;
 42 
 43 class BarrierSetC2;
 44 class FastLockNode;
 45 class FastUnlockNode;
 46 class IdealKit;
 47 class LibraryCallKit;
 48 class Parse;
 49 class RootNode;
 50 
 51 //-----------------------------------------------------------------------------
 52 //----------------------------GraphKit-----------------------------------------
 53 // Toolkit for building the common sorts of subgraphs.
 54 // Does not know about bytecode parsing or type-flow results.
 55 // It is able to create graphs implementing the semantics of most
 56 // or all bytecodes, so that it can expand intrinsics and calls.
 57 // It may depend on JVMState structure, but it must not depend
 58 // on specific bytecode streams.
 59 class GraphKit : public Phase {
 60   friend class PreserveJVMState;
</pre>
<hr />
<pre>
361   Node* null_check_receiver() {
362     assert(argument(0)-&gt;bottom_type()-&gt;isa_ptr(), &quot;must be&quot;);
363     return null_check(argument(0));
364   }
365   Node* zero_check_int(Node* value) {
366     assert(value-&gt;bottom_type()-&gt;basic_type() == T_INT,
367            &quot;wrong type: %s&quot;, type2name(value-&gt;bottom_type()-&gt;basic_type()));
368     return null_check_common(value, T_INT);
369   }
370   Node* zero_check_long(Node* value) {
371     assert(value-&gt;bottom_type()-&gt;basic_type() == T_LONG,
372            &quot;wrong type: %s&quot;, type2name(value-&gt;bottom_type()-&gt;basic_type()));
373     return null_check_common(value, T_LONG);
374   }
375   // Throw an uncommon trap if a given value is __not__ null.
376   // Return the value cast to null, and be clever about dominating checks.
377   Node* null_assert(Node* value, BasicType type = T_OBJECT) {
378     return null_check_common(value, type, true, NULL, _gvn.type(value)-&gt;speculative_always_null());
379   }
380 
<span class="line-modified">381   Node* null2default(Node* value, ciInlineKlass* vk = NULL);</span>
382 
383   // Check if value is null and abort if it is
384   Node* must_be_not_null(Node* value, bool do_replace_in_map);
385 
386   // Null check oop.  Return null-path control into (*null_control).
387   // Return a cast-not-null node which depends on the not-null control.
388   // If never_see_null, use an uncommon trap (*null_control sees a top).
389   // The cast is not valid along the null path; keep a copy of the original.
390   // If safe_for_replace, then we can replace the value with the cast
391   // in the parsing map (the cast is guaranteed to dominate the map)
392   Node* null_check_oop(Node* value, Node* *null_control,
393                        bool never_see_null = false,
394                        bool safe_for_replace = false,
395                        bool speculative = false);
396 
397   // Check the null_seen bit.
398   bool seems_never_null(Node* obj, ciProfileData* data, bool&amp; speculating);
399 
400   void guard_klass_being_initialized(Node* klass);
401   void guard_init_thread(Node* klass);
</pre>
<hr />
<pre>
668     make_dtrace_method_entry_exit(method, true);
669   }
670   void make_dtrace_method_exit(ciMethod* method) {
671     make_dtrace_method_entry_exit(method, false);
672   }
673 
674   //--------------- stub generation -------------------
675  public:
676   void gen_stub(address C_function,
677                 const char *name,
678                 int is_fancy_jump,
679                 bool pass_tls,
680                 bool return_pc);
681 
682   //---------- help for generating calls --------------
683 
684   // Do a null check on the receiver as it would happen before the call to
685   // callee (with all arguments still on the stack).
686   Node* null_check_receiver_before_call(ciMethod* callee, bool replace_value = true) {
687     assert(!callee-&gt;is_static(), &quot;must be a virtual method&quot;);
<span class="line-modified">688     if (argument(0)-&gt;is_InlineType()) {</span>
689       return argument(0);
690     }
691     // Callsite signature can be different from actual method being called (i.e _linkTo* sites).
692     // Use callsite signature always.
693     ciMethod* declared_method = method()-&gt;get_method_at_bci(bci());
694     const int nargs = declared_method-&gt;arg_size();
695     inc_sp(nargs);
696     Node* n = null_check_receiver();
697     dec_sp(nargs);
<span class="line-modified">698     // Scalarize inline type receiver</span>
699     const Type* recv_type = gvn().type(n);
<span class="line-modified">700     if (recv_type-&gt;is_inlinetypeptr() &amp;&amp; recv_type-&gt;inline_klass()-&gt;is_scalarizable()) {</span>
701       assert(!recv_type-&gt;maybe_null(), &quot;should never be null&quot;);
<span class="line-modified">702       InlineTypeNode* vt = InlineTypeNode::make_from_oop(this, n, recv_type-&gt;inline_klass());</span>
703       set_argument(0, vt);
704       if (replace_value &amp;&amp; !Compile::current()-&gt;inlining_incrementally()) {
705         // Only replace in map if we are not incrementally inlining because we
<span class="line-modified">706         // share a map with the caller which might expect the inline type as oop.</span>
707         replace_in_map(n, vt);
708       }
709       n = vt;
710     }
711     return n;
712   }
713 
714   // Fill in argument edges for the call from argument(0), argument(1), ...
715   // (The next step is to call set_edges_for_java_call.)
716   void  set_arguments_for_java_call(CallJavaNode* call, bool is_late_inline = false);
717 
718   // Fill in non-argument edges for the call.
719   // Transform the call, and update the basics: control, i_o, memory.
720   // (The next step is usually to call set_results_for_java_call.)
721   void set_edges_for_java_call(CallJavaNode* call,
722                                bool must_throw = false, bool separate_io_proj = false);
723 
724   // Finish up a java call that was started by set_edges_for_java_call.
725   // Call add_exception on any throw arising from the call.
726   // Return the call result (transformed).
</pre>
<hr />
<pre>
836 
837   // Helper functions to build synchronizations
838   int next_monitor();
839   Node* insert_mem_bar(int opcode, Node* precedent = NULL);
840   Node* insert_mem_bar_volatile(int opcode, int alias_idx, Node* precedent = NULL);
841   // Optional &#39;precedent&#39; is appended as an extra edge, to force ordering.
842   FastLockNode* shared_lock(Node* obj);
843   void shared_unlock(Node* box, Node* obj);
844 
845   // helper functions for the fast path/slow path idioms
846   Node* fast_and_slow(Node* in, const Type *result_type, Node* null_result, IfNode* fast_test, Node* fast_result, address slow_call, const TypeFunc *slow_call_type, Node* slow_arg, Klass* ex_klass, Node* slow_result);
847 
848   // Generate an instance-of idiom.  Used by both the instance-of bytecode
849   // and the reflective instance-of call.
850   Node* gen_instanceof(Node *subobj, Node* superkls, bool safe_for_replace = false);
851 
852   // Generate a check-cast idiom.  Used by both the check-cast bytecode
853   // and the array-store bytecode
854   Node* gen_checkcast(Node *subobj, Node* superkls, Node* *failure_control = NULL);
855 
<span class="line-modified">856   Node* is_inline_type(Node* obj);</span>
857   Node* is_non_flattened_array(Node* ary);
858   Node* is_nullable_array(Node* ary);
<span class="line-modified">859   Node* gen_inline_array_null_guard(Node* ary, Node* val, int nargs, bool safe_for_replace = false);</span>
860   Node* load_lh_array_tag(Node* kls);
861   Node* gen_lh_array_test(Node* kls, unsigned int lh_value);
862 
863   Node* gen_subtype_check(Node* obj, Node* superklass);
864 
865   // Exact type check used for predicted calls and casts.
866   // Rewrites (*casted_receiver) to be casted to the stronger type.
867   // (Caller is responsible for doing replace_in_map.)
868   Node* type_check_receiver(Node* receiver, ciKlass* klass, float prob,
869                             Node* *casted_receiver);
870   Node* type_check(Node* recv_klass, const TypeKlassPtr* tklass, float prob);
871 
872   // Inexact type check used for predicted calls.
873   Node* subtype_check_receiver(Node* receiver, ciKlass* klass,
874                                Node** casted_receiver);
875 
876   // implementation of object creation
877   Node* set_output_for_allocation(AllocateNode* alloc,
878                                   const TypeOopPtr* oop_type,
879                                   bool deoptimize_on_exception=false);
880   Node* get_layout_helper(Node* klass_node, jint&amp; constant_value);
881   Node* new_instance(Node* klass_node,
882                      Node* slow_test = NULL,
883                      Node* *return_size_val = NULL,
884                      bool deoptimize_on_exception = false,
<span class="line-modified">885                      InlineTypeBaseNode* inline_type_node = NULL);</span>
886   Node* new_array(Node* klass_node, Node* count_val, int nargs,
887                   Node* *return_size_val = NULL,
888                   bool deoptimize_on_exception = false);
889 
890   // java.lang.String helpers
891   Node* load_String_length(Node* str, bool set_ctrl);
892   Node* load_String_value(Node* str, bool set_ctrl);
893   Node* load_String_coder(Node* str, bool set_ctrl);
894   void store_String_value(Node* str, Node* value);
895   void store_String_coder(Node* str, Node* value);
896   Node* capture_memory(const TypePtr* src_type, const TypePtr* dst_type);
897   Node* compress_string(Node* src, const TypeAryPtr* src_type, Node* dst, Node* count);
898   void inflate_string(Node* src, Node* dst, const TypeAryPtr* dst_type, Node* count);
899   void inflate_string_slow(Node* src, Node* dst, Node* start, Node* count);
900 
901   // Handy for making control flow
902   IfNode* create_and_map_if(Node* ctrl, Node* tst, float prob, float cnt) {
903     IfNode* iff = new IfNode(ctrl, tst, prob, cnt);// New IfNode&#39;s
904     _gvn.set_type(iff, iff-&gt;Value(&amp;_gvn)); // Value may be known at parse-time
905     // Place &#39;if&#39; on worklist if it will be in graph
</pre>
</td>
</tr>
</table>
<center><a href="graphKit.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="library_call.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>