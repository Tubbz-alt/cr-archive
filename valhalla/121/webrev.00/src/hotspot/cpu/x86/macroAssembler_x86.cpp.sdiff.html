<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
3612     jcc(Assembler::notZero, loop);
3613   }
3614 
3615   bind(done);
3616 }
3617 
3618 void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {
3619   movptr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));
3620 #ifdef ASSERT
3621   {
3622     Label done;
3623     cmpptr(inline_klass, 0);
3624     jcc(Assembler::notEqual, done);
3625     stop(&quot;get_inline_type_field_klass contains no inline klass&quot;);
3626     bind(done);
3627   }
3628 #endif
3629   movptr(inline_klass, Address(inline_klass, index, Address::times_ptr));
3630 }
3631 
<span class="line-modified">3632 void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
3633 #ifdef ASSERT
3634   {
3635     Label done_check;
<span class="line-modified">3636     test_klass_is_inline_type(value_klass, temp_reg, done_check);</span>
3637     stop(&quot;get_default_value_oop from non inline type klass&quot;);
3638     bind(done_check);
3639   }
3640 #endif
3641   Register offset = temp_reg;
3642   // Getting the offset of the pre-allocated default value
<span class="line-modified">3643   movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));</span>
3644   movl(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));
3645 
3646   // Getting the mirror
<span class="line-modified">3647   movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="line-modified">3648   resolve_oop_handle(obj, value_klass);</span>
3649 
3650   // Getting the pre-allocated default value from the mirror
3651   Address field(obj, offset, Address::times_1);
3652   load_heap_oop(obj, field);
3653 }
3654 
3655 void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {
3656 #ifdef ASSERT
3657   {
3658     Label done_check;
3659     test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);
3660     stop(&quot;get_empty_value from non-empty inline klass&quot;);
3661     bind(done_check);
3662   }
3663 #endif
3664   get_default_value_oop(inline_klass, temp_reg, obj);
3665 }
3666 
3667 
3668 // Look up the method for a megamorphic invokeinterface call.
</pre>
<hr />
<pre>
4660   if (as_raw) {
4661     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4662   } else {
4663     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4664   }
4665 }
4666 
4667 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
4668                                      Register tmp1, Register tmp2, Register tmp3) {
4669   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4670   decorators = AccessInternal::decorator_fixup(decorators);
4671   bool as_raw = (decorators &amp; AS_RAW) != 0;
4672   if (as_raw) {
4673     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);
4674   } else {
4675     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);
4676   }
4677 }
4678 
4679 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,
<span class="line-modified">4680                                        Register value_klass) {</span>
4681   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
<span class="line-modified">4682   bs-&gt;value_copy(this, decorators, src, dst, value_klass);</span>
4683 }
4684 
<span class="line-modified">4685 void MacroAssembler::first_field_offset(Register value_klass, Register offset) {</span>
<span class="line-modified">4686   movptr(offset, Address(value_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));</span>
4687   movl(offset, Address(offset, InlineKlass::first_field_offset_offset()));
4688 }
4689 
<span class="line-modified">4690 void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {</span>
4691   // ((address) (void*) o) + vk-&gt;first_field_offset();
4692   Register offset = (data == oop) ? rscratch1 : data;
<span class="line-modified">4693   first_field_offset(value_klass, offset);</span>
4694   if (data == oop) {
4695     addptr(data, offset);
4696   } else {
4697     lea(data, Address(oop, offset));
4698   }
4699 }
4700 
4701 void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,
4702                                                 Register index, Register data) {
4703   assert(index != rcx, &quot;index needs to shift by rcx&quot;);
4704   assert_different_registers(array, array_klass, index);
4705   assert_different_registers(rcx, array, index);
4706 
4707   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));
4708   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));
4709 
4710   // Klass::layout_helper_log2_element_size(lh)
4711   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;
4712   shrl(rcx, Klass::_lh_log2_element_size_shift);
4713   andl(rcx, Klass::_lh_log2_element_size_mask);
</pre>
<hr />
<pre>
5188   } else {
5189     movdqu(Address(base,  0), xtmp);
5190     movdqu(Address(base, 16), xtmp);
5191   }
5192   addptr(base, 32);
5193   subptr(cnt, 4);
5194 
5195   BIND(L_tail);
5196   addptr(cnt, 4);
5197   jccb(Assembler::lessEqual, L_end);
5198   decrement(cnt);
5199 
5200   BIND(L_sloop);
5201   movq(Address(base, 0), xtmp);
5202   addptr(base, 8);
5203   decrement(cnt);
5204   jccb(Assembler::greaterEqual, L_sloop);
5205   BIND(L_end);
5206 }
5207 
<span class="line-modified">5208 int MacroAssembler::store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
5209   // An inline type might be returned. If fields are in registers we
5210   // need to allocate an inline type instance and initialize it with
5211   // the value of the fields.
5212   Label skip;
<span class="line-modified">5213   // We only need a new buffered value if a new one is not returned</span>
5214   testptr(rax, 1);
5215   jcc(Assembler::zero, skip);
5216   int call_offset = -1;
5217 
5218 #ifdef _LP64
5219   Label slow_case;
5220 
<span class="line-modified">5221   // Try to allocate a new buffered value (from the heap)</span>
5222   if (UseTLAB) {
5223     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.
5224     if (vk != NULL) {
5225       // Called from C1, where the return type is statically known.
<span class="line-modified">5226       movptr(rbx, (intptr_t)vk-&gt;get_ValueKlass());</span>
5227       jint lh = vk-&gt;layout_helper();
5228       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);
5229       movl(r14, lh);
5230     } else {
5231       // Call from interpreter. RAX contains ((the InlineKlass* of the return type) | 0x01)
5232       mov(rbx, rax);
5233       andptr(rbx, -2);
5234       movl(r14, Address(rbx, Klass::layout_helper_offset()));
5235     }
5236 
5237     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));
5238     lea(r14, Address(r13, r14, Address::times_1));
5239     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));
5240     jcc(Assembler::above, slow_case);
5241     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);
5242     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());
5243 
5244     xorl(rax, rax); // use zero reg to clear memory (shorter code)
5245     store_klass_gap(r13, rax);  // zero klass gap for compressed oops
5246 
5247     if (vk == NULL) {
5248       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
5249       mov(rax, rbx);
5250     }
5251     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
5252     store_klass(r13, rbx, tmp_store_klass);  // klass
5253 
<span class="line-modified">5254     // We have our new buffered value, initialize its fields with a</span>
<span class="line-removed">5255     // value class specific handler</span>
5256     if (vk != NULL) {
5257       // FIXME -- do the packing in-line to avoid the runtime call
5258       mov(rax, r13);
5259       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.
5260     } else {
5261       movptr(rbx, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));
5262       movptr(rbx, Address(rbx, InlineKlass::pack_handler_offset()));
5263       mov(rax, r13);
5264       call(rbx);
5265     }
5266     jmp(skip);
5267   }
5268 
5269   bind(slow_case);
<span class="line-modified">5270   // We failed to allocate a new value, fall back to a runtime</span>
5271   // call. Some oop field may be live in some registers but we can&#39;t
5272   // tell. That runtime call will take care of preserving them
5273   // across a GC if there&#39;s one.
5274 #endif
5275 
5276   if (from_interpreter) {
5277     super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
5278   } else {
5279     call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
5280     call_offset = offset();
5281   }
5282 
5283   bind(skip);
5284   return call_offset;
5285 }
5286 
5287 
5288 // Move a value between registers/stack slots and update the reg_state
5289 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {
5290   if (reg_state[to-&gt;value()] == reg_written) {
</pre>
<hr />
<pre>
5331             assert(bt == T_FLOAT, &quot;must be float&quot;);
5332             movflt(to-&gt;as_XMMRegister(), from_addr);
5333           }
5334         } else {
5335           movq(to-&gt;as_Register(), from_addr);
5336         }
5337       } else {
5338         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5339         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);
5340         movq(r13, from_addr);
5341         movq(Address(rsp, st_off), r13);
5342       }
5343     }
5344   }
5345   // Update register states
5346   reg_state[from-&gt;value()] = reg_writable;
5347   reg_state[to-&gt;value()] = reg_written;
5348   return true;
5349 }
5350 
<span class="line-modified">5351 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-modified">5352 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
5353                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {
5354   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5355   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5356 
5357   int vt = 1;
5358   bool done = true;
5359   bool mark_done = true;
5360   do {
5361     sig_index--;
5362     BasicType bt = sig-&gt;at(sig_index)._bt;
5363     if (bt == T_INLINE_TYPE) {
5364       vt--;
5365     } else if (bt == T_VOID &amp;&amp;
5366                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5367                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5368       vt++;
5369     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5370       to_index--; // Ignore this
5371     } else {
5372       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5413           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);
5414           movq(Address(rsp, st_off), dst);
5415         }
5416       } else {
5417         if (bt == T_DOUBLE) {
5418           movdbl(to-&gt;as_XMMRegister(), fromAddr);
5419         } else {
5420           assert(bt == T_FLOAT, &quot;must be float&quot;);
5421           movflt(to-&gt;as_XMMRegister(), fromAddr);
5422         }
5423       }
5424     }
5425   } while (vt != 0);
5426   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5427     // This is okay because no one else will write to that slot
5428     reg_state[from-&gt;value()] = reg_writable;
5429   }
5430   return done;
5431 }
5432 
<span class="line-modified">5433 // Pack fields back into a value type oop</span>
<span class="line-modified">5434 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
5435                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],
5436                                        int ret_off, int extra_stack_offset) {
5437   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5438   assert(to-&gt;is_valid(), &quot;must be&quot;);
5439 
5440   if (reg_state[to-&gt;value()] == reg_written) {
5441     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5442     return true; // Already written
5443   }
5444 
5445   Register val_array = rax;
5446   Register val_obj_tmp = r11;
5447   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling
5448   Register tmp1 = r10;
5449   Register tmp2 = r13;
5450   Register tmp3 = rbx;
5451   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5452 
5453   if (reg_state[to-&gt;value()] == reg_readonly) {
5454     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
</pre>
<hr />
<pre>
5492       }
5493     } else {
5494       if (from_r2-&gt;is_valid()) {
5495         movdbl(dst, from_r1-&gt;as_XMMRegister());
5496       } else {
5497         movflt(dst, from_r1-&gt;as_XMMRegister());
5498       }
5499     }
5500     reg_state[from_r1-&gt;value()] = reg_writable;
5501   }
5502   sig_index = stream.sig_cc_index();
5503   from_index = stream.regs_cc_index();
5504 
5505   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5506   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5507   assert(success, &quot;to register must be writeable&quot;);
5508 
5509   return true;
5510 }
5511 
<span class="line-modified">5512 // Unpack all value type arguments passed as oops</span>
<span class="line-modified">5513 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-modified">5514   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
5515   // Emit code for verified entry and save increment for stack repair on return
5516   verified_entry(C, sp_inc);
5517 }
5518 
<span class="line-modified">5519 void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
5520                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,
5521                                         int args_passed, int args_on_stack, VMRegPair* regs,
5522                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {
5523   // Check if we need to extend the stack for packing/unpacking
5524   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {
5525     // Save the return address, adjust the stack (make sure it is properly
5526     // 16-byte aligned) and copy the return address to the new top of the stack.
5527     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5528     pop(r13);
5529     subptr(rsp, sp_inc);
5530     push(r13);
5531   }
5532 
5533   int ret_off; // make sure we don&#39;t overwrite the return address
5534   if (is_packing) {
<span class="line-modified">5535     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
5536     // rsp[0] during shuffling.
5537     ret_off = 0;
5538   } else {
5539     // C2 code ensures that sp_inc is a reserved slot.
5540     ret_off = sp_inc;
5541   }
5542 
<span class="line-modified">5543   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
5544                             sig_bt, sig_cc,
5545                             args_passed, args_on_stack, regs,
5546                             args_passed_to, args_on_stack_to, regs_to,
5547                             sp_inc, ret_off);
5548 }
5549 
5550 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5551   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();
5552 }
5553 
5554 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {
5555   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
5556   if (needs_stack_repair) {
5557     movq(rbp, Address(rsp, initial_framesize));
5558     addq(rsp, Address(rsp, sp_inc_offset));
5559   } else {
5560     if (initial_framesize &gt; 0) {
5561       addq(rsp, initial_framesize);
5562     }
5563     pop(rbp);
</pre>
</td>
<td>
<hr />
<pre>
3612     jcc(Assembler::notZero, loop);
3613   }
3614 
3615   bind(done);
3616 }
3617 
3618 void MacroAssembler::get_inline_type_field_klass(Register klass, Register index, Register inline_klass) {
3619   movptr(inline_klass, Address(klass, InstanceKlass::inline_type_field_klasses_offset()));
3620 #ifdef ASSERT
3621   {
3622     Label done;
3623     cmpptr(inline_klass, 0);
3624     jcc(Assembler::notEqual, done);
3625     stop(&quot;get_inline_type_field_klass contains no inline klass&quot;);
3626     bind(done);
3627   }
3628 #endif
3629   movptr(inline_klass, Address(inline_klass, index, Address::times_ptr));
3630 }
3631 
<span class="line-modified">3632 void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {</span>
3633 #ifdef ASSERT
3634   {
3635     Label done_check;
<span class="line-modified">3636     test_klass_is_inline_type(inline_klass, temp_reg, done_check);</span>
3637     stop(&quot;get_default_value_oop from non inline type klass&quot;);
3638     bind(done_check);
3639   }
3640 #endif
3641   Register offset = temp_reg;
3642   // Getting the offset of the pre-allocated default value
<span class="line-modified">3643   movptr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));</span>
3644   movl(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));
3645 
3646   // Getting the mirror
<span class="line-modified">3647   movptr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="line-modified">3648   resolve_oop_handle(obj, inline_klass);</span>
3649 
3650   // Getting the pre-allocated default value from the mirror
3651   Address field(obj, offset, Address::times_1);
3652   load_heap_oop(obj, field);
3653 }
3654 
3655 void MacroAssembler::get_empty_inline_type_oop(Register inline_klass, Register temp_reg, Register obj) {
3656 #ifdef ASSERT
3657   {
3658     Label done_check;
3659     test_klass_is_empty_inline_type(inline_klass, temp_reg, done_check);
3660     stop(&quot;get_empty_value from non-empty inline klass&quot;);
3661     bind(done_check);
3662   }
3663 #endif
3664   get_default_value_oop(inline_klass, temp_reg, obj);
3665 }
3666 
3667 
3668 // Look up the method for a megamorphic invokeinterface call.
</pre>
<hr />
<pre>
4660   if (as_raw) {
4661     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4662   } else {
4663     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4664   }
4665 }
4666 
4667 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
4668                                      Register tmp1, Register tmp2, Register tmp3) {
4669   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4670   decorators = AccessInternal::decorator_fixup(decorators);
4671   bool as_raw = (decorators &amp; AS_RAW) != 0;
4672   if (as_raw) {
4673     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);
4674   } else {
4675     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);
4676   }
4677 }
4678 
4679 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,
<span class="line-modified">4680                                        Register inline_klass) {</span>
4681   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
<span class="line-modified">4682   bs-&gt;value_copy(this, decorators, src, dst, inline_klass);</span>
4683 }
4684 
<span class="line-modified">4685 void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {</span>
<span class="line-modified">4686   movptr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));</span>
4687   movl(offset, Address(offset, InlineKlass::first_field_offset_offset()));
4688 }
4689 
<span class="line-modified">4690 void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {</span>
4691   // ((address) (void*) o) + vk-&gt;first_field_offset();
4692   Register offset = (data == oop) ? rscratch1 : data;
<span class="line-modified">4693   first_field_offset(inline_klass, offset);</span>
4694   if (data == oop) {
4695     addptr(data, offset);
4696   } else {
4697     lea(data, Address(oop, offset));
4698   }
4699 }
4700 
4701 void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,
4702                                                 Register index, Register data) {
4703   assert(index != rcx, &quot;index needs to shift by rcx&quot;);
4704   assert_different_registers(array, array_klass, index);
4705   assert_different_registers(rcx, array, index);
4706 
4707   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));
4708   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));
4709 
4710   // Klass::layout_helper_log2_element_size(lh)
4711   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;
4712   shrl(rcx, Klass::_lh_log2_element_size_shift);
4713   andl(rcx, Klass::_lh_log2_element_size_mask);
</pre>
<hr />
<pre>
5188   } else {
5189     movdqu(Address(base,  0), xtmp);
5190     movdqu(Address(base, 16), xtmp);
5191   }
5192   addptr(base, 32);
5193   subptr(cnt, 4);
5194 
5195   BIND(L_tail);
5196   addptr(cnt, 4);
5197   jccb(Assembler::lessEqual, L_end);
5198   decrement(cnt);
5199 
5200   BIND(L_sloop);
5201   movq(Address(base, 0), xtmp);
5202   addptr(base, 8);
5203   decrement(cnt);
5204   jccb(Assembler::greaterEqual, L_sloop);
5205   BIND(L_end);
5206 }
5207 
<span class="line-modified">5208 int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {</span>
5209   // An inline type might be returned. If fields are in registers we
5210   // need to allocate an inline type instance and initialize it with
5211   // the value of the fields.
5212   Label skip;
<span class="line-modified">5213   // We only need a new buffered inline type if a new one is not returned</span>
5214   testptr(rax, 1);
5215   jcc(Assembler::zero, skip);
5216   int call_offset = -1;
5217 
5218 #ifdef _LP64
5219   Label slow_case;
5220 
<span class="line-modified">5221   // Try to allocate a new buffered inline type (from the heap)</span>
5222   if (UseTLAB) {
5223     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.
5224     if (vk != NULL) {
5225       // Called from C1, where the return type is statically known.
<span class="line-modified">5226       movptr(rbx, (intptr_t)vk-&gt;get_InlineKlass());</span>
5227       jint lh = vk-&gt;layout_helper();
5228       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);
5229       movl(r14, lh);
5230     } else {
5231       // Call from interpreter. RAX contains ((the InlineKlass* of the return type) | 0x01)
5232       mov(rbx, rax);
5233       andptr(rbx, -2);
5234       movl(r14, Address(rbx, Klass::layout_helper_offset()));
5235     }
5236 
5237     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));
5238     lea(r14, Address(r13, r14, Address::times_1));
5239     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));
5240     jcc(Assembler::above, slow_case);
5241     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);
5242     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());
5243 
5244     xorl(rax, rax); // use zero reg to clear memory (shorter code)
5245     store_klass_gap(r13, rax);  // zero klass gap for compressed oops
5246 
5247     if (vk == NULL) {
5248       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
5249       mov(rax, rbx);
5250     }
5251     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
5252     store_klass(r13, rbx, tmp_store_klass);  // klass
5253 
<span class="line-modified">5254     // We have our new buffered inline type, initialize its fields with an inline class specific handler</span>

5255     if (vk != NULL) {
5256       // FIXME -- do the packing in-line to avoid the runtime call
5257       mov(rax, r13);
5258       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.
5259     } else {
5260       movptr(rbx, Address(rax, InstanceKlass::adr_inlineklass_fixed_block_offset()));
5261       movptr(rbx, Address(rbx, InlineKlass::pack_handler_offset()));
5262       mov(rax, r13);
5263       call(rbx);
5264     }
5265     jmp(skip);
5266   }
5267 
5268   bind(slow_case);
<span class="line-modified">5269   // We failed to allocate a new inline type, fall back to a runtime</span>
5270   // call. Some oop field may be live in some registers but we can&#39;t
5271   // tell. That runtime call will take care of preserving them
5272   // across a GC if there&#39;s one.
5273 #endif
5274 
5275   if (from_interpreter) {
5276     super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
5277   } else {
5278     call(RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
5279     call_offset = offset();
5280   }
5281 
5282   bind(skip);
5283   return call_offset;
5284 }
5285 
5286 
5287 // Move a value between registers/stack slots and update the reg_state
5288 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {
5289   if (reg_state[to-&gt;value()] == reg_written) {
</pre>
<hr />
<pre>
5330             assert(bt == T_FLOAT, &quot;must be float&quot;);
5331             movflt(to-&gt;as_XMMRegister(), from_addr);
5332           }
5333         } else {
5334           movq(to-&gt;as_Register(), from_addr);
5335         }
5336       } else {
5337         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5338         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);
5339         movq(r13, from_addr);
5340         movq(Address(rsp, st_off), r13);
5341       }
5342     }
5343   }
5344   // Update register states
5345   reg_state[from-&gt;value()] = reg_writable;
5346   reg_state[to-&gt;value()] = reg_written;
5347   return true;
5348 }
5349 
<span class="line-modified">5350 // Read all fields from an inline type oop and store the values in registers/stack slots</span>
<span class="line-modified">5351 bool MacroAssembler::unpack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
5352                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {
5353   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5354   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5355 
5356   int vt = 1;
5357   bool done = true;
5358   bool mark_done = true;
5359   do {
5360     sig_index--;
5361     BasicType bt = sig-&gt;at(sig_index)._bt;
5362     if (bt == T_INLINE_TYPE) {
5363       vt--;
5364     } else if (bt == T_VOID &amp;&amp;
5365                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5366                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5367       vt++;
5368     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5369       to_index--; // Ignore this
5370     } else {
5371       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5412           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);
5413           movq(Address(rsp, st_off), dst);
5414         }
5415       } else {
5416         if (bt == T_DOUBLE) {
5417           movdbl(to-&gt;as_XMMRegister(), fromAddr);
5418         } else {
5419           assert(bt == T_FLOAT, &quot;must be float&quot;);
5420           movflt(to-&gt;as_XMMRegister(), fromAddr);
5421         }
5422       }
5423     }
5424   } while (vt != 0);
5425   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5426     // This is okay because no one else will write to that slot
5427     reg_state[from-&gt;value()] = reg_writable;
5428   }
5429   return done;
5430 }
5431 
<span class="line-modified">5432 // Pack fields back into an inline type oop</span>
<span class="line-modified">5433 bool MacroAssembler::pack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
5434                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],
5435                                        int ret_off, int extra_stack_offset) {
5436   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5437   assert(to-&gt;is_valid(), &quot;must be&quot;);
5438 
5439   if (reg_state[to-&gt;value()] == reg_written) {
5440     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5441     return true; // Already written
5442   }
5443 
5444   Register val_array = rax;
5445   Register val_obj_tmp = r11;
5446   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling
5447   Register tmp1 = r10;
5448   Register tmp2 = r13;
5449   Register tmp3 = rbx;
5450   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5451 
5452   if (reg_state[to-&gt;value()] == reg_readonly) {
5453     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
</pre>
<hr />
<pre>
5491       }
5492     } else {
5493       if (from_r2-&gt;is_valid()) {
5494         movdbl(dst, from_r1-&gt;as_XMMRegister());
5495       } else {
5496         movflt(dst, from_r1-&gt;as_XMMRegister());
5497       }
5498     }
5499     reg_state[from_r1-&gt;value()] = reg_writable;
5500   }
5501   sig_index = stream.sig_cc_index();
5502   from_index = stream.regs_cc_index();
5503 
5504   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5505   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5506   assert(success, &quot;to register must be writeable&quot;);
5507 
5508   return true;
5509 }
5510 
<span class="line-modified">5511 // Unpack all inline type arguments passed as oops</span>
<span class="line-modified">5512 void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {</span>
<span class="line-modified">5513   int sp_inc = unpack_inline_args_common(C, receiver_only);</span>
5514   // Emit code for verified entry and save increment for stack repair on return
5515   verified_entry(C, sp_inc);
5516 }
5517 
<span class="line-modified">5518 void MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
5519                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,
5520                                         int args_passed, int args_on_stack, VMRegPair* regs,
5521                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {
5522   // Check if we need to extend the stack for packing/unpacking
5523   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {
5524     // Save the return address, adjust the stack (make sure it is properly
5525     // 16-byte aligned) and copy the return address to the new top of the stack.
5526     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5527     pop(r13);
5528     subptr(rsp, sp_inc);
5529     push(r13);
5530   }
5531 
5532   int ret_off; // make sure we don&#39;t overwrite the return address
5533   if (is_packing) {
<span class="line-modified">5534     // For C1 code, the VIEP doesn&#39;t have reserved slots, so we store the returned address at</span>
5535     // rsp[0] during shuffling.
5536     ret_off = 0;
5537   } else {
5538     // C2 code ensures that sp_inc is a reserved slot.
5539     ret_off = sp_inc;
5540   }
5541 
<span class="line-modified">5542   shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,</span>
5543                             sig_bt, sig_cc,
5544                             args_passed, args_on_stack, regs,
5545                             args_passed_to, args_on_stack_to, regs_to,
5546                             sp_inc, ret_off);
5547 }
5548 
5549 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5550   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();
5551 }
5552 
5553 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {
5554   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
5555   if (needs_stack_repair) {
5556     movq(rbp, Address(rsp, initial_framesize));
5557     addq(rsp, Address(rsp, sp_inc_offset));
5558   } else {
5559     if (initial_framesize &gt; 0) {
5560       addq(rsp, initial_framesize);
5561     }
5562     pop(rbp);
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>