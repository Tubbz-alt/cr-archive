diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -29,12 +29,12 @@
 #include "c1/c1_LIRAssembler.hpp"
 #include "c1/c1_MacroAssembler.hpp"
 #include "c1/c1_Runtime1.hpp"
 #include "c1/c1_ValueStack.hpp"
 #include "ci/ciArrayKlass.hpp"
+#include "ci/ciInlineKlass.hpp"
 #include "ci/ciInstance.hpp"
-#include "ci/ciValueKlass.hpp"
 #include "gc/shared/collectedHeap.hpp"
 #include "nativeInst_x86.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "runtime/frame.inline.hpp"
@@ -527,12 +527,12 @@
     assert(result->fpu() == 0, "result must already be on TOS");
   }
 
   ciMethod* method = compilation()->method();
   ciType* return_type = method->return_type();
-  if (InlineTypeReturnedAsFields && return_type->is_valuetype()) {
-    ciValueKlass* vk = return_type->as_value_klass();
+  if (InlineTypeReturnedAsFields && return_type->is_inlinetype()) {
+    ciInlineKlass* vk = return_type->as_inline_klass();
     if (vk->can_be_returned_as_fields()) {
 #ifndef _LP64
       Unimplemented();
 #else
       address unpack_handler = vk->unpack_handler();
@@ -570,11 +570,11 @@
   __ testl(rax, Address(poll_addr, 0));
   __ ret(0);
 }
 
 
-int LIR_Assembler::store_inline_type_fields_to_buf(ciValueKlass* vk) {
+int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {
   return (__ store_inline_type_fields_to_buf(vk, false));
 }
 
 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
   guarantee(info != NULL, "Shouldn't be NULL");
@@ -2049,22 +2049,22 @@
 
   // (2) Value object check -- if either of the operands is not a value object,
   //     they are not substitutable. We do this only if we are not sure that the
   //     operands are value objects
   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
-      !left_klass->is_valuetype() || !right_klass->is_valuetype()) {
+      !left_klass->is_inlinetype() || !right_klass->is_inlinetype()) {
     Register tmp1  = op->tmp1()->as_register();
     __ movptr(tmp1, (intptr_t)markWord::always_locked_pattern);
     __ andl(tmp1, Address(left, oopDesc::mark_offset_in_bytes()));
     __ andl(tmp1, Address(right, oopDesc::mark_offset_in_bytes()));
     __ cmpptr(tmp1, (intptr_t)markWord::always_locked_pattern);
     __ jcc(Assembler::notEqual, L_oops_not_equal);
   }
 
   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.
-  if (left_klass != NULL && left_klass->is_valuetype() && left_klass == right_klass) {
-    // No need to load klass -- the operands are statically known to be the same value klass.
+  if (left_klass != NULL && left_klass->is_inlinetype() && left_klass == right_klass) {
+    // No need to load klass -- the operands are statically known to be the same inline klass.
     __ jmp(*op->stub()->entry());
   } else {
     Register left_klass_op = op->left_klass_op()->as_register();
     Register right_klass_op = op->right_klass_op()->as_register();
 
@@ -3254,11 +3254,11 @@
   assert(offset_from_rsp_in_bytes < frame_map()->reserved_argument_area_size(), "invalid offset");
   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
 }
 
 
-void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {
+void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {
   if (null_check) {
     __ testptr(obj, obj);
     __ jcc(Assembler::zero, *slow_path->entry());
   }
   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
@@ -3300,16 +3300,16 @@
     __ jmp(*stub->entry());
     __ bind(*stub->continuation());
     return;
   }
 
-  if (flags & LIR_OpArrayCopy::src_valuetype_check) {
-    arraycopy_valuetype_check(src, tmp, stub, false, (flags & LIR_OpArrayCopy::src_null_check));
+  if (flags & LIR_OpArrayCopy::src_inlinetype_check) {
+    arraycopy_inlinetype_check(src, tmp, stub, false, (flags & LIR_OpArrayCopy::src_null_check));
   }
 
-  if (flags & LIR_OpArrayCopy::dst_valuetype_check) {
-    arraycopy_valuetype_check(dst, tmp, stub, true, (flags & LIR_OpArrayCopy::dst_null_check));
+  if (flags & LIR_OpArrayCopy::dst_inlinetype_check) {
+    arraycopy_inlinetype_check(dst, tmp, stub, true, (flags & LIR_OpArrayCopy::dst_null_check));
   }
 
   // if we don't know anything, just go through the generic arraycopy
   if (default_type == NULL) {
     // save outgoing arguments on stack in case call to System.arraycopy is needed
