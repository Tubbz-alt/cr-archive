diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -3627,27 +3627,27 @@
   }
 #endif
   movptr(inline_klass, Address(inline_klass, index, Address::times_ptr));
 }
 
-void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {
+void MacroAssembler::get_default_value_oop(Register inline_klass, Register temp_reg, Register obj) {
 #ifdef ASSERT
   {
     Label done_check;
-    test_klass_is_inline_type(value_klass, temp_reg, done_check);
+    test_klass_is_inline_type(inline_klass, temp_reg, done_check);
     stop("get_default_value_oop from non inline type klass");
     bind(done_check);
   }
 #endif
   Register offset = temp_reg;
   // Getting the offset of the pre-allocated default value
-  movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));
+  movptr(offset, Address(inline_klass, in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())));
   movl(offset, Address(offset, in_bytes(InlineKlass::default_value_offset_offset())));
 
   // Getting the mirror
-  movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));
-  resolve_oop_handle(obj, value_klass);
+  movptr(obj, Address(inline_klass, in_bytes(Klass::java_mirror_offset())));
+  resolve_oop_handle(obj, inline_klass);
 
   // Getting the pre-allocated default value from the mirror
   Address field(obj, offset, Address::times_1);
   load_heap_oop(obj, field);
 }
@@ -4675,24 +4675,24 @@
     bs->store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);
   }
 }
 
 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,
-                                       Register value_klass) {
+                                       Register inline_klass) {
   BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();
-  bs->value_copy(this, decorators, src, dst, value_klass);
+  bs->value_copy(this, decorators, src, dst, inline_klass);
 }
 
-void MacroAssembler::first_field_offset(Register value_klass, Register offset) {
-  movptr(offset, Address(value_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));
+void MacroAssembler::first_field_offset(Register inline_klass, Register offset) {
+  movptr(offset, Address(inline_klass, InstanceKlass::adr_inlineklass_fixed_block_offset()));
   movl(offset, Address(offset, InlineKlass::first_field_offset_offset()));
 }
 
-void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {
+void MacroAssembler::data_for_oop(Register oop, Register data, Register inline_klass) {
   // ((address) (void*) o) + vk->first_field_offset();
   Register offset = (data == oop) ? rscratch1 : data;
-  first_field_offset(value_klass, offset);
+  first_field_offset(inline_klass, offset);
   if (data == oop) {
     addptr(data, offset);
   } else {
     lea(data, Address(oop, offset));
   }
@@ -5203,29 +5203,29 @@
   decrement(cnt);
   jccb(Assembler::greaterEqual, L_sloop);
   BIND(L_end);
 }
 
-int MacroAssembler::store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {
+int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {
   // An inline type might be returned. If fields are in registers we
   // need to allocate an inline type instance and initialize it with
   // the value of the fields.
   Label skip;
-  // We only need a new buffered value if a new one is not returned
+  // We only need a new buffered inline type if a new one is not returned
   testptr(rax, 1);
   jcc(Assembler::zero, skip);
   int call_offset = -1;
 
 #ifdef _LP64
   Label slow_case;
 
-  // Try to allocate a new buffered value (from the heap)
+  // Try to allocate a new buffered inline type (from the heap)
   if (UseTLAB) {
     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.
     if (vk != NULL) {
       // Called from C1, where the return type is statically known.
-      movptr(rbx, (intptr_t)vk->get_ValueKlass());
+      movptr(rbx, (intptr_t)vk->get_InlineKlass());
       jint lh = vk->layout_helper();
       assert(lh != Klass::_lh_neutral_value, "inline class in return type must have been resolved");
       movl(r14, lh);
     } else {
       // Call from interpreter. RAX contains ((the InlineKlass* of the return type) | 0x01)
@@ -5249,12 +5249,11 @@
       mov(rax, rbx);
     }
     Register tmp_store_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
     store_klass(r13, rbx, tmp_store_klass);  // klass
 
-    // We have our new buffered value, initialize its fields with a
-    // value class specific handler
+    // We have our new buffered inline type, initialize its fields with an inline class specific handler
     if (vk != NULL) {
       // FIXME -- do the packing in-line to avoid the runtime call
       mov(rax, r13);
       call(RuntimeAddress(vk->pack_handler())); // no need for call info as this will not safepoint.
     } else {
@@ -5265,11 +5264,11 @@
     }
     jmp(skip);
   }
 
   bind(slow_case);
-  // We failed to allocate a new value, fall back to a runtime
+  // We failed to allocate a new inline type, fall back to a runtime
   // call. Some oop field may be live in some registers but we can't
   // tell. That runtime call will take care of preserving them
   // across a GC if there's one.
 #endif
 
@@ -5346,12 +5345,12 @@
   reg_state[from->value()] = reg_writable;
   reg_state[to->value()] = reg_written;
   return true;
 }
 
-// Read all fields from a value type oop and store the values in registers/stack slots
-bool MacroAssembler::unpack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to,
+// Read all fields from an inline type oop and store the values in registers/stack slots
+bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to,
                                          int& to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {
   Register fromReg = from->is_reg() ? from->as_Register() : noreg;
   assert(sig->at(sig_index)._bt == T_VOID, "should be at end delimiter");
 
   int vt = 1;
@@ -5428,12 +5427,12 @@
     reg_state[from->value()] = reg_writable;
   }
   return done;
 }
 
-// Pack fields back into a value type oop
-bool MacroAssembler::pack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,
+// Pack fields back into an inline type oop
+bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,
                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],
                                        int ret_off, int extra_stack_offset) {
   assert(sig->at(sig_index)._bt == T_INLINE_TYPE, "should be at end delimiter");
   assert(to->is_valid(), "must be");
 
@@ -5507,18 +5506,18 @@
   assert(success, "to register must be writeable");
 
   return true;
 }
 
-// Unpack all value type arguments passed as oops
-void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {
-  int sp_inc = unpack_value_args_common(C, receiver_only);
+// Unpack all inline type arguments passed as oops
+void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {
+  int sp_inc = unpack_inline_args_common(C, receiver_only);
   // Emit code for verified entry and save increment for stack repair on return
   verified_entry(C, sp_inc);
 }
 
-void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,
+void MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,
                                         BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,
                                         int args_passed, int args_on_stack, VMRegPair* regs,
                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {
   // Check if we need to extend the stack for packing/unpacking
   if (sp_inc > 0 && !is_packing) {
@@ -5530,19 +5529,19 @@
     push(r13);
   }
 
   int ret_off; // make sure we don't overwrite the return address
   if (is_packing) {
-    // For C1 code, the VVEP doesn't have reserved slots, so we store the returned address at
+    // For C1 code, the VIEP doesn't have reserved slots, so we store the returned address at
     // rsp[0] during shuffling.
     ret_off = 0;
   } else {
     // C2 code ensures that sp_inc is a reserved slot.
     ret_off = sp_inc;
   }
 
-  shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,
+  shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,
                             sig_bt, sig_cc,
                             args_passed, args_on_stack, regs,
                             args_passed_to, args_on_stack_to, regs_to,
                             sp_inc, ret_off);
 }
