<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_CodeStubs_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;c1/c1_Compilation.hpp&quot;
  29 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  30 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  31 #include &quot;c1/c1_Runtime1.hpp&quot;
  32 #include &quot;c1/c1_ValueStack.hpp&quot;
  33 #include &quot;ci/ciArrayKlass.hpp&quot;

  34 #include &quot;ci/ciInstance.hpp&quot;
<span class="line-removed">  35 #include &quot;ci/ciValueKlass.hpp&quot;</span>
  36 #include &quot;gc/shared/collectedHeap.hpp&quot;
  37 #include &quot;nativeInst_x86.hpp&quot;
  38 #include &quot;oops/oop.inline.hpp&quot;
  39 #include &quot;oops/objArrayKlass.hpp&quot;
  40 #include &quot;runtime/frame.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 #include &quot;vmreg_x86.inline.hpp&quot;
  45 
  46 
  47 // These masks are used to provide 128-bit aligned bitmasks to the XMM
  48 // instructions, to allow sign-masking or sign-bit flipping.  They allow
  49 // fast versions of NegF/NegD and AbsF/AbsD.
  50 
  51 // Note: &#39;double&#39; and &#39;long long&#39; have 32-bits alignment on x86.
  52 static jlong* double_quadword(jlong *adr, jlong lo, jlong hi) {
  53   // Use the expression (adr)&amp;(~0xF) to provide 128-bits aligned address
  54   // of 128-bits operands for SSE instructions.
  55   jlong *operand = (jlong*)(((intptr_t)adr) &amp; ((intptr_t)(~0xF)));
</pre>
<hr />
<pre>
 512   int offset = code_offset();
 513   InternalAddress here(__ pc());
 514 
 515   __ pushptr(here.addr());
 516   __ jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 517   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 518   __ end_a_stub();
 519 
 520   return offset;
 521 }
 522 
 523 
 524 void LIR_Assembler::return_op(LIR_Opr result) {
 525   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == rax, &quot;word returns are in rax,&quot;);
 526   if (!result-&gt;is_illegal() &amp;&amp; result-&gt;is_float_kind() &amp;&amp; !result-&gt;is_xmm_register()) {
 527     assert(result-&gt;fpu() == 0, &quot;result must already be on TOS&quot;);
 528   }
 529 
 530   ciMethod* method = compilation()-&gt;method();
 531   ciType* return_type = method-&gt;return_type();
<span class="line-modified"> 532   if (InlineTypeReturnedAsFields &amp;&amp; return_type-&gt;is_valuetype()) {</span>
<span class="line-modified"> 533     ciValueKlass* vk = return_type-&gt;as_value_klass();</span>
 534     if (vk-&gt;can_be_returned_as_fields()) {
 535 #ifndef _LP64
 536       Unimplemented();
 537 #else
 538       address unpack_handler = vk-&gt;unpack_handler();
 539       assert(unpack_handler != NULL, &quot;must be&quot;);
 540       __ call(RuntimeAddress(unpack_handler));
 541       // At this point, rax points to the value object (for interpreter or C1 caller).
 542       // The fields of the object are copied into registers (for C2 caller).
 543 #endif
 544     }
 545   }
 546 
 547   // Pop the stack before the safepoint code
 548   int initial_framesize = initial_frame_size_in_bytes();
 549   __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);
 550 
 551   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 552     __ reserved_stack_check();
 553   }
</pre>
<hr />
<pre>
 555   bool result_is_oop = result-&gt;is_valid() ? result-&gt;is_oop() : false;
 556 
 557   // Note: we do not need to round double result; float result has the right precision
 558   // the poll sets the condition code, but no data registers
 559 
 560 #ifdef _LP64
 561   const Register poll_addr = rscratch1;
 562   __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 563 #else
 564   const Register poll_addr = rbx;
 565   assert(FrameMap::is_caller_save_register(poll_addr), &quot;will overwrite&quot;);
 566   __ get_thread(poll_addr);
 567   __ movptr(poll_addr, Address(poll_addr, Thread::polling_page_offset()));
 568 #endif
 569   __ relocate(relocInfo::poll_return_type);
 570   __ testl(rax, Address(poll_addr, 0));
 571   __ ret(0);
 572 }
 573 
 574 
<span class="line-modified"> 575 int LIR_Assembler::store_inline_type_fields_to_buf(ciValueKlass* vk) {</span>
 576   return (__ store_inline_type_fields_to_buf(vk, false));
 577 }
 578 
 579 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 580   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 581   int offset = __ offset();
 582 #ifdef _LP64
 583   const Register poll_addr = rscratch1;
 584   __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 585 #else
 586   assert(tmp-&gt;is_cpu_register(), &quot;needed&quot;);
 587   const Register poll_addr = tmp-&gt;as_register();
 588   __ get_thread(poll_addr);
 589   __ movptr(poll_addr, Address(poll_addr, in_bytes(Thread::polling_page_offset())));
 590 #endif
 591   add_debug_info_for_branch(info);
 592   __ relocate(relocInfo::poll_type);
 593   address pre_pc = __ pc();
 594   __ testl(rax, Address(poll_addr, 0));
 595   address post_pc = __ pc();
</pre>
<hr />
<pre>
2034   __ jcc(Assembler::equal, L_oops_equal);
2035 
2036   // (1) Null check -- if one of the operands is null, the other must not be null (because
2037   //     the two references are not equal), so they are not substitutable,
2038   //     FIXME: do null check only if the operand is nullable
2039   {
2040     __ cmpptr(left, (int32_t)NULL_WORD);
2041     __ jcc(Assembler::equal, L_oops_not_equal);
2042 
2043     __ cmpptr(right, (int32_t)NULL_WORD);
2044     __ jcc(Assembler::equal, L_oops_not_equal);
2045   }
2046 
2047   ciKlass* left_klass = op-&gt;left_klass();
2048   ciKlass* right_klass = op-&gt;right_klass();
2049 
2050   // (2) Value object check -- if either of the operands is not a value object,
2051   //     they are not substitutable. We do this only if we are not sure that the
2052   //     operands are value objects
2053   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
<span class="line-modified">2054       !left_klass-&gt;is_valuetype() || !right_klass-&gt;is_valuetype()) {</span>
2055     Register tmp1  = op-&gt;tmp1()-&gt;as_register();
2056     __ movptr(tmp1, (intptr_t)markWord::always_locked_pattern);
2057     __ andl(tmp1, Address(left, oopDesc::mark_offset_in_bytes()));
2058     __ andl(tmp1, Address(right, oopDesc::mark_offset_in_bytes()));
2059     __ cmpptr(tmp1, (intptr_t)markWord::always_locked_pattern);
2060     __ jcc(Assembler::notEqual, L_oops_not_equal);
2061   }
2062 
2063   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.
<span class="line-modified">2064   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_valuetype() &amp;&amp; left_klass == right_klass) {</span>
<span class="line-modified">2065     // No need to load klass -- the operands are statically known to be the same value klass.</span>
2066     __ jmp(*op-&gt;stub()-&gt;entry());
2067   } else {
2068     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();
2069     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();
2070 
2071     if (UseCompressedOops) {
2072       __ movl(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
2073       __ movl(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
2074       __ cmpl(left_klass_op, right_klass_op);
2075     } else {
2076       __ movptr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
2077       __ movptr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
2078       __ cmpptr(left_klass_op, right_klass_op);
2079     }
2080 
2081     __ jcc(Assembler::equal, *op-&gt;stub()-&gt;entry()); // same klass -&gt; do slow check
2082     // fall through to L_oops_not_equal
2083   }
2084 
2085   __ bind(L_oops_not_equal);
</pre>
<hr />
<pre>
3239   __ movptr (Address(rsp, offset_from_rsp_in_bytes), c);
3240 }
3241 
3242 
3243 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
3244   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3245   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3246   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3247   __ movoop (Address(rsp, offset_from_rsp_in_bytes), o);
3248 }
3249 
3250 
3251 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3252   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3253   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3254   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3255   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3256 }
3257 
3258 
<span class="line-modified">3259 void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {</span>
3260   if (null_check) {
3261     __ testptr(obj, obj);
3262     __ jcc(Assembler::zero, *slow_path-&gt;entry());
3263   }
3264   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
3265   __ load_klass(tmp, obj, tmp_load_klass);
3266   __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));
3267   if (is_dest) {
3268     // We also take slow path if it&#39;s a null_free destination array, just in case the source array
3269     // contains NULLs.
3270     __ testl(tmp, Klass::_lh_null_free_bit_inplace);
3271   } else {
3272     __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);
3273   }
3274   __ jcc(Assembler::notZero, *slow_path-&gt;entry());
3275 }
3276 
3277 
3278 // This code replaces a call to arraycopy; no exception may
3279 // be thrown in this code, they must be thrown in the System.arraycopy
</pre>
<hr />
<pre>
3285   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3286   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3287   Register length  = op-&gt;length()-&gt;as_register();
3288   Register tmp = op-&gt;tmp()-&gt;as_register();
3289   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
3290 
3291   __ resolve(ACCESS_READ, src);
3292   __ resolve(ACCESS_WRITE, dst);
3293 
3294   CodeStub* stub = op-&gt;stub();
3295   int flags = op-&gt;flags();
3296   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3297   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3298 
3299   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {
3300     __ jmp(*stub-&gt;entry());
3301     __ bind(*stub-&gt;continuation());
3302     return;
3303   }
3304 
<span class="line-modified">3305   if (flags &amp; LIR_OpArrayCopy::src_valuetype_check) {</span>
<span class="line-modified">3306     arraycopy_valuetype_check(src, tmp, stub, false, (flags &amp; LIR_OpArrayCopy::src_null_check));</span>
3307   }
3308 
<span class="line-modified">3309   if (flags &amp; LIR_OpArrayCopy::dst_valuetype_check) {</span>
<span class="line-modified">3310     arraycopy_valuetype_check(dst, tmp, stub, true, (flags &amp; LIR_OpArrayCopy::dst_null_check));</span>
3311   }
3312 
3313   // if we don&#39;t know anything, just go through the generic arraycopy
3314   if (default_type == NULL) {
3315     // save outgoing arguments on stack in case call to System.arraycopy is needed
3316     // HACK ALERT. This code used to push the parameters in a hardwired fashion
3317     // for interpreter calling conventions. Now we have to do it in new style conventions.
3318     // For the moment until C1 gets the new register allocator I just force all the
3319     // args to the right place (except the register args) and then on the back side
3320     // reload the register args properly if we go slow path. Yuck
3321 
3322     // These are proper for the calling convention
3323     store_parameter(length, 2);
3324     store_parameter(dst_pos, 1);
3325     store_parameter(dst, 0);
3326 
3327     // these are just temporary placements until we need to reload
3328     store_parameter(src_pos, 3);
3329     store_parameter(src, 4);
3330     NOT_LP64(assert(src == rcx &amp;&amp; src_pos == rdx, &quot;mismatch in calling convention&quot;);)
</pre>
</td>
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/macroAssembler.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;c1/c1_Compilation.hpp&quot;
  29 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  30 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  31 #include &quot;c1/c1_Runtime1.hpp&quot;
  32 #include &quot;c1/c1_ValueStack.hpp&quot;
  33 #include &quot;ci/ciArrayKlass.hpp&quot;
<span class="line-added">  34 #include &quot;ci/ciInlineKlass.hpp&quot;</span>
  35 #include &quot;ci/ciInstance.hpp&quot;

  36 #include &quot;gc/shared/collectedHeap.hpp&quot;
  37 #include &quot;nativeInst_x86.hpp&quot;
  38 #include &quot;oops/oop.inline.hpp&quot;
  39 #include &quot;oops/objArrayKlass.hpp&quot;
  40 #include &quot;runtime/frame.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 #include &quot;vmreg_x86.inline.hpp&quot;
  45 
  46 
  47 // These masks are used to provide 128-bit aligned bitmasks to the XMM
  48 // instructions, to allow sign-masking or sign-bit flipping.  They allow
  49 // fast versions of NegF/NegD and AbsF/AbsD.
  50 
  51 // Note: &#39;double&#39; and &#39;long long&#39; have 32-bits alignment on x86.
  52 static jlong* double_quadword(jlong *adr, jlong lo, jlong hi) {
  53   // Use the expression (adr)&amp;(~0xF) to provide 128-bits aligned address
  54   // of 128-bits operands for SSE instructions.
  55   jlong *operand = (jlong*)(((intptr_t)adr) &amp; ((intptr_t)(~0xF)));
</pre>
<hr />
<pre>
 512   int offset = code_offset();
 513   InternalAddress here(__ pc());
 514 
 515   __ pushptr(here.addr());
 516   __ jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 517   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 518   __ end_a_stub();
 519 
 520   return offset;
 521 }
 522 
 523 
 524 void LIR_Assembler::return_op(LIR_Opr result) {
 525   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == rax, &quot;word returns are in rax,&quot;);
 526   if (!result-&gt;is_illegal() &amp;&amp; result-&gt;is_float_kind() &amp;&amp; !result-&gt;is_xmm_register()) {
 527     assert(result-&gt;fpu() == 0, &quot;result must already be on TOS&quot;);
 528   }
 529 
 530   ciMethod* method = compilation()-&gt;method();
 531   ciType* return_type = method-&gt;return_type();
<span class="line-modified"> 532   if (InlineTypeReturnedAsFields &amp;&amp; return_type-&gt;is_inlinetype()) {</span>
<span class="line-modified"> 533     ciInlineKlass* vk = return_type-&gt;as_inline_klass();</span>
 534     if (vk-&gt;can_be_returned_as_fields()) {
 535 #ifndef _LP64
 536       Unimplemented();
 537 #else
 538       address unpack_handler = vk-&gt;unpack_handler();
 539       assert(unpack_handler != NULL, &quot;must be&quot;);
 540       __ call(RuntimeAddress(unpack_handler));
 541       // At this point, rax points to the value object (for interpreter or C1 caller).
 542       // The fields of the object are copied into registers (for C2 caller).
 543 #endif
 544     }
 545   }
 546 
 547   // Pop the stack before the safepoint code
 548   int initial_framesize = initial_frame_size_in_bytes();
 549   __ remove_frame(initial_framesize, needs_stack_repair(), initial_framesize - wordSize);
 550 
 551   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 552     __ reserved_stack_check();
 553   }
</pre>
<hr />
<pre>
 555   bool result_is_oop = result-&gt;is_valid() ? result-&gt;is_oop() : false;
 556 
 557   // Note: we do not need to round double result; float result has the right precision
 558   // the poll sets the condition code, but no data registers
 559 
 560 #ifdef _LP64
 561   const Register poll_addr = rscratch1;
 562   __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 563 #else
 564   const Register poll_addr = rbx;
 565   assert(FrameMap::is_caller_save_register(poll_addr), &quot;will overwrite&quot;);
 566   __ get_thread(poll_addr);
 567   __ movptr(poll_addr, Address(poll_addr, Thread::polling_page_offset()));
 568 #endif
 569   __ relocate(relocInfo::poll_return_type);
 570   __ testl(rax, Address(poll_addr, 0));
 571   __ ret(0);
 572 }
 573 
 574 
<span class="line-modified"> 575 int LIR_Assembler::store_inline_type_fields_to_buf(ciInlineKlass* vk) {</span>
 576   return (__ store_inline_type_fields_to_buf(vk, false));
 577 }
 578 
 579 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 580   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 581   int offset = __ offset();
 582 #ifdef _LP64
 583   const Register poll_addr = rscratch1;
 584   __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 585 #else
 586   assert(tmp-&gt;is_cpu_register(), &quot;needed&quot;);
 587   const Register poll_addr = tmp-&gt;as_register();
 588   __ get_thread(poll_addr);
 589   __ movptr(poll_addr, Address(poll_addr, in_bytes(Thread::polling_page_offset())));
 590 #endif
 591   add_debug_info_for_branch(info);
 592   __ relocate(relocInfo::poll_type);
 593   address pre_pc = __ pc();
 594   __ testl(rax, Address(poll_addr, 0));
 595   address post_pc = __ pc();
</pre>
<hr />
<pre>
2034   __ jcc(Assembler::equal, L_oops_equal);
2035 
2036   // (1) Null check -- if one of the operands is null, the other must not be null (because
2037   //     the two references are not equal), so they are not substitutable,
2038   //     FIXME: do null check only if the operand is nullable
2039   {
2040     __ cmpptr(left, (int32_t)NULL_WORD);
2041     __ jcc(Assembler::equal, L_oops_not_equal);
2042 
2043     __ cmpptr(right, (int32_t)NULL_WORD);
2044     __ jcc(Assembler::equal, L_oops_not_equal);
2045   }
2046 
2047   ciKlass* left_klass = op-&gt;left_klass();
2048   ciKlass* right_klass = op-&gt;right_klass();
2049 
2050   // (2) Value object check -- if either of the operands is not a value object,
2051   //     they are not substitutable. We do this only if we are not sure that the
2052   //     operands are value objects
2053   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
<span class="line-modified">2054       !left_klass-&gt;is_inlinetype() || !right_klass-&gt;is_inlinetype()) {</span>
2055     Register tmp1  = op-&gt;tmp1()-&gt;as_register();
2056     __ movptr(tmp1, (intptr_t)markWord::always_locked_pattern);
2057     __ andl(tmp1, Address(left, oopDesc::mark_offset_in_bytes()));
2058     __ andl(tmp1, Address(right, oopDesc::mark_offset_in_bytes()));
2059     __ cmpptr(tmp1, (intptr_t)markWord::always_locked_pattern);
2060     __ jcc(Assembler::notEqual, L_oops_not_equal);
2061   }
2062 
2063   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.
<span class="line-modified">2064   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_inlinetype() &amp;&amp; left_klass == right_klass) {</span>
<span class="line-modified">2065     // No need to load klass -- the operands are statically known to be the same inline klass.</span>
2066     __ jmp(*op-&gt;stub()-&gt;entry());
2067   } else {
2068     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();
2069     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();
2070 
2071     if (UseCompressedOops) {
2072       __ movl(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
2073       __ movl(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
2074       __ cmpl(left_klass_op, right_klass_op);
2075     } else {
2076       __ movptr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
2077       __ movptr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
2078       __ cmpptr(left_klass_op, right_klass_op);
2079     }
2080 
2081     __ jcc(Assembler::equal, *op-&gt;stub()-&gt;entry()); // same klass -&gt; do slow check
2082     // fall through to L_oops_not_equal
2083   }
2084 
2085   __ bind(L_oops_not_equal);
</pre>
<hr />
<pre>
3239   __ movptr (Address(rsp, offset_from_rsp_in_bytes), c);
3240 }
3241 
3242 
3243 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
3244   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3245   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3246   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3247   __ movoop (Address(rsp, offset_from_rsp_in_bytes), o);
3248 }
3249 
3250 
3251 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3252   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3253   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3254   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3255   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3256 }
3257 
3258 
<span class="line-modified">3259 void LIR_Assembler::arraycopy_inlinetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest, bool null_check) {</span>
3260   if (null_check) {
3261     __ testptr(obj, obj);
3262     __ jcc(Assembler::zero, *slow_path-&gt;entry());
3263   }
3264   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
3265   __ load_klass(tmp, obj, tmp_load_klass);
3266   __ movl(tmp, Address(tmp, Klass::layout_helper_offset()));
3267   if (is_dest) {
3268     // We also take slow path if it&#39;s a null_free destination array, just in case the source array
3269     // contains NULLs.
3270     __ testl(tmp, Klass::_lh_null_free_bit_inplace);
3271   } else {
3272     __ testl(tmp, Klass::_lh_array_tag_vt_value_bit_inplace);
3273   }
3274   __ jcc(Assembler::notZero, *slow_path-&gt;entry());
3275 }
3276 
3277 
3278 // This code replaces a call to arraycopy; no exception may
3279 // be thrown in this code, they must be thrown in the System.arraycopy
</pre>
<hr />
<pre>
3285   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3286   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3287   Register length  = op-&gt;length()-&gt;as_register();
3288   Register tmp = op-&gt;tmp()-&gt;as_register();
3289   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
3290 
3291   __ resolve(ACCESS_READ, src);
3292   __ resolve(ACCESS_WRITE, dst);
3293 
3294   CodeStub* stub = op-&gt;stub();
3295   int flags = op-&gt;flags();
3296   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3297   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3298 
3299   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {
3300     __ jmp(*stub-&gt;entry());
3301     __ bind(*stub-&gt;continuation());
3302     return;
3303   }
3304 
<span class="line-modified">3305   if (flags &amp; LIR_OpArrayCopy::src_inlinetype_check) {</span>
<span class="line-modified">3306     arraycopy_inlinetype_check(src, tmp, stub, false, (flags &amp; LIR_OpArrayCopy::src_null_check));</span>
3307   }
3308 
<span class="line-modified">3309   if (flags &amp; LIR_OpArrayCopy::dst_inlinetype_check) {</span>
<span class="line-modified">3310     arraycopy_inlinetype_check(dst, tmp, stub, true, (flags &amp; LIR_OpArrayCopy::dst_null_check));</span>
3311   }
3312 
3313   // if we don&#39;t know anything, just go through the generic arraycopy
3314   if (default_type == NULL) {
3315     // save outgoing arguments on stack in case call to System.arraycopy is needed
3316     // HACK ALERT. This code used to push the parameters in a hardwired fashion
3317     // for interpreter calling conventions. Now we have to do it in new style conventions.
3318     // For the moment until C1 gets the new register allocator I just force all the
3319     // args to the right place (except the register args) and then on the back side
3320     // reload the register args properly if we go slow path. Yuck
3321 
3322     // These are proper for the calling convention
3323     store_parameter(length, 2);
3324     store_parameter(dst_pos, 1);
3325     store_parameter(dst, 0);
3326 
3327     // these are just temporary placements until we need to reload
3328     store_parameter(src_pos, 3);
3329     store_parameter(src, 4);
3330     NOT_LP64(assert(src == rcx &amp;&amp; src_pos == rdx, &quot;mismatch in calling convention&quot;);)
</pre>
</td>
</tr>
</table>
<center><a href="c1_CodeStubs_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>