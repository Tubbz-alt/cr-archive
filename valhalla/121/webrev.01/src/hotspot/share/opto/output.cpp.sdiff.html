<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/output.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="node.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="output.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/output.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 291   Block *broot = C-&gt;cfg()-&gt;get_root_block();
 292 
 293   const StartNode *start = entry-&gt;head()-&gt;as_Start();
 294 
 295   // Replace StartNode with prolog
 296   Label verified_entry;
 297   MachPrologNode* prolog = new MachPrologNode(&amp;verified_entry);
 298   entry-&gt;map_node(prolog, 0);
 299   C-&gt;cfg()-&gt;map_node_to_block(prolog, entry);
 300   C-&gt;cfg()-&gt;unmap_node_from_block(start); // start is no longer in any block
 301 
 302   // Virtual methods need an unverified entry point
 303   if (C-&gt;is_osr_compilation()) {
 304     if (PoisonOSREntry) {
 305       // TODO: Should use a ShouldNotReachHereNode...
 306       C-&gt;cfg()-&gt;insert( broot, 0, new MachBreakpointNode() );
 307     }
 308   } else {
 309     if (C-&gt;method()) {
 310       if (C-&gt;method()-&gt;has_scalarized_args()) {
<span class="line-modified"> 311         // Add entry point to unpack all value type arguments</span>
 312         C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ true, /* receiver_only */ false));
 313         if (!C-&gt;method()-&gt;is_static()) {
<span class="line-modified"> 314           // Add verified/unverified entry points to only unpack value type receiver at interface calls</span>
 315           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ false, /* receiver_only */ false));
 316           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ true,  /* receiver_only */ true));
 317           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ false, /* receiver_only */ true));
 318         }
 319       } else if (!C-&gt;method()-&gt;is_static()) {
 320         // Insert unvalidated entry point
 321         C-&gt;cfg()-&gt;insert(broot, 0, new MachUEPNode());
 322       }
 323     }
 324   }
 325 
 326   // Break before main entry point
 327   if ((C-&gt;method() &amp;&amp; C-&gt;directive()-&gt;BreakAtExecuteOption) ||
 328       (OptoBreakpoint &amp;&amp; C-&gt;is_method_compilation())       ||
 329       (OptoBreakpointOSR &amp;&amp; C-&gt;is_osr_compilation())       ||
 330       (OptoBreakpointC2R &amp;&amp; !C-&gt;method())                   ) {
 331     // checking for C-&gt;method() means that OptoBreakpoint does not apply to
 332     // runtime stubs or frame converters
 333     C-&gt;cfg()-&gt;insert( entry, 1, new MachBreakpointNode() );
 334   }
</pre>
<hr />
<pre>
 344         C-&gt;cfg()-&gt;map_node_to_block(epilog, block);
 345       }
 346     }
 347   }
 348 
 349   // Keeper of sizing aspects
 350   _buf_sizes = BufferSizingData();
 351 
 352   // Initialize code buffer
 353   estimate_buffer_size(_buf_sizes._const);
 354   if (C-&gt;failing()) return;
 355 
 356   // Pre-compute the length of blocks and replace
 357   // long branches with short if machine supports it.
 358   // Must be done before ScheduleAndBundle due to SPARC delay slots
 359   uint* blk_starts = NEW_RESOURCE_ARRAY(uint, C-&gt;cfg()-&gt;number_of_blocks() + 1);
 360   blk_starts[0] = 0;
 361   shorten_branches(blk_starts);
 362 
 363   if (!C-&gt;is_osr_compilation() &amp;&amp; C-&gt;has_scalarized_args()) {
<span class="line-modified"> 364     // Compute the offsets of the entry points required by the value type calling convention</span>
 365     if (!C-&gt;method()-&gt;is_static()) {
 366       // We have entries at the beginning of the method, implemented by the first 4 nodes.
 367       // Entry                     (unverified) @ offset 0
<span class="line-modified"> 368       // Verified_Value_Entry_RO</span>
<span class="line-modified"> 369       // Value_Entry               (unverified)</span>
<span class="line-modified"> 370       // Verified_Value_Entry</span>
 371       uint offset = 0;
 372       _code_offsets.set_value(CodeOffsets::Entry, offset);
 373 
 374       offset += ((MachVEPNode*)broot-&gt;get_node(0))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 375       _code_offsets.set_value(CodeOffsets::Verified_Value_Entry_RO, offset);</span>
 376 
 377       offset += ((MachVEPNode*)broot-&gt;get_node(1))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 378       _code_offsets.set_value(CodeOffsets::Value_Entry, offset);</span>
 379 
 380       offset += ((MachVEPNode*)broot-&gt;get_node(2))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 381       _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, offset);</span>
 382     } else {
 383       _code_offsets.set_value(CodeOffsets::Entry, -1); // will be patched later
<span class="line-modified"> 384       _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, 0);</span>
 385     }
 386   }
 387 
 388   ScheduleAndBundle();
 389   if (C-&gt;failing()) {
 390     return;
 391   }
 392 
 393   perform_mach_node_analysis();
 394 
 395   // Complete sizing of codebuffer
 396   CodeBuffer* cb = init_buffer();
 397   if (cb == NULL || C-&gt;failing()) {
 398     return;
 399   }
 400 
 401   BuildOopMaps();
 402 
 403   if (C-&gt;failing())  {
 404     return;
</pre>
<hr />
<pre>
3219 
3220 //-----------------------init_scratch_buffer_blob------------------------------
3221 // Construct a temporary BufferBlob and cache it for this compile.
3222 void PhaseOutput::init_scratch_buffer_blob(int const_size) {
3223   // If there is already a scratch buffer blob allocated and the
3224   // constant section is big enough, use it.  Otherwise free the
3225   // current and allocate a new one.
3226   BufferBlob* blob = scratch_buffer_blob();
3227   if ((blob != NULL) &amp;&amp; (const_size &lt;= _scratch_const_size)) {
3228     // Use the current blob.
3229   } else {
3230     if (blob != NULL) {
3231       BufferBlob::free(blob);
3232     }
3233 
3234     ResourceMark rm;
3235     _scratch_const_size = const_size;
3236     int size = C2Compiler::initial_code_buffer_size(const_size);
3237 #ifdef ASSERT
3238     if (C-&gt;has_scalarized_args()) {
<span class="line-modified">3239       // Oop verification for loading object fields from scalarized value types in the new entry point requires lots of space</span>
3240       size += 5120;
3241     }
3242 #endif
3243     blob = BufferBlob::create(&quot;Compile::scratch_buffer&quot;, size);
3244     // Record the buffer blob for next time.
3245     set_scratch_buffer_blob(blob);
3246     // Have we run out of code space?
3247     if (scratch_buffer_blob() == NULL) {
3248       // Let CompilerBroker disable further compilations.
3249       C-&gt;record_failure(&quot;Not enough space for scratch buffer in CodeCache&quot;);
3250       return;
3251     }
3252   }
3253 
3254   // Initialize the relocation buffers
3255   relocInfo* locs_buf = (relocInfo*) blob-&gt;content_end() - MAX_locs_size;
3256   set_scratch_locs_memory(locs_buf);
3257 }
3258 
3259 
</pre>
<hr />
<pre>
3349                                int               entry_bci,
3350                                AbstractCompiler* compiler,
3351                                bool              has_unsafe_access,
3352                                bool              has_wide_vectors,
3353                                RTMState          rtm_state) {
3354   // Check if we want to skip execution of all compiled code.
3355   {
3356 #ifndef PRODUCT
3357     if (OptoNoExecute) {
3358       C-&gt;record_method_not_compilable(&quot;+OptoNoExecute&quot;);  // Flag as failed
3359       return;
3360     }
3361 #endif
3362     Compile::TracePhase tp(&quot;install_code&quot;, &amp;timers[_t_registerMethod]);
3363 
3364     if (C-&gt;is_osr_compilation()) {
3365       _code_offsets.set_value(CodeOffsets::Verified_Entry, 0);
3366       _code_offsets.set_value(CodeOffsets::OSR_Entry, _first_block_size);
3367     } else {
3368       _code_offsets.set_value(CodeOffsets::Verified_Entry, _first_block_size);
<span class="line-modified">3369       if (_code_offsets.value(CodeOffsets::Verified_Value_Entry) == -1) {</span>
<span class="line-modified">3370         _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, _first_block_size);</span>
3371       }
<span class="line-modified">3372       if (_code_offsets.value(CodeOffsets::Verified_Value_Entry_RO) == -1) {</span>
<span class="line-modified">3373         _code_offsets.set_value(CodeOffsets::Verified_Value_Entry_RO, _first_block_size);</span>
3374       }
3375       if (_code_offsets.value(CodeOffsets::Entry) == -1) {
3376         _code_offsets.set_value(CodeOffsets::Entry, _first_block_size);
3377       }
3378       _code_offsets.set_value(CodeOffsets::OSR_Entry, 0);
3379     }
3380 
3381     C-&gt;env()-&gt;register_method(target,
3382                               entry_bci,
3383                               &amp;_code_offsets,
3384                               _orig_pc_slot_offset_in_bytes,
3385                               code_buffer(),
3386                               frame_size_in_words(),
3387                               _oop_map_set,
3388                               &amp;_handler_table,
3389                               &amp;_inc_table,
3390                               compiler,
3391                               has_unsafe_access,
3392                               SharedRuntime::is_wide_vector(C-&gt;max_vector_size()),
3393                               C-&gt;rtm_state());
</pre>
</td>
<td>
<hr />
<pre>
 291   Block *broot = C-&gt;cfg()-&gt;get_root_block();
 292 
 293   const StartNode *start = entry-&gt;head()-&gt;as_Start();
 294 
 295   // Replace StartNode with prolog
 296   Label verified_entry;
 297   MachPrologNode* prolog = new MachPrologNode(&amp;verified_entry);
 298   entry-&gt;map_node(prolog, 0);
 299   C-&gt;cfg()-&gt;map_node_to_block(prolog, entry);
 300   C-&gt;cfg()-&gt;unmap_node_from_block(start); // start is no longer in any block
 301 
 302   // Virtual methods need an unverified entry point
 303   if (C-&gt;is_osr_compilation()) {
 304     if (PoisonOSREntry) {
 305       // TODO: Should use a ShouldNotReachHereNode...
 306       C-&gt;cfg()-&gt;insert( broot, 0, new MachBreakpointNode() );
 307     }
 308   } else {
 309     if (C-&gt;method()) {
 310       if (C-&gt;method()-&gt;has_scalarized_args()) {
<span class="line-modified"> 311         // Add entry point to unpack all inline type arguments</span>
 312         C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ true, /* receiver_only */ false));
 313         if (!C-&gt;method()-&gt;is_static()) {
<span class="line-modified"> 314           // Add verified/unverified entry points to only unpack inline type receiver at interface calls</span>
 315           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ false, /* receiver_only */ false));
 316           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ true,  /* receiver_only */ true));
 317           C-&gt;cfg()-&gt;insert(broot, 0, new MachVEPNode(&amp;verified_entry, /* verified */ false, /* receiver_only */ true));
 318         }
 319       } else if (!C-&gt;method()-&gt;is_static()) {
 320         // Insert unvalidated entry point
 321         C-&gt;cfg()-&gt;insert(broot, 0, new MachUEPNode());
 322       }
 323     }
 324   }
 325 
 326   // Break before main entry point
 327   if ((C-&gt;method() &amp;&amp; C-&gt;directive()-&gt;BreakAtExecuteOption) ||
 328       (OptoBreakpoint &amp;&amp; C-&gt;is_method_compilation())       ||
 329       (OptoBreakpointOSR &amp;&amp; C-&gt;is_osr_compilation())       ||
 330       (OptoBreakpointC2R &amp;&amp; !C-&gt;method())                   ) {
 331     // checking for C-&gt;method() means that OptoBreakpoint does not apply to
 332     // runtime stubs or frame converters
 333     C-&gt;cfg()-&gt;insert( entry, 1, new MachBreakpointNode() );
 334   }
</pre>
<hr />
<pre>
 344         C-&gt;cfg()-&gt;map_node_to_block(epilog, block);
 345       }
 346     }
 347   }
 348 
 349   // Keeper of sizing aspects
 350   _buf_sizes = BufferSizingData();
 351 
 352   // Initialize code buffer
 353   estimate_buffer_size(_buf_sizes._const);
 354   if (C-&gt;failing()) return;
 355 
 356   // Pre-compute the length of blocks and replace
 357   // long branches with short if machine supports it.
 358   // Must be done before ScheduleAndBundle due to SPARC delay slots
 359   uint* blk_starts = NEW_RESOURCE_ARRAY(uint, C-&gt;cfg()-&gt;number_of_blocks() + 1);
 360   blk_starts[0] = 0;
 361   shorten_branches(blk_starts);
 362 
 363   if (!C-&gt;is_osr_compilation() &amp;&amp; C-&gt;has_scalarized_args()) {
<span class="line-modified"> 364     // Compute the offsets of the entry points required by the inline type calling convention</span>
 365     if (!C-&gt;method()-&gt;is_static()) {
 366       // We have entries at the beginning of the method, implemented by the first 4 nodes.
 367       // Entry                     (unverified) @ offset 0
<span class="line-modified"> 368       // Verified_Inline_Entry_RO</span>
<span class="line-modified"> 369       // Inline_Entry              (unverified)</span>
<span class="line-modified"> 370       // Verified_Inline_Entry</span>
 371       uint offset = 0;
 372       _code_offsets.set_value(CodeOffsets::Entry, offset);
 373 
 374       offset += ((MachVEPNode*)broot-&gt;get_node(0))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 375       _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry_RO, offset);</span>
 376 
 377       offset += ((MachVEPNode*)broot-&gt;get_node(1))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 378       _code_offsets.set_value(CodeOffsets::Inline_Entry, offset);</span>
 379 
 380       offset += ((MachVEPNode*)broot-&gt;get_node(2))-&gt;size(C-&gt;regalloc());
<span class="line-modified"> 381       _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, offset);</span>
 382     } else {
 383       _code_offsets.set_value(CodeOffsets::Entry, -1); // will be patched later
<span class="line-modified"> 384       _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, 0);</span>
 385     }
 386   }
 387 
 388   ScheduleAndBundle();
 389   if (C-&gt;failing()) {
 390     return;
 391   }
 392 
 393   perform_mach_node_analysis();
 394 
 395   // Complete sizing of codebuffer
 396   CodeBuffer* cb = init_buffer();
 397   if (cb == NULL || C-&gt;failing()) {
 398     return;
 399   }
 400 
 401   BuildOopMaps();
 402 
 403   if (C-&gt;failing())  {
 404     return;
</pre>
<hr />
<pre>
3219 
3220 //-----------------------init_scratch_buffer_blob------------------------------
3221 // Construct a temporary BufferBlob and cache it for this compile.
3222 void PhaseOutput::init_scratch_buffer_blob(int const_size) {
3223   // If there is already a scratch buffer blob allocated and the
3224   // constant section is big enough, use it.  Otherwise free the
3225   // current and allocate a new one.
3226   BufferBlob* blob = scratch_buffer_blob();
3227   if ((blob != NULL) &amp;&amp; (const_size &lt;= _scratch_const_size)) {
3228     // Use the current blob.
3229   } else {
3230     if (blob != NULL) {
3231       BufferBlob::free(blob);
3232     }
3233 
3234     ResourceMark rm;
3235     _scratch_const_size = const_size;
3236     int size = C2Compiler::initial_code_buffer_size(const_size);
3237 #ifdef ASSERT
3238     if (C-&gt;has_scalarized_args()) {
<span class="line-modified">3239       // Oop verification for loading object fields from scalarized inline types in the new entry point requires lots of space</span>
3240       size += 5120;
3241     }
3242 #endif
3243     blob = BufferBlob::create(&quot;Compile::scratch_buffer&quot;, size);
3244     // Record the buffer blob for next time.
3245     set_scratch_buffer_blob(blob);
3246     // Have we run out of code space?
3247     if (scratch_buffer_blob() == NULL) {
3248       // Let CompilerBroker disable further compilations.
3249       C-&gt;record_failure(&quot;Not enough space for scratch buffer in CodeCache&quot;);
3250       return;
3251     }
3252   }
3253 
3254   // Initialize the relocation buffers
3255   relocInfo* locs_buf = (relocInfo*) blob-&gt;content_end() - MAX_locs_size;
3256   set_scratch_locs_memory(locs_buf);
3257 }
3258 
3259 
</pre>
<hr />
<pre>
3349                                int               entry_bci,
3350                                AbstractCompiler* compiler,
3351                                bool              has_unsafe_access,
3352                                bool              has_wide_vectors,
3353                                RTMState          rtm_state) {
3354   // Check if we want to skip execution of all compiled code.
3355   {
3356 #ifndef PRODUCT
3357     if (OptoNoExecute) {
3358       C-&gt;record_method_not_compilable(&quot;+OptoNoExecute&quot;);  // Flag as failed
3359       return;
3360     }
3361 #endif
3362     Compile::TracePhase tp(&quot;install_code&quot;, &amp;timers[_t_registerMethod]);
3363 
3364     if (C-&gt;is_osr_compilation()) {
3365       _code_offsets.set_value(CodeOffsets::Verified_Entry, 0);
3366       _code_offsets.set_value(CodeOffsets::OSR_Entry, _first_block_size);
3367     } else {
3368       _code_offsets.set_value(CodeOffsets::Verified_Entry, _first_block_size);
<span class="line-modified">3369       if (_code_offsets.value(CodeOffsets::Verified_Inline_Entry) == -1) {</span>
<span class="line-modified">3370         _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry, _first_block_size);</span>
3371       }
<span class="line-modified">3372       if (_code_offsets.value(CodeOffsets::Verified_Inline_Entry_RO) == -1) {</span>
<span class="line-modified">3373         _code_offsets.set_value(CodeOffsets::Verified_Inline_Entry_RO, _first_block_size);</span>
3374       }
3375       if (_code_offsets.value(CodeOffsets::Entry) == -1) {
3376         _code_offsets.set_value(CodeOffsets::Entry, _first_block_size);
3377       }
3378       _code_offsets.set_value(CodeOffsets::OSR_Entry, 0);
3379     }
3380 
3381     C-&gt;env()-&gt;register_method(target,
3382                               entry_bci,
3383                               &amp;_code_offsets,
3384                               _orig_pc_slot_offset_in_bytes,
3385                               code_buffer(),
3386                               frame_size_in_words(),
3387                               _oop_map_set,
3388                               &amp;_handler_table,
3389                               &amp;_inc_table,
3390                               compiler,
3391                               has_unsafe_access,
3392                               SharedRuntime::is_wide_vector(C-&gt;max_vector_size()),
3393                               C-&gt;rtm_state());
</pre>
</td>
</tr>
</table>
<center><a href="node.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="output.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>