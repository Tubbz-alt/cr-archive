<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/deoptimization.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../precompiled/precompiled.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/deoptimization.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 217       if (objects != NULL) {
 218         realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);
 219         Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal, THREAD);
 220       }
 221     JRT_END
 222 #ifndef PRODUCT
 223     if (TraceDeoptimization) {
 224       ttyLocker ttyl;
 225       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
 226       if (objects != NULL) {
 227         Deoptimization::print_objects(objects, realloc_failures);
 228       } else {
 229         Handle obj = realloc_failures ? Handle() : return_oops.first();
 230         Deoptimization::print_object(vk, obj, realloc_failures);
 231       }
 232     }
 233 #endif
 234   }
 235   if (save_oop_result || vk != NULL) {
 236     // Restore result.
<span class="line-modified"> 237     assert(return_oops.length() == 1, &quot;no value type&quot;);</span>
 238     deoptee.set_saved_oop_result(&amp;map, return_oops.pop()());
 239   }
 240   return realloc_failures;
 241 }
 242 
 243 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 244 #ifndef PRODUCT
 245   bool first = true;
 246 #endif
 247   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 248     compiledVFrame* cvf = chunk-&gt;at(i);
 249     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 250     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 251     if (monitors-&gt;is_nonempty()) {
 252       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 253 #ifndef PRODUCT
 254       if (PrintDeoptimizationDetails) {
 255         ttyLocker ttyl;
 256         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 257           MonitorInfo* mi = monitors-&gt;at(j);
</pre>
<hr />
<pre>
1019     oop obj = NULL;
1020 
1021     if (k-&gt;is_instance_klass()) {
1022 #if INCLUDE_JVMCI || INCLUDE_AOT
1023       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
1024       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
1025         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
1026         obj = get_cached_box(abv, fr, reg_map, THREAD);
1027         if (obj != NULL) {
1028           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
1029           abv-&gt;set_cached(true);
1030         }
1031       }
1032 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1033       InstanceKlass* ik = InstanceKlass::cast(k);
1034       if (obj == NULL) {
1035         obj = ik-&gt;allocate_instance(THREAD);
1036       }
1037     } else if (k-&gt;is_flatArray_klass()) {
1038       FlatArrayKlass* ak = FlatArrayKlass::cast(k);
<span class="line-modified">1039       // Value type array must be zeroed because not all memory is reassigned</span>
1040       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1041     } else if (k-&gt;is_typeArray_klass()) {
1042       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1043       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1044       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1045       obj = ak-&gt;allocate(len, THREAD);
1046     } else if (k-&gt;is_objArray_klass()) {
1047       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1048       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1049     }
1050 
1051     if (obj == NULL) {
1052       failures = true;
1053     }
1054 
1055     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1056     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1057     CLEAR_PENDING_EXCEPTION;
1058     sv-&gt;set_value(obj);
1059   }
</pre>
<hr />
<pre>
1266 int compare(ReassignedField* left, ReassignedField* right) {
1267   return left-&gt;_offset - right-&gt;_offset;
1268 }
1269 
1270 // Restore fields of an eliminated instance object using the same field order
1271 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
1272 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {
1273 
1274   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1275   InstanceKlass* ik = klass;
1276   while (ik != NULL) {
1277     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1278       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1279         ReassignedField field;
1280         field._offset = fs.offset();
1281         field._type = Signature::basic_type(fs.signature());
1282         if (field._type == T_INLINE_TYPE) {
1283           field._type = T_OBJECT;
1284         }
1285         if (fs.is_inlined()) {
<span class="line-modified">1286           // Resolve klass of flattened value type field</span>
1287           Klass* vk = klass-&gt;get_inline_type_field_klass(fs.index());
1288           field._klass = InlineKlass::cast(vk);
1289           field._type = T_INLINE_TYPE;
1290         }
1291         fields-&gt;append(field);
1292       }
1293     }
1294     ik = ik-&gt;superklass();
1295   }
1296   fields-&gt;sort(compare);
1297   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1298     intptr_t val;
1299     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1300     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
1301     int offset = base_offset + fields-&gt;at(i)._offset;
1302     BasicType type = fields-&gt;at(i)._type;
1303     switch (type) {
1304       case T_OBJECT:
1305       case T_ARRAY:
1306         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1307         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1308         break;
1309 
1310       case T_INLINE_TYPE: {
<span class="line-modified">1311         // Recursively re-assign flattened value type fields</span>
1312         InstanceKlass* vk = fields-&gt;at(i)._klass;
1313         assert(vk != NULL, &quot;must be resolved&quot;);
1314         offset -= InlineKlass::cast(vk)-&gt;first_field_offset(); // Adjust offset to omit oop header
1315         svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);
1316         continue; // Continue because we don&#39;t need to increment svIndex
1317       }
1318 
1319       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1320       case T_INT: case T_FLOAT: { // 4 bytes.
1321         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1322         bool big_value = false;
1323         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1324           if (scope_field-&gt;is_location()) {
1325             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1326             if (type == Location::dbl || type == Location::lng) {
1327               big_value = true;
1328             }
1329           }
1330           if (scope_field-&gt;is_constant_int()) {
1331             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
</pre>
</td>
<td>
<hr />
<pre>
 217       if (objects != NULL) {
 218         realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &amp;deoptee, &amp;map, objects, THREAD);
 219         Deoptimization::reassign_fields(&amp;deoptee, &amp;map, objects, realloc_failures, skip_internal, THREAD);
 220       }
 221     JRT_END
 222 #ifndef PRODUCT
 223     if (TraceDeoptimization) {
 224       ttyLocker ttyl;
 225       tty-&gt;print_cr(&quot;REALLOC OBJECTS in thread &quot; INTPTR_FORMAT, p2i(thread));
 226       if (objects != NULL) {
 227         Deoptimization::print_objects(objects, realloc_failures);
 228       } else {
 229         Handle obj = realloc_failures ? Handle() : return_oops.first();
 230         Deoptimization::print_object(vk, obj, realloc_failures);
 231       }
 232     }
 233 #endif
 234   }
 235   if (save_oop_result || vk != NULL) {
 236     // Restore result.
<span class="line-modified"> 237     assert(return_oops.length() == 1, &quot;no inline type&quot;);</span>
 238     deoptee.set_saved_oop_result(&amp;map, return_oops.pop()());
 239   }
 240   return realloc_failures;
 241 }
 242 
 243 static void eliminate_locks(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk, bool realloc_failures) {
 244 #ifndef PRODUCT
 245   bool first = true;
 246 #endif
 247   for (int i = 0; i &lt; chunk-&gt;length(); i++) {
 248     compiledVFrame* cvf = chunk-&gt;at(i);
 249     assert (cvf-&gt;scope() != NULL,&quot;expect only compiled java frames&quot;);
 250     GrowableArray&lt;MonitorInfo*&gt;* monitors = cvf-&gt;monitors();
 251     if (monitors-&gt;is_nonempty()) {
 252       Deoptimization::relock_objects(monitors, thread, realloc_failures);
 253 #ifndef PRODUCT
 254       if (PrintDeoptimizationDetails) {
 255         ttyLocker ttyl;
 256         for (int j = 0; j &lt; monitors-&gt;length(); j++) {
 257           MonitorInfo* mi = monitors-&gt;at(j);
</pre>
<hr />
<pre>
1019     oop obj = NULL;
1020 
1021     if (k-&gt;is_instance_klass()) {
1022 #if INCLUDE_JVMCI || INCLUDE_AOT
1023       CompiledMethod* cm = fr-&gt;cb()-&gt;as_compiled_method_or_null();
1024       if (cm-&gt;is_compiled_by_jvmci() &amp;&amp; sv-&gt;is_auto_box()) {
1025         AutoBoxObjectValue* abv = (AutoBoxObjectValue*) sv;
1026         obj = get_cached_box(abv, fr, reg_map, THREAD);
1027         if (obj != NULL) {
1028           // Set the flag to indicate the box came from a cache, so that we can skip the field reassignment for it.
1029           abv-&gt;set_cached(true);
1030         }
1031       }
1032 #endif // INCLUDE_JVMCI || INCLUDE_AOT
1033       InstanceKlass* ik = InstanceKlass::cast(k);
1034       if (obj == NULL) {
1035         obj = ik-&gt;allocate_instance(THREAD);
1036       }
1037     } else if (k-&gt;is_flatArray_klass()) {
1038       FlatArrayKlass* ak = FlatArrayKlass::cast(k);
<span class="line-modified">1039       // Inline type array must be zeroed because not all memory is reassigned</span>
1040       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1041     } else if (k-&gt;is_typeArray_klass()) {
1042       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
1043       assert(sv-&gt;field_size() % type2size[ak-&gt;element_type()] == 0, &quot;non-integral array length&quot;);
1044       int len = sv-&gt;field_size() / type2size[ak-&gt;element_type()];
1045       obj = ak-&gt;allocate(len, THREAD);
1046     } else if (k-&gt;is_objArray_klass()) {
1047       ObjArrayKlass* ak = ObjArrayKlass::cast(k);
1048       obj = ak-&gt;allocate(sv-&gt;field_size(), THREAD);
1049     }
1050 
1051     if (obj == NULL) {
1052       failures = true;
1053     }
1054 
1055     assert(sv-&gt;value().is_null(), &quot;redundant reallocation&quot;);
1056     assert(obj != NULL || HAS_PENDING_EXCEPTION, &quot;allocation should succeed or we should get an exception&quot;);
1057     CLEAR_PENDING_EXCEPTION;
1058     sv-&gt;set_value(obj);
1059   }
</pre>
<hr />
<pre>
1266 int compare(ReassignedField* left, ReassignedField* right) {
1267   return left-&gt;_offset - right-&gt;_offset;
1268 }
1269 
1270 // Restore fields of an eliminated instance object using the same field order
1271 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
1272 static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {
1273 
1274   GrowableArray&lt;ReassignedField&gt;* fields = new GrowableArray&lt;ReassignedField&gt;();
1275   InstanceKlass* ik = klass;
1276   while (ik != NULL) {
1277     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
1278       if (!fs.access_flags().is_static() &amp;&amp; (!skip_internal || !fs.access_flags().is_internal())) {
1279         ReassignedField field;
1280         field._offset = fs.offset();
1281         field._type = Signature::basic_type(fs.signature());
1282         if (field._type == T_INLINE_TYPE) {
1283           field._type = T_OBJECT;
1284         }
1285         if (fs.is_inlined()) {
<span class="line-modified">1286           // Resolve klass of flattened inline type field</span>
1287           Klass* vk = klass-&gt;get_inline_type_field_klass(fs.index());
1288           field._klass = InlineKlass::cast(vk);
1289           field._type = T_INLINE_TYPE;
1290         }
1291         fields-&gt;append(field);
1292       }
1293     }
1294     ik = ik-&gt;superklass();
1295   }
1296   fields-&gt;sort(compare);
1297   for (int i = 0; i &lt; fields-&gt;length(); i++) {
1298     intptr_t val;
1299     ScopeValue* scope_field = sv-&gt;field_at(svIndex);
1300     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
1301     int offset = base_offset + fields-&gt;at(i)._offset;
1302     BasicType type = fields-&gt;at(i)._type;
1303     switch (type) {
1304       case T_OBJECT:
1305       case T_ARRAY:
1306         assert(value-&gt;type() == T_OBJECT, &quot;Agreement.&quot;);
1307         obj-&gt;obj_field_put(offset, value-&gt;get_obj()());
1308         break;
1309 
1310       case T_INLINE_TYPE: {
<span class="line-modified">1311         // Recursively re-assign flattened inline type fields</span>
1312         InstanceKlass* vk = fields-&gt;at(i)._klass;
1313         assert(vk != NULL, &quot;must be resolved&quot;);
1314         offset -= InlineKlass::cast(vk)-&gt;first_field_offset(); // Adjust offset to omit oop header
1315         svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);
1316         continue; // Continue because we don&#39;t need to increment svIndex
1317       }
1318 
1319       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
1320       case T_INT: case T_FLOAT: { // 4 bytes.
1321         assert(value-&gt;type() == T_INT, &quot;Agreement.&quot;);
1322         bool big_value = false;
1323         if (i+1 &lt; fields-&gt;length() &amp;&amp; fields-&gt;at(i+1)._type == T_INT) {
1324           if (scope_field-&gt;is_location()) {
1325             Location::Type type = ((LocationValue*) scope_field)-&gt;location().type();
1326             if (type == Location::dbl || type == Location::lng) {
1327               big_value = true;
1328             }
1329           }
1330           if (scope_field-&gt;is_constant_int()) {
1331             ScopeValue* next_scope_field = sv-&gt;field_at(svIndex + 1);
</pre>
</td>
</tr>
</table>
<center><a href="../precompiled/precompiled.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>