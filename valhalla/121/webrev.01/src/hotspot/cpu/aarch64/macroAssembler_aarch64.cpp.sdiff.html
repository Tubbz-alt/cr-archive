<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
5247 
5248 // n.b. frame size includes space for return pc and rfp
5249   const long framesize = C-&gt;frame_size_in_bytes();
5250   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2 * wordSize alignment&quot;);
5251 
5252   // insert a nop at the start of the prolog so we can patch in a
5253   // branch if we need to invalidate the method later
5254   nop();
5255 
5256   int bangsize = C-&gt;bang_size_in_bytes();
5257   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
5258      generate_stack_overflow_check(bangsize);
5259 
5260   build_frame(framesize);
5261 
5262   if (VerifyStackAtCalls) {
5263     Unimplemented();
5264   }
5265 }
5266 
<span class="line-modified">5267 int MacroAssembler::store_inline_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
5268   // An inline type might be returned. If fields are in registers we
5269   // need to allocate an inline type instance and initialize it with
5270   // the value of the fields.
5271   Label skip;
<span class="line-modified">5272   // We only need a new buffered value if a new one is not returned</span>
5273   cmp(r0, (u1) 1);
5274   br(Assembler::EQ, skip);
5275   int call_offset = -1;
5276 
5277   Label slow_case;
5278 
<span class="line-modified">5279   // Try to allocate a new buffered value (from the heap)</span>
5280   if (UseTLAB) {
5281 
5282     if (vk != NULL) {
5283       // Called from C1, where the return type is statically known.
5284       mov(r1, (intptr_t)vk-&gt;get_InlineKlass());
5285       jint lh = vk-&gt;layout_helper();
5286       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);
5287       mov(r14, lh);
5288     } else {
5289        // Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)
5290        andr(r1, r0, -2);
5291        // get obj size
5292        ldrw(r14, Address(rscratch1 /*klass*/, Klass::layout_helper_offset()));
5293     }
5294 
5295      ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));
5296 
5297      // check whether we have space in TLAB,
5298      // rscratch1 contains pointer to just allocated obj
5299       lea(r14, Address(r13, r14));
</pre>
<hr />
<pre>
5307       str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));
5308 
5309       // Set new class always locked
5310       mov(rscratch1, (uint64_t) markWord::always_locked_prototype().value());
5311       str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));
5312 
5313       store_klass_gap(r13, zr);  // zero klass gap for compressed oops
5314       if (vk == NULL) {
5315         // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
5316          mov(r0, r1);
5317       }
5318 
5319       store_klass(r13, r1);  // klass
5320 
5321       if (vk != NULL) {
5322         // FIXME -- do the packing in-line to avoid the runtime call
5323         mov(r0, r13);
5324         far_call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.
5325       } else {
5326 
<span class="line-modified">5327         // We have our new buffered value, initialize its fields with a</span>
<span class="line-removed">5328         // value class specific handler</span>
5329         ldr(r1, Address(r0, InstanceKlass::adr_inlineklass_fixed_block_offset()));
5330         ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));
5331 
5332         // Mov new class to r0 and call pack_handler
5333         mov(r0, r13);
5334         blr(r1);
5335       }
5336       b(skip);
5337   }
5338 
5339   bind(slow_case);
<span class="line-modified">5340   // We failed to allocate a new value, fall back to a runtime</span>
5341   // call. Some oop field may be live in some registers but we can&#39;t
5342   // tell. That runtime call will take care of preserving them
5343   // across a GC if there&#39;s one.
5344 
5345 
5346   if (from_interpreter) {
5347     super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
5348   } else {
5349     ldr(rscratch1, RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
5350     blr(rscratch1);
5351     call_offset = offset();
5352   }
5353 
5354   bind(skip);
5355   return call_offset;
5356 }
5357 
5358 // Move a value between registers/stack slots and update the reg_state
5359 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {
5360   if (reg_state[to-&gt;value()] == reg_written) {
</pre>
<hr />
<pre>
5392             assert(bt == T_FLOAT, &quot;must be float&quot;);
5393             ldrs(to-&gt;as_FloatRegister(), from_addr);
5394           }
5395         } else {
5396           ldr(to-&gt;as_Register(), from_addr);
5397         }
5398       } else {
5399         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5400         ldr(rscratch1, from_addr);
5401         str(rscratch1, Address(sp, st_off));
5402       }
5403     }
5404   }
5405 
5406   // Update register states
5407   reg_state[from-&gt;value()] = reg_writable;
5408   reg_state[to-&gt;value()] = reg_written;
5409   return true;
5410 }
5411 
<span class="line-modified">5412 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-modified">5413 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-modified">5414                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
5415   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5416   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5417 
5418 
5419   int vt = 1;
5420   bool done = true;
5421   bool mark_done = true;
5422   do {
5423     sig_index--;
5424     BasicType bt = sig-&gt;at(sig_index)._bt;
5425     if (bt == T_INLINE_TYPE) {
5426       vt--;
5427     } else if (bt == T_VOID &amp;&amp;
5428                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5429                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5430       vt++;
5431     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5432       to_index--; // Ignore this
5433     } else {
5434       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5480       } else {
5481         if (bt == T_DOUBLE) {
5482           ldrd(to-&gt;as_FloatRegister(), fromAddr);
5483         } else {
5484           assert(bt == T_FLOAT, &quot;must be float&quot;);
5485           ldrs(to-&gt;as_FloatRegister(), fromAddr);
5486         }
5487      }
5488 
5489     }
5490 
5491   } while (vt != 0);
5492 
5493   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5494     // This is okay because no one else will write to that slot
5495     reg_state[from-&gt;value()] = reg_writable;
5496   }
5497   return done;
5498 }
5499 
<span class="line-modified">5500 // Pack fields back into a value type oop</span>
<span class="line-modified">5501 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-modified">5502                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-modified">5503                                        int ret_off, int extra_stack_offset) {</span>
5504   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5505   assert(to-&gt;is_valid(), &quot;must be&quot;);
5506 
5507   if (reg_state[to-&gt;value()] == reg_written) {
5508     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5509     return true; // Already written
5510   }
5511 
5512   Register val_array = r0;
5513   Register val_obj_tmp = r11;
5514   Register from_reg_tmp = r10;
5515   Register tmp1 = r14;
5516   Register tmp2 = r13;
5517   Register tmp3 = r1;
5518   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5519 
5520   if (reg_state[to-&gt;value()] == reg_readonly) {
5521     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
5522       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5523       return false; // Not yet writable
</pre>
<hr />
<pre>
5563     } else {
5564       if (from_r2-&gt;is_valid()) {
5565         strd(from_r1-&gt;as_FloatRegister(), dst);
5566       } else {
5567         strs(from_r1-&gt;as_FloatRegister(), dst);
5568       }
5569     }
5570 
5571     reg_state[from_r1-&gt;value()] = reg_writable;
5572   }
5573   sig_index = stream.sig_cc_index();
5574   from_index = stream.regs_cc_index();
5575 
5576   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5577   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5578   assert(success, &quot;to register must be writeable&quot;);
5579 
5580   return true;
5581 }
5582 
<span class="line-modified">5583 // Unpack all value type arguments passed as oops</span>
<span class="line-modified">5584 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-modified">5585   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
5586   // Emit code for verified entry and save increment for stack repair on return
5587   verified_entry(C, sp_inc);
5588 }
5589 
<span class="line-modified">5590 int MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-modified">5591                                        BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified">5592                                        int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-modified">5593                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
5594   // Check if we need to extend the stack for packing/unpacking
5595   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;
5596   if (sp_inc &gt; 0) {
5597     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
5598     if (!is_packing) {
5599       // Save the return address, adjust the stack (make sure it is properly
5600       // 16-byte aligned) and copy the return address to the new top of the stack.
5601       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5602       // FIXME: We need not to preserve return address on aarch64
5603       pop(rscratch1);
5604       sub(sp, sp, sp_inc);
5605       push(rscratch1);
5606     }
5607   } else {
5608     // The scalarized calling convention needs less stack space than the unscalarized one.
5609     // No need to extend the stack, the caller will take care of these adjustments.
5610     sp_inc = 0;
5611   }
5612 
5613   int ret_off; // make sure we don&#39;t overwrite the return address
5614   if (is_packing) {
<span class="line-modified">5615     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
5616     // rsp[0] during shuffling.
5617     ret_off = 0;
5618   } else {
5619     // C2 code ensures that sp_inc is a reserved slot.
5620     ret_off = sp_inc;
5621   }
5622 
<span class="line-modified">5623   return shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-modified">5624                                    sig_bt, sig_cc,</span>
<span class="line-modified">5625                                    args_passed, args_on_stack, regs,</span>
<span class="line-modified">5626                                    args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified">5627                                    sp_inc, ret_off);</span>
5628 }
5629 
5630 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5631   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();
5632 }
5633 
5634 void MacroAssembler::cache_wb(Address line) {
5635   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5636   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5637   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5638   // would like to assert this
5639   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5640   if (VM_Version::supports_dcpop()) {
5641     // writeback using clear virtual address to point of persistence
5642     dc(Assembler::CVAP, line.base());
5643   } else {
5644     // no need to generate anything as Unsafe.writebackMemory should
5645     // never invoke this stub
5646   }
5647 }
</pre>
</td>
<td>
<hr />
<pre>
5247 
5248 // n.b. frame size includes space for return pc and rfp
5249   const long framesize = C-&gt;frame_size_in_bytes();
5250   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2 * wordSize alignment&quot;);
5251 
5252   // insert a nop at the start of the prolog so we can patch in a
5253   // branch if we need to invalidate the method later
5254   nop();
5255 
5256   int bangsize = C-&gt;bang_size_in_bytes();
5257   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
5258      generate_stack_overflow_check(bangsize);
5259 
5260   build_frame(framesize);
5261 
5262   if (VerifyStackAtCalls) {
5263     Unimplemented();
5264   }
5265 }
5266 
<span class="line-modified">5267 int MacroAssembler::store_inline_type_fields_to_buf(ciInlineKlass* vk, bool from_interpreter) {</span>
5268   // An inline type might be returned. If fields are in registers we
5269   // need to allocate an inline type instance and initialize it with
5270   // the value of the fields.
5271   Label skip;
<span class="line-modified">5272   // We only need a new buffered inline type if a new one is not returned</span>
5273   cmp(r0, (u1) 1);
5274   br(Assembler::EQ, skip);
5275   int call_offset = -1;
5276 
5277   Label slow_case;
5278 
<span class="line-modified">5279   // Try to allocate a new buffered inline type (from the heap)</span>
5280   if (UseTLAB) {
5281 
5282     if (vk != NULL) {
5283       // Called from C1, where the return type is statically known.
5284       mov(r1, (intptr_t)vk-&gt;get_InlineKlass());
5285       jint lh = vk-&gt;layout_helper();
5286       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);
5287       mov(r14, lh);
5288     } else {
5289        // Call from interpreter. R0 contains ((the InlineKlass* of the return type) | 0x01)
5290        andr(r1, r0, -2);
5291        // get obj size
5292        ldrw(r14, Address(rscratch1 /*klass*/, Klass::layout_helper_offset()));
5293     }
5294 
5295      ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));
5296 
5297      // check whether we have space in TLAB,
5298      // rscratch1 contains pointer to just allocated obj
5299       lea(r14, Address(r13, r14));
</pre>
<hr />
<pre>
5307       str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));
5308 
5309       // Set new class always locked
5310       mov(rscratch1, (uint64_t) markWord::always_locked_prototype().value());
5311       str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));
5312 
5313       store_klass_gap(r13, zr);  // zero klass gap for compressed oops
5314       if (vk == NULL) {
5315         // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).
5316          mov(r0, r1);
5317       }
5318 
5319       store_klass(r13, r1);  // klass
5320 
5321       if (vk != NULL) {
5322         // FIXME -- do the packing in-line to avoid the runtime call
5323         mov(r0, r13);
5324         far_call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.
5325       } else {
5326 
<span class="line-modified">5327         // We have our new buffered inline type, initialize its fields with an inline class specific handler</span>

5328         ldr(r1, Address(r0, InstanceKlass::adr_inlineklass_fixed_block_offset()));
5329         ldr(r1, Address(r1, InlineKlass::pack_handler_offset()));
5330 
5331         // Mov new class to r0 and call pack_handler
5332         mov(r0, r13);
5333         blr(r1);
5334       }
5335       b(skip);
5336   }
5337 
5338   bind(slow_case);
<span class="line-modified">5339   // We failed to allocate a new inline type, fall back to a runtime</span>
5340   // call. Some oop field may be live in some registers but we can&#39;t
5341   // tell. That runtime call will take care of preserving them
5342   // across a GC if there&#39;s one.
5343 
5344 
5345   if (from_interpreter) {
5346     super_call_VM_leaf(StubRoutines::store_inline_type_fields_to_buf());
5347   } else {
5348     ldr(rscratch1, RuntimeAddress(StubRoutines::store_inline_type_fields_to_buf()));
5349     blr(rscratch1);
5350     call_offset = offset();
5351   }
5352 
5353   bind(skip);
5354   return call_offset;
5355 }
5356 
5357 // Move a value between registers/stack slots and update the reg_state
5358 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {
5359   if (reg_state[to-&gt;value()] == reg_written) {
</pre>
<hr />
<pre>
5391             assert(bt == T_FLOAT, &quot;must be float&quot;);
5392             ldrs(to-&gt;as_FloatRegister(), from_addr);
5393           }
5394         } else {
5395           ldr(to-&gt;as_Register(), from_addr);
5396         }
5397       } else {
5398         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5399         ldr(rscratch1, from_addr);
5400         str(rscratch1, Address(sp, st_off));
5401       }
5402     }
5403   }
5404 
5405   // Update register states
5406   reg_state[from-&gt;value()] = reg_writable;
5407   reg_state[to-&gt;value()] = reg_written;
5408   return true;
5409 }
5410 
<span class="line-modified">5411 // Read all fields from an inline type oop and store the values in registers/stack slots</span>
<span class="line-modified">5412 bool MacroAssembler::unpack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-modified">5413                                           int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
5414   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5415   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5416 
5417 
5418   int vt = 1;
5419   bool done = true;
5420   bool mark_done = true;
5421   do {
5422     sig_index--;
5423     BasicType bt = sig-&gt;at(sig_index)._bt;
5424     if (bt == T_INLINE_TYPE) {
5425       vt--;
5426     } else if (bt == T_VOID &amp;&amp;
5427                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5428                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5429       vt++;
5430     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5431       to_index--; // Ignore this
5432     } else {
5433       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5479       } else {
5480         if (bt == T_DOUBLE) {
5481           ldrd(to-&gt;as_FloatRegister(), fromAddr);
5482         } else {
5483           assert(bt == T_FLOAT, &quot;must be float&quot;);
5484           ldrs(to-&gt;as_FloatRegister(), fromAddr);
5485         }
5486      }
5487 
5488     }
5489 
5490   } while (vt != 0);
5491 
5492   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5493     // This is okay because no one else will write to that slot
5494     reg_state[from-&gt;value()] = reg_writable;
5495   }
5496   return done;
5497 }
5498 
<span class="line-modified">5499 // Pack fields back into an inline type oop</span>
<span class="line-modified">5500 bool MacroAssembler::pack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-modified">5501                                         VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-modified">5502                                         int ret_off, int extra_stack_offset) {</span>
5503   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5504   assert(to-&gt;is_valid(), &quot;must be&quot;);
5505 
5506   if (reg_state[to-&gt;value()] == reg_written) {
5507     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5508     return true; // Already written
5509   }
5510 
5511   Register val_array = r0;
5512   Register val_obj_tmp = r11;
5513   Register from_reg_tmp = r10;
5514   Register tmp1 = r14;
5515   Register tmp2 = r13;
5516   Register tmp3 = r1;
5517   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5518 
5519   if (reg_state[to-&gt;value()] == reg_readonly) {
5520     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
5521       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5522       return false; // Not yet writable
</pre>
<hr />
<pre>
5562     } else {
5563       if (from_r2-&gt;is_valid()) {
5564         strd(from_r1-&gt;as_FloatRegister(), dst);
5565       } else {
5566         strs(from_r1-&gt;as_FloatRegister(), dst);
5567       }
5568     }
5569 
5570     reg_state[from_r1-&gt;value()] = reg_writable;
5571   }
5572   sig_index = stream.sig_cc_index();
5573   from_index = stream.regs_cc_index();
5574 
5575   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5576   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5577   assert(success, &quot;to register must be writeable&quot;);
5578 
5579   return true;
5580 }
5581 
<span class="line-modified">5582 // Unpack all inline type arguments passed as oops</span>
<span class="line-modified">5583 void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {</span>
<span class="line-modified">5584   int sp_inc = unpack_inline_args_common(C, receiver_only);</span>
5585   // Emit code for verified entry and save increment for stack repair on return
5586   verified_entry(C, sp_inc);
5587 }
5588 
<span class="line-modified">5589 int MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-modified">5590                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified">5591                                         int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-modified">5592                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
5593   // Check if we need to extend the stack for packing/unpacking
5594   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;
5595   if (sp_inc &gt; 0) {
5596     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
5597     if (!is_packing) {
5598       // Save the return address, adjust the stack (make sure it is properly
5599       // 16-byte aligned) and copy the return address to the new top of the stack.
5600       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5601       // FIXME: We need not to preserve return address on aarch64
5602       pop(rscratch1);
5603       sub(sp, sp, sp_inc);
5604       push(rscratch1);
5605     }
5606   } else {
5607     // The scalarized calling convention needs less stack space than the unscalarized one.
5608     // No need to extend the stack, the caller will take care of these adjustments.
5609     sp_inc = 0;
5610   }
5611 
5612   int ret_off; // make sure we don&#39;t overwrite the return address
5613   if (is_packing) {
<span class="line-modified">5614     // For C1 code, the VIEP doesn&#39;t have reserved slots, so we store the returned address at</span>
5615     // rsp[0] during shuffling.
5616     ret_off = 0;
5617   } else {
5618     // C2 code ensures that sp_inc is a reserved slot.
5619     ret_off = sp_inc;
5620   }
5621 
<span class="line-modified">5622   return shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-modified">5623                                     sig_bt, sig_cc,</span>
<span class="line-modified">5624                                     args_passed, args_on_stack, regs,</span>
<span class="line-modified">5625                                     args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified">5626                                     sp_inc, ret_off);</span>
5627 }
5628 
5629 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5630   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();
5631 }
5632 
5633 void MacroAssembler::cache_wb(Address line) {
5634   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5635   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5636   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5637   // would like to assert this
5638   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5639   if (VM_Version::supports_dcpop()) {
5640     // writeback using clear virtual address to point of persistence
5641     dc(Assembler::CVAP, line.base());
5642   } else {
5643     // no need to generate anything as Unsafe.writebackMemory should
5644     // never invoke this stub
5645   }
5646 }
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>