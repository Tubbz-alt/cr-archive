diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -5347,11 +5347,11 @@
   return true;
 }
 
 // Read all fields from an inline type oop and store the values in registers/stack slots
 bool MacroAssembler::unpack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, VMReg from, VMRegPair* regs_to,
-                                         int& to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {
+                                          int& to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {
   Register fromReg = from->is_reg() ? from->as_Register() : noreg;
   assert(sig->at(sig_index)._bt == T_VOID, "should be at end delimiter");
 
   int vt = 1;
   bool done = true;
@@ -5429,12 +5429,12 @@
   return done;
 }
 
 // Pack fields back into an inline type oop
 bool MacroAssembler::pack_inline_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,
-                                       VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],
-                                       int ret_off, int extra_stack_offset) {
+                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],
+                                        int ret_off, int extra_stack_offset) {
   assert(sig->at(sig_index)._bt == T_INLINE_TYPE, "should be at end delimiter");
   assert(to->is_valid(), "must be");
 
   if (reg_state[to->value()] == reg_written) {
     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
@@ -5514,13 +5514,13 @@
   // Emit code for verified entry and save increment for stack repair on return
   verified_entry(C, sp_inc);
 }
 
 void MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,
-                                        BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,
-                                        int args_passed, int args_on_stack, VMRegPair* regs,
-                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {
+                                         BasicType* sig_bt, const GrowableArray<SigEntry>* sig_cc,
+                                         int args_passed, int args_on_stack, VMRegPair* regs,
+                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {
   // Check if we need to extend the stack for packing/unpacking
   if (sp_inc > 0 && !is_packing) {
     // Save the return address, adjust the stack (make sure it is properly
     // 16-byte aligned) and copy the return address to the new top of the stack.
     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
@@ -5538,14 +5538,14 @@
     // C2 code ensures that sp_inc is a reserved slot.
     ret_off = sp_inc;
   }
 
   shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,
-                            sig_bt, sig_cc,
-                            args_passed, args_on_stack, regs,
-                            args_passed_to, args_on_stack_to, regs_to,
-                            sp_inc, ret_off);
+                             sig_bt, sig_cc,
+                             args_passed, args_on_stack, regs,
+                             args_passed_to, args_on_stack_to, regs_to,
+                             sp_inc, ret_off);
 }
 
 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
   return reg->is_XMMRegister() ? xmm8->as_VMReg() : r14->as_VMReg();
 }
