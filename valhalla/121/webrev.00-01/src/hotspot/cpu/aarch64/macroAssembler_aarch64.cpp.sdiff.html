<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_MacroAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
5393           }
5394         } else {
5395           ldr(to-&gt;as_Register(), from_addr);
5396         }
5397       } else {
5398         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5399         ldr(rscratch1, from_addr);
5400         str(rscratch1, Address(sp, st_off));
5401       }
5402     }
5403   }
5404 
5405   // Update register states
5406   reg_state[from-&gt;value()] = reg_writable;
5407   reg_state[to-&gt;value()] = reg_written;
5408   return true;
5409 }
5410 
5411 // Read all fields from an inline type oop and store the values in registers/stack slots
5412 bool MacroAssembler::unpack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,
<span class="line-modified">5413                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
5414   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5415   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5416 
5417 
5418   int vt = 1;
5419   bool done = true;
5420   bool mark_done = true;
5421   do {
5422     sig_index--;
5423     BasicType bt = sig-&gt;at(sig_index)._bt;
5424     if (bt == T_INLINE_TYPE) {
5425       vt--;
5426     } else if (bt == T_VOID &amp;&amp;
5427                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5428                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5429       vt++;
5430     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5431       to_index--; // Ignore this
5432     } else {
5433       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5481           ldrd(to-&gt;as_FloatRegister(), fromAddr);
5482         } else {
5483           assert(bt == T_FLOAT, &quot;must be float&quot;);
5484           ldrs(to-&gt;as_FloatRegister(), fromAddr);
5485         }
5486      }
5487 
5488     }
5489 
5490   } while (vt != 0);
5491 
5492   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5493     // This is okay because no one else will write to that slot
5494     reg_state[from-&gt;value()] = reg_writable;
5495   }
5496   return done;
5497 }
5498 
5499 // Pack fields back into an inline type oop
5500 bool MacroAssembler::pack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,
<span class="line-modified">5501                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-modified">5502                                        int ret_off, int extra_stack_offset) {</span>
5503   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5504   assert(to-&gt;is_valid(), &quot;must be&quot;);
5505 
5506   if (reg_state[to-&gt;value()] == reg_written) {
5507     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5508     return true; // Already written
5509   }
5510 
5511   Register val_array = r0;
5512   Register val_obj_tmp = r11;
5513   Register from_reg_tmp = r10;
5514   Register tmp1 = r14;
5515   Register tmp2 = r13;
5516   Register tmp3 = r1;
5517   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5518 
5519   if (reg_state[to-&gt;value()] == reg_readonly) {
5520     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
5521       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5522       return false; // Not yet writable
</pre>
<hr />
<pre>
5570     reg_state[from_r1-&gt;value()] = reg_writable;
5571   }
5572   sig_index = stream.sig_cc_index();
5573   from_index = stream.regs_cc_index();
5574 
5575   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5576   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5577   assert(success, &quot;to register must be writeable&quot;);
5578 
5579   return true;
5580 }
5581 
5582 // Unpack all inline type arguments passed as oops
5583 void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {
5584   int sp_inc = unpack_inline_args_common(C, receiver_only);
5585   // Emit code for verified entry and save increment for stack repair on return
5586   verified_entry(C, sp_inc);
5587 }
5588 
5589 int MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,
<span class="line-modified">5590                                        BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified">5591                                        int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-modified">5592                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
5593   // Check if we need to extend the stack for packing/unpacking
5594   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;
5595   if (sp_inc &gt; 0) {
5596     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
5597     if (!is_packing) {
5598       // Save the return address, adjust the stack (make sure it is properly
5599       // 16-byte aligned) and copy the return address to the new top of the stack.
5600       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5601       // FIXME: We need not to preserve return address on aarch64
5602       pop(rscratch1);
5603       sub(sp, sp, sp_inc);
5604       push(rscratch1);
5605     }
5606   } else {
5607     // The scalarized calling convention needs less stack space than the unscalarized one.
5608     // No need to extend the stack, the caller will take care of these adjustments.
5609     sp_inc = 0;
5610   }
5611 
5612   int ret_off; // make sure we don&#39;t overwrite the return address
5613   if (is_packing) {
5614     // For C1 code, the VIEP doesn&#39;t have reserved slots, so we store the returned address at
5615     // rsp[0] during shuffling.
5616     ret_off = 0;
5617   } else {
5618     // C2 code ensures that sp_inc is a reserved slot.
5619     ret_off = sp_inc;
5620   }
5621 
5622   return shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,
<span class="line-modified">5623                                    sig_bt, sig_cc,</span>
<span class="line-modified">5624                                    args_passed, args_on_stack, regs,</span>
<span class="line-modified">5625                                    args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified">5626                                    sp_inc, ret_off);</span>
5627 }
5628 
5629 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5630   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();
5631 }
5632 
5633 void MacroAssembler::cache_wb(Address line) {
5634   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5635   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5636   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5637   // would like to assert this
5638   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5639   if (VM_Version::supports_dcpop()) {
5640     // writeback using clear virtual address to point of persistence
5641     dc(Assembler::CVAP, line.base());
5642   } else {
5643     // no need to generate anything as Unsafe.writebackMemory should
5644     // never invoke this stub
5645   }
5646 }
</pre>
</td>
<td>
<hr />
<pre>
5393           }
5394         } else {
5395           ldr(to-&gt;as_Register(), from_addr);
5396         }
5397       } else {
5398         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;
5399         ldr(rscratch1, from_addr);
5400         str(rscratch1, Address(sp, st_off));
5401       }
5402     }
5403   }
5404 
5405   // Update register states
5406   reg_state[from-&gt;value()] = reg_writable;
5407   reg_state[to-&gt;value()] = reg_written;
5408   return true;
5409 }
5410 
5411 // Read all fields from an inline type oop and store the values in registers/stack slots
5412 bool MacroAssembler::unpack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,
<span class="line-modified">5413                                           int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
5414   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;
5415   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);
5416 
5417 
5418   int vt = 1;
5419   bool done = true;
5420   bool mark_done = true;
5421   do {
5422     sig_index--;
5423     BasicType bt = sig-&gt;at(sig_index)._bt;
5424     if (bt == T_INLINE_TYPE) {
5425       vt--;
5426     } else if (bt == T_VOID &amp;&amp;
5427                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;
5428                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {
5429       vt++;
5430     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {
5431       to_index--; // Ignore this
5432     } else {
5433       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);
</pre>
<hr />
<pre>
5481           ldrd(to-&gt;as_FloatRegister(), fromAddr);
5482         } else {
5483           assert(bt == T_FLOAT, &quot;must be float&quot;);
5484           ldrs(to-&gt;as_FloatRegister(), fromAddr);
5485         }
5486      }
5487 
5488     }
5489 
5490   } while (vt != 0);
5491 
5492   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {
5493     // This is okay because no one else will write to that slot
5494     reg_state[from-&gt;value()] = reg_writable;
5495   }
5496   return done;
5497 }
5498 
5499 // Pack fields back into an inline type oop
5500 bool MacroAssembler::pack_inline_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,
<span class="line-modified">5501                                         VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-modified">5502                                         int ret_off, int extra_stack_offset) {</span>
5503   assert(sig-&gt;at(sig_index)._bt == T_INLINE_TYPE, &quot;should be at end delimiter&quot;);
5504   assert(to-&gt;is_valid(), &quot;must be&quot;);
5505 
5506   if (reg_state[to-&gt;value()] == reg_written) {
5507     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5508     return true; // Already written
5509   }
5510 
5511   Register val_array = r0;
5512   Register val_obj_tmp = r11;
5513   Register from_reg_tmp = r10;
5514   Register tmp1 = r14;
5515   Register tmp2 = r13;
5516   Register tmp3 = r1;
5517   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();
5518 
5519   if (reg_state[to-&gt;value()] == reg_readonly) {
5520     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {
5521       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
5522       return false; // Not yet writable
</pre>
<hr />
<pre>
5570     reg_state[from_r1-&gt;value()] = reg_writable;
5571   }
5572   sig_index = stream.sig_cc_index();
5573   from_index = stream.regs_cc_index();
5574 
5575   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
5576   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
5577   assert(success, &quot;to register must be writeable&quot;);
5578 
5579   return true;
5580 }
5581 
5582 // Unpack all inline type arguments passed as oops
5583 void MacroAssembler::unpack_inline_args(Compile* C, bool receiver_only) {
5584   int sp_inc = unpack_inline_args_common(C, receiver_only);
5585   // Emit code for verified entry and save increment for stack repair on return
5586   verified_entry(C, sp_inc);
5587 }
5588 
5589 int MacroAssembler::shuffle_inline_args(bool is_packing, bool receiver_only, int extra_stack_offset,
<span class="line-modified">5590                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified">5591                                         int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-modified">5592                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
5593   // Check if we need to extend the stack for packing/unpacking
5594   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;
5595   if (sp_inc &gt; 0) {
5596     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
5597     if (!is_packing) {
5598       // Save the return address, adjust the stack (make sure it is properly
5599       // 16-byte aligned) and copy the return address to the new top of the stack.
5600       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).
5601       // FIXME: We need not to preserve return address on aarch64
5602       pop(rscratch1);
5603       sub(sp, sp, sp_inc);
5604       push(rscratch1);
5605     }
5606   } else {
5607     // The scalarized calling convention needs less stack space than the unscalarized one.
5608     // No need to extend the stack, the caller will take care of these adjustments.
5609     sp_inc = 0;
5610   }
5611 
5612   int ret_off; // make sure we don&#39;t overwrite the return address
5613   if (is_packing) {
5614     // For C1 code, the VIEP doesn&#39;t have reserved slots, so we store the returned address at
5615     // rsp[0] during shuffling.
5616     ret_off = 0;
5617   } else {
5618     // C2 code ensures that sp_inc is a reserved slot.
5619     ret_off = sp_inc;
5620   }
5621 
5622   return shuffle_inline_args_common(is_packing, receiver_only, extra_stack_offset,
<span class="line-modified">5623                                     sig_bt, sig_cc,</span>
<span class="line-modified">5624                                     args_passed, args_on_stack, regs,</span>
<span class="line-modified">5625                                     args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified">5626                                     sp_inc, ret_off);</span>
5627 }
5628 
5629 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
5630   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();
5631 }
5632 
5633 void MacroAssembler::cache_wb(Address line) {
5634   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5635   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5636   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5637   // would like to assert this
5638   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5639   if (VM_Version::supports_dcpop()) {
5640     // writeback using clear virtual address to point of persistence
5641     dc(Assembler::CVAP, line.base());
5642   } else {
5643     // no need to generate anything as Unsafe.writebackMemory should
5644     // never invoke this stub
5645   }
5646 }
</pre>
</td>
</tr>
</table>
<center><a href="c1_MacroAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>