<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
301   // explicit NULL check not needed since load from [klass_offset] causes a trap
302   // check against inline cache
303   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
304   int start_offset = offset();
305 
306   if (UseCompressedClassPointers) {
307     load_klass(rscratch1, receiver);
308     cmpptr(rscratch1, iCache);
309   } else {
310     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
311   }
312   // if icache check fails, then jump to runtime routine
313   // Note: RECEIVER must still contain the receiver!
314   jump_cc(Assembler::notEqual,
315           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
316   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
317   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
318 }
319 
320 
<span class="line-modified">321 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, bool needs_stack_repair, Label* verified_value_entry_label) {</span>
<span class="line-modified">322   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>






323   // Make sure there is enough stack space for this method&#39;s activation.
324   // Note that we do this before doing an enter(). This matches the
325   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
326   // the SharedRuntime stack overflow handling to be consistent
327   // between the two compilers.

328   generate_stack_overflow_check(bang_size_in_bytes);
<span class="line-removed">329 </span>
<span class="line-removed">330   if (!needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {</span>
<span class="line-removed">331     bind(*verified_value_entry_label);</span>
<span class="line-removed">332   }</span>
333   push(rbp);
334   if (PreserveFramePointer) {
335     mov(rbp, rsp);
336   }
337 #if !defined(_LP64) &amp;&amp; defined(TIERED)
338   if (UseSSE &lt; 2 ) {
339     // c2 leaves fpu stack dirty. Clean it on entry
340     empty_FPU_stack();
341   }
342 #endif // !_LP64 &amp;&amp; TIERED
343   decrement(rsp, frame_size_in_bytes); // does not emit code for frame_size == 0
344   if (needs_stack_repair) {
345     int real_frame_size =  frame_size_in_bytes
346            + wordSize     // skip over pushed rbp
347            + wordSize;    // skip over RA pushed by caller
348     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
349     if (verified_value_entry_label != NULL) {
350       bind(*verified_value_entry_label);
351     }
352   }
353 
354   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
355   bs-&gt;nmethod_entry_barrier(this);
356 }
357 
358 
359 void C1_MacroAssembler::remove_frame(int frame_size_in_bytes, bool needs_stack_repair) {
360   if (!needs_stack_repair) {
361     increment(rsp, frame_size_in_bytes);  // Does not emit code for frame_size == 0
362     pop(rbp);
363   } else {
364     movq(r13, Address(rsp, frame_size_in_bytes + wordSize)); // return address
365     movq(rbp, Address(rsp, frame_size_in_bytes));
<span class="line-modified">366     addq(rsp, Address(rsp, frame_size_in_bytes - wordSize)); // now we are back to caller frame, without the outgoing returned address</span>
<span class="line-modified">367     push(r13);                  // restore the returned address, as pushed by caller</span>
368   }
369 }
370 
371 
<span class="line-modified">372 void C1_MacroAssembler::verified_value_entry() {</span>
373   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
374     // Verified Entry first instruction should be 5 bytes long for correct
375     // patching by patch_verified_entry().
376     //
377     // C1Breakpoint and VerifyFPU have one byte first instruction.
378     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
379     // code is not generated (see build_frame() above).
380     // For all these cases generate long instruction first.
381     fat_nop();
382   }
383   if (C1Breakpoint)int3();
384   // build frame
385   IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )
386 }
387 
<span class="line-modified">388 int C1_MacroAssembler::scalarized_entry(const CompiledEntrySignature *ces, int frame_size_in_bytes, int bang_size_in_bytes, Label&amp; verified_value_entry_label, bool is_value_ro_entry) {</span>
<span class="line-removed">389   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {</span>
<span class="line-removed">390     // Verified Entry first instruction should be 5 bytes long for correct</span>
<span class="line-removed">391     // patching by patch_verified_entry().</span>
<span class="line-removed">392     //</span>
<span class="line-removed">393     // C1Breakpoint and VerifyFPU have one byte first instruction.</span>
<span class="line-removed">394     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging</span>
<span class="line-removed">395     // code is not generated (see build_frame() above).</span>
<span class="line-removed">396     // For all these cases generate long instruction first.</span>
<span class="line-removed">397     fat_nop();</span>
<span class="line-removed">398   }</span>
<span class="line-removed">399   if (C1Breakpoint)int3();</span>
<span class="line-removed">400   IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )</span>
<span class="line-removed">401 </span>
402   assert(ValueTypePassFieldsAsArgs, &quot;sanity&quot;);
<span class="line-modified">403   GrowableArray&lt;SigEntry&gt;* sig   = &amp;ces-&gt;sig();</span>




404   GrowableArray&lt;SigEntry&gt;* sig_cc = is_value_ro_entry ? &amp;ces-&gt;sig_cc_ro() : &amp;ces-&gt;sig_cc();
405   VMRegPair* regs      = ces-&gt;regs();
406   VMRegPair* regs_cc   = is_value_ro_entry ? ces-&gt;regs_cc_ro() : ces-&gt;regs_cc();
407   int args_on_stack    = ces-&gt;args_on_stack();
408   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();
409 
410   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);
411   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
412   int args_passed = sig-&gt;length();
413   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);
<span class="line-removed">414 </span>
415   int extra_stack_offset = wordSize; // tos is return address.
416 
<span class="line-removed">417   // Create a temp frame so we can call into runtime. It must be properly set up to accommodate GC.</span>
418   int sp_inc = (args_on_stack - args_on_stack_cc) * VMRegImpl::stack_slot_size;
419   if (sp_inc &gt; 0) {
420     pop(r13);
421     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
422     subptr(rsp, sp_inc);
423     push(r13);
424   } else {
425     sp_inc = 0;
426   }


427   push(rbp);
428   if (PreserveFramePointer) {
429     mov(rbp, rsp);
430   }
431   subptr(rsp, frame_size_in_bytes);
432   if (sp_inc &gt; 0) {
433     int real_frame_size = frame_size_in_bytes +
434            + wordSize  // pushed rbp
<span class="line-modified">435            + wordSize  // returned address pushed by the stack extension code</span>
436            + sp_inc;   // stack extension
437     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
438   }
439 



440   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.
441   movptr(rbx, (intptr_t)(ces-&gt;method()));
442   if (is_value_ro_entry) {
443     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));
444   } else {
445     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));
446   }
447   int rt_call_offset = offset();
448 
449   // Remove the temp frame
450   addptr(rsp, frame_size_in_bytes);
451   pop(rbp);
452 
453   int n = shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,
454                              args_passed_cc, args_on_stack_cc, regs_cc, // from
455                              args_passed, args_on_stack, regs);         // to
456   assert(sp_inc == n, &quot;must be&quot;);
457 
458   if (sp_inc != 0) {
<span class="line-modified">459     // Do the stack banging here, and skip over the stack repair code in the</span>
460     // verified_value_entry (which has a different real_frame_size).
461     assert(sp_inc &gt; 0, &quot;stack should not shrink&quot;);
<span class="line-removed">462     generate_stack_overflow_check(bang_size_in_bytes);</span>
463     push(rbp);
464     if (PreserveFramePointer) {
465       mov(rbp, rsp);
466     }
467 #if !defined(_LP64) &amp;&amp; defined(TIERED)
468     // c2 leaves fpu stack dirty. Clean it on entry
469     if (UseSSE &lt; 2 ) {
470       empty_FPU_stack();
471     }
472 #endif // TIERED
473     decrement(rsp, frame_size_in_bytes);
474   }
475 
476   jmp(verified_value_entry_label);
477   return rt_call_offset;
478 }
479 
480 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
481   // rbp, + 0: link
482   //     + 1: return address
</pre>
</td>
<td>
<hr />
<pre>
301   // explicit NULL check not needed since load from [klass_offset] causes a trap
302   // check against inline cache
303   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
304   int start_offset = offset();
305 
306   if (UseCompressedClassPointers) {
307     load_klass(rscratch1, receiver);
308     cmpptr(rscratch1, iCache);
309   } else {
310     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
311   }
312   // if icache check fails, then jump to runtime routine
313   // Note: RECEIVER must still contain the receiver!
314   jump_cc(Assembler::notEqual,
315           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
316   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
317   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
318 }
319 
320 
<span class="line-modified">321 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_value_entry_label) {</span>
<span class="line-modified">322   if (has_scalarized_args) {</span>
<span class="line-added">323     // Initialize orig_pc to detect deoptimization during buffering in the entry points</span>
<span class="line-added">324     movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);</span>
<span class="line-added">325   }</span>
<span class="line-added">326   if (!needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {</span>
<span class="line-added">327     bind(*verified_value_entry_label);</span>
<span class="line-added">328   }</span>
329   // Make sure there is enough stack space for this method&#39;s activation.
330   // Note that we do this before doing an enter(). This matches the
331   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
332   // the SharedRuntime stack overflow handling to be consistent
333   // between the two compilers.
<span class="line-added">334   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>
335   generate_stack_overflow_check(bang_size_in_bytes);




336   push(rbp);
337   if (PreserveFramePointer) {
338     mov(rbp, rsp);
339   }
340 #if !defined(_LP64) &amp;&amp; defined(TIERED)
341   if (UseSSE &lt; 2 ) {
342     // c2 leaves fpu stack dirty. Clean it on entry
343     empty_FPU_stack();
344   }
345 #endif // !_LP64 &amp;&amp; TIERED
346   decrement(rsp, frame_size_in_bytes); // does not emit code for frame_size == 0
347   if (needs_stack_repair) {
348     int real_frame_size =  frame_size_in_bytes
349            + wordSize     // skip over pushed rbp
350            + wordSize;    // skip over RA pushed by caller
351     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
352     if (verified_value_entry_label != NULL) {
353       bind(*verified_value_entry_label);
354     }
355   }
356 
357   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
358   bs-&gt;nmethod_entry_barrier(this);
359 }
360 
361 
362 void C1_MacroAssembler::remove_frame(int frame_size_in_bytes, bool needs_stack_repair) {
363   if (!needs_stack_repair) {
364     increment(rsp, frame_size_in_bytes);  // Does not emit code for frame_size == 0
365     pop(rbp);
366   } else {
367     movq(r13, Address(rsp, frame_size_in_bytes + wordSize)); // return address
368     movq(rbp, Address(rsp, frame_size_in_bytes));
<span class="line-modified">369     addq(rsp, Address(rsp, frame_size_in_bytes - wordSize)); // now we are back to caller frame, without the outgoing return address</span>
<span class="line-modified">370     push(r13); // restore the return address, as pushed by caller</span>
371   }
372 }
373 
374 
<span class="line-modified">375 void C1_MacroAssembler::verified_entry() {</span>
376   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
377     // Verified Entry first instruction should be 5 bytes long for correct
378     // patching by patch_verified_entry().
379     //
380     // C1Breakpoint and VerifyFPU have one byte first instruction.
381     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
382     // code is not generated (see build_frame() above).
383     // For all these cases generate long instruction first.
384     fat_nop();
385   }
386   if (C1Breakpoint)int3();
387   // build frame
388   IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )
389 }
390 
<span class="line-modified">391 int C1_MacroAssembler::scalarized_entry(const CompiledEntrySignature *ces, int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, Label&amp; verified_value_entry_label, bool is_value_ro_entry) {</span>













392   assert(ValueTypePassFieldsAsArgs, &quot;sanity&quot;);
<span class="line-modified">393   // Make sure there is enough stack space for this method&#39;s activation.</span>
<span class="line-added">394   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);</span>
<span class="line-added">395   generate_stack_overflow_check(bang_size_in_bytes);</span>
<span class="line-added">396 </span>
<span class="line-added">397   GrowableArray&lt;SigEntry&gt;* sig    = &amp;ces-&gt;sig();</span>
398   GrowableArray&lt;SigEntry&gt;* sig_cc = is_value_ro_entry ? &amp;ces-&gt;sig_cc_ro() : &amp;ces-&gt;sig_cc();
399   VMRegPair* regs      = ces-&gt;regs();
400   VMRegPair* regs_cc   = is_value_ro_entry ? ces-&gt;regs_cc_ro() : ces-&gt;regs_cc();
401   int args_on_stack    = ces-&gt;args_on_stack();
402   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();
403 
404   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);
405   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
406   int args_passed = sig-&gt;length();
407   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);

408   int extra_stack_offset = wordSize; // tos is return address.
409 

410   int sp_inc = (args_on_stack - args_on_stack_cc) * VMRegImpl::stack_slot_size;
411   if (sp_inc &gt; 0) {
412     pop(r13);
413     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
414     subptr(rsp, sp_inc);
415     push(r13);
416   } else {
417     sp_inc = 0;
418   }
<span class="line-added">419 </span>
<span class="line-added">420   // Create a temp frame so we can call into runtime. It must be properly set up to accommodate GC.</span>
421   push(rbp);
422   if (PreserveFramePointer) {
423     mov(rbp, rsp);
424   }
425   subptr(rsp, frame_size_in_bytes);
426   if (sp_inc &gt; 0) {
427     int real_frame_size = frame_size_in_bytes +
428            + wordSize  // pushed rbp
<span class="line-modified">429            + wordSize  // return address pushed by the stack extension code</span>
430            + sp_inc;   // stack extension
431     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
432   }
433 
<span class="line-added">434   // Initialize orig_pc to detect deoptimization during buffering in below runtime call</span>
<span class="line-added">435   movptr(Address(rsp, sp_offset_for_orig_pc), 0);</span>
<span class="line-added">436 </span>
437   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.
438   movptr(rbx, (intptr_t)(ces-&gt;method()));
439   if (is_value_ro_entry) {
440     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));
441   } else {
442     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));
443   }
444   int rt_call_offset = offset();
445 
446   // Remove the temp frame
447   addptr(rsp, frame_size_in_bytes);
448   pop(rbp);
449 
450   int n = shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,
451                              args_passed_cc, args_on_stack_cc, regs_cc, // from
452                              args_passed, args_on_stack, regs);         // to
453   assert(sp_inc == n, &quot;must be&quot;);
454 
455   if (sp_inc != 0) {
<span class="line-modified">456     // Skip over the stack banging and frame setup code in the</span>
457     // verified_value_entry (which has a different real_frame_size).
458     assert(sp_inc &gt; 0, &quot;stack should not shrink&quot;);

459     push(rbp);
460     if (PreserveFramePointer) {
461       mov(rbp, rsp);
462     }
463 #if !defined(_LP64) &amp;&amp; defined(TIERED)
464     // c2 leaves fpu stack dirty. Clean it on entry
465     if (UseSSE &lt; 2 ) {
466       empty_FPU_stack();
467     }
468 #endif // TIERED
469     decrement(rsp, frame_size_in_bytes);
470   }
471 
472   jmp(verified_value_entry_label);
473   return rt_call_offset;
474 }
475 
476 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
477   // rbp, + 0: link
478   //     + 1: return address
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>