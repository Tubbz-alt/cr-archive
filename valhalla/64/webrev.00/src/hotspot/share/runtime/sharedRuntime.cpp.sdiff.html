<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/sharedRuntime.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="safepoint.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../utilities/globalDefinitions.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/sharedRuntime.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1267   CompiledMethod* callee = callee_method-&gt;code();
1268 
1269   if (callee != NULL) {
1270     assert(callee-&gt;is_compiled(), &quot;must be nmethod for patching&quot;);
1271   }
1272 
1273   if (callee != NULL &amp;&amp; !callee-&gt;is_in_use()) {
1274     // Patch call site to C2I adapter if callee nmethod is deoptimized or unloaded.
1275     callee = NULL;
1276   }
1277   nmethodLocker nl_callee(callee);
1278 #ifdef ASSERT
1279   address dest_entry_point = callee == NULL ? 0 : callee-&gt;entry_point(); // used below
1280 #endif
1281 
1282   bool is_nmethod = caller_nm-&gt;is_nmethod();
1283   bool caller_is_c1 = caller_nm-&gt;is_compiled_by_c1();
1284 
1285   if (is_virtual) {
1286     Klass* receiver_klass = NULL;
<span class="line-modified">1287     if (ValueTypePassFieldsAsArgs &amp;&amp; !caller_is_c1 &amp;&amp; callee_method-&gt;method_holder()-&gt;is_value()) {</span>
<span class="line-modified">1288       // If the receiver is a value type that is passed as fields, no oop is available</span>
1289       receiver_klass = callee_method-&gt;method_holder();
1290     } else {
1291       assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, &quot;sanity check&quot;);
1292       receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver-&gt;klass();
1293     }
1294     bool static_bound = call_info.resolved_method()-&gt;can_be_statically_bound();
1295     CompiledIC::compute_monomorphic_entry(callee_method, receiver_klass,
1296                      is_optimized, static_bound, is_nmethod, caller_is_c1, virtual_call_info,
1297                      CHECK_false);
1298   } else {
1299     // static call
1300     CompiledStaticCall::compute_entry(callee_method, caller_nm, static_call_info);
1301   }
1302 
1303   // grab lock, check for deoptimization and potentially patch caller
1304   {
1305     CompiledICLocker ml(caller_nm);
1306 
1307     // Lock blocks for safepoint during which both nmethods can change state.
1308 
</pre>
<hr />
<pre>
2343   // TO DO:  Consider integrating this with a more global scheme for compressing signatures.
2344   // For now, 4 bits per components (plus T_VOID gaps after double/long) is not excessive.
2345 
2346   union {
2347     int  _compact[_compact_int_count];
2348     int* _fingerprint;
2349   } _value;
2350   int _length; // A negative length indicates the fingerprint is in the compact form,
2351                // Otherwise _value._fingerprint is the array.
2352 
2353   // Remap BasicTypes that are handled equivalently by the adapters.
2354   // These are correct for the current system but someday it might be
2355   // necessary to make this mapping platform dependent.
2356   static int adapter_encoding(BasicType in, bool is_valuetype) {
2357     switch (in) {
2358       case T_BOOLEAN:
2359       case T_BYTE:
2360       case T_SHORT:
2361       case T_CHAR: {
2362         if (is_valuetype) {
<span class="line-modified">2363           // Do not widen value type field types</span>
<span class="line-modified">2364           assert(ValueTypePassFieldsAsArgs, &quot;must be enabled&quot;);</span>
2365           return in;
2366         } else {
2367           // They are all promoted to T_INT in the calling convention
2368           return T_INT;
2369         }
2370       }
2371 
2372       case T_VALUETYPE: {
<span class="line-modified">2373         // If value types are passed as fields, return &#39;in&#39; to differentiate</span>
2374         // between a T_VALUETYPE and a T_OBJECT in the signature.
<span class="line-modified">2375         return ValueTypePassFieldsAsArgs ? in : adapter_encoding(T_OBJECT, false);</span>
2376       }
2377 
2378       case T_OBJECT:
2379       case T_ARRAY:
2380         // In other words, we assume that any register good enough for
2381         // an int or long is good enough for a managed pointer.
2382 #ifdef _LP64
2383         return T_LONG;
2384 #else
2385         return T_INT;
2386 #endif
2387 
2388       case T_INT:
2389       case T_LONG:
2390       case T_FLOAT:
2391       case T_DOUBLE:
2392       case T_VOID:
2393         return in;
2394 
2395       default:
</pre>
<hr />
<pre>
2411       // Storing the signature encoded as signed chars hits about 98%
2412       // of the time.
2413       _length = -len;
2414       ptr = _value._compact;
2415     } else {
2416       _length = len;
2417       _value._fingerprint = NEW_C_HEAP_ARRAY(int, _length, mtCode);
2418       ptr = _value._fingerprint;
2419     }
2420 
2421     // Now pack the BasicTypes with 8 per int
2422     int sig_index = 0;
2423     BasicType prev_sbt = T_ILLEGAL;
2424     int vt_count = 0;
2425     for (int index = 0; index &lt; len; index++) {
2426       int value = 0;
2427       for (int byte = 0; byte &lt; _basic_types_per_int; byte++) {
2428         int bt = 0;
2429         if (sig_index &lt; total_args_passed) {
2430           BasicType sbt = sig-&gt;at(sig_index++)._bt;
<span class="line-modified">2431           if (ValueTypePassFieldsAsArgs &amp;&amp; sbt == T_VALUETYPE) {</span>
<span class="line-modified">2432             // Found start of value type in signature</span>
2433             vt_count++;
2434             if (sig_index == 1 &amp;&amp; has_ro_adapter) {
2435               // With a ro_adapter, replace receiver value type delimiter by T_VOID to prevent matching
2436               // with other adapters that have the same value type as first argument and no receiver.
2437               sbt = T_VOID;
2438             }
<span class="line-modified">2439           } else if (ValueTypePassFieldsAsArgs &amp;&amp; sbt == T_VOID &amp;&amp;</span>
2440                      prev_sbt != T_LONG &amp;&amp; prev_sbt != T_DOUBLE) {
<span class="line-modified">2441             // Found end of value type in signature</span>
2442             vt_count--;
2443             assert(vt_count &gt;= 0, &quot;invalid vt_count&quot;);
2444           }
2445           bt = adapter_encoding(sbt, vt_count &gt; 0);
2446           prev_sbt = sbt;
2447         }
2448         assert((bt &amp; _basic_type_mask) == bt, &quot;must fit in 4 bits&quot;);
2449         value = (value &lt;&lt; _basic_type_bits) | bt;
2450       }
2451       ptr[index] = value;
2452     }
2453     assert(vt_count == 0, &quot;invalid vt_count&quot;);
2454   }
2455 
2456   ~AdapterFingerPrint() {
2457     if (_length &gt; 0) {
2458       FREE_C_HEAP_ARRAY(int, _value._fingerprint);
2459     }
2460   }
2461 
</pre>
<hr />
<pre>
2831 
2832 void CompiledEntrySignature::compute_calling_conventions() {
2833   // Get the (non-scalarized) signature and check for value type arguments
2834   if (!_method-&gt;is_static()) {
2835     if (_method-&gt;method_holder()-&gt;is_value() &amp;&amp; ValueKlass::cast(_method-&gt;method_holder())-&gt;is_scalarizable()) {
2836       _has_value_recv = true;
2837       _num_value_args++;
2838     }
2839     SigEntry::add_entry(_sig, T_OBJECT);
2840   }
2841   for (SignatureStream ss(_method-&gt;signature()); !ss.at_return_type(); ss.next()) {
2842     BasicType bt = ss.type();
2843     if (bt == T_VALUETYPE) {
2844       if (ss.as_value_klass(_method-&gt;method_holder())-&gt;is_scalarizable()) {
2845         _num_value_args++;
2846       }
2847       bt = T_OBJECT;
2848     }
2849     SigEntry::add_entry(_sig, bt);
2850   }
<span class="line-modified">2851   if (_method-&gt;is_abstract() &amp;&amp; !(ValueTypePassFieldsAsArgs &amp;&amp; has_value_arg())) {</span>
2852     return;
2853   }
2854 
2855   // Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage
2856   _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig-&gt;length());
2857   _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);
2858 
2859   // Now compute the scalarized calling convention if there are value types in the signature
2860   _sig_cc = _sig;
2861   _sig_cc_ro = _sig;
2862   _regs_cc = _regs;
2863   _regs_cc_ro = _regs;
2864   _args_on_stack_cc = _args_on_stack;
2865   _args_on_stack_cc_ro = _args_on_stack;
2866 
<span class="line-modified">2867   if (ValueTypePassFieldsAsArgs &amp;&amp; has_value_arg() &amp;&amp; !_method-&gt;is_native()) {</span>
2868     _args_on_stack_cc = compute_scalarized_cc(_sig_cc, _regs_cc, /* scalar_receiver = */ true);
2869 
2870     _sig_cc_ro = _sig_cc;
2871     _regs_cc_ro = _regs_cc;
2872     _args_on_stack_cc_ro = _args_on_stack_cc;
2873     if (_has_value_recv || _args_on_stack_cc &gt; _args_on_stack) {
2874       // For interface calls, we need another entry point / adapter to unpack the receiver
2875       _args_on_stack_cc_ro = compute_scalarized_cc(_sig_cc_ro, _regs_cc_ro, /* scalar_receiver = */ false);
2876     }
2877 
2878     // Compute the stack extension that is required to convert between the calling conventions.
2879     // The stack slots at these offsets are occupied by the return address with the unscalarized
2880     // calling convention. Don&#39;t use them for arguments with the scalarized calling convention.
2881     int ret_off    = _args_on_stack_cc - _args_on_stack;
2882     int ret_off_ro = _args_on_stack_cc - _args_on_stack_cc_ro;
2883     assert(ret_off_ro &lt;= 0 || ret_off &gt; 0, &quot;receiver unpacking requires more stack space than expected&quot;);
2884 
2885     if (ret_off &gt; 0) {
2886       // Make sure the stack of the scalarized calling convention with the reserved
2887       // entries (2 slots each) remains 16-byte (4 slots) aligned after stack extension.
</pre>
<hr />
<pre>
3562 }
3563 
3564 void SharedRuntime::on_slowpath_allocation_exit(JavaThread* thread) {
3565   // After any safepoint, just before going back to compiled code,
3566   // we inform the GC that we will be doing initializing writes to
3567   // this object in the future without emitting card-marks, so
3568   // GC may take any compensating steps.
3569 
3570   oop new_obj = thread-&gt;vm_result();
3571   if (new_obj == NULL) return;
3572 
3573   BarrierSet *bs = BarrierSet::barrier_set();
3574   bs-&gt;on_slowpath_allocation_exit(thread, new_obj);
3575 }
3576 
3577 // We are at a compiled code to interpreter call. We need backing
3578 // buffers for all value type arguments. Allocate an object array to
3579 // hold them (convenient because once we&#39;re done with it we don&#39;t have
3580 // to worry about freeing it).
3581 oop SharedRuntime::allocate_value_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
<span class="line-modified">3582   assert(ValueTypePassFieldsAsArgs, &quot;no reason to call this&quot;);</span>
3583   ResourceMark rm;
3584 
3585   int nb_slots = 0;
3586   InstanceKlass* holder = callee-&gt;method_holder();
3587   allocate_receiver &amp;= !callee-&gt;is_static() &amp;&amp; holder-&gt;is_value();
3588   if (allocate_receiver) {
3589     nb_slots++;
3590   }
3591   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3592     if (ss.type() == T_VALUETYPE) {
3593       nb_slots++;
3594     }
3595   }
3596   objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);
3597   objArrayHandle array(THREAD, array_oop);
3598   int i = 0;
3599   if (allocate_receiver) {
3600     ValueKlass* vk = ValueKlass::cast(holder);
3601     oop res = vk-&gt;allocate_instance(CHECK_NULL);
3602     array-&gt;obj_at_put(i, res);
</pre>
<hr />
<pre>
3608       oop res = vk-&gt;allocate_instance(CHECK_NULL);
3609       array-&gt;obj_at_put(i, res);
3610       i++;
3611     }
3612   }
3613   return array();
3614 }
3615 
3616 JRT_ENTRY(void, SharedRuntime::allocate_value_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
3617   methodHandle callee(thread, callee_method);
3618   oop array = SharedRuntime::allocate_value_types_impl(thread, callee, allocate_receiver, CHECK);
3619   thread-&gt;set_vm_result(array);
3620   thread-&gt;set_vm_result_2(callee()); // TODO: required to keep callee live?
3621 JRT_END
3622 
3623 // TODO remove this once the AARCH64 dependency is gone
3624 // Iterate over the array of heap allocated value types and apply the GC post barrier to all reference fields.
3625 // This is called from the C2I adapter after value type arguments are heap allocated and initialized.
3626 JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))
3627 {
<span class="line-modified">3628   assert(ValueTypePassFieldsAsArgs, &quot;no reason to call this&quot;);</span>
3629   assert(oopDesc::is_oop(array), &quot;should be oop&quot;);
3630   for (int i = 0; i &lt; array-&gt;length(); ++i) {
3631     instanceOop valueOop = (instanceOop)array-&gt;obj_at(i);
3632     ValueKlass* vk = ValueKlass::cast(valueOop-&gt;klass());
3633     if (vk-&gt;contains_oops()) {
3634       const address dst_oop_addr = ((address) (void*) valueOop);
3635       OopMapBlock* map = vk-&gt;start_of_nonstatic_oop_maps();
3636       OopMapBlock* const end = map + vk-&gt;nonstatic_oop_map_count();
3637       while (map != end) {
3638         address doop_address = dst_oop_addr + map-&gt;offset();
3639         barrier_set_cast&lt;ModRefBarrierSet&gt;(BarrierSet::barrier_set())-&gt;
3640           write_ref_array((HeapWord*) doop_address, map-&gt;count());
3641         map++;
3642       }
3643     }
3644   }
3645 }
3646 JRT_END
3647 
3648 // We&#39;re returning from an interpreted method: load each field into a
</pre>
</td>
<td>
<hr />
<pre>
1267   CompiledMethod* callee = callee_method-&gt;code();
1268 
1269   if (callee != NULL) {
1270     assert(callee-&gt;is_compiled(), &quot;must be nmethod for patching&quot;);
1271   }
1272 
1273   if (callee != NULL &amp;&amp; !callee-&gt;is_in_use()) {
1274     // Patch call site to C2I adapter if callee nmethod is deoptimized or unloaded.
1275     callee = NULL;
1276   }
1277   nmethodLocker nl_callee(callee);
1278 #ifdef ASSERT
1279   address dest_entry_point = callee == NULL ? 0 : callee-&gt;entry_point(); // used below
1280 #endif
1281 
1282   bool is_nmethod = caller_nm-&gt;is_nmethod();
1283   bool caller_is_c1 = caller_nm-&gt;is_compiled_by_c1();
1284 
1285   if (is_virtual) {
1286     Klass* receiver_klass = NULL;
<span class="line-modified">1287     if (InlineTypePassFieldsAsArgs &amp;&amp; !caller_is_c1 &amp;&amp; callee_method-&gt;method_holder()-&gt;is_value()) {</span>
<span class="line-modified">1288       // If the receiver is an inline type that is passed as fields, no oop is available</span>
1289       receiver_klass = callee_method-&gt;method_holder();
1290     } else {
1291       assert(receiver.not_null() || invoke_code == Bytecodes::_invokehandle, &quot;sanity check&quot;);
1292       receiver_klass = invoke_code == Bytecodes::_invokehandle ? NULL : receiver-&gt;klass();
1293     }
1294     bool static_bound = call_info.resolved_method()-&gt;can_be_statically_bound();
1295     CompiledIC::compute_monomorphic_entry(callee_method, receiver_klass,
1296                      is_optimized, static_bound, is_nmethod, caller_is_c1, virtual_call_info,
1297                      CHECK_false);
1298   } else {
1299     // static call
1300     CompiledStaticCall::compute_entry(callee_method, caller_nm, static_call_info);
1301   }
1302 
1303   // grab lock, check for deoptimization and potentially patch caller
1304   {
1305     CompiledICLocker ml(caller_nm);
1306 
1307     // Lock blocks for safepoint during which both nmethods can change state.
1308 
</pre>
<hr />
<pre>
2343   // TO DO:  Consider integrating this with a more global scheme for compressing signatures.
2344   // For now, 4 bits per components (plus T_VOID gaps after double/long) is not excessive.
2345 
2346   union {
2347     int  _compact[_compact_int_count];
2348     int* _fingerprint;
2349   } _value;
2350   int _length; // A negative length indicates the fingerprint is in the compact form,
2351                // Otherwise _value._fingerprint is the array.
2352 
2353   // Remap BasicTypes that are handled equivalently by the adapters.
2354   // These are correct for the current system but someday it might be
2355   // necessary to make this mapping platform dependent.
2356   static int adapter_encoding(BasicType in, bool is_valuetype) {
2357     switch (in) {
2358       case T_BOOLEAN:
2359       case T_BYTE:
2360       case T_SHORT:
2361       case T_CHAR: {
2362         if (is_valuetype) {
<span class="line-modified">2363           // Do not widen inline type field types</span>
<span class="line-modified">2364           assert(InlineTypePassFieldsAsArgs, &quot;must be enabled&quot;);</span>
2365           return in;
2366         } else {
2367           // They are all promoted to T_INT in the calling convention
2368           return T_INT;
2369         }
2370       }
2371 
2372       case T_VALUETYPE: {
<span class="line-modified">2373         // If inline types are passed as fields, return &#39;in&#39; to differentiate</span>
2374         // between a T_VALUETYPE and a T_OBJECT in the signature.
<span class="line-modified">2375         return InlineTypePassFieldsAsArgs ? in : adapter_encoding(T_OBJECT, false);</span>
2376       }
2377 
2378       case T_OBJECT:
2379       case T_ARRAY:
2380         // In other words, we assume that any register good enough for
2381         // an int or long is good enough for a managed pointer.
2382 #ifdef _LP64
2383         return T_LONG;
2384 #else
2385         return T_INT;
2386 #endif
2387 
2388       case T_INT:
2389       case T_LONG:
2390       case T_FLOAT:
2391       case T_DOUBLE:
2392       case T_VOID:
2393         return in;
2394 
2395       default:
</pre>
<hr />
<pre>
2411       // Storing the signature encoded as signed chars hits about 98%
2412       // of the time.
2413       _length = -len;
2414       ptr = _value._compact;
2415     } else {
2416       _length = len;
2417       _value._fingerprint = NEW_C_HEAP_ARRAY(int, _length, mtCode);
2418       ptr = _value._fingerprint;
2419     }
2420 
2421     // Now pack the BasicTypes with 8 per int
2422     int sig_index = 0;
2423     BasicType prev_sbt = T_ILLEGAL;
2424     int vt_count = 0;
2425     for (int index = 0; index &lt; len; index++) {
2426       int value = 0;
2427       for (int byte = 0; byte &lt; _basic_types_per_int; byte++) {
2428         int bt = 0;
2429         if (sig_index &lt; total_args_passed) {
2430           BasicType sbt = sig-&gt;at(sig_index++)._bt;
<span class="line-modified">2431           if (InlineTypePassFieldsAsArgs &amp;&amp; sbt == T_VALUETYPE) {</span>
<span class="line-modified">2432             // Found start of inline type in signature</span>
2433             vt_count++;
2434             if (sig_index == 1 &amp;&amp; has_ro_adapter) {
2435               // With a ro_adapter, replace receiver value type delimiter by T_VOID to prevent matching
2436               // with other adapters that have the same value type as first argument and no receiver.
2437               sbt = T_VOID;
2438             }
<span class="line-modified">2439           } else if (InlineTypePassFieldsAsArgs &amp;&amp; sbt == T_VOID &amp;&amp;</span>
2440                      prev_sbt != T_LONG &amp;&amp; prev_sbt != T_DOUBLE) {
<span class="line-modified">2441             // Found end of inline type in signature</span>
2442             vt_count--;
2443             assert(vt_count &gt;= 0, &quot;invalid vt_count&quot;);
2444           }
2445           bt = adapter_encoding(sbt, vt_count &gt; 0);
2446           prev_sbt = sbt;
2447         }
2448         assert((bt &amp; _basic_type_mask) == bt, &quot;must fit in 4 bits&quot;);
2449         value = (value &lt;&lt; _basic_type_bits) | bt;
2450       }
2451       ptr[index] = value;
2452     }
2453     assert(vt_count == 0, &quot;invalid vt_count&quot;);
2454   }
2455 
2456   ~AdapterFingerPrint() {
2457     if (_length &gt; 0) {
2458       FREE_C_HEAP_ARRAY(int, _value._fingerprint);
2459     }
2460   }
2461 
</pre>
<hr />
<pre>
2831 
2832 void CompiledEntrySignature::compute_calling_conventions() {
2833   // Get the (non-scalarized) signature and check for value type arguments
2834   if (!_method-&gt;is_static()) {
2835     if (_method-&gt;method_holder()-&gt;is_value() &amp;&amp; ValueKlass::cast(_method-&gt;method_holder())-&gt;is_scalarizable()) {
2836       _has_value_recv = true;
2837       _num_value_args++;
2838     }
2839     SigEntry::add_entry(_sig, T_OBJECT);
2840   }
2841   for (SignatureStream ss(_method-&gt;signature()); !ss.at_return_type(); ss.next()) {
2842     BasicType bt = ss.type();
2843     if (bt == T_VALUETYPE) {
2844       if (ss.as_value_klass(_method-&gt;method_holder())-&gt;is_scalarizable()) {
2845         _num_value_args++;
2846       }
2847       bt = T_OBJECT;
2848     }
2849     SigEntry::add_entry(_sig, bt);
2850   }
<span class="line-modified">2851   if (_method-&gt;is_abstract() &amp;&amp; !(InlineTypePassFieldsAsArgs &amp;&amp; has_value_arg())) {</span>
2852     return;
2853   }
2854 
2855   // Get a description of the compiled java calling convention and the largest used (VMReg) stack slot usage
2856   _regs = NEW_RESOURCE_ARRAY(VMRegPair, _sig-&gt;length());
2857   _args_on_stack = SharedRuntime::java_calling_convention(_sig, _regs);
2858 
2859   // Now compute the scalarized calling convention if there are value types in the signature
2860   _sig_cc = _sig;
2861   _sig_cc_ro = _sig;
2862   _regs_cc = _regs;
2863   _regs_cc_ro = _regs;
2864   _args_on_stack_cc = _args_on_stack;
2865   _args_on_stack_cc_ro = _args_on_stack;
2866 
<span class="line-modified">2867   if (InlineTypePassFieldsAsArgs &amp;&amp; has_value_arg() &amp;&amp; !_method-&gt;is_native()) {</span>
2868     _args_on_stack_cc = compute_scalarized_cc(_sig_cc, _regs_cc, /* scalar_receiver = */ true);
2869 
2870     _sig_cc_ro = _sig_cc;
2871     _regs_cc_ro = _regs_cc;
2872     _args_on_stack_cc_ro = _args_on_stack_cc;
2873     if (_has_value_recv || _args_on_stack_cc &gt; _args_on_stack) {
2874       // For interface calls, we need another entry point / adapter to unpack the receiver
2875       _args_on_stack_cc_ro = compute_scalarized_cc(_sig_cc_ro, _regs_cc_ro, /* scalar_receiver = */ false);
2876     }
2877 
2878     // Compute the stack extension that is required to convert between the calling conventions.
2879     // The stack slots at these offsets are occupied by the return address with the unscalarized
2880     // calling convention. Don&#39;t use them for arguments with the scalarized calling convention.
2881     int ret_off    = _args_on_stack_cc - _args_on_stack;
2882     int ret_off_ro = _args_on_stack_cc - _args_on_stack_cc_ro;
2883     assert(ret_off_ro &lt;= 0 || ret_off &gt; 0, &quot;receiver unpacking requires more stack space than expected&quot;);
2884 
2885     if (ret_off &gt; 0) {
2886       // Make sure the stack of the scalarized calling convention with the reserved
2887       // entries (2 slots each) remains 16-byte (4 slots) aligned after stack extension.
</pre>
<hr />
<pre>
3562 }
3563 
3564 void SharedRuntime::on_slowpath_allocation_exit(JavaThread* thread) {
3565   // After any safepoint, just before going back to compiled code,
3566   // we inform the GC that we will be doing initializing writes to
3567   // this object in the future without emitting card-marks, so
3568   // GC may take any compensating steps.
3569 
3570   oop new_obj = thread-&gt;vm_result();
3571   if (new_obj == NULL) return;
3572 
3573   BarrierSet *bs = BarrierSet::barrier_set();
3574   bs-&gt;on_slowpath_allocation_exit(thread, new_obj);
3575 }
3576 
3577 // We are at a compiled code to interpreter call. We need backing
3578 // buffers for all value type arguments. Allocate an object array to
3579 // hold them (convenient because once we&#39;re done with it we don&#39;t have
3580 // to worry about freeing it).
3581 oop SharedRuntime::allocate_value_types_impl(JavaThread* thread, methodHandle callee, bool allocate_receiver, TRAPS) {
<span class="line-modified">3582   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);</span>
3583   ResourceMark rm;
3584 
3585   int nb_slots = 0;
3586   InstanceKlass* holder = callee-&gt;method_holder();
3587   allocate_receiver &amp;= !callee-&gt;is_static() &amp;&amp; holder-&gt;is_value();
3588   if (allocate_receiver) {
3589     nb_slots++;
3590   }
3591   for (SignatureStream ss(callee-&gt;signature()); !ss.at_return_type(); ss.next()) {
3592     if (ss.type() == T_VALUETYPE) {
3593       nb_slots++;
3594     }
3595   }
3596   objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);
3597   objArrayHandle array(THREAD, array_oop);
3598   int i = 0;
3599   if (allocate_receiver) {
3600     ValueKlass* vk = ValueKlass::cast(holder);
3601     oop res = vk-&gt;allocate_instance(CHECK_NULL);
3602     array-&gt;obj_at_put(i, res);
</pre>
<hr />
<pre>
3608       oop res = vk-&gt;allocate_instance(CHECK_NULL);
3609       array-&gt;obj_at_put(i, res);
3610       i++;
3611     }
3612   }
3613   return array();
3614 }
3615 
3616 JRT_ENTRY(void, SharedRuntime::allocate_value_types(JavaThread* thread, Method* callee_method, bool allocate_receiver))
3617   methodHandle callee(thread, callee_method);
3618   oop array = SharedRuntime::allocate_value_types_impl(thread, callee, allocate_receiver, CHECK);
3619   thread-&gt;set_vm_result(array);
3620   thread-&gt;set_vm_result_2(callee()); // TODO: required to keep callee live?
3621 JRT_END
3622 
3623 // TODO remove this once the AARCH64 dependency is gone
3624 // Iterate over the array of heap allocated value types and apply the GC post barrier to all reference fields.
3625 // This is called from the C2I adapter after value type arguments are heap allocated and initialized.
3626 JRT_LEAF(void, SharedRuntime::apply_post_barriers(JavaThread* thread, objArrayOopDesc* array))
3627 {
<span class="line-modified">3628   assert(InlineTypePassFieldsAsArgs, &quot;no reason to call this&quot;);</span>
3629   assert(oopDesc::is_oop(array), &quot;should be oop&quot;);
3630   for (int i = 0; i &lt; array-&gt;length(); ++i) {
3631     instanceOop valueOop = (instanceOop)array-&gt;obj_at(i);
3632     ValueKlass* vk = ValueKlass::cast(valueOop-&gt;klass());
3633     if (vk-&gt;contains_oops()) {
3634       const address dst_oop_addr = ((address) (void*) valueOop);
3635       OopMapBlock* map = vk-&gt;start_of_nonstatic_oop_maps();
3636       OopMapBlock* const end = map + vk-&gt;nonstatic_oop_map_count();
3637       while (map != end) {
3638         address doop_address = dst_oop_addr + map-&gt;offset();
3639         barrier_set_cast&lt;ModRefBarrierSet&gt;(BarrierSet::barrier_set())-&gt;
3640           write_ref_array((HeapWord*) doop_address, map-&gt;count());
3641         map++;
3642       }
3643     }
3644   }
3645 }
3646 JRT_END
3647 
3648 // We&#39;re returning from an interpreted method: load each field into a
</pre>
</td>
</tr>
</table>
<center><a href="safepoint.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../utilities/globalDefinitions.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>