<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/x86/globals_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef CPU_X86_GLOBALS_X86_HPP
 26 #define CPU_X86_GLOBALS_X86_HPP
 27 
 28 #include &quot;utilities/globalDefinitions.hpp&quot;
 29 #include &quot;utilities/macros.hpp&quot;
 30 
 31 // Sets the default values for platform dependent flags used by the runtime system.
 32 // (see globals.hpp)
 33 
 34 define_pd_global(bool, ImplicitNullChecks,       true);  // Generate code for implicit null checks
 35 define_pd_global(bool, TrapBasedNullChecks,      false); // Not needed on x86.
 36 define_pd_global(bool, UncommonNullCast,         true);  // Uncommon-trap NULLs passed to check cast
 37 
 38 define_pd_global(uintx, CodeCacheSegmentSize,    64 TIERED_ONLY(+64)); // Tiered compilation has large code-entry alignment.
 39 // See 4827828 for this change. There is no globals_core_i486.hpp. I can&#39;t
 40 // assign a different value for C2 without touching a number of files. Use
 41 // #ifdef to minimize the change as it&#39;s late in Mantis. -- FIXME.
 42 // c1 doesn&#39;t have this problem because the fix to 4858033 assures us
 43 // the the vep is aligned at CodeEntryAlignment whereas c2 only aligns
 44 // the uep and the vep doesn&#39;t get real alignment but just slops on by
 45 // only assured that the entry instruction meets the 5 byte size requirement.
 46 #if COMPILER2_OR_JVMCI
 47 define_pd_global(intx, CodeEntryAlignment,       32);
 48 #else
 49 define_pd_global(intx, CodeEntryAlignment,       16);
 50 #endif // COMPILER2_OR_JVMCI
 51 define_pd_global(intx, OptoLoopAlignment,        16);
 52 define_pd_global(intx, InlineFrequencyCount,     100);
 53 define_pd_global(intx, InlineSmallCode,          1000);
 54 
 55 #define DEFAULT_STACK_YELLOW_PAGES (NOT_WINDOWS(2) WINDOWS_ONLY(3))
 56 #define DEFAULT_STACK_RED_PAGES (1)
 57 #define DEFAULT_STACK_RESERVED_PAGES (NOT_WINDOWS(1) WINDOWS_ONLY(0))
 58 
 59 #define MIN_STACK_YELLOW_PAGES DEFAULT_STACK_YELLOW_PAGES
 60 #define MIN_STACK_RED_PAGES DEFAULT_STACK_RED_PAGES
 61 #define MIN_STACK_RESERVED_PAGES (0)
 62 
 63 #ifdef _LP64
 64 // Java_java_net_SocketOutputStream_socketWrite0() uses a 64k buffer on the
 65 // stack if compiled for unix and LP64. To pass stack overflow tests we need
 66 // 20 shadow pages.
 67 #define DEFAULT_STACK_SHADOW_PAGES (NOT_WIN64(20) WIN64_ONLY(7) DEBUG_ONLY(+2))
 68 // For those clients that do not use write socket, we allow
 69 // the min range value to be below that of the default
 70 #define MIN_STACK_SHADOW_PAGES (NOT_WIN64(10) WIN64_ONLY(7) DEBUG_ONLY(+2))
 71 #else
 72 #define DEFAULT_STACK_SHADOW_PAGES (4 DEBUG_ONLY(+5))
 73 #define MIN_STACK_SHADOW_PAGES DEFAULT_STACK_SHADOW_PAGES
 74 #endif // _LP64
 75 
 76 define_pd_global(intx, StackYellowPages, DEFAULT_STACK_YELLOW_PAGES);
 77 define_pd_global(intx, StackRedPages, DEFAULT_STACK_RED_PAGES);
 78 define_pd_global(intx, StackShadowPages, DEFAULT_STACK_SHADOW_PAGES);
 79 define_pd_global(intx, StackReservedPages, DEFAULT_STACK_RESERVED_PAGES);
 80 
 81 define_pd_global(bool, RewriteBytecodes,     true);
 82 define_pd_global(bool, RewriteFrequentPairs, true);
 83 
 84 define_pd_global(uintx, TypeProfileLevel, 111);
 85 
 86 define_pd_global(bool, CompactStrings, true);
 87 
 88 define_pd_global(bool, PreserveFramePointer, false);
 89 
 90 define_pd_global(intx, InitArrayShortSize, 8*BytesPerLong);
 91 
 92 define_pd_global(bool, InlineTypePassFieldsAsArgs, LP64_ONLY(true) NOT_LP64(false));
 93 define_pd_global(bool, InlineTypeReturnedAsFields, LP64_ONLY(true) NOT_LP64(false));
 94 
 95 #define ARCH_FLAGS(develop, \
 96                    product, \
 97                    diagnostic, \
 98                    experimental, \
 99                    notproduct, \
100                    range, \
101                    constraint) \
102                                                                             \
103   develop(bool, IEEEPrecision, true,                                        \
104           &quot;Enables IEEE precision (for INTEL only)&quot;)                        \
105                                                                             \
106   product(bool, UseStoreImmI16, true,                                       \
107           &quot;Use store immediate 16-bits value instruction on x86&quot;)           \
108                                                                             \
109   product(intx, UseSSE, 99,                                                 \
110           &quot;Highest supported SSE instructions set on x86/x64&quot;)              \
111           range(0, 99)                                                      \
112                                                                             \
113   product(intx, UseAVX, 3,                                                  \
114           &quot;Highest supported AVX instructions set on x86/x64&quot;)              \
115           range(0, 99)                                                      \
116                                                                             \
117   product(bool, UseCLMUL, false,                                            \
118           &quot;Control whether CLMUL instructions can be used on x86/x64&quot;)      \
119                                                                             \
120   diagnostic(bool, UseIncDec, true,                                         \
121           &quot;Use INC, DEC instructions on x86&quot;)                               \
122                                                                             \
123   product(bool, UseNewLongLShift, false,                                    \
124           &quot;Use optimized bitwise shift left&quot;)                               \
125                                                                             \
126   product(bool, UseAddressNop, false,                                       \
127           &quot;Use &#39;0F 1F [addr]&#39; NOP instructions on x86 cpus&quot;)                \
128                                                                             \
129   product(bool, UseXmmLoadAndClearUpper, true,                              \
130           &quot;Load low part of XMM register and clear upper part&quot;)             \
131                                                                             \
132   product(bool, UseXmmRegToRegMoveAll, false,                               \
133           &quot;Copy all XMM register bits when moving value between registers&quot;) \
134                                                                             \
135   product(bool, UseXmmI2D, false,                                           \
136           &quot;Use SSE2 CVTDQ2PD instruction to convert Integer to Double&quot;)     \
137                                                                             \
138   product(bool, UseXmmI2F, false,                                           \
139           &quot;Use SSE2 CVTDQ2PS instruction to convert Integer to Float&quot;)      \
140                                                                             \
141   product(bool, UseUnalignedLoadStores, false,                              \
142           &quot;Use SSE2 MOVDQU instruction for Arraycopy&quot;)                      \
143                                                                             \
144   product(bool, UseXMMForObjInit, false,                                    \
145           &quot;Use XMM/YMM MOVDQU instruction for Object Initialization&quot;)       \
146                                                                             \
147   product(bool, UseFastStosb, false,                                        \
148           &quot;Use fast-string operation for zeroing: rep stosb&quot;)               \
149                                                                             \
150   /* Use Restricted Transactional Memory for lock eliding */                \
151   product(bool, UseRTMLocking, false,                                       \
152           &quot;Enable RTM lock eliding for inflated locks in compiled code&quot;)    \
153                                                                             \
154   experimental(bool, UseRTMForStackLocks, false,                            \
155           &quot;Enable RTM lock eliding for stack locks in compiled code&quot;)       \
156                                                                             \
157   product(bool, UseRTMDeopt, false,                                         \
158           &quot;Perform deopt and recompilation based on RTM abort ratio&quot;)       \
159                                                                             \
160   product(int, RTMRetryCount, 5,                                            \
161           &quot;Number of RTM retries on lock abort or busy&quot;)                    \
162           range(0, max_jint)                                                \
163                                                                             \
164   experimental(int, RTMSpinLoopCount, 100,                                  \
165           &quot;Spin count for lock to become free before RTM retry&quot;)            \
166           range(0, max_jint)                                                \
167                                                                             \
168   experimental(int, RTMAbortThreshold, 1000,                                \
169           &quot;Calculate abort ratio after this number of aborts&quot;)              \
170           range(0, max_jint)                                                \
171                                                                             \
172   experimental(int, RTMLockingThreshold, 10000,                             \
173           &quot;Lock count at which to do RTM lock eliding without &quot;             \
174           &quot;abort ratio calculation&quot;)                                        \
175           range(0, max_jint)                                                \
176                                                                             \
177   experimental(int, RTMAbortRatio, 50,                                      \
178           &quot;Lock abort ratio at which to stop use RTM lock eliding&quot;)         \
179           range(0, 100) /* natural range */                                 \
180                                                                             \
181   experimental(int, RTMTotalCountIncrRate, 64,                              \
182           &quot;Increment total RTM attempted lock count once every n times&quot;)    \
183           range(1, max_jint)                                                \
184           constraint(RTMTotalCountIncrRateConstraintFunc,AfterErgo)         \
185                                                                             \
186   experimental(intx, RTMLockingCalculationDelay, 0,                         \
187           &quot;Number of milliseconds to wait before start calculating aborts &quot; \
188           &quot;for RTM locking&quot;)                                                \
189                                                                             \
190   experimental(bool, UseRTMXendForLockBusy, true,                           \
191           &quot;Use RTM Xend instead of Xabort when lock busy&quot;)                  \
192                                                                             \
193   /* assembler */                                                           \
194   product(bool, UseCountLeadingZerosInstruction, false,                     \
195           &quot;Use count leading zeros instruction&quot;)                            \
196                                                                             \
197   product(bool, UseCountTrailingZerosInstruction, false,                    \
198           &quot;Use count trailing zeros instruction&quot;)                           \
199                                                                             \
200   product(bool, UseSSE42Intrinsics, false,                                  \
201           &quot;SSE4.2 versions of intrinsics&quot;)                                  \
202                                                                             \
203   product(bool, UseBMI1Instructions, false,                                 \
204           &quot;Use BMI1 instructions&quot;)                                          \
205                                                                             \
206   product(bool, UseBMI2Instructions, false,                                 \
207           &quot;Use BMI2 instructions&quot;)                                          \
208                                                                             \
209   diagnostic(bool, UseLibmIntrinsic, true,                                  \
210           &quot;Use Libm Intrinsics&quot;)                                            \
211                                                                             \
212   /* Minimum array size in bytes to use AVX512 intrinsics */                \
213   /* for copy, inflate and fill which don&#39;t bail out early based on any */  \
214   /* condition. When this value is set to zero compare operations like */   \
215   /* compare, vectorizedMismatch, compress can also use AVX512 intrinsics.*/\
216   diagnostic(int, AVX3Threshold, 4096,                                      \
217              &quot;Minimum array size in bytes to use AVX512 intrinsics&quot;         \
218              &quot;for copy, inflate and fill. When this value is set as zero&quot;   \
219              &quot;compare operations can also use AVX512 intrinsics.&quot;)          \
220              range(0, max_jint)                                             \
221                                                                             \
222   diagnostic(bool, IntelJccErratumMitigation, true,                         \
223              &quot;Turn off JVM mitigations related to Intel micro code &quot;        \
224              &quot;mitigations for the Intel JCC erratum&quot;)
225 
226 #endif // CPU_X86_GLOBALS_X86_HPP
    </pre>
  </body>
</html>