<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/oops/compressedOops.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;aot/aotLoader.hpp&quot;
 27 #include &quot;logging/log.hpp&quot;
 28 #include &quot;logging/logStream.hpp&quot;
 29 #include &quot;memory/memRegion.hpp&quot;
 30 #include &quot;memory/universe.hpp&quot;
 31 #include &quot;oops/compressedOops.hpp&quot;
 32 #include &quot;gc/shared/collectedHeap.hpp&quot;
 33 #include &quot;runtime/globals.hpp&quot;
 34 
 35 // For UseCompressedOops.
 36 NarrowPtrStruct CompressedOops::_narrow_oop = { NULL, 0, true };
 37 MemRegion       CompressedOops::_heap_address_range;
 38 
 39 // Choose the heap base address and oop encoding mode
 40 // when compressed oops are used:
 41 // Unscaled  - Use 32-bits oops without encoding when
 42 //     NarrowOopHeapBaseMin + heap_size &lt; 4Gb
 43 // ZeroBased - Use zero based compressed oops with encoding when
 44 //     NarrowOopHeapBaseMin + heap_size &lt; 32Gb
 45 // HeapBased - Use compressed oops with heap base + encoding.
 46 void CompressedOops::initialize(const ReservedHeapSpace&amp; heap_space) {
 47 #ifdef _LP64
 48   // Subtract a page because something can get allocated at heap base.
 49   // This also makes implicit null checking work, because the
 50   // memory+1 page below heap_base needs to cause a signal.
 51   // See needs_explicit_null_check.
 52   // Only set the heap base for compressed oops because it indicates
 53   // compressed oops for pstack code.
 54   if ((uint64_t)heap_space.end() &gt; UnscaledOopHeapMax) {
 55     // Didn&#39;t reserve heap below 4Gb.  Must shift.
 56     set_shift(LogMinObjAlignmentInBytes);
 57   }
 58   if ((uint64_t)heap_space.end() &lt;= OopEncodingHeapMax) {
 59     // Did reserve heap below 32Gb. Can use base == 0;
 60     set_base(0);
 61   } else {
 62     set_base((address)heap_space.compressed_oop_base());
 63   }
 64 
 65   AOTLoader::set_narrow_oop_shift();
 66 
 67   _heap_address_range = heap_space.region();
 68 
 69   LogTarget(Debug, gc, heap, coops) lt;
 70   if (lt.is_enabled()) {
 71     ResourceMark rm;
 72     LogStream ls(lt);
 73     print_mode(&amp;ls);
 74   }
 75 
 76   // Tell tests in which mode we run.
 77   Arguments::PropertyList_add(new SystemProperty(&quot;java.vm.compressedOopsMode&quot;,
 78                                                  mode_to_string(mode()),
 79                                                  false));
 80 
 81   // base() is one page below the heap.
 82   assert((intptr_t)base() &lt;= ((intptr_t)_heap_address_range.start() - os::vm_page_size()) ||
 83          base() == NULL, &quot;invalid value&quot;);
 84   assert(shift() == LogMinObjAlignmentInBytes ||
 85          shift() == 0, &quot;invalid value&quot;);
 86 #endif
 87 }
 88 
 89 void CompressedOops::set_base(address base) {
 90   assert(UseCompressedOops, &quot;no compressed oops?&quot;);
 91   _narrow_oop._base    = base;
 92 }
 93 
 94 void CompressedOops::set_shift(int shift) {
 95   _narrow_oop._shift   = shift;
 96 }
 97 
 98 void CompressedOops::set_use_implicit_null_checks(bool use) {
 99   assert(UseCompressedOops, &quot;no compressed ptrs?&quot;);
100   _narrow_oop._use_implicit_null_checks   = use;
101 }
102 
103 bool CompressedOops::is_in(void* addr) {
104   return _heap_address_range.contains(addr);
105 }
106 
107 bool CompressedOops::is_in(MemRegion mr) {
108   return _heap_address_range.contains(mr);
109 }
110 
111 CompressedOops::Mode CompressedOops::mode() {
112   if (base_disjoint()) {
113     return DisjointBaseNarrowOop;
114   }
115 
116   if (base() != 0) {
117     return HeapBasedNarrowOop;
118   }
119 
120   if (shift() != 0) {
121     return ZeroBasedNarrowOop;
122   }
123 
124   return UnscaledNarrowOop;
125 }
126 
127 const char* CompressedOops::mode_to_string(Mode mode) {
128   switch (mode) {
129     case UnscaledNarrowOop:
130       return &quot;32-bit&quot;;
131     case ZeroBasedNarrowOop:
132       return &quot;Zero based&quot;;
133     case DisjointBaseNarrowOop:
134       return &quot;Non-zero disjoint base&quot;;
135     case HeapBasedNarrowOop:
136       return &quot;Non-zero based&quot;;
137     default:
138       ShouldNotReachHere();
139       return &quot;&quot;;
140   }
141 }
142 
143 // Test whether bits of addr and possible offsets into the heap overlap.
144 bool CompressedOops::is_disjoint_heap_base_address(address addr) {
145   return (((uint64_t)(intptr_t)addr) &amp;
146           (((uint64_t)UCONST64(0xFFFFffffFFFFffff)) &gt;&gt; (32-LogMinObjAlignmentInBytes))) == 0;
147 }
148 
149 // Check for disjoint base compressed oops.
150 bool CompressedOops::base_disjoint() {
151   return _narrow_oop._base != NULL &amp;&amp; is_disjoint_heap_base_address(_narrow_oop._base);
152 }
153 
154 // Check for real heapbased compressed oops.
155 // We must subtract the base as the bits overlap.
156 // If we negate above function, we also get unscaled and zerobased.
157 bool CompressedOops::base_overlaps() {
158   return _narrow_oop._base != NULL &amp;&amp; !is_disjoint_heap_base_address(_narrow_oop._base);
159 }
160 
161 void CompressedOops::print_mode(outputStream* st) {
162   st-&gt;print(&quot;Heap address: &quot; PTR_FORMAT &quot;, size: &quot; SIZE_FORMAT &quot; MB&quot;,
163             p2i(_heap_address_range.start()), _heap_address_range.byte_size()/M);
164 
165   st-&gt;print(&quot;, Compressed Oops mode: %s&quot;, mode_to_string(mode()));
166 
167   if (base() != 0) {
168     st-&gt;print(&quot;: &quot; PTR_FORMAT, p2i(base()));
169   }
170 
171   if (shift() != 0) {
172     st-&gt;print(&quot;, Oop shift amount: %d&quot;, shift());
173   }
174 
175   if (!use_implicit_null_checks()) {
176     st-&gt;print(&quot;, no protected page in front of the heap&quot;);
177   }
178   st-&gt;cr();
179 }
180 
181 // For UseCompressedClassPointers.
182 NarrowPtrStruct CompressedKlassPointers::_narrow_klass = { NULL, 0, true };
183 
184 // CompressedClassSpaceSize set to 1GB, but appear 3GB away from _narrow_ptrs_base during CDS dump.
185 // (Todo: we should #ifdef out CompressedKlassPointers for 32bit completely and fix all call sites which
186 //  are compiled for 32bit to LP64_ONLY).
187 size_t CompressedKlassPointers::_range = 0;
188 
189 
190 // Given an address range [addr, addr+len) which the encoding is supposed to
191 //  cover, choose base, shift and range.
192 //  The address range is the expected range of uncompressed Klass pointers we
193 //  will encounter (and the implicit promise that there will be no Klass
194 //  structures outside this range).
195 void CompressedKlassPointers::initialize(address addr, size_t len) {
196 #ifdef _LP64
197   assert(is_valid_base(addr), &quot;Address must be a valid encoding base&quot;);
198   address const end = addr + len;
199 
200   address base;
201   int shift;
202   size_t range;
203 
204   if (UseSharedSpaces || DumpSharedSpaces) {
205 
206     // Special requirements if CDS is active:
207     // Encoding base and shift must be the same between dump and run time.
208     //   CDS takes care that the SharedBaseAddress and CompressedClassSpaceSize
209     //   are the same. Archive size will be probably different at runtime, but
210     //   it can only be smaller than at, never larger, since archives get
211     //   shrunk at the end of the dump process.
212     //   From that it follows that the range [addr, len) we are handed in at
213     //   runtime will start at the same address then at dumptime, and its len
214     //   may be smaller at runtime then it was at dump time.
215     //
216     // To be very careful here, we avoid any optimizations and just keep using
217     //  the same address and shift value. Specifically we avoid using zero-based
218     //  encoding. We also set the expected value range to 4G (encoding range
219     //  cannot be larger than that).
220 
221     base = addr;
222     shift = LogKlassAlignmentInBytes;
223 
224     // This must be true since at dumptime cds+ccs is 4G, at runtime it can
225     //  only be smaller, see comment above.
226     assert(len &lt;= 4 * G, &quot;Encoding range cannot be larger than 4G&quot;);
227     range = 4 * G;
228 
229   } else {
230 
231     // Otherwise we attempt to use a zero base if the range fits in lower 32G.
232     if (end &lt;= (address)KlassEncodingMetaspaceMax) {
233       base = 0;
234     } else {
235       base = addr;
236     }
237 
238     // Highest offset a Klass* can ever have in relation to base.
239     range = end - base;
240 
241     // We may not even need a shift if the range fits into 32bit:
242     const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
243     if (range &lt; UnscaledClassSpaceMax) {
244       shift = 0;
245     } else {
246       shift = LogKlassAlignmentInBytes;
247     }
248 
249   }
250 
251   set_base(base);
252   set_shift(shift);
253   set_range(range);
254 
255   // Note: this may modify our shift.
256   AOTLoader::set_narrow_klass_shift();
257 #else
258   fatal(&quot;64bit only.&quot;);
259 #endif
260 }
261 
262 // Given an address p, return true if p can be used as an encoding base.
263 //  (Some platforms have restrictions of what constitutes a valid base address).
264 bool CompressedKlassPointers::is_valid_base(address p) {
265 #ifdef AARCH64
266   // Below 32G, base must be aligned to 4G.
267   // Above that point, base must be aligned to 32G
268   if (p &lt; (address)(32 * G)) {
269     return is_aligned(p, 4 * G);
270   }
271   return is_aligned(p, (4 &lt;&lt; LogKlassAlignmentInBytes) * G);
272 #else
273   return true;
274 #endif
275 }
276 
277 void CompressedKlassPointers::print_mode(outputStream* st) {
278   st-&gt;print_cr(&quot;Narrow klass base: &quot; PTR_FORMAT &quot;, Narrow klass shift: %d, &quot;
279                &quot;Narrow klass range: &quot; SIZE_FORMAT_HEX, p2i(base()), shift(),
280                range());
281 }
282 
283 void CompressedKlassPointers::set_base(address base) {
284   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
285   _narrow_klass._base   = base;
286 }
287 
288 void CompressedKlassPointers::set_shift(int shift)       {
289   assert(shift == 0 || shift == LogKlassAlignmentInBytes, &quot;invalid shift for klass ptrs&quot;);
290   _narrow_klass._shift   = shift;
291 }
292 
293 void CompressedKlassPointers::set_range(size_t range) {
294   assert(UseCompressedClassPointers, &quot;no compressed klass ptrs?&quot;);
295   _range = range;
296 }
    </pre>
  </body>
</html>