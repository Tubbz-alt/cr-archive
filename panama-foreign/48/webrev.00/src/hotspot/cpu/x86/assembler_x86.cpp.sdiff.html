<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/assembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../sparc/vm_version_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/assembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1311 }
1312 
1313 void Assembler::aesdec(XMMRegister dst, Address src) {
1314   assert(VM_Version::supports_aes(), &quot;&quot;);
1315   InstructionMark im(this);
1316   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1317   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1318   emit_int8((unsigned char)0xDE);
1319   emit_operand(dst, src);
1320 }
1321 
1322 void Assembler::aesdec(XMMRegister dst, XMMRegister src) {
1323   assert(VM_Version::supports_aes(), &quot;&quot;);
1324   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1325   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1326   emit_int8((unsigned char)0xDE);
1327   emit_int8(0xC0 | encode);
1328 }
1329 
1330 void Assembler::vaesdec(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1331   assert(VM_Version::supports_vaes(), &quot;&quot;);</span>
1332   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1333   attributes.set_is_evex_instruction();
1334   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1335   emit_int8((unsigned char)0xDE);
1336   emit_int8((unsigned char)(0xC0 | encode));
1337 }
1338 
1339 
1340 void Assembler::aesdeclast(XMMRegister dst, Address src) {
1341   assert(VM_Version::supports_aes(), &quot;&quot;);
1342   InstructionMark im(this);
1343   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1344   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1345   emit_int8((unsigned char)0xDF);
1346   emit_operand(dst, src);
1347 }
1348 
1349 void Assembler::aesdeclast(XMMRegister dst, XMMRegister src) {
1350   assert(VM_Version::supports_aes(), &quot;&quot;);
1351   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1352   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1353   emit_int8((unsigned char)0xDF);
1354   emit_int8((unsigned char)(0xC0 | encode));
1355 }
1356 
1357 void Assembler::vaesdeclast(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1358   assert(VM_Version::supports_vaes(), &quot;&quot;);</span>
1359   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1360   attributes.set_is_evex_instruction();
1361   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1362   emit_int8((unsigned char)0xDF);
1363   emit_int8((unsigned char)(0xC0 | encode));
1364 }
1365 
1366 void Assembler::aesenc(XMMRegister dst, Address src) {
1367   assert(VM_Version::supports_aes(), &quot;&quot;);
1368   InstructionMark im(this);
1369   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1370   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1371   emit_int8((unsigned char)0xDC);
1372   emit_operand(dst, src);
1373 }
1374 
1375 void Assembler::aesenc(XMMRegister dst, XMMRegister src) {
1376   assert(VM_Version::supports_aes(), &quot;&quot;);
1377   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1378   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1379   emit_int8((unsigned char)0xDC);
1380   emit_int8(0xC0 | encode);
1381 }
1382 
1383 void Assembler::vaesenc(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1384   assert(VM_Version::supports_vaes(), &quot;requires vaes support/enabling&quot;);</span>
1385   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1386   attributes.set_is_evex_instruction();
1387   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1388   emit_int8((unsigned char)0xDC);
1389   emit_int8((unsigned char)(0xC0 | encode));
1390 }
1391 
1392 void Assembler::aesenclast(XMMRegister dst, Address src) {
1393   assert(VM_Version::supports_aes(), &quot;&quot;);
1394   InstructionMark im(this);
1395   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1396   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1397   emit_int8((unsigned char)0xDD);
1398   emit_operand(dst, src);
1399 }
1400 
1401 void Assembler::aesenclast(XMMRegister dst, XMMRegister src) {
1402   assert(VM_Version::supports_aes(), &quot;&quot;);
1403   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1404   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1405   emit_int8((unsigned char)0xDD);
1406   emit_int8((unsigned char)(0xC0 | encode));
1407 }
1408 
1409 void Assembler::vaesenclast(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1410   assert(VM_Version::supports_vaes(), &quot;requires vaes support/enabling&quot;);</span>
1411   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1412   attributes.set_is_evex_instruction();
1413   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1414   emit_int8((unsigned char)0xDD);
1415   emit_int8((unsigned char)(0xC0 | encode));
1416 }
1417 
1418 void Assembler::andl(Address dst, int32_t imm32) {
1419   InstructionMark im(this);
1420   prefix(dst);
1421   emit_int8((unsigned char)0x81);
1422   emit_operand(rsp, dst, 4);
1423   emit_int32(imm32);
1424 }
1425 
1426 void Assembler::andl(Register dst, int32_t imm32) {
1427   prefix(dst);
1428   emit_arith(0x81, 0xE0, dst, imm32);
1429 }
1430 
</pre>
<hr />
<pre>
4086 void Assembler::pmaddwd(XMMRegister dst, XMMRegister src) {
4087   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4088   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4089   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4090   emit_int8((unsigned char)0xF5);
4091   emit_int8((unsigned char)(0xC0 | encode));
4092 }
4093 
4094 void Assembler::vpmaddwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4095   assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :
4096     (vector_len == AVX_256bit ? VM_Version::supports_avx2() :
4097     (vector_len == AVX_512bit ? VM_Version::supports_evex() : 0)), &quot;&quot;);
4098   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4099   int encode = simd_prefix_and_encode(dst, nds, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4100   emit_int8((unsigned char)0xF5);
4101   emit_int8((unsigned char)(0xC0 | encode));
4102 }
4103 
4104 void Assembler::evpdpwssd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4105   assert(VM_Version::supports_evex(), &quot;&quot;);
<span class="line-modified">4106   assert(VM_Version::supports_vnni(), &quot;must support vnni&quot;);</span>
4107   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4108   attributes.set_is_evex_instruction();
4109   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4110   emit_int8(0x52);
4111   emit_int8((unsigned char)(0xC0 | encode));
4112 }
4113 
4114 // generic
4115 void Assembler::pop(Register dst) {
4116   int encode = prefix_and_encode(dst-&gt;encoding());
4117   emit_int8(0x58 | encode);
4118 }
4119 
4120 void Assembler::popcntl(Register dst, Address src) {
4121   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
4122   InstructionMark im(this);
4123   emit_int8((unsigned char)0xF3);
4124   prefix(src, dst);
4125   emit_int8(0x0F);
4126   emit_int8((unsigned char)0xB8);
4127   emit_operand(dst, src);
4128 }
4129 
4130 void Assembler::popcntl(Register dst, Register src) {
4131   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
4132   emit_int8((unsigned char)0xF3);
4133   int encode = prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding());
4134   emit_int8(0x0F);
4135   emit_int8((unsigned char)0xB8);
4136   emit_int8((unsigned char)(0xC0 | encode));
4137 }
4138 
4139 void Assembler::vpopcntd(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">4140   assert(VM_Version::supports_vpopcntdq(), &quot;must support vpopcntdq feature&quot;);</span>
4141   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4142   attributes.set_is_evex_instruction();
4143   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4144   emit_int8(0x55);
4145   emit_int8((unsigned char)(0xC0 | encode));
4146 }
4147 
4148 void Assembler::popf() {
4149   emit_int8((unsigned char)0x9D);
4150 }
4151 
4152 #ifndef _LP64 // no 32bit push/pop on amd64
4153 void Assembler::popl(Address dst) {
4154   // NOTE: this will adjust stack by 8byte on 64bits
4155   InstructionMark im(this);
4156   prefix(dst);
4157   emit_int8((unsigned char)0x8F);
4158   emit_operand(rax, dst);
4159 }
4160 #endif
</pre>
<hr />
<pre>
6527 
6528 void Assembler::vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
6529   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6530   InstructionMark im(this);
6531   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6532   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
6533   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6534   emit_int8((unsigned char)0xDB);
6535   emit_operand(dst, src);
6536 }
6537 
6538 void Assembler::vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6539   assert(VM_Version::supports_evex(), &quot;&quot;);
6540   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6541   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6542   emit_int8((unsigned char)0xDB);
6543   emit_int8((unsigned char)(0xC0 | encode));
6544 }
6545 
6546 void Assembler::vpshldvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
<span class="line-modified">6547   assert(VM_Version::supports_vbmi2(), &quot;requires vbmi2&quot;);</span>
6548   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6549   attributes.set_is_evex_instruction();
6550   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6551   emit_int8(0x71);
6552   emit_int8((unsigned char)(0xC0 | encode));
6553 }
6554 
6555 void Assembler::vpshrdvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
<span class="line-modified">6556   assert(VM_Version::supports_vbmi2(), &quot;requires vbmi2&quot;);</span>
6557   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6558   attributes.set_is_evex_instruction();
6559   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6560   emit_int8(0x73);
6561   emit_int8((unsigned char)(0xC0 | encode));
6562 }
6563 
6564 void Assembler::pandn(XMMRegister dst, XMMRegister src) {
6565   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6566   InstructionAttr attributes(AVX_128bit, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6567   attributes.set_rex_vex_w_reverted();
6568   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6569   emit_int8((unsigned char)0xDF);
6570   emit_int8((unsigned char)(0xC0 | encode));
6571 }
6572 
6573 void Assembler::vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6574   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6575   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6576   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
</pre>
<hr />
<pre>
7143 }
7144 
7145 void Assembler::evbroadcasti64x2(XMMRegister dst, Address src, int vector_len) {
7146   assert(vector_len != Assembler::AVX_128bit, &quot;&quot;);
7147   assert(VM_Version::supports_avx512dq(), &quot;&quot;);
7148   assert(dst != xnoreg, &quot;sanity&quot;);
7149   InstructionMark im(this);
7150   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7151   attributes.set_rex_vex_w_reverted();
7152   attributes.set_address_attributes(/* tuple_type */ EVEX_T2, /* input_size_in_bits */ EVEX_64bit);
7153   // swap src&lt;-&gt;dst for encoding
7154   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7155   emit_int8(0x5A);
7156   emit_operand(dst, src);
7157 }
7158 
7159 // scalar single/double precision replicate
7160 
7161 // duplicate single precision data from src into programmed locations in dest : requires AVX512VL
7162 void Assembler::vbroadcastss(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">7163   assert(VM_Version::supports_avx(), &quot;&quot;);</span>
7164   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7165   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7166   emit_int8(0x18);
7167   emit_int8((unsigned char)(0xC0 | encode));
7168 }
7169 
7170 void Assembler::vbroadcastss(XMMRegister dst, Address src, int vector_len) {
7171   assert(VM_Version::supports_avx(), &quot;&quot;);
7172   assert(dst != xnoreg, &quot;sanity&quot;);
7173   InstructionMark im(this);
7174   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7175   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_32bit);
7176   // swap src&lt;-&gt;dst for encoding
7177   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7178   emit_int8(0x18);
7179   emit_operand(dst, src);
7180 }
7181 
7182 // duplicate double precision data from src into programmed locations in dest : requires AVX512VL
7183 void Assembler::vbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">7184   assert(VM_Version::supports_avx(), &quot;&quot;);</span>

7185   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7186   attributes.set_rex_vex_w_reverted();
7187   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7188   emit_int8(0x19);
7189   emit_int8((unsigned char)(0xC0 | encode));
7190 }
7191 
7192 void Assembler::vbroadcastsd(XMMRegister dst, Address src, int vector_len) {
7193   assert(VM_Version::supports_avx(), &quot;&quot;);

7194   assert(dst != xnoreg, &quot;sanity&quot;);
7195   InstructionMark im(this);
7196   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7197   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
7198   attributes.set_rex_vex_w_reverted();
7199   // swap src&lt;-&gt;dst for encoding
7200   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7201   emit_int8(0x19);
7202   emit_operand(dst, src);
7203 }
7204 
7205 
7206 // gpr source broadcast forms
7207 
7208 // duplicate 1-byte integer data from src into programmed locations in dest : requires AVX512BW and AVX512VL
7209 void Assembler::evpbroadcastb(XMMRegister dst, Register src, int vector_len) {
7210   assert(VM_Version::supports_avx512bw(), &quot;&quot;);
7211   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
7212   attributes.set_is_evex_instruction();
7213   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
</pre>
<hr />
<pre>
7271 // Carry-Less Multiplication Quadword
7272 void Assembler::vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask) {
7273   assert(VM_Version::supports_avx() &amp;&amp; VM_Version::supports_clmul(), &quot;&quot;);
7274   InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7275   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7276   emit_int8(0x44);
7277   emit_int8((unsigned char)(0xC0 | encode));
7278   emit_int8((unsigned char)mask);
7279 }
7280 
7281 void Assembler::evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len) {
7282   assert(VM_Version::supports_avx512_vpclmulqdq(), &quot;Requires vector carryless multiplication support&quot;);
7283   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7284   attributes.set_is_evex_instruction();
7285   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7286   emit_int8(0x44);
7287   emit_int8((unsigned char)(0xC0 | encode));
7288   emit_int8((unsigned char)mask);
7289 }
7290 
<span class="line-modified">7291 void Assembler::vzeroupper() {</span>
7292   if (VM_Version::supports_vzeroupper()) {
7293     InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
7294     (void)vex_prefix_and_encode(0, 0, 0, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
7295     emit_int8(0x77);
7296   }
7297 }
7298 
7299 #ifndef _LP64
7300 // 32bit only pieces of the assembler
7301 




7302 void Assembler::cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec) {
7303   // NO PREFIX AS NEVER 64BIT
7304   InstructionMark im(this);
7305   emit_int8((unsigned char)0x81);
7306   emit_int8((unsigned char)(0xF8 | src1-&gt;encoding()));
7307   emit_data(imm32, rspec, 0);
7308 }
7309 
7310 void Assembler::cmp_literal32(Address src1, int32_t imm32, RelocationHolder const&amp; rspec) {
7311   // NO PREFIX AS NEVER 64BIT (not even 32bit versions of 64bit regs
7312   InstructionMark im(this);
7313   emit_int8((unsigned char)0x81);
7314   emit_operand(rdi, src1);
7315   emit_data(imm32, rspec, 0);
7316 }
7317 
7318 // The 64-bit (32bit platform) cmpxchg compares the value at adr with the contents of rdx:rax,
7319 // and stores rcx:rbx into adr if so; otherwise, the value at adr is loaded
7320 // into rdx:rax.  The ZF is set if the compared values were equal, and cleared otherwise.
7321 void Assembler::cmpxchg8(Address adr) {
</pre>
<hr />
<pre>
9231   emit_int32(imm32);
9232 }
9233 
9234 void Assembler::orq(Register dst, int32_t imm32) {
9235   (void) prefixq_and_encode(dst-&gt;encoding());
9236   emit_arith(0x81, 0xC8, dst, imm32);
9237 }
9238 
9239 void Assembler::orq(Register dst, Address src) {
9240   InstructionMark im(this);
9241   prefixq(src, dst);
9242   emit_int8(0x0B);
9243   emit_operand(dst, src);
9244 }
9245 
9246 void Assembler::orq(Register dst, Register src) {
9247   (void) prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
9248   emit_arith(0x0B, 0xC0, dst, src);
9249 }
9250 
<span class="line-removed">9251 void Assembler::popa() { // 64bit</span>
<span class="line-removed">9252   movq(r15, Address(rsp, 0));</span>
<span class="line-removed">9253   movq(r14, Address(rsp, wordSize));</span>
<span class="line-removed">9254   movq(r13, Address(rsp, 2 * wordSize));</span>
<span class="line-removed">9255   movq(r12, Address(rsp, 3 * wordSize));</span>
<span class="line-removed">9256   movq(r11, Address(rsp, 4 * wordSize));</span>
<span class="line-removed">9257   movq(r10, Address(rsp, 5 * wordSize));</span>
<span class="line-removed">9258   movq(r9,  Address(rsp, 6 * wordSize));</span>
<span class="line-removed">9259   movq(r8,  Address(rsp, 7 * wordSize));</span>
<span class="line-removed">9260   movq(rdi, Address(rsp, 8 * wordSize));</span>
<span class="line-removed">9261   movq(rsi, Address(rsp, 9 * wordSize));</span>
<span class="line-removed">9262   movq(rbp, Address(rsp, 10 * wordSize));</span>
<span class="line-removed">9263   // skip rsp</span>
<span class="line-removed">9264   movq(rbx, Address(rsp, 12 * wordSize));</span>
<span class="line-removed">9265   movq(rdx, Address(rsp, 13 * wordSize));</span>
<span class="line-removed">9266   movq(rcx, Address(rsp, 14 * wordSize));</span>
<span class="line-removed">9267   movq(rax, Address(rsp, 15 * wordSize));</span>
<span class="line-removed">9268 </span>
<span class="line-removed">9269   addq(rsp, 16 * wordSize);</span>
<span class="line-removed">9270 }</span>
<span class="line-removed">9271 </span>
9272 void Assembler::popcntq(Register dst, Address src) {
9273   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
9274   InstructionMark im(this);
9275   emit_int8((unsigned char)0xF3);
9276   prefixq(src, dst);
9277   emit_int8((unsigned char)0x0F);
9278   emit_int8((unsigned char)0xB8);
9279   emit_operand(dst, src);
9280 }
9281 
9282 void Assembler::popcntq(Register dst, Register src) {
9283   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
9284   emit_int8((unsigned char)0xF3);
9285   int encode = prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
9286   emit_int8((unsigned char)0x0F);
9287   emit_int8((unsigned char)0xB8);
9288   emit_int8((unsigned char)(0xC0 | encode));
9289 }
9290 
9291 void Assembler::popq(Address dst) {
9292   InstructionMark im(this);
9293   prefixq(dst);
9294   emit_int8((unsigned char)0x8F);
9295   emit_operand(rax, dst);
9296 }
9297 




























































































9298 void Assembler::pusha() { // 64bit




9299   // we have to store original rsp.  ABI says that 128 bytes
9300   // below rsp are local scratch.
9301   movq(Address(rsp, -5 * wordSize), rsp);
9302 
9303   subq(rsp, 16 * wordSize);
9304 
9305   movq(Address(rsp, 15 * wordSize), rax);
9306   movq(Address(rsp, 14 * wordSize), rcx);
9307   movq(Address(rsp, 13 * wordSize), rdx);
9308   movq(Address(rsp, 12 * wordSize), rbx);
9309   // skip rsp
9310   movq(Address(rsp, 10 * wordSize), rbp);
9311   movq(Address(rsp, 9 * wordSize), rsi);
9312   movq(Address(rsp, 8 * wordSize), rdi);
9313   movq(Address(rsp, 7 * wordSize), r8);
9314   movq(Address(rsp, 6 * wordSize), r9);
9315   movq(Address(rsp, 5 * wordSize), r10);
9316   movq(Address(rsp, 4 * wordSize), r11);
9317   movq(Address(rsp, 3 * wordSize), r12);
9318   movq(Address(rsp, 2 * wordSize), r13);
9319   movq(Address(rsp, wordSize), r14);
9320   movq(Address(rsp, 0), r15);
9321 }
9322 




9323 void Assembler::pushq(Address src) {
9324   InstructionMark im(this);
9325   prefixq(src);
9326   emit_int8((unsigned char)0xFF);
9327   emit_operand(rsi, src);
9328 }
9329 
9330 void Assembler::rclq(Register dst, int imm8) {
9331   assert(isShiftCount(imm8 &gt;&gt; 1), &quot;illegal shift count&quot;);
9332   int encode = prefixq_and_encode(dst-&gt;encoding());
9333   if (imm8 == 1) {
9334     emit_int8((unsigned char)0xD1);
9335     emit_int8((unsigned char)(0xD0 | encode));
9336   } else {
9337     emit_int8((unsigned char)0xC1);
9338     emit_int8((unsigned char)(0xD0 | encode));
9339     emit_int8(imm8);
9340   }
9341 }
9342 
</pre>
</td>
<td>
<hr />
<pre>
1311 }
1312 
1313 void Assembler::aesdec(XMMRegister dst, Address src) {
1314   assert(VM_Version::supports_aes(), &quot;&quot;);
1315   InstructionMark im(this);
1316   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1317   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1318   emit_int8((unsigned char)0xDE);
1319   emit_operand(dst, src);
1320 }
1321 
1322 void Assembler::aesdec(XMMRegister dst, XMMRegister src) {
1323   assert(VM_Version::supports_aes(), &quot;&quot;);
1324   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1325   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1326   emit_int8((unsigned char)0xDE);
1327   emit_int8(0xC0 | encode);
1328 }
1329 
1330 void Assembler::vaesdec(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1331   assert(VM_Version::supports_avx512_vaes(), &quot;&quot;);</span>
1332   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1333   attributes.set_is_evex_instruction();
1334   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1335   emit_int8((unsigned char)0xDE);
1336   emit_int8((unsigned char)(0xC0 | encode));
1337 }
1338 
1339 
1340 void Assembler::aesdeclast(XMMRegister dst, Address src) {
1341   assert(VM_Version::supports_aes(), &quot;&quot;);
1342   InstructionMark im(this);
1343   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1344   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1345   emit_int8((unsigned char)0xDF);
1346   emit_operand(dst, src);
1347 }
1348 
1349 void Assembler::aesdeclast(XMMRegister dst, XMMRegister src) {
1350   assert(VM_Version::supports_aes(), &quot;&quot;);
1351   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1352   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1353   emit_int8((unsigned char)0xDF);
1354   emit_int8((unsigned char)(0xC0 | encode));
1355 }
1356 
1357 void Assembler::vaesdeclast(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1358   assert(VM_Version::supports_avx512_vaes(), &quot;&quot;);</span>
1359   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1360   attributes.set_is_evex_instruction();
1361   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1362   emit_int8((unsigned char)0xDF);
1363   emit_int8((unsigned char)(0xC0 | encode));
1364 }
1365 
1366 void Assembler::aesenc(XMMRegister dst, Address src) {
1367   assert(VM_Version::supports_aes(), &quot;&quot;);
1368   InstructionMark im(this);
1369   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1370   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1371   emit_int8((unsigned char)0xDC);
1372   emit_operand(dst, src);
1373 }
1374 
1375 void Assembler::aesenc(XMMRegister dst, XMMRegister src) {
1376   assert(VM_Version::supports_aes(), &quot;&quot;);
1377   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1378   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1379   emit_int8((unsigned char)0xDC);
1380   emit_int8(0xC0 | encode);
1381 }
1382 
1383 void Assembler::vaesenc(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1384   assert(VM_Version::supports_avx512_vaes(), &quot;requires vaes support/enabling&quot;);</span>
1385   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1386   attributes.set_is_evex_instruction();
1387   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1388   emit_int8((unsigned char)0xDC);
1389   emit_int8((unsigned char)(0xC0 | encode));
1390 }
1391 
1392 void Assembler::aesenclast(XMMRegister dst, Address src) {
1393   assert(VM_Version::supports_aes(), &quot;&quot;);
1394   InstructionMark im(this);
1395   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1396   simd_prefix(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1397   emit_int8((unsigned char)0xDD);
1398   emit_operand(dst, src);
1399 }
1400 
1401 void Assembler::aesenclast(XMMRegister dst, XMMRegister src) {
1402   assert(VM_Version::supports_aes(), &quot;&quot;);
1403   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
1404   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1405   emit_int8((unsigned char)0xDD);
1406   emit_int8((unsigned char)(0xC0 | encode));
1407 }
1408 
1409 void Assembler::vaesenclast(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
<span class="line-modified">1410   assert(VM_Version::supports_avx512_vaes(), &quot;requires vaes support/enabling&quot;);</span>
1411   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
1412   attributes.set_is_evex_instruction();
1413   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
1414   emit_int8((unsigned char)0xDD);
1415   emit_int8((unsigned char)(0xC0 | encode));
1416 }
1417 
1418 void Assembler::andl(Address dst, int32_t imm32) {
1419   InstructionMark im(this);
1420   prefix(dst);
1421   emit_int8((unsigned char)0x81);
1422   emit_operand(rsp, dst, 4);
1423   emit_int32(imm32);
1424 }
1425 
1426 void Assembler::andl(Register dst, int32_t imm32) {
1427   prefix(dst);
1428   emit_arith(0x81, 0xE0, dst, imm32);
1429 }
1430 
</pre>
<hr />
<pre>
4086 void Assembler::pmaddwd(XMMRegister dst, XMMRegister src) {
4087   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
4088   InstructionAttr attributes(AVX_128bit, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4089   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4090   emit_int8((unsigned char)0xF5);
4091   emit_int8((unsigned char)(0xC0 | encode));
4092 }
4093 
4094 void Assembler::vpmaddwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4095   assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :
4096     (vector_len == AVX_256bit ? VM_Version::supports_avx2() :
4097     (vector_len == AVX_512bit ? VM_Version::supports_evex() : 0)), &quot;&quot;);
4098   InstructionAttr attributes(vector_len, /* rex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
4099   int encode = simd_prefix_and_encode(dst, nds, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
4100   emit_int8((unsigned char)0xF5);
4101   emit_int8((unsigned char)(0xC0 | encode));
4102 }
4103 
4104 void Assembler::evpdpwssd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
4105   assert(VM_Version::supports_evex(), &quot;&quot;);
<span class="line-modified">4106   assert(VM_Version::supports_avx512_vnni(), &quot;must support vnni&quot;);</span>
4107   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4108   attributes.set_is_evex_instruction();
4109   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4110   emit_int8(0x52);
4111   emit_int8((unsigned char)(0xC0 | encode));
4112 }
4113 
4114 // generic
4115 void Assembler::pop(Register dst) {
4116   int encode = prefix_and_encode(dst-&gt;encoding());
4117   emit_int8(0x58 | encode);
4118 }
4119 
4120 void Assembler::popcntl(Register dst, Address src) {
4121   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
4122   InstructionMark im(this);
4123   emit_int8((unsigned char)0xF3);
4124   prefix(src, dst);
4125   emit_int8(0x0F);
4126   emit_int8((unsigned char)0xB8);
4127   emit_operand(dst, src);
4128 }
4129 
4130 void Assembler::popcntl(Register dst, Register src) {
4131   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
4132   emit_int8((unsigned char)0xF3);
4133   int encode = prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding());
4134   emit_int8(0x0F);
4135   emit_int8((unsigned char)0xB8);
4136   emit_int8((unsigned char)(0xC0 | encode));
4137 }
4138 
4139 void Assembler::vpopcntd(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">4140   assert(VM_Version::supports_avx512_vpopcntdq(), &quot;must support vpopcntdq feature&quot;);</span>
4141   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
4142   attributes.set_is_evex_instruction();
4143   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
4144   emit_int8(0x55);
4145   emit_int8((unsigned char)(0xC0 | encode));
4146 }
4147 
4148 void Assembler::popf() {
4149   emit_int8((unsigned char)0x9D);
4150 }
4151 
4152 #ifndef _LP64 // no 32bit push/pop on amd64
4153 void Assembler::popl(Address dst) {
4154   // NOTE: this will adjust stack by 8byte on 64bits
4155   InstructionMark im(this);
4156   prefix(dst);
4157   emit_int8((unsigned char)0x8F);
4158   emit_operand(rax, dst);
4159 }
4160 #endif
</pre>
<hr />
<pre>
6527 
6528 void Assembler::vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {
6529   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6530   InstructionMark im(this);
6531   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6532   attributes.set_address_attributes(/* tuple_type */ EVEX_FV, /* input_size_in_bits */ EVEX_32bit);
6533   vex_prefix(src, nds-&gt;encoding(), dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6534   emit_int8((unsigned char)0xDB);
6535   emit_operand(dst, src);
6536 }
6537 
6538 void Assembler::vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6539   assert(VM_Version::supports_evex(), &quot;&quot;);
6540   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6541   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6542   emit_int8((unsigned char)0xDB);
6543   emit_int8((unsigned char)(0xC0 | encode));
6544 }
6545 
6546 void Assembler::vpshldvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
<span class="line-modified">6547   assert(VM_Version::supports_avx512_vbmi2(), &quot;requires vbmi2&quot;);</span>
6548   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6549   attributes.set_is_evex_instruction();
6550   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6551   emit_int8(0x71);
6552   emit_int8((unsigned char)(0xC0 | encode));
6553 }
6554 
6555 void Assembler::vpshrdvd(XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len) {
<span class="line-modified">6556   assert(VM_Version::supports_avx512_vbmi2(), &quot;requires vbmi2&quot;);</span>
6557   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6558   attributes.set_is_evex_instruction();
6559   int encode = vex_prefix_and_encode(dst-&gt;encoding(), src-&gt;encoding(), shift-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
6560   emit_int8(0x73);
6561   emit_int8((unsigned char)(0xC0 | encode));
6562 }
6563 
6564 void Assembler::pandn(XMMRegister dst, XMMRegister src) {
6565   NOT_LP64(assert(VM_Version::supports_sse2(), &quot;&quot;));
6566   InstructionAttr attributes(AVX_128bit, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6567   attributes.set_rex_vex_w_reverted();
6568   int encode = simd_prefix_and_encode(dst, dst, src, VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
6569   emit_int8((unsigned char)0xDF);
6570   emit_int8((unsigned char)(0xC0 | encode));
6571 }
6572 
6573 void Assembler::vpandn(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {
6574   assert(UseAVX &gt; 0, &quot;requires some form of AVX&quot;);
6575   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
6576   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &amp;attributes);
</pre>
<hr />
<pre>
7143 }
7144 
7145 void Assembler::evbroadcasti64x2(XMMRegister dst, Address src, int vector_len) {
7146   assert(vector_len != Assembler::AVX_128bit, &quot;&quot;);
7147   assert(VM_Version::supports_avx512dq(), &quot;&quot;);
7148   assert(dst != xnoreg, &quot;sanity&quot;);
7149   InstructionMark im(this);
7150   InstructionAttr attributes(vector_len, /* vex_w */ true, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7151   attributes.set_rex_vex_w_reverted();
7152   attributes.set_address_attributes(/* tuple_type */ EVEX_T2, /* input_size_in_bits */ EVEX_64bit);
7153   // swap src&lt;-&gt;dst for encoding
7154   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7155   emit_int8(0x5A);
7156   emit_operand(dst, src);
7157 }
7158 
7159 // scalar single/double precision replicate
7160 
7161 // duplicate single precision data from src into programmed locations in dest : requires AVX512VL
7162 void Assembler::vbroadcastss(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">7163   assert(VM_Version::supports_avx2(), &quot;&quot;);</span>
7164   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7165   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7166   emit_int8(0x18);
7167   emit_int8((unsigned char)(0xC0 | encode));
7168 }
7169 
7170 void Assembler::vbroadcastss(XMMRegister dst, Address src, int vector_len) {
7171   assert(VM_Version::supports_avx(), &quot;&quot;);
7172   assert(dst != xnoreg, &quot;sanity&quot;);
7173   InstructionMark im(this);
7174   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7175   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_32bit);
7176   // swap src&lt;-&gt;dst for encoding
7177   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7178   emit_int8(0x18);
7179   emit_operand(dst, src);
7180 }
7181 
7182 // duplicate double precision data from src into programmed locations in dest : requires AVX512VL
7183 void Assembler::vbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len) {
<span class="line-modified">7184   assert(VM_Version::supports_avx2(), &quot;&quot;);</span>
<span class="line-added">7185   assert(vector_len == AVX_256bit || vector_len == AVX_512bit, &quot;&quot;);</span>
7186   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7187   attributes.set_rex_vex_w_reverted();
7188   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7189   emit_int8(0x19);
7190   emit_int8((unsigned char)(0xC0 | encode));
7191 }
7192 
7193 void Assembler::vbroadcastsd(XMMRegister dst, Address src, int vector_len) {
7194   assert(VM_Version::supports_avx(), &quot;&quot;);
<span class="line-added">7195   assert(vector_len == AVX_256bit || vector_len == AVX_512bit, &quot;&quot;);</span>
7196   assert(dst != xnoreg, &quot;sanity&quot;);
7197   InstructionMark im(this);
7198   InstructionAttr attributes(vector_len, /* vex_w */ VM_Version::supports_evex(), /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7199   attributes.set_address_attributes(/* tuple_type */ EVEX_T1S, /* input_size_in_bits */ EVEX_64bit);
7200   attributes.set_rex_vex_w_reverted();
7201   // swap src&lt;-&gt;dst for encoding
7202   vex_prefix(src, 0, dst-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
7203   emit_int8(0x19);
7204   emit_operand(dst, src);
7205 }
7206 
7207 
7208 // gpr source broadcast forms
7209 
7210 // duplicate 1-byte integer data from src into programmed locations in dest : requires AVX512BW and AVX512VL
7211 void Assembler::evpbroadcastb(XMMRegister dst, Register src, int vector_len) {
7212   assert(VM_Version::supports_avx512bw(), &quot;&quot;);
7213   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ _legacy_mode_bw, /* no_mask_reg */ true, /* uses_vl */ true);
7214   attributes.set_is_evex_instruction();
7215   int encode = vex_prefix_and_encode(dst-&gt;encoding(), 0, src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &amp;attributes);
</pre>
<hr />
<pre>
7273 // Carry-Less Multiplication Quadword
7274 void Assembler::vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask) {
7275   assert(VM_Version::supports_avx() &amp;&amp; VM_Version::supports_clmul(), &quot;&quot;);
7276   InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ true);
7277   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7278   emit_int8(0x44);
7279   emit_int8((unsigned char)(0xC0 | encode));
7280   emit_int8((unsigned char)mask);
7281 }
7282 
7283 void Assembler::evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len) {
7284   assert(VM_Version::supports_avx512_vpclmulqdq(), &quot;Requires vector carryless multiplication support&quot;);
7285   InstructionAttr attributes(vector_len, /* vex_w */ false, /* legacy_mode */ false, /* no_mask_reg */ true, /* uses_vl */ true);
7286   attributes.set_is_evex_instruction();
7287   int encode = vex_prefix_and_encode(dst-&gt;encoding(), nds-&gt;encoding(), src-&gt;encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &amp;attributes);
7288   emit_int8(0x44);
7289   emit_int8((unsigned char)(0xC0 | encode));
7290   emit_int8((unsigned char)mask);
7291 }
7292 
<span class="line-modified">7293 void Assembler::vzeroupper_uncached() {</span>
7294   if (VM_Version::supports_vzeroupper()) {
7295     InstructionAttr attributes(AVX_128bit, /* vex_w */ false, /* legacy_mode */ true, /* no_mask_reg */ true, /* uses_vl */ false);
7296     (void)vex_prefix_and_encode(0, 0, 0, VEX_SIMD_NONE, VEX_OPCODE_0F, &amp;attributes);
7297     emit_int8(0x77);
7298   }
7299 }
7300 
7301 #ifndef _LP64
7302 // 32bit only pieces of the assembler
7303 
<span class="line-added">7304 void Assembler::vzeroupper() {</span>
<span class="line-added">7305   vzeroupper_uncached();</span>
<span class="line-added">7306 }</span>
<span class="line-added">7307 </span>
7308 void Assembler::cmp_literal32(Register src1, int32_t imm32, RelocationHolder const&amp; rspec) {
7309   // NO PREFIX AS NEVER 64BIT
7310   InstructionMark im(this);
7311   emit_int8((unsigned char)0x81);
7312   emit_int8((unsigned char)(0xF8 | src1-&gt;encoding()));
7313   emit_data(imm32, rspec, 0);
7314 }
7315 
7316 void Assembler::cmp_literal32(Address src1, int32_t imm32, RelocationHolder const&amp; rspec) {
7317   // NO PREFIX AS NEVER 64BIT (not even 32bit versions of 64bit regs
7318   InstructionMark im(this);
7319   emit_int8((unsigned char)0x81);
7320   emit_operand(rdi, src1);
7321   emit_data(imm32, rspec, 0);
7322 }
7323 
7324 // The 64-bit (32bit platform) cmpxchg compares the value at adr with the contents of rdx:rax,
7325 // and stores rcx:rbx into adr if so; otherwise, the value at adr is loaded
7326 // into rdx:rax.  The ZF is set if the compared values were equal, and cleared otherwise.
7327 void Assembler::cmpxchg8(Address adr) {
</pre>
<hr />
<pre>
9237   emit_int32(imm32);
9238 }
9239 
9240 void Assembler::orq(Register dst, int32_t imm32) {
9241   (void) prefixq_and_encode(dst-&gt;encoding());
9242   emit_arith(0x81, 0xC8, dst, imm32);
9243 }
9244 
9245 void Assembler::orq(Register dst, Address src) {
9246   InstructionMark im(this);
9247   prefixq(src, dst);
9248   emit_int8(0x0B);
9249   emit_operand(dst, src);
9250 }
9251 
9252 void Assembler::orq(Register dst, Register src) {
9253   (void) prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
9254   emit_arith(0x0B, 0xC0, dst, src);
9255 }
9256 





















9257 void Assembler::popcntq(Register dst, Address src) {
9258   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
9259   InstructionMark im(this);
9260   emit_int8((unsigned char)0xF3);
9261   prefixq(src, dst);
9262   emit_int8((unsigned char)0x0F);
9263   emit_int8((unsigned char)0xB8);
9264   emit_operand(dst, src);
9265 }
9266 
9267 void Assembler::popcntq(Register dst, Register src) {
9268   assert(VM_Version::supports_popcnt(), &quot;must support&quot;);
9269   emit_int8((unsigned char)0xF3);
9270   int encode = prefixq_and_encode(dst-&gt;encoding(), src-&gt;encoding());
9271   emit_int8((unsigned char)0x0F);
9272   emit_int8((unsigned char)0xB8);
9273   emit_int8((unsigned char)(0xC0 | encode));
9274 }
9275 
9276 void Assembler::popq(Address dst) {
9277   InstructionMark im(this);
9278   prefixq(dst);
9279   emit_int8((unsigned char)0x8F);
9280   emit_operand(rax, dst);
9281 }
9282 
<span class="line-added">9283 // Precomputable: popa, pusha, vzeroupper</span>
<span class="line-added">9284 </span>
<span class="line-added">9285 // The result of these routines are invariant from one invocation to another</span>
<span class="line-added">9286 // invocation for the duration of a run. Caching the result on bootstrap</span>
<span class="line-added">9287 // and copying it out on subsequent invocations can thus be beneficial</span>
<span class="line-added">9288 static bool     precomputed = false;</span>
<span class="line-added">9289 </span>
<span class="line-added">9290 static u_char* popa_code  = NULL;</span>
<span class="line-added">9291 static int     popa_len   = 0;</span>
<span class="line-added">9292 </span>
<span class="line-added">9293 static u_char* pusha_code = NULL;</span>
<span class="line-added">9294 static int     pusha_len  = 0;</span>
<span class="line-added">9295 </span>
<span class="line-added">9296 static u_char* vzup_code  = NULL;</span>
<span class="line-added">9297 static int     vzup_len   = 0;</span>
<span class="line-added">9298 </span>
<span class="line-added">9299 void Assembler::precompute_instructions() {</span>
<span class="line-added">9300   assert(!Universe::is_fully_initialized(), &quot;must still be single threaded&quot;);</span>
<span class="line-added">9301   guarantee(!precomputed, &quot;only once&quot;);</span>
<span class="line-added">9302   precomputed = true;</span>
<span class="line-added">9303   ResourceMark rm;</span>
<span class="line-added">9304 </span>
<span class="line-added">9305   // Make a temporary buffer big enough for the routines we&#39;re capturing</span>
<span class="line-added">9306   int size = 256;</span>
<span class="line-added">9307   char* tmp_code = NEW_RESOURCE_ARRAY(char, size);</span>
<span class="line-added">9308   CodeBuffer buffer((address)tmp_code, size);</span>
<span class="line-added">9309   MacroAssembler masm(&amp;buffer);</span>
<span class="line-added">9310 </span>
<span class="line-added">9311   address begin_popa  = masm.code_section()-&gt;end();</span>
<span class="line-added">9312   masm.popa_uncached();</span>
<span class="line-added">9313   address end_popa    = masm.code_section()-&gt;end();</span>
<span class="line-added">9314   masm.pusha_uncached();</span>
<span class="line-added">9315   address end_pusha   = masm.code_section()-&gt;end();</span>
<span class="line-added">9316   masm.vzeroupper_uncached();</span>
<span class="line-added">9317   address end_vzup    = masm.code_section()-&gt;end();</span>
<span class="line-added">9318 </span>
<span class="line-added">9319   // Save the instructions to permanent buffers.</span>
<span class="line-added">9320   popa_len = (int)(end_popa - begin_popa);</span>
<span class="line-added">9321   popa_code = NEW_C_HEAP_ARRAY(u_char, popa_len, mtInternal);</span>
<span class="line-added">9322   memcpy(popa_code, begin_popa, popa_len);</span>
<span class="line-added">9323 </span>
<span class="line-added">9324   pusha_len = (int)(end_pusha - end_popa);</span>
<span class="line-added">9325   pusha_code = NEW_C_HEAP_ARRAY(u_char, pusha_len, mtInternal);</span>
<span class="line-added">9326   memcpy(pusha_code, end_popa, pusha_len);</span>
<span class="line-added">9327 </span>
<span class="line-added">9328   vzup_len = (int)(end_vzup - end_pusha);</span>
<span class="line-added">9329   if (vzup_len &gt; 0) {</span>
<span class="line-added">9330     vzup_code = NEW_C_HEAP_ARRAY(u_char, vzup_len, mtInternal);</span>
<span class="line-added">9331     memcpy(vzup_code, end_pusha, vzup_len);</span>
<span class="line-added">9332   } else {</span>
<span class="line-added">9333     vzup_code = pusha_code; // dummy</span>
<span class="line-added">9334   }</span>
<span class="line-added">9335 </span>
<span class="line-added">9336   assert(masm.code()-&gt;total_oop_size() == 0 &amp;&amp;</span>
<span class="line-added">9337          masm.code()-&gt;total_metadata_size() == 0 &amp;&amp;</span>
<span class="line-added">9338          masm.code()-&gt;total_relocation_size() == 0,</span>
<span class="line-added">9339          &quot;pre-computed code can&#39;t reference oops, metadata or contain relocations&quot;);</span>
<span class="line-added">9340 }</span>
<span class="line-added">9341 </span>
<span class="line-added">9342 static void emit_copy(CodeSection* code_section, u_char* src, int src_len) {</span>
<span class="line-added">9343   assert(src != NULL, &quot;code to copy must have been pre-computed&quot;);</span>
<span class="line-added">9344   assert(code_section-&gt;limit() - code_section-&gt;end() &gt; src_len, &quot;code buffer not large enough&quot;);</span>
<span class="line-added">9345   address end = code_section-&gt;end();</span>
<span class="line-added">9346   memcpy(end, src, src_len);</span>
<span class="line-added">9347   code_section-&gt;set_end(end + src_len);</span>
<span class="line-added">9348 }</span>
<span class="line-added">9349 </span>
<span class="line-added">9350 void Assembler::popa() { // 64bit</span>
<span class="line-added">9351   emit_copy(code_section(), popa_code, popa_len);</span>
<span class="line-added">9352 }</span>
<span class="line-added">9353 </span>
<span class="line-added">9354 void Assembler::popa_uncached() { // 64bit</span>
<span class="line-added">9355   movq(r15, Address(rsp, 0));</span>
<span class="line-added">9356   movq(r14, Address(rsp, wordSize));</span>
<span class="line-added">9357   movq(r13, Address(rsp, 2 * wordSize));</span>
<span class="line-added">9358   movq(r12, Address(rsp, 3 * wordSize));</span>
<span class="line-added">9359   movq(r11, Address(rsp, 4 * wordSize));</span>
<span class="line-added">9360   movq(r10, Address(rsp, 5 * wordSize));</span>
<span class="line-added">9361   movq(r9,  Address(rsp, 6 * wordSize));</span>
<span class="line-added">9362   movq(r8,  Address(rsp, 7 * wordSize));</span>
<span class="line-added">9363   movq(rdi, Address(rsp, 8 * wordSize));</span>
<span class="line-added">9364   movq(rsi, Address(rsp, 9 * wordSize));</span>
<span class="line-added">9365   movq(rbp, Address(rsp, 10 * wordSize));</span>
<span class="line-added">9366   // skip rsp</span>
<span class="line-added">9367   movq(rbx, Address(rsp, 12 * wordSize));</span>
<span class="line-added">9368   movq(rdx, Address(rsp, 13 * wordSize));</span>
<span class="line-added">9369   movq(rcx, Address(rsp, 14 * wordSize));</span>
<span class="line-added">9370   movq(rax, Address(rsp, 15 * wordSize));</span>
<span class="line-added">9371 </span>
<span class="line-added">9372   addq(rsp, 16 * wordSize);</span>
<span class="line-added">9373 }</span>
<span class="line-added">9374 </span>
9375 void Assembler::pusha() { // 64bit
<span class="line-added">9376   emit_copy(code_section(), pusha_code, pusha_len);</span>
<span class="line-added">9377 }</span>
<span class="line-added">9378 </span>
<span class="line-added">9379 void Assembler::pusha_uncached() { // 64bit</span>
9380   // we have to store original rsp.  ABI says that 128 bytes
9381   // below rsp are local scratch.
9382   movq(Address(rsp, -5 * wordSize), rsp);
9383 
9384   subq(rsp, 16 * wordSize);
9385 
9386   movq(Address(rsp, 15 * wordSize), rax);
9387   movq(Address(rsp, 14 * wordSize), rcx);
9388   movq(Address(rsp, 13 * wordSize), rdx);
9389   movq(Address(rsp, 12 * wordSize), rbx);
9390   // skip rsp
9391   movq(Address(rsp, 10 * wordSize), rbp);
9392   movq(Address(rsp, 9 * wordSize), rsi);
9393   movq(Address(rsp, 8 * wordSize), rdi);
9394   movq(Address(rsp, 7 * wordSize), r8);
9395   movq(Address(rsp, 6 * wordSize), r9);
9396   movq(Address(rsp, 5 * wordSize), r10);
9397   movq(Address(rsp, 4 * wordSize), r11);
9398   movq(Address(rsp, 3 * wordSize), r12);
9399   movq(Address(rsp, 2 * wordSize), r13);
9400   movq(Address(rsp, wordSize), r14);
9401   movq(Address(rsp, 0), r15);
9402 }
9403 
<span class="line-added">9404 void Assembler::vzeroupper() {</span>
<span class="line-added">9405   emit_copy(code_section(), vzup_code, vzup_len);</span>
<span class="line-added">9406 }</span>
<span class="line-added">9407 </span>
9408 void Assembler::pushq(Address src) {
9409   InstructionMark im(this);
9410   prefixq(src);
9411   emit_int8((unsigned char)0xFF);
9412   emit_operand(rsi, src);
9413 }
9414 
9415 void Assembler::rclq(Register dst, int imm8) {
9416   assert(isShiftCount(imm8 &gt;&gt; 1), &quot;illegal shift count&quot;);
9417   int encode = prefixq_and_encode(dst-&gt;encoding());
9418   if (imm8 == 1) {
9419     emit_int8((unsigned char)0xD1);
9420     emit_int8((unsigned char)(0xD0 | encode));
9421   } else {
9422     emit_int8((unsigned char)0xC1);
9423     emit_int8((unsigned char)(0xD0 | encode));
9424     emit_int8(imm8);
9425   }
9426 }
9427 
</pre>
</td>
</tr>
</table>
<center><a href="../sparc/vm_version_sparc.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>