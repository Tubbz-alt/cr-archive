<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/opto/loopnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciMethodData.hpp&quot;
  27 #include &quot;compiler/compileLog.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  30 #include &quot;libadt/vectset.hpp&quot;
  31 #include &quot;memory/allocation.inline.hpp&quot;
  32 #include &quot;memory/resourceArea.hpp&quot;
  33 #include &quot;opto/addnode.hpp&quot;
  34 #include &quot;opto/callnode.hpp&quot;
  35 #include &quot;opto/connode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
  37 #include &quot;opto/divnode.hpp&quot;
  38 #include &quot;opto/idealGraphPrinter.hpp&quot;
  39 #include &quot;opto/loopnode.hpp&quot;
  40 #include &quot;opto/mulnode.hpp&quot;
  41 #include &quot;opto/rootnode.hpp&quot;
  42 #include &quot;opto/superword.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 
  45 //=============================================================================
  46 //--------------------------is_cloop_ind_var-----------------------------------
  47 // Determine if a node is a counted loop induction variable.
  48 // NOTE: The method is declared in &quot;node.hpp&quot;.
  49 bool Node::is_cloop_ind_var() const {
  50   return (is_Phi() &amp;&amp; !as_Phi()-&gt;is_copy() &amp;&amp;
  51           as_Phi()-&gt;region()-&gt;is_CountedLoop() &amp;&amp;
  52           as_Phi()-&gt;region()-&gt;as_CountedLoop()-&gt;phi() == this);
  53 }
  54 
  55 //=============================================================================
  56 //------------------------------dump_spec--------------------------------------
  57 // Dump special per-node info
  58 #ifndef PRODUCT
  59 void LoopNode::dump_spec(outputStream *st) const {
  60   if (is_inner_loop()) st-&gt;print( &quot;inner &quot; );
  61   if (is_partial_peel_loop()) st-&gt;print( &quot;partial_peel &quot; );
  62   if (partial_peel_has_failed()) st-&gt;print( &quot;partial_peel_failed &quot; );
  63 }
  64 #endif
  65 
  66 //------------------------------is_valid_counted_loop-------------------------
  67 bool LoopNode::is_valid_counted_loop() const {
  68   if (is_CountedLoop()) {
  69     CountedLoopNode*    l  = as_CountedLoop();
  70     CountedLoopEndNode* le = l-&gt;loopexit_or_null();
  71     if (le != NULL &amp;&amp;
  72         le-&gt;proj_out_or_null(1 /* true */) == l-&gt;in(LoopNode::LoopBackControl)) {
  73       Node* phi  = l-&gt;phi();
  74       Node* exit = le-&gt;proj_out_or_null(0 /* false */);
  75       if (exit != NULL &amp;&amp; exit-&gt;Opcode() == Op_IfFalse &amp;&amp;
  76           phi != NULL &amp;&amp; phi-&gt;is_Phi() &amp;&amp;
  77           phi-&gt;in(LoopNode::LoopBackControl) == l-&gt;incr() &amp;&amp;
  78           le-&gt;loopnode() == l &amp;&amp; le-&gt;stride_is_con()) {
  79         return true;
  80       }
  81     }
  82   }
  83   return false;
  84 }
  85 
  86 //------------------------------get_early_ctrl---------------------------------
  87 // Compute earliest legal control
  88 Node *PhaseIdealLoop::get_early_ctrl( Node *n ) {
  89   assert( !n-&gt;is_Phi() &amp;&amp; !n-&gt;is_CFG(), &quot;this code only handles data nodes&quot; );
  90   uint i;
  91   Node *early;
  92   if (n-&gt;in(0) &amp;&amp; !n-&gt;is_expensive()) {
  93     early = n-&gt;in(0);
  94     if (!early-&gt;is_CFG()) // Might be a non-CFG multi-def
  95       early = get_ctrl(early);        // So treat input as a straight data input
  96     i = 1;
  97   } else {
  98     early = get_ctrl(n-&gt;in(1));
  99     i = 2;
 100   }
 101   uint e_d = dom_depth(early);
 102   assert( early, &quot;&quot; );
 103   for (; i &lt; n-&gt;req(); i++) {
 104     Node *cin = get_ctrl(n-&gt;in(i));
 105     assert( cin, &quot;&quot; );
 106     // Keep deepest dominator depth
 107     uint c_d = dom_depth(cin);
 108     if (c_d &gt; e_d) {           // Deeper guy?
 109       early = cin;              // Keep deepest found so far
 110       e_d = c_d;
 111     } else if (c_d == e_d &amp;&amp;    // Same depth?
 112                early != cin) { // If not equal, must use slower algorithm
 113       // If same depth but not equal, one _must_ dominate the other
 114       // and we want the deeper (i.e., dominated) guy.
 115       Node *n1 = early;
 116       Node *n2 = cin;
 117       while (1) {
 118         n1 = idom(n1);          // Walk up until break cycle
 119         n2 = idom(n2);
 120         if (n1 == cin ||        // Walked early up to cin
 121             dom_depth(n2) &lt; c_d)
 122           break;                // early is deeper; keep him
 123         if (n2 == early ||      // Walked cin up to early
 124             dom_depth(n1) &lt; c_d) {
 125           early = cin;          // cin is deeper; keep him
 126           break;
 127         }
 128       }
 129       e_d = dom_depth(early);   // Reset depth register cache
 130     }
 131   }
 132 
 133   // Return earliest legal location
 134   assert(early == find_non_split_ctrl(early), &quot;unexpected early control&quot;);
 135 
 136   if (n-&gt;is_expensive() &amp;&amp; !_verify_only &amp;&amp; !_verify_me) {
 137     assert(n-&gt;in(0), &quot;should have control input&quot;);
 138     early = get_early_ctrl_for_expensive(n, early);
 139   }
 140 
 141   return early;
 142 }
 143 
 144 //------------------------------get_early_ctrl_for_expensive---------------------------------
 145 // Move node up the dominator tree as high as legal while still beneficial
 146 Node *PhaseIdealLoop::get_early_ctrl_for_expensive(Node *n, Node* earliest) {
 147   assert(n-&gt;in(0) &amp;&amp; n-&gt;is_expensive(), &quot;expensive node with control input here&quot;);
 148   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
 149 
 150   Node* ctl = n-&gt;in(0);
 151   assert(ctl-&gt;is_CFG(), &quot;expensive input 0 must be cfg&quot;);
 152   uint min_dom_depth = dom_depth(earliest);
 153 #ifdef ASSERT
 154   if (!is_dominator(ctl, earliest) &amp;&amp; !is_dominator(earliest, ctl)) {
 155     dump_bad_graph(&quot;Bad graph detected in get_early_ctrl_for_expensive&quot;, n, earliest, ctl);
 156     assert(false, &quot;Bad graph detected in get_early_ctrl_for_expensive&quot;);
 157   }
 158 #endif
 159   if (dom_depth(ctl) &lt; min_dom_depth) {
 160     return earliest;
 161   }
 162 
 163   while (1) {
 164     Node *next = ctl;
 165     // Moving the node out of a loop on the projection of a If
 166     // confuses loop predication. So once we hit a Loop in a If branch
 167     // that doesn&#39;t branch to an UNC, we stop. The code that process
 168     // expensive nodes will notice the loop and skip over it to try to
 169     // move the node further up.
 170     if (ctl-&gt;is_CountedLoop() &amp;&amp; ctl-&gt;in(1) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0)-&gt;is_If()) {
 171       if (!ctl-&gt;in(1)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 172         break;
 173       }
 174       next = idom(ctl-&gt;in(1)-&gt;in(0));
 175     } else if (ctl-&gt;is_Proj()) {
 176       // We only move it up along a projection if the projection is
 177       // the single control projection for its parent: same code path,
 178       // if it&#39;s a If with UNC or fallthrough of a call.
 179       Node* parent_ctl = ctl-&gt;in(0);
 180       if (parent_ctl == NULL) {
 181         break;
 182       } else if (parent_ctl-&gt;is_CountedLoopEnd() &amp;&amp; parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode() != NULL) {
 183         next = parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode()-&gt;init_control();
 184       } else if (parent_ctl-&gt;is_If()) {
 185         if (!ctl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 186           break;
 187         }
 188         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 189         next = idom(parent_ctl);
 190       } else if (ctl-&gt;is_CatchProj()) {
 191         if (ctl-&gt;as_Proj()-&gt;_con != CatchProjNode::fall_through_index) {
 192           break;
 193         }
 194         assert(parent_ctl-&gt;in(0)-&gt;in(0)-&gt;is_Call(), &quot;strange graph&quot;);
 195         next = parent_ctl-&gt;in(0)-&gt;in(0)-&gt;in(0);
 196       } else {
 197         // Check if parent control has a single projection (this
 198         // control is the only possible successor of the parent
 199         // control). If so, we can try to move the node above the
 200         // parent control.
 201         int nb_ctl_proj = 0;
 202         for (DUIterator_Fast imax, i = parent_ctl-&gt;fast_outs(imax); i &lt; imax; i++) {
 203           Node *p = parent_ctl-&gt;fast_out(i);
 204           if (p-&gt;is_Proj() &amp;&amp; p-&gt;is_CFG()) {
 205             nb_ctl_proj++;
 206             if (nb_ctl_proj &gt; 1) {
 207               break;
 208             }
 209           }
 210         }
 211 
 212         if (nb_ctl_proj &gt; 1) {
 213           break;
 214         }
 215         assert(parent_ctl-&gt;is_Start() || parent_ctl-&gt;is_MemBar() || parent_ctl-&gt;is_Call() ||
 216                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(parent_ctl), &quot;unexpected node&quot;);
 217         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 218         next = idom(parent_ctl);
 219       }
 220     } else {
 221       next = idom(ctl);
 222     }
 223     if (next-&gt;is_Root() || next-&gt;is_Start() || dom_depth(next) &lt; min_dom_depth) {
 224       break;
 225     }
 226     ctl = next;
 227   }
 228 
 229   if (ctl != n-&gt;in(0)) {
 230     _igvn.replace_input_of(n, 0, ctl);
 231     _igvn.hash_insert(n);
 232   }
 233 
 234   return ctl;
 235 }
 236 
 237 
 238 //------------------------------set_early_ctrl---------------------------------
 239 // Set earliest legal control
 240 void PhaseIdealLoop::set_early_ctrl( Node *n ) {
 241   Node *early = get_early_ctrl(n);
 242 
 243   // Record earliest legal location
 244   set_ctrl(n, early);
 245 }
 246 
 247 //------------------------------set_subtree_ctrl-------------------------------
 248 // set missing _ctrl entries on new nodes
 249 void PhaseIdealLoop::set_subtree_ctrl( Node *n ) {
 250   // Already set?  Get out.
 251   if( _nodes[n-&gt;_idx] ) return;
 252   // Recursively set _nodes array to indicate where the Node goes
 253   uint i;
 254   for( i = 0; i &lt; n-&gt;req(); ++i ) {
 255     Node *m = n-&gt;in(i);
 256     if( m &amp;&amp; m != C-&gt;root() )
 257       set_subtree_ctrl( m );
 258   }
 259 
 260   // Fixup self
 261   set_early_ctrl( n );
 262 }
 263 
 264 // Create a skeleton strip mined outer loop: a Loop head before the
 265 // inner strip mined loop, a safepoint and an exit condition guarded
 266 // by an opaque node after the inner strip mined loop with a backedge
 267 // to the loop head. The inner strip mined loop is left as it is. Only
 268 // once loop optimizations are over, do we adjust the inner loop exit
 269 // condition to limit its number of iterations, set the outer loop
 270 // exit condition and add Phis to the outer loop head. Some loop
 271 // optimizations that operate on the inner strip mined loop need to be
 272 // aware of the outer strip mined loop: loop unswitching needs to
 273 // clone the outer loop as well as the inner, unrolling needs to only
 274 // clone the inner loop etc. No optimizations need to change the outer
 275 // strip mined loop as it is only a skeleton.
 276 IdealLoopTree* PhaseIdealLoop::create_outer_strip_mined_loop(BoolNode *test, Node *cmp, Node *init_control,
 277                                                              IdealLoopTree* loop, float cl_prob, float le_fcnt,
 278                                                              Node*&amp; entry_control, Node*&amp; iffalse) {
 279   Node* outer_test = _igvn.intcon(0);
 280   set_ctrl(outer_test, C-&gt;root());
 281   Node *orig = iffalse;
 282   iffalse = iffalse-&gt;clone();
 283   _igvn.register_new_node_with_optimizer(iffalse);
 284   set_idom(iffalse, idom(orig), dom_depth(orig));
 285 
 286   IfNode *outer_le = new OuterStripMinedLoopEndNode(iffalse, outer_test, cl_prob, le_fcnt);
 287   Node *outer_ift = new IfTrueNode (outer_le);
 288   Node* outer_iff = orig;
 289   _igvn.replace_input_of(outer_iff, 0, outer_le);
 290 
 291   LoopNode *outer_l = new OuterStripMinedLoopNode(C, init_control, outer_ift);
 292   entry_control = outer_l;
 293 
 294   IdealLoopTree* outer_ilt = new IdealLoopTree(this, outer_l, outer_ift);
 295   IdealLoopTree* parent = loop-&gt;_parent;
 296   IdealLoopTree* sibling = parent-&gt;_child;
 297   if (sibling == loop) {
 298     parent-&gt;_child = outer_ilt;
 299   } else {
 300     while (sibling-&gt;_next != loop) {
 301       sibling = sibling-&gt;_next;
 302     }
 303     sibling-&gt;_next = outer_ilt;
 304   }
 305   outer_ilt-&gt;_next = loop-&gt;_next;
 306   outer_ilt-&gt;_parent = parent;
 307   outer_ilt-&gt;_child = loop;
 308   outer_ilt-&gt;_nest = loop-&gt;_nest;
 309   loop-&gt;_parent = outer_ilt;
 310   loop-&gt;_next = NULL;
 311   loop-&gt;_nest++;
 312 
 313   set_loop(iffalse, outer_ilt);
 314   register_control(outer_le, outer_ilt, iffalse);
 315   register_control(outer_ift, outer_ilt, outer_le);
 316   set_idom(outer_iff, outer_le, dom_depth(outer_le));
 317   _igvn.register_new_node_with_optimizer(outer_l);
 318   set_loop(outer_l, outer_ilt);
 319   set_idom(outer_l, init_control, dom_depth(init_control)+1);
 320 
 321   return outer_ilt;
 322 }
 323 
 324 void PhaseIdealLoop::insert_loop_limit_check(ProjNode* limit_check_proj, Node* cmp_limit, Node* bol) {
 325   Node* new_predicate_proj = create_new_if_for_predicate(limit_check_proj, NULL,
 326                                                          Deoptimization::Reason_loop_limit_check,
 327                                                          Op_If);
 328   Node* iff = new_predicate_proj-&gt;in(0);
 329   assert(iff-&gt;Opcode() == Op_If, &quot;bad graph shape&quot;);
 330   Node* conv = iff-&gt;in(1);
 331   assert(conv-&gt;Opcode() == Op_Conv2B, &quot;bad graph shape&quot;);
 332   Node* opaq = conv-&gt;in(1);
 333   assert(opaq-&gt;Opcode() == Op_Opaque1, &quot;bad graph shape&quot;);
 334   cmp_limit = _igvn.register_new_node_with_optimizer(cmp_limit);
 335   bol = _igvn.register_new_node_with_optimizer(bol);
 336   set_subtree_ctrl(bol);
 337   _igvn.replace_input_of(iff, 1, bol);
 338 
 339 #ifndef PRODUCT
 340   // report that the loop predication has been actually performed
 341   // for this loop
 342   if (TraceLoopLimitCheck) {
 343     tty-&gt;print_cr(&quot;Counted Loop Limit Check generated:&quot;);
 344     debug_only( bol-&gt;dump(2); )
 345   }
 346 #endif
 347 }
 348 
 349 //------------------------------is_counted_loop--------------------------------
 350 bool PhaseIdealLoop::is_counted_loop(Node* x, IdealLoopTree*&amp; loop) {
 351   PhaseGVN *gvn = &amp;_igvn;
 352 
 353   // Counted loop head must be a good RegionNode with only 3 not NULL
 354   // control input edges: Self, Entry, LoopBack.
 355   if (x-&gt;in(LoopNode::Self) == NULL || x-&gt;req() != 3 || loop-&gt;_irreducible) {
 356     return false;
 357   }
 358   Node *init_control = x-&gt;in(LoopNode::EntryControl);
 359   Node *back_control = x-&gt;in(LoopNode::LoopBackControl);
 360   if (init_control == NULL || back_control == NULL)    // Partially dead
 361     return false;
 362   // Must also check for TOP when looking for a dead loop
 363   if (init_control-&gt;is_top() || back_control-&gt;is_top())
 364     return false;
 365 
 366   // Allow funny placement of Safepoint
 367   if (back_control-&gt;Opcode() == Op_SafePoint) {
 368     if (LoopStripMiningIter != 0) {
 369       // Leaving the safepoint on the backedge and creating a
 370       // CountedLoop will confuse optimizations. We can&#39;t move the
 371       // safepoint around because its jvm state wouldn&#39;t match a new
 372       // location. Give up on that loop.
 373       return false;
 374     }
 375     back_control = back_control-&gt;in(TypeFunc::Control);
 376   }
 377 
 378   // Controlling test for loop
 379   Node *iftrue = back_control;
 380   uint iftrue_op = iftrue-&gt;Opcode();
 381   if (iftrue_op != Op_IfTrue &amp;&amp;
 382       iftrue_op != Op_IfFalse)
 383     // I have a weird back-control.  Probably the loop-exit test is in
 384     // the middle of the loop and I am looking at some trailing control-flow
 385     // merge point.  To fix this I would have to partially peel the loop.
 386     return false; // Obscure back-control
 387 
 388   // Get boolean guarding loop-back test
 389   Node *iff = iftrue-&gt;in(0);
 390   if (get_loop(iff) != loop || !iff-&gt;in(1)-&gt;is_Bool())
 391     return false;
 392   BoolNode *test = iff-&gt;in(1)-&gt;as_Bool();
 393   BoolTest::mask bt = test-&gt;_test._test;
 394   float cl_prob = iff-&gt;as_If()-&gt;_prob;
 395   if (iftrue_op == Op_IfFalse) {
 396     bt = BoolTest(bt).negate();
 397     cl_prob = 1.0 - cl_prob;
 398   }
 399   // Get backedge compare
 400   Node *cmp = test-&gt;in(1);
 401   int cmp_op = cmp-&gt;Opcode();
 402   if (cmp_op != Op_CmpI)
 403     return false;                // Avoid pointer &amp; float compares
 404 
 405   // Find the trip-counter increment &amp; limit.  Limit must be loop invariant.
 406   Node *incr  = cmp-&gt;in(1);
 407   Node *limit = cmp-&gt;in(2);
 408 
 409   // ---------
 410   // need &#39;loop()&#39; test to tell if limit is loop invariant
 411   // ---------
 412 
 413   if (!is_member(loop, get_ctrl(incr))) { // Swapped trip counter and limit?
 414     Node *tmp = incr;            // Then reverse order into the CmpI
 415     incr = limit;
 416     limit = tmp;
 417     bt = BoolTest(bt).commute(); // And commute the exit test
 418   }
 419   if (is_member(loop, get_ctrl(limit))) // Limit must be loop-invariant
 420     return false;
 421   if (!is_member(loop, get_ctrl(incr))) // Trip counter must be loop-variant
 422     return false;
 423 
 424   Node* phi_incr = NULL;
 425   // Trip-counter increment must be commutative &amp; associative.
 426   if (incr-&gt;Opcode() == Op_CastII) {
 427     incr = incr-&gt;in(1);
 428   }
 429   if (incr-&gt;is_Phi()) {
 430     if (incr-&gt;as_Phi()-&gt;region() != x || incr-&gt;req() != 3)
 431       return false; // Not simple trip counter expression
 432     phi_incr = incr;
 433     incr = phi_incr-&gt;in(LoopNode::LoopBackControl); // Assume incr is on backedge of Phi
 434     if (!is_member(loop, get_ctrl(incr))) // Trip counter must be loop-variant
 435       return false;
 436   }
 437 
 438   Node* trunc1 = NULL;
 439   Node* trunc2 = NULL;
 440   const TypeInt* iv_trunc_t = NULL;
 441   Node* orig_incr = incr;
 442   if (!(incr = CountedLoopNode::match_incr_with_optional_truncation(incr, &amp;trunc1, &amp;trunc2, &amp;iv_trunc_t))) {
 443     return false; // Funny increment opcode
 444   }
 445   assert(incr-&gt;Opcode() == Op_AddI, &quot;wrong increment code&quot;);
 446 
 447   const TypeInt* limit_t = gvn-&gt;type(limit)-&gt;is_int();
 448   if (trunc1 != NULL) {
 449     // When there is a truncation, we must be sure that after the truncation
 450     // the trip counter will end up higher than the limit, otherwise we are looking
 451     // at an endless loop. Can happen with range checks.
 452 
 453     // Example:
 454     // int i = 0;
 455     // while (true)
 456     //    sum + = array[i];
 457     //    i++;
 458     //    i = i &amp;&amp; 0x7fff;
 459     //  }
 460     //
 461     // If the array is shorter than 0x8000 this exits through a AIOOB
 462     //  - Counted loop transformation is ok
 463     // If the array is longer then this is an endless loop
 464     //  - No transformation can be done.
 465 
 466     const TypeInt* incr_t = gvn-&gt;type(orig_incr)-&gt;is_int();
 467     if (limit_t-&gt;_hi &gt; incr_t-&gt;_hi) {
 468       // if the limit can have a higher value than the increment (before the phi)
 469       return false;
 470     }
 471   }
 472 
 473   // Get merge point
 474   Node *xphi = incr-&gt;in(1);
 475   Node *stride = incr-&gt;in(2);
 476   if (!stride-&gt;is_Con()) {     // Oops, swap these
 477     if (!xphi-&gt;is_Con())       // Is the other guy a constant?
 478       return false;             // Nope, unknown stride, bail out
 479     Node *tmp = xphi;           // &#39;incr&#39; is commutative, so ok to swap
 480     xphi = stride;
 481     stride = tmp;
 482   }
 483   if (xphi-&gt;Opcode() == Op_CastII) {
 484     xphi = xphi-&gt;in(1);
 485   }
 486   // Stride must be constant
 487   int stride_con = stride-&gt;get_int();
 488   if (stride_con == 0)
 489     return false; // missed some peephole opt
 490 
 491   if (!xphi-&gt;is_Phi())
 492     return false; // Too much math on the trip counter
 493   if (phi_incr != NULL &amp;&amp; phi_incr != xphi)
 494     return false;
 495   PhiNode *phi = xphi-&gt;as_Phi();
 496 
 497   // Phi must be of loop header; backedge must wrap to increment
 498   if (phi-&gt;region() != x)
 499     return false;
 500   if ((trunc1 == NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != incr) ||
 501       (trunc1 != NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != trunc1)) {
 502     return false;
 503   }
 504   Node *init_trip = phi-&gt;in(LoopNode::EntryControl);
 505 
 506   // If iv trunc type is smaller than int, check for possible wrap.
 507   if (!TypeInt::INT-&gt;higher_equal(iv_trunc_t)) {
 508     assert(trunc1 != NULL, &quot;must have found some truncation&quot;);
 509 
 510     // Get a better type for the phi (filtered thru if&#39;s)
 511     const TypeInt* phi_ft = filtered_type(phi);
 512 
 513     // Can iv take on a value that will wrap?
 514     //
 515     // Ensure iv&#39;s limit is not within &quot;stride&quot; of the wrap value.
 516     //
 517     // Example for &quot;short&quot; type
 518     //    Truncation ensures value is in the range -32768..32767 (iv_trunc_t)
 519     //    If the stride is +10, then the last value of the induction
 520     //    variable before the increment (phi_ft-&gt;_hi) must be
 521     //    &lt;= 32767 - 10 and (phi_ft-&gt;_lo) must be &gt;= -32768 to
 522     //    ensure no truncation occurs after the increment.
 523 
 524     if (stride_con &gt; 0) {
 525       if (iv_trunc_t-&gt;_hi - phi_ft-&gt;_hi &lt; stride_con ||
 526           iv_trunc_t-&gt;_lo &gt; phi_ft-&gt;_lo) {
 527         return false;  // truncation may occur
 528       }
 529     } else if (stride_con &lt; 0) {
 530       if (iv_trunc_t-&gt;_lo - phi_ft-&gt;_lo &gt; stride_con ||
 531           iv_trunc_t-&gt;_hi &lt; phi_ft-&gt;_hi) {
 532         return false;  // truncation may occur
 533       }
 534     }
 535     // No possibility of wrap so truncation can be discarded
 536     // Promote iv type to Int
 537   } else {
 538     assert(trunc1 == NULL &amp;&amp; trunc2 == NULL, &quot;no truncation for int&quot;);
 539   }
 540 
 541   // If the condition is inverted and we will be rolling
 542   // through MININT to MAXINT, then bail out.
 543   if (bt == BoolTest::eq || // Bail out, but this loop trips at most twice!
 544       // Odd stride
 545       (bt == BoolTest::ne &amp;&amp; stride_con != 1 &amp;&amp; stride_con != -1) ||
 546       // Count down loop rolls through MAXINT
 547       ((bt == BoolTest::le || bt == BoolTest::lt) &amp;&amp; stride_con &lt; 0) ||
 548       // Count up loop rolls through MININT
 549       ((bt == BoolTest::ge || bt == BoolTest::gt) &amp;&amp; stride_con &gt; 0)) {
 550     return false; // Bail out
 551   }
 552 
 553   const TypeInt* init_t = gvn-&gt;type(init_trip)-&gt;is_int();
 554 
 555   if (stride_con &gt; 0) {
 556     jlong init_p = (jlong)init_t-&gt;_lo + stride_con;
 557     if (init_p &gt; (jlong)max_jint || init_p &gt; (jlong)limit_t-&gt;_hi)
 558       return false; // cyclic loop or this loop trips only once
 559   } else {
 560     jlong init_p = (jlong)init_t-&gt;_hi + stride_con;
 561     if (init_p &lt; (jlong)min_jint || init_p &lt; (jlong)limit_t-&gt;_lo)
 562       return false; // cyclic loop or this loop trips only once
 563   }
 564 
 565   if (phi_incr != NULL &amp;&amp; bt != BoolTest::ne) {
 566     // check if there is a possiblity of IV overflowing after the first increment
 567     if (stride_con &gt; 0) {
 568       if (init_t-&gt;_hi &gt; max_jint - stride_con) {
 569         return false;
 570       }
 571     } else {
 572       if (init_t-&gt;_lo &lt; min_jint - stride_con) {
 573         return false;
 574       }
 575     }
 576   }
 577 
 578   // =================================================
 579   // ---- SUCCESS!   Found A Trip-Counted Loop!  -----
 580   //
 581   assert(x-&gt;Opcode() == Op_Loop, &quot;regular loops only&quot;);
 582   C-&gt;print_method(PHASE_BEFORE_CLOOPS, 3);
 583 
 584   Node *hook = new Node(6);
 585 
 586   // ===================================================
 587   // Generate loop limit check to avoid integer overflow
 588   // in cases like next (cyclic loops):
 589   //
 590   // for (i=0; i &lt;= max_jint; i++) {}
 591   // for (i=0; i &lt;  max_jint; i+=2) {}
 592   //
 593   //
 594   // Limit check predicate depends on the loop test:
 595   //
 596   // for(;i != limit; i++)       --&gt; limit &lt;= (max_jint)
 597   // for(;i &lt;  limit; i+=stride) --&gt; limit &lt;= (max_jint - stride + 1)
 598   // for(;i &lt;= limit; i+=stride) --&gt; limit &lt;= (max_jint - stride    )
 599   //
 600 
 601   // Check if limit is excluded to do more precise int overflow check.
 602   bool incl_limit = (bt == BoolTest::le || bt == BoolTest::ge);
 603   int stride_m  = stride_con - (incl_limit ? 0 : (stride_con &gt; 0 ? 1 : -1));
 604 
 605   // If compare points directly to the phi we need to adjust
 606   // the compare so that it points to the incr. Limit have
 607   // to be adjusted to keep trip count the same and the
 608   // adjusted limit should be checked for int overflow.
 609   if (phi_incr != NULL) {
 610     stride_m  += stride_con;
 611   }
 612 
 613   if (limit-&gt;is_Con()) {
 614     int limit_con = limit-&gt;get_int();
 615     if ((stride_con &gt; 0 &amp;&amp; limit_con &gt; (max_jint - stride_m)) ||
 616         (stride_con &lt; 0 &amp;&amp; limit_con &lt; (min_jint - stride_m))) {
 617       // Bailout: it could be integer overflow.
 618       return false;
 619     }
 620   } else if ((stride_con &gt; 0 &amp;&amp; limit_t-&gt;_hi &lt;= (max_jint - stride_m)) ||
 621              (stride_con &lt; 0 &amp;&amp; limit_t-&gt;_lo &gt;= (min_jint - stride_m))) {
 622       // Limit&#39;s type may satisfy the condition, for example,
 623       // when it is an array length.
 624   } else {
 625     // Generate loop&#39;s limit check.
 626     // Loop limit check predicate should be near the loop.
 627     ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 628     if (!limit_check_proj) {
 629       // The limit check predicate is not generated if this method trapped here before.
 630 #ifdef ASSERT
 631       if (TraceLoopLimitCheck) {
 632         tty-&gt;print(&quot;missing loop limit check:&quot;);
 633         loop-&gt;dump_head();
 634         x-&gt;dump(1);
 635       }
 636 #endif
 637       return false;
 638     }
 639 
 640     IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 641 
 642     if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0))) {
 643       return false;
 644     }
 645 
 646     Node* cmp_limit;
 647     Node* bol;
 648 
 649     if (stride_con &gt; 0) {
 650       cmp_limit = new CmpINode(limit, _igvn.intcon(max_jint - stride_m));
 651       bol = new BoolNode(cmp_limit, BoolTest::le);
 652     } else {
 653       cmp_limit = new CmpINode(limit, _igvn.intcon(min_jint - stride_m));
 654       bol = new BoolNode(cmp_limit, BoolTest::ge);
 655     }
 656 
 657     insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 658   }
 659 
 660   // Now we need to canonicalize loop condition.
 661   if (bt == BoolTest::ne) {
 662     assert(stride_con == 1 || stride_con == -1, &quot;simple increment only&quot;);
 663     if (stride_con &gt; 0 &amp;&amp; init_t-&gt;_hi &lt; limit_t-&gt;_lo) {
 664       // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 665       bt = BoolTest::lt;
 666     } else if (stride_con &lt; 0 &amp;&amp; init_t-&gt;_lo &gt; limit_t-&gt;_hi) {
 667       // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 668       bt = BoolTest::gt;
 669     } else {
 670       ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 671       if (!limit_check_proj) {
 672         // The limit check predicate is not generated if this method trapped here before.
 673 #ifdef ASSERT
 674         if (TraceLoopLimitCheck) {
 675           tty-&gt;print(&quot;missing loop limit check:&quot;);
 676           loop-&gt;dump_head();
 677           x-&gt;dump(1);
 678         }
 679 #endif
 680         return false;
 681       }
 682       IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 683 
 684       if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0)) ||
 685           !is_dominator(get_ctrl(init_trip), check_iff-&gt;in(0))) {
 686         return false;
 687       }
 688 
 689       Node* cmp_limit;
 690       Node* bol;
 691 
 692       if (stride_con &gt; 0) {
 693         cmp_limit = new CmpINode(init_trip, limit);
 694         bol = new BoolNode(cmp_limit, BoolTest::lt);
 695       } else {
 696         cmp_limit = new CmpINode(init_trip, limit);
 697         bol = new BoolNode(cmp_limit, BoolTest::gt);
 698       }
 699 
 700       insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 701 
 702       if (stride_con &gt; 0) {
 703         // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 704         bt = BoolTest::lt;
 705       } else if (stride_con &lt; 0) {
 706         // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 707         bt = BoolTest::gt;
 708       }
 709     }
 710   }
 711 
 712   if (phi_incr != NULL) {
 713     // If compare points directly to the phi we need to adjust
 714     // the compare so that it points to the incr. Limit have
 715     // to be adjusted to keep trip count the same and we
 716     // should avoid int overflow.
 717     //
 718     //   i = init; do {} while(i++ &lt; limit);
 719     // is converted to
 720     //   i = init; do {} while(++i &lt; limit+1);
 721     //
 722     limit = gvn-&gt;transform(new AddINode(limit, stride));
 723   }
 724 
 725   if (incl_limit) {
 726     // The limit check guaranties that &#39;limit &lt;= (max_jint - stride)&#39; so
 727     // we can convert &#39;i &lt;= limit&#39; to &#39;i &lt; limit+1&#39; since stride != 0.
 728     //
 729     Node* one = (stride_con &gt; 0) ? gvn-&gt;intcon( 1) : gvn-&gt;intcon(-1);
 730     limit = gvn-&gt;transform(new AddINode(limit, one));
 731     if (bt == BoolTest::le)
 732       bt = BoolTest::lt;
 733     else if (bt == BoolTest::ge)
 734       bt = BoolTest::gt;
 735     else
 736       ShouldNotReachHere();
 737   }
 738   set_subtree_ctrl( limit );
 739 
 740   if (LoopStripMiningIter == 0) {
 741     // Check for SafePoint on backedge and remove
 742     Node *sfpt = x-&gt;in(LoopNode::LoopBackControl);
 743     if (sfpt-&gt;Opcode() == Op_SafePoint &amp;&amp; is_deleteable_safept(sfpt)) {
 744       lazy_replace( sfpt, iftrue );
 745       if (loop-&gt;_safepts != NULL) {
 746         loop-&gt;_safepts-&gt;yank(sfpt);
 747       }
 748       loop-&gt;_tail = iftrue;
 749     }
 750   }
 751 
 752   // Build a canonical trip test.
 753   // Clone code, as old values may be in use.
 754   incr = incr-&gt;clone();
 755   incr-&gt;set_req(1,phi);
 756   incr-&gt;set_req(2,stride);
 757   incr = _igvn.register_new_node_with_optimizer(incr);
 758   set_early_ctrl( incr );
 759   _igvn.rehash_node_delayed(phi);
 760   phi-&gt;set_req_X( LoopNode::LoopBackControl, incr, &amp;_igvn );
 761 
 762   // If phi type is more restrictive than Int, raise to
 763   // Int to prevent (almost) infinite recursion in igvn
 764   // which can only handle integer types for constants or minint..maxint.
 765   if (!TypeInt::INT-&gt;higher_equal(phi-&gt;bottom_type())) {
 766     Node* nphi = PhiNode::make(phi-&gt;in(0), phi-&gt;in(LoopNode::EntryControl), TypeInt::INT);
 767     nphi-&gt;set_req(LoopNode::LoopBackControl, phi-&gt;in(LoopNode::LoopBackControl));
 768     nphi = _igvn.register_new_node_with_optimizer(nphi);
 769     set_ctrl(nphi, get_ctrl(phi));
 770     _igvn.replace_node(phi, nphi);
 771     phi = nphi-&gt;as_Phi();
 772   }
 773   cmp = cmp-&gt;clone();
 774   cmp-&gt;set_req(1,incr);
 775   cmp-&gt;set_req(2,limit);
 776   cmp = _igvn.register_new_node_with_optimizer(cmp);
 777   set_ctrl(cmp, iff-&gt;in(0));
 778 
 779   test = test-&gt;clone()-&gt;as_Bool();
 780   (*(BoolTest*)&amp;test-&gt;_test)._test = bt;
 781   test-&gt;set_req(1,cmp);
 782   _igvn.register_new_node_with_optimizer(test);
 783   set_ctrl(test, iff-&gt;in(0));
 784 
 785   // Replace the old IfNode with a new LoopEndNode
 786   Node *lex = _igvn.register_new_node_with_optimizer(new CountedLoopEndNode( iff-&gt;in(0), test, cl_prob, iff-&gt;as_If()-&gt;_fcnt ));
 787   IfNode *le = lex-&gt;as_If();
 788   uint dd = dom_depth(iff);
 789   set_idom(le, le-&gt;in(0), dd); // Update dominance for loop exit
 790   set_loop(le, loop);
 791 
 792   // Get the loop-exit control
 793   Node *iffalse = iff-&gt;as_If()-&gt;proj_out(!(iftrue_op == Op_IfTrue));
 794 
 795   // Need to swap loop-exit and loop-back control?
 796   if (iftrue_op == Op_IfFalse) {
 797     Node *ift2=_igvn.register_new_node_with_optimizer(new IfTrueNode (le));
 798     Node *iff2=_igvn.register_new_node_with_optimizer(new IfFalseNode(le));
 799 
 800     loop-&gt;_tail = back_control = ift2;
 801     set_loop(ift2, loop);
 802     set_loop(iff2, get_loop(iffalse));
 803 
 804     // Lazy update of &#39;get_ctrl&#39; mechanism.
 805     lazy_replace(iffalse, iff2);
 806     lazy_replace(iftrue,  ift2);
 807 
 808     // Swap names
 809     iffalse = iff2;
 810     iftrue  = ift2;
 811   } else {
 812     _igvn.rehash_node_delayed(iffalse);
 813     _igvn.rehash_node_delayed(iftrue);
 814     iffalse-&gt;set_req_X( 0, le, &amp;_igvn );
 815     iftrue -&gt;set_req_X( 0, le, &amp;_igvn );
 816   }
 817 
 818   set_idom(iftrue,  le, dd+1);
 819   set_idom(iffalse, le, dd+1);
 820   assert(iff-&gt;outcnt() == 0, &quot;should be dead now&quot;);
 821   lazy_replace( iff, le ); // fix &#39;get_ctrl&#39;
 822 
 823   Node *sfpt2 = le-&gt;in(0);
 824 
 825   Node* entry_control = init_control;
 826   bool strip_mine_loop = LoopStripMiningIter &gt; 1 &amp;&amp; loop-&gt;_child == NULL &amp;&amp;
 827     sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; !loop-&gt;_has_call;
 828   IdealLoopTree* outer_ilt = NULL;
 829   if (strip_mine_loop) {
 830     outer_ilt = create_outer_strip_mined_loop(test, cmp, init_control, loop,
 831                                               cl_prob, le-&gt;_fcnt, entry_control,
 832                                               iffalse);
 833   }
 834 
 835   // Now setup a new CountedLoopNode to replace the existing LoopNode
 836   CountedLoopNode *l = new CountedLoopNode(entry_control, back_control);
 837   l-&gt;set_unswitch_count(x-&gt;as_Loop()-&gt;unswitch_count()); // Preserve
 838   // The following assert is approximately true, and defines the intention
 839   // of can_be_counted_loop.  It fails, however, because phase-&gt;type
 840   // is not yet initialized for this loop and its parts.
 841   //assert(l-&gt;can_be_counted_loop(this), &quot;sanity&quot;);
 842   _igvn.register_new_node_with_optimizer(l);
 843   set_loop(l, loop);
 844   loop-&gt;_head = l;
 845   // Fix all data nodes placed at the old loop head.
 846   // Uses the lazy-update mechanism of &#39;get_ctrl&#39;.
 847   lazy_replace( x, l );
 848   set_idom(l, entry_control, dom_depth(entry_control) + 1);
 849 
 850   if (LoopStripMiningIter == 0 || strip_mine_loop) {
 851     // Check for immediately preceding SafePoint and remove
 852     if (sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; (LoopStripMiningIter != 0 || is_deleteable_safept(sfpt2))) {
 853       if (strip_mine_loop) {
 854         Node* outer_le = outer_ilt-&gt;_tail-&gt;in(0);
 855         Node* sfpt = sfpt2-&gt;clone();
 856         sfpt-&gt;set_req(0, iffalse);
 857         outer_le-&gt;set_req(0, sfpt);
 858         register_control(sfpt, outer_ilt, iffalse);
 859         set_idom(outer_le, sfpt, dom_depth(sfpt));
 860       }
 861       lazy_replace( sfpt2, sfpt2-&gt;in(TypeFunc::Control));
 862       if (loop-&gt;_safepts != NULL) {
 863         loop-&gt;_safepts-&gt;yank(sfpt2);
 864       }
 865     }
 866   }
 867 
 868   // Free up intermediate goo
 869   _igvn.remove_dead_node(hook);
 870 
 871 #ifdef ASSERT
 872   assert(l-&gt;is_valid_counted_loop(), &quot;counted loop shape is messed up&quot;);
 873   assert(l == loop-&gt;_head &amp;&amp; l-&gt;phi() == phi &amp;&amp; l-&gt;loopexit_or_null() == lex, &quot;&quot; );
 874 #endif
 875 #ifndef PRODUCT
 876   if (TraceLoopOpts) {
 877     tty-&gt;print(&quot;Counted      &quot;);
 878     loop-&gt;dump_head();
 879   }
 880 #endif
 881 
 882   C-&gt;print_method(PHASE_AFTER_CLOOPS, 3);
 883 
 884   // Capture bounds of the loop in the induction variable Phi before
 885   // subsequent transformation (iteration splitting) obscures the
 886   // bounds
 887   l-&gt;phi()-&gt;as_Phi()-&gt;set_type(l-&gt;phi()-&gt;Value(&amp;_igvn));
 888 
 889   if (strip_mine_loop) {
 890     l-&gt;mark_strip_mined();
 891     l-&gt;verify_strip_mined(1);
 892     outer_ilt-&gt;_head-&gt;as_Loop()-&gt;verify_strip_mined(1);
 893     loop = outer_ilt;
 894   }
 895 
 896   return true;
 897 }
 898 
 899 //----------------------exact_limit-------------------------------------------
 900 Node* PhaseIdealLoop::exact_limit( IdealLoopTree *loop ) {
 901   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
 902   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
 903   assert(cl-&gt;is_valid_counted_loop(), &quot;&quot;);
 904 
 905   if (ABS(cl-&gt;stride_con()) == 1 ||
 906       cl-&gt;limit()-&gt;Opcode() == Op_LoopLimit) {
 907     // Old code has exact limit (it could be incorrect in case of int overflow).
 908     // Loop limit is exact with stride == 1. And loop may already have exact limit.
 909     return cl-&gt;limit();
 910   }
 911   Node *limit = NULL;
 912 #ifdef ASSERT
 913   BoolTest::mask bt = cl-&gt;loopexit()-&gt;test_trip();
 914   assert(bt == BoolTest::lt || bt == BoolTest::gt, &quot;canonical test is expected&quot;);
 915 #endif
 916   if (cl-&gt;has_exact_trip_count()) {
 917     // Simple case: loop has constant boundaries.
 918     // Use jlongs to avoid integer overflow.
 919     int stride_con = cl-&gt;stride_con();
 920     jlong  init_con = cl-&gt;init_trip()-&gt;get_int();
 921     jlong limit_con = cl-&gt;limit()-&gt;get_int();
 922     julong trip_cnt = cl-&gt;trip_count();
 923     jlong final_con = init_con + trip_cnt*stride_con;
 924     int final_int = (int)final_con;
 925     // The final value should be in integer range since the loop
 926     // is counted and the limit was checked for overflow.
 927     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
 928     limit = _igvn.intcon(final_int);
 929   } else {
 930     // Create new LoopLimit node to get exact limit (final iv value).
 931     limit = new LoopLimitNode(C, cl-&gt;init_trip(), cl-&gt;limit(), cl-&gt;stride());
 932     register_new_node(limit, cl-&gt;in(LoopNode::EntryControl));
 933   }
 934   assert(limit != NULL, &quot;sanity&quot;);
 935   return limit;
 936 }
 937 
 938 //------------------------------Ideal------------------------------------------
 939 // Return a node which is more &quot;ideal&quot; than the current node.
 940 // Attempt to convert into a counted-loop.
 941 Node *LoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 942   if (!can_be_counted_loop(phase) &amp;&amp; !is_OuterStripMinedLoop()) {
 943     phase-&gt;C-&gt;set_major_progress();
 944   }
 945   return RegionNode::Ideal(phase, can_reshape);
 946 }
 947 
 948 #ifdef ASSERT
 949 void LoopNode::verify_strip_mined(int expect_skeleton) const {
 950   const OuterStripMinedLoopNode* outer = NULL;
 951   const CountedLoopNode* inner = NULL;
 952   if (is_strip_mined()) {
 953     if (!is_valid_counted_loop()) {
 954       return; // Skip malformed counted loop
 955     }
 956     assert(is_CountedLoop(), &quot;no Loop should be marked strip mined&quot;);
 957     inner = as_CountedLoop();
 958     outer = inner-&gt;in(LoopNode::EntryControl)-&gt;as_OuterStripMinedLoop();
 959   } else if (is_OuterStripMinedLoop()) {
 960     outer = this-&gt;as_OuterStripMinedLoop();
 961     inner = outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop();
 962     assert(inner-&gt;is_valid_counted_loop() &amp;&amp; inner-&gt;is_strip_mined(), &quot;OuterStripMinedLoop should have been removed&quot;);
 963     assert(!is_strip_mined(), &quot;outer loop shouldn&#39;t be marked strip mined&quot;);
 964   }
 965   if (inner != NULL || outer != NULL) {
 966     assert(inner != NULL &amp;&amp; outer != NULL, &quot;missing loop in strip mined nest&quot;);
 967     Node* outer_tail = outer-&gt;in(LoopNode::LoopBackControl);
 968     Node* outer_le = outer_tail-&gt;in(0);
 969     assert(outer_le-&gt;Opcode() == Op_OuterStripMinedLoopEnd, &quot;tail of outer loop should be an If&quot;);
 970     Node* sfpt = outer_le-&gt;in(0);
 971     assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;where&#39;s the safepoint?&quot;);
 972     Node* inner_out = sfpt-&gt;in(0);
 973     if (inner_out-&gt;outcnt() != 1) {
 974       ResourceMark rm;
 975       Unique_Node_List wq;
 976 
 977       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
 978         Node* u = inner_out-&gt;fast_out(i);
 979         if (u == sfpt) {
 980           continue;
 981         }
 982         wq.clear();
 983         wq.push(u);
 984         bool found_sfpt = false;
 985         for (uint next = 0; next &lt; wq.size() &amp;&amp; !found_sfpt; next++) {
 986           Node* n = wq.at(next);
 987           for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; !found_sfpt; i++) {
 988             Node* u = n-&gt;fast_out(i);
 989             if (u == sfpt) {
 990               found_sfpt = true;
 991             }
 992             if (!u-&gt;is_CFG()) {
 993               wq.push(u);
 994             }
 995           }
 996         }
 997         assert(found_sfpt, &quot;no node in loop that&#39;s not input to safepoint&quot;);
 998       }
 999     }
1000 
1001     CountedLoopEndNode* cle = inner_out-&gt;in(0)-&gt;as_CountedLoopEnd();
1002     assert(cle == inner-&gt;loopexit_or_null(), &quot;mismatch&quot;);
1003     bool has_skeleton = outer_le-&gt;in(1)-&gt;bottom_type()-&gt;singleton() &amp;&amp; outer_le-&gt;in(1)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0;
1004     if (has_skeleton) {
1005       assert(expect_skeleton == 1 || expect_skeleton == -1, &quot;unexpected skeleton node&quot;);
1006       assert(outer-&gt;outcnt() == 2, &quot;only phis&quot;);
1007     } else {
1008       assert(expect_skeleton == 0 || expect_skeleton == -1, &quot;no skeleton node?&quot;);
1009       uint phis = 0;
1010       for (DUIterator_Fast imax, i = inner-&gt;fast_outs(imax); i &lt; imax; i++) {
1011         Node* u = inner-&gt;fast_out(i);
1012         if (u-&gt;is_Phi()) {
1013           phis++;
1014         }
1015       }
1016       for (DUIterator_Fast imax, i = outer-&gt;fast_outs(imax); i &lt; imax; i++) {
1017         Node* u = outer-&gt;fast_out(i);
1018         assert(u == outer || u == inner || u-&gt;is_Phi(), &quot;nothing between inner and outer loop&quot;);
1019       }
1020       uint stores = 0;
1021       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1022         Node* u = inner_out-&gt;fast_out(i);
1023         if (u-&gt;is_Store()) {
1024           stores++;
1025         }
1026       }
1027       assert(outer-&gt;outcnt() &gt;= phis + 2 &amp;&amp; outer-&gt;outcnt() &lt;= phis + 2 + stores + 1, &quot;only phis&quot;);
1028     }
1029     assert(sfpt-&gt;outcnt() == 1, &quot;no data node&quot;);
1030     assert(outer_tail-&gt;outcnt() == 1 || !has_skeleton, &quot;no data node&quot;);
1031   }
1032 }
1033 #endif
1034 
1035 //=============================================================================
1036 //------------------------------Ideal------------------------------------------
1037 // Return a node which is more &quot;ideal&quot; than the current node.
1038 // Attempt to convert into a counted-loop.
1039 Node *CountedLoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1040   return RegionNode::Ideal(phase, can_reshape);
1041 }
1042 
1043 //------------------------------dump_spec--------------------------------------
1044 // Dump special per-node info
1045 #ifndef PRODUCT
1046 void CountedLoopNode::dump_spec(outputStream *st) const {
1047   LoopNode::dump_spec(st);
1048   if (stride_is_con()) {
1049     st-&gt;print(&quot;stride: %d &quot;,stride_con());
1050   }
1051   if (is_pre_loop ()) st-&gt;print(&quot;pre of N%d&quot; , _main_idx);
1052   if (is_main_loop()) st-&gt;print(&quot;main of N%d&quot;, _idx);
1053   if (is_post_loop()) st-&gt;print(&quot;post of N%d&quot;, _main_idx);
1054   if (is_strip_mined()) st-&gt;print(&quot; strip mined&quot;);
1055 }
1056 #endif
1057 
1058 //=============================================================================
1059 int CountedLoopEndNode::stride_con() const {
1060   return stride()-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1061 }
1062 
1063 //=============================================================================
1064 //------------------------------Value-----------------------------------------
1065 const Type* LoopLimitNode::Value(PhaseGVN* phase) const {
1066   const Type* init_t   = phase-&gt;type(in(Init));
1067   const Type* limit_t  = phase-&gt;type(in(Limit));
1068   const Type* stride_t = phase-&gt;type(in(Stride));
1069   // Either input is TOP ==&gt; the result is TOP
1070   if (init_t   == Type::TOP) return Type::TOP;
1071   if (limit_t  == Type::TOP) return Type::TOP;
1072   if (stride_t == Type::TOP) return Type::TOP;
1073 
1074   int stride_con = stride_t-&gt;is_int()-&gt;get_con();
1075   if (stride_con == 1)
1076     return NULL;  // Identity
1077 
1078   if (init_t-&gt;is_int()-&gt;is_con() &amp;&amp; limit_t-&gt;is_int()-&gt;is_con()) {
1079     // Use jlongs to avoid integer overflow.
1080     jlong init_con   =  init_t-&gt;is_int()-&gt;get_con();
1081     jlong limit_con  = limit_t-&gt;is_int()-&gt;get_con();
1082     int  stride_m   = stride_con - (stride_con &gt; 0 ? 1 : -1);
1083     jlong trip_count = (limit_con - init_con + stride_m)/stride_con;
1084     jlong final_con  = init_con + stride_con*trip_count;
1085     int final_int = (int)final_con;
1086     // The final value should be in integer range since the loop
1087     // is counted and the limit was checked for overflow.
1088     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
1089     return TypeInt::make(final_int);
1090   }
1091 
1092   return bottom_type(); // TypeInt::INT
1093 }
1094 
1095 //------------------------------Ideal------------------------------------------
1096 // Return a node which is more &quot;ideal&quot; than the current node.
1097 Node *LoopLimitNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1098   if (phase-&gt;type(in(Init))   == Type::TOP ||
1099       phase-&gt;type(in(Limit))  == Type::TOP ||
1100       phase-&gt;type(in(Stride)) == Type::TOP)
1101     return NULL;  // Dead
1102 
1103   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1104   if (stride_con == 1)
1105     return NULL;  // Identity
1106 
1107   if (in(Init)-&gt;is_Con() &amp;&amp; in(Limit)-&gt;is_Con())
1108     return NULL;  // Value
1109 
1110   // Delay following optimizations until all loop optimizations
1111   // done to keep Ideal graph simple.
1112   if (!can_reshape || phase-&gt;C-&gt;major_progress())
1113     return NULL;
1114 
1115   const TypeInt* init_t  = phase-&gt;type(in(Init) )-&gt;is_int();
1116   const TypeInt* limit_t = phase-&gt;type(in(Limit))-&gt;is_int();
1117   int stride_p;
1118   jlong lim, ini;
1119   julong max;
1120   if (stride_con &gt; 0) {
1121     stride_p = stride_con;
1122     lim = limit_t-&gt;_hi;
1123     ini = init_t-&gt;_lo;
1124     max = (julong)max_jint;
1125   } else {
1126     stride_p = -stride_con;
1127     lim = init_t-&gt;_hi;
1128     ini = limit_t-&gt;_lo;
1129     max = (julong)min_jint;
1130   }
1131   julong range = lim - ini + stride_p;
1132   if (range &lt;= max) {
1133     // Convert to integer expression if it is not overflow.
1134     Node* stride_m = phase-&gt;intcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1135     Node *range = phase-&gt;transform(new SubINode(in(Limit), in(Init)));
1136     Node *bias  = phase-&gt;transform(new AddINode(range, stride_m));
1137     Node *trip  = phase-&gt;transform(new DivINode(0, bias, in(Stride)));
1138     Node *span  = phase-&gt;transform(new MulINode(trip, in(Stride)));
1139     return new AddINode(span, in(Init)); // exact limit
1140   }
1141 
1142   if (is_power_of_2(stride_p) ||                // divisor is 2^n
1143       !Matcher::has_match_rule(Op_LoopLimit)) { // or no specialized Mach node?
1144     // Convert to long expression to avoid integer overflow
1145     // and let igvn optimizer convert this division.
1146     //
1147     Node*   init   = phase-&gt;transform( new ConvI2LNode(in(Init)));
1148     Node*  limit   = phase-&gt;transform( new ConvI2LNode(in(Limit)));
1149     Node* stride   = phase-&gt;longcon(stride_con);
1150     Node* stride_m = phase-&gt;longcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1151 
1152     Node *range = phase-&gt;transform(new SubLNode(limit, init));
1153     Node *bias  = phase-&gt;transform(new AddLNode(range, stride_m));
1154     Node *span;
1155     if (stride_con &gt; 0 &amp;&amp; is_power_of_2(stride_p)) {
1156       // bias &gt;= 0 if stride &gt;0, so if stride is 2^n we can use &amp;(-stride)
1157       // and avoid generating rounding for division. Zero trip guard should
1158       // guarantee that init &lt; limit but sometimes the guard is missing and
1159       // we can get situation when init &gt; limit. Note, for the empty loop
1160       // optimization zero trip guard is generated explicitly which leaves
1161       // only RCE predicate where exact limit is used and the predicate
1162       // will simply fail forcing recompilation.
1163       Node* neg_stride   = phase-&gt;longcon(-stride_con);
1164       span = phase-&gt;transform(new AndLNode(bias, neg_stride));
1165     } else {
1166       Node *trip  = phase-&gt;transform(new DivLNode(0, bias, stride));
1167       span = phase-&gt;transform(new MulLNode(trip, stride));
1168     }
1169     // Convert back to int
1170     Node *span_int = phase-&gt;transform(new ConvL2INode(span));
1171     return new AddINode(span_int, in(Init)); // exact limit
1172   }
1173 
1174   return NULL;    // No progress
1175 }
1176 
1177 //------------------------------Identity---------------------------------------
1178 // If stride == 1 return limit node.
1179 Node* LoopLimitNode::Identity(PhaseGVN* phase) {
1180   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1181   if (stride_con == 1 || stride_con == -1)
1182     return in(Limit);
1183   return this;
1184 }
1185 
1186 //=============================================================================
1187 //----------------------match_incr_with_optional_truncation--------------------
1188 // Match increment with optional truncation:
1189 // CHAR: (i+1)&amp;0x7fff, BYTE: ((i+1)&lt;&lt;8)&gt;&gt;8, or SHORT: ((i+1)&lt;&lt;16)&gt;&gt;16
1190 // Return NULL for failure. Success returns the increment node.
1191 Node* CountedLoopNode::match_incr_with_optional_truncation(
1192                       Node* expr, Node** trunc1, Node** trunc2, const TypeInt** trunc_type) {
1193   // Quick cutouts:
1194   if (expr == NULL || expr-&gt;req() != 3)  return NULL;
1195 
1196   Node *t1 = NULL;
1197   Node *t2 = NULL;
1198   const TypeInt* trunc_t = TypeInt::INT;
1199   Node* n1 = expr;
1200   int   n1op = n1-&gt;Opcode();
1201 
1202   // Try to strip (n1 &amp; M) or (n1 &lt;&lt; N &gt;&gt; N) from n1.
1203   if (n1op == Op_AndI &amp;&amp;
1204       n1-&gt;in(2)-&gt;is_Con() &amp;&amp;
1205       n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0x7fff) {
1206     // %%% This check should match any mask of 2**K-1.
1207     t1 = n1;
1208     n1 = t1-&gt;in(1);
1209     n1op = n1-&gt;Opcode();
1210     trunc_t = TypeInt::CHAR;
1211   } else if (n1op == Op_RShiftI &amp;&amp;
1212              n1-&gt;in(1) != NULL &amp;&amp;
1213              n1-&gt;in(1)-&gt;Opcode() == Op_LShiftI &amp;&amp;
1214              n1-&gt;in(2) == n1-&gt;in(1)-&gt;in(2) &amp;&amp;
1215              n1-&gt;in(2)-&gt;is_Con()) {
1216     jint shift = n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1217     // %%% This check should match any shift in [1..31].
1218     if (shift == 16 || shift == 8) {
1219       t1 = n1;
1220       t2 = t1-&gt;in(1);
1221       n1 = t2-&gt;in(1);
1222       n1op = n1-&gt;Opcode();
1223       if (shift == 16) {
1224         trunc_t = TypeInt::SHORT;
1225       } else if (shift == 8) {
1226         trunc_t = TypeInt::BYTE;
1227       }
1228     }
1229   }
1230 
1231   // If (maybe after stripping) it is an AddI, we won:
1232   if (n1op == Op_AddI) {
1233     *trunc1 = t1;
1234     *trunc2 = t2;
1235     *trunc_type = trunc_t;
1236     return n1;
1237   }
1238 
1239   // failed
1240   return NULL;
1241 }
1242 
1243 LoopNode* CountedLoopNode::skip_strip_mined(int expect_skeleton) {
1244   if (is_strip_mined() &amp;&amp; is_valid_counted_loop()) {
1245     verify_strip_mined(expect_skeleton);
1246     return in(EntryControl)-&gt;as_Loop();
1247   }
1248   return this;
1249 }
1250 
1251 OuterStripMinedLoopNode* CountedLoopNode::outer_loop() const {
1252   assert(is_strip_mined(), &quot;not a strip mined loop&quot;);
1253   Node* c = in(EntryControl);
1254   if (c == NULL || c-&gt;is_top() || !c-&gt;is_OuterStripMinedLoop()) {
1255     return NULL;
1256   }
1257   return c-&gt;as_OuterStripMinedLoop();
1258 }
1259 
1260 IfTrueNode* OuterStripMinedLoopNode::outer_loop_tail() const {
1261   Node* c = in(LoopBackControl);
1262   if (c == NULL || c-&gt;is_top()) {
1263     return NULL;
1264   }
1265   return c-&gt;as_IfTrue();
1266 }
1267 
1268 IfTrueNode* CountedLoopNode::outer_loop_tail() const {
1269   LoopNode* l = outer_loop();
1270   if (l == NULL) {
1271     return NULL;
1272   }
1273   return l-&gt;outer_loop_tail();
1274 }
1275 
1276 OuterStripMinedLoopEndNode* OuterStripMinedLoopNode::outer_loop_end() const {
1277   IfTrueNode* proj = outer_loop_tail();
1278   if (proj == NULL) {
1279     return NULL;
1280   }
1281   Node* c = proj-&gt;in(0);
1282   if (c == NULL || c-&gt;is_top() || c-&gt;outcnt() != 2) {
1283     return NULL;
1284   }
1285   return c-&gt;as_OuterStripMinedLoopEnd();
1286 }
1287 
1288 OuterStripMinedLoopEndNode* CountedLoopNode::outer_loop_end() const {
1289   LoopNode* l = outer_loop();
1290   if (l == NULL) {
1291     return NULL;
1292   }
1293   return l-&gt;outer_loop_end();
1294 }
1295 
1296 IfFalseNode* OuterStripMinedLoopNode::outer_loop_exit() const {
1297   IfNode* le = outer_loop_end();
1298   if (le == NULL) {
1299     return NULL;
1300   }
1301   Node* c = le-&gt;proj_out_or_null(false);
1302   if (c == NULL) {
1303     return NULL;
1304   }
1305   return c-&gt;as_IfFalse();
1306 }
1307 
1308 IfFalseNode* CountedLoopNode::outer_loop_exit() const {
1309   LoopNode* l = outer_loop();
1310   if (l == NULL) {
1311     return NULL;
1312   }
1313   return l-&gt;outer_loop_exit();
1314 }
1315 
1316 SafePointNode* OuterStripMinedLoopNode::outer_safepoint() const {
1317   IfNode* le = outer_loop_end();
1318   if (le == NULL) {
1319     return NULL;
1320   }
1321   Node* c = le-&gt;in(0);
1322   if (c == NULL || c-&gt;is_top()) {
1323     return NULL;
1324   }
1325   assert(c-&gt;Opcode() == Op_SafePoint, &quot;broken outer loop&quot;);
1326   return c-&gt;as_SafePoint();
1327 }
1328 
1329 SafePointNode* CountedLoopNode::outer_safepoint() const {
1330   LoopNode* l = outer_loop();
1331   if (l == NULL) {
1332     return NULL;
1333   }
1334   return l-&gt;outer_safepoint();
1335 }
1336 
1337 Node* CountedLoopNode::skip_predicates_from_entry(Node* ctrl) {
1338     while (ctrl != NULL &amp;&amp; ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_If() &amp;&amp;
1339            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;outcnt() == 1 &amp;&amp;
1340            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;unique_out()-&gt;Opcode() == Op_Halt) {
1341       ctrl = ctrl-&gt;in(0)-&gt;in(0);
1342     }
1343 
1344     return ctrl;
1345   }
1346 
1347 Node* CountedLoopNode::skip_predicates() {
1348   if (is_main_loop()) {
1349     Node* ctrl = skip_strip_mined()-&gt;in(LoopNode::EntryControl);
1350 
1351     return skip_predicates_from_entry(ctrl);
1352   }
1353   return in(LoopNode::EntryControl);
1354 }
1355 
1356 void OuterStripMinedLoopNode::adjust_strip_mined_loop(PhaseIterGVN* igvn) {
1357   // Look for the outer &amp; inner strip mined loop, reduce number of
1358   // iterations of the inner loop, set exit condition of outer loop,
1359   // construct required phi nodes for outer loop.
1360   CountedLoopNode* inner_cl = unique_ctrl_out()-&gt;as_CountedLoop();
1361   assert(inner_cl-&gt;is_strip_mined(), &quot;inner loop should be strip mined&quot;);
1362   Node* inner_iv_phi = inner_cl-&gt;phi();
1363   if (inner_iv_phi == NULL) {
1364     IfNode* outer_le = outer_loop_end();
1365     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1366     igvn-&gt;replace_node(outer_le, iff);
1367     inner_cl-&gt;clear_strip_mined();
1368     return;
1369   }
1370   CountedLoopEndNode* inner_cle = inner_cl-&gt;loopexit();
1371 
1372   int stride = inner_cl-&gt;stride_con();
1373   jlong scaled_iters_long = ((jlong)LoopStripMiningIter) * ABS(stride);
1374   int scaled_iters = (int)scaled_iters_long;
1375   int short_scaled_iters = LoopStripMiningIterShortLoop* ABS(stride);
1376   const TypeInt* inner_iv_t = igvn-&gt;type(inner_iv_phi)-&gt;is_int();
1377   jlong iter_estimate = (jlong)inner_iv_t-&gt;_hi - (jlong)inner_iv_t-&gt;_lo;
1378   assert(iter_estimate &gt; 0, &quot;broken&quot;);
1379   if ((jlong)scaled_iters != scaled_iters_long || iter_estimate &lt;= short_scaled_iters) {
1380     // Remove outer loop and safepoint (too few iterations)
1381     Node* outer_sfpt = outer_safepoint();
1382     Node* outer_out = outer_loop_exit();
1383     igvn-&gt;replace_node(outer_out, outer_sfpt-&gt;in(0));
1384     igvn-&gt;replace_input_of(outer_sfpt, 0, igvn-&gt;C-&gt;top());
1385     inner_cl-&gt;clear_strip_mined();
1386     return;
1387   }
1388   if (iter_estimate &lt;= scaled_iters_long) {
1389     // We would only go through one iteration of
1390     // the outer loop: drop the outer loop but
1391     // keep the safepoint so we don&#39;t run for
1392     // too long without a safepoint
1393     IfNode* outer_le = outer_loop_end();
1394     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1395     igvn-&gt;replace_node(outer_le, iff);
1396     inner_cl-&gt;clear_strip_mined();
1397     return;
1398   }
1399 
1400   Node* cle_tail = inner_cle-&gt;proj_out(true);
1401   ResourceMark rm;
1402   Node_List old_new;
1403   if (cle_tail-&gt;outcnt() &gt; 1) {
1404     // Look for nodes on backedge of inner loop and clone them
1405     Unique_Node_List backedge_nodes;
1406     for (DUIterator_Fast imax, i = cle_tail-&gt;fast_outs(imax); i &lt; imax; i++) {
1407       Node* u = cle_tail-&gt;fast_out(i);
1408       if (u != inner_cl) {
1409         assert(!u-&gt;is_CFG(), &quot;control flow on the backedge?&quot;);
1410         backedge_nodes.push(u);
1411       }
1412     }
1413     uint last = igvn-&gt;C-&gt;unique();
1414     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1415       Node* n = backedge_nodes.at(next);
1416       old_new.map(n-&gt;_idx, n-&gt;clone());
1417       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
1418         Node* u = n-&gt;fast_out(i);
1419         assert(!u-&gt;is_CFG(), &quot;broken&quot;);
1420         if (u-&gt;_idx &gt;= last) {
1421           continue;
1422         }
1423         if (!u-&gt;is_Phi()) {
1424           backedge_nodes.push(u);
1425         } else {
1426           assert(u-&gt;in(0) == inner_cl, &quot;strange phi on the backedge&quot;);
1427         }
1428       }
1429     }
1430     // Put the clones on the outer loop backedge
1431     Node* le_tail = outer_loop_tail();
1432     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1433       Node *n = old_new[backedge_nodes.at(next)-&gt;_idx];
1434       for (uint i = 1; i &lt; n-&gt;req(); i++) {
1435         if (n-&gt;in(i) != NULL &amp;&amp; old_new[n-&gt;in(i)-&gt;_idx] != NULL) {
1436           n-&gt;set_req(i, old_new[n-&gt;in(i)-&gt;_idx]);
1437         }
1438       }
1439       if (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0) == cle_tail) {
1440         n-&gt;set_req(0, le_tail);
1441       }
1442       igvn-&gt;register_new_node_with_optimizer(n);
1443     }
1444   }
1445 
1446   Node* iv_phi = NULL;
1447   // Make a clone of each phi in the inner loop
1448   // for the outer loop
1449   for (uint i = 0; i &lt; inner_cl-&gt;outcnt(); i++) {
1450     Node* u = inner_cl-&gt;raw_out(i);
1451     if (u-&gt;is_Phi()) {
1452       assert(u-&gt;in(0) == inner_cl, &quot;inconsistent&quot;);
1453       Node* phi = u-&gt;clone();
1454       phi-&gt;set_req(0, this);
1455       Node* be = old_new[phi-&gt;in(LoopNode::LoopBackControl)-&gt;_idx];
1456       if (be != NULL) {
1457         phi-&gt;set_req(LoopNode::LoopBackControl, be);
1458       }
1459       phi = igvn-&gt;transform(phi);
1460       igvn-&gt;replace_input_of(u, LoopNode::EntryControl, phi);
1461       if (u == inner_iv_phi) {
1462         iv_phi = phi;
1463       }
1464     }
1465   }
1466   Node* cle_out = inner_cle-&gt;proj_out(false);
1467   if (cle_out-&gt;outcnt() &gt; 1) {
1468     // Look for chains of stores that were sunk
1469     // out of the inner loop and are in the outer loop
1470     for (DUIterator_Fast imax, i = cle_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1471       Node* u = cle_out-&gt;fast_out(i);
1472       if (u-&gt;is_Store()) {
1473         Node* first = u;
1474         for(;;) {
1475           Node* next = first-&gt;in(MemNode::Memory);
1476           if (!next-&gt;is_Store() || next-&gt;in(0) != cle_out) {
1477             break;
1478           }
1479           first = next;
1480         }
1481         Node* last = u;
1482         for(;;) {
1483           Node* next = NULL;
1484           for (DUIterator_Fast jmax, j = last-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1485             Node* uu = last-&gt;fast_out(j);
1486             if (uu-&gt;is_Store() &amp;&amp; uu-&gt;in(0) == cle_out) {
1487               assert(next == NULL, &quot;only one in the outer loop&quot;);
1488               next = uu;
1489             }
1490           }
1491           if (next == NULL) {
1492             break;
1493           }
1494           last = next;
1495         }
1496         Node* phi = NULL;
1497         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1498           Node* uu = fast_out(j);
1499           if (uu-&gt;is_Phi()) {
1500             Node* be = uu-&gt;in(LoopNode::LoopBackControl);
1501             if (be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL) {
1502               assert(false, &quot;store on the backedge + sunk stores: unsupported&quot;);
1503               // drop outer loop
1504               IfNode* outer_le = outer_loop_end();
1505               Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1506               igvn-&gt;replace_node(outer_le, iff);
1507               inner_cl-&gt;clear_strip_mined();
1508               return;
1509             }
1510             if (be == last || be == first-&gt;in(MemNode::Memory)) {
1511               assert(phi == NULL, &quot;only one phi&quot;);
1512               phi = uu;
1513             }
1514           }
1515         }
1516 #ifdef ASSERT
1517         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1518           Node* uu = fast_out(j);
1519           if (uu-&gt;is_Phi() &amp;&amp; uu-&gt;bottom_type() == Type::MEMORY) {
1520             if (uu-&gt;adr_type() == igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()))) {
1521               assert(phi == uu, &quot;what&#39;s that phi?&quot;);
1522             } else if (uu-&gt;adr_type() == TypePtr::BOTTOM) {
1523               Node* n = uu-&gt;in(LoopNode::LoopBackControl);
1524               uint limit = igvn-&gt;C-&gt;live_nodes();
1525               uint i = 0;
1526               while (n != uu) {
1527                 i++;
1528                 assert(i &lt; limit, &quot;infinite loop&quot;);
1529                 if (n-&gt;is_Proj()) {
1530                   n = n-&gt;in(0);
1531                 } else if (n-&gt;is_SafePoint() || n-&gt;is_MemBar()) {
1532                   n = n-&gt;in(TypeFunc::Memory);
1533                 } else if (n-&gt;is_Phi()) {
1534                   n = n-&gt;in(1);
1535                 } else if (n-&gt;is_MergeMem()) {
1536                   n = n-&gt;as_MergeMem()-&gt;memory_at(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()));
1537                 } else if (n-&gt;is_Store() || n-&gt;is_LoadStore() || n-&gt;is_ClearArray()) {
1538                   n = n-&gt;in(MemNode::Memory);
1539                 } else {
1540                   n-&gt;dump();
1541                   ShouldNotReachHere();
1542                 }
1543               }
1544             }
1545           }
1546         }
1547 #endif
1548         if (phi == NULL) {
1549           // If the an entire chains was sunk, the
1550           // inner loop has no phi for that memory
1551           // slice, create one for the outer loop
1552           phi = PhiNode::make(this, first-&gt;in(MemNode::Memory), Type::MEMORY,
1553                               igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type())));
1554           phi-&gt;set_req(LoopNode::LoopBackControl, last);
1555           phi = igvn-&gt;transform(phi);
1556           igvn-&gt;replace_input_of(first, MemNode::Memory, phi);
1557         } else {
1558           // Or fix the outer loop fix to include
1559           // that chain of stores.
1560           Node* be = phi-&gt;in(LoopNode::LoopBackControl);
1561           assert(!(be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL), &quot;store on the backedge + sunk stores: unsupported&quot;);
1562           if (be == first-&gt;in(MemNode::Memory)) {
1563             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1564               igvn-&gt;replace_input_of(phi, LoopNode::LoopBackControl, last);
1565             } else {
1566               igvn-&gt;replace_input_of(be, MemNode::Memory, last);
1567             }
1568           } else {
1569 #ifdef ASSERT
1570             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1571               assert(phi-&gt;in(LoopNode::LoopBackControl) == last, &quot;&quot;);
1572             } else {
1573               assert(be-&gt;in(MemNode::Memory) == last, &quot;&quot;);
1574             }
1575 #endif
1576           }
1577         }
1578       }
1579     }
1580   }
1581 
1582   if (iv_phi != NULL) {
1583     // Now adjust the inner loop&#39;s exit condition
1584     Node* limit = inner_cl-&gt;limit();
1585     Node* sub = NULL;
1586     if (stride &gt; 0) {
1587       sub = igvn-&gt;transform(new SubINode(limit, iv_phi));
1588     } else {
1589       sub = igvn-&gt;transform(new SubINode(iv_phi, limit));
1590     }
1591     Node* min = igvn-&gt;transform(new MinINode(sub, igvn-&gt;intcon(scaled_iters)));
1592     Node* new_limit = NULL;
1593     if (stride &gt; 0) {
1594       new_limit = igvn-&gt;transform(new AddINode(min, iv_phi));
1595     } else {
1596       new_limit = igvn-&gt;transform(new SubINode(iv_phi, min));
1597     }
1598     Node* inner_cmp = inner_cle-&gt;cmp_node();
1599     Node* inner_bol = inner_cle-&gt;in(CountedLoopEndNode::TestValue);
1600     Node* outer_bol = inner_bol;
1601     // cmp node for inner loop may be shared
1602     inner_cmp = inner_cmp-&gt;clone();
1603     inner_cmp-&gt;set_req(2, new_limit);
1604     inner_bol = inner_bol-&gt;clone();
1605     inner_bol-&gt;set_req(1, igvn-&gt;transform(inner_cmp));
1606     igvn-&gt;replace_input_of(inner_cle, CountedLoopEndNode::TestValue, igvn-&gt;transform(inner_bol));
1607     // Set the outer loop&#39;s exit condition too
1608     igvn-&gt;replace_input_of(outer_loop_end(), 1, outer_bol);
1609   } else {
1610     assert(false, &quot;should be able to adjust outer loop&quot;);
1611     IfNode* outer_le = outer_loop_end();
1612     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1613     igvn-&gt;replace_node(outer_le, iff);
1614     inner_cl-&gt;clear_strip_mined();
1615   }
1616 }
1617 
1618 const Type* OuterStripMinedLoopEndNode::Value(PhaseGVN* phase) const {
1619   if (!in(0)) return Type::TOP;
1620   if (phase-&gt;type(in(0)) == Type::TOP)
1621     return Type::TOP;
1622 
1623   return TypeTuple::IFBOTH;
1624 }
1625 
1626 Node *OuterStripMinedLoopEndNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1627   if (remove_dead_region(phase, can_reshape))  return this;
1628 
1629   return NULL;
1630 }
1631 
1632 //------------------------------filtered_type--------------------------------
1633 // Return a type based on condition control flow
1634 // A successful return will be a type that is restricted due
1635 // to a series of dominating if-tests, such as:
1636 //    if (i &lt; 10) {
1637 //       if (i &gt; 0) {
1638 //          here: &quot;i&quot; type is [1..10)
1639 //       }
1640 //    }
1641 // or a control flow merge
1642 //    if (i &lt; 10) {
1643 //       do {
1644 //          phi( , ) -- at top of loop type is [min_int..10)
1645 //         i = ?
1646 //       } while ( i &lt; 10)
1647 //
1648 const TypeInt* PhaseIdealLoop::filtered_type( Node *n, Node* n_ctrl) {
1649   assert(n &amp;&amp; n-&gt;bottom_type()-&gt;is_int(), &quot;must be int&quot;);
1650   const TypeInt* filtered_t = NULL;
1651   if (!n-&gt;is_Phi()) {
1652     assert(n_ctrl != NULL || n_ctrl == C-&gt;top(), &quot;valid control&quot;);
1653     filtered_t = filtered_type_from_dominators(n, n_ctrl);
1654 
1655   } else {
1656     Node* phi    = n-&gt;as_Phi();
1657     Node* region = phi-&gt;in(0);
1658     assert(n_ctrl == NULL || n_ctrl == region, &quot;ctrl parameter must be region&quot;);
1659     if (region &amp;&amp; region != C-&gt;top()) {
1660       for (uint i = 1; i &lt; phi-&gt;req(); i++) {
1661         Node* val   = phi-&gt;in(i);
1662         Node* use_c = region-&gt;in(i);
1663         const TypeInt* val_t = filtered_type_from_dominators(val, use_c);
1664         if (val_t != NULL) {
1665           if (filtered_t == NULL) {
1666             filtered_t = val_t;
1667           } else {
1668             filtered_t = filtered_t-&gt;meet(val_t)-&gt;is_int();
1669           }
1670         }
1671       }
1672     }
1673   }
1674   const TypeInt* n_t = _igvn.type(n)-&gt;is_int();
1675   if (filtered_t != NULL) {
1676     n_t = n_t-&gt;join(filtered_t)-&gt;is_int();
1677   }
1678   return n_t;
1679 }
1680 
1681 
1682 //------------------------------filtered_type_from_dominators--------------------------------
1683 // Return a possibly more restrictive type for val based on condition control flow of dominators
1684 const TypeInt* PhaseIdealLoop::filtered_type_from_dominators( Node* val, Node *use_ctrl) {
1685   if (val-&gt;is_Con()) {
1686      return val-&gt;bottom_type()-&gt;is_int();
1687   }
1688   uint if_limit = 10; // Max number of dominating if&#39;s visited
1689   const TypeInt* rtn_t = NULL;
1690 
1691   if (use_ctrl &amp;&amp; use_ctrl != C-&gt;top()) {
1692     Node* val_ctrl = get_ctrl(val);
1693     uint val_dom_depth = dom_depth(val_ctrl);
1694     Node* pred = use_ctrl;
1695     uint if_cnt = 0;
1696     while (if_cnt &lt; if_limit) {
1697       if ((pred-&gt;Opcode() == Op_IfTrue || pred-&gt;Opcode() == Op_IfFalse)) {
1698         if_cnt++;
1699         const TypeInt* if_t = IfNode::filtered_int_type(&amp;_igvn, val, pred);
1700         if (if_t != NULL) {
1701           if (rtn_t == NULL) {
1702             rtn_t = if_t;
1703           } else {
1704             rtn_t = rtn_t-&gt;join(if_t)-&gt;is_int();
1705           }
1706         }
1707       }
1708       pred = idom(pred);
1709       if (pred == NULL || pred == C-&gt;top()) {
1710         break;
1711       }
1712       // Stop if going beyond definition block of val
1713       if (dom_depth(pred) &lt; val_dom_depth) {
1714         break;
1715       }
1716     }
1717   }
1718   return rtn_t;
1719 }
1720 
1721 
1722 //------------------------------dump_spec--------------------------------------
1723 // Dump special per-node info
1724 #ifndef PRODUCT
1725 void CountedLoopEndNode::dump_spec(outputStream *st) const {
1726   if( in(TestValue) != NULL &amp;&amp; in(TestValue)-&gt;is_Bool() ) {
1727     BoolTest bt( test_trip()); // Added this for g++.
1728 
1729     st-&gt;print(&quot;[&quot;);
1730     bt.dump_on(st);
1731     st-&gt;print(&quot;]&quot;);
1732   }
1733   st-&gt;print(&quot; &quot;);
1734   IfNode::dump_spec(st);
1735 }
1736 #endif
1737 
1738 //=============================================================================
1739 //------------------------------is_member--------------------------------------
1740 // Is &#39;l&#39; a member of &#39;this&#39;?
1741 bool IdealLoopTree::is_member(const IdealLoopTree *l) const {
1742   while( l-&gt;_nest &gt; _nest ) l = l-&gt;_parent;
1743   return l == this;
1744 }
1745 
1746 //------------------------------set_nest---------------------------------------
1747 // Set loop tree nesting depth.  Accumulate _has_call bits.
1748 int IdealLoopTree::set_nest( uint depth ) {
1749   _nest = depth;
1750   int bits = _has_call;
1751   if( _child ) bits |= _child-&gt;set_nest(depth+1);
1752   if( bits ) _has_call = 1;
1753   if( _next  ) bits |= _next -&gt;set_nest(depth  );
1754   return bits;
1755 }
1756 
1757 //------------------------------split_fall_in----------------------------------
1758 // Split out multiple fall-in edges from the loop header.  Move them to a
1759 // private RegionNode before the loop.  This becomes the loop landing pad.
1760 void IdealLoopTree::split_fall_in( PhaseIdealLoop *phase, int fall_in_cnt ) {
1761   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1762   uint i;
1763 
1764   // Make a new RegionNode to be the landing pad.
1765   Node *landing_pad = new RegionNode( fall_in_cnt+1 );
1766   phase-&gt;set_loop(landing_pad,_parent);
1767   // Gather all the fall-in control paths into the landing pad
1768   uint icnt = fall_in_cnt;
1769   uint oreq = _head-&gt;req();
1770   for( i = oreq-1; i&gt;0; i-- )
1771     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
1772       landing_pad-&gt;set_req(icnt--,_head-&gt;in(i));
1773 
1774   // Peel off PhiNode edges as well
1775   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1776     Node *oj = _head-&gt;fast_out(j);
1777     if( oj-&gt;is_Phi() ) {
1778       PhiNode* old_phi = oj-&gt;as_Phi();
1779       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1780       igvn.hash_delete(old_phi);   // Yank from hash before hacking edges
1781       Node *p = PhiNode::make_blank(landing_pad, old_phi);
1782       uint icnt = fall_in_cnt;
1783       for( i = oreq-1; i&gt;0; i-- ) {
1784         if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1785           p-&gt;init_req(icnt--, old_phi-&gt;in(i));
1786           // Go ahead and clean out old edges from old phi
1787           old_phi-&gt;del_req(i);
1788         }
1789       }
1790       // Search for CSE&#39;s here, because ZKM.jar does a lot of
1791       // loop hackery and we need to be a little incremental
1792       // with the CSE to avoid O(N^2) node blow-up.
1793       Node *p2 = igvn.hash_find_insert(p); // Look for a CSE
1794       if( p2 ) {                // Found CSE
1795         p-&gt;destruct();          // Recover useless new node
1796         p = p2;                 // Use old node
1797       } else {
1798         igvn.register_new_node_with_optimizer(p, old_phi);
1799       }
1800       // Make old Phi refer to new Phi.
1801       old_phi-&gt;add_req(p);
1802       // Check for the special case of making the old phi useless and
1803       // disappear it.  In JavaGrande I have a case where this useless
1804       // Phi is the loop limit and prevents recognizing a CountedLoop
1805       // which in turn prevents removing an empty loop.
1806       Node *id_old_phi = old_phi-&gt;Identity(&amp;igvn);
1807       if( id_old_phi != old_phi ) { // Found a simple identity?
1808         // Note that I cannot call &#39;replace_node&#39; here, because
1809         // that will yank the edge from old_phi to the Region and
1810         // I&#39;m mid-iteration over the Region&#39;s uses.
1811         for (DUIterator_Last imin, i = old_phi-&gt;last_outs(imin); i &gt;= imin; ) {
1812           Node* use = old_phi-&gt;last_out(i);
1813           igvn.rehash_node_delayed(use);
1814           uint uses_found = 0;
1815           for (uint j = 0; j &lt; use-&gt;len(); j++) {
1816             if (use-&gt;in(j) == old_phi) {
1817               if (j &lt; use-&gt;req()) use-&gt;set_req (j, id_old_phi);
1818               else                use-&gt;set_prec(j, id_old_phi);
1819               uses_found++;
1820             }
1821           }
1822           i -= uses_found;    // we deleted 1 or more copies of this edge
1823         }
1824       }
1825       igvn._worklist.push(old_phi);
1826     }
1827   }
1828   // Finally clean out the fall-in edges from the RegionNode
1829   for( i = oreq-1; i&gt;0; i-- ) {
1830     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1831       _head-&gt;del_req(i);
1832     }
1833   }
1834   igvn.rehash_node_delayed(_head);
1835   // Transform landing pad
1836   igvn.register_new_node_with_optimizer(landing_pad, _head);
1837   // Insert landing pad into the header
1838   _head-&gt;add_req(landing_pad);
1839 }
1840 
1841 //------------------------------split_outer_loop-------------------------------
1842 // Split out the outermost loop from this shared header.
1843 void IdealLoopTree::split_outer_loop( PhaseIdealLoop *phase ) {
1844   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1845 
1846   // Find index of outermost loop; it should also be my tail.
1847   uint outer_idx = 1;
1848   while( _head-&gt;in(outer_idx) != _tail ) outer_idx++;
1849 
1850   // Make a LoopNode for the outermost loop.
1851   Node *ctl = _head-&gt;in(LoopNode::EntryControl);
1852   Node *outer = new LoopNode( ctl, _head-&gt;in(outer_idx) );
1853   outer = igvn.register_new_node_with_optimizer(outer, _head);
1854   phase-&gt;set_created_loop_node();
1855 
1856   // Outermost loop falls into &#39;_head&#39; loop
1857   _head-&gt;set_req(LoopNode::EntryControl, outer);
1858   _head-&gt;del_req(outer_idx);
1859   // Split all the Phis up between &#39;_head&#39; loop and &#39;outer&#39; loop.
1860   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1861     Node *out = _head-&gt;fast_out(j);
1862     if( out-&gt;is_Phi() ) {
1863       PhiNode *old_phi = out-&gt;as_Phi();
1864       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1865       Node *phi = PhiNode::make_blank(outer, old_phi);
1866       phi-&gt;init_req(LoopNode::EntryControl,    old_phi-&gt;in(LoopNode::EntryControl));
1867       phi-&gt;init_req(LoopNode::LoopBackControl, old_phi-&gt;in(outer_idx));
1868       phi = igvn.register_new_node_with_optimizer(phi, old_phi);
1869       // Make old Phi point to new Phi on the fall-in path
1870       igvn.replace_input_of(old_phi, LoopNode::EntryControl, phi);
1871       old_phi-&gt;del_req(outer_idx);
1872     }
1873   }
1874 
1875   // Use the new loop head instead of the old shared one
1876   _head = outer;
1877   phase-&gt;set_loop(_head, this);
1878 }
1879 
1880 //------------------------------fix_parent-------------------------------------
1881 static void fix_parent( IdealLoopTree *loop, IdealLoopTree *parent ) {
1882   loop-&gt;_parent = parent;
1883   if( loop-&gt;_child ) fix_parent( loop-&gt;_child, loop   );
1884   if( loop-&gt;_next  ) fix_parent( loop-&gt;_next , parent );
1885 }
1886 
1887 //------------------------------estimate_path_freq-----------------------------
1888 static float estimate_path_freq( Node *n ) {
1889   // Try to extract some path frequency info
1890   IfNode *iff;
1891   for( int i = 0; i &lt; 50; i++ ) { // Skip through a bunch of uncommon tests
1892     uint nop = n-&gt;Opcode();
1893     if( nop == Op_SafePoint ) {   // Skip any safepoint
1894       n = n-&gt;in(0);
1895       continue;
1896     }
1897     if( nop == Op_CatchProj ) {   // Get count from a prior call
1898       // Assume call does not always throw exceptions: means the call-site
1899       // count is also the frequency of the fall-through path.
1900       assert( n-&gt;is_CatchProj(), &quot;&quot; );
1901       if( ((CatchProjNode*)n)-&gt;_con != CatchProjNode::fall_through_index )
1902         return 0.0f;            // Assume call exception path is rare
1903       Node *call = n-&gt;in(0)-&gt;in(0)-&gt;in(0);
1904       assert( call-&gt;is_Call(), &quot;expect a call here&quot; );
1905       const JVMState *jvms = ((CallNode*)call)-&gt;jvms();
1906       ciMethodData* methodData = jvms-&gt;method()-&gt;method_data();
1907       if (!methodData-&gt;is_mature())  return 0.0f; // No call-site data
1908       ciProfileData* data = methodData-&gt;bci_to_data(jvms-&gt;bci());
1909       if ((data == NULL) || !data-&gt;is_CounterData()) {
1910         // no call profile available, try call&#39;s control input
1911         n = n-&gt;in(0);
1912         continue;
1913       }
1914       return data-&gt;as_CounterData()-&gt;count()/FreqCountInvocations;
1915     }
1916     // See if there&#39;s a gating IF test
1917     Node *n_c = n-&gt;in(0);
1918     if( !n_c-&gt;is_If() ) break;       // No estimate available
1919     iff = n_c-&gt;as_If();
1920     if( iff-&gt;_fcnt != COUNT_UNKNOWN )   // Have a valid count?
1921       // Compute how much count comes on this path
1922       return ((nop == Op_IfTrue) ? iff-&gt;_prob : 1.0f - iff-&gt;_prob) * iff-&gt;_fcnt;
1923     // Have no count info.  Skip dull uncommon-trap like branches.
1924     if( (nop == Op_IfTrue  &amp;&amp; iff-&gt;_prob &lt; PROB_LIKELY_MAG(5)) ||
1925         (nop == Op_IfFalse &amp;&amp; iff-&gt;_prob &gt; PROB_UNLIKELY_MAG(5)) )
1926       break;
1927     // Skip through never-taken branch; look for a real loop exit.
1928     n = iff-&gt;in(0);
1929   }
1930   return 0.0f;                  // No estimate available
1931 }
1932 
1933 //------------------------------merge_many_backedges---------------------------
1934 // Merge all the backedges from the shared header into a private Region.
1935 // Feed that region as the one backedge to this loop.
1936 void IdealLoopTree::merge_many_backedges( PhaseIdealLoop *phase ) {
1937   uint i;
1938 
1939   // Scan for the top 2 hottest backedges
1940   float hotcnt = 0.0f;
1941   float warmcnt = 0.0f;
1942   uint hot_idx = 0;
1943   // Loop starts at 2 because slot 1 is the fall-in path
1944   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
1945     float cnt = estimate_path_freq(_head-&gt;in(i));
1946     if( cnt &gt; hotcnt ) {       // Grab hottest path
1947       warmcnt = hotcnt;
1948       hotcnt = cnt;
1949       hot_idx = i;
1950     } else if( cnt &gt; warmcnt ) { // And 2nd hottest path
1951       warmcnt = cnt;
1952     }
1953   }
1954 
1955   // See if the hottest backedge is worthy of being an inner loop
1956   // by being much hotter than the next hottest backedge.
1957   if( hotcnt &lt;= 0.0001 ||
1958       hotcnt &lt; 2.0*warmcnt ) hot_idx = 0;// No hot backedge
1959 
1960   // Peel out the backedges into a private merge point; peel
1961   // them all except optionally hot_idx.
1962   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1963 
1964   Node *hot_tail = NULL;
1965   // Make a Region for the merge point
1966   Node *r = new RegionNode(1);
1967   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
1968     if( i != hot_idx )
1969       r-&gt;add_req( _head-&gt;in(i) );
1970     else hot_tail = _head-&gt;in(i);
1971   }
1972   igvn.register_new_node_with_optimizer(r, _head);
1973   // Plug region into end of loop _head, followed by hot_tail
1974   while( _head-&gt;req() &gt; 3 ) _head-&gt;del_req( _head-&gt;req()-1 );
1975   igvn.replace_input_of(_head, 2, r);
1976   if( hot_idx ) _head-&gt;add_req(hot_tail);
1977 
1978   // Split all the Phis up between &#39;_head&#39; loop and the Region &#39;r&#39;
1979   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1980     Node *out = _head-&gt;fast_out(j);
1981     if( out-&gt;is_Phi() ) {
1982       PhiNode* n = out-&gt;as_Phi();
1983       igvn.hash_delete(n);      // Delete from hash before hacking edges
1984       Node *hot_phi = NULL;
1985       Node *phi = new PhiNode(r, n-&gt;type(), n-&gt;adr_type());
1986       // Check all inputs for the ones to peel out
1987       uint j = 1;
1988       for( uint i = 2; i &lt; n-&gt;req(); i++ ) {
1989         if( i != hot_idx )
1990           phi-&gt;set_req( j++, n-&gt;in(i) );
1991         else hot_phi = n-&gt;in(i);
1992       }
1993       // Register the phi but do not transform until whole place transforms
1994       igvn.register_new_node_with_optimizer(phi, n);
1995       // Add the merge phi to the old Phi
1996       while( n-&gt;req() &gt; 3 ) n-&gt;del_req( n-&gt;req()-1 );
1997       igvn.replace_input_of(n, 2, phi);
1998       if( hot_idx ) n-&gt;add_req(hot_phi);
1999     }
2000   }
2001 
2002 
2003   // Insert a new IdealLoopTree inserted below me.  Turn it into a clone
2004   // of self loop tree.  Turn self into a loop headed by _head and with
2005   // tail being the new merge point.
2006   IdealLoopTree *ilt = new IdealLoopTree( phase, _head, _tail );
2007   phase-&gt;set_loop(_tail,ilt);   // Adjust tail
2008   _tail = r;                    // Self&#39;s tail is new merge point
2009   phase-&gt;set_loop(r,this);
2010   ilt-&gt;_child = _child;         // New guy has my children
2011   _child = ilt;                 // Self has new guy as only child
2012   ilt-&gt;_parent = this;          // new guy has self for parent
2013   ilt-&gt;_nest = _nest;           // Same nesting depth (for now)
2014 
2015   // Starting with &#39;ilt&#39;, look for child loop trees using the same shared
2016   // header.  Flatten these out; they will no longer be loops in the end.
2017   IdealLoopTree **pilt = &amp;_child;
2018   while( ilt ) {
2019     if( ilt-&gt;_head == _head ) {
2020       uint i;
2021       for( i = 2; i &lt; _head-&gt;req(); i++ )
2022         if( _head-&gt;in(i) == ilt-&gt;_tail )
2023           break;                // Still a loop
2024       if( i == _head-&gt;req() ) { // No longer a loop
2025         // Flatten ilt.  Hang ilt&#39;s &quot;_next&quot; list from the end of
2026         // ilt&#39;s &#39;_child&#39; list.  Move the ilt&#39;s _child up to replace ilt.
2027         IdealLoopTree **cp = &amp;ilt-&gt;_child;
2028         while( *cp ) cp = &amp;(*cp)-&gt;_next;   // Find end of child list
2029         *cp = ilt-&gt;_next;       // Hang next list at end of child list
2030         *pilt = ilt-&gt;_child;    // Move child up to replace ilt
2031         ilt-&gt;_head = NULL;      // Flag as a loop UNIONED into parent
2032         ilt = ilt-&gt;_child;      // Repeat using new ilt
2033         continue;               // do not advance over ilt-&gt;_child
2034       }
2035       assert( ilt-&gt;_tail == hot_tail, &quot;expected to only find the hot inner loop here&quot; );
2036       phase-&gt;set_loop(_head,ilt);
2037     }
2038     pilt = &amp;ilt-&gt;_child;        // Advance to next
2039     ilt = *pilt;
2040   }
2041 
2042   if( _child ) fix_parent( _child, this );
2043 }
2044 
2045 //------------------------------beautify_loops---------------------------------
2046 // Split shared headers and insert loop landing pads.
2047 // Insert a LoopNode to replace the RegionNode.
2048 // Return TRUE if loop tree is structurally changed.
2049 bool IdealLoopTree::beautify_loops( PhaseIdealLoop *phase ) {
2050   bool result = false;
2051   // Cache parts in locals for easy
2052   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
2053 
2054   igvn.hash_delete(_head);      // Yank from hash before hacking edges
2055 
2056   // Check for multiple fall-in paths.  Peel off a landing pad if need be.
2057   int fall_in_cnt = 0;
2058   for( uint i = 1; i &lt; _head-&gt;req(); i++ )
2059     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
2060       fall_in_cnt++;
2061   assert( fall_in_cnt, &quot;at least 1 fall-in path&quot; );
2062   if( fall_in_cnt &gt; 1 )         // Need a loop landing pad to merge fall-ins
2063     split_fall_in( phase, fall_in_cnt );
2064 
2065   // Swap inputs to the _head and all Phis to move the fall-in edge to
2066   // the left.
2067   fall_in_cnt = 1;
2068   while( phase-&gt;is_member( this, _head-&gt;in(fall_in_cnt) ) )
2069     fall_in_cnt++;
2070   if( fall_in_cnt &gt; 1 ) {
2071     // Since I am just swapping inputs I do not need to update def-use info
2072     Node *tmp = _head-&gt;in(1);
2073     igvn.rehash_node_delayed(_head);
2074     _head-&gt;set_req( 1, _head-&gt;in(fall_in_cnt) );
2075     _head-&gt;set_req( fall_in_cnt, tmp );
2076     // Swap also all Phis
2077     for (DUIterator_Fast imax, i = _head-&gt;fast_outs(imax); i &lt; imax; i++) {
2078       Node* phi = _head-&gt;fast_out(i);
2079       if( phi-&gt;is_Phi() ) {
2080         igvn.rehash_node_delayed(phi); // Yank from hash before hacking edges
2081         tmp = phi-&gt;in(1);
2082         phi-&gt;set_req( 1, phi-&gt;in(fall_in_cnt) );
2083         phi-&gt;set_req( fall_in_cnt, tmp );
2084       }
2085     }
2086   }
2087   assert( !phase-&gt;is_member( this, _head-&gt;in(1) ), &quot;left edge is fall-in&quot; );
2088   assert(  phase-&gt;is_member( this, _head-&gt;in(2) ), &quot;right edge is loop&quot; );
2089 
2090   // If I am a shared header (multiple backedges), peel off the many
2091   // backedges into a private merge point and use the merge point as
2092   // the one true backedge.
2093   if (_head-&gt;req() &gt; 3 &amp;&amp; !_irreducible) {
2094     // Merge the many backedges into a single backedge but leave
2095     // the hottest backedge as separate edge for the following peel.
2096     merge_many_backedges( phase );
2097     result = true;
2098   }
2099 
2100   // If I have one hot backedge, peel off myself loop.
2101   // I better be the outermost loop.
2102   if (_head-&gt;req() &gt; 3 &amp;&amp; !_irreducible) {
2103     split_outer_loop( phase );
2104     result = true;
2105 
2106   } else if (!_head-&gt;is_Loop() &amp;&amp; !_irreducible) {
2107     // Make a new LoopNode to replace the old loop head
2108     Node *l = new LoopNode( _head-&gt;in(1), _head-&gt;in(2) );
2109     l = igvn.register_new_node_with_optimizer(l, _head);
2110     phase-&gt;set_created_loop_node();
2111     // Go ahead and replace _head
2112     phase-&gt;_igvn.replace_node( _head, l );
2113     _head = l;
2114     phase-&gt;set_loop(_head, this);
2115   }
2116 
2117   // Now recursively beautify nested loops
2118   if( _child ) result |= _child-&gt;beautify_loops( phase );
2119   if( _next  ) result |= _next -&gt;beautify_loops( phase );
2120   return result;
2121 }
2122 
2123 //------------------------------allpaths_check_safepts----------------------------
2124 // Allpaths backwards scan from loop tail, terminating each path at first safepoint
2125 // encountered.  Helper for check_safepts.
2126 void IdealLoopTree::allpaths_check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2127   assert(stack.size() == 0, &quot;empty stack&quot;);
2128   stack.push(_tail);
2129   visited.clear();
2130   visited.set(_tail-&gt;_idx);
2131   while (stack.size() &gt; 0) {
2132     Node* n = stack.pop();
2133     if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2134       // Terminate this path
2135     } else if (n-&gt;Opcode() == Op_SafePoint) {
2136       if (_phase-&gt;get_loop(n) != this) {
2137         if (_required_safept == NULL) _required_safept = new Node_List();
2138         _required_safept-&gt;push(n);  // save the one closest to the tail
2139       }
2140       // Terminate this path
2141     } else {
2142       uint start = n-&gt;is_Region() ? 1 : 0;
2143       uint end   = n-&gt;is_Region() &amp;&amp; !n-&gt;is_Loop() ? n-&gt;req() : start + 1;
2144       for (uint i = start; i &lt; end; i++) {
2145         Node* in = n-&gt;in(i);
2146         assert(in-&gt;is_CFG(), &quot;must be&quot;);
2147         if (!visited.test_set(in-&gt;_idx) &amp;&amp; is_member(_phase-&gt;get_loop(in))) {
2148           stack.push(in);
2149         }
2150       }
2151     }
2152   }
2153 }
2154 
2155 //------------------------------check_safepts----------------------------
2156 // Given dominators, try to find loops with calls that must always be
2157 // executed (call dominates loop tail).  These loops do not need non-call
2158 // safepoints (ncsfpt).
2159 //
2160 // A complication is that a safepoint in a inner loop may be needed
2161 // by an outer loop. In the following, the inner loop sees it has a
2162 // call (block 3) on every path from the head (block 2) to the
2163 // backedge (arc 3-&gt;2).  So it deletes the ncsfpt (non-call safepoint)
2164 // in block 2, _but_ this leaves the outer loop without a safepoint.
2165 //
2166 //          entry  0
2167 //                 |
2168 //                 v
2169 // outer 1,2    +-&gt;1
2170 //              |  |
2171 //              |  v
2172 //              |  2&lt;---+  ncsfpt in 2
2173 //              |_/|\   |
2174 //                 | v  |
2175 // inner 2,3      /  3  |  call in 3
2176 //               /   |  |
2177 //              v    +--+
2178 //        exit  4
2179 //
2180 //
2181 // This method creates a list (_required_safept) of ncsfpt nodes that must
2182 // be protected is created for each loop. When a ncsfpt maybe deleted, it
2183 // is first looked for in the lists for the outer loops of the current loop.
2184 //
2185 // The insights into the problem:
2186 //  A) counted loops are okay
2187 //  B) innermost loops are okay (only an inner loop can delete
2188 //     a ncsfpt needed by an outer loop)
2189 //  C) a loop is immune from an inner loop deleting a safepoint
2190 //     if the loop has a call on the idom-path
2191 //  D) a loop is also immune if it has a ncsfpt (non-call safepoint) on the
2192 //     idom-path that is not in a nested loop
2193 //  E) otherwise, an ncsfpt on the idom-path that is nested in an inner
2194 //     loop needs to be prevented from deletion by an inner loop
2195 //
2196 // There are two analyses:
2197 //  1) The first, and cheaper one, scans the loop body from
2198 //     tail to head following the idom (immediate dominator)
2199 //     chain, looking for the cases (C,D,E) above.
2200 //     Since inner loops are scanned before outer loops, there is summary
2201 //     information about inner loops.  Inner loops can be skipped over
2202 //     when the tail of an inner loop is encountered.
2203 //
2204 //  2) The second, invoked if the first fails to find a call or ncsfpt on
2205 //     the idom path (which is rare), scans all predecessor control paths
2206 //     from the tail to the head, terminating a path when a call or sfpt
2207 //     is encountered, to find the ncsfpt&#39;s that are closest to the tail.
2208 //
2209 void IdealLoopTree::check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2210   // Bottom up traversal
2211   IdealLoopTree* ch = _child;
2212   if (_child) _child-&gt;check_safepts(visited, stack);
2213   if (_next)  _next -&gt;check_safepts(visited, stack);
2214 
2215   if (!_head-&gt;is_CountedLoop() &amp;&amp; !_has_sfpt &amp;&amp; _parent != NULL &amp;&amp; !_irreducible) {
2216     bool  has_call         = false; // call on dom-path
2217     bool  has_local_ncsfpt = false; // ncsfpt on dom-path at this loop depth
2218     Node* nonlocal_ncsfpt  = NULL;  // ncsfpt on dom-path at a deeper depth
2219     // Scan the dom-path nodes from tail to head
2220     for (Node* n = tail(); n != _head; n = _phase-&gt;idom(n)) {
2221       if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2222         has_call = true;
2223         _has_sfpt = 1;          // Then no need for a safept!
2224         break;
2225       } else if (n-&gt;Opcode() == Op_SafePoint) {
2226         if (_phase-&gt;get_loop(n) == this) {
2227           has_local_ncsfpt = true;
2228           break;
2229         }
2230         if (nonlocal_ncsfpt == NULL) {
2231           nonlocal_ncsfpt = n; // save the one closest to the tail
2232         }
2233       } else {
2234         IdealLoopTree* nlpt = _phase-&gt;get_loop(n);
2235         if (this != nlpt) {
2236           // If at an inner loop tail, see if the inner loop has already
2237           // recorded seeing a call on the dom-path (and stop.)  If not,
2238           // jump to the head of the inner loop.
2239           assert(is_member(nlpt), &quot;nested loop&quot;);
2240           Node* tail = nlpt-&gt;_tail;
2241           if (tail-&gt;in(0)-&gt;is_If()) tail = tail-&gt;in(0);
2242           if (n == tail) {
2243             // If inner loop has call on dom-path, so does outer loop
2244             if (nlpt-&gt;_has_sfpt) {
2245               has_call = true;
2246               _has_sfpt = 1;
2247               break;
2248             }
2249             // Skip to head of inner loop
2250             assert(_phase-&gt;is_dominator(_head, nlpt-&gt;_head), &quot;inner head dominated by outer head&quot;);
2251             n = nlpt-&gt;_head;
2252           }
2253         }
2254       }
2255     }
2256     // Record safept&#39;s that this loop needs preserved when an
2257     // inner loop attempts to delete it&#39;s safepoints.
2258     if (_child != NULL &amp;&amp; !has_call &amp;&amp; !has_local_ncsfpt) {
2259       if (nonlocal_ncsfpt != NULL) {
2260         if (_required_safept == NULL) _required_safept = new Node_List();
2261         _required_safept-&gt;push(nonlocal_ncsfpt);
2262       } else {
2263         // Failed to find a suitable safept on the dom-path.  Now use
2264         // an all paths walk from tail to head, looking for safepoints to preserve.
2265         allpaths_check_safepts(visited, stack);
2266       }
2267     }
2268   }
2269 }
2270 
2271 //---------------------------is_deleteable_safept----------------------------
2272 // Is safept not required by an outer loop?
2273 bool PhaseIdealLoop::is_deleteable_safept(Node* sfpt) {
2274   assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;&quot;);
2275   IdealLoopTree* lp = get_loop(sfpt)-&gt;_parent;
2276   while (lp != NULL) {
2277     Node_List* sfpts = lp-&gt;_required_safept;
2278     if (sfpts != NULL) {
2279       for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2280         if (sfpt == sfpts-&gt;at(i))
2281           return false;
2282       }
2283     }
2284     lp = lp-&gt;_parent;
2285   }
2286   return true;
2287 }
2288 
2289 //---------------------------replace_parallel_iv-------------------------------
2290 // Replace parallel induction variable (parallel to trip counter)
2291 void PhaseIdealLoop::replace_parallel_iv(IdealLoopTree *loop) {
2292   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
2293   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
2294   if (!cl-&gt;is_valid_counted_loop())
2295     return;         // skip malformed counted loop
2296   Node *incr = cl-&gt;incr();
2297   if (incr == NULL)
2298     return;         // Dead loop?
2299   Node *init = cl-&gt;init_trip();
2300   Node *phi  = cl-&gt;phi();
2301   int stride_con = cl-&gt;stride_con();
2302 
2303   // Visit all children, looking for Phis
2304   for (DUIterator i = cl-&gt;outs(); cl-&gt;has_out(i); i++) {
2305     Node *out = cl-&gt;out(i);
2306     // Look for other phis (secondary IVs). Skip dead ones
2307     if (!out-&gt;is_Phi() || out == phi || !has_node(out))
2308       continue;
2309     PhiNode* phi2 = out-&gt;as_Phi();
2310     Node *incr2 = phi2-&gt;in( LoopNode::LoopBackControl );
2311     // Look for induction variables of the form:  X += constant
2312     if (phi2-&gt;region() != loop-&gt;_head ||
2313         incr2-&gt;req() != 3 ||
2314         incr2-&gt;in(1) != phi2 ||
2315         incr2 == incr ||
2316         incr2-&gt;Opcode() != Op_AddI ||
2317         !incr2-&gt;in(2)-&gt;is_Con())
2318       continue;
2319 
2320     // Check for parallel induction variable (parallel to trip counter)
2321     // via an affine function.  In particular, count-down loops with
2322     // count-up array indices are common. We only RCE references off
2323     // the trip-counter, so we need to convert all these to trip-counter
2324     // expressions.
2325     Node *init2 = phi2-&gt;in( LoopNode::EntryControl );
2326     int stride_con2 = incr2-&gt;in(2)-&gt;get_int();
2327 
2328     // The ratio of the two strides cannot be represented as an int
2329     // if stride_con2 is min_int and stride_con is -1.
2330     if (stride_con2 == min_jint &amp;&amp; stride_con == -1) {
2331       continue;
2332     }
2333 
2334     // The general case here gets a little tricky.  We want to find the
2335     // GCD of all possible parallel IV&#39;s and make a new IV using this
2336     // GCD for the loop.  Then all possible IVs are simple multiples of
2337     // the GCD.  In practice, this will cover very few extra loops.
2338     // Instead we require &#39;stride_con2&#39; to be a multiple of &#39;stride_con&#39;,
2339     // where +/-1 is the common case, but other integer multiples are
2340     // also easy to handle.
2341     int ratio_con = stride_con2/stride_con;
2342 
2343     if ((ratio_con * stride_con) == stride_con2) { // Check for exact
2344 #ifndef PRODUCT
2345       if (TraceLoopOpts) {
2346         tty-&gt;print(&quot;Parallel IV: %d &quot;, phi2-&gt;_idx);
2347         loop-&gt;dump_head();
2348       }
2349 #endif
2350       // Convert to using the trip counter.  The parallel induction
2351       // variable differs from the trip counter by a loop-invariant
2352       // amount, the difference between their respective initial values.
2353       // It is scaled by the &#39;ratio_con&#39;.
2354       Node* ratio = _igvn.intcon(ratio_con);
2355       set_ctrl(ratio, C-&gt;root());
2356       Node* ratio_init = new MulINode(init, ratio);
2357       _igvn.register_new_node_with_optimizer(ratio_init, init);
2358       set_early_ctrl(ratio_init);
2359       Node* diff = new SubINode(init2, ratio_init);
2360       _igvn.register_new_node_with_optimizer(diff, init2);
2361       set_early_ctrl(diff);
2362       Node* ratio_idx = new MulINode(phi, ratio);
2363       _igvn.register_new_node_with_optimizer(ratio_idx, phi);
2364       set_ctrl(ratio_idx, cl);
2365       Node* add = new AddINode(ratio_idx, diff);
2366       _igvn.register_new_node_with_optimizer(add);
2367       set_ctrl(add, cl);
2368       _igvn.replace_node( phi2, add );
2369       // Sometimes an induction variable is unused
2370       if (add-&gt;outcnt() == 0) {
2371         _igvn.remove_dead_node(add);
2372       }
2373       --i; // deleted this phi; rescan starting with next position
2374       continue;
2375     }
2376   }
2377 }
2378 
2379 void IdealLoopTree::remove_safepoints(PhaseIdealLoop* phase, bool keep_one) {
2380   Node* keep = NULL;
2381   if (keep_one) {
2382     // Look for a safepoint on the idom-path.
2383     for (Node* i = tail(); i != _head; i = phase-&gt;idom(i)) {
2384       if (i-&gt;Opcode() == Op_SafePoint &amp;&amp; phase-&gt;get_loop(i) == this) {
2385         keep = i;
2386         break; // Found one
2387       }
2388     }
2389   }
2390 
2391   // Don&#39;t remove any safepoints if it is requested to keep a single safepoint and
2392   // no safepoint was found on idom-path. It is not safe to remove any safepoint
2393   // in this case since there&#39;s no safepoint dominating all paths in the loop body.
2394   bool prune = !keep_one || keep != NULL;
2395 
2396   // Delete other safepoints in this loop.
2397   Node_List* sfpts = _safepts;
2398   if (prune &amp;&amp; sfpts != NULL) {
2399     assert(keep == NULL || keep-&gt;Opcode() == Op_SafePoint, &quot;not safepoint&quot;);
2400     for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2401       Node* n = sfpts-&gt;at(i);
2402       assert(phase-&gt;get_loop(n) == this, &quot;&quot;);
2403       if (n != keep &amp;&amp; phase-&gt;is_deleteable_safept(n)) {
2404         phase-&gt;lazy_replace(n, n-&gt;in(TypeFunc::Control));
2405       }
2406     }
2407   }
2408 }
2409 
2410 //------------------------------counted_loop-----------------------------------
2411 // Convert to counted loops where possible
2412 void IdealLoopTree::counted_loop( PhaseIdealLoop *phase ) {
2413 
2414   // For grins, set the inner-loop flag here
2415   if (!_child) {
2416     if (_head-&gt;is_Loop()) _head-&gt;as_Loop()-&gt;set_inner_loop();
2417   }
2418 
2419   IdealLoopTree* loop = this;
2420   if (_head-&gt;is_CountedLoop() ||
2421       phase-&gt;is_counted_loop(_head, loop)) {
2422 
2423     if (LoopStripMiningIter == 0 || (LoopStripMiningIter &gt; 1 &amp;&amp; _child == NULL)) {
2424       // Indicate we do not need a safepoint here
2425       _has_sfpt = 1;
2426     }
2427 
2428     // Remove safepoints
2429     bool keep_one_sfpt = !(_has_call || _has_sfpt);
2430     remove_safepoints(phase, keep_one_sfpt);
2431 
2432     // Look for induction variables
2433     phase-&gt;replace_parallel_iv(this);
2434 
2435   } else if (_parent != NULL &amp;&amp; !_irreducible) {
2436     // Not a counted loop. Keep one safepoint.
2437     bool keep_one_sfpt = true;
2438     remove_safepoints(phase, keep_one_sfpt);
2439   }
2440 
2441   // Recursively
2442   assert(loop-&gt;_child != this || (loop-&gt;_head-&gt;as_Loop()-&gt;is_OuterStripMinedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_strip_mined()), &quot;what kind of loop was added?&quot;);
2443   assert(loop-&gt;_child != this || (loop-&gt;_child-&gt;_child == NULL &amp;&amp; loop-&gt;_child-&gt;_next == NULL), &quot;would miss some loops&quot;);
2444   if (loop-&gt;_child &amp;&amp; loop-&gt;_child != this) loop-&gt;_child-&gt;counted_loop(phase);
2445   if (loop-&gt;_next)  loop-&gt;_next -&gt;counted_loop(phase);
2446 }
2447 
2448 
2449 // The Estimated Loop Clone Size:
2450 //   CloneFactor * (~112% * BodySize + BC) + CC + FanOutTerm,
2451 // where  BC and  CC are  totally ad-hoc/magic  &quot;body&quot; and &quot;clone&quot; constants,
2452 // respectively, used to ensure that the node usage estimates made are on the
2453 // safe side, for the most part. The FanOutTerm is an attempt to estimate the
2454 // possible additional/excessive nodes generated due to data and control flow
2455 // merging, for edges reaching outside the loop.
2456 uint IdealLoopTree::est_loop_clone_sz(uint factor) const {
2457 
2458   precond(0 &lt; factor &amp;&amp; factor &lt; 16);
2459 
2460   uint const bc = 13;
2461   uint const cc = 17;
2462   uint const sz = _body.size() + (_body.size() + 7) / 8;
2463   uint estimate = factor * (sz + bc) + cc;
2464 
2465   assert((estimate - cc) / factor == sz + bc, &quot;overflow&quot;);
2466 
2467   return estimate + est_loop_flow_merge_sz();
2468 }
2469 
2470 // The Estimated Loop (full-) Unroll Size:
2471 //   UnrollFactor * (~106% * BodySize) + CC + FanOutTerm,
2472 // where CC is a (totally) ad-hoc/magic &quot;clone&quot; constant, used to ensure that
2473 // node usage estimates made are on the safe side, for the most part. This is
2474 // a &quot;light&quot; version of the loop clone size calculation (above), based on the
2475 // assumption that most of the loop-construct overhead will be unraveled when
2476 // (fully) unrolled. Defined for unroll factors larger or equal to one (&gt;=1),
2477 // including an overflow check and returning UINT_MAX in case of an overflow.
2478 uint IdealLoopTree::est_loop_unroll_sz(uint factor) const {
2479 
2480   precond(factor &gt; 0);
2481 
2482   // Take into account that after unroll conjoined heads and tails will fold.
2483   uint const b0 = _body.size() - EMPTY_LOOP_SIZE;
2484   uint const cc = 7;
2485   uint const sz = b0 + (b0 + 15) / 16;
2486   uint estimate = factor * sz + cc;
2487 
2488   if ((estimate - cc) / factor != sz) {
2489     return UINT_MAX;
2490   }
2491 
2492   return estimate + est_loop_flow_merge_sz();
2493 }
2494 
2495 // Estimate the growth effect (in nodes) of merging control and data flow when
2496 // cloning a loop body, based on the amount of  control and data flow reaching
2497 // outside of the (current) loop body.
2498 uint IdealLoopTree::est_loop_flow_merge_sz() const {
2499 
2500   uint ctrl_edge_out_cnt = 0;
2501   uint data_edge_out_cnt = 0;
2502 
2503   for (uint i = 0; i &lt; _body.size(); i++) {
2504     Node* node = _body.at(i);
2505     uint outcnt = node-&gt;outcnt();
2506 
2507     for (uint k = 0; k &lt; outcnt; k++) {
2508       Node* out = node-&gt;raw_out(k);
2509       if (out == NULL) continue;
2510       if (out-&gt;is_CFG()) {
2511         if (!is_member(_phase-&gt;get_loop(out))) {
2512           ctrl_edge_out_cnt++;
2513         }
2514       } else if (_phase-&gt;has_ctrl(out)) {
2515         Node* ctrl = _phase-&gt;get_ctrl(out);
2516         assert(ctrl != NULL, &quot;must be&quot;);
2517         assert(ctrl-&gt;is_CFG(), &quot;must be&quot;);
2518         if (!is_member(_phase-&gt;get_loop(ctrl))) {
2519           data_edge_out_cnt++;
2520         }
2521       }
2522     }
2523   }
2524   // Use data and control count (x2.0) in estimate iff both are &gt; 0. This is
2525   // a rather pessimistic estimate for the most part, in particular for some
2526   // complex loops, but still not enough to capture all loops.
2527   if (ctrl_edge_out_cnt &gt; 0 &amp;&amp; data_edge_out_cnt &gt; 0) {
2528     return 2 * (ctrl_edge_out_cnt + data_edge_out_cnt);
2529   }
2530   return 0;
2531 }
2532 
2533 #ifndef PRODUCT
2534 //------------------------------dump_head--------------------------------------
2535 // Dump 1 liner for loop header info
2536 void IdealLoopTree::dump_head() const {
2537   tty-&gt;sp(2 * _nest);
2538   tty-&gt;print(&quot;Loop: N%d/N%d &quot;, _head-&gt;_idx, _tail-&gt;_idx);
2539   if (_irreducible) tty-&gt;print(&quot; IRREDUCIBLE&quot;);
2540   Node* entry = _head-&gt;is_Loop() ? _head-&gt;as_Loop()-&gt;skip_strip_mined(-1)-&gt;in(LoopNode::EntryControl) : _head-&gt;in(LoopNode::EntryControl);
2541   Node* predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_loop_limit_check);
2542   if (predicate != NULL ) {
2543     tty-&gt;print(&quot; limit_check&quot;);
2544     entry = PhaseIdealLoop::skip_loop_predicates(entry);
2545   }
2546   if (UseProfiledLoopPredicate) {
2547     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_profile_predicate);
2548     if (predicate != NULL) {
2549       tty-&gt;print(&quot; profile_predicated&quot;);
2550       entry = PhaseIdealLoop::skip_loop_predicates(entry);
2551     }
2552   }
2553   if (UseLoopPredicate) {
2554     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_predicate);
2555     if (predicate != NULL) {
2556       tty-&gt;print(&quot; predicated&quot;);
2557     }
2558   }
2559   if (_head-&gt;is_CountedLoop()) {
2560     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
2561     tty-&gt;print(&quot; counted&quot;);
2562 
2563     Node* init_n = cl-&gt;init_trip();
2564     if (init_n  != NULL &amp;&amp;  init_n-&gt;is_Con())
2565       tty-&gt;print(&quot; [%d,&quot;, cl-&gt;init_trip()-&gt;get_int());
2566     else
2567       tty-&gt;print(&quot; [int,&quot;);
2568     Node* limit_n = cl-&gt;limit();
2569     if (limit_n  != NULL &amp;&amp;  limit_n-&gt;is_Con())
2570       tty-&gt;print(&quot;%d),&quot;, cl-&gt;limit()-&gt;get_int());
2571     else
2572       tty-&gt;print(&quot;int),&quot;);
2573     int stride_con  = cl-&gt;stride_con();
2574     if (stride_con &gt; 0) tty-&gt;print(&quot;+&quot;);
2575     tty-&gt;print(&quot;%d&quot;, stride_con);
2576 
2577     tty-&gt;print(&quot; (%0.f iters) &quot;, cl-&gt;profile_trip_cnt());
2578 
2579     if (cl-&gt;is_pre_loop ()) tty-&gt;print(&quot; pre&quot; );
2580     if (cl-&gt;is_main_loop()) tty-&gt;print(&quot; main&quot;);
2581     if (cl-&gt;is_post_loop()) tty-&gt;print(&quot; post&quot;);
2582     if (cl-&gt;is_vectorized_loop()) tty-&gt;print(&quot; vector&quot;);
2583     if (cl-&gt;range_checks_present()) tty-&gt;print(&quot; rc &quot;);
2584     if (cl-&gt;is_multiversioned()) tty-&gt;print(&quot; multi &quot;);
2585   }
2586   if (_has_call) tty-&gt;print(&quot; has_call&quot;);
2587   if (_has_sfpt) tty-&gt;print(&quot; has_sfpt&quot;);
2588   if (_rce_candidate) tty-&gt;print(&quot; rce&quot;);
2589   if (_safepts != NULL &amp;&amp; _safepts-&gt;size() &gt; 0) {
2590     tty-&gt;print(&quot; sfpts={&quot;); _safepts-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2591   }
2592   if (_required_safept != NULL &amp;&amp; _required_safept-&gt;size() &gt; 0) {
2593     tty-&gt;print(&quot; req={&quot;); _required_safept-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2594   }
2595   if (Verbose) {
2596     tty-&gt;print(&quot; body={&quot;); _body.dump_simple(); tty-&gt;print(&quot; }&quot;);
2597   }
2598   if (_head-&gt;is_Loop() &amp;&amp; _head-&gt;as_Loop()-&gt;is_strip_mined()) {
2599     tty-&gt;print(&quot; strip_mined&quot;);
2600   }
2601   tty-&gt;cr();
2602 }
2603 
2604 //------------------------------dump-------------------------------------------
2605 // Dump loops by loop tree
2606 void IdealLoopTree::dump() const {
2607   dump_head();
2608   if (_child) _child-&gt;dump();
2609   if (_next)  _next -&gt;dump();
2610 }
2611 
2612 #endif
2613 
2614 static void log_loop_tree(IdealLoopTree* root, IdealLoopTree* loop, CompileLog* log) {
2615   if (loop == root) {
2616     if (loop-&gt;_child != NULL) {
2617       log-&gt;begin_head(&quot;loop_tree&quot;);
2618       log-&gt;end_head();
2619       if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2620       log-&gt;tail(&quot;loop_tree&quot;);
2621       assert(loop-&gt;_next == NULL, &quot;what?&quot;);
2622     }
2623   } else {
2624     Node* head = loop-&gt;_head;
2625     log-&gt;begin_head(&quot;loop&quot;);
2626     log-&gt;print(&quot; idx=&#39;%d&#39; &quot;, head-&gt;_idx);
2627     if (loop-&gt;_irreducible) log-&gt;print(&quot;irreducible=&#39;1&#39; &quot;);
2628     if (head-&gt;is_Loop()) {
2629       if (head-&gt;as_Loop()-&gt;is_inner_loop()) log-&gt;print(&quot;inner_loop=&#39;1&#39; &quot;);
2630       if (head-&gt;as_Loop()-&gt;is_partial_peel_loop()) log-&gt;print(&quot;partial_peel_loop=&#39;1&#39; &quot;);
2631     }
2632     if (head-&gt;is_CountedLoop()) {
2633       CountedLoopNode* cl = head-&gt;as_CountedLoop();
2634       if (cl-&gt;is_pre_loop())  log-&gt;print(&quot;pre_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2635       if (cl-&gt;is_main_loop()) log-&gt;print(&quot;main_loop=&#39;%d&#39; &quot;, cl-&gt;_idx);
2636       if (cl-&gt;is_post_loop()) log-&gt;print(&quot;post_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2637     }
2638     log-&gt;end_head();
2639     if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2640     log-&gt;tail(&quot;loop&quot;);
2641     if( loop-&gt;_next  ) log_loop_tree(root, loop-&gt;_next, log);
2642   }
2643 }
2644 
2645 //---------------------collect_potentially_useful_predicates-----------------------
2646 // Helper function to collect potentially useful predicates to prevent them from
2647 // being eliminated by PhaseIdealLoop::eliminate_useless_predicates
2648 void PhaseIdealLoop::collect_potentially_useful_predicates(
2649                          IdealLoopTree * loop, Unique_Node_List &amp;useful_predicates) {
2650   if (loop-&gt;_child) { // child
2651     collect_potentially_useful_predicates(loop-&gt;_child, useful_predicates);
2652   }
2653 
2654   // self (only loops that we can apply loop predication may use their predicates)
2655   if (loop-&gt;_head-&gt;is_Loop() &amp;&amp;
2656       !loop-&gt;_irreducible    &amp;&amp;
2657       !loop-&gt;tail()-&gt;is_top()) {
2658     LoopNode* lpn = loop-&gt;_head-&gt;as_Loop();
2659     Node* entry = lpn-&gt;in(LoopNode::EntryControl);
2660     Node* predicate_proj = find_predicate(entry); // loop_limit_check first
2661     if (predicate_proj != NULL) { // right pattern that can be used by loop predication
2662       assert(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2663       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2664       entry = skip_loop_predicates(entry);
2665     }
2666     if (UseProfiledLoopPredicate) {
2667       predicate_proj = find_predicate(entry); // Predicate
2668       if (predicate_proj != NULL) {
2669         useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2670         entry = skip_loop_predicates(entry);
2671       }
2672     }
2673     predicate_proj = find_predicate(entry); // Predicate
2674     if (predicate_proj != NULL) {
2675       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2676     }
2677   }
2678 
2679   if (loop-&gt;_next) { // sibling
2680     collect_potentially_useful_predicates(loop-&gt;_next, useful_predicates);
2681   }
2682 }
2683 
2684 //------------------------eliminate_useless_predicates-----------------------------
2685 // Eliminate all inserted predicates if they could not be used by loop predication.
2686 // Note: it will also eliminates loop limits check predicate since it also uses
2687 // Opaque1 node (see Parse::add_predicate()).
2688 void PhaseIdealLoop::eliminate_useless_predicates() {
2689   if (C-&gt;predicate_count() == 0)
2690     return; // no predicate left
2691 
2692   Unique_Node_List useful_predicates; // to store useful predicates
2693   if (C-&gt;has_loops()) {
2694     collect_potentially_useful_predicates(_ltree_root-&gt;_child, useful_predicates);
2695   }
2696 
2697   for (int i = C-&gt;predicate_count(); i &gt; 0; i--) {
2698      Node * n = C-&gt;predicate_opaque1_node(i-1);
2699      assert(n-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2700      if (!useful_predicates.member(n)) { // not in the useful list
2701        _igvn.replace_node(n, n-&gt;in(1));
2702      }
2703   }
2704 }
2705 
2706 //------------------------process_expensive_nodes-----------------------------
2707 // Expensive nodes have their control input set to prevent the GVN
2708 // from commoning them and as a result forcing the resulting node to
2709 // be in a more frequent path. Use CFG information here, to change the
2710 // control inputs so that some expensive nodes can be commoned while
2711 // not executed more frequently.
2712 bool PhaseIdealLoop::process_expensive_nodes() {
2713   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
2714 
2715   // Sort nodes to bring similar nodes together
2716   C-&gt;sort_expensive_nodes();
2717 
2718   bool progress = false;
2719 
2720   for (int i = 0; i &lt; C-&gt;expensive_count(); ) {
2721     Node* n = C-&gt;expensive_node(i);
2722     int start = i;
2723     // Find nodes similar to n
2724     i++;
2725     for (; i &lt; C-&gt;expensive_count() &amp;&amp; Compile::cmp_expensive_nodes(n, C-&gt;expensive_node(i)) == 0; i++);
2726     int end = i;
2727     // And compare them two by two
2728     for (int j = start; j &lt; end; j++) {
2729       Node* n1 = C-&gt;expensive_node(j);
2730       if (is_node_unreachable(n1)) {
2731         continue;
2732       }
2733       for (int k = j+1; k &lt; end; k++) {
2734         Node* n2 = C-&gt;expensive_node(k);
2735         if (is_node_unreachable(n2)) {
2736           continue;
2737         }
2738 
2739         assert(n1 != n2, &quot;should be pair of nodes&quot;);
2740 
2741         Node* c1 = n1-&gt;in(0);
2742         Node* c2 = n2-&gt;in(0);
2743 
2744         Node* parent_c1 = c1;
2745         Node* parent_c2 = c2;
2746 
2747         // The call to get_early_ctrl_for_expensive() moves the
2748         // expensive nodes up but stops at loops that are in a if
2749         // branch. See whether we can exit the loop and move above the
2750         // If.
2751         if (c1-&gt;is_Loop()) {
2752           parent_c1 = c1-&gt;in(1);
2753         }
2754         if (c2-&gt;is_Loop()) {
2755           parent_c2 = c2-&gt;in(1);
2756         }
2757 
2758         if (parent_c1 == parent_c2) {
2759           _igvn._worklist.push(n1);
2760           _igvn._worklist.push(n2);
2761           continue;
2762         }
2763 
2764         // Look for identical expensive node up the dominator chain.
2765         if (is_dominator(c1, c2)) {
2766           c2 = c1;
2767         } else if (is_dominator(c2, c1)) {
2768           c1 = c2;
2769         } else if (parent_c1-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0)-&gt;is_If() &amp;&amp;
2770                    parent_c2-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0) == parent_c2-&gt;in(0)) {
2771           // Both branches have the same expensive node so move it up
2772           // before the if.
2773           c1 = c2 = idom(parent_c1-&gt;in(0));
2774         }
2775         // Do the actual moves
2776         if (n1-&gt;in(0) != c1) {
2777           _igvn.hash_delete(n1);
2778           n1-&gt;set_req(0, c1);
2779           _igvn.hash_insert(n1);
2780           _igvn._worklist.push(n1);
2781           progress = true;
2782         }
2783         if (n2-&gt;in(0) != c2) {
2784           _igvn.hash_delete(n2);
2785           n2-&gt;set_req(0, c2);
2786           _igvn.hash_insert(n2);
2787           _igvn._worklist.push(n2);
2788           progress = true;
2789         }
2790       }
2791     }
2792   }
2793 
2794   return progress;
2795 }
2796 
2797 
2798 //=============================================================================
2799 //----------------------------build_and_optimize-------------------------------
2800 // Create a PhaseLoop.  Build the ideal Loop tree.  Map each Ideal Node to
2801 // its corresponding LoopNode.  If &#39;optimize&#39; is true, do some loop cleanups.
2802 void PhaseIdealLoop::build_and_optimize(LoopOptsMode mode) {
2803   bool do_split_ifs = (mode == LoopOptsDefault);
2804   bool skip_loop_opts = (mode == LoopOptsNone);
2805 
2806   int old_progress = C-&gt;major_progress();
2807   uint orig_worklist_size = _igvn._worklist.size();
2808 
2809   // Reset major-progress flag for the driver&#39;s heuristics
2810   C-&gt;clear_major_progress();
2811 
2812 #ifndef PRODUCT
2813   // Capture for later assert
2814   uint unique = C-&gt;unique();
2815   _loop_invokes++;
2816   _loop_work += unique;
2817 #endif
2818 
2819   // True if the method has at least 1 irreducible loop
2820   _has_irreducible_loops = false;
2821 
2822   _created_loop_node = false;
2823 
2824   Arena *a = Thread::current()-&gt;resource_area();
2825   VectorSet visited(a);
2826   // Pre-grow the mapping from Nodes to IdealLoopTrees.
2827   _nodes.map(C-&gt;unique(), NULL);
2828   memset(_nodes.adr(), 0, wordSize * C-&gt;unique());
2829 
2830   // Pre-build the top-level outermost loop tree entry
2831   _ltree_root = new IdealLoopTree( this, C-&gt;root(), C-&gt;root() );
2832   // Do not need a safepoint at the top level
2833   _ltree_root-&gt;_has_sfpt = 1;
2834 
2835   // Initialize Dominators.
2836   // Checked in clone_loop_predicate() during beautify_loops().
2837   _idom_size = 0;
2838   _idom      = NULL;
2839   _dom_depth = NULL;
2840   _dom_stk   = NULL;
2841 
2842   // Empty pre-order array
2843   allocate_preorders();
2844 
2845   // Build a loop tree on the fly.  Build a mapping from CFG nodes to
2846   // IdealLoopTree entries.  Data nodes are NOT walked.
2847   build_loop_tree();
2848   // Check for bailout, and return
2849   if (C-&gt;failing()) {
2850     return;
2851   }
2852 
2853   // No loops after all
2854   if( !_ltree_root-&gt;_child &amp;&amp; !_verify_only ) C-&gt;set_has_loops(false);
2855 
2856   // There should always be an outer loop containing the Root and Return nodes.
2857   // If not, we have a degenerate empty program.  Bail out in this case.
2858   if (!has_node(C-&gt;root())) {
2859     if (!_verify_only) {
2860       C-&gt;clear_major_progress();
2861       C-&gt;record_method_not_compilable(&quot;empty program detected during loop optimization&quot;);
2862     }
2863     return;
2864   }
2865 
2866   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
2867   // Nothing to do, so get out
2868   bool stop_early = !C-&gt;has_loops() &amp;&amp; !skip_loop_opts &amp;&amp; !do_split_ifs &amp;&amp; !_verify_me &amp;&amp; !_verify_only &amp;&amp;
2869     !bs-&gt;is_gc_specific_loop_opts_pass(mode);
2870   bool do_expensive_nodes = C-&gt;should_optimize_expensive_nodes(_igvn);
2871   bool strip_mined_loops_expanded = bs-&gt;strip_mined_loops_expanded(mode);
2872   if (stop_early &amp;&amp; !do_expensive_nodes) {
2873     _igvn.optimize();           // Cleanup NeverBranches
2874     return;
2875   }
2876 
2877   // Set loop nesting depth
2878   _ltree_root-&gt;set_nest( 0 );
2879 
2880   // Split shared headers and insert loop landing pads.
2881   // Do not bother doing this on the Root loop of course.
2882   if( !_verify_me &amp;&amp; !_verify_only &amp;&amp; _ltree_root-&gt;_child ) {
2883     C-&gt;print_method(PHASE_BEFORE_BEAUTIFY_LOOPS, 3);
2884     if( _ltree_root-&gt;_child-&gt;beautify_loops( this ) ) {
2885       // Re-build loop tree!
2886       _ltree_root-&gt;_child = NULL;
2887       _nodes.clear();
2888       reallocate_preorders();
2889       build_loop_tree();
2890       // Check for bailout, and return
2891       if (C-&gt;failing()) {
2892         return;
2893       }
2894       // Reset loop nesting depth
2895       _ltree_root-&gt;set_nest( 0 );
2896 
2897       C-&gt;print_method(PHASE_AFTER_BEAUTIFY_LOOPS, 3);
2898     }
2899   }
2900 
2901   // Build Dominators for elision of NULL checks &amp; loop finding.
2902   // Since nodes do not have a slot for immediate dominator, make
2903   // a persistent side array for that info indexed on node-&gt;_idx.
2904   _idom_size = C-&gt;unique();
2905   _idom      = NEW_RESOURCE_ARRAY( Node*, _idom_size );
2906   _dom_depth = NEW_RESOURCE_ARRAY( uint,  _idom_size );
2907   _dom_stk   = NULL; // Allocated on demand in recompute_dom_depth
2908   memset( _dom_depth, 0, _idom_size * sizeof(uint) );
2909 
2910   Dominators();
2911 
2912   if (!_verify_only) {
2913     // As a side effect, Dominators removed any unreachable CFG paths
2914     // into RegionNodes.  It doesn&#39;t do this test against Root, so
2915     // we do it here.
2916     for( uint i = 1; i &lt; C-&gt;root()-&gt;req(); i++ ) {
2917       if( !_nodes[C-&gt;root()-&gt;in(i)-&gt;_idx] ) {    // Dead path into Root?
2918         _igvn.delete_input_of(C-&gt;root(), i);
2919         i--;                      // Rerun same iteration on compressed edges
2920       }
2921     }
2922 
2923     // Given dominators, try to find inner loops with calls that must
2924     // always be executed (call dominates loop tail).  These loops do
2925     // not need a separate safepoint.
2926     Node_List cisstack(a);
2927     _ltree_root-&gt;check_safepts(visited, cisstack);
2928   }
2929 
2930   // Walk the DATA nodes and place into loops.  Find earliest control
2931   // node.  For CFG nodes, the _nodes array starts out and remains
2932   // holding the associated IdealLoopTree pointer.  For DATA nodes, the
2933   // _nodes array holds the earliest legal controlling CFG node.
2934 
2935   // Allocate stack with enough space to avoid frequent realloc
2936   int stack_size = (C-&gt;live_nodes() &gt;&gt; 1) + 16; // (live_nodes&gt;&gt;1)+16 from Java2D stats
2937   Node_Stack nstack( a, stack_size );
2938 
2939   visited.clear();
2940   Node_List worklist(a);
2941   // Don&#39;t need C-&gt;root() on worklist since
2942   // it will be processed among C-&gt;top() inputs
2943   worklist.push(C-&gt;top());
2944   visited.set(C-&gt;top()-&gt;_idx); // Set C-&gt;top() as visited now
2945   build_loop_early( visited, worklist, nstack );
2946 
2947   // Given early legal placement, try finding counted loops.  This placement
2948   // is good enough to discover most loop invariants.
2949   if (!_verify_me &amp;&amp; !_verify_only &amp;&amp; !strip_mined_loops_expanded) {
2950     _ltree_root-&gt;counted_loop( this );
2951   }
2952 
2953   // Find latest loop placement.  Find ideal loop placement.
2954   visited.clear();
2955   init_dom_lca_tags();
2956   // Need C-&gt;root() on worklist when processing outs
2957   worklist.push(C-&gt;root());
2958   NOT_PRODUCT( C-&gt;verify_graph_edges(); )
2959   worklist.push(C-&gt;top());
2960   build_loop_late( visited, worklist, nstack );
2961 
2962   if (_verify_only) {
2963     C-&gt;restore_major_progress(old_progress);
2964     assert(C-&gt;unique() == unique, &quot;verification mode made Nodes? ? ?&quot;);
2965     assert(_igvn._worklist.size() == orig_worklist_size, &quot;shouldn&#39;t push anything&quot;);
2966     return;
2967   }
2968 
2969   // clear out the dead code after build_loop_late
2970   while (_deadlist.size()) {
2971     _igvn.remove_globally_dead_node(_deadlist.pop());
2972   }
2973 
2974   if (stop_early) {
2975     assert(do_expensive_nodes, &quot;why are we here?&quot;);
2976     if (process_expensive_nodes()) {
2977       // If we made some progress when processing expensive nodes then
2978       // the IGVN may modify the graph in a way that will allow us to
2979       // make some more progress: we need to try processing expensive
2980       // nodes again.
2981       C-&gt;set_major_progress();
2982     }
2983     _igvn.optimize();
2984     return;
2985   }
2986 
2987   // Some parser-inserted loop predicates could never be used by loop
2988   // predication or they were moved away from loop during some optimizations.
2989   // For example, peeling. Eliminate them before next loop optimizations.
2990   eliminate_useless_predicates();
2991 
2992 #ifndef PRODUCT
2993   C-&gt;verify_graph_edges();
2994   if (_verify_me) {             // Nested verify pass?
2995     // Check to see if the verify mode is broken
2996     assert(C-&gt;unique() == unique, &quot;non-optimize mode made Nodes? ? ?&quot;);
2997     return;
2998   }
2999   if (VerifyLoopOptimizations) verify();
3000   if (TraceLoopOpts &amp;&amp; C-&gt;has_loops()) {
3001     _ltree_root-&gt;dump();
3002   }
3003 #endif
3004 
3005   if (skip_loop_opts) {
3006     // restore major progress flag
3007     C-&gt;restore_major_progress(old_progress);
3008 
3009     // Cleanup any modified bits
3010     _igvn.optimize();
3011 
3012     if (C-&gt;log() != NULL) {
3013       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3014     }
3015     return;
3016   }
3017 
3018   if (mode == LoopOptsMaxUnroll) {
3019     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3020       IdealLoopTree* lpt = iter.current();
3021       if (lpt-&gt;is_innermost() &amp;&amp; lpt-&gt;_allow_optimizations &amp;&amp; !lpt-&gt;_has_call &amp;&amp; lpt-&gt;is_counted()) {
3022         lpt-&gt;compute_trip_count(this);
3023         if (!lpt-&gt;do_one_iteration_loop(this) &amp;&amp;
3024             !lpt-&gt;do_remove_empty_loop(this)) {
3025           AutoNodeBudget node_budget(this);
3026           if (lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_normal_loop() &amp;&amp;
3027               lpt-&gt;policy_maximally_unroll(this)) {
3028             memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3029             do_maximally_unroll(lpt, worklist);
3030           }
3031         }
3032       }
3033     }
3034 
3035     C-&gt;restore_major_progress(old_progress);
3036 
3037     _igvn.optimize();
3038 
3039     if (C-&gt;log() != NULL) {
3040       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3041     }
3042     return;
3043   }
3044 
3045   if (bs-&gt;optimize_loops(this, mode, visited, nstack, worklist)) {
3046     _igvn.optimize();
3047     if (C-&gt;log() != NULL) {
3048       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3049     }
3050     return;
3051   }
3052 
3053   if (ReassociateInvariants) {
3054     // Reassociate invariants and prep for split_thru_phi
3055     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3056       IdealLoopTree* lpt = iter.current();
3057       bool is_counted = lpt-&gt;is_counted();
3058       if (!is_counted || !lpt-&gt;is_innermost()) continue;
3059 
3060       // check for vectorized loops, any reassociation of invariants was already done
3061       if (is_counted &amp;&amp; lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_unroll_only()) {
3062         continue;
3063       } else {
3064         AutoNodeBudget node_budget(this);
3065         lpt-&gt;reassociate_invariants(this);
3066       }
3067       // Because RCE opportunities can be masked by split_thru_phi,
3068       // look for RCE candidates and inhibit split_thru_phi
3069       // on just their loop-phi&#39;s for this pass of loop opts
3070       if (SplitIfBlocks &amp;&amp; do_split_ifs) {
3071         AutoNodeBudget node_budget(this, AutoNodeBudget::NO_BUDGET_CHECK);
3072         if (lpt-&gt;policy_range_check(this)) {
3073           lpt-&gt;_rce_candidate = 1; // = true
3074         }
3075       }
3076     }
3077   }
3078 
3079   // Check for aggressive application of split-if and other transforms
3080   // that require basic-block info (like cloning through Phi&#39;s)
3081   if( SplitIfBlocks &amp;&amp; do_split_ifs ) {
3082     visited.clear();
3083     split_if_with_blocks( visited, nstack);
3084     NOT_PRODUCT( if( VerifyLoopOptimizations ) verify(); );
3085   }
3086 
3087   if (!C-&gt;major_progress() &amp;&amp; do_expensive_nodes &amp;&amp; process_expensive_nodes()) {
3088     C-&gt;set_major_progress();
3089   }
3090 
3091   // Perform loop predication before iteration splitting
3092   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3093     _ltree_root-&gt;_child-&gt;loop_predication(this);
3094   }
3095 
3096   if (OptimizeFill &amp;&amp; UseLoopPredicate &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3097     if (do_intrinsify_fill()) {
3098       C-&gt;set_major_progress();
3099     }
3100   }
3101 
3102   // Perform iteration-splitting on inner loops.  Split iterations to avoid
3103   // range checks or one-shot null checks.
3104 
3105   // If split-if&#39;s didn&#39;t hack the graph too bad (no CFG changes)
3106   // then do loop opts.
3107   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3108     memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3109     _ltree_root-&gt;_child-&gt;iteration_split( this, worklist );
3110     // No verify after peeling!  GCM has hoisted code out of the loop.
3111     // After peeling, the hoisted code could sink inside the peeled area.
3112     // The peeling code does not try to recompute the best location for
3113     // all the code before the peeled area, so the verify pass will always
3114     // complain about it.
3115   }
3116   // Do verify graph edges in any case
3117   NOT_PRODUCT( C-&gt;verify_graph_edges(); );
3118 
3119   if (!do_split_ifs) {
3120     // We saw major progress in Split-If to get here.  We forced a
3121     // pass with unrolling and not split-if, however more split-if&#39;s
3122     // might make progress.  If the unrolling didn&#39;t make progress
3123     // then the major-progress flag got cleared and we won&#39;t try
3124     // another round of Split-If.  In particular the ever-common
3125     // instance-of/check-cast pattern requires at least 2 rounds of
3126     // Split-If to clear out.
3127     C-&gt;set_major_progress();
3128   }
3129 
3130   // Repeat loop optimizations if new loops were seen
3131   if (created_loop_node()) {
3132     C-&gt;set_major_progress();
3133   }
3134 
3135   // Keep loop predicates and perform optimizations with them
3136   // until no more loop optimizations could be done.
3137   // After that switch predicates off and do more loop optimizations.
3138   if (!C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3139      C-&gt;cleanup_loop_predicates(_igvn);
3140      if (TraceLoopOpts) {
3141        tty-&gt;print_cr(&quot;PredicatesOff&quot;);
3142      }
3143      C-&gt;set_major_progress();
3144   }
3145 
3146   // Convert scalar to superword operations at the end of all loop opts.
3147   if (UseSuperWord &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3148     // SuperWord transform
3149     SuperWord sw(this);
3150     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3151       IdealLoopTree* lpt = iter.current();
3152       if (lpt-&gt;is_counted()) {
3153         CountedLoopNode *cl = lpt-&gt;_head-&gt;as_CountedLoop();
3154 
3155         if (PostLoopMultiversioning &amp;&amp; cl-&gt;is_rce_post_loop() &amp;&amp; !cl-&gt;is_vectorized_loop()) {
3156           // Check that the rce&#39;d post loop is encountered first, multiversion after all
3157           // major main loop optimization are concluded
3158           if (!C-&gt;major_progress()) {
3159             IdealLoopTree *lpt_next = lpt-&gt;_next;
3160             if (lpt_next &amp;&amp; lpt_next-&gt;is_counted()) {
3161               CountedLoopNode *cl = lpt_next-&gt;_head-&gt;as_CountedLoop();
3162               has_range_checks(lpt_next);
3163               if (cl-&gt;is_post_loop() &amp;&amp; cl-&gt;range_checks_present()) {
3164                 if (!cl-&gt;is_multiversioned()) {
3165                   if (multi_version_post_loops(lpt, lpt_next) == false) {
3166                     // Cause the rce loop to be optimized away if we fail
3167                     cl-&gt;mark_is_multiversioned();
3168                     cl-&gt;set_slp_max_unroll(0);
3169                     poison_rce_post_loop(lpt);
3170                   }
3171                 }
3172               }
3173             }
3174             sw.transform_loop(lpt, true);
3175           }
3176         } else if (cl-&gt;is_main_loop()) {
3177           sw.transform_loop(lpt, true);
3178         }
3179       }
3180     }
3181   }
3182 
3183   // Cleanup any modified bits
3184   _igvn.optimize();
3185 
3186   // disable assert until issue with split_flow_path is resolved (6742111)
3187   // assert(!_has_irreducible_loops || C-&gt;parsed_irreducible_loop() || C-&gt;is_osr_compilation(),
3188   //        &quot;shouldn&#39;t introduce irreducible loops&quot;);
3189 
3190   if (C-&gt;log() != NULL) {
3191     log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3192   }
3193 }
3194 
3195 #ifndef PRODUCT
3196 //------------------------------print_statistics-------------------------------
3197 int PhaseIdealLoop::_loop_invokes=0;// Count of PhaseIdealLoop invokes
3198 int PhaseIdealLoop::_loop_work=0; // Sum of PhaseIdealLoop x unique
3199 void PhaseIdealLoop::print_statistics() {
3200   tty-&gt;print_cr(&quot;PhaseIdealLoop=%d, sum _unique=%d&quot;, _loop_invokes, _loop_work);
3201 }
3202 
3203 //------------------------------verify-----------------------------------------
3204 // Build a verify-only PhaseIdealLoop, and see that it agrees with me.
3205 static int fail;                // debug only, so its multi-thread dont care
3206 void PhaseIdealLoop::verify() const {
3207   int old_progress = C-&gt;major_progress();
3208   ResourceMark rm;
3209   PhaseIdealLoop loop_verify( _igvn, this );
3210   VectorSet visited(Thread::current()-&gt;resource_area());
3211 
3212   fail = 0;
3213   verify_compare( C-&gt;root(), &amp;loop_verify, visited );
3214   assert( fail == 0, &quot;verify loops failed&quot; );
3215   // Verify loop structure is the same
3216   _ltree_root-&gt;verify_tree(loop_verify._ltree_root, NULL);
3217   // Reset major-progress.  It was cleared by creating a verify version of
3218   // PhaseIdealLoop.
3219   C-&gt;restore_major_progress(old_progress);
3220 }
3221 
3222 //------------------------------verify_compare---------------------------------
3223 // Make sure me and the given PhaseIdealLoop agree on key data structures
3224 void PhaseIdealLoop::verify_compare( Node *n, const PhaseIdealLoop *loop_verify, VectorSet &amp;visited ) const {
3225   if( !n ) return;
3226   if( visited.test_set( n-&gt;_idx ) ) return;
3227   if( !_nodes[n-&gt;_idx] ) {      // Unreachable
3228     assert( !loop_verify-&gt;_nodes[n-&gt;_idx], &quot;both should be unreachable&quot; );
3229     return;
3230   }
3231 
3232   uint i;
3233   for( i = 0; i &lt; n-&gt;req(); i++ )
3234     verify_compare( n-&gt;in(i), loop_verify, visited );
3235 
3236   // Check the &#39;_nodes&#39; block/loop structure
3237   i = n-&gt;_idx;
3238   if( has_ctrl(n) ) {           // We have control; verify has loop or ctrl
3239     if( _nodes[i] != loop_verify-&gt;_nodes[i] &amp;&amp;
3240         get_ctrl_no_update(n) != loop_verify-&gt;get_ctrl_no_update(n) ) {
3241       tty-&gt;print(&quot;Mismatched control setting for: &quot;);
3242       n-&gt;dump();
3243       if( fail++ &gt; 10 ) return;
3244       Node *c = get_ctrl_no_update(n);
3245       tty-&gt;print(&quot;We have it as: &quot;);
3246       if( c-&gt;in(0) ) c-&gt;dump();
3247         else tty-&gt;print_cr(&quot;N%d&quot;,c-&gt;_idx);
3248       tty-&gt;print(&quot;Verify thinks: &quot;);
3249       if( loop_verify-&gt;has_ctrl(n) )
3250         loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3251       else
3252         loop_verify-&gt;get_loop_idx(n)-&gt;dump();
3253       tty-&gt;cr();
3254     }
3255   } else {                    // We have a loop
3256     IdealLoopTree *us = get_loop_idx(n);
3257     if( loop_verify-&gt;has_ctrl(n) ) {
3258       tty-&gt;print(&quot;Mismatched loop setting for: &quot;);
3259       n-&gt;dump();
3260       if( fail++ &gt; 10 ) return;
3261       tty-&gt;print(&quot;We have it as: &quot;);
3262       us-&gt;dump();
3263       tty-&gt;print(&quot;Verify thinks: &quot;);
3264       loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3265       tty-&gt;cr();
3266     } else if (!C-&gt;major_progress()) {
3267       // Loop selection can be messed up if we did a major progress
3268       // operation, like split-if.  Do not verify in that case.
3269       IdealLoopTree *them = loop_verify-&gt;get_loop_idx(n);
3270       if( us-&gt;_head != them-&gt;_head ||  us-&gt;_tail != them-&gt;_tail ) {
3271         tty-&gt;print(&quot;Unequals loops for: &quot;);
3272         n-&gt;dump();
3273         if( fail++ &gt; 10 ) return;
3274         tty-&gt;print(&quot;We have it as: &quot;);
3275         us-&gt;dump();
3276         tty-&gt;print(&quot;Verify thinks: &quot;);
3277         them-&gt;dump();
3278         tty-&gt;cr();
3279       }
3280     }
3281   }
3282 
3283   // Check for immediate dominators being equal
3284   if( i &gt;= _idom_size ) {
3285     if( !n-&gt;is_CFG() ) return;
3286     tty-&gt;print(&quot;CFG Node with no idom: &quot;);
3287     n-&gt;dump();
3288     return;
3289   }
3290   if( !n-&gt;is_CFG() ) return;
3291   if( n == C-&gt;root() ) return; // No IDOM here
3292 
3293   assert(n-&gt;_idx == i, &quot;sanity&quot;);
3294   Node *id = idom_no_update(n);
3295   if( id != loop_verify-&gt;idom_no_update(n) ) {
3296     tty-&gt;print(&quot;Unequals idoms for: &quot;);
3297     n-&gt;dump();
3298     if( fail++ &gt; 10 ) return;
3299     tty-&gt;print(&quot;We have it as: &quot;);
3300     id-&gt;dump();
3301     tty-&gt;print(&quot;Verify thinks: &quot;);
3302     loop_verify-&gt;idom_no_update(n)-&gt;dump();
3303     tty-&gt;cr();
3304   }
3305 
3306 }
3307 
3308 //------------------------------verify_tree------------------------------------
3309 // Verify that tree structures match.  Because the CFG can change, siblings
3310 // within the loop tree can be reordered.  We attempt to deal with that by
3311 // reordering the verify&#39;s loop tree if possible.
3312 void IdealLoopTree::verify_tree(IdealLoopTree *loop, const IdealLoopTree *parent) const {
3313   assert( _parent == parent, &quot;Badly formed loop tree&quot; );
3314 
3315   // Siblings not in same order?  Attempt to re-order.
3316   if( _head != loop-&gt;_head ) {
3317     // Find _next pointer to update
3318     IdealLoopTree **pp = &amp;loop-&gt;_parent-&gt;_child;
3319     while( *pp != loop )
3320       pp = &amp;((*pp)-&gt;_next);
3321     // Find proper sibling to be next
3322     IdealLoopTree **nn = &amp;loop-&gt;_next;
3323     while( (*nn) &amp;&amp; (*nn)-&gt;_head != _head )
3324       nn = &amp;((*nn)-&gt;_next);
3325 
3326     // Check for no match.
3327     if( !(*nn) ) {
3328       // Annoyingly, irreducible loops can pick different headers
3329       // after a major_progress operation, so the rest of the loop
3330       // tree cannot be matched.
3331       if (_irreducible &amp;&amp; Compile::current()-&gt;major_progress())  return;
3332       assert( 0, &quot;failed to match loop tree&quot; );
3333     }
3334 
3335     // Move (*nn) to (*pp)
3336     IdealLoopTree *hit = *nn;
3337     *nn = hit-&gt;_next;
3338     hit-&gt;_next = loop;
3339     *pp = loop;
3340     loop = hit;
3341     // Now try again to verify
3342   }
3343 
3344   assert( _head  == loop-&gt;_head , &quot;mismatched loop head&quot; );
3345   Node *tail = _tail;           // Inline a non-updating version of
3346   while( !tail-&gt;in(0) )         // the &#39;tail()&#39; call.
3347     tail = tail-&gt;in(1);
3348   assert( tail == loop-&gt;_tail, &quot;mismatched loop tail&quot; );
3349 
3350   // Counted loops that are guarded should be able to find their guards
3351   if( _head-&gt;is_CountedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_main_loop() ) {
3352     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
3353     Node *init = cl-&gt;init_trip();
3354     Node *ctrl = cl-&gt;in(LoopNode::EntryControl);
3355     assert( ctrl-&gt;Opcode() == Op_IfTrue || ctrl-&gt;Opcode() == Op_IfFalse, &quot;&quot; );
3356     Node *iff  = ctrl-&gt;in(0);
3357     assert( iff-&gt;Opcode() == Op_If, &quot;&quot; );
3358     Node *bol  = iff-&gt;in(1);
3359     assert( bol-&gt;Opcode() == Op_Bool, &quot;&quot; );
3360     Node *cmp  = bol-&gt;in(1);
3361     assert( cmp-&gt;Opcode() == Op_CmpI, &quot;&quot; );
3362     Node *add  = cmp-&gt;in(1);
3363     Node *opaq;
3364     if( add-&gt;Opcode() == Op_Opaque1 ) {
3365       opaq = add;
3366     } else {
3367       assert( add-&gt;Opcode() == Op_AddI || add-&gt;Opcode() == Op_ConI , &quot;&quot; );
3368       assert( add == init, &quot;&quot; );
3369       opaq = cmp-&gt;in(2);
3370     }
3371     assert( opaq-&gt;Opcode() == Op_Opaque1, &quot;&quot; );
3372 
3373   }
3374 
3375   if (_child != NULL)  _child-&gt;verify_tree(loop-&gt;_child, this);
3376   if (_next  != NULL)  _next -&gt;verify_tree(loop-&gt;_next,  parent);
3377   // Innermost loops need to verify loop bodies,
3378   // but only if no &#39;major_progress&#39;
3379   int fail = 0;
3380   if (!Compile::current()-&gt;major_progress() &amp;&amp; _child == NULL) {
3381     for( uint i = 0; i &lt; _body.size(); i++ ) {
3382       Node *n = _body.at(i);
3383       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3384       uint j;
3385       for( j = 0; j &lt; loop-&gt;_body.size(); j++ )
3386         if( loop-&gt;_body.at(j) == n )
3387           break;
3388       if( j == loop-&gt;_body.size() ) { // Not found in loop body
3389         // Last ditch effort to avoid assertion: Its possible that we
3390         // have some users (so outcnt not zero) but are still dead.
3391         // Try to find from root.
3392         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3393           fail++;
3394           tty-&gt;print(&quot;We have that verify does not: &quot;);
3395           n-&gt;dump();
3396         }
3397       }
3398     }
3399     for( uint i2 = 0; i2 &lt; loop-&gt;_body.size(); i2++ ) {
3400       Node *n = loop-&gt;_body.at(i2);
3401       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3402       uint j;
3403       for( j = 0; j &lt; _body.size(); j++ )
3404         if( _body.at(j) == n )
3405           break;
3406       if( j == _body.size() ) { // Not found in loop body
3407         // Last ditch effort to avoid assertion: Its possible that we
3408         // have some users (so outcnt not zero) but are still dead.
3409         // Try to find from root.
3410         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3411           fail++;
3412           tty-&gt;print(&quot;Verify has that we do not: &quot;);
3413           n-&gt;dump();
3414         }
3415       }
3416     }
3417     assert( !fail, &quot;loop body mismatch&quot; );
3418   }
3419 }
3420 
3421 #endif
3422 
3423 //------------------------------set_idom---------------------------------------
3424 void PhaseIdealLoop::set_idom(Node* d, Node* n, uint dom_depth) {
3425   uint idx = d-&gt;_idx;
3426   if (idx &gt;= _idom_size) {
3427     uint newsize = next_power_of_2(idx);
3428     _idom      = REALLOC_RESOURCE_ARRAY( Node*,     _idom,_idom_size,newsize);
3429     _dom_depth = REALLOC_RESOURCE_ARRAY( uint, _dom_depth,_idom_size,newsize);
3430     memset( _dom_depth + _idom_size, 0, (newsize - _idom_size) * sizeof(uint) );
3431     _idom_size = newsize;
3432   }
3433   _idom[idx] = n;
3434   _dom_depth[idx] = dom_depth;
3435 }
3436 
3437 //------------------------------recompute_dom_depth---------------------------------------
3438 // The dominator tree is constructed with only parent pointers.
3439 // This recomputes the depth in the tree by first tagging all
3440 // nodes as &quot;no depth yet&quot; marker.  The next pass then runs up
3441 // the dom tree from each node marked &quot;no depth yet&quot;, and computes
3442 // the depth on the way back down.
3443 void PhaseIdealLoop::recompute_dom_depth() {
3444   uint no_depth_marker = C-&gt;unique();
3445   uint i;
3446   // Initialize depth to &quot;no depth yet&quot; and realize all lazy updates
3447   for (i = 0; i &lt; _idom_size; i++) {
3448     // Only indices with a _dom_depth has a Node* or NULL (otherwise uninitalized).
3449     if (_dom_depth[i] &gt; 0 &amp;&amp; _idom[i] != NULL) {
3450       _dom_depth[i] = no_depth_marker;
3451 
3452       // heal _idom if it has a fwd mapping in _nodes
3453       if (_idom[i]-&gt;in(0) == NULL) {
3454         idom(i);
3455       }
3456     }
3457   }
3458   if (_dom_stk == NULL) {
3459     uint init_size = C-&gt;live_nodes() / 100; // Guess that 1/100 is a reasonable initial size.
3460     if (init_size &lt; 10) init_size = 10;
3461     _dom_stk = new GrowableArray&lt;uint&gt;(init_size);
3462   }
3463   // Compute new depth for each node.
3464   for (i = 0; i &lt; _idom_size; i++) {
3465     uint j = i;
3466     // Run up the dom tree to find a node with a depth
3467     while (_dom_depth[j] == no_depth_marker) {
3468       _dom_stk-&gt;push(j);
3469       j = _idom[j]-&gt;_idx;
3470     }
3471     // Compute the depth on the way back down this tree branch
3472     uint dd = _dom_depth[j] + 1;
3473     while (_dom_stk-&gt;length() &gt; 0) {
3474       uint j = _dom_stk-&gt;pop();
3475       _dom_depth[j] = dd;
3476       dd++;
3477     }
3478   }
3479 }
3480 
3481 //------------------------------sort-------------------------------------------
3482 // Insert &#39;loop&#39; into the existing loop tree.  &#39;innermost&#39; is a leaf of the
3483 // loop tree, not the root.
3484 IdealLoopTree *PhaseIdealLoop::sort( IdealLoopTree *loop, IdealLoopTree *innermost ) {
3485   if( !innermost ) return loop; // New innermost loop
3486 
3487   int loop_preorder = get_preorder(loop-&gt;_head); // Cache pre-order number
3488   assert( loop_preorder, &quot;not yet post-walked loop&quot; );
3489   IdealLoopTree **pp = &amp;innermost;      // Pointer to previous next-pointer
3490   IdealLoopTree *l = *pp;               // Do I go before or after &#39;l&#39;?
3491 
3492   // Insert at start of list
3493   while( l ) {                  // Insertion sort based on pre-order
3494     if( l == loop ) return innermost; // Already on list!
3495     int l_preorder = get_preorder(l-&gt;_head); // Cache pre-order number
3496     assert( l_preorder, &quot;not yet post-walked l&quot; );
3497     // Check header pre-order number to figure proper nesting
3498     if( loop_preorder &gt; l_preorder )
3499       break;                    // End of insertion
3500     // If headers tie (e.g., shared headers) check tail pre-order numbers.
3501     // Since I split shared headers, you&#39;d think this could not happen.
3502     // BUT: I must first do the preorder numbering before I can discover I
3503     // have shared headers, so the split headers all get the same preorder
3504     // number as the RegionNode they split from.
3505     if( loop_preorder == l_preorder &amp;&amp;
3506         get_preorder(loop-&gt;_tail) &lt; get_preorder(l-&gt;_tail) )
3507       break;                    // Also check for shared headers (same pre#)
3508     pp = &amp;l-&gt;_parent;           // Chain up list
3509     l = *pp;
3510   }
3511   // Link into list
3512   // Point predecessor to me
3513   *pp = loop;
3514   // Point me to successor
3515   IdealLoopTree *p = loop-&gt;_parent;
3516   loop-&gt;_parent = l;            // Point me to successor
3517   if( p ) sort( p, innermost ); // Insert my parents into list as well
3518   return innermost;
3519 }
3520 
3521 //------------------------------build_loop_tree--------------------------------
3522 // I use a modified Vick/Tarjan algorithm.  I need pre- and a post- visit
3523 // bits.  The _nodes[] array is mapped by Node index and holds a NULL for
3524 // not-yet-pre-walked, pre-order # for pre-but-not-post-walked and holds the
3525 // tightest enclosing IdealLoopTree for post-walked.
3526 //
3527 // During my forward walk I do a short 1-layer lookahead to see if I can find
3528 // a loop backedge with that doesn&#39;t have any work on the backedge.  This
3529 // helps me construct nested loops with shared headers better.
3530 //
3531 // Once I&#39;ve done the forward recursion, I do the post-work.  For each child
3532 // I check to see if there is a backedge.  Backedges define a loop!  I
3533 // insert an IdealLoopTree at the target of the backedge.
3534 //
3535 // During the post-work I also check to see if I have several children
3536 // belonging to different loops.  If so, then this Node is a decision point
3537 // where control flow can choose to change loop nests.  It is at this
3538 // decision point where I can figure out how loops are nested.  At this
3539 // time I can properly order the different loop nests from my children.
3540 // Note that there may not be any backedges at the decision point!
3541 //
3542 // Since the decision point can be far removed from the backedges, I can&#39;t
3543 // order my loops at the time I discover them.  Thus at the decision point
3544 // I need to inspect loop header pre-order numbers to properly nest my
3545 // loops.  This means I need to sort my childrens&#39; loops by pre-order.
3546 // The sort is of size number-of-control-children, which generally limits
3547 // it to size 2 (i.e., I just choose between my 2 target loops).
3548 void PhaseIdealLoop::build_loop_tree() {
3549   // Allocate stack of size C-&gt;live_nodes()/2 to avoid frequent realloc
3550   GrowableArray &lt;Node *&gt; bltstack(C-&gt;live_nodes() &gt;&gt; 1);
3551   Node *n = C-&gt;root();
3552   bltstack.push(n);
3553   int pre_order = 1;
3554   int stack_size;
3555 
3556   while ( ( stack_size = bltstack.length() ) != 0 ) {
3557     n = bltstack.top(); // Leave node on stack
3558     if ( !is_visited(n) ) {
3559       // ---- Pre-pass Work ----
3560       // Pre-walked but not post-walked nodes need a pre_order number.
3561 
3562       set_preorder_visited( n, pre_order ); // set as visited
3563 
3564       // ---- Scan over children ----
3565       // Scan first over control projections that lead to loop headers.
3566       // This helps us find inner-to-outer loops with shared headers better.
3567 
3568       // Scan children&#39;s children for loop headers.
3569       for ( int i = n-&gt;outcnt() - 1; i &gt;= 0; --i ) {
3570         Node* m = n-&gt;raw_out(i);       // Child
3571         if( m-&gt;is_CFG() &amp;&amp; !is_visited(m) ) { // Only for CFG children
3572           // Scan over children&#39;s children to find loop
3573           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3574             Node* l = m-&gt;fast_out(j);
3575             if( is_visited(l) &amp;&amp;       // Been visited?
3576                 !is_postvisited(l) &amp;&amp;  // But not post-visited
3577                 get_preorder(l) &lt; pre_order ) { // And smaller pre-order
3578               // Found!  Scan the DFS down this path before doing other paths
3579               bltstack.push(m);
3580               break;
3581             }
3582           }
3583         }
3584       }
3585       pre_order++;
3586     }
3587     else if ( !is_postvisited(n) ) {
3588       // Note: build_loop_tree_impl() adds out edges on rare occasions,
3589       // such as com.sun.rsasign.am::a.
3590       // For non-recursive version, first, process current children.
3591       // On next iteration, check if additional children were added.
3592       for ( int k = n-&gt;outcnt() - 1; k &gt;= 0; --k ) {
3593         Node* u = n-&gt;raw_out(k);
3594         if ( u-&gt;is_CFG() &amp;&amp; !is_visited(u) ) {
3595           bltstack.push(u);
3596         }
3597       }
3598       if ( bltstack.length() == stack_size ) {
3599         // There were no additional children, post visit node now
3600         (void)bltstack.pop(); // Remove node from stack
3601         pre_order = build_loop_tree_impl( n, pre_order );
3602         // Check for bailout
3603         if (C-&gt;failing()) {
3604           return;
3605         }
3606         // Check to grow _preorders[] array for the case when
3607         // build_loop_tree_impl() adds new nodes.
3608         check_grow_preorders();
3609       }
3610     }
3611     else {
3612       (void)bltstack.pop(); // Remove post-visited node from stack
3613     }
3614   }
3615 }
3616 
3617 //------------------------------build_loop_tree_impl---------------------------
3618 int PhaseIdealLoop::build_loop_tree_impl( Node *n, int pre_order ) {
3619   // ---- Post-pass Work ----
3620   // Pre-walked but not post-walked nodes need a pre_order number.
3621 
3622   // Tightest enclosing loop for this Node
3623   IdealLoopTree *innermost = NULL;
3624 
3625   // For all children, see if any edge is a backedge.  If so, make a loop
3626   // for it.  Then find the tightest enclosing loop for the self Node.
3627   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3628     Node* m = n-&gt;fast_out(i);   // Child
3629     if( n == m ) continue;      // Ignore control self-cycles
3630     if( !m-&gt;is_CFG() ) continue;// Ignore non-CFG edges
3631 
3632     IdealLoopTree *l;           // Child&#39;s loop
3633     if( !is_postvisited(m) ) {  // Child visited but not post-visited?
3634       // Found a backedge
3635       assert( get_preorder(m) &lt; pre_order, &quot;should be backedge&quot; );
3636       // Check for the RootNode, which is already a LoopNode and is allowed
3637       // to have multiple &quot;backedges&quot;.
3638       if( m == C-&gt;root()) {     // Found the root?
3639         l = _ltree_root;        // Root is the outermost LoopNode
3640       } else {                  // Else found a nested loop
3641         // Insert a LoopNode to mark this loop.
3642         l = new IdealLoopTree(this, m, n);
3643       } // End of Else found a nested loop
3644       if( !has_loop(m) )        // If &#39;m&#39; does not already have a loop set
3645         set_loop(m, l);         // Set loop header to loop now
3646 
3647     } else {                    // Else not a nested loop
3648       if( !_nodes[m-&gt;_idx] ) continue; // Dead code has no loop
3649       l = get_loop(m);          // Get previously determined loop
3650       // If successor is header of a loop (nest), move up-loop till it
3651       // is a member of some outer enclosing loop.  Since there are no
3652       // shared headers (I&#39;ve split them already) I only need to go up
3653       // at most 1 level.
3654       while( l &amp;&amp; l-&gt;_head == m ) // Successor heads loop?
3655         l = l-&gt;_parent;         // Move up 1 for me
3656       // If this loop is not properly parented, then this loop
3657       // has no exit path out, i.e. its an infinite loop.
3658       if( !l ) {
3659         // Make loop &quot;reachable&quot; from root so the CFG is reachable.  Basically
3660         // insert a bogus loop exit that is never taken.  &#39;m&#39;, the loop head,
3661         // points to &#39;n&#39;, one (of possibly many) fall-in paths.  There may be
3662         // many backedges as well.
3663 
3664         // Here I set the loop to be the root loop.  I could have, after
3665         // inserting a bogus loop exit, restarted the recursion and found my
3666         // new loop exit.  This would make the infinite loop a first-class
3667         // loop and it would then get properly optimized.  What&#39;s the use of
3668         // optimizing an infinite loop?
3669         l = _ltree_root;        // Oops, found infinite loop
3670 
3671         if (!_verify_only) {
3672           // Insert the NeverBranch between &#39;m&#39; and it&#39;s control user.
3673           NeverBranchNode *iff = new NeverBranchNode( m );
3674           _igvn.register_new_node_with_optimizer(iff);
3675           set_loop(iff, l);
3676           Node *if_t = new CProjNode( iff, 0 );
3677           _igvn.register_new_node_with_optimizer(if_t);
3678           set_loop(if_t, l);
3679 
3680           Node* cfg = NULL;       // Find the One True Control User of m
3681           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3682             Node* x = m-&gt;fast_out(j);
3683             if (x-&gt;is_CFG() &amp;&amp; x != m &amp;&amp; x != iff)
3684               { cfg = x; break; }
3685           }
3686           assert(cfg != NULL, &quot;must find the control user of m&quot;);
3687           uint k = 0;             // Probably cfg-&gt;in(0)
3688           while( cfg-&gt;in(k) != m ) k++; // But check incase cfg is a Region
3689           cfg-&gt;set_req( k, if_t ); // Now point to NeverBranch
3690           _igvn._worklist.push(cfg);
3691 
3692           // Now create the never-taken loop exit
3693           Node *if_f = new CProjNode( iff, 1 );
3694           _igvn.register_new_node_with_optimizer(if_f);
3695           set_loop(if_f, l);
3696           // Find frame ptr for Halt.  Relies on the optimizer
3697           // V-N&#39;ing.  Easier and quicker than searching through
3698           // the program structure.
3699           Node *frame = new ParmNode( C-&gt;start(), TypeFunc::FramePtr );
3700           _igvn.register_new_node_with_optimizer(frame);
3701           // Halt &amp; Catch Fire
3702           Node* halt = new HaltNode(if_f, frame, &quot;never-taken loop exit reached&quot;);
3703           _igvn.register_new_node_with_optimizer(halt);
3704           set_loop(halt, l);
3705           C-&gt;root()-&gt;add_req(halt);
3706         }
3707         set_loop(C-&gt;root(), _ltree_root);
3708       }
3709     }
3710     // Weeny check for irreducible.  This child was already visited (this
3711     // IS the post-work phase).  Is this child&#39;s loop header post-visited
3712     // as well?  If so, then I found another entry into the loop.
3713     if (!_verify_only) {
3714       while( is_postvisited(l-&gt;_head) ) {
3715         // found irreducible
3716         l-&gt;_irreducible = 1; // = true
3717         l = l-&gt;_parent;
3718         _has_irreducible_loops = true;
3719         // Check for bad CFG here to prevent crash, and bailout of compile
3720         if (l == NULL) {
3721           C-&gt;record_method_not_compilable(&quot;unhandled CFG detected during loop optimization&quot;);
3722           return pre_order;
3723         }
3724       }
3725       C-&gt;set_has_irreducible_loop(_has_irreducible_loops);
3726     }
3727 
3728     // This Node might be a decision point for loops.  It is only if
3729     // it&#39;s children belong to several different loops.  The sort call
3730     // does a trivial amount of work if there is only 1 child or all
3731     // children belong to the same loop.  If however, the children
3732     // belong to different loops, the sort call will properly set the
3733     // _parent pointers to show how the loops nest.
3734     //
3735     // In any case, it returns the tightest enclosing loop.
3736     innermost = sort( l, innermost );
3737   }
3738 
3739   // Def-use info will have some dead stuff; dead stuff will have no
3740   // loop decided on.
3741 
3742   // Am I a loop header?  If so fix up my parent&#39;s child and next ptrs.
3743   if( innermost &amp;&amp; innermost-&gt;_head == n ) {
3744     assert( get_loop(n) == innermost, &quot;&quot; );
3745     IdealLoopTree *p = innermost-&gt;_parent;
3746     IdealLoopTree *l = innermost;
3747     while( p &amp;&amp; l-&gt;_head == n ) {
3748       l-&gt;_next = p-&gt;_child;     // Put self on parents &#39;next child&#39;
3749       p-&gt;_child = l;            // Make self as first child of parent
3750       l = p;                    // Now walk up the parent chain
3751       p = l-&gt;_parent;
3752     }
3753   } else {
3754     // Note that it is possible for a LoopNode to reach here, if the
3755     // backedge has been made unreachable (hence the LoopNode no longer
3756     // denotes a Loop, and will eventually be removed).
3757 
3758     // Record tightest enclosing loop for self.  Mark as post-visited.
3759     set_loop(n, innermost);
3760     // Also record has_call flag early on
3761     if( innermost ) {
3762       if( n-&gt;is_Call() &amp;&amp; !n-&gt;is_CallLeaf() &amp;&amp; !n-&gt;is_macro() ) {
3763         // Do not count uncommon calls
3764         if( !n-&gt;is_CallStaticJava() || !n-&gt;as_CallStaticJava()-&gt;_name ) {
3765           Node *iff = n-&gt;in(0)-&gt;in(0);
3766           // No any calls for vectorized loops.
3767           if( UseSuperWord || !iff-&gt;is_If() ||
3768               (n-&gt;in(0)-&gt;Opcode() == Op_IfFalse &amp;&amp;
3769                (1.0 - iff-&gt;as_If()-&gt;_prob) &gt;= 0.01) ||
3770               (iff-&gt;as_If()-&gt;_prob &gt;= 0.01) )
3771             innermost-&gt;_has_call = 1;
3772         }
3773       } else if( n-&gt;is_Allocate() &amp;&amp; n-&gt;as_Allocate()-&gt;_is_scalar_replaceable ) {
3774         // Disable loop optimizations if the loop has a scalar replaceable
3775         // allocation. This disabling may cause a potential performance lost
3776         // if the allocation is not eliminated for some reason.
3777         innermost-&gt;_allow_optimizations = false;
3778         innermost-&gt;_has_call = 1; // = true
3779       } else if (n-&gt;Opcode() == Op_SafePoint) {
3780         // Record all safepoints in this loop.
3781         if (innermost-&gt;_safepts == NULL) innermost-&gt;_safepts = new Node_List();
3782         innermost-&gt;_safepts-&gt;push(n);
3783       }
3784     }
3785   }
3786 
3787   // Flag as post-visited now
3788   set_postvisited(n);
3789   return pre_order;
3790 }
3791 
3792 
3793 //------------------------------build_loop_early-------------------------------
3794 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
3795 // First pass computes the earliest controlling node possible.  This is the
3796 // controlling input with the deepest dominating depth.
3797 void PhaseIdealLoop::build_loop_early( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
3798   while (worklist.size() != 0) {
3799     // Use local variables nstack_top_n &amp; nstack_top_i to cache values
3800     // on nstack&#39;s top.
3801     Node *nstack_top_n = worklist.pop();
3802     uint  nstack_top_i = 0;
3803 //while_nstack_nonempty:
3804     while (true) {
3805       // Get parent node and next input&#39;s index from stack&#39;s top.
3806       Node  *n = nstack_top_n;
3807       uint   i = nstack_top_i;
3808       uint cnt = n-&gt;req(); // Count of inputs
3809       if (i == 0) {        // Pre-process the node.
3810         if( has_node(n) &amp;&amp;            // Have either loop or control already?
3811             !has_ctrl(n) ) {          // Have loop picked out already?
3812           // During &quot;merge_many_backedges&quot; we fold up several nested loops
3813           // into a single loop.  This makes the members of the original
3814           // loop bodies pointing to dead loops; they need to move up
3815           // to the new UNION&#39;d larger loop.  I set the _head field of these
3816           // dead loops to NULL and the _parent field points to the owning
3817           // loop.  Shades of UNION-FIND algorithm.
3818           IdealLoopTree *ilt;
3819           while( !(ilt = get_loop(n))-&gt;_head ) {
3820             // Normally I would use a set_loop here.  But in this one special
3821             // case, it is legal (and expected) to change what loop a Node
3822             // belongs to.
3823             _nodes.map(n-&gt;_idx, (Node*)(ilt-&gt;_parent) );
3824           }
3825           // Remove safepoints ONLY if I&#39;ve already seen I don&#39;t need one.
3826           // (the old code here would yank a 2nd safepoint after seeing a
3827           // first one, even though the 1st did not dominate in the loop body
3828           // and thus could be avoided indefinitely)
3829           if( !_verify_only &amp;&amp; !_verify_me &amp;&amp; ilt-&gt;_has_sfpt &amp;&amp; n-&gt;Opcode() == Op_SafePoint &amp;&amp;
3830               is_deleteable_safept(n)) {
3831             Node *in = n-&gt;in(TypeFunc::Control);
3832             lazy_replace(n,in);       // Pull safepoint now
3833             if (ilt-&gt;_safepts != NULL) {
3834               ilt-&gt;_safepts-&gt;yank(n);
3835             }
3836             // Carry on with the recursion &quot;as if&quot; we are walking
3837             // only the control input
3838             if( !visited.test_set( in-&gt;_idx ) ) {
3839               worklist.push(in);      // Visit this guy later, using worklist
3840             }
3841             // Get next node from nstack:
3842             // - skip n&#39;s inputs processing by setting i &gt; cnt;
3843             // - we also will not call set_early_ctrl(n) since
3844             //   has_node(n) == true (see the condition above).
3845             i = cnt + 1;
3846           }
3847         }
3848       } // if (i == 0)
3849 
3850       // Visit all inputs
3851       bool done = true;       // Assume all n&#39;s inputs will be processed
3852       while (i &lt; cnt) {
3853         Node *in = n-&gt;in(i);
3854         ++i;
3855         if (in == NULL) continue;
3856         if (in-&gt;pinned() &amp;&amp; !in-&gt;is_CFG())
3857           set_ctrl(in, in-&gt;in(0));
3858         int is_visited = visited.test_set( in-&gt;_idx );
3859         if (!has_node(in)) {  // No controlling input yet?
3860           assert( !in-&gt;is_CFG(), &quot;CFG Node with no controlling input?&quot; );
3861           assert( !is_visited, &quot;visit only once&quot; );
3862           nstack.push(n, i);  // Save parent node and next input&#39;s index.
3863           nstack_top_n = in;  // Process current input now.
3864           nstack_top_i = 0;
3865           done = false;       // Not all n&#39;s inputs processed.
3866           break; // continue while_nstack_nonempty;
3867         } else if (!is_visited) {
3868           // This guy has a location picked out for him, but has not yet
3869           // been visited.  Happens to all CFG nodes, for instance.
3870           // Visit him using the worklist instead of recursion, to break
3871           // cycles.  Since he has a location already we do not need to
3872           // find his location before proceeding with the current Node.
3873           worklist.push(in);  // Visit this guy later, using worklist
3874         }
3875       }
3876       if (done) {
3877         // All of n&#39;s inputs have been processed, complete post-processing.
3878 
3879         // Compute earliest point this Node can go.
3880         // CFG, Phi, pinned nodes already know their controlling input.
3881         if (!has_node(n)) {
3882           // Record earliest legal location
3883           set_early_ctrl( n );
3884         }
3885         if (nstack.is_empty()) {
3886           // Finished all nodes on stack.
3887           // Process next node on the worklist.
3888           break;
3889         }
3890         // Get saved parent node and next input&#39;s index.
3891         nstack_top_n = nstack.node();
3892         nstack_top_i = nstack.index();
3893         nstack.pop();
3894       }
3895     } // while (true)
3896   }
3897 }
3898 
3899 //------------------------------dom_lca_internal--------------------------------
3900 // Pair-wise LCA
3901 Node *PhaseIdealLoop::dom_lca_internal( Node *n1, Node *n2 ) const {
3902   if( !n1 ) return n2;          // Handle NULL original LCA
3903   assert( n1-&gt;is_CFG(), &quot;&quot; );
3904   assert( n2-&gt;is_CFG(), &quot;&quot; );
3905   // find LCA of all uses
3906   uint d1 = dom_depth(n1);
3907   uint d2 = dom_depth(n2);
3908   while (n1 != n2) {
3909     if (d1 &gt; d2) {
3910       n1 =      idom(n1);
3911       d1 = dom_depth(n1);
3912     } else if (d1 &lt; d2) {
3913       n2 =      idom(n2);
3914       d2 = dom_depth(n2);
3915     } else {
3916       // Here d1 == d2.  Due to edits of the dominator-tree, sections
3917       // of the tree might have the same depth.  These sections have
3918       // to be searched more carefully.
3919 
3920       // Scan up all the n1&#39;s with equal depth, looking for n2.
3921       Node *t1 = idom(n1);
3922       while (dom_depth(t1) == d1) {
3923         if (t1 == n2)  return n2;
3924         t1 = idom(t1);
3925       }
3926       // Scan up all the n2&#39;s with equal depth, looking for n1.
3927       Node *t2 = idom(n2);
3928       while (dom_depth(t2) == d2) {
3929         if (t2 == n1)  return n1;
3930         t2 = idom(t2);
3931       }
3932       // Move up to a new dominator-depth value as well as up the dom-tree.
3933       n1 = t1;
3934       n2 = t2;
3935       d1 = dom_depth(n1);
3936       d2 = dom_depth(n2);
3937     }
3938   }
3939   return n1;
3940 }
3941 
3942 //------------------------------compute_idom-----------------------------------
3943 // Locally compute IDOM using dom_lca call.  Correct only if the incoming
3944 // IDOMs are correct.
3945 Node *PhaseIdealLoop::compute_idom( Node *region ) const {
3946   assert( region-&gt;is_Region(), &quot;&quot; );
3947   Node *LCA = NULL;
3948   for( uint i = 1; i &lt; region-&gt;req(); i++ ) {
3949     if( region-&gt;in(i) != C-&gt;top() )
3950       LCA = dom_lca( LCA, region-&gt;in(i) );
3951   }
3952   return LCA;
3953 }
3954 
3955 bool PhaseIdealLoop::verify_dominance(Node* n, Node* use, Node* LCA, Node* early) {
3956   bool had_error = false;
3957 #ifdef ASSERT
3958   if (early != C-&gt;root()) {
3959     // Make sure that there&#39;s a dominance path from LCA to early
3960     Node* d = LCA;
3961     while (d != early) {
3962       if (d == C-&gt;root()) {
3963         dump_bad_graph(&quot;Bad graph detected in compute_lca_of_uses&quot;, n, early, LCA);
3964         tty-&gt;print_cr(&quot;*** Use %d isn&#39;t dominated by def %d ***&quot;, use-&gt;_idx, n-&gt;_idx);
3965         had_error = true;
3966         break;
3967       }
3968       d = idom(d);
3969     }
3970   }
3971 #endif
3972   return had_error;
3973 }
3974 
3975 
3976 Node* PhaseIdealLoop::compute_lca_of_uses(Node* n, Node* early, bool verify) {
3977   // Compute LCA over list of uses
3978   bool had_error = false;
3979   Node *LCA = NULL;
3980   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; LCA != early; i++) {
3981     Node* c = n-&gt;fast_out(i);
3982     if (_nodes[c-&gt;_idx] == NULL)
3983       continue;                 // Skip the occasional dead node
3984     if( c-&gt;is_Phi() ) {         // For Phis, we must land above on the path
3985       for( uint j=1; j&lt;c-&gt;req(); j++ ) {// For all inputs
3986         if( c-&gt;in(j) == n ) {   // Found matching input?
3987           Node *use = c-&gt;in(0)-&gt;in(j);
3988           if (_verify_only &amp;&amp; use-&gt;is_top()) continue;
3989           LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
3990           if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
3991         }
3992       }
3993     } else {
3994       // For CFG data-users, use is in the block just prior
3995       Node *use = has_ctrl(c) ? get_ctrl(c) : c-&gt;in(0);
3996       LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
3997       if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
3998     }
3999   }
4000   assert(!had_error, &quot;bad dominance&quot;);
4001   return LCA;
4002 }
4003 
4004 // Check the shape of the graph at the loop entry. In some cases,
4005 // the shape of the graph does not match the shape outlined below.
4006 // That is caused by the Opaque1 node &quot;protecting&quot; the shape of
4007 // the graph being removed by, for example, the IGVN performed
4008 // in PhaseIdealLoop::build_and_optimize().
4009 //
4010 // After the Opaque1 node has been removed, optimizations (e.g., split-if,
4011 // loop unswitching, and IGVN, or a combination of them) can freely change
4012 // the graph&#39;s shape. As a result, the graph shape outlined below cannot
4013 // be guaranteed anymore.
4014 bool PhaseIdealLoop::is_canonical_loop_entry(CountedLoopNode* cl) {
4015   if (!cl-&gt;is_main_loop() &amp;&amp; !cl-&gt;is_post_loop()) {
4016     return false;
4017   }
4018   Node* ctrl = cl-&gt;skip_predicates();
4019 
4020   if (ctrl == NULL || (!ctrl-&gt;is_IfTrue() &amp;&amp; !ctrl-&gt;is_IfFalse())) {
4021     return false;
4022   }
4023   Node* iffm = ctrl-&gt;in(0);
4024   if (iffm == NULL || !iffm-&gt;is_If()) {
4025     return false;
4026   }
4027   Node* bolzm = iffm-&gt;in(1);
4028   if (bolzm == NULL || !bolzm-&gt;is_Bool()) {
4029     return false;
4030   }
4031   Node* cmpzm = bolzm-&gt;in(1);
4032   if (cmpzm == NULL || !cmpzm-&gt;is_Cmp()) {
4033     return false;
4034   }
4035   // compares can get conditionally flipped
4036   bool found_opaque = false;
4037   for (uint i = 1; i &lt; cmpzm-&gt;req(); i++) {
4038     Node* opnd = cmpzm-&gt;in(i);
4039     if (opnd &amp;&amp; opnd-&gt;Opcode() == Op_Opaque1) {
4040       found_opaque = true;
4041       break;
4042     }
4043   }
4044   if (!found_opaque) {
4045     return false;
4046   }
4047   return true;
4048 }
4049 
4050 //------------------------------get_late_ctrl----------------------------------
4051 // Compute latest legal control.
4052 Node *PhaseIdealLoop::get_late_ctrl( Node *n, Node *early ) {
4053   assert(early != NULL, &quot;early control should not be NULL&quot;);
4054 
4055   Node* LCA = compute_lca_of_uses(n, early);
4056 #ifdef ASSERT
4057   if (LCA == C-&gt;root() &amp;&amp; LCA != early) {
4058     // def doesn&#39;t dominate uses so print some useful debugging output
4059     compute_lca_of_uses(n, early, true);
4060   }
4061 #endif
4062 
4063   // if this is a load, check for anti-dependent stores
4064   // We use a conservative algorithm to identify potential interfering
4065   // instructions and for rescheduling the load.  The users of the memory
4066   // input of this load are examined.  Any use which is not a load and is
4067   // dominated by early is considered a potentially interfering store.
4068   // This can produce false positives.
4069   if (n-&gt;is_Load() &amp;&amp; LCA != early) {
4070     int load_alias_idx = C-&gt;get_alias_index(n-&gt;adr_type());
4071     if (C-&gt;alias_type(load_alias_idx)-&gt;is_rewritable()) {
4072 
4073       Node_List worklist;
4074 
4075       Node *mem = n-&gt;in(MemNode::Memory);
4076       for (DUIterator_Fast imax, i = mem-&gt;fast_outs(imax); i &lt; imax; i++) {
4077         Node* s = mem-&gt;fast_out(i);
4078         worklist.push(s);
4079       }
4080       while(worklist.size() != 0 &amp;&amp; LCA != early) {
4081         Node* s = worklist.pop();
4082         if (s-&gt;is_Load() || s-&gt;Opcode() == Op_SafePoint ||
4083             (s-&gt;is_CallStaticJava() &amp;&amp; s-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0)) {
4084           continue;
4085         } else if (s-&gt;is_MergeMem()) {
4086           for (DUIterator_Fast imax, i = s-&gt;fast_outs(imax); i &lt; imax; i++) {
4087             Node* s1 = s-&gt;fast_out(i);
4088             worklist.push(s1);
4089           }
4090         } else {
4091           Node *sctrl = has_ctrl(s) ? get_ctrl(s) : s-&gt;in(0);
4092           assert(sctrl != NULL || !s-&gt;is_reachable_from_root(), &quot;must have control&quot;);
4093           if (sctrl != NULL &amp;&amp; !sctrl-&gt;is_top() &amp;&amp; C-&gt;can_alias(s-&gt;adr_type(), load_alias_idx) &amp;&amp; is_dominator(early, sctrl)) {
4094             LCA = dom_lca_for_get_late_ctrl(LCA, sctrl, n);
4095           }
4096         }
4097       }
4098     }
4099   }
4100 
4101   assert(LCA == find_non_split_ctrl(LCA), &quot;unexpected late control&quot;);
4102   return LCA;
4103 }
4104 
4105 // true if CFG node d dominates CFG node n
4106 bool PhaseIdealLoop::is_dominator(Node *d, Node *n) {
4107   if (d == n)
4108     return true;
4109   assert(d-&gt;is_CFG() &amp;&amp; n-&gt;is_CFG(), &quot;must have CFG nodes&quot;);
4110   uint dd = dom_depth(d);
4111   while (dom_depth(n) &gt;= dd) {
4112     if (n == d)
4113       return true;
4114     n = idom(n);
4115   }
4116   return false;
4117 }
4118 
4119 //------------------------------dom_lca_for_get_late_ctrl_internal-------------
4120 // Pair-wise LCA with tags.
4121 // Tag each index with the node &#39;tag&#39; currently being processed
4122 // before advancing up the dominator chain using idom().
4123 // Later calls that find a match to &#39;tag&#39; know that this path has already
4124 // been considered in the current LCA (which is input &#39;n1&#39; by convention).
4125 // Since get_late_ctrl() is only called once for each node, the tag array
4126 // does not need to be cleared between calls to get_late_ctrl().
4127 // Algorithm trades a larger constant factor for better asymptotic behavior
4128 //
4129 Node *PhaseIdealLoop::dom_lca_for_get_late_ctrl_internal( Node *n1, Node *n2, Node *tag ) {
4130   uint d1 = dom_depth(n1);
4131   uint d2 = dom_depth(n2);
4132 
4133   do {
4134     if (d1 &gt; d2) {
4135       // current lca is deeper than n2
4136       _dom_lca_tags.map(n1-&gt;_idx, tag);
4137       n1 =      idom(n1);
4138       d1 = dom_depth(n1);
4139     } else if (d1 &lt; d2) {
4140       // n2 is deeper than current lca
4141       Node *memo = _dom_lca_tags[n2-&gt;_idx];
4142       if( memo == tag ) {
4143         return n1;    // Return the current LCA
4144       }
4145       _dom_lca_tags.map(n2-&gt;_idx, tag);
4146       n2 =      idom(n2);
4147       d2 = dom_depth(n2);
4148     } else {
4149       // Here d1 == d2.  Due to edits of the dominator-tree, sections
4150       // of the tree might have the same depth.  These sections have
4151       // to be searched more carefully.
4152 
4153       // Scan up all the n1&#39;s with equal depth, looking for n2.
4154       _dom_lca_tags.map(n1-&gt;_idx, tag);
4155       Node *t1 = idom(n1);
4156       while (dom_depth(t1) == d1) {
4157         if (t1 == n2)  return n2;
4158         _dom_lca_tags.map(t1-&gt;_idx, tag);
4159         t1 = idom(t1);
4160       }
4161       // Scan up all the n2&#39;s with equal depth, looking for n1.
4162       _dom_lca_tags.map(n2-&gt;_idx, tag);
4163       Node *t2 = idom(n2);
4164       while (dom_depth(t2) == d2) {
4165         if (t2 == n1)  return n1;
4166         _dom_lca_tags.map(t2-&gt;_idx, tag);
4167         t2 = idom(t2);
4168       }
4169       // Move up to a new dominator-depth value as well as up the dom-tree.
4170       n1 = t1;
4171       n2 = t2;
4172       d1 = dom_depth(n1);
4173       d2 = dom_depth(n2);
4174     }
4175   } while (n1 != n2);
4176   return n1;
4177 }
4178 
4179 //------------------------------init_dom_lca_tags------------------------------
4180 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4181 // Intended use does not involve any growth for the array, so it could
4182 // be of fixed size.
4183 void PhaseIdealLoop::init_dom_lca_tags() {
4184   uint limit = C-&gt;unique() + 1;
4185   _dom_lca_tags.map( limit, NULL );
4186 #ifdef ASSERT
4187   for( uint i = 0; i &lt; limit; ++i ) {
4188     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4189   }
4190 #endif // ASSERT
4191 }
4192 
4193 //------------------------------clear_dom_lca_tags------------------------------
4194 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4195 // Intended use does not involve any growth for the array, so it could
4196 // be of fixed size.
4197 void PhaseIdealLoop::clear_dom_lca_tags() {
4198   uint limit = C-&gt;unique() + 1;
4199   _dom_lca_tags.map( limit, NULL );
4200   _dom_lca_tags.clear();
4201 #ifdef ASSERT
4202   for( uint i = 0; i &lt; limit; ++i ) {
4203     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4204   }
4205 #endif // ASSERT
4206 }
4207 
4208 //------------------------------build_loop_late--------------------------------
4209 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4210 // Second pass finds latest legal placement, and ideal loop placement.
4211 void PhaseIdealLoop::build_loop_late( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
4212   while (worklist.size() != 0) {
4213     Node *n = worklist.pop();
4214     // Only visit once
4215     if (visited.test_set(n-&gt;_idx)) continue;
4216     uint cnt = n-&gt;outcnt();
4217     uint   i = 0;
4218     while (true) {
4219       assert( _nodes[n-&gt;_idx], &quot;no dead nodes&quot; );
4220       // Visit all children
4221       if (i &lt; cnt) {
4222         Node* use = n-&gt;raw_out(i);
4223         ++i;
4224         // Check for dead uses.  Aggressively prune such junk.  It might be
4225         // dead in the global sense, but still have local uses so I cannot
4226         // easily call &#39;remove_dead_node&#39;.
4227         if( _nodes[use-&gt;_idx] != NULL || use-&gt;is_top() ) { // Not dead?
4228           // Due to cycles, we might not hit the same fixed point in the verify
4229           // pass as we do in the regular pass.  Instead, visit such phis as
4230           // simple uses of the loop head.
4231           if( use-&gt;in(0) &amp;&amp; (use-&gt;is_CFG() || use-&gt;is_Phi()) ) {
4232             if( !visited.test(use-&gt;_idx) )
4233               worklist.push(use);
4234           } else if( !visited.test_set(use-&gt;_idx) ) {
4235             nstack.push(n, i); // Save parent and next use&#39;s index.
4236             n   = use;         // Process all children of current use.
4237             cnt = use-&gt;outcnt();
4238             i   = 0;
4239           }
4240         } else {
4241           // Do not visit around the backedge of loops via data edges.
4242           // push dead code onto a worklist
4243           _deadlist.push(use);
4244         }
4245       } else {
4246         // All of n&#39;s children have been processed, complete post-processing.
4247         build_loop_late_post(n);
4248         if (nstack.is_empty()) {
4249           // Finished all nodes on stack.
4250           // Process next node on the worklist.
4251           break;
4252         }
4253         // Get saved parent node and next use&#39;s index. Visit the rest of uses.
4254         n   = nstack.node();
4255         cnt = n-&gt;outcnt();
4256         i   = nstack.index();
4257         nstack.pop();
4258       }
4259     }
4260   }
4261 }
4262 
4263 // Verify that no data node is scheduled in the outer loop of a strip
4264 // mined loop.
4265 void PhaseIdealLoop::verify_strip_mined_scheduling(Node *n, Node* least) {
4266 #ifdef ASSERT
4267   if (get_loop(least)-&gt;_nest == 0) {
4268     return;
4269   }
4270   IdealLoopTree* loop = get_loop(least);
4271   Node* head = loop-&gt;_head;
4272   if (head-&gt;is_OuterStripMinedLoop() &amp;&amp;
4273       // Verification can&#39;t be applied to fully built strip mined loops
4274       head-&gt;as_Loop()-&gt;outer_loop_end()-&gt;in(1)-&gt;find_int_con(-1) == 0) {
4275     Node* sfpt = head-&gt;as_Loop()-&gt;outer_safepoint();
4276     ResourceMark rm;
4277     Unique_Node_List wq;
4278     wq.push(sfpt);
4279     for (uint i = 0; i &lt; wq.size(); i++) {
4280       Node *m = wq.at(i);
4281       for (uint i = 1; i &lt; m-&gt;req(); i++) {
4282         Node* nn = m-&gt;in(i);
4283         if (nn == n) {
4284           return;
4285         }
4286         if (nn != NULL &amp;&amp; has_ctrl(nn) &amp;&amp; get_loop(get_ctrl(nn)) == loop) {
4287           wq.push(nn);
4288         }
4289       }
4290     }
4291     ShouldNotReachHere();
4292   }
4293 #endif
4294 }
4295 
4296 
4297 //------------------------------build_loop_late_post---------------------------
4298 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4299 // Second pass finds latest legal placement, and ideal loop placement.
4300 void PhaseIdealLoop::build_loop_late_post(Node *n) {
4301   build_loop_late_post_work(n, true);
4302 }
4303 
4304 void PhaseIdealLoop::build_loop_late_post_work(Node *n, bool pinned) {
4305 
4306   if (n-&gt;req() == 2 &amp;&amp; (n-&gt;Opcode() == Op_ConvI2L || n-&gt;Opcode() == Op_CastII) &amp;&amp; !C-&gt;major_progress() &amp;&amp; !_verify_only) {
4307     _igvn._worklist.push(n);  // Maybe we&#39;ll normalize it, if no more loops.
4308   }
4309 
4310 #ifdef ASSERT
4311   if (_verify_only &amp;&amp; !n-&gt;is_CFG()) {
4312     // Check def-use domination.
4313     compute_lca_of_uses(n, get_ctrl(n), true /* verify */);
4314   }
4315 #endif
4316 
4317   // CFG and pinned nodes already handled
4318   if( n-&gt;in(0) ) {
4319     if( n-&gt;in(0)-&gt;is_top() ) return; // Dead?
4320 
4321     // We&#39;d like +VerifyLoopOptimizations to not believe that Mod&#39;s/Loads
4322     // _must_ be pinned (they have to observe their control edge of course).
4323     // Unlike Stores (which modify an unallocable resource, the memory
4324     // state), Mods/Loads can float around.  So free them up.
4325     switch( n-&gt;Opcode() ) {
4326     case Op_DivI:
4327     case Op_DivF:
4328     case Op_DivD:
4329     case Op_ModI:
4330     case Op_ModF:
4331     case Op_ModD:
4332     case Op_LoadB:              // Same with Loads; they can sink
4333     case Op_LoadUB:             // during loop optimizations.
4334     case Op_LoadUS:
4335     case Op_LoadD:
4336     case Op_LoadF:
4337     case Op_LoadI:
4338     case Op_LoadKlass:
4339     case Op_LoadNKlass:
4340     case Op_LoadL:
4341     case Op_LoadS:
4342     case Op_LoadP:
4343     case Op_LoadN:
4344     case Op_LoadRange:
4345     case Op_LoadD_unaligned:
4346     case Op_LoadL_unaligned:
4347     case Op_StrComp:            // Does a bunch of load-like effects
4348     case Op_StrEquals:
4349     case Op_StrIndexOf:
4350     case Op_StrIndexOfChar:
4351     case Op_AryEq:
4352     case Op_HasNegatives:
4353       pinned = false;
4354     }
4355     if (n-&gt;is_CMove()) {
4356       pinned = false;
4357     }
4358     if( pinned ) {
4359       IdealLoopTree *chosen_loop = get_loop(n-&gt;is_CFG() ? n : get_ctrl(n));
4360       if( !chosen_loop-&gt;_child )       // Inner loop?
4361         chosen_loop-&gt;_body.push(n); // Collect inner loops
4362       return;
4363     }
4364   } else {                      // No slot zero
4365     if( n-&gt;is_CFG() ) {         // CFG with no slot 0 is dead
4366       _nodes.map(n-&gt;_idx,0);    // No block setting, it&#39;s globally dead
4367       return;
4368     }
4369     assert(!n-&gt;is_CFG() || n-&gt;outcnt() == 0, &quot;&quot;);
4370   }
4371 
4372   // Do I have a &quot;safe range&quot; I can select over?
4373   Node *early = get_ctrl(n);// Early location already computed
4374 
4375   // Compute latest point this Node can go
4376   Node *LCA = get_late_ctrl( n, early );
4377   // LCA is NULL due to uses being dead
4378   if( LCA == NULL ) {
4379 #ifdef ASSERT
4380     for (DUIterator i1 = n-&gt;outs(); n-&gt;has_out(i1); i1++) {
4381       assert( _nodes[n-&gt;out(i1)-&gt;_idx] == NULL, &quot;all uses must also be dead&quot;);
4382     }
4383 #endif
4384     _nodes.map(n-&gt;_idx, 0);     // This node is useless
4385     _deadlist.push(n);
4386     return;
4387   }
4388   assert(LCA != NULL &amp;&amp; !LCA-&gt;is_top(), &quot;no dead nodes&quot;);
4389 
4390   Node *legal = LCA;            // Walk &#39;legal&#39; up the IDOM chain
4391   Node *least = legal;          // Best legal position so far
4392   while( early != legal ) {     // While not at earliest legal
4393 #ifdef ASSERT
4394     if (legal-&gt;is_Start() &amp;&amp; !early-&gt;is_Root()) {
4395       // Bad graph. Print idom path and fail.
4396       dump_bad_graph(&quot;Bad graph detected in build_loop_late&quot;, n, early, LCA);
4397       assert(false, &quot;Bad graph detected in build_loop_late&quot;);
4398     }
4399 #endif
4400     // Find least loop nesting depth
4401     legal = idom(legal);        // Bump up the IDOM tree
4402     // Check for lower nesting depth
4403     if( get_loop(legal)-&gt;_nest &lt; get_loop(least)-&gt;_nest )
4404       least = legal;
4405   }
4406   assert(early == legal || legal != C-&gt;root(), &quot;bad dominance of inputs&quot;);
4407 
4408   // Try not to place code on a loop entry projection
4409   // which can inhibit range check elimination.
4410   if (least != early) {
4411     Node* ctrl_out = least-&gt;unique_ctrl_out();
4412     if (ctrl_out &amp;&amp; ctrl_out-&gt;is_Loop() &amp;&amp;
4413         least == ctrl_out-&gt;in(LoopNode::EntryControl)) {
4414       // Move the node above predicates as far up as possible so a
4415       // following pass of loop predication doesn&#39;t hoist a predicate
4416       // that depends on it above that node.
4417       Node* new_ctrl = least;
4418       for (;;) {
4419         if (!new_ctrl-&gt;is_Proj()) {
4420           break;
4421         }
4422         CallStaticJavaNode* call = new_ctrl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
4423         if (call == NULL) {
4424           break;
4425         }
4426         int req = call-&gt;uncommon_trap_request();
4427         Deoptimization::DeoptReason trap_reason = Deoptimization::trap_request_reason(req);
4428         if (trap_reason != Deoptimization::Reason_loop_limit_check &amp;&amp;
4429             trap_reason != Deoptimization::Reason_predicate &amp;&amp;
4430             trap_reason != Deoptimization::Reason_profile_predicate) {
4431           break;
4432         }
4433         Node* c = new_ctrl-&gt;in(0)-&gt;in(0);
4434         if (is_dominator(c, early) &amp;&amp; c != early) {
4435           break;
4436         }
4437         new_ctrl = c;
4438       }
4439       least = new_ctrl;
4440     }
4441   }
4442 
4443 #ifdef ASSERT
4444   // If verifying, verify that &#39;verify_me&#39; has a legal location
4445   // and choose it as our location.
4446   if( _verify_me ) {
4447     Node *v_ctrl = _verify_me-&gt;get_ctrl_no_update(n);
4448     Node *legal = LCA;
4449     while( early != legal ) {   // While not at earliest legal
4450       if( legal == v_ctrl ) break;  // Check for prior good location
4451       legal = idom(legal)      ;// Bump up the IDOM tree
4452     }
4453     // Check for prior good location
4454     if( legal == v_ctrl ) least = legal; // Keep prior if found
4455   }
4456 #endif
4457 
4458   // Assign discovered &quot;here or above&quot; point
4459   least = find_non_split_ctrl(least);
4460   verify_strip_mined_scheduling(n, least);
4461   set_ctrl(n, least);
4462 
4463   // Collect inner loop bodies
4464   IdealLoopTree *chosen_loop = get_loop(least);
4465   if( !chosen_loop-&gt;_child )   // Inner loop?
4466     chosen_loop-&gt;_body.push(n);// Collect inner loops
4467 }
4468 
4469 #ifdef ASSERT
4470 void PhaseIdealLoop::dump_bad_graph(const char* msg, Node* n, Node* early, Node* LCA) {
4471   tty-&gt;print_cr(&quot;%s&quot;, msg);
4472   tty-&gt;print(&quot;n: &quot;); n-&gt;dump();
4473   tty-&gt;print(&quot;early(n): &quot;); early-&gt;dump();
4474   if (n-&gt;in(0) != NULL  &amp;&amp; !n-&gt;in(0)-&gt;is_top() &amp;&amp;
4475       n-&gt;in(0) != early &amp;&amp; !n-&gt;in(0)-&gt;is_Root()) {
4476     tty-&gt;print(&quot;n-&gt;in(0): &quot;); n-&gt;in(0)-&gt;dump();
4477   }
4478   for (uint i = 1; i &lt; n-&gt;req(); i++) {
4479     Node* in1 = n-&gt;in(i);
4480     if (in1 != NULL &amp;&amp; in1 != n &amp;&amp; !in1-&gt;is_top()) {
4481       tty-&gt;print(&quot;n-&gt;in(%d): &quot;, i); in1-&gt;dump();
4482       Node* in1_early = get_ctrl(in1);
4483       tty-&gt;print(&quot;early(n-&gt;in(%d)): &quot;, i); in1_early-&gt;dump();
4484       if (in1-&gt;in(0) != NULL     &amp;&amp; !in1-&gt;in(0)-&gt;is_top() &amp;&amp;
4485           in1-&gt;in(0) != in1_early &amp;&amp; !in1-&gt;in(0)-&gt;is_Root()) {
4486         tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(0): &quot;, i); in1-&gt;in(0)-&gt;dump();
4487       }
4488       for (uint j = 1; j &lt; in1-&gt;req(); j++) {
4489         Node* in2 = in1-&gt;in(j);
4490         if (in2 != NULL &amp;&amp; in2 != n &amp;&amp; in2 != in1 &amp;&amp; !in2-&gt;is_top()) {
4491           tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d): &quot;, i, j); in2-&gt;dump();
4492           Node* in2_early = get_ctrl(in2);
4493           tty-&gt;print(&quot;early(n-&gt;in(%d)-&gt;in(%d)): &quot;, i, j); in2_early-&gt;dump();
4494           if (in2-&gt;in(0) != NULL     &amp;&amp; !in2-&gt;in(0)-&gt;is_top() &amp;&amp;
4495               in2-&gt;in(0) != in2_early &amp;&amp; !in2-&gt;in(0)-&gt;is_Root()) {
4496             tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d)-&gt;in(0): &quot;, i, j); in2-&gt;in(0)-&gt;dump();
4497           }
4498         }
4499       }
4500     }
4501   }
4502   tty-&gt;cr();
4503   tty-&gt;print(&quot;LCA(n): &quot;); LCA-&gt;dump();
4504   for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {
4505     Node* u1 = n-&gt;raw_out(i);
4506     if (u1 == n)
4507       continue;
4508     tty-&gt;print(&quot;n-&gt;out(%d): &quot;, i); u1-&gt;dump();
4509     if (u1-&gt;is_CFG()) {
4510       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4511         Node* u2 = u1-&gt;raw_out(j);
4512         if (u2 != u1 &amp;&amp; u2 != n &amp;&amp; u2-&gt;is_CFG()) {
4513           tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4514         }
4515       }
4516     } else {
4517       Node* u1_later = get_ctrl(u1);
4518       tty-&gt;print(&quot;later(n-&gt;out(%d)): &quot;, i); u1_later-&gt;dump();
4519       if (u1-&gt;in(0) != NULL     &amp;&amp; !u1-&gt;in(0)-&gt;is_top() &amp;&amp;
4520           u1-&gt;in(0) != u1_later &amp;&amp; !u1-&gt;in(0)-&gt;is_Root()) {
4521         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u1-&gt;in(0)-&gt;dump();
4522       }
4523       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4524         Node* u2 = u1-&gt;raw_out(j);
4525         if (u2 == n || u2 == u1)
4526           continue;
4527         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4528         if (!u2-&gt;is_CFG()) {
4529           Node* u2_later = get_ctrl(u2);
4530           tty-&gt;print(&quot;later(n-&gt;out(%d)-&gt;out(%d)): &quot;, i, j); u2_later-&gt;dump();
4531           if (u2-&gt;in(0) != NULL     &amp;&amp; !u2-&gt;in(0)-&gt;is_top() &amp;&amp;
4532               u2-&gt;in(0) != u2_later &amp;&amp; !u2-&gt;in(0)-&gt;is_Root()) {
4533             tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u2-&gt;in(0)-&gt;dump();
4534           }
4535         }
4536       }
4537     }
4538   }
4539   tty-&gt;cr();
4540   int ct = 0;
4541   Node *dbg_legal = LCA;
4542   while(!dbg_legal-&gt;is_Start() &amp;&amp; ct &lt; 100) {
4543     tty-&gt;print(&quot;idom[%d] &quot;,ct); dbg_legal-&gt;dump();
4544     ct++;
4545     dbg_legal = idom(dbg_legal);
4546   }
4547   tty-&gt;cr();
4548 }
4549 #endif
4550 
4551 #ifndef PRODUCT
4552 //------------------------------dump-------------------------------------------
4553 void PhaseIdealLoop::dump() const {
4554   ResourceMark rm;
4555   Arena* arena = Thread::current()-&gt;resource_area();
4556   Node_Stack stack(arena, C-&gt;live_nodes() &gt;&gt; 2);
4557   Node_List rpo_list;
4558   VectorSet visited(arena);
4559   visited.set(C-&gt;top()-&gt;_idx);
4560   rpo(C-&gt;root(), stack, visited, rpo_list);
4561   // Dump root loop indexed by last element in PO order
4562   dump(_ltree_root, rpo_list.size(), rpo_list);
4563 }
4564 
4565 void PhaseIdealLoop::dump(IdealLoopTree* loop, uint idx, Node_List &amp;rpo_list) const {
4566   loop-&gt;dump_head();
4567 
4568   // Now scan for CFG nodes in the same loop
4569   for (uint j = idx; j &gt; 0; j--) {
4570     Node* n = rpo_list[j-1];
4571     if (!_nodes[n-&gt;_idx])      // Skip dead nodes
4572       continue;
4573 
4574     if (get_loop(n) != loop) { // Wrong loop nest
4575       if (get_loop(n)-&gt;_head == n &amp;&amp;    // Found nested loop?
4576           get_loop(n)-&gt;_parent == loop)
4577         dump(get_loop(n), rpo_list.size(), rpo_list);     // Print it nested-ly
4578       continue;
4579     }
4580 
4581     // Dump controlling node
4582     tty-&gt;sp(2 * loop-&gt;_nest);
4583     tty-&gt;print(&quot;C&quot;);
4584     if (n == C-&gt;root()) {
4585       n-&gt;dump();
4586     } else {
4587       Node* cached_idom   = idom_no_update(n);
4588       Node* computed_idom = n-&gt;in(0);
4589       if (n-&gt;is_Region()) {
4590         computed_idom = compute_idom(n);
4591         // computed_idom() will return n-&gt;in(0) when idom(n) is an IfNode (or
4592         // any MultiBranch ctrl node), so apply a similar transform to
4593         // the cached idom returned from idom_no_update.
4594         cached_idom = find_non_split_ctrl(cached_idom);
4595       }
4596       tty-&gt;print(&quot; ID:%d&quot;, computed_idom-&gt;_idx);
4597       n-&gt;dump();
4598       if (cached_idom != computed_idom) {
4599         tty-&gt;print_cr(&quot;*** BROKEN IDOM!  Computed as: %d, cached as: %d&quot;,
4600                       computed_idom-&gt;_idx, cached_idom-&gt;_idx);
4601       }
4602     }
4603     // Dump nodes it controls
4604     for (uint k = 0; k &lt; _nodes.Size(); k++) {
4605       // (k &lt; C-&gt;unique() &amp;&amp; get_ctrl(find(k)) == n)
4606       if (k &lt; C-&gt;unique() &amp;&amp; _nodes[k] == (Node*)((intptr_t)n + 1)) {
4607         Node* m = C-&gt;root()-&gt;find(k);
4608         if (m &amp;&amp; m-&gt;outcnt() &gt; 0) {
4609           if (!(has_ctrl(m) &amp;&amp; get_ctrl_no_update(m) == n)) {
4610             tty-&gt;print_cr(&quot;*** BROKEN CTRL ACCESSOR!  _nodes[k] is %p, ctrl is %p&quot;,
4611                           _nodes[k], has_ctrl(m) ? get_ctrl_no_update(m) : NULL);
4612           }
4613           tty-&gt;sp(2 * loop-&gt;_nest + 1);
4614           m-&gt;dump();
4615         }
4616       }
4617     }
4618   }
4619 }
4620 #endif
4621 
4622 // Collect a R-P-O for the whole CFG.
4623 // Result list is in post-order (scan backwards for RPO)
4624 void PhaseIdealLoop::rpo(Node* start, Node_Stack &amp;stk, VectorSet &amp;visited, Node_List &amp;rpo_list) const {
4625   stk.push(start, 0);
4626   visited.set(start-&gt;_idx);
4627 
4628   while (stk.is_nonempty()) {
4629     Node* m   = stk.node();
4630     uint  idx = stk.index();
4631     if (idx &lt; m-&gt;outcnt()) {
4632       stk.set_index(idx + 1);
4633       Node* n = m-&gt;raw_out(idx);
4634       if (n-&gt;is_CFG() &amp;&amp; !visited.test_set(n-&gt;_idx)) {
4635         stk.push(n, 0);
4636       }
4637     } else {
4638       rpo_list.push(m);
4639       stk.pop();
4640     }
4641   }
4642 }
4643 
4644 
4645 //=============================================================================
4646 //------------------------------LoopTreeIterator-------------------------------
4647 
4648 // Advance to next loop tree using a preorder, left-to-right traversal.
4649 void LoopTreeIterator::next() {
4650   assert(!done(), &quot;must not be done.&quot;);
4651   if (_curnt-&gt;_child != NULL) {
4652     _curnt = _curnt-&gt;_child;
4653   } else if (_curnt-&gt;_next != NULL) {
4654     _curnt = _curnt-&gt;_next;
4655   } else {
4656     while (_curnt != _root &amp;&amp; _curnt-&gt;_next == NULL) {
4657       _curnt = _curnt-&gt;_parent;
4658     }
4659     if (_curnt == _root) {
4660       _curnt = NULL;
4661       assert(done(), &quot;must be done.&quot;);
4662     } else {
4663       assert(_curnt-&gt;_next != NULL, &quot;must be more to do&quot;);
4664       _curnt = _curnt-&gt;_next;
4665     }
4666   }
4667 }
    </pre>
  </body>
</html>