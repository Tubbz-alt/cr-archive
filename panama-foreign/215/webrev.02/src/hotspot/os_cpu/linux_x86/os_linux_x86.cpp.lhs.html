<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/os_cpu/linux_x86/os_linux_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 // no precompiled headers
 26 #include &quot;jvm.h&quot;
 27 #include &quot;asm/macroAssembler.hpp&quot;
 28 #include &quot;classfile/classLoader.hpp&quot;
 29 #include &quot;classfile/systemDictionary.hpp&quot;
 30 #include &quot;classfile/vmSymbols.hpp&quot;
 31 #include &quot;code/codeCache.hpp&quot;
 32 #include &quot;code/icBuffer.hpp&quot;
 33 #include &quot;code/vtableStubs.hpp&quot;
 34 #include &quot;interpreter/interpreter.hpp&quot;
 35 #include &quot;logging/log.hpp&quot;
 36 #include &quot;memory/allocation.inline.hpp&quot;
 37 #include &quot;os_share_linux.hpp&quot;
 38 #include &quot;prims/jniFastGetField.hpp&quot;
 39 #include &quot;prims/jvm_misc.hpp&quot;
 40 #include &quot;runtime/arguments.hpp&quot;
<a name="1" id="anc1"></a><span class="line-removed"> 41 #include &quot;runtime/extendedPC.hpp&quot;</span>
 42 #include &quot;runtime/frame.inline.hpp&quot;
 43 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 44 #include &quot;runtime/java.hpp&quot;
 45 #include &quot;runtime/javaCalls.hpp&quot;
 46 #include &quot;runtime/mutexLocker.hpp&quot;
 47 #include &quot;runtime/osThread.hpp&quot;
 48 #include &quot;runtime/safepointMechanism.hpp&quot;
 49 #include &quot;runtime/sharedRuntime.hpp&quot;
 50 #include &quot;runtime/stubRoutines.hpp&quot;
 51 #include &quot;runtime/thread.inline.hpp&quot;
 52 #include &quot;runtime/timer.hpp&quot;
 53 #include &quot;services/memTracker.hpp&quot;
 54 #include &quot;utilities/align.hpp&quot;
 55 #include &quot;utilities/debug.hpp&quot;
 56 #include &quot;utilities/events.hpp&quot;
 57 #include &quot;utilities/vmError.hpp&quot;
 58 
 59 // put OS-includes here
 60 # include &lt;sys/types.h&gt;
 61 # include &lt;sys/mman.h&gt;
 62 # include &lt;pthread.h&gt;
 63 # include &lt;signal.h&gt;
 64 # include &lt;errno.h&gt;
 65 # include &lt;dlfcn.h&gt;
 66 # include &lt;stdlib.h&gt;
 67 # include &lt;stdio.h&gt;
 68 # include &lt;unistd.h&gt;
 69 # include &lt;sys/resource.h&gt;
 70 # include &lt;pthread.h&gt;
 71 # include &lt;sys/stat.h&gt;
 72 # include &lt;sys/time.h&gt;
 73 # include &lt;sys/utsname.h&gt;
 74 # include &lt;sys/socket.h&gt;
 75 # include &lt;sys/wait.h&gt;
 76 # include &lt;pwd.h&gt;
 77 # include &lt;poll.h&gt;
 78 # include &lt;ucontext.h&gt;
 79 #ifndef AMD64
 80 # include &lt;fpu_control.h&gt;
 81 #endif
 82 
 83 #ifdef AMD64
 84 #define REG_SP REG_RSP
 85 #define REG_PC REG_RIP
 86 #define REG_FP REG_RBP
 87 #define SPELL_REG_SP &quot;rsp&quot;
 88 #define SPELL_REG_FP &quot;rbp&quot;
 89 #else
 90 #define REG_SP REG_UESP
 91 #define REG_PC REG_EIP
 92 #define REG_FP REG_EBP
 93 #define SPELL_REG_SP &quot;esp&quot;
 94 #define SPELL_REG_FP &quot;ebp&quot;
 95 #endif // AMD64
 96 
 97 address os::current_stack_pointer() {
 98   return (address)__builtin_frame_address(0);
 99 }
100 
101 char* os::non_memory_address_word() {
102   // Must never look like an address returned by reserve_memory,
103   // even in its subfields (as defined by the CPU immediate fields,
104   // if the CPU splits constants across multiple instructions).
105 
106   return (char*) -1;
107 }
108 
109 address os::Linux::ucontext_get_pc(const ucontext_t * uc) {
110   return (address)uc-&gt;uc_mcontext.gregs[REG_PC];
111 }
112 
113 void os::Linux::ucontext_set_pc(ucontext_t * uc, address pc) {
114   uc-&gt;uc_mcontext.gregs[REG_PC] = (intptr_t)pc;
115 }
116 
117 intptr_t* os::Linux::ucontext_get_sp(const ucontext_t * uc) {
118   return (intptr_t*)uc-&gt;uc_mcontext.gregs[REG_SP];
119 }
120 
121 intptr_t* os::Linux::ucontext_get_fp(const ucontext_t * uc) {
122   return (intptr_t*)uc-&gt;uc_mcontext.gregs[REG_FP];
123 }
124 
<a name="2" id="anc2"></a><span class="line-modified">125 // For Forte Analyzer AsyncGetCallTrace profiling support - thread</span>
<span class="line-removed">126 // is currently interrupted by SIGPROF.</span>
<span class="line-removed">127 // os::Solaris::fetch_frame_from_ucontext() tries to skip nested signal</span>
<span class="line-removed">128 // frames. Currently we don&#39;t do that on Linux, so it&#39;s the same as</span>
<span class="line-removed">129 // os::fetch_frame_from_context().</span>
<span class="line-removed">130 // This method is also used for stack overflow signal handling.</span>
<span class="line-removed">131 ExtendedPC os::Linux::fetch_frame_from_ucontext(Thread* thread,</span>
<span class="line-removed">132   const ucontext_t* uc, intptr_t** ret_sp, intptr_t** ret_fp) {</span>
<span class="line-removed">133 </span>
<span class="line-removed">134   assert(thread != NULL, &quot;just checking&quot;);</span>
<span class="line-removed">135   assert(ret_sp != NULL, &quot;just checking&quot;);</span>
<span class="line-removed">136   assert(ret_fp != NULL, &quot;just checking&quot;);</span>
<span class="line-removed">137 </span>
<span class="line-removed">138   return os::fetch_frame_from_context(uc, ret_sp, ret_fp);</span>
<span class="line-removed">139 }</span>
<span class="line-removed">140 </span>
<span class="line-removed">141 ExtendedPC os::fetch_frame_from_context(const void* ucVoid,</span>
142                     intptr_t** ret_sp, intptr_t** ret_fp) {
143 
<a name="3" id="anc3"></a><span class="line-modified">144   ExtendedPC  epc;</span>
145   const ucontext_t* uc = (const ucontext_t*)ucVoid;
146 
147   if (uc != NULL) {
<a name="4" id="anc4"></a><span class="line-modified">148     epc = ExtendedPC(os::Linux::ucontext_get_pc(uc));</span>
149     if (ret_sp) *ret_sp = os::Linux::ucontext_get_sp(uc);
150     if (ret_fp) *ret_fp = os::Linux::ucontext_get_fp(uc);
151   } else {
<a name="5" id="anc5"></a><span class="line-modified">152     // construct empty ExtendedPC for return value checking</span>
<span class="line-removed">153     epc = ExtendedPC(NULL);</span>
154     if (ret_sp) *ret_sp = (intptr_t *)NULL;
155     if (ret_fp) *ret_fp = (intptr_t *)NULL;
156   }
157 
158   return epc;
159 }
160 
161 frame os::fetch_frame_from_context(const void* ucVoid) {
162   intptr_t* sp;
163   intptr_t* fp;
<a name="6" id="anc6"></a><span class="line-modified">164   ExtendedPC epc = fetch_frame_from_context(ucVoid, &amp;sp, &amp;fp);</span>
<span class="line-modified">165   return frame(sp, fp, epc.pc());</span>
<span class="line-removed">166 }</span>
<span class="line-removed">167 </span>
<span class="line-removed">168 frame os::fetch_frame_from_ucontext(Thread* thread, void* ucVoid) {</span>
<span class="line-removed">169   intptr_t* sp;</span>
<span class="line-removed">170   intptr_t* fp;</span>
<span class="line-removed">171   ExtendedPC epc = os::Linux::fetch_frame_from_ucontext(thread, (ucontext_t*)ucVoid, &amp;sp, &amp;fp);</span>
<span class="line-removed">172   return frame(sp, fp, epc.pc());</span>
173 }
174 
175 bool os::Linux::get_frame_at_stack_banging_point(JavaThread* thread, ucontext_t* uc, frame* fr) {
176   address pc = (address) os::Linux::ucontext_get_pc(uc);
177   if (Interpreter::contains(pc)) {
178     // interpreter performs stack banging after the fixed frame header has
179     // been generated while the compilers perform it before. To maintain
180     // semantic consistency between interpreted and compiled frames, the
181     // method returns the Java sender of the current frame.
<a name="7" id="anc7"></a><span class="line-modified">182     *fr = os::fetch_frame_from_ucontext(thread, uc);</span>
183     if (!fr-&gt;is_first_java_frame()) {
184       // get_frame_at_stack_banging_point() is only called when we
185       // have well defined stacks so java_sender() calls do not need
186       // to assert safe_for_sender() first.
187       *fr = fr-&gt;java_sender();
188     }
189   } else {
190     // more complex code with compiled code
191     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);
192     CodeBlob* cb = CodeCache::find_blob(pc);
193     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {
194       // Not sure where the pc points to, fallback to default
195       // stack overflow handling
196       return false;
197     } else {
198       // in compiled code, the stack banging is performed just after the return pc
199       // has been pushed on the stack
200       intptr_t* fp = os::Linux::ucontext_get_fp(uc);
201       intptr_t* sp = os::Linux::ucontext_get_sp(uc);
202       *fr = frame(sp + 1, fp, (address)*sp);
203       if (!fr-&gt;is_java_frame()) {
204         assert(!fr-&gt;is_first_frame(), &quot;Safety check&quot;);
205         // See java_sender() comment above.
206         *fr = fr-&gt;java_sender();
207       }
208     }
209   }
210   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);
211   return true;
212 }
213 
214 // By default, gcc always save frame pointer (%ebp/%rbp) on stack. It may get
215 // turned off by -fomit-frame-pointer,
216 frame os::get_sender_for_C_frame(frame* fr) {
217   return frame(fr-&gt;sender_sp(), fr-&gt;link(), fr-&gt;sender_pc());
218 }
219 
220 intptr_t* _get_previous_fp() {
221 #if defined(__clang__)
222   intptr_t **ebp;
223   __asm__ __volatile__ (&quot;mov %%&quot; SPELL_REG_FP &quot;, %0&quot;:&quot;=r&quot;(ebp):);
224 #else
225   register intptr_t **ebp __asm__ (SPELL_REG_FP);
226 #endif
227   // ebp is for this frame (_get_previous_fp). We want the ebp for the
228   // caller of os::current_frame*(), so go up two frames. However, for
229   // optimized builds, _get_previous_fp() will be inlined, so only go
230   // up 1 frame in that case.
231 #ifdef _NMT_NOINLINE_
232   return **(intptr_t***)ebp;
233 #else
234   return *ebp;
235 #endif
236 }
237 
238 
239 frame os::current_frame() {
240   intptr_t* fp = _get_previous_fp();
241   frame myframe((intptr_t*)os::current_stack_pointer(),
242                 (intptr_t*)fp,
243                 CAST_FROM_FN_PTR(address, os::current_frame));
244   if (os::is_first_C_frame(&amp;myframe)) {
245     // stack is not walkable
246     return frame();
247   } else {
248     return os::get_sender_for_C_frame(&amp;myframe);
249   }
250 }
251 
252 // Utility functions
253 
254 // From IA32 System Programming Guide
255 enum {
256   trap_page_fault = 0xE
257 };
258 
259 extern &quot;C&quot; JNIEXPORT int
260 JVM_handle_linux_signal(int sig,
261                         siginfo_t* info,
262                         void* ucVoid,
263                         int abort_if_unrecognized) {
264   ucontext_t* uc = (ucontext_t*) ucVoid;
265 
266   Thread* t = Thread::current_or_null_safe();
267 
268   // Must do this before SignalHandlerMark, if crash protection installed we will longjmp away
269   // (no destructors can be run)
270   os::ThreadCrashProtection::check_crash_protection(sig, t);
271 
272   SignalHandlerMark shm(t);
273 
274   // Note: it&#39;s not uncommon that JNI code uses signal/sigset to install
275   // then restore certain signal handler (e.g. to temporarily block SIGPIPE,
276   // or have a SIGILL handler when detecting CPU type). When that happens,
277   // JVM_handle_linux_signal() might be invoked with junk info/ucVoid. To
278   // avoid unnecessary crash when libjsig is not preloaded, try handle signals
279   // that do not require siginfo/ucontext first.
280 
281   if (sig == SIGPIPE || sig == SIGXFSZ) {
282     // allow chained handler to go first
283     if (os::Linux::chained_handler(sig, info, ucVoid)) {
284       return true;
285     } else {
286       // Ignoring SIGPIPE/SIGXFSZ - see bugs 4229104 or 6499219
287       return true;
288     }
289   }
290 
291 #ifdef CAN_SHOW_REGISTERS_ON_ASSERT
292   if ((sig == SIGSEGV || sig == SIGBUS) &amp;&amp; info != NULL &amp;&amp; info-&gt;si_addr == g_assert_poison) {
293     if (handle_assert_poison_fault(ucVoid, info-&gt;si_addr)) {
294       return 1;
295     }
296   }
297 #endif
298 
299   JavaThread* thread = NULL;
300   VMThread* vmthread = NULL;
301   if (os::Linux::signal_handlers_are_installed) {
302     if (t != NULL ){
303       if(t-&gt;is_Java_thread()) {
304         thread = (JavaThread*)t;
305       }
306       else if(t-&gt;is_VM_thread()){
307         vmthread = (VMThread *)t;
308       }
309     }
310   }
311 /*
312   NOTE: does not seem to work on linux.
313   if (info == NULL || info-&gt;si_code &lt;= 0 || info-&gt;si_code == SI_NOINFO) {
314     // can&#39;t decode this kind of signal
315     info = NULL;
316   } else {
317     assert(sig == info-&gt;si_signo, &quot;bad siginfo&quot;);
318   }
319 */
320   // decide if this trap can be handled by a stub
321   address stub = NULL;
322 
323   address pc          = NULL;
324 
325   //%note os_trap_1
326   if (info != NULL &amp;&amp; uc != NULL &amp;&amp; thread != NULL) {
327     pc = (address) os::Linux::ucontext_get_pc(uc);
328 
329     if (StubRoutines::is_safefetch_fault(pc)) {
330       os::Linux::ucontext_set_pc(uc, StubRoutines::continuation_for_safefetch_fault(pc));
331       return 1;
332     }
333 
334 #ifndef AMD64
335     // Halt if SI_KERNEL before more crashes get misdiagnosed as Java bugs
336     // This can happen in any running code (currently more frequently in
337     // interpreter code but has been seen in compiled code)
338     if (sig == SIGSEGV &amp;&amp; info-&gt;si_addr == 0 &amp;&amp; info-&gt;si_code == SI_KERNEL) {
339       fatal(&quot;An irrecoverable SI_KERNEL SIGSEGV has occurred due &quot;
340             &quot;to unstable signal handling in this distribution.&quot;);
341     }
342 #endif // AMD64
343 
344     // Handle ALL stack overflow variations here
345     if (sig == SIGSEGV) {
346       address addr = (address) info-&gt;si_addr;
347 
348       // check if fault address is within thread stack
349       if (thread-&gt;is_in_full_stack(addr)) {
350         // stack overflow
351         if (thread-&gt;in_stack_yellow_reserved_zone(addr)) {
352           if (thread-&gt;thread_state() == _thread_in_Java) {
353             if (thread-&gt;in_stack_reserved_zone(addr)) {
354               frame fr;
355               if (os::Linux::get_frame_at_stack_banging_point(thread, uc, &amp;fr)) {
356                 assert(fr.is_java_frame(), &quot;Must be a Java frame&quot;);
357                 frame activation =
358                   SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);
359                 if (activation.sp() != NULL) {
360                   thread-&gt;disable_stack_reserved_zone();
361                   if (activation.is_interpreted_frame()) {
362                     thread-&gt;set_reserved_stack_activation((address)(
363                       activation.fp() + frame::interpreter_frame_initial_sp_offset));
364                   } else {
365                     thread-&gt;set_reserved_stack_activation((address)activation.unextended_sp());
366                   }
367                   return 1;
368                 }
369               }
370             }
371             // Throw a stack overflow exception.  Guard pages will be reenabled
372             // while unwinding the stack.
373             thread-&gt;disable_stack_yellow_reserved_zone();
374             stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);
375           } else {
376             // Thread was in the vm or native code.  Return and try to finish.
377             thread-&gt;disable_stack_yellow_reserved_zone();
378             return 1;
379           }
380         } else if (thread-&gt;in_stack_red_zone(addr)) {
381           // Fatal red zone violation.  Disable the guard pages and fall through
382           // to handle_unexpected_exception way down below.
383           thread-&gt;disable_stack_red_zone();
384           tty-&gt;print_raw_cr(&quot;An irrecoverable stack overflow has occurred.&quot;);
385 
386           // This is a likely cause, but hard to verify. Let&#39;s just print
387           // it as a hint.
388           tty-&gt;print_raw_cr(&quot;Please check if any of your loaded .so files has &quot;
389                             &quot;enabled executable stack (see man page execstack(8))&quot;);
390         } else {
391           // Accessing stack address below sp may cause SEGV if current
392           // thread has MAP_GROWSDOWN stack. This should only happen when
393           // current thread was created by user code with MAP_GROWSDOWN flag
394           // and then attached to VM. See notes in os_linux.cpp.
395           if (thread-&gt;osthread()-&gt;expanding_stack() == 0) {
396              thread-&gt;osthread()-&gt;set_expanding_stack();
397              if (os::Linux::manually_expand_stack(thread, addr)) {
398                thread-&gt;osthread()-&gt;clear_expanding_stack();
399                return 1;
400              }
401              thread-&gt;osthread()-&gt;clear_expanding_stack();
402           } else {
403              fatal(&quot;recursive segv. expanding stack.&quot;);
404           }
405         }
406       }
407     }
408 
409     if ((sig == SIGSEGV) &amp;&amp; VM_Version::is_cpuinfo_segv_addr(pc)) {
410       // Verify that OS save/restore AVX registers.
411       stub = VM_Version::cpuinfo_cont_addr();
412     }
413 
414     if (thread-&gt;thread_state() == _thread_in_Java) {
415       // Java thread running in Java code =&gt; find exception handler if any
416       // a fault inside compiled code, the interpreter, or a stub
417 
418       if (sig == SIGSEGV &amp;&amp; SafepointMechanism::is_poll_address((address)info-&gt;si_addr)) {
419         stub = SharedRuntime::get_poll_stub(pc);
420       } else if (sig == SIGBUS /* &amp;&amp; info-&gt;si_code == BUS_OBJERR */) {
421         // BugId 4454115: A read from a MappedByteBuffer can fault
422         // here if the underlying file has been truncated.
423         // Do not crash the VM in such a case.
424         CodeBlob* cb = CodeCache::find_blob_unsafe(pc);
425         CompiledMethod* nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
426         bool is_unsafe_arraycopy = thread-&gt;doing_unsafe_access() &amp;&amp; UnsafeCopyMemory::contains_pc(pc);
427         if ((nm != NULL &amp;&amp; nm-&gt;has_unsafe_access()) || is_unsafe_arraycopy) {
428           address next_pc = Assembler::locate_next_instruction(pc);
429           if (is_unsafe_arraycopy) {
430             next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
431           }
432           stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
433         }
434       }
435       else
436 
437 #ifdef AMD64
438       if (sig == SIGFPE  &amp;&amp;
439           (info-&gt;si_code == FPE_INTDIV || info-&gt;si_code == FPE_FLTDIV)) {
440         stub =
441           SharedRuntime::
442           continuation_for_implicit_exception(thread,
443                                               pc,
444                                               SharedRuntime::
445                                               IMPLICIT_DIVIDE_BY_ZERO);
446 #else
447       if (sig == SIGFPE /* &amp;&amp; info-&gt;si_code == FPE_INTDIV */) {
448         // HACK: si_code does not work on linux 2.2.12-20!!!
449         int op = pc[0];
450         if (op == 0xDB) {
451           // FIST
452           // TODO: The encoding of D2I in i486.ad can cause an exception
453           // prior to the fist instruction if there was an invalid operation
454           // pending. We want to dismiss that exception. From the win_32
455           // side it also seems that if it really was the fist causing
456           // the exception that we do the d2i by hand with different
457           // rounding. Seems kind of weird.
458           // NOTE: that we take the exception at the NEXT floating point instruction.
459           assert(pc[0] == 0xDB, &quot;not a FIST opcode&quot;);
460           assert(pc[1] == 0x14, &quot;not a FIST opcode&quot;);
461           assert(pc[2] == 0x24, &quot;not a FIST opcode&quot;);
462           return true;
463         } else if (op == 0xF7) {
464           // IDIV
465           stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_DIVIDE_BY_ZERO);
466         } else {
467           // TODO: handle more cases if we are using other x86 instructions
468           //   that can generate SIGFPE signal on linux.
469           tty-&gt;print_cr(&quot;unknown opcode 0x%X with SIGFPE.&quot;, op);
470           fatal(&quot;please update this code.&quot;);
471         }
472 #endif // AMD64
473       } else if (sig == SIGSEGV &amp;&amp;
474                  MacroAssembler::uses_implicit_null_check(info-&gt;si_addr)) {
475           // Determination of interpreter/vtable stub/compiled code null exception
476           stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);
477       }
478     } else if ((thread-&gt;thread_state() == _thread_in_vm ||
479                 thread-&gt;thread_state() == _thread_in_native) &amp;&amp;
480                (sig == SIGBUS &amp;&amp; /* info-&gt;si_code == BUS_OBJERR &amp;&amp; */
481                thread-&gt;doing_unsafe_access())) {
482         address next_pc = Assembler::locate_next_instruction(pc);
483         if (UnsafeCopyMemory::contains_pc(pc)) {
484           next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
485         }
486         stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
487     }
488 
489     // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks in
490     // and the heap gets shrunk before the field access.
491     if ((sig == SIGSEGV) || (sig == SIGBUS)) {
492       address addr = JNI_FastGetField::find_slowcase_pc(pc);
493       if (addr != (address)-1) {
494         stub = addr;
495       }
496     }
497   }
498 
499 #ifndef AMD64
500   // Execution protection violation
501   //
502   // This should be kept as the last step in the triage.  We don&#39;t
503   // have a dedicated trap number for a no-execute fault, so be
504   // conservative and allow other handlers the first shot.
505   //
506   // Note: We don&#39;t test that info-&gt;si_code == SEGV_ACCERR here.
507   // this si_code is so generic that it is almost meaningless; and
508   // the si_code for this condition may change in the future.
509   // Furthermore, a false-positive should be harmless.
510   if (UnguardOnExecutionViolation &gt; 0 &amp;&amp;
511       (sig == SIGSEGV || sig == SIGBUS) &amp;&amp;
512       uc-&gt;uc_mcontext.gregs[REG_TRAPNO] == trap_page_fault) {
513     int page_size = os::vm_page_size();
514     address addr = (address) info-&gt;si_addr;
515     address pc = os::Linux::ucontext_get_pc(uc);
516     // Make sure the pc and the faulting address are sane.
517     //
518     // If an instruction spans a page boundary, and the page containing
519     // the beginning of the instruction is executable but the following
520     // page is not, the pc and the faulting address might be slightly
521     // different - we still want to unguard the 2nd page in this case.
522     //
523     // 15 bytes seems to be a (very) safe value for max instruction size.
524     bool pc_is_near_addr =
525       (pointer_delta((void*) addr, (void*) pc, sizeof(char)) &lt; 15);
526     bool instr_spans_page_boundary =
527       (align_down((intptr_t) pc ^ (intptr_t) addr,
528                        (intptr_t) page_size) &gt; 0);
529 
530     if (pc == addr || (pc_is_near_addr &amp;&amp; instr_spans_page_boundary)) {
531       static volatile address last_addr =
532         (address) os::non_memory_address_word();
533 
534       // In conservative mode, don&#39;t unguard unless the address is in the VM
535       if (addr != last_addr &amp;&amp;
536           (UnguardOnExecutionViolation &gt; 1 || os::address_is_in_vm(addr))) {
537 
538         // Set memory to RWX and retry
539         address page_start = align_down(addr, page_size);
540         bool res = os::protect_memory((char*) page_start, page_size,
541                                       os::MEM_PROT_RWX);
542 
543         log_debug(os)(&quot;Execution protection violation &quot;
544                       &quot;at &quot; INTPTR_FORMAT
545                       &quot;, unguarding &quot; INTPTR_FORMAT &quot;: %s, errno=%d&quot;, p2i(addr),
546                       p2i(page_start), (res ? &quot;success&quot; : &quot;failed&quot;), errno);
547         stub = pc;
548 
549         // Set last_addr so if we fault again at the same address, we don&#39;t end
550         // up in an endless loop.
551         //
552         // There are two potential complications here.  Two threads trapping at
553         // the same address at the same time could cause one of the threads to
554         // think it already unguarded, and abort the VM.  Likely very rare.
555         //
556         // The other race involves two threads alternately trapping at
557         // different addresses and failing to unguard the page, resulting in
558         // an endless loop.  This condition is probably even more unlikely than
559         // the first.
560         //
561         // Although both cases could be avoided by using locks or thread local
562         // last_addr, these solutions are unnecessary complication: this
563         // handler is a best-effort safety net, not a complete solution.  It is
564         // disabled by default and should only be used as a workaround in case
565         // we missed any no-execute-unsafe VM code.
566 
567         last_addr = addr;
568       }
569     }
570   }
571 #endif // !AMD64
572 
573   if (stub != NULL) {
574     // save all thread context in case we need to restore it
575     if (thread != NULL) thread-&gt;set_saved_exception_pc(pc);
576 
577     os::Linux::ucontext_set_pc(uc, stub);
578     return true;
579   }
580 
581   // signal-chaining
582   if (os::Linux::chained_handler(sig, info, ucVoid)) {
583      return true;
584   }
585 
586   if (!abort_if_unrecognized) {
587     // caller wants another chance, so give it to him
588     return false;
589   }
590 
591   if (pc == NULL &amp;&amp; uc != NULL) {
592     pc = os::Linux::ucontext_get_pc(uc);
593   }
594 
595   // unmask current signal
596   sigset_t newset;
597   sigemptyset(&amp;newset);
598   sigaddset(&amp;newset, sig);
599   sigprocmask(SIG_UNBLOCK, &amp;newset, NULL);
600 
601   VMError::report_and_die(t, sig, pc, info, ucVoid);
602 
603   ShouldNotReachHere();
604   return true; // Mute compiler
605 }
606 
607 void os::Linux::init_thread_fpu_state(void) {
608 #ifndef AMD64
609   // set fpu to 53 bit precision
610   set_fpu_control_word(0x27f);
611 #endif // !AMD64
612 }
613 
614 int os::Linux::get_fpu_control_word(void) {
615 #ifdef AMD64
616   return 0;
617 #else
618   int fpu_control;
619   _FPU_GETCW(fpu_control);
620   return fpu_control &amp; 0xffff;
621 #endif // AMD64
622 }
623 
624 void os::Linux::set_fpu_control_word(int fpu_control) {
625 #ifndef AMD64
626   _FPU_SETCW(fpu_control);
627 #endif // !AMD64
628 }
629 
630 // Check that the linux kernel version is 2.4 or higher since earlier
631 // versions do not support SSE without patches.
632 bool os::supports_sse() {
633 #ifdef AMD64
634   return true;
635 #else
636   struct utsname uts;
637   if( uname(&amp;uts) != 0 ) return false; // uname fails?
638   char *minor_string;
639   int major = strtol(uts.release,&amp;minor_string,10);
640   int minor = strtol(minor_string+1,NULL,10);
641   bool result = (major &gt; 2 || (major==2 &amp;&amp; minor &gt;= 4));
642   log_info(os)(&quot;OS version is %d.%d, which %s support SSE/SSE2&quot;,
643                major,minor, result ? &quot;DOES&quot; : &quot;does NOT&quot;);
644   return result;
645 #endif // AMD64
646 }
647 
648 bool os::is_allocatable(size_t bytes) {
649 #ifdef AMD64
650   // unused on amd64?
651   return true;
652 #else
653 
654   if (bytes &lt; 2 * G) {
655     return true;
656   }
657 
658   char* addr = reserve_memory(bytes, NULL);
659 
660   if (addr != NULL) {
661     release_memory(addr, bytes);
662   }
663 
664   return addr != NULL;
665 #endif // AMD64
666 }
667 
668 ////////////////////////////////////////////////////////////////////////////////
669 // thread stack
670 
671 // Minimum usable stack sizes required to get to user code. Space for
672 // HotSpot guard pages is added later.
673 size_t os::Posix::_compiler_thread_min_stack_allowed = 48 * K;
674 size_t os::Posix::_java_thread_min_stack_allowed = 40 * K;
675 #ifdef _LP64
676 size_t os::Posix::_vm_internal_thread_min_stack_allowed = 64 * K;
677 #else
678 size_t os::Posix::_vm_internal_thread_min_stack_allowed = (48 DEBUG_ONLY(+ 4)) * K;
679 #endif // _LP64
680 
681 // return default stack size for thr_type
682 size_t os::Posix::default_stack_size(os::ThreadType thr_type) {
683   // default stack size (compiler thread needs larger stack)
684 #ifdef AMD64
685   size_t s = (thr_type == os::compiler_thread ? 4 * M : 1 * M);
686 #else
687   size_t s = (thr_type == os::compiler_thread ? 2 * M : 512 * K);
688 #endif // AMD64
689   return s;
690 }
691 
692 /////////////////////////////////////////////////////////////////////////////
693 // helper functions for fatal error handler
694 
695 void os::print_context(outputStream *st, const void *context) {
696   if (context == NULL) return;
697 
698   const ucontext_t *uc = (const ucontext_t*)context;
699   st-&gt;print_cr(&quot;Registers:&quot;);
700 #ifdef AMD64
701   st-&gt;print(  &quot;RAX=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RAX]);
702   st-&gt;print(&quot;, RBX=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RBX]);
703   st-&gt;print(&quot;, RCX=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RCX]);
704   st-&gt;print(&quot;, RDX=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RDX]);
705   st-&gt;cr();
706   st-&gt;print(  &quot;RSP=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RSP]);
707   st-&gt;print(&quot;, RBP=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RBP]);
708   st-&gt;print(&quot;, RSI=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RSI]);
709   st-&gt;print(&quot;, RDI=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RDI]);
710   st-&gt;cr();
711   st-&gt;print(  &quot;R8 =&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R8]);
712   st-&gt;print(&quot;, R9 =&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R9]);
713   st-&gt;print(&quot;, R10=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R10]);
714   st-&gt;print(&quot;, R11=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R11]);
715   st-&gt;cr();
716   st-&gt;print(  &quot;R12=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R12]);
717   st-&gt;print(&quot;, R13=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R13]);
718   st-&gt;print(&quot;, R14=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R14]);
719   st-&gt;print(&quot;, R15=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_R15]);
720   st-&gt;cr();
721   st-&gt;print(  &quot;RIP=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_RIP]);
722   st-&gt;print(&quot;, EFLAGS=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_EFL]);
723   st-&gt;print(&quot;, CSGSFS=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_CSGSFS]);
724   st-&gt;print(&quot;, ERR=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_ERR]);
725   st-&gt;cr();
726   st-&gt;print(&quot;  TRAPNO=&quot; INTPTR_FORMAT, (intptr_t)uc-&gt;uc_mcontext.gregs[REG_TRAPNO]);
727 #else
728   st-&gt;print(  &quot;EAX=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EAX]);
729   st-&gt;print(&quot;, EBX=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EBX]);
730   st-&gt;print(&quot;, ECX=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_ECX]);
731   st-&gt;print(&quot;, EDX=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EDX]);
732   st-&gt;cr();
733   st-&gt;print(  &quot;ESP=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_UESP]);
734   st-&gt;print(&quot;, EBP=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EBP]);
735   st-&gt;print(&quot;, ESI=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_ESI]);
736   st-&gt;print(&quot;, EDI=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EDI]);
737   st-&gt;cr();
738   st-&gt;print(  &quot;EIP=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EIP]);
739   st-&gt;print(&quot;, EFLAGS=&quot; INTPTR_FORMAT, uc-&gt;uc_mcontext.gregs[REG_EFL]);
740   st-&gt;print(&quot;, CR2=&quot; PTR64_FORMAT, (uint64_t)uc-&gt;uc_mcontext.cr2);
741 #endif // AMD64
742   st-&gt;cr();
743   st-&gt;cr();
744 
745   intptr_t *sp = (intptr_t *)os::Linux::ucontext_get_sp(uc);
746   st-&gt;print_cr(&quot;Top of Stack: (sp=&quot; PTR_FORMAT &quot;)&quot;, p2i(sp));
747   print_hex_dump(st, (address)sp, (address)(sp + 8), sizeof(intptr_t));
748   st-&gt;cr();
749 
750   // Note: it may be unsafe to inspect memory near pc. For example, pc may
751   // point to garbage if entry point in an nmethod is corrupted. Leave
752   // this at the end, and hope for the best.
753   address pc = os::Linux::ucontext_get_pc(uc);
754   print_instructions(st, pc, sizeof(char));
755   st-&gt;cr();
756 }
757 
758 void os::print_register_info(outputStream *st, const void *context) {
759   if (context == NULL) return;
760 
761   const ucontext_t *uc = (const ucontext_t*)context;
762 
763   st-&gt;print_cr(&quot;Register to memory mapping:&quot;);
764   st-&gt;cr();
765 
766   // this is horrendously verbose but the layout of the registers in the
767   // context does not match how we defined our abstract Register set, so
768   // we can&#39;t just iterate through the gregs area
769 
770   // this is only for the &quot;general purpose&quot; registers
771 
772 #ifdef AMD64
773   st-&gt;print(&quot;RAX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RAX]);
774   st-&gt;print(&quot;RBX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RBX]);
775   st-&gt;print(&quot;RCX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RCX]);
776   st-&gt;print(&quot;RDX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RDX]);
777   st-&gt;print(&quot;RSP=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RSP]);
778   st-&gt;print(&quot;RBP=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RBP]);
779   st-&gt;print(&quot;RSI=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RSI]);
780   st-&gt;print(&quot;RDI=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_RDI]);
781   st-&gt;print(&quot;R8 =&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R8]);
782   st-&gt;print(&quot;R9 =&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R9]);
783   st-&gt;print(&quot;R10=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R10]);
784   st-&gt;print(&quot;R11=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R11]);
785   st-&gt;print(&quot;R12=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R12]);
786   st-&gt;print(&quot;R13=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R13]);
787   st-&gt;print(&quot;R14=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R14]);
788   st-&gt;print(&quot;R15=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_R15]);
789 #else
790   st-&gt;print(&quot;EAX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_EAX]);
791   st-&gt;print(&quot;EBX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_EBX]);
792   st-&gt;print(&quot;ECX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_ECX]);
793   st-&gt;print(&quot;EDX=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_EDX]);
794   st-&gt;print(&quot;ESP=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_ESP]);
795   st-&gt;print(&quot;EBP=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_EBP]);
796   st-&gt;print(&quot;ESI=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_ESI]);
797   st-&gt;print(&quot;EDI=&quot;); print_location(st, uc-&gt;uc_mcontext.gregs[REG_EDI]);
798 #endif // AMD64
799 
800   st-&gt;cr();
801 }
802 
803 void os::setup_fpu() {
804 #ifndef AMD64
805   address fpu_cntrl = StubRoutines::addr_fpu_cntrl_wrd_std();
806   __asm__ volatile (  &quot;fldcw (%0)&quot; :
807                       : &quot;r&quot; (fpu_cntrl) : &quot;memory&quot;);
808 #endif // !AMD64
809 }
810 
811 #ifndef PRODUCT
812 void os::verify_stack_alignment() {
813 #ifdef AMD64
814   assert(((intptr_t)os::current_stack_pointer() &amp; (StackAlignmentInBytes-1)) == 0, &quot;incorrect stack alignment&quot;);
815 #endif
816 }
817 #endif
818 
819 
820 /*
821  * IA32 only: execute code at a high address in case buggy NX emulation is present. I.e. avoid CS limit
822  * updates (JDK-8023956).
823  */
824 void os::workaround_expand_exec_shield_cs_limit() {
825 #if defined(IA32)
826   assert(Linux::initial_thread_stack_bottom() != NULL, &quot;sanity&quot;);
827   size_t page_size = os::vm_page_size();
828 
829   /*
830    * JDK-8197429
831    *
832    * Expand the stack mapping to the end of the initial stack before
833    * attempting to install the codebuf.  This is needed because newer
834    * Linux kernels impose a distance of a megabyte between stack
835    * memory and other memory regions.  If we try to install the
836    * codebuf before expanding the stack the installation will appear
837    * to succeed but we&#39;ll get a segfault later if we expand the stack
838    * in Java code.
839    *
840    */
841   if (os::is_primordial_thread()) {
842     address limit = Linux::initial_thread_stack_bottom();
843     if (! DisablePrimordialThreadGuardPages) {
844       limit += JavaThread::stack_red_zone_size() +
845         JavaThread::stack_yellow_zone_size();
846     }
847     os::Linux::expand_stack_to(limit);
848   }
849 
850   /*
851    * Take the highest VA the OS will give us and exec
852    *
853    * Although using -(pagesz) as mmap hint works on newer kernel as you would
854    * think, older variants affected by this work-around don&#39;t (search forward only).
855    *
856    * On the affected distributions, we understand the memory layout to be:
857    *
858    *   TASK_LIMIT= 3G, main stack base close to TASK_LIMT.
859    *
860    * A few pages south main stack will do it.
861    *
862    * If we are embedded in an app other than launcher (initial != main stack),
863    * we don&#39;t have much control or understanding of the address space, just let it slide.
864    */
865   char* hint = (char*)(Linux::initial_thread_stack_bottom() -
866                        (JavaThread::stack_guard_zone_size() + page_size));
867   char* codebuf = os::attempt_reserve_memory_at(page_size, hint);
868 
869   if (codebuf == NULL) {
870     // JDK-8197429: There may be a stack gap of one megabyte between
871     // the limit of the stack and the nearest memory region: this is a
872     // Linux kernel workaround for CVE-2017-1000364.  If we failed to
873     // map our codebuf, try again at an address one megabyte lower.
874     hint -= 1 * M;
875     codebuf = os::attempt_reserve_memory_at(page_size, hint);
876   }
877 
878   if ((codebuf == NULL) || (!os::commit_memory(codebuf, page_size, true))) {
879     return; // No matter, we tried, best effort.
880   }
881 
882   MemTracker::record_virtual_memory_type((address)codebuf, mtInternal);
883 
884   log_info(os)(&quot;[CS limit NX emulation work-around, exec code at: %p]&quot;, codebuf);
885 
886   // Some code to exec: the &#39;ret&#39; instruction
887   codebuf[0] = 0xC3;
888 
889   // Call the code in the codebuf
890   __asm__ volatile(&quot;call *%0&quot; : : &quot;r&quot;(codebuf));
891 
892   // keep the page mapped so CS limit isn&#39;t reduced.
893 #endif
894 }
895 
896 int os::extra_bang_size_in_bytes() {
897   // JDK-8050147 requires the full cache line bang for x86.
898   return VM_Version::L1_line_size();
899 }
<a name="8" id="anc8"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="8" type="hidden" />
</body>
</html>