<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames doc/testing.md</title>
    <link rel="stylesheet" href="../style.css" />
    <script type="text/javascript" src="../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 % Testing the JDK
  2 
  3 ## Using &quot;make test&quot; (the run-test framework)
  4 
  5 This new way of running tests is developer-centric. It assumes that you have
  6 built a JDK locally and want to test it. Running common test targets is simple,
  7 and more complex ad-hoc combination of tests is possible. The user interface is
  8 forgiving, and clearly report errors it cannot resolve.
  9 
 10 The main target `test` uses the jdk-image as the tested product. There is
 11 also an alternate target `exploded-test` that uses the exploded image
 12 instead. Not all tests will run successfully on the exploded image, but using
 13 this target can greatly improve rebuild times for certain workflows.
 14 
 15 Previously, `make test` was used to invoke an old system for running tests, and
 16 `make run-test` was used for the new test framework. For backward compatibility
 17 with scripts and muscle memory, `run-test` (and variants like
 18 `exploded-run-test` or `run-test-tier1`) are kept as aliases.
 19 
 20 Some example command-lines:
 21 
 22     $ make test-tier1
 23     $ make test-jdk_lang JTREG=&quot;JOBS=8&quot;
 24     $ make test TEST=jdk_lang
 25     $ make test-only TEST=&quot;gtest:LogTagSet gtest:LogTagSetDescriptions&quot; GTEST=&quot;REPEAT=-1&quot;
 26     $ make test TEST=&quot;hotspot:hotspot_gc&quot; JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;
 27     $ make test TEST=&quot;jtreg:test/hotspot:hotspot_gc test/hotspot/jtreg/native_sanity/JniVersion.java&quot;
 28     $ make test TEST=&quot;micro:java.lang.reflect&quot; MICRO=&quot;FORK=1;WARMUP_ITER=2&quot;
 29     $ make exploded-test TEST=tier2
 30 
 31 ### Configuration
 32 
 33 To be able to run JTReg tests, `configure` needs to know where to find the
 34 JTReg test framework. If it is not picked up automatically by configure, use
 35 the `--with-jtreg=&lt;path to jtreg home&gt;` option to point to the JTReg framework.
 36 Note that this option should point to the JTReg home, i.e. the top directory,
 37 containing `lib/jtreg.jar` etc. (An alternative is to set the `JT_HOME`
 38 environment variable to point to the JTReg home before running `configure`.)
 39 
<a name="1" id="anc1"></a><span class="line-modified"> 40 To be able to run microbenchmarks, `configure` needs to know where to find the</span>
<span class="line-modified"> 41 JMH dependency. Use `--with-jmh=&lt;path to JMH jars&gt;` to point to a directory</span>
<span class="line-modified"> 42 containing the core JMH and transitive dependencies. The recommended</span>
<span class="line-modified"> 43 dependencies can be retrieved by running `sh make/devkit/createJMHBundle.sh`,</span>
<span class="line-modified"> 44 after which `--with-jmh=build/jmh/jars` should work.</span>
 45 
 46 ## Test selection
 47 
 48 All functionality is available using the `test` make target. In this use case,
 49 the test or tests to be executed is controlled using the `TEST` variable. To
 50 speed up subsequent test runs with no source code changes, `test-only` can be
 51 used instead, which do not depend on the source and test image build.
 52 
 53 For some common top-level tests, direct make targets have been generated. This
 54 includes all JTReg test groups, the hotspot gtest, and custom tests (if
 55 present). This means that `make test-tier1` is equivalent to `make test
 56 TEST=&quot;tier1&quot;`, but the latter is more tab-completion friendly. For more complex
 57 test runs, the `test TEST=&quot;x&quot;` solution needs to be used.
 58 
 59 The test specifications given in `TEST` is parsed into fully qualified test
 60 descriptors, which clearly and unambigously show which tests will be run. As an
 61 example, `:tier1` will expand to `jtreg:$(TOPDIR)/test/hotspot/jtreg:tier1
 62 jtreg:$(TOPDIR)/test/jdk:tier1 jtreg:$(TOPDIR)/test/langtools:tier1
 63 jtreg:$(TOPDIR)/test/nashorn:tier1 jtreg:$(TOPDIR)/test/jaxp:tier1`. You can
 64 always submit a list of fully qualified test descriptors in the `TEST` variable
 65 if you want to shortcut the parser.
 66 
 67 ### JTReg
 68 
 69 JTReg tests can be selected either by picking a JTReg test group, or a selection
 70 of files or directories containing JTReg tests.
 71 
 72 JTReg test groups can be specified either without a test root, e.g. `:tier1`
 73 (or `tier1`, the initial colon is optional), or with, e.g. `hotspot:tier1`,
 74 `test/jdk:jdk_util` or `$(TOPDIR)/test/hotspot/jtreg:hotspot_all`. The test
 75 root can be specified either as an absolute path, or a path relative to the
 76 JDK top directory, or the `test` directory. For simplicity, the hotspot
 77 JTReg test root, which really is `hotspot/jtreg` can be abbreviated as
 78 just `hotspot`.
 79 
 80 When specified without a test root, all matching groups from all test roots
 81 will be added. Otherwise, only the group from the specified test root will be
 82 added.
 83 
 84 Individual JTReg tests or directories containing JTReg tests can also be
 85 specified, like `test/hotspot/jtreg/native_sanity/JniVersion.java` or
 86 `hotspot/jtreg/native_sanity`. Just like for test root selection, you can
 87 either specify an absolute path (which can even point to JTReg tests outside
 88 the source tree), or a path relative to either the JDK top directory or the
 89 `test` directory. `hotspot` can be used as an alias for `hotspot/jtreg` here as
 90 well.
 91 
 92 As long as the test groups or test paths can be uniquely resolved, you do not
 93 need to enter the `jtreg:` prefix. If this is not possible, or if you want to
 94 use a fully qualified test descriptor, add `jtreg:`, e.g.
 95 `jtreg:test/hotspot/jtreg/native_sanity`.
 96 
 97 ### Gtest
 98 
 99 Since the Hotspot Gtest suite is so quick, the default is to run all tests.
100 This is specified by just `gtest`, or as a fully qualified test descriptor
101 `gtest:all`.
102 
103 If you want, you can single out an individual test or a group of tests, for
104 instance `gtest:LogDecorations` or `gtest:LogDecorations.level_test_vm`. This
105 can be particularly useful if you want to run a shaky test repeatedly.
106 
107 For Gtest, there is a separate test suite for each JVM variant. The JVM variant
108 is defined by adding `/&lt;variant&gt;` to the test descriptor, e.g.
109 `gtest:Log/client`. If you specify no variant, gtest will run once for each JVM
110 variant present (e.g. server, client). So if you only have the server JVM
111 present, then `gtest:all` will be equivalent to `gtest:all/server`.
112 
113 ### Microbenchmarks
114 
115 Which microbenchmarks to run is selected using a regular expression
116 following the `micro:` test descriptor, e.g., `micro:java.lang.reflect`. This
117 delegates the test selection to JMH, meaning package name, class name and even
118 benchmark method names can be used to select tests.
119 
120 Using special characters like `|` in the regular expression is possible, but
121 needs to be escaped multiple times: `micro:ArrayCopy\\\\\|reflect`.
122 
123 ### Special tests
124 
125 A handful of odd tests that are not covered by any other testing framework are
126 accessible using the `special:` test descriptor. Currently, this includes
127 `failure-handler` and `make`.
128 
129   * Failure handler testing is run using `special:failure-handler` or just
130     `failure-handler` as test descriptor.
131 
132   * Tests for the build system, including both makefiles and related
133     functionality, is run using `special:make` or just `make` as test
134     descriptor. This is equivalent to `special:make:all`.
135 
136     A specific make test can be run by supplying it as argument, e.g.
137     `special:make:idea`. As a special syntax, this can also be expressed as
138     `make-idea`, which allows for command lines as `make test-make-idea`.
139 
140 ## Test results and summary
141 
142 At the end of the test run, a summary of all tests run will be presented. This
143 will have a consistent look, regardless of what test suites were used. This is
144 a sample summary:
145 
146     ==============================
147     Test summary
148     ==============================
149        TEST                                          TOTAL  PASS  FAIL ERROR
150     &gt;&gt; jtreg:jdk/test:tier1                           1867  1865     2     0 &lt;&lt;
151        jtreg:langtools/test:tier1                     4711  4711     0     0
152        jtreg:nashorn/test:tier1                        133   133     0     0
153     ==============================
154     TEST FAILURE
155 
156 Tests where the number of TOTAL tests does not equal the number of PASSed tests
157 will be considered a test failure. These are marked with the `&gt;&gt; ... &lt;&lt;` marker
158 for easy identification.
159 
160 The classification of non-passed tests differs a bit between test suites. In
161 the summary, ERROR is used as a catch-all for tests that neither passed nor are
162 classified as failed by the framework. This might indicate test framework
163 error, timeout or other problems.
164 
165 In case of test failures, `make test` will exit with a non-zero exit value.
166 
167 All tests have their result stored in `build/$BUILD/test-results/$TEST_ID`,
168 where TEST_ID is a path-safe conversion from the fully qualified test
169 descriptor, e.g. for `jtreg:jdk/test:tier1` the TEST_ID is
170 `jtreg_jdk_test_tier1`. This path is also printed in the log at the end of the
171 test run.
172 
173 Additional work data is stored in `build/$BUILD/test-support/$TEST_ID`. For
174 some frameworks, this directory might contain information that is useful in
175 determining the cause of a failed test.
176 
177 ## Test suite control
178 
179 It is possible to control various aspects of the test suites using make control
180 variables.
181 
182 These variables use a keyword=value approach to allow multiple values to be
183 set. So, for instance, `JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8&quot;` will set the JTReg
184 concurrency level to 1 and the timeout factor to 8. This is equivalent to
<a name="2" id="anc2"></a><span class="line-modified">185 setting `JTREG_JOBS=1 JTREG_TIMEOUT_FACTOR=8`, but using the keyword format</span>
<span class="line-modified">186 means that the `JTREG` variable is parsed and verified for correctness, so</span>
<span class="line-modified">187 `JTREG=&quot;TMIEOUT_FACTOR=8&quot;` would give an error, while `JTREG_TMIEOUT_FACTOR=8`</span>
<span class="line-modified">188 would just pass unnoticed.</span>
189 
190 To separate multiple keyword=value pairs, use `;` (semicolon). Since the shell
191 normally eats `;`, the recommended usage is to write the assignment inside
192 qoutes, e.g. `JTREG=&quot;...;...&quot;`. This will also make sure spaces are preserved,
193 as in `JTREG=&quot;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;`.
194 
195 (Other ways are possible, e.g. using backslash: `JTREG=JOBS=1\;TIMEOUT_FACTOR=8`.
196 Also, as a special technique, the string `%20` will be replaced with space for
197 certain options, e.g. `JTREG=JAVA_OPTIONS=-XshowSettings%20-Xlog:gc+ref=debug`.
198 This can be useful if you have layers of scripts and have trouble getting
199 proper quoting of command line arguments through.)
200 
201 As far as possible, the names of the keywords have been standardized between
202 test suites.
203 
204 ### General keywords (TEST_OPTS)
205 
<a name="3" id="anc3"></a><span class="line-modified">206 Some keywords are valid across different test suites. If you want to run tests</span>
<span class="line-modified">207 from multiple test suites, or just don&#39;t want to care which test suite specific</span>
<span class="line-modified">208 control variable to use, then you can use the general TEST_OPTS control</span>
<span class="line-added">209 variable.</span>
210 
211 There are also some keywords that applies globally to the test runner system,
212 not to any specific test suites. These are also available as TEST_OPTS keywords.
213 
214 #### JOBS
215 
216 Currently only applies to JTReg.
217 
218 #### TIMEOUT_FACTOR
219 
220 Currently only applies to JTReg.
221 
222 #### JAVA_OPTIONS
223 
224 Applies to JTReg, GTest and Micro.
225 
226 #### VM_OPTIONS
227 
228 Applies to JTReg, GTest and Micro.
229 
230 #### AOT_MODULES
231 
232 Applies to JTReg and GTest.
233 
234 #### JCOV
235 
236 This keywords applies globally to the test runner system. If set to `true`, it
237 enables JCov coverage reporting for all tests run. To be useful, the JDK under
238 test must be run with a JDK built with JCov instrumentation (`configure
239 --with-jcov=&lt;path to directory containing lib/jcov.jar&gt;`, `make jcov-image`).
240 
241 The simplest way to run tests with JCov coverage report is to use the special
242 target `jcov-test` instead of `test`, e.g. `make jcov-test TEST=jdk_lang`. This
243 will make sure the JCov image is built, and that JCov reporting is enabled.
244 
245 The JCov report is stored in `build/$BUILD/test-results/jcov-output/report`.
246 
247 Please note that running with JCov reporting can be very memory intensive.
248 
249 #### JCOV_DIFF_CHANGESET
250 
251 While collecting code coverage with JCov, it is also possible to find coverage
252 for only recently changed code. JCOV_DIFF_CHANGESET specifies a source
253 revision. A textual report will be generated showing coverage of the diff
254 between the specified revision and the repository tip.
255 
<a name="4" id="anc4"></a><span class="line-modified">256 The report is stored in</span>
<span class="line-modified">257 `build/$BUILD/test-results/jcov-output/diff_coverage_report` file.</span>
258 
259 ### JTReg keywords
260 
261 #### JOBS
<a name="5" id="anc5"></a><span class="line-added">262 </span>
263 The test concurrency (`-concurrency`).
264 
265 Defaults to TEST_JOBS (if set by `--with-test-jobs=`), otherwise it defaults to
266 JOBS, except for Hotspot, where the default is *number of CPU cores/2*,
267 but never more than *memory size in GB/2*.
268 
269 #### TIMEOUT_FACTOR
<a name="6" id="anc6"></a><span class="line-added">270 </span>
271 The timeout factor (`-timeoutFactor`).
272 
273 Defaults to 4.
274 
<a name="7" id="anc7"></a><span class="line-added">275 #### FAILURE_HANDLER_TIMEOUT</span>
<span class="line-added">276 </span>
<span class="line-added">277 Sets the argument `-timeoutHandlerTimeout` for JTReg. The default value is 0.</span>
<span class="line-added">278 This is only valid if the failure handler is built.</span>
<span class="line-added">279 </span>
280 #### TEST_MODE
<a name="8" id="anc8"></a><span class="line-added">281 </span>
282 The test mode (`agentvm` or `othervm`).
283 
284 Defaults to `agentvm`.
285 
286 #### ASSERT
<a name="9" id="anc9"></a><span class="line-added">287 </span>
288 Enable asserts (`-ea -esa`, or none).
289 
290 Set to `true` or `false`. If true, adds `-ea -esa`. Defaults to true, except
291 for hotspot.
292 
293 #### VERBOSE
<a name="10" id="anc10"></a><span class="line-added">294 </span>
295 The verbosity level (`-verbose`).
296 
297 Defaults to `fail,error,summary`.
298 
299 #### RETAIN
<a name="11" id="anc11"></a><span class="line-added">300 </span>
301 What test data to retain (`-retain`).
302 
303 Defaults to `fail,error`.
304 
305 #### MAX_MEM
<a name="12" id="anc12"></a><span class="line-added">306 </span>
307 Limit memory consumption (`-Xmx` and `-vmoption:-Xmx`, or none).
308 
309 Limit memory consumption for JTReg test framework and VM under test. Set to 0
310 to disable the limits.
311 
312 Defaults to 512m, except for hotspot, where it defaults to 0 (no limit).
313 
<a name="13" id="anc13"></a><span class="line-added">314 #### MAX_OUTPUT</span>
<span class="line-added">315 </span>
<span class="line-added">316 Set the property `javatest.maxOutputSize` for the launcher, to change the</span>
<span class="line-added">317 default JTReg log limit.</span>
<span class="line-added">318 </span>
319 #### KEYWORDS
320 
<a name="14" id="anc14"></a><span class="line-modified">321 JTReg keywords sent to JTReg using `-k`. Please be careful in making sure that</span>
322 spaces and special characters (like `!`) are properly quoted. To avoid some
323 issues, the special value `%20` can be used instead of space.
324 
325 #### EXTRA_PROBLEM_LISTS
326 
327 Use additional problem lists file or files, in addition to the default
328 ProblemList.txt located at the JTReg test roots.
329 
330 If multiple file names are specified, they should be separated by space (or, to
331 help avoid quoting issues, the special value `%20`).
332 
333 The file names should be either absolute, or relative to the JTReg test root of
334 the tests to be run.
335 
336 #### RUN_PROBLEM_LISTS
337 
338 Use the problem lists to select tests instead of excluding them.
339 
340 Set to `true` or `false`.
341 If `true`, JTReg will use `-match:` option, otherwise `-exclude:` will be used.
342 Default is `false`.
343 
<a name="15" id="anc15"></a>
344 #### OPTIONS
<a name="16" id="anc16"></a><span class="line-added">345 </span>
346 Additional options to the JTReg test framework.
347 
348 Use `JTREG=&quot;OPTIONS=--help all&quot;` to see all available JTReg options.
349 
350 #### JAVA_OPTIONS
<a name="17" id="anc17"></a><span class="line-added">351 </span>
352 Additional Java options for running test classes (sent to JTReg as
353 `-javaoption`).
354 
355 #### VM_OPTIONS
<a name="18" id="anc18"></a><span class="line-added">356 </span>
357 Additional Java options to be used when compiling and running classes (sent to
358 JTReg as `-vmoption`).
359 
360 This option is only needed in special circumstances. To pass Java options to
361 your test classes, use `JAVA_OPTIONS`.
362 
<a name="19" id="anc19"></a><span class="line-added">363 #### LAUNCHER_OPTIONS</span>
<span class="line-added">364 </span>
<span class="line-added">365 Additional Java options that are sent to the java launcher that starts the</span>
<span class="line-added">366 JTReg harness.</span>
<span class="line-added">367 </span>
368 #### AOT_MODULES
369 
370 Generate AOT modules before testing for the specified module, or set of
371 modules. If multiple modules are specified, they should be separated by space
372 (or, to help avoid quoting issues, the special value `%20`).
373 
374 #### RETRY_COUNT
375 
376 Retry failed tests up to a set number of times. Defaults to 0.
377 
378 ### Gtest keywords
379 
380 #### REPEAT
<a name="20" id="anc20"></a><span class="line-added">381 </span>
382 The number of times to repeat the tests (`--gtest_repeat`).
383 
384 Default is 1. Set to -1 to repeat indefinitely. This can be especially useful
385 combined with `OPTIONS=--gtest_break_on_failure` to reproduce an intermittent
386 problem.
387 
388 #### OPTIONS
<a name="21" id="anc21"></a><span class="line-added">389 </span>
390 Additional options to the Gtest test framework.
391 
392 Use `GTEST=&quot;OPTIONS=--help&quot;` to see all available Gtest options.
393 
394 #### AOT_MODULES
395 
396 Generate AOT modules before testing for the specified module, or set of
397 modules. If multiple modules are specified, they should be separated by space
398 (or, to help avoid quoting issues, the special value `%20`).
399 
400 ### Microbenchmark keywords
401 
402 #### FORK
<a name="22" id="anc22"></a><span class="line-added">403 </span>
404 Override the number of benchmark forks to spawn. Same as specifying `-f &lt;num&gt;`.
405 
406 #### ITER
<a name="23" id="anc23"></a><span class="line-added">407 </span>
408 Number of measurement iterations per fork. Same as specifying `-i &lt;num&gt;`.
409 
410 #### TIME
<a name="24" id="anc24"></a><span class="line-added">411 </span>
412 Amount of time to spend in each measurement iteration, in seconds. Same as
413 specifying `-r &lt;num&gt;`
414 
415 #### WARMUP_ITER
<a name="25" id="anc25"></a><span class="line-added">416 </span>
417 Number of warmup iterations to run before the measurement phase in each fork.
418 Same as specifying `-wi &lt;num&gt;`.
419 
420 #### WARMUP_TIME
<a name="26" id="anc26"></a><span class="line-added">421 </span>
422 Amount of time to spend in each warmup iteration. Same as specifying `-w &lt;num&gt;`.
423 
424 #### RESULTS_FORMAT
<a name="27" id="anc27"></a><span class="line-added">425 </span>
426 Specify to have the test run save a log of the values. Accepts the same values
427 as `-rff`, i.e., `text`, `csv`, `scsv`, `json`, or `latex`.
428 
429 #### VM_OPTIONS
<a name="28" id="anc28"></a><span class="line-added">430 </span>
431 Additional VM arguments to provide to forked off VMs. Same as `-jvmArgs &lt;args&gt;`
432 
433 #### OPTIONS
<a name="29" id="anc29"></a><span class="line-added">434 </span>
435 Additional arguments to send to JMH.
436 
437 ## Notes for Specific Tests
438 
439 ### Docker Tests
440 
<a name="30" id="anc30"></a><span class="line-modified">441 Docker tests with default parameters may fail on systems with glibc versions</span>
<span class="line-modified">442 not compatible with the one used in the default docker image (e.g., Oracle</span>
<span class="line-modified">443 Linux 7.6 for x86). For example, they pass on Ubuntu 16.04 but fail on Ubuntu</span>
<span class="line-added">444 18.04 if run like this on x86:</span>
445 
<a name="31" id="anc31"></a><span class="line-modified">446 ```</span>
<span class="line-added">447 $ make test TEST=&quot;jtreg:test/hotspot/jtreg/containers/docker&quot;</span>
<span class="line-added">448 ```</span>
449 
<a name="32" id="anc32"></a><span class="line-modified">450 To run these tests correctly, additional parameters for the correct docker</span>
<span class="line-modified">451 image are required on Ubuntu 18.04 by using `JAVA_OPTIONS`.</span>
452 
<a name="33" id="anc33"></a><span class="line-modified">453 ```</span>
<span class="line-added">454 $ make test TEST=&quot;jtreg:test/hotspot/jtreg/containers/docker&quot; \</span>
<span class="line-added">455     JTREG=&quot;JAVA_OPTIONS=-Djdk.test.docker.image.name=ubuntu</span>
<span class="line-added">456     -Djdk.test.docker.image.version=latest&quot;</span>
<span class="line-added">457 ```</span>
458 
459 ### Non-US locale
460 
<a name="34" id="anc34"></a><span class="line-modified">461 If your locale is non-US, some tests are likely to fail. To work around this</span>
<span class="line-modified">462 you can set the locale to US. On Unix platforms simply setting `LANG=&quot;en_US&quot;`</span>
<span class="line-modified">463 in the environment before running tests should work. On Windows, setting</span>
<span class="line-modified">464 `JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot;` helps for most, but</span>
<span class="line-added">465 not all test cases.</span>
<span class="line-added">466 </span>
467 For example:
468 
<a name="35" id="anc35"></a><span class="line-modified">469 ```</span>
<span class="line-modified">470 $ export LANG=&quot;en_US&quot; &amp;&amp; make test TEST=...</span>
<span class="line-added">471 $ make test JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot; TEST=...</span>
<span class="line-added">472 ```</span>
473 
474 ### PKCS11 Tests
475 
<a name="36" id="anc36"></a><span class="line-modified">476 It is highly recommended to use the latest NSS version when running PKCS11</span>
<span class="line-modified">477 tests. Improper NSS version may lead to unexpected failures which are hard to</span>
<span class="line-modified">478 diagnose. For example, sun/security/pkcs11/Secmod/AddTrustedCert.java may fail</span>
<span class="line-modified">479 on Ubuntu 18.04 with the default NSS version in the system. To run these tests</span>
<span class="line-modified">480 correctly, the system property `test.nss.lib.paths` is required on Ubuntu 18.04</span>
<span class="line-modified">481 to specify the alternative NSS lib directories.</span>
<span class="line-added">482 </span>
483 For example:
484 
<a name="37" id="anc37"></a><span class="line-modified">485 ```</span>
<span class="line-added">486 $ make test TEST=&quot;jtreg:sun/security/pkcs11/Secmod/AddTrustedCert.java&quot; \</span>
<span class="line-added">487     JTREG=&quot;JAVA_OPTIONS=-Dtest.nss.lib.paths=/path/to/your/latest/NSS-libs&quot;</span>
<span class="line-added">488 ```</span>
489 
<a name="38" id="anc38"></a><span class="line-modified">490 For more notes about the PKCS11 tests, please refer to</span>
<span class="line-added">491 test/jdk/sun/security/pkcs11/README.</span>
492 
493 ### Client UI Tests
494 
495 Some Client UI tests use key sequences which may be reserved by the operating
<a name="39" id="anc39"></a><span class="line-modified">496 system. Usually that causes the test failure. So it is highly recommended to</span>
<span class="line-modified">497 disable system key shortcuts prior testing. The steps to access and disable</span>
<span class="line-modified">498 system key shortcuts for various platforms are provided below.</span>
499 
500 #### MacOS
<a name="40" id="anc40"></a><span class="line-added">501 </span>
502 Choose Apple menu; System Preferences, click Keyboard, then click Shortcuts;
503 select or deselect desired shortcut.
504 
<a name="41" id="anc41"></a><span class="line-modified">505 For example,</span>
<span class="line-modified">506 test/jdk/javax/swing/TooltipManager/JMenuItemToolTipKeyBindingsTest/JMenuItemToolTipKeyBindingsTest.java</span>
<span class="line-modified">507 fails on MacOS because it uses `CTRL + F1` key sequence to show or hide tooltip</span>
<span class="line-modified">508 message but the key combination is reserved by the operating system. To run the</span>
<span class="line-modified">509 test correctly the default global key shortcut should be disabled using the</span>
<span class="line-added">510 steps described above, and then deselect &quot;Turn keyboard access on or off&quot;</span>
<span class="line-added">511 option which is responsible for `CTRL + F1` combination.</span>
512 
513 #### Linux
<a name="42" id="anc42"></a><span class="line-modified">514 </span>
<span class="line-modified">515 Open the Activities overview and start typing Settings; Choose Settings, click</span>
<span class="line-added">516 Devices, then click Keyboard; set or override desired shortcut.</span>
517 
518 #### Windows
<a name="43" id="anc43"></a><span class="line-modified">519 </span>
<span class="line-modified">520 Type `gpedit` in the Search and then click Edit group policy; navigate to User</span>
<span class="line-modified">521 Configuration -&gt; Administrative Templates -&gt; Windows Components -&gt; File</span>
<span class="line-modified">522 Explorer; in the right-side pane look for &quot;Turn off Windows key hotkeys&quot; and</span>
<span class="line-added">523 double click on it; enable or disable hotkeys.</span>
524 
525 Note: restart is required to make the settings take effect.
526 
527 ---
528 # Override some definitions in the global css file that are not optimal for
529 # this document.
530 header-includes:
531  - &#39;&lt;style type=&quot;text/css&quot;&gt;pre, code, tt { color: #1d6ae5; }&lt;/style&gt;&#39;
532 ---
<a name="44" id="anc44"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="44" type="hidden" />
</body>
</html>