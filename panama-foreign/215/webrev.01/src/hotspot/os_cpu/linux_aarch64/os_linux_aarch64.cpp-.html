<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/os_cpu/linux_aarch64/os_linux_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 // no precompiled headers
 27 #include &quot;jvm.h&quot;
 28 #include &quot;asm/macroAssembler.hpp&quot;
 29 #include &quot;classfile/classLoader.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;classfile/vmSymbols.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;code/icBuffer.hpp&quot;
 34 #include &quot;code/vtableStubs.hpp&quot;
 35 #include &quot;code/nativeInst.hpp&quot;
 36 #include &quot;interpreter/interpreter.hpp&quot;
 37 #include &quot;memory/allocation.inline.hpp&quot;
 38 #include &quot;os_share_linux.hpp&quot;
 39 #include &quot;prims/jniFastGetField.hpp&quot;
 40 #include &quot;prims/jvm_misc.hpp&quot;
 41 #include &quot;runtime/arguments.hpp&quot;
 42 #include &quot;runtime/extendedPC.hpp&quot;
 43 #include &quot;runtime/frame.inline.hpp&quot;
 44 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 45 #include &quot;runtime/java.hpp&quot;
 46 #include &quot;runtime/javaCalls.hpp&quot;
 47 #include &quot;runtime/mutexLocker.hpp&quot;
 48 #include &quot;runtime/osThread.hpp&quot;
 49 #include &quot;runtime/safepointMechanism.hpp&quot;
 50 #include &quot;runtime/sharedRuntime.hpp&quot;
 51 #include &quot;runtime/stubRoutines.hpp&quot;
 52 #include &quot;runtime/thread.inline.hpp&quot;
 53 #include &quot;runtime/timer.hpp&quot;
 54 #include &quot;utilities/debug.hpp&quot;
 55 #include &quot;utilities/events.hpp&quot;
 56 #include &quot;utilities/vmError.hpp&quot;
 57 
 58 // put OS-includes here
 59 # include &lt;sys/types.h&gt;
 60 # include &lt;sys/mman.h&gt;
 61 # include &lt;pthread.h&gt;
 62 # include &lt;signal.h&gt;
 63 # include &lt;errno.h&gt;
 64 # include &lt;dlfcn.h&gt;
 65 # include &lt;stdlib.h&gt;
 66 # include &lt;stdio.h&gt;
 67 # include &lt;unistd.h&gt;
 68 # include &lt;sys/resource.h&gt;
 69 # include &lt;pthread.h&gt;
 70 # include &lt;sys/stat.h&gt;
 71 # include &lt;sys/time.h&gt;
 72 # include &lt;sys/utsname.h&gt;
 73 # include &lt;sys/socket.h&gt;
 74 # include &lt;sys/wait.h&gt;
 75 # include &lt;pwd.h&gt;
 76 # include &lt;poll.h&gt;
 77 # include &lt;ucontext.h&gt;
 78 # include &lt;fpu_control.h&gt;
 79 
 80 #define REG_FP 29
 81 #define REG_LR 30
 82 
 83 NOINLINE address os::current_stack_pointer() {
 84   return (address)__builtin_frame_address(0);
 85 }
 86 
 87 char* os::non_memory_address_word() {
 88   // Must never look like an address returned by reserve_memory,
 89   // even in its subfields (as defined by the CPU immediate fields,
 90   // if the CPU splits constants across multiple instructions).
 91 
 92   return (char*) 0xffffffffffff;
 93 }
 94 
 95 address os::Linux::ucontext_get_pc(const ucontext_t * uc) {
 96   return (address)uc-&gt;uc_mcontext.pc;
 97 }
 98 
 99 void os::Linux::ucontext_set_pc(ucontext_t * uc, address pc) {
100   uc-&gt;uc_mcontext.pc = (intptr_t)pc;
101 }
102 
103 intptr_t* os::Linux::ucontext_get_sp(const ucontext_t * uc) {
104   return (intptr_t*)uc-&gt;uc_mcontext.sp;
105 }
106 
107 intptr_t* os::Linux::ucontext_get_fp(const ucontext_t * uc) {
108   return (intptr_t*)uc-&gt;uc_mcontext.regs[REG_FP];
109 }
110 
111 // For Forte Analyzer AsyncGetCallTrace profiling support - thread
112 // is currently interrupted by SIGPROF.
113 // os::Solaris::fetch_frame_from_ucontext() tries to skip nested signal
114 // frames. Currently we don&#39;t do that on Linux, so it&#39;s the same as
115 // os::fetch_frame_from_context().
116 ExtendedPC os::Linux::fetch_frame_from_ucontext(Thread* thread,
117   const ucontext_t* uc, intptr_t** ret_sp, intptr_t** ret_fp) {
118 
119   assert(thread != NULL, &quot;just checking&quot;);
120   assert(ret_sp != NULL, &quot;just checking&quot;);
121   assert(ret_fp != NULL, &quot;just checking&quot;);
122 
123   return os::fetch_frame_from_context(uc, ret_sp, ret_fp);
124 }
125 
126 ExtendedPC os::fetch_frame_from_context(const void* ucVoid,
127                     intptr_t** ret_sp, intptr_t** ret_fp) {
128 
129   ExtendedPC  epc;
130   const ucontext_t* uc = (const ucontext_t*)ucVoid;
131 
132   if (uc != NULL) {
133     epc = ExtendedPC(os::Linux::ucontext_get_pc(uc));
134     if (ret_sp) *ret_sp = os::Linux::ucontext_get_sp(uc);
135     if (ret_fp) *ret_fp = os::Linux::ucontext_get_fp(uc);
136   } else {
137     // construct empty ExtendedPC for return value checking
138     epc = ExtendedPC(NULL);
139     if (ret_sp) *ret_sp = (intptr_t *)NULL;
140     if (ret_fp) *ret_fp = (intptr_t *)NULL;
141   }
142 
143   return epc;
144 }
145 
146 frame os::fetch_frame_from_context(const void* ucVoid) {
147   intptr_t* sp;
148   intptr_t* fp;
149   ExtendedPC epc = fetch_frame_from_context(ucVoid, &amp;sp, &amp;fp);
150   return frame(sp, fp, epc.pc());
151 }
152 
153 bool os::Linux::get_frame_at_stack_banging_point(JavaThread* thread, ucontext_t* uc, frame* fr) {
154   address pc = (address) os::Linux::ucontext_get_pc(uc);
155   if (Interpreter::contains(pc)) {
156     // interpreter performs stack banging after the fixed frame header has
157     // been generated while the compilers perform it before. To maintain
158     // semantic consistency between interpreted and compiled frames, the
159     // method returns the Java sender of the current frame.
160     *fr = os::fetch_frame_from_context(uc);
161     if (!fr-&gt;is_first_java_frame()) {
162       assert(fr-&gt;safe_for_sender(thread), &quot;Safety check&quot;);
163       *fr = fr-&gt;java_sender();
164     }
165   } else {
166     // more complex code with compiled code
167     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);
168     CodeBlob* cb = CodeCache::find_blob(pc);
169     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {
170       // Not sure where the pc points to, fallback to default
171       // stack overflow handling
172       return false;
173     } else {
174       // In compiled code, the stack banging is performed before LR
175       // has been saved in the frame.  LR is live, and SP and FP
176       // belong to the caller.
177       intptr_t* fp = os::Linux::ucontext_get_fp(uc);
178       intptr_t* sp = os::Linux::ucontext_get_sp(uc);
179       address pc = (address)(uc-&gt;uc_mcontext.regs[REG_LR]
180                          - NativeInstruction::instruction_size);
181       *fr = frame(sp, fp, pc);
182       if (!fr-&gt;is_java_frame()) {
183         assert(fr-&gt;safe_for_sender(thread), &quot;Safety check&quot;);
184         assert(!fr-&gt;is_first_frame(), &quot;Safety check&quot;);
185         *fr = fr-&gt;java_sender();
186       }
187     }
188   }
189   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);
190   return true;
191 }
192 
193 // By default, gcc always saves frame pointer rfp on this stack. This
194 // may get turned off by -fomit-frame-pointer.
195 frame os::get_sender_for_C_frame(frame* fr) {
196   return frame(fr-&gt;link(), fr-&gt;link(), fr-&gt;sender_pc());
197 }
198 
199 NOINLINE frame os::current_frame() {
200   intptr_t *fp = *(intptr_t **)__builtin_frame_address(0);
201   frame myframe((intptr_t*)os::current_stack_pointer(),
202                 (intptr_t*)fp,
203                 CAST_FROM_FN_PTR(address, os::current_frame));
204   if (os::is_first_C_frame(&amp;myframe)) {
205     // stack is not walkable
206     return frame();
207   } else {
208     return os::get_sender_for_C_frame(&amp;myframe);
209   }
210 }
211 
212 extern &quot;C&quot; JNIEXPORT int
213 JVM_handle_linux_signal(int sig,
214                         siginfo_t* info,
215                         void* ucVoid,
216                         int abort_if_unrecognized) {
217   ucontext_t* uc = (ucontext_t*) ucVoid;
218 
219   Thread* t = Thread::current_or_null_safe();
220 
221   // Must do this before SignalHandlerMark, if crash protection installed we will longjmp away
222   // (no destructors can be run)
223   os::ThreadCrashProtection::check_crash_protection(sig, t);
224 
225   SignalHandlerMark shm(t);
226 
227   // Note: it&#39;s not uncommon that JNI code uses signal/sigset to install
228   // then restore certain signal handler (e.g. to temporarily block SIGPIPE,
229   // or have a SIGILL handler when detecting CPU type). When that happens,
230   // JVM_handle_linux_signal() might be invoked with junk info/ucVoid. To
231   // avoid unnecessary crash when libjsig is not preloaded, try handle signals
232   // that do not require siginfo/ucontext first.
233 
234   if (sig == SIGPIPE || sig == SIGXFSZ) {
235     // allow chained handler to go first
236     if (os::Linux::chained_handler(sig, info, ucVoid)) {
237       return true;
238     } else {
239       // Ignoring SIGPIPE/SIGXFSZ - see bugs 4229104 or 6499219
240       return true;
241     }
242   }
243 
244 #ifdef CAN_SHOW_REGISTERS_ON_ASSERT
245   if ((sig == SIGSEGV || sig == SIGBUS) &amp;&amp; info != NULL &amp;&amp; info-&gt;si_addr == g_assert_poison) {
246     if (handle_assert_poison_fault(ucVoid, info-&gt;si_addr)) {
247       return 1;
248     }
249   }
250 #endif
251 
252   JavaThread* thread = NULL;
253   VMThread* vmthread = NULL;
254   if (os::Linux::signal_handlers_are_installed) {
255     if (t != NULL ){
256       if(t-&gt;is_Java_thread()) {
257         thread = (JavaThread*)t;
258       }
259       else if(t-&gt;is_VM_thread()){
260         vmthread = (VMThread *)t;
261       }
262     }
263   }
264 /*
265   NOTE: does not seem to work on linux.
266   if (info == NULL || info-&gt;si_code &lt;= 0 || info-&gt;si_code == SI_NOINFO) {
267     // can&#39;t decode this kind of signal
268     info = NULL;
269   } else {
270     assert(sig == info-&gt;si_signo, &quot;bad siginfo&quot;);
271   }
272 */
273   // decide if this trap can be handled by a stub
274   address stub = NULL;
275 
276   address pc          = NULL;
277 
278   //%note os_trap_1
279   if (info != NULL &amp;&amp; uc != NULL &amp;&amp; thread != NULL) {
280     pc = (address) os::Linux::ucontext_get_pc(uc);
281 
282     if (StubRoutines::is_safefetch_fault(pc)) {
283       os::Linux::ucontext_set_pc(uc, StubRoutines::continuation_for_safefetch_fault(pc));
284       return 1;
285     }
286 
287     address addr = (address) info-&gt;si_addr;
288 
289     // Make sure the high order byte is sign extended, as it may be masked away by the hardware.
290     if ((uintptr_t(addr) &amp; (uintptr_t(1) &lt;&lt; 55)) != 0) {
291       addr = address(uintptr_t(addr) | (uintptr_t(0xFF) &lt;&lt; 56));
292     }
293 
294     // Handle ALL stack overflow variations here
295     if (sig == SIGSEGV) {
296       // check if fault address is within thread stack
297       if (thread-&gt;is_in_full_stack(addr)) {
298         // stack overflow
299         if (thread-&gt;in_stack_yellow_reserved_zone(addr)) {
300           if (thread-&gt;thread_state() == _thread_in_Java) {
301             if (thread-&gt;in_stack_reserved_zone(addr)) {
302               frame fr;
303               if (os::Linux::get_frame_at_stack_banging_point(thread, uc, &amp;fr)) {
304                 assert(fr.is_java_frame(), &quot;Must be a Java frame&quot;);
305                 frame activation =
306                   SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);
307                 if (activation.sp() != NULL) {
308                   thread-&gt;disable_stack_reserved_zone();
309                   if (activation.is_interpreted_frame()) {
310                     thread-&gt;set_reserved_stack_activation((address)(
311                       activation.fp() + frame::interpreter_frame_initial_sp_offset));
312                   } else {
313                     thread-&gt;set_reserved_stack_activation((address)activation.unextended_sp());
314                   }
315                   return 1;
316                 }
317               }
318             }
319             // Throw a stack overflow exception.  Guard pages will be reenabled
320             // while unwinding the stack.
321             thread-&gt;disable_stack_yellow_reserved_zone();
322             stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);
323           } else {
324             // Thread was in the vm or native code.  Return and try to finish.
325             thread-&gt;disable_stack_yellow_reserved_zone();
326             return 1;
327           }
328         } else if (thread-&gt;in_stack_red_zone(addr)) {
329           // Fatal red zone violation.  Disable the guard pages and fall through
330           // to handle_unexpected_exception way down below.
331           thread-&gt;disable_stack_red_zone();
332           tty-&gt;print_raw_cr(&quot;An irrecoverable stack overflow has occurred.&quot;);
333 
334           // This is a likely cause, but hard to verify. Let&#39;s just print
335           // it as a hint.
336           tty-&gt;print_raw_cr(&quot;Please check if any of your loaded .so files has &quot;
337                             &quot;enabled executable stack (see man page execstack(8))&quot;);
338         } else {
339           // Accessing stack address below sp may cause SEGV if current
340           // thread has MAP_GROWSDOWN stack. This should only happen when
341           // current thread was created by user code with MAP_GROWSDOWN flag
342           // and then attached to VM. See notes in os_linux.cpp.
343           if (thread-&gt;osthread()-&gt;expanding_stack() == 0) {
344              thread-&gt;osthread()-&gt;set_expanding_stack();
345              if (os::Linux::manually_expand_stack(thread, addr)) {
346                thread-&gt;osthread()-&gt;clear_expanding_stack();
347                return 1;
348              }
349              thread-&gt;osthread()-&gt;clear_expanding_stack();
350           } else {
351              fatal(&quot;recursive segv. expanding stack.&quot;);
352           }
353         }
354       }
355     }
356 
357     if (thread-&gt;thread_state() == _thread_in_Java) {
358       // Java thread running in Java code =&gt; find exception handler if any
359       // a fault inside compiled code, the interpreter, or a stub
360 
361       // Handle signal from NativeJump::patch_verified_entry().
362       if ((sig == SIGILL || sig == SIGTRAP)
363           &amp;&amp; nativeInstruction_at(pc)-&gt;is_sigill_zombie_not_entrant()) {
364         if (TraceTraps) {
365           tty-&gt;print_cr(&quot;trap: zombie_not_entrant (%s)&quot;, (sig == SIGTRAP) ? &quot;SIGTRAP&quot; : &quot;SIGILL&quot;);
366         }
367         stub = SharedRuntime::get_handle_wrong_method_stub();
368       } else if (sig == SIGSEGV &amp;&amp; SafepointMechanism::is_poll_address((address)info-&gt;si_addr)) {
369         stub = SharedRuntime::get_poll_stub(pc);
370       } else if (sig == SIGBUS /* &amp;&amp; info-&gt;si_code == BUS_OBJERR */) {
371         // BugId 4454115: A read from a MappedByteBuffer can fault
372         // here if the underlying file has been truncated.
373         // Do not crash the VM in such a case.
374         CodeBlob* cb = CodeCache::find_blob_unsafe(pc);
375         CompiledMethod* nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
376         bool is_unsafe_arraycopy = (thread-&gt;doing_unsafe_access() &amp;&amp; UnsafeCopyMemory::contains_pc(pc));
377         if ((nm != NULL &amp;&amp; nm-&gt;has_unsafe_access()) || is_unsafe_arraycopy) {
378           address next_pc = pc + NativeCall::instruction_size;
379           if (is_unsafe_arraycopy) {
380             next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
381           }
382           stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
383         }
384       } else if (sig == SIGILL &amp;&amp; nativeInstruction_at(pc)-&gt;is_stop()) {
385         // Pull a pointer to the error message out of the instruction
386         // stream.
387         const uint64_t *detail_msg_ptr
388           = (uint64_t*)(pc + NativeInstruction::instruction_size);
389         const char *detail_msg = (const char *)*detail_msg_ptr;
390         const char *msg = &quot;stop&quot;;
391         if (TraceTraps) {
392           tty-&gt;print_cr(&quot;trap: %s: (SIGILL)&quot;, msg);
393         }
394 
395         va_list detail_args;
396         VMError::report_and_die(INTERNAL_ERROR, msg, detail_msg, detail_args, thread,
397                                 pc, info, ucVoid, NULL, 0, 0);
398         va_end(detail_args);
399       }
400       else
401 
402       if (sig == SIGFPE  &amp;&amp;
403           (info-&gt;si_code == FPE_INTDIV || info-&gt;si_code == FPE_FLTDIV)) {
404         stub =
405           SharedRuntime::
406           continuation_for_implicit_exception(thread,
407                                               pc,
408                                               SharedRuntime::
409                                               IMPLICIT_DIVIDE_BY_ZERO);
410       } else if (sig == SIGSEGV &amp;&amp;
411                  MacroAssembler::uses_implicit_null_check((void*)addr)) {
412           // Determination of interpreter/vtable stub/compiled code null exception
413           stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);
414       }
415     } else if ((thread-&gt;thread_state() == _thread_in_vm ||
416                  thread-&gt;thread_state() == _thread_in_native) &amp;&amp;
417                sig == SIGBUS &amp;&amp; /* info-&gt;si_code == BUS_OBJERR &amp;&amp; */
418                thread-&gt;doing_unsafe_access()) {
419       address next_pc = pc + NativeCall::instruction_size;
420       if (UnsafeCopyMemory::contains_pc(pc)) {
421         next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
422       }
423       stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
424     }
425 
426     // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks in
427     // and the heap gets shrunk before the field access.
428     if ((sig == SIGSEGV) || (sig == SIGBUS)) {
429       address addr = JNI_FastGetField::find_slowcase_pc(pc);
430       if (addr != (address)-1) {
431         stub = addr;
432       }
433     }
434   }
435 
436   if (stub != NULL) {
437     // save all thread context in case we need to restore it
438     if (thread != NULL) thread-&gt;set_saved_exception_pc(pc);
439 
440     os::Linux::ucontext_set_pc(uc, stub);
441     return true;
442   }
443 
444   // signal-chaining
445   if (os::Linux::chained_handler(sig, info, ucVoid)) {
446      return true;
447   }
448 
449   if (!abort_if_unrecognized) {
450     // caller wants another chance, so give it to him
451     return false;
452   }
453 
454   if (pc == NULL &amp;&amp; uc != NULL) {
455     pc = os::Linux::ucontext_get_pc(uc);
456   }
457 
458   // unmask current signal
459   sigset_t newset;
460   sigemptyset(&amp;newset);
461   sigaddset(&amp;newset, sig);
462   sigprocmask(SIG_UNBLOCK, &amp;newset, NULL);
463 
464   VMError::report_and_die(t, sig, pc, info, ucVoid);
465 
466   ShouldNotReachHere();
467   return true; // Mute compiler
468 }
469 
470 void os::Linux::init_thread_fpu_state(void) {
471 }
472 
473 int os::Linux::get_fpu_control_word(void) {
474   return 0;
475 }
476 
477 void os::Linux::set_fpu_control_word(int fpu_control) {
478 }
479 
480 bool os::is_allocatable(size_t bytes) {
481   return true;
482 }
483 
484 ////////////////////////////////////////////////////////////////////////////////
485 // thread stack
486 
487 // Minimum usable stack sizes required to get to user code. Space for
488 // HotSpot guard pages is added later.
489 size_t os::Posix::_compiler_thread_min_stack_allowed = 72 * K;
490 size_t os::Posix::_java_thread_min_stack_allowed = 72 * K;
491 size_t os::Posix::_vm_internal_thread_min_stack_allowed = 72 * K;
492 
493 // return default stack size for thr_type
494 size_t os::Posix::default_stack_size(os::ThreadType thr_type) {
495   // default stack size (compiler thread needs larger stack)
496   size_t s = (thr_type == os::compiler_thread ? 4 * M : 1 * M);
497   return s;
498 }
499 
500 /////////////////////////////////////////////////////////////////////////////
501 // helper functions for fatal error handler
502 
503 void os::print_context(outputStream *st, const void *context) {
504   if (context == NULL) return;
505 
506   const ucontext_t *uc = (const ucontext_t*)context;
507   st-&gt;print_cr(&quot;Registers:&quot;);
508   for (int r = 0; r &lt; 31; r++) {
509     st-&gt;print(&quot;R%-2d=&quot;, r);
510     print_location(st, uc-&gt;uc_mcontext.regs[r]);
511   }
512   st-&gt;cr();
513 
514   intptr_t *sp = (intptr_t *)os::Linux::ucontext_get_sp(uc);
515   st-&gt;print_cr(&quot;Top of Stack: (sp=&quot; PTR_FORMAT &quot;)&quot;, p2i(sp));
516   print_hex_dump(st, (address)sp, (address)(sp + 8*sizeof(intptr_t)), sizeof(intptr_t));
517   st-&gt;cr();
518 
519   // Note: it may be unsafe to inspect memory near pc. For example, pc may
520   // point to garbage if entry point in an nmethod is corrupted. Leave
521   // this at the end, and hope for the best.
522   address pc = os::Linux::ucontext_get_pc(uc);
523   print_instructions(st, pc, 4/*native instruction size*/);
524   st-&gt;cr();
525 }
526 
527 void os::print_register_info(outputStream *st, const void *context) {
528   if (context == NULL) return;
529 
530   const ucontext_t *uc = (const ucontext_t*)context;
531 
532   st-&gt;print_cr(&quot;Register to memory mapping:&quot;);
533   st-&gt;cr();
534 
535   // this is horrendously verbose but the layout of the registers in the
536   // context does not match how we defined our abstract Register set, so
537   // we can&#39;t just iterate through the gregs area
538 
539   // this is only for the &quot;general purpose&quot; registers
540 
541   for (int r = 0; r &lt; 31; r++)
542     st-&gt;print_cr(  &quot;R%d=&quot; INTPTR_FORMAT, r, (uintptr_t)uc-&gt;uc_mcontext.regs[r]);
543   st-&gt;cr();
544 }
545 
546 void os::setup_fpu() {
547 }
548 
549 #ifndef PRODUCT
550 void os::verify_stack_alignment() {
551   assert(((intptr_t)os::current_stack_pointer() &amp; (StackAlignmentInBytes-1)) == 0, &quot;incorrect stack alignment&quot;);
552 }
553 #endif
554 
555 int os::extra_bang_size_in_bytes() {
556   // AArch64 does not require the additional stack bang.
557   return 0;
558 }
559 
560 extern &quot;C&quot; {
561   int SpinPause() {
562     return 0;
563   }
564 
565   void _Copy_conjoint_jshorts_atomic(const jshort* from, jshort* to, size_t count) {
566     if (from &gt; to) {
567       const jshort *end = from + count;
568       while (from &lt; end)
569         *(to++) = *(from++);
570     }
571     else if (from &lt; to) {
572       const jshort *end = from;
573       from += count - 1;
574       to   += count - 1;
575       while (from &gt;= end)
576         *(to--) = *(from--);
577     }
578   }
579   void _Copy_conjoint_jints_atomic(const jint* from, jint* to, size_t count) {
580     if (from &gt; to) {
581       const jint *end = from + count;
582       while (from &lt; end)
583         *(to++) = *(from++);
584     }
585     else if (from &lt; to) {
586       const jint *end = from;
587       from += count - 1;
588       to   += count - 1;
589       while (from &gt;= end)
590         *(to--) = *(from--);
591     }
592   }
593   void _Copy_conjoint_jlongs_atomic(const jlong* from, jlong* to, size_t count) {
594     if (from &gt; to) {
595       const jlong *end = from + count;
596       while (from &lt; end)
597         os::atomic_copy64(from++, to++);
598     }
599     else if (from &lt; to) {
600       const jlong *end = from;
601       from += count - 1;
602       to   += count - 1;
603       while (from &gt;= end)
604         os::atomic_copy64(from--, to--);
605     }
606   }
607 
608   void _Copy_arrayof_conjoint_bytes(const HeapWord* from,
609                                     HeapWord* to,
610                                     size_t    count) {
611     memmove(to, from, count);
612   }
613   void _Copy_arrayof_conjoint_jshorts(const HeapWord* from,
614                                       HeapWord* to,
615                                       size_t    count) {
616     memmove(to, from, count * 2);
617   }
618   void _Copy_arrayof_conjoint_jints(const HeapWord* from,
619                                     HeapWord* to,
620                                     size_t    count) {
621     memmove(to, from, count * 4);
622   }
623   void _Copy_arrayof_conjoint_jlongs(const HeapWord* from,
624                                      HeapWord* to,
625                                      size_t    count) {
626     memmove(to, from, count * 8);
627   }
628 };
    </pre>
  </body>
</html>