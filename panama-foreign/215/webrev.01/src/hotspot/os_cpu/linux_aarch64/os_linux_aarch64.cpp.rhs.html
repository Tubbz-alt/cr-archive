<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/os_cpu/linux_aarch64/os_linux_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 // no precompiled headers
 27 #include &quot;jvm.h&quot;
 28 #include &quot;asm/macroAssembler.hpp&quot;
 29 #include &quot;classfile/classLoader.hpp&quot;
 30 #include &quot;classfile/systemDictionary.hpp&quot;
 31 #include &quot;classfile/vmSymbols.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;code/icBuffer.hpp&quot;
 34 #include &quot;code/vtableStubs.hpp&quot;
 35 #include &quot;code/nativeInst.hpp&quot;
 36 #include &quot;interpreter/interpreter.hpp&quot;
 37 #include &quot;memory/allocation.inline.hpp&quot;
 38 #include &quot;os_share_linux.hpp&quot;
 39 #include &quot;prims/jniFastGetField.hpp&quot;
 40 #include &quot;prims/jvm_misc.hpp&quot;
 41 #include &quot;runtime/arguments.hpp&quot;
<a name="1" id="anc1"></a>
 42 #include &quot;runtime/frame.inline.hpp&quot;
 43 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 44 #include &quot;runtime/java.hpp&quot;
 45 #include &quot;runtime/javaCalls.hpp&quot;
 46 #include &quot;runtime/mutexLocker.hpp&quot;
 47 #include &quot;runtime/osThread.hpp&quot;
 48 #include &quot;runtime/safepointMechanism.hpp&quot;
 49 #include &quot;runtime/sharedRuntime.hpp&quot;
 50 #include &quot;runtime/stubRoutines.hpp&quot;
 51 #include &quot;runtime/thread.inline.hpp&quot;
 52 #include &quot;runtime/timer.hpp&quot;
 53 #include &quot;utilities/debug.hpp&quot;
 54 #include &quot;utilities/events.hpp&quot;
 55 #include &quot;utilities/vmError.hpp&quot;
 56 
 57 // put OS-includes here
 58 # include &lt;sys/types.h&gt;
 59 # include &lt;sys/mman.h&gt;
 60 # include &lt;pthread.h&gt;
 61 # include &lt;signal.h&gt;
 62 # include &lt;errno.h&gt;
 63 # include &lt;dlfcn.h&gt;
 64 # include &lt;stdlib.h&gt;
 65 # include &lt;stdio.h&gt;
 66 # include &lt;unistd.h&gt;
 67 # include &lt;sys/resource.h&gt;
 68 # include &lt;pthread.h&gt;
 69 # include &lt;sys/stat.h&gt;
 70 # include &lt;sys/time.h&gt;
 71 # include &lt;sys/utsname.h&gt;
 72 # include &lt;sys/socket.h&gt;
 73 # include &lt;sys/wait.h&gt;
 74 # include &lt;pwd.h&gt;
 75 # include &lt;poll.h&gt;
 76 # include &lt;ucontext.h&gt;
 77 # include &lt;fpu_control.h&gt;
 78 
 79 #define REG_FP 29
 80 #define REG_LR 30
 81 
 82 NOINLINE address os::current_stack_pointer() {
 83   return (address)__builtin_frame_address(0);
 84 }
 85 
 86 char* os::non_memory_address_word() {
 87   // Must never look like an address returned by reserve_memory,
 88   // even in its subfields (as defined by the CPU immediate fields,
 89   // if the CPU splits constants across multiple instructions).
 90 
 91   return (char*) 0xffffffffffff;
 92 }
 93 
 94 address os::Linux::ucontext_get_pc(const ucontext_t * uc) {
 95   return (address)uc-&gt;uc_mcontext.pc;
 96 }
 97 
 98 void os::Linux::ucontext_set_pc(ucontext_t * uc, address pc) {
 99   uc-&gt;uc_mcontext.pc = (intptr_t)pc;
100 }
101 
102 intptr_t* os::Linux::ucontext_get_sp(const ucontext_t * uc) {
103   return (intptr_t*)uc-&gt;uc_mcontext.sp;
104 }
105 
106 intptr_t* os::Linux::ucontext_get_fp(const ucontext_t * uc) {
107   return (intptr_t*)uc-&gt;uc_mcontext.regs[REG_FP];
108 }
109 
<a name="2" id="anc2"></a><span class="line-modified">110 address os::fetch_frame_from_context(const void* ucVoid,</span>















111                     intptr_t** ret_sp, intptr_t** ret_fp) {
112 
<a name="3" id="anc3"></a><span class="line-modified">113   address epc;</span>
114   const ucontext_t* uc = (const ucontext_t*)ucVoid;
115 
116   if (uc != NULL) {
<a name="4" id="anc4"></a><span class="line-modified">117     epc = os::Linux::ucontext_get_pc(uc);</span>
118     if (ret_sp) *ret_sp = os::Linux::ucontext_get_sp(uc);
119     if (ret_fp) *ret_fp = os::Linux::ucontext_get_fp(uc);
120   } else {
<a name="5" id="anc5"></a><span class="line-modified">121     epc = NULL;</span>

122     if (ret_sp) *ret_sp = (intptr_t *)NULL;
123     if (ret_fp) *ret_fp = (intptr_t *)NULL;
124   }
125 
126   return epc;
127 }
128 
129 frame os::fetch_frame_from_context(const void* ucVoid) {
130   intptr_t* sp;
131   intptr_t* fp;
<a name="6" id="anc6"></a><span class="line-modified">132   address epc = fetch_frame_from_context(ucVoid, &amp;sp, &amp;fp);</span>
<span class="line-modified">133   return frame(sp, fp, epc);</span>
134 }
135 
136 bool os::Linux::get_frame_at_stack_banging_point(JavaThread* thread, ucontext_t* uc, frame* fr) {
137   address pc = (address) os::Linux::ucontext_get_pc(uc);
138   if (Interpreter::contains(pc)) {
139     // interpreter performs stack banging after the fixed frame header has
140     // been generated while the compilers perform it before. To maintain
141     // semantic consistency between interpreted and compiled frames, the
142     // method returns the Java sender of the current frame.
143     *fr = os::fetch_frame_from_context(uc);
144     if (!fr-&gt;is_first_java_frame()) {
145       assert(fr-&gt;safe_for_sender(thread), &quot;Safety check&quot;);
146       *fr = fr-&gt;java_sender();
147     }
148   } else {
149     // more complex code with compiled code
150     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);
151     CodeBlob* cb = CodeCache::find_blob(pc);
152     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {
153       // Not sure where the pc points to, fallback to default
154       // stack overflow handling
155       return false;
156     } else {
157       // In compiled code, the stack banging is performed before LR
158       // has been saved in the frame.  LR is live, and SP and FP
159       // belong to the caller.
160       intptr_t* fp = os::Linux::ucontext_get_fp(uc);
161       intptr_t* sp = os::Linux::ucontext_get_sp(uc);
162       address pc = (address)(uc-&gt;uc_mcontext.regs[REG_LR]
163                          - NativeInstruction::instruction_size);
164       *fr = frame(sp, fp, pc);
165       if (!fr-&gt;is_java_frame()) {
166         assert(fr-&gt;safe_for_sender(thread), &quot;Safety check&quot;);
167         assert(!fr-&gt;is_first_frame(), &quot;Safety check&quot;);
168         *fr = fr-&gt;java_sender();
169       }
170     }
171   }
172   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);
173   return true;
174 }
175 
176 // By default, gcc always saves frame pointer rfp on this stack. This
177 // may get turned off by -fomit-frame-pointer.
178 frame os::get_sender_for_C_frame(frame* fr) {
179   return frame(fr-&gt;link(), fr-&gt;link(), fr-&gt;sender_pc());
180 }
181 
182 NOINLINE frame os::current_frame() {
183   intptr_t *fp = *(intptr_t **)__builtin_frame_address(0);
184   frame myframe((intptr_t*)os::current_stack_pointer(),
185                 (intptr_t*)fp,
186                 CAST_FROM_FN_PTR(address, os::current_frame));
187   if (os::is_first_C_frame(&amp;myframe)) {
188     // stack is not walkable
189     return frame();
190   } else {
191     return os::get_sender_for_C_frame(&amp;myframe);
192   }
193 }
194 
195 extern &quot;C&quot; JNIEXPORT int
196 JVM_handle_linux_signal(int sig,
197                         siginfo_t* info,
198                         void* ucVoid,
199                         int abort_if_unrecognized) {
200   ucontext_t* uc = (ucontext_t*) ucVoid;
201 
202   Thread* t = Thread::current_or_null_safe();
203 
204   // Must do this before SignalHandlerMark, if crash protection installed we will longjmp away
205   // (no destructors can be run)
206   os::ThreadCrashProtection::check_crash_protection(sig, t);
207 
208   SignalHandlerMark shm(t);
209 
210   // Note: it&#39;s not uncommon that JNI code uses signal/sigset to install
211   // then restore certain signal handler (e.g. to temporarily block SIGPIPE,
212   // or have a SIGILL handler when detecting CPU type). When that happens,
213   // JVM_handle_linux_signal() might be invoked with junk info/ucVoid. To
214   // avoid unnecessary crash when libjsig is not preloaded, try handle signals
215   // that do not require siginfo/ucontext first.
216 
217   if (sig == SIGPIPE || sig == SIGXFSZ) {
218     // allow chained handler to go first
219     if (os::Linux::chained_handler(sig, info, ucVoid)) {
220       return true;
221     } else {
222       // Ignoring SIGPIPE/SIGXFSZ - see bugs 4229104 or 6499219
223       return true;
224     }
225   }
226 
227 #ifdef CAN_SHOW_REGISTERS_ON_ASSERT
228   if ((sig == SIGSEGV || sig == SIGBUS) &amp;&amp; info != NULL &amp;&amp; info-&gt;si_addr == g_assert_poison) {
229     if (handle_assert_poison_fault(ucVoid, info-&gt;si_addr)) {
230       return 1;
231     }
232   }
233 #endif
234 
235   JavaThread* thread = NULL;
236   VMThread* vmthread = NULL;
237   if (os::Linux::signal_handlers_are_installed) {
238     if (t != NULL ){
239       if(t-&gt;is_Java_thread()) {
240         thread = (JavaThread*)t;
241       }
242       else if(t-&gt;is_VM_thread()){
243         vmthread = (VMThread *)t;
244       }
245     }
246   }
247 /*
248   NOTE: does not seem to work on linux.
249   if (info == NULL || info-&gt;si_code &lt;= 0 || info-&gt;si_code == SI_NOINFO) {
250     // can&#39;t decode this kind of signal
251     info = NULL;
252   } else {
253     assert(sig == info-&gt;si_signo, &quot;bad siginfo&quot;);
254   }
255 */
256   // decide if this trap can be handled by a stub
257   address stub = NULL;
258 
259   address pc          = NULL;
260 
261   //%note os_trap_1
262   if (info != NULL &amp;&amp; uc != NULL &amp;&amp; thread != NULL) {
263     pc = (address) os::Linux::ucontext_get_pc(uc);
264 
265     if (StubRoutines::is_safefetch_fault(pc)) {
266       os::Linux::ucontext_set_pc(uc, StubRoutines::continuation_for_safefetch_fault(pc));
267       return 1;
268     }
269 
270     address addr = (address) info-&gt;si_addr;
271 
272     // Make sure the high order byte is sign extended, as it may be masked away by the hardware.
273     if ((uintptr_t(addr) &amp; (uintptr_t(1) &lt;&lt; 55)) != 0) {
274       addr = address(uintptr_t(addr) | (uintptr_t(0xFF) &lt;&lt; 56));
275     }
276 
277     // Handle ALL stack overflow variations here
278     if (sig == SIGSEGV) {
279       // check if fault address is within thread stack
280       if (thread-&gt;is_in_full_stack(addr)) {
281         // stack overflow
282         if (thread-&gt;in_stack_yellow_reserved_zone(addr)) {
283           if (thread-&gt;thread_state() == _thread_in_Java) {
284             if (thread-&gt;in_stack_reserved_zone(addr)) {
285               frame fr;
286               if (os::Linux::get_frame_at_stack_banging_point(thread, uc, &amp;fr)) {
287                 assert(fr.is_java_frame(), &quot;Must be a Java frame&quot;);
288                 frame activation =
289                   SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);
290                 if (activation.sp() != NULL) {
291                   thread-&gt;disable_stack_reserved_zone();
292                   if (activation.is_interpreted_frame()) {
293                     thread-&gt;set_reserved_stack_activation((address)(
294                       activation.fp() + frame::interpreter_frame_initial_sp_offset));
295                   } else {
296                     thread-&gt;set_reserved_stack_activation((address)activation.unextended_sp());
297                   }
298                   return 1;
299                 }
300               }
301             }
302             // Throw a stack overflow exception.  Guard pages will be reenabled
303             // while unwinding the stack.
304             thread-&gt;disable_stack_yellow_reserved_zone();
305             stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW);
306           } else {
307             // Thread was in the vm or native code.  Return and try to finish.
308             thread-&gt;disable_stack_yellow_reserved_zone();
309             return 1;
310           }
311         } else if (thread-&gt;in_stack_red_zone(addr)) {
312           // Fatal red zone violation.  Disable the guard pages and fall through
313           // to handle_unexpected_exception way down below.
314           thread-&gt;disable_stack_red_zone();
315           tty-&gt;print_raw_cr(&quot;An irrecoverable stack overflow has occurred.&quot;);
316 
317           // This is a likely cause, but hard to verify. Let&#39;s just print
318           // it as a hint.
319           tty-&gt;print_raw_cr(&quot;Please check if any of your loaded .so files has &quot;
320                             &quot;enabled executable stack (see man page execstack(8))&quot;);
321         } else {
322           // Accessing stack address below sp may cause SEGV if current
323           // thread has MAP_GROWSDOWN stack. This should only happen when
324           // current thread was created by user code with MAP_GROWSDOWN flag
325           // and then attached to VM. See notes in os_linux.cpp.
326           if (thread-&gt;osthread()-&gt;expanding_stack() == 0) {
327              thread-&gt;osthread()-&gt;set_expanding_stack();
328              if (os::Linux::manually_expand_stack(thread, addr)) {
329                thread-&gt;osthread()-&gt;clear_expanding_stack();
330                return 1;
331              }
332              thread-&gt;osthread()-&gt;clear_expanding_stack();
333           } else {
334              fatal(&quot;recursive segv. expanding stack.&quot;);
335           }
336         }
337       }
338     }
339 
340     if (thread-&gt;thread_state() == _thread_in_Java) {
341       // Java thread running in Java code =&gt; find exception handler if any
342       // a fault inside compiled code, the interpreter, or a stub
343 
344       // Handle signal from NativeJump::patch_verified_entry().
345       if ((sig == SIGILL || sig == SIGTRAP)
346           &amp;&amp; nativeInstruction_at(pc)-&gt;is_sigill_zombie_not_entrant()) {
347         if (TraceTraps) {
348           tty-&gt;print_cr(&quot;trap: zombie_not_entrant (%s)&quot;, (sig == SIGTRAP) ? &quot;SIGTRAP&quot; : &quot;SIGILL&quot;);
349         }
350         stub = SharedRuntime::get_handle_wrong_method_stub();
351       } else if (sig == SIGSEGV &amp;&amp; SafepointMechanism::is_poll_address((address)info-&gt;si_addr)) {
352         stub = SharedRuntime::get_poll_stub(pc);
353       } else if (sig == SIGBUS /* &amp;&amp; info-&gt;si_code == BUS_OBJERR */) {
354         // BugId 4454115: A read from a MappedByteBuffer can fault
355         // here if the underlying file has been truncated.
356         // Do not crash the VM in such a case.
357         CodeBlob* cb = CodeCache::find_blob_unsafe(pc);
358         CompiledMethod* nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
359         bool is_unsafe_arraycopy = (thread-&gt;doing_unsafe_access() &amp;&amp; UnsafeCopyMemory::contains_pc(pc));
360         if ((nm != NULL &amp;&amp; nm-&gt;has_unsafe_access()) || is_unsafe_arraycopy) {
361           address next_pc = pc + NativeCall::instruction_size;
362           if (is_unsafe_arraycopy) {
363             next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
364           }
365           stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
366         }
367       } else if (sig == SIGILL &amp;&amp; nativeInstruction_at(pc)-&gt;is_stop()) {
368         // Pull a pointer to the error message out of the instruction
369         // stream.
370         const uint64_t *detail_msg_ptr
371           = (uint64_t*)(pc + NativeInstruction::instruction_size);
372         const char *detail_msg = (const char *)*detail_msg_ptr;
373         const char *msg = &quot;stop&quot;;
374         if (TraceTraps) {
375           tty-&gt;print_cr(&quot;trap: %s: (SIGILL)&quot;, msg);
376         }
377 
378         va_list detail_args;
379         VMError::report_and_die(INTERNAL_ERROR, msg, detail_msg, detail_args, thread,
380                                 pc, info, ucVoid, NULL, 0, 0);
381         va_end(detail_args);
382       }
383       else
384 
385       if (sig == SIGFPE  &amp;&amp;
386           (info-&gt;si_code == FPE_INTDIV || info-&gt;si_code == FPE_FLTDIV)) {
387         stub =
388           SharedRuntime::
389           continuation_for_implicit_exception(thread,
390                                               pc,
391                                               SharedRuntime::
392                                               IMPLICIT_DIVIDE_BY_ZERO);
393       } else if (sig == SIGSEGV &amp;&amp;
394                  MacroAssembler::uses_implicit_null_check((void*)addr)) {
395           // Determination of interpreter/vtable stub/compiled code null exception
396           stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);
397       }
398     } else if ((thread-&gt;thread_state() == _thread_in_vm ||
399                  thread-&gt;thread_state() == _thread_in_native) &amp;&amp;
400                sig == SIGBUS &amp;&amp; /* info-&gt;si_code == BUS_OBJERR &amp;&amp; */
401                thread-&gt;doing_unsafe_access()) {
402       address next_pc = pc + NativeCall::instruction_size;
403       if (UnsafeCopyMemory::contains_pc(pc)) {
404         next_pc = UnsafeCopyMemory::page_error_continue_pc(pc);
405       }
406       stub = SharedRuntime::handle_unsafe_access(thread, next_pc);
407     }
408 
409     // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks in
410     // and the heap gets shrunk before the field access.
411     if ((sig == SIGSEGV) || (sig == SIGBUS)) {
412       address addr = JNI_FastGetField::find_slowcase_pc(pc);
413       if (addr != (address)-1) {
414         stub = addr;
415       }
416     }
417   }
418 
419   if (stub != NULL) {
420     // save all thread context in case we need to restore it
421     if (thread != NULL) thread-&gt;set_saved_exception_pc(pc);
422 
423     os::Linux::ucontext_set_pc(uc, stub);
424     return true;
425   }
426 
427   // signal-chaining
428   if (os::Linux::chained_handler(sig, info, ucVoid)) {
429      return true;
430   }
431 
432   if (!abort_if_unrecognized) {
433     // caller wants another chance, so give it to him
434     return false;
435   }
436 
437   if (pc == NULL &amp;&amp; uc != NULL) {
438     pc = os::Linux::ucontext_get_pc(uc);
439   }
440 
441   // unmask current signal
442   sigset_t newset;
443   sigemptyset(&amp;newset);
444   sigaddset(&amp;newset, sig);
445   sigprocmask(SIG_UNBLOCK, &amp;newset, NULL);
446 
447   VMError::report_and_die(t, sig, pc, info, ucVoid);
448 
449   ShouldNotReachHere();
450   return true; // Mute compiler
451 }
452 
453 void os::Linux::init_thread_fpu_state(void) {
454 }
455 
456 int os::Linux::get_fpu_control_word(void) {
457   return 0;
458 }
459 
460 void os::Linux::set_fpu_control_word(int fpu_control) {
461 }
462 
463 bool os::is_allocatable(size_t bytes) {
464   return true;
465 }
466 
467 ////////////////////////////////////////////////////////////////////////////////
468 // thread stack
469 
470 // Minimum usable stack sizes required to get to user code. Space for
471 // HotSpot guard pages is added later.
472 size_t os::Posix::_compiler_thread_min_stack_allowed = 72 * K;
473 size_t os::Posix::_java_thread_min_stack_allowed = 72 * K;
474 size_t os::Posix::_vm_internal_thread_min_stack_allowed = 72 * K;
475 
476 // return default stack size for thr_type
477 size_t os::Posix::default_stack_size(os::ThreadType thr_type) {
478   // default stack size (compiler thread needs larger stack)
479   size_t s = (thr_type == os::compiler_thread ? 4 * M : 1 * M);
480   return s;
481 }
482 
483 /////////////////////////////////////////////////////////////////////////////
484 // helper functions for fatal error handler
485 
486 void os::print_context(outputStream *st, const void *context) {
487   if (context == NULL) return;
488 
489   const ucontext_t *uc = (const ucontext_t*)context;
490   st-&gt;print_cr(&quot;Registers:&quot;);
491   for (int r = 0; r &lt; 31; r++) {
492     st-&gt;print(&quot;R%-2d=&quot;, r);
493     print_location(st, uc-&gt;uc_mcontext.regs[r]);
494   }
495   st-&gt;cr();
496 
497   intptr_t *sp = (intptr_t *)os::Linux::ucontext_get_sp(uc);
498   st-&gt;print_cr(&quot;Top of Stack: (sp=&quot; PTR_FORMAT &quot;)&quot;, p2i(sp));
499   print_hex_dump(st, (address)sp, (address)(sp + 8*sizeof(intptr_t)), sizeof(intptr_t));
500   st-&gt;cr();
501 
502   // Note: it may be unsafe to inspect memory near pc. For example, pc may
503   // point to garbage if entry point in an nmethod is corrupted. Leave
504   // this at the end, and hope for the best.
505   address pc = os::Linux::ucontext_get_pc(uc);
506   print_instructions(st, pc, 4/*native instruction size*/);
507   st-&gt;cr();
508 }
509 
510 void os::print_register_info(outputStream *st, const void *context) {
511   if (context == NULL) return;
512 
513   const ucontext_t *uc = (const ucontext_t*)context;
514 
515   st-&gt;print_cr(&quot;Register to memory mapping:&quot;);
516   st-&gt;cr();
517 
518   // this is horrendously verbose but the layout of the registers in the
519   // context does not match how we defined our abstract Register set, so
520   // we can&#39;t just iterate through the gregs area
521 
522   // this is only for the &quot;general purpose&quot; registers
523 
524   for (int r = 0; r &lt; 31; r++)
525     st-&gt;print_cr(  &quot;R%d=&quot; INTPTR_FORMAT, r, (uintptr_t)uc-&gt;uc_mcontext.regs[r]);
526   st-&gt;cr();
527 }
528 
529 void os::setup_fpu() {
530 }
531 
532 #ifndef PRODUCT
533 void os::verify_stack_alignment() {
534   assert(((intptr_t)os::current_stack_pointer() &amp; (StackAlignmentInBytes-1)) == 0, &quot;incorrect stack alignment&quot;);
535 }
536 #endif
537 
538 int os::extra_bang_size_in_bytes() {
539   // AArch64 does not require the additional stack bang.
540   return 0;
541 }
542 
543 extern &quot;C&quot; {
544   int SpinPause() {
545     return 0;
546   }
547 
548   void _Copy_conjoint_jshorts_atomic(const jshort* from, jshort* to, size_t count) {
549     if (from &gt; to) {
550       const jshort *end = from + count;
551       while (from &lt; end)
552         *(to++) = *(from++);
553     }
554     else if (from &lt; to) {
555       const jshort *end = from;
556       from += count - 1;
557       to   += count - 1;
558       while (from &gt;= end)
559         *(to--) = *(from--);
560     }
561   }
562   void _Copy_conjoint_jints_atomic(const jint* from, jint* to, size_t count) {
563     if (from &gt; to) {
564       const jint *end = from + count;
565       while (from &lt; end)
566         *(to++) = *(from++);
567     }
568     else if (from &lt; to) {
569       const jint *end = from;
570       from += count - 1;
571       to   += count - 1;
572       while (from &gt;= end)
573         *(to--) = *(from--);
574     }
575   }
576   void _Copy_conjoint_jlongs_atomic(const jlong* from, jlong* to, size_t count) {
577     if (from &gt; to) {
578       const jlong *end = from + count;
579       while (from &lt; end)
580         os::atomic_copy64(from++, to++);
581     }
582     else if (from &lt; to) {
583       const jlong *end = from;
584       from += count - 1;
585       to   += count - 1;
586       while (from &gt;= end)
587         os::atomic_copy64(from--, to--);
588     }
589   }
590 
591   void _Copy_arrayof_conjoint_bytes(const HeapWord* from,
592                                     HeapWord* to,
593                                     size_t    count) {
594     memmove(to, from, count);
595   }
596   void _Copy_arrayof_conjoint_jshorts(const HeapWord* from,
597                                       HeapWord* to,
598                                       size_t    count) {
599     memmove(to, from, count * 2);
600   }
601   void _Copy_arrayof_conjoint_jints(const HeapWord* from,
602                                     HeapWord* to,
603                                     size_t    count) {
604     memmove(to, from, count * 4);
605   }
606   void _Copy_arrayof_conjoint_jlongs(const HeapWord* from,
607                                      HeapWord* to,
608                                      size_t    count) {
609     memmove(to, from, count * 8);
610   }
611 };
<a name="7" id="anc7"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="7" type="hidden" />
</body>
</html>