<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/os/linux/os_linux.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef OS_LINUX_OS_LINUX_HPP
 26 #define OS_LINUX_OS_LINUX_HPP
 27 
 28 // Linux_OS defines the interface to Linux operating systems
 29 
 30 // Information about the protection of the page at address &#39;0&#39; on this os.
 31 static bool zero_page_read_protected() { return true; }
 32 
 33 class Linux {
 34   friend class CgroupSubsystem;
 35   friend class os;
 36   friend class OSContainer;
 37   friend class TestReserveMemorySpecial;
 38 
 39   static bool libjsig_is_loaded;        // libjsig that interposes sigaction(),
 40                                         // __sigaction(), signal() is loaded
 41   static struct sigaction *(*get_signal_action)(int);
 42 
 43   static void check_signal_handler(int sig);
 44 
 45   static int (*_pthread_getcpuclockid)(pthread_t, clockid_t *);
 46   static int (*_pthread_setname_np)(pthread_t, const char*);
 47 
 48   static address   _initial_thread_stack_bottom;
 49   static uintptr_t _initial_thread_stack_size;
 50 
 51   static const char *_glibc_version;
 52   static const char *_libpthread_version;
 53 
 54   static bool _supports_fast_thread_cpu_time;
 55 
 56   static GrowableArray&lt;int&gt;* _cpu_to_node;
 57   static GrowableArray&lt;int&gt;* _nindex_to_node;
 58 
 59   static size_t _default_large_page_size;
 60 
 61  protected:
 62 
 63   static julong _physical_memory;
 64   static pthread_t _main_thread;
 65   static int _page_size;
 66 
 67   static julong available_memory();
 68   static julong physical_memory() { return _physical_memory; }
 69   static void set_physical_memory(julong phys_mem) { _physical_memory = phys_mem; }
 70   static int active_processor_count();
 71 
 72   static void initialize_system_info();
 73 
 74   static int commit_memory_impl(char* addr, size_t bytes, bool exec);
 75   static int commit_memory_impl(char* addr, size_t bytes,
 76                                 size_t alignment_hint, bool exec);
 77 
 78   static void set_glibc_version(const char *s)      { _glibc_version = s; }
 79   static void set_libpthread_version(const char *s) { _libpthread_version = s; }
 80 
 81   static void rebuild_cpu_to_node_map();
 82   static void rebuild_nindex_to_node_map();
 83   static GrowableArray&lt;int&gt;* cpu_to_node()    { return _cpu_to_node; }
 84   static GrowableArray&lt;int&gt;* nindex_to_node()  { return _nindex_to_node; }
 85 
 86   static size_t default_large_page_size();
 87   static size_t find_default_large_page_size();
 88   static size_t find_large_page_size(size_t page_size);
 89   static size_t setup_large_page_size();
 90 
 91   static bool setup_large_page_type(size_t page_size);
 92   static bool transparent_huge_pages_sanity_check(bool warn, size_t pages_size);
 93   static bool hugetlbfs_sanity_check(bool warn, size_t page_size);
 94 
 95   static char* reserve_memory_special_shm(size_t bytes, size_t alignment, char* req_addr, bool exec);
 96   static char* reserve_memory_special_huge_tlbfs(size_t bytes, size_t alignment, char* req_addr, bool exec);
 97   static char* reserve_memory_special_huge_tlbfs_only(size_t bytes, char* req_addr, bool exec);
 98   static char* reserve_memory_special_huge_tlbfs_mixed(size_t bytes, size_t alignment, char* req_addr, bool exec);
 99 
100   static bool release_memory_special_impl(char* base, size_t bytes);
101   static bool release_memory_special_shm(char* base, size_t bytes);
102   static bool release_memory_special_huge_tlbfs(char* base, size_t bytes);
103 
104   static void print_full_memory_info(outputStream* st);
105   static bool print_container_info(outputStream* st);
106   static void print_steal_info(outputStream* st);
107   static void print_distro_info(outputStream* st);
108   static void print_libversion_info(outputStream* st);
109   static void print_proc_sys_info(outputStream* st);
110   static bool print_ld_preload_file(outputStream* st);
111   static void print_uptime_info(outputStream* st);
112 
113  public:
114   struct CPUPerfTicks {
115     uint64_t used;
116     uint64_t usedKernel;
117     uint64_t total;
118     uint64_t steal;
119     bool     has_steal_ticks;
120   };
121 
122   // which_logical_cpu=-1 returns accumulated ticks for all cpus.
123   static bool get_tick_information(CPUPerfTicks* pticks, int which_logical_cpu);
124   static bool _stack_is_executable;
125   static void *dlopen_helper(const char *name, char *ebuf, int ebuflen);
126   static void *dll_load_in_vmthread(const char *name, char *ebuf, int ebuflen);
127 
128   static void init_thread_fpu_state();
129   static int  get_fpu_control_word();
130   static void set_fpu_control_word(int fpu_control);
131   static pthread_t main_thread(void)                                { return _main_thread; }
132   // returns kernel thread id (similar to LWP id on Solaris), which can be
133   // used to access /proc
134   static pid_t gettid();
135   static void hotspot_sigmask(Thread* thread);
136 
137   static address   initial_thread_stack_bottom(void)                { return _initial_thread_stack_bottom; }
138   static uintptr_t initial_thread_stack_size(void)                  { return _initial_thread_stack_size; }
139 
140   static int page_size(void)                                        { return _page_size; }
141   static void set_page_size(int val)                                { _page_size = val; }
142 
143   static address   ucontext_get_pc(const ucontext_t* uc);
144   static void ucontext_set_pc(ucontext_t* uc, address pc);
145   static intptr_t* ucontext_get_sp(const ucontext_t* uc);
146   static intptr_t* ucontext_get_fp(const ucontext_t* uc);
147 
148   // For Analyzer Forte AsyncGetCallTrace profiling support:
149   //
150   // This interface should be declared in os_linux_i486.hpp, but
151   // that file provides extensions to the os class and not the
152   // Linux class.
153   static ExtendedPC fetch_frame_from_ucontext(Thread* thread, const ucontext_t* uc,
154                                               intptr_t** ret_sp, intptr_t** ret_fp);
155 
156   static bool get_frame_at_stack_banging_point(JavaThread* thread, ucontext_t* uc, frame* fr);
157 
158   // This boolean allows users to forward their own non-matching signals
159   // to JVM_handle_linux_signal, harmlessly.
160   static bool signal_handlers_are_installed;
161 
162   static int get_our_sigflags(int);
163   static void set_our_sigflags(int, int);
164   static void signal_sets_init();
165   static void install_signal_handlers();
166   static void set_signal_handler(int, bool);
167 
168   static sigset_t* unblocked_signals();
169   static sigset_t* vm_signals();
170 
171   // For signal-chaining
172   static struct sigaction *get_chained_signal_action(int sig);
173   static bool chained_handler(int sig, siginfo_t* siginfo, void* context);
174 
175   // GNU libc and libpthread version strings
176   static const char *glibc_version()          { return _glibc_version; }
177   static const char *libpthread_version()     { return _libpthread_version; }
178 
179   static void libpthread_init();
180   static void sched_getcpu_init();
181   static bool libnuma_init();
182   static void* libnuma_dlsym(void* handle, const char* name);
183   // libnuma v2 (libnuma_1.2) symbols
184   static void* libnuma_v2_dlsym(void* handle, const char* name);
185 
186   // Return default guard size for the specified thread type
187   static size_t default_guard_size(os::ThreadType thr_type);
188 
189   static void capture_initial_stack(size_t max_size);
190 
191   // Stack overflow handling
192   static bool manually_expand_stack(JavaThread * t, address addr);
193 
194   // fast POSIX clocks support
195   static void fast_thread_clock_init(void);
196 
197   static int pthread_getcpuclockid(pthread_t tid, clockid_t *clock_id) {
198     return _pthread_getcpuclockid ? _pthread_getcpuclockid(tid, clock_id) : -1;
199   }
200 
201   static bool supports_fast_thread_cpu_time() {
202     return _supports_fast_thread_cpu_time;
203   }
204 
205   static jlong fast_thread_cpu_time(clockid_t clockid);
206 
207   // Stack repair handling
208 
209   // none present
210 
211  private:
212   static void numa_init();
213   static void expand_stack_to(address bottom);
214 
215   typedef int (*sched_getcpu_func_t)(void);
216   typedef int (*numa_node_to_cpus_func_t)(int node, unsigned long *buffer, int bufferlen);
217   typedef int (*numa_max_node_func_t)(void);
218   typedef int (*numa_num_configured_nodes_func_t)(void);
219   typedef int (*numa_available_func_t)(void);
220   typedef int (*numa_tonode_memory_func_t)(void *start, size_t size, int node);
221   typedef void (*numa_interleave_memory_func_t)(void *start, size_t size, unsigned long *nodemask);
222   typedef void (*numa_interleave_memory_v2_func_t)(void *start, size_t size, struct bitmask* mask);
223   typedef struct bitmask* (*numa_get_membind_func_t)(void);
224   typedef struct bitmask* (*numa_get_interleave_mask_func_t)(void);
225   typedef long (*numa_move_pages_func_t)(int pid, unsigned long count, void **pages, const int *nodes, int *status, int flags);
226   typedef void (*numa_set_preferred_func_t)(int node);
227   typedef void (*numa_set_bind_policy_func_t)(int policy);
228   typedef int (*numa_bitmask_isbitset_func_t)(struct bitmask *bmp, unsigned int n);
229   typedef int (*numa_distance_func_t)(int node1, int node2);
230 
231   static sched_getcpu_func_t _sched_getcpu;
232   static numa_node_to_cpus_func_t _numa_node_to_cpus;
233   static numa_max_node_func_t _numa_max_node;
234   static numa_num_configured_nodes_func_t _numa_num_configured_nodes;
235   static numa_available_func_t _numa_available;
236   static numa_tonode_memory_func_t _numa_tonode_memory;
237   static numa_interleave_memory_func_t _numa_interleave_memory;
238   static numa_interleave_memory_v2_func_t _numa_interleave_memory_v2;
239   static numa_set_bind_policy_func_t _numa_set_bind_policy;
240   static numa_bitmask_isbitset_func_t _numa_bitmask_isbitset;
241   static numa_distance_func_t _numa_distance;
242   static numa_get_membind_func_t _numa_get_membind;
243   static numa_get_interleave_mask_func_t _numa_get_interleave_mask;
244   static numa_move_pages_func_t _numa_move_pages;
245   static numa_set_preferred_func_t _numa_set_preferred;
246   static unsigned long* _numa_all_nodes;
247   static struct bitmask* _numa_all_nodes_ptr;
248   static struct bitmask* _numa_nodes_ptr;
249   static struct bitmask* _numa_interleave_bitmask;
250   static struct bitmask* _numa_membind_bitmask;
251 
252   static void set_sched_getcpu(sched_getcpu_func_t func) { _sched_getcpu = func; }
253   static void set_numa_node_to_cpus(numa_node_to_cpus_func_t func) { _numa_node_to_cpus = func; }
254   static void set_numa_max_node(numa_max_node_func_t func) { _numa_max_node = func; }
255   static void set_numa_num_configured_nodes(numa_num_configured_nodes_func_t func) { _numa_num_configured_nodes = func; }
256   static void set_numa_available(numa_available_func_t func) { _numa_available = func; }
257   static void set_numa_tonode_memory(numa_tonode_memory_func_t func) { _numa_tonode_memory = func; }
258   static void set_numa_interleave_memory(numa_interleave_memory_func_t func) { _numa_interleave_memory = func; }
259   static void set_numa_interleave_memory_v2(numa_interleave_memory_v2_func_t func) { _numa_interleave_memory_v2 = func; }
260   static void set_numa_set_bind_policy(numa_set_bind_policy_func_t func) { _numa_set_bind_policy = func; }
261   static void set_numa_bitmask_isbitset(numa_bitmask_isbitset_func_t func) { _numa_bitmask_isbitset = func; }
262   static void set_numa_distance(numa_distance_func_t func) { _numa_distance = func; }
263   static void set_numa_get_membind(numa_get_membind_func_t func) { _numa_get_membind = func; }
264   static void set_numa_get_interleave_mask(numa_get_interleave_mask_func_t func) { _numa_get_interleave_mask = func; }
265   static void set_numa_move_pages(numa_move_pages_func_t func) { _numa_move_pages = func; }
266   static void set_numa_set_preferred(numa_set_preferred_func_t func) { _numa_set_preferred = func; }
267   static void set_numa_all_nodes(unsigned long* ptr) { _numa_all_nodes = ptr; }
268   static void set_numa_all_nodes_ptr(struct bitmask **ptr) { _numa_all_nodes_ptr = (ptr == NULL ? NULL : *ptr); }
269   static void set_numa_nodes_ptr(struct bitmask **ptr) { _numa_nodes_ptr = (ptr == NULL ? NULL : *ptr); }
270   static void set_numa_interleave_bitmask(struct bitmask* ptr)     { _numa_interleave_bitmask = ptr ;   }
271   static void set_numa_membind_bitmask(struct bitmask* ptr)        { _numa_membind_bitmask = ptr ;      }
272   static int sched_getcpu_syscall(void);
273 
274   enum NumaAllocationPolicy{
275     NotInitialized,
276     Membind,
277     Interleave
278   };
279   static NumaAllocationPolicy _current_numa_policy;
280 
281  public:
282   static int sched_getcpu()  { return _sched_getcpu != NULL ? _sched_getcpu() : -1; }
283   static int numa_node_to_cpus(int node, unsigned long *buffer, int bufferlen) {
284     return _numa_node_to_cpus != NULL ? _numa_node_to_cpus(node, buffer, bufferlen) : -1;
285   }
286   static int numa_max_node() { return _numa_max_node != NULL ? _numa_max_node() : -1; }
287   static int numa_num_configured_nodes() {
288     return _numa_num_configured_nodes != NULL ? _numa_num_configured_nodes() : -1;
289   }
290   static int numa_available() { return _numa_available != NULL ? _numa_available() : -1; }
291   static int numa_tonode_memory(void *start, size_t size, int node) {
292     return _numa_tonode_memory != NULL ? _numa_tonode_memory(start, size, node) : -1;
293   }
294 
295   static bool is_running_in_interleave_mode() {
296     return _current_numa_policy == Interleave;
297   }
298 
299   static void set_configured_numa_policy(NumaAllocationPolicy numa_policy) {
300     _current_numa_policy = numa_policy;
301   }
302 
303   static NumaAllocationPolicy identify_numa_policy() {
304     for (int node = 0; node &lt;= Linux::numa_max_node(); node++) {
305       if (Linux::_numa_bitmask_isbitset(Linux::_numa_interleave_bitmask, node)) {
306         return Interleave;
307       }
308     }
309     return Membind;
310   }
311 
312   static void numa_interleave_memory(void *start, size_t size) {
313     // Prefer v2 API
314     if (_numa_interleave_memory_v2 != NULL) {
315       if (is_running_in_interleave_mode()) {
316         _numa_interleave_memory_v2(start, size, _numa_interleave_bitmask);
317       } else if (_numa_membind_bitmask != NULL) {
318         _numa_interleave_memory_v2(start, size, _numa_membind_bitmask);
319       }
320     } else if (_numa_interleave_memory != NULL) {
321       _numa_interleave_memory(start, size, _numa_all_nodes);
322     }
323   }
324   static void numa_set_preferred(int node) {
325     if (_numa_set_preferred != NULL) {
326       _numa_set_preferred(node);
327     }
328   }
329   static void numa_set_bind_policy(int policy) {
330     if (_numa_set_bind_policy != NULL) {
331       _numa_set_bind_policy(policy);
332     }
333   }
334   static int numa_distance(int node1, int node2) {
335     return _numa_distance != NULL ? _numa_distance(node1, node2) : -1;
336   }
337   static long numa_move_pages(int pid, unsigned long count, void **pages, const int *nodes, int *status, int flags) {
338     return _numa_move_pages != NULL ? _numa_move_pages(pid, count, pages, nodes, status, flags) : -1;
339   }
340   static int get_node_by_cpu(int cpu_id);
341   static int get_existing_num_nodes();
342   // Check if numa node is configured (non-zero memory node).
343   static bool is_node_in_configured_nodes(unsigned int n) {
344     if (_numa_bitmask_isbitset != NULL &amp;&amp; _numa_all_nodes_ptr != NULL) {
345       return _numa_bitmask_isbitset(_numa_all_nodes_ptr, n);
346     } else
347       return false;
348   }
349   // Check if numa node exists in the system (including zero memory nodes).
350   static bool is_node_in_existing_nodes(unsigned int n) {
351     if (_numa_bitmask_isbitset != NULL &amp;&amp; _numa_nodes_ptr != NULL) {
352       return _numa_bitmask_isbitset(_numa_nodes_ptr, n);
353     } else if (_numa_bitmask_isbitset != NULL &amp;&amp; _numa_all_nodes_ptr != NULL) {
354       // Not all libnuma API v2 implement numa_nodes_ptr, so it&#39;s not possible
355       // to trust the API version for checking its absence. On the other hand,
356       // numa_nodes_ptr found in libnuma 2.0.9 and above is the only way to get
357       // a complete view of all numa nodes in the system, hence numa_nodes_ptr
358       // is used to handle CPU and nodes on architectures (like PowerPC) where
359       // there can exist nodes with CPUs but no memory or vice-versa and the
360       // nodes may be non-contiguous. For most of the architectures, like
361       // x86_64, numa_node_ptr presents the same node set as found in
362       // numa_all_nodes_ptr so it&#39;s possible to use numa_all_nodes_ptr as a
363       // substitute.
364       return _numa_bitmask_isbitset(_numa_all_nodes_ptr, n);
365     } else
366       return false;
367   }
368   // Check if node is in bound node set.
369   static bool is_node_in_bound_nodes(int node) {
370     if (_numa_bitmask_isbitset != NULL) {
371       if (is_running_in_interleave_mode()) {
372         return _numa_bitmask_isbitset(_numa_interleave_bitmask, node);
373       } else {
374         return _numa_membind_bitmask != NULL ? _numa_bitmask_isbitset(_numa_membind_bitmask, node) : false;
375       }
376     }
377     return false;
378   }
379   // Check if bound to only one numa node.
380   // Returns true if bound to a single numa node, otherwise returns false.
381   static bool is_bound_to_single_node() {
382     int nodes = 0;
383     struct bitmask* bmp = NULL;
384     unsigned int node = 0;
385     unsigned int highest_node_number = 0;
386 
387     if (_numa_get_membind != NULL &amp;&amp; _numa_max_node != NULL &amp;&amp; _numa_bitmask_isbitset != NULL) {
388       bmp = _numa_get_membind();
389       highest_node_number = _numa_max_node();
390     } else {
391       return false;
392     }
393 
394     for (node = 0; node &lt;= highest_node_number; node++) {
395       if (_numa_bitmask_isbitset(bmp, node)) {
396         nodes++;
397       }
398     }
399 
400     if (nodes == 1) {
401       return true;
402     } else {
403       return false;
404     }
405   }
406 
407   static const GrowableArray&lt;int&gt;* numa_nindex_to_node() {
408     return _nindex_to_node;
409   }
410 };
411 
412 #endif // OS_LINUX_OS_LINUX_HPP
    </pre>
  </body>
</html>