<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/interpreter/zero/bytecodeInterpreter.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2002, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // no precompiled headers
  26 #include &quot;classfile/vmSymbols.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.hpp&quot;
  28 #include &quot;gc/shared/threadLocalAllocBuffer.inline.hpp&quot;
  29 #include &quot;interpreter/bytecodeHistogram.hpp&quot;
  30 #include &quot;interpreter/zero/bytecodeInterpreter.inline.hpp&quot;
  31 #include &quot;interpreter/zero/bytecodeInterpreterProfiling.hpp&quot;
  32 #include &quot;interpreter/interpreter.hpp&quot;
  33 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  34 #include &quot;logging/log.hpp&quot;
  35 #include &quot;memory/resourceArea.hpp&quot;
  36 #include &quot;memory/universe.hpp&quot;
  37 #include &quot;oops/constantPool.inline.hpp&quot;
  38 #include &quot;oops/cpCache.inline.hpp&quot;
  39 #include &quot;oops/method.inline.hpp&quot;
  40 #include &quot;oops/methodCounters.hpp&quot;
  41 #include &quot;oops/objArrayKlass.hpp&quot;
  42 #include &quot;oops/objArrayOop.inline.hpp&quot;
  43 #include &quot;oops/oop.inline.hpp&quot;
  44 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  45 #include &quot;prims/jvmtiExport.hpp&quot;
  46 #include &quot;prims/jvmtiThreadState.hpp&quot;
  47 #include &quot;runtime/atomic.hpp&quot;
  48 #include &quot;runtime/biasedLocking.hpp&quot;
  49 #include &quot;runtime/frame.inline.hpp&quot;
  50 #include &quot;runtime/handles.inline.hpp&quot;
  51 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  52 #include &quot;runtime/orderAccess.hpp&quot;
  53 #include &quot;runtime/sharedRuntime.hpp&quot;
  54 #include &quot;runtime/threadCritical.hpp&quot;
  55 #include &quot;utilities/exceptions.hpp&quot;
  56 
  57 // no precompiled headers
  58 
  59 /*
  60  * USELABELS - If using GCC, then use labels for the opcode dispatching
  61  * rather -then a switch statement. This improves performance because it
  62  * gives us the opportunity to have the instructions that calculate the
  63  * next opcode to jump to be intermixed with the rest of the instructions
  64  * that implement the opcode (see UPDATE_PC_AND_TOS_AND_CONTINUE macro).
  65  */
  66 #undef USELABELS
  67 #ifdef __GNUC__
  68 /*
  69    ASSERT signifies debugging. It is much easier to step thru bytecodes if we
  70    don&#39;t use the computed goto approach.
  71 */
  72 #ifndef ASSERT
  73 #define USELABELS
  74 #endif
  75 #endif
  76 
  77 #undef CASE
  78 #ifdef USELABELS
  79 #define CASE(opcode) opc ## opcode
  80 #define DEFAULT opc_default
  81 #else
  82 #define CASE(opcode) case Bytecodes:: opcode
  83 #define DEFAULT default
  84 #endif
  85 
  86 /*
  87  * PREFETCH_OPCCODE - Some compilers do better if you prefetch the next
  88  * opcode before going back to the top of the while loop, rather then having
  89  * the top of the while loop handle it. This provides a better opportunity
  90  * for instruction scheduling. Some compilers just do this prefetch
  91  * automatically. Some actually end up with worse performance if you
  92  * force the prefetch. Solaris gcc seems to do better, but cc does worse.
  93  */
  94 #undef PREFETCH_OPCCODE
  95 #define PREFETCH_OPCCODE
  96 
  97 /*
  98   Interpreter safepoint: it is expected that the interpreter will have no live
  99   handles of its own creation live at an interpreter safepoint. Therefore we
 100   run a HandleMarkCleaner and trash all handles allocated in the call chain
 101   since the JavaCalls::call_helper invocation that initiated the chain.
 102   There really shouldn&#39;t be any handles remaining to trash but this is cheap
 103   in relation to a safepoint.
 104 */
 105 #define SAFEPOINT                                                                 \
 106     {                                                                             \
 107        /* zap freed handles rather than GC&#39;ing them */                            \
 108        HandleMarkCleaner __hmc(THREAD);                                           \
 109        CALL_VM(SafepointMechanism::block_if_requested(THREAD), handle_exception); \
 110     }
 111 
 112 /*
 113  * VM_JAVA_ERROR - Macro for throwing a java exception from
 114  * the interpreter loop. Should really be a CALL_VM but there
 115  * is no entry point to do the transition to vm so we just
 116  * do it by hand here.
 117  */
 118 #define VM_JAVA_ERROR_NO_JUMP(name, msg)                                          \
 119     DECACHE_STATE();                                                              \
 120     SET_LAST_JAVA_FRAME();                                                        \
 121     {                                                                             \
 122        ThreadInVMfromJava trans(THREAD);                                          \
 123        Exceptions::_throw_msg(THREAD, __FILE__, __LINE__, name, msg);             \
 124     }                                                                             \
 125     RESET_LAST_JAVA_FRAME();                                                      \
 126     CACHE_STATE();
 127 
 128 // Normal throw of a java error.
 129 #define VM_JAVA_ERROR(name, msg)                                     \
 130     VM_JAVA_ERROR_NO_JUMP(name, msg)                                 \
 131     goto handle_exception;
 132 
 133 #ifdef PRODUCT
 134 #define DO_UPDATE_INSTRUCTION_COUNT(opcode)
 135 #else
 136 #define DO_UPDATE_INSTRUCTION_COUNT(opcode)                                                          \
 137 {                                                                                                    \
 138     BytecodeCounter::_counter_value++;                                                               \
 139     BytecodeHistogram::_counters[(Bytecodes::Code)opcode]++;                                         \
 140     if (StopInterpreterAt &amp;&amp; StopInterpreterAt == BytecodeCounter::_counter_value) os::breakpoint(); \
 141     if (TraceBytecodes) {                                                                            \
 142       CALL_VM((void)InterpreterRuntime::trace_bytecode(THREAD, 0,                    \
 143                                         topOfStack[Interpreter::expr_index_at(1)],   \
 144                                         topOfStack[Interpreter::expr_index_at(2)]),  \
 145                                         handle_exception);                           \
 146     }                                                                                \
 147 }
 148 #endif
 149 
 150 #undef DEBUGGER_SINGLE_STEP_NOTIFY
 151 #ifdef VM_JVMTI
 152 /* NOTE: (kbr) This macro must be called AFTER the PC has been
 153    incremented. JvmtiExport::at_single_stepping_point() may cause a
 154    breakpoint opcode to get inserted at the current PC to allow the
 155    debugger to coalesce single-step events.
 156 
 157    As a result if we call at_single_stepping_point() we refetch opcode
 158    to get the current opcode. This will override any other prefetching
 159    that might have occurred.
 160 */
 161 #define DEBUGGER_SINGLE_STEP_NOTIFY()                                            \
 162 {                                                                                \
 163       if (_jvmti_interp_events) {                                                \
 164         if (JvmtiExport::should_post_single_step()) {                            \
 165           DECACHE_STATE();                                                       \
 166           SET_LAST_JAVA_FRAME();                                                 \
 167           ThreadInVMfromJava trans(THREAD);                                      \
 168           JvmtiExport::at_single_stepping_point(THREAD,                          \
 169                                           istate-&gt;method(),                      \
 170                                           pc);                                   \
 171           RESET_LAST_JAVA_FRAME();                                               \
 172           CACHE_STATE();                                                         \
 173           if (THREAD-&gt;has_pending_popframe() &amp;&amp;                                  \
 174               !THREAD-&gt;pop_frame_in_process()) {                                 \
 175             goto handle_Pop_Frame;                                               \
 176           }                                                                      \
 177           if (THREAD-&gt;jvmti_thread_state() &amp;&amp;                                    \
 178               THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) {             \
 179             goto handle_Early_Return;                                            \
 180           }                                                                      \
 181           opcode = *pc;                                                          \
 182         }                                                                        \
 183       }                                                                          \
 184 }
 185 #else
 186 #define DEBUGGER_SINGLE_STEP_NOTIFY()
 187 #endif
 188 
 189 /*
 190  * CONTINUE - Macro for executing the next opcode.
 191  */
 192 #undef CONTINUE
 193 #ifdef USELABELS
 194 // Have to do this dispatch this way in C++ because otherwise gcc complains about crossing an
 195 // initialization (which is is the initialization of the table pointer...)
 196 #define DISPATCH(opcode) goto *(void*)dispatch_table[opcode]
 197 #define CONTINUE {                              \
 198         opcode = *pc;                           \
 199         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 200         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 201         DISPATCH(opcode);                       \
 202     }
 203 #else
 204 #ifdef PREFETCH_OPCCODE
 205 #define CONTINUE {                              \
 206         opcode = *pc;                           \
 207         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 208         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 209         continue;                               \
 210     }
 211 #else
 212 #define CONTINUE {                              \
 213         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 214         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 215         continue;                               \
 216     }
 217 #endif
 218 #endif
 219 
 220 
 221 #define UPDATE_PC(opsize) {pc += opsize; }
 222 /*
 223  * UPDATE_PC_AND_TOS - Macro for updating the pc and topOfStack.
 224  */
 225 #undef UPDATE_PC_AND_TOS
 226 #define UPDATE_PC_AND_TOS(opsize, stack) \
 227     {pc += opsize; MORE_STACK(stack); }
 228 
 229 /*
 230  * UPDATE_PC_AND_TOS_AND_CONTINUE - Macro for updating the pc and topOfStack,
 231  * and executing the next opcode. It&#39;s somewhat similar to the combination
 232  * of UPDATE_PC_AND_TOS and CONTINUE, but with some minor optimizations.
 233  */
 234 #undef UPDATE_PC_AND_TOS_AND_CONTINUE
 235 #ifdef USELABELS
 236 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) {         \
 237         pc += opsize; opcode = *pc; MORE_STACK(stack);          \
 238         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 239         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 240         DISPATCH(opcode);                                       \
 241     }
 242 
 243 #define UPDATE_PC_AND_CONTINUE(opsize) {                        \
 244         pc += opsize; opcode = *pc;                             \
 245         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 246         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 247         DISPATCH(opcode);                                       \
 248     }
 249 #else
 250 #ifdef PREFETCH_OPCCODE
 251 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) {         \
 252         pc += opsize; opcode = *pc; MORE_STACK(stack);          \
 253         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 254         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 255         goto do_continue;                                       \
 256     }
 257 
 258 #define UPDATE_PC_AND_CONTINUE(opsize) {                        \
 259         pc += opsize; opcode = *pc;                             \
 260         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 261         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 262         goto do_continue;                                       \
 263     }
 264 #else
 265 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) { \
 266         pc += opsize; MORE_STACK(stack);                \
 267         DO_UPDATE_INSTRUCTION_COUNT(opcode);            \
 268         DEBUGGER_SINGLE_STEP_NOTIFY();                  \
 269         goto do_continue;                               \
 270     }
 271 
 272 #define UPDATE_PC_AND_CONTINUE(opsize) {                \
 273         pc += opsize;                                   \
 274         DO_UPDATE_INSTRUCTION_COUNT(opcode);            \
 275         DEBUGGER_SINGLE_STEP_NOTIFY();                  \
 276         goto do_continue;                               \
 277     }
 278 #endif /* PREFETCH_OPCCODE */
 279 #endif /* USELABELS */
 280 
 281 // About to call a new method, update the save the adjusted pc and return to frame manager
 282 #define UPDATE_PC_AND_RETURN(opsize)  \
 283    DECACHE_TOS();                     \
 284    istate-&gt;set_bcp(pc+opsize);        \
 285    return;
 286 
 287 
 288 #define METHOD istate-&gt;method()
 289 #define GET_METHOD_COUNTERS(res)
 290 #define DO_BACKEDGE_CHECKS(skip, branch_pc)
 291 
 292 /*
 293  * For those opcodes that need to have a GC point on a backwards branch
 294  */
 295 
 296 /*
 297  * Macros for caching and flushing the interpreter state. Some local
 298  * variables need to be flushed out to the frame before we do certain
 299  * things (like pushing frames or becomming gc safe) and some need to
 300  * be recached later (like after popping a frame). We could use one
 301  * macro to cache or decache everything, but this would be less then
 302  * optimal because we don&#39;t always need to cache or decache everything
 303  * because some things we know are already cached or decached.
 304  */
 305 #undef DECACHE_TOS
 306 #undef CACHE_TOS
 307 #undef CACHE_PREV_TOS
 308 #define DECACHE_TOS()    istate-&gt;set_stack(topOfStack);
 309 
 310 #define CACHE_TOS()      topOfStack = (intptr_t *)istate-&gt;stack();
 311 
 312 #undef DECACHE_PC
 313 #undef CACHE_PC
 314 #define DECACHE_PC()    istate-&gt;set_bcp(pc);
 315 #define CACHE_PC()      pc = istate-&gt;bcp();
 316 #define CACHE_CP()      cp = istate-&gt;constants();
 317 #define CACHE_LOCALS()  locals = istate-&gt;locals();
 318 #undef CACHE_FRAME
 319 #define CACHE_FRAME()
 320 
 321 // BCI() returns the current bytecode-index.
 322 #undef  BCI
 323 #define BCI()           ((int)(intptr_t)(pc - (intptr_t)istate-&gt;method()-&gt;code_base()))
 324 
 325 /*
 326  * CHECK_NULL - Macro for throwing a NullPointerException if the object
 327  * passed is a null ref.
 328  * On some architectures/platforms it should be possible to do this implicitly
 329  */
 330 #undef CHECK_NULL
 331 #define CHECK_NULL(obj_)                                                                         \
 332         if ((obj_) == NULL) {                                                                    \
 333           VM_JAVA_ERROR(vmSymbols::java_lang_NullPointerException(), NULL);                      \
 334         }                                                                                        \
 335         VERIFY_OOP(obj_)
 336 
 337 #define VMdoubleConstZero() 0.0
 338 #define VMdoubleConstOne() 1.0
 339 #define VMlongConstZero() (max_jlong-max_jlong)
 340 #define VMlongConstOne() ((max_jlong-max_jlong)+1)
 341 
 342 /*
 343  * Alignment
 344  */
 345 #define VMalignWordUp(val)          (((uintptr_t)(val) + 3) &amp; ~3)
 346 
 347 // Decache the interpreter state that interpreter modifies directly (i.e. GC is indirect mod)
 348 #define DECACHE_STATE() DECACHE_PC(); DECACHE_TOS();
 349 
 350 // Reload interpreter state after calling the VM or a possible GC
 351 #define CACHE_STATE()   \
 352         CACHE_TOS();    \
 353         CACHE_PC();     \
 354         CACHE_CP();     \
 355         CACHE_LOCALS();
 356 
 357 // Call the VM with last java frame only.
 358 #define CALL_VM_NAKED_LJF(func)                                    \
 359         DECACHE_STATE();                                           \
 360         SET_LAST_JAVA_FRAME();                                     \
 361         func;                                                      \
 362         RESET_LAST_JAVA_FRAME();                                   \
 363         CACHE_STATE();
 364 
 365 // Call the VM. Don&#39;t check for pending exceptions.
 366 #define CALL_VM_NOCHECK(func)                                      \
 367         CALL_VM_NAKED_LJF(func)                                    \
 368         if (THREAD-&gt;has_pending_popframe() &amp;&amp;                      \
 369             !THREAD-&gt;pop_frame_in_process()) {                     \
 370           goto handle_Pop_Frame;                                   \
 371         }                                                          \
 372         if (THREAD-&gt;jvmti_thread_state() &amp;&amp;                        \
 373             THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) { \
 374           goto handle_Early_Return;                                \
 375         }
 376 
 377 // Call the VM and check for pending exceptions
 378 #define CALL_VM(func, label) {                                     \
 379           CALL_VM_NOCHECK(func);                                   \
 380           if (THREAD-&gt;has_pending_exception()) goto label;         \
 381         }
 382 
 383 /*
 384  * BytecodeInterpreter::run(interpreterState istate)
 385  * BytecodeInterpreter::runWithChecks(interpreterState istate)
 386  *
 387  * The real deal. This is where byte codes actually get interpreted.
 388  * Basically it&#39;s a big while loop that iterates until we return from
 389  * the method passed in.
 390  *
 391  * The runWithChecks is used if JVMTI is enabled.
 392  *
 393  */
 394 #if defined(VM_JVMTI)
 395 void
 396 BytecodeInterpreter::runWithChecks(interpreterState istate) {
 397 #else
 398 void
 399 BytecodeInterpreter::run(interpreterState istate) {
 400 #endif
 401 
 402   // In order to simplify some tests based on switches set at runtime
 403   // we invoke the interpreter a single time after switches are enabled
 404   // and set simpler to to test variables rather than method calls or complex
 405   // boolean expressions.
 406 
 407   static int initialized = 0;
 408   static int checkit = 0;
 409   static intptr_t* c_addr = NULL;
 410   static intptr_t  c_value;
 411 
 412   if (checkit &amp;&amp; *c_addr != c_value) {
 413     os::breakpoint();
 414   }
 415 #ifdef VM_JVMTI
 416   static bool _jvmti_interp_events = 0;
 417 #endif
 418 
 419   static int _compiling;  // (UseCompiler || CountCompiledCalls)
 420 
 421 #ifdef ASSERT
 422   if (istate-&gt;_msg != initialize) {
 423     assert(labs(istate-&gt;_stack_base - istate-&gt;_stack_limit) == (istate-&gt;_method-&gt;max_stack() + 1), &quot;bad stack limit&quot;);
 424     IA32_ONLY(assert(istate-&gt;_stack_limit == istate-&gt;_thread-&gt;last_Java_sp() + 1, &quot;wrong&quot;));
 425   }
 426   // Verify linkages.
 427   interpreterState l = istate;
 428   do {
 429     assert(l == l-&gt;_self_link, &quot;bad link&quot;);
 430     l = l-&gt;_prev_link;
 431   } while (l != NULL);
 432   // Screwups with stack management usually cause us to overwrite istate
 433   // save a copy so we can verify it.
 434   interpreterState orig = istate;
 435 #endif
 436 
 437   intptr_t*        topOfStack = (intptr_t *)istate-&gt;stack(); /* access with STACK macros */
 438   address          pc = istate-&gt;bcp();
 439   jubyte opcode;
 440   intptr_t*        locals = istate-&gt;locals();
 441   ConstantPoolCache*    cp = istate-&gt;constants(); // method()-&gt;constants()-&gt;cache()
 442 #ifdef LOTS_OF_REGS
 443   JavaThread*      THREAD = istate-&gt;thread();
 444 #else
 445 #undef THREAD
 446 #define THREAD istate-&gt;thread()
 447 #endif
 448 
 449 #ifdef USELABELS
 450   const static void* const opclabels_data[256] = {
 451 /* 0x00 */ &amp;&amp;opc_nop,     &amp;&amp;opc_aconst_null,&amp;&amp;opc_iconst_m1,&amp;&amp;opc_iconst_0,
 452 /* 0x04 */ &amp;&amp;opc_iconst_1,&amp;&amp;opc_iconst_2,   &amp;&amp;opc_iconst_3, &amp;&amp;opc_iconst_4,
 453 /* 0x08 */ &amp;&amp;opc_iconst_5,&amp;&amp;opc_lconst_0,   &amp;&amp;opc_lconst_1, &amp;&amp;opc_fconst_0,
 454 /* 0x0C */ &amp;&amp;opc_fconst_1,&amp;&amp;opc_fconst_2,   &amp;&amp;opc_dconst_0, &amp;&amp;opc_dconst_1,
 455 
 456 /* 0x10 */ &amp;&amp;opc_bipush, &amp;&amp;opc_sipush, &amp;&amp;opc_ldc,    &amp;&amp;opc_ldc_w,
 457 /* 0x14 */ &amp;&amp;opc_ldc2_w, &amp;&amp;opc_iload,  &amp;&amp;opc_lload,  &amp;&amp;opc_fload,
 458 /* 0x18 */ &amp;&amp;opc_dload,  &amp;&amp;opc_aload,  &amp;&amp;opc_iload_0,&amp;&amp;opc_iload_1,
 459 /* 0x1C */ &amp;&amp;opc_iload_2,&amp;&amp;opc_iload_3,&amp;&amp;opc_lload_0,&amp;&amp;opc_lload_1,
 460 
 461 /* 0x20 */ &amp;&amp;opc_lload_2,&amp;&amp;opc_lload_3,&amp;&amp;opc_fload_0,&amp;&amp;opc_fload_1,
 462 /* 0x24 */ &amp;&amp;opc_fload_2,&amp;&amp;opc_fload_3,&amp;&amp;opc_dload_0,&amp;&amp;opc_dload_1,
 463 /* 0x28 */ &amp;&amp;opc_dload_2,&amp;&amp;opc_dload_3,&amp;&amp;opc_aload_0,&amp;&amp;opc_aload_1,
 464 /* 0x2C */ &amp;&amp;opc_aload_2,&amp;&amp;opc_aload_3,&amp;&amp;opc_iaload, &amp;&amp;opc_laload,
 465 
 466 /* 0x30 */ &amp;&amp;opc_faload,  &amp;&amp;opc_daload,  &amp;&amp;opc_aaload,  &amp;&amp;opc_baload,
 467 /* 0x34 */ &amp;&amp;opc_caload,  &amp;&amp;opc_saload,  &amp;&amp;opc_istore,  &amp;&amp;opc_lstore,
 468 /* 0x38 */ &amp;&amp;opc_fstore,  &amp;&amp;opc_dstore,  &amp;&amp;opc_astore,  &amp;&amp;opc_istore_0,
 469 /* 0x3C */ &amp;&amp;opc_istore_1,&amp;&amp;opc_istore_2,&amp;&amp;opc_istore_3,&amp;&amp;opc_lstore_0,
 470 
 471 /* 0x40 */ &amp;&amp;opc_lstore_1,&amp;&amp;opc_lstore_2,&amp;&amp;opc_lstore_3,&amp;&amp;opc_fstore_0,
 472 /* 0x44 */ &amp;&amp;opc_fstore_1,&amp;&amp;opc_fstore_2,&amp;&amp;opc_fstore_3,&amp;&amp;opc_dstore_0,
 473 /* 0x48 */ &amp;&amp;opc_dstore_1,&amp;&amp;opc_dstore_2,&amp;&amp;opc_dstore_3,&amp;&amp;opc_astore_0,
 474 /* 0x4C */ &amp;&amp;opc_astore_1,&amp;&amp;opc_astore_2,&amp;&amp;opc_astore_3,&amp;&amp;opc_iastore,
 475 
 476 /* 0x50 */ &amp;&amp;opc_lastore,&amp;&amp;opc_fastore,&amp;&amp;opc_dastore,&amp;&amp;opc_aastore,
 477 /* 0x54 */ &amp;&amp;opc_bastore,&amp;&amp;opc_castore,&amp;&amp;opc_sastore,&amp;&amp;opc_pop,
 478 /* 0x58 */ &amp;&amp;opc_pop2,   &amp;&amp;opc_dup,    &amp;&amp;opc_dup_x1, &amp;&amp;opc_dup_x2,
 479 /* 0x5C */ &amp;&amp;opc_dup2,   &amp;&amp;opc_dup2_x1,&amp;&amp;opc_dup2_x2,&amp;&amp;opc_swap,
 480 
 481 /* 0x60 */ &amp;&amp;opc_iadd,&amp;&amp;opc_ladd,&amp;&amp;opc_fadd,&amp;&amp;opc_dadd,
 482 /* 0x64 */ &amp;&amp;opc_isub,&amp;&amp;opc_lsub,&amp;&amp;opc_fsub,&amp;&amp;opc_dsub,
 483 /* 0x68 */ &amp;&amp;opc_imul,&amp;&amp;opc_lmul,&amp;&amp;opc_fmul,&amp;&amp;opc_dmul,
 484 /* 0x6C */ &amp;&amp;opc_idiv,&amp;&amp;opc_ldiv,&amp;&amp;opc_fdiv,&amp;&amp;opc_ddiv,
 485 
 486 /* 0x70 */ &amp;&amp;opc_irem, &amp;&amp;opc_lrem, &amp;&amp;opc_frem,&amp;&amp;opc_drem,
 487 /* 0x74 */ &amp;&amp;opc_ineg, &amp;&amp;opc_lneg, &amp;&amp;opc_fneg,&amp;&amp;opc_dneg,
 488 /* 0x78 */ &amp;&amp;opc_ishl, &amp;&amp;opc_lshl, &amp;&amp;opc_ishr,&amp;&amp;opc_lshr,
 489 /* 0x7C */ &amp;&amp;opc_iushr,&amp;&amp;opc_lushr,&amp;&amp;opc_iand,&amp;&amp;opc_land,
 490 
 491 /* 0x80 */ &amp;&amp;opc_ior, &amp;&amp;opc_lor,&amp;&amp;opc_ixor,&amp;&amp;opc_lxor,
 492 /* 0x84 */ &amp;&amp;opc_iinc,&amp;&amp;opc_i2l,&amp;&amp;opc_i2f, &amp;&amp;opc_i2d,
 493 /* 0x88 */ &amp;&amp;opc_l2i, &amp;&amp;opc_l2f,&amp;&amp;opc_l2d, &amp;&amp;opc_f2i,
 494 /* 0x8C */ &amp;&amp;opc_f2l, &amp;&amp;opc_f2d,&amp;&amp;opc_d2i, &amp;&amp;opc_d2l,
 495 
 496 /* 0x90 */ &amp;&amp;opc_d2f,  &amp;&amp;opc_i2b,  &amp;&amp;opc_i2c,  &amp;&amp;opc_i2s,
 497 /* 0x94 */ &amp;&amp;opc_lcmp, &amp;&amp;opc_fcmpl,&amp;&amp;opc_fcmpg,&amp;&amp;opc_dcmpl,
 498 /* 0x98 */ &amp;&amp;opc_dcmpg,&amp;&amp;opc_ifeq, &amp;&amp;opc_ifne, &amp;&amp;opc_iflt,
 499 /* 0x9C */ &amp;&amp;opc_ifge, &amp;&amp;opc_ifgt, &amp;&amp;opc_ifle, &amp;&amp;opc_if_icmpeq,
 500 
 501 /* 0xA0 */ &amp;&amp;opc_if_icmpne,&amp;&amp;opc_if_icmplt,&amp;&amp;opc_if_icmpge,  &amp;&amp;opc_if_icmpgt,
 502 /* 0xA4 */ &amp;&amp;opc_if_icmple,&amp;&amp;opc_if_acmpeq,&amp;&amp;opc_if_acmpne,  &amp;&amp;opc_goto,
 503 /* 0xA8 */ &amp;&amp;opc_jsr,      &amp;&amp;opc_ret,      &amp;&amp;opc_tableswitch,&amp;&amp;opc_lookupswitch,
 504 /* 0xAC */ &amp;&amp;opc_ireturn,  &amp;&amp;opc_lreturn,  &amp;&amp;opc_freturn,    &amp;&amp;opc_dreturn,
 505 
 506 /* 0xB0 */ &amp;&amp;opc_areturn,     &amp;&amp;opc_return,         &amp;&amp;opc_getstatic,    &amp;&amp;opc_putstatic,
 507 /* 0xB4 */ &amp;&amp;opc_getfield,    &amp;&amp;opc_putfield,       &amp;&amp;opc_invokevirtual,&amp;&amp;opc_invokespecial,
 508 /* 0xB8 */ &amp;&amp;opc_invokestatic,&amp;&amp;opc_invokeinterface,&amp;&amp;opc_invokedynamic,&amp;&amp;opc_new,
 509 /* 0xBC */ &amp;&amp;opc_newarray,    &amp;&amp;opc_anewarray,      &amp;&amp;opc_arraylength,  &amp;&amp;opc_athrow,
 510 
 511 /* 0xC0 */ &amp;&amp;opc_checkcast,   &amp;&amp;opc_instanceof,     &amp;&amp;opc_monitorenter, &amp;&amp;opc_monitorexit,
 512 /* 0xC4 */ &amp;&amp;opc_wide,        &amp;&amp;opc_multianewarray, &amp;&amp;opc_ifnull,       &amp;&amp;opc_ifnonnull,
 513 /* 0xC8 */ &amp;&amp;opc_goto_w,      &amp;&amp;opc_jsr_w,          &amp;&amp;opc_breakpoint,   &amp;&amp;opc_default,
 514 /* 0xCC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 515 
 516 /* 0xD0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 517 /* 0xD4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 518 /* 0xD8 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 519 /* 0xDC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 520 
 521 /* 0xE0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,         &amp;&amp;opc_default,
 522 /* 0xE4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_fast_aldc,    &amp;&amp;opc_fast_aldc_w,
 523 /* 0xE8 */ &amp;&amp;opc_return_register_finalizer,
 524                               &amp;&amp;opc_invokehandle,   &amp;&amp;opc_default,      &amp;&amp;opc_default,
 525 /* 0xEC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,         &amp;&amp;opc_default,
 526 
 527 /* 0xF0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 528 /* 0xF4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 529 /* 0xF8 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 530 /* 0xFC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default
 531   };
 532   uintptr_t *dispatch_table = (uintptr_t*)&amp;opclabels_data[0];
 533 #endif /* USELABELS */
 534 
 535 #ifdef ASSERT
 536   // this will trigger a VERIFY_OOP on entry
 537   if (istate-&gt;msg() != initialize &amp;&amp; ! METHOD-&gt;is_static()) {
 538     oop rcvr = LOCALS_OBJECT(0);
 539     VERIFY_OOP(rcvr);
 540   }
 541 #endif
 542 
 543   /* QQQ this should be a stack method so we don&#39;t know actual direction */
 544   guarantee(istate-&gt;msg() == initialize ||
 545          topOfStack &gt;= istate-&gt;stack_limit() &amp;&amp;
 546          topOfStack &lt; istate-&gt;stack_base(),
 547          &quot;Stack top out of range&quot;);
 548 
 549   const uint mdo_last_branch_taken_count = 0;
 550 
 551   switch (istate-&gt;msg()) {
 552     case initialize: {
 553       if (initialized++) ShouldNotReachHere(); // Only one initialize call.
 554       _compiling = (UseCompiler || CountCompiledCalls);
 555 #ifdef VM_JVMTI
 556       _jvmti_interp_events = JvmtiExport::can_post_interpreter_events();
 557 #endif
 558       return;
 559     }
 560     break;
 561     case method_entry: {
 562       THREAD-&gt;set_do_not_unlock();
 563       // count invocations
 564       assert(initialized, &quot;Interpreter not initialized&quot;);
 565       if (_compiling) {
 566         // Get or create profile data. Check for pending (async) exceptions.
 567         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 568         SAFEPOINT;
 569       }
 570 
 571       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 572         // initialize
 573         os::breakpoint();
 574       }
 575 
 576       // Lock method if synchronized.
 577       if (METHOD-&gt;is_synchronized()) {
 578         // oop rcvr = locals[0].j.r;
 579         oop rcvr;
 580         if (METHOD-&gt;is_static()) {
 581           rcvr = METHOD-&gt;constants()-&gt;pool_holder()-&gt;java_mirror();
 582         } else {
 583           rcvr = LOCALS_OBJECT(0);
 584           VERIFY_OOP(rcvr);
 585         }
 586         // The initial monitor is ours for the taking.
 587         // Monitor not filled in frame manager any longer as this caused race condition with biased locking.
 588         BasicObjectLock* mon = &amp;istate-&gt;monitor_base()[-1];
 589         mon-&gt;set_obj(rcvr);
 590         bool success = false;
 591         uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
 592         markWord mark = rcvr-&gt;mark();
 593         intptr_t hash = (intptr_t) markWord::no_hash;
 594         // Implies UseBiasedLocking.
 595         if (mark.has_bias_pattern()) {
 596           uintptr_t thread_ident;
 597           uintptr_t anticipated_bias_locking_value;
 598           thread_ident = (uintptr_t)istate-&gt;thread();
 599           anticipated_bias_locking_value =
 600             ((rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
 601             ~(markWord::age_mask_in_place);
 602 
 603           if (anticipated_bias_locking_value == 0) {
 604             // Already biased towards this thread, nothing to do.
 605             if (PrintBiasedLockingStatistics) {
 606               (* BiasedLocking::biased_lock_entry_count_addr())++;
 607             }
 608             success = true;
 609           } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
 610             // Try to revoke bias.
 611             markWord header = rcvr-&gt;klass()-&gt;prototype_header();
 612             if (hash != markWord::no_hash) {
 613               header = header.copy_set_hash(hash);
 614             }
 615             if (rcvr-&gt;cas_set_mark(header, mark) == mark) {
 616               if (PrintBiasedLockingStatistics)
 617                 (*BiasedLocking::revoked_lock_entry_count_addr())++;
 618             }
 619           } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) != 0) {
 620             // Try to rebias.
 621             markWord new_header( (intptr_t) rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident);
 622             if (hash != markWord::no_hash) {
 623               new_header = new_header.copy_set_hash(hash);
 624             }
 625             if (rcvr-&gt;cas_set_mark(new_header, mark) == mark) {
 626               if (PrintBiasedLockingStatistics) {
 627                 (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 628               }
 629             } else {
 630               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 631             }
 632             success = true;
 633           } else {
 634             // Try to bias towards thread in case object is anonymously biased.
 635             markWord header(mark.value() &amp;
 636                             (markWord::biased_lock_mask_in_place |
 637                              markWord::age_mask_in_place | epoch_mask_in_place));
 638             if (hash != markWord::no_hash) {
 639               header = header.copy_set_hash(hash);
 640             }
 641             markWord new_header(header.value() | thread_ident);
 642             // Debugging hint.
 643             DEBUG_ONLY(mon-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
 644             if (rcvr-&gt;cas_set_mark(new_header, header) == header) {
 645               if (PrintBiasedLockingStatistics) {
 646                 (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 647               }
 648             } else {
 649               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 650             }
 651             success = true;
 652           }
 653         }
 654 
 655         // Traditional lightweight locking.
 656         if (!success) {
 657           markWord displaced = rcvr-&gt;mark().set_unlocked();
 658           mon-&gt;lock()-&gt;set_displaced_header(displaced);
 659           bool call_vm = UseHeavyMonitors;
 660           if (call_vm || rcvr-&gt;cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {
 661             // Is it simple recursive case?
 662             if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
 663               mon-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
 664             } else {
 665               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 666             }
 667           }
 668         }
 669       }
 670       THREAD-&gt;clr_do_not_unlock();
 671 
 672       // Notify jvmti
 673 #ifdef VM_JVMTI
 674       if (_jvmti_interp_events) {
 675         // Whenever JVMTI puts a thread in interp_only_mode, method
 676         // entry/exit events are sent for that thread to track stack depth.
 677         if (THREAD-&gt;is_interp_only_mode()) {
 678           CALL_VM(InterpreterRuntime::post_method_entry(THREAD),
 679                   handle_exception);
 680         }
 681       }
 682 #endif /* VM_JVMTI */
 683 
 684       goto run;
 685     }
 686 
 687     case popping_frame: {
 688       // returned from a java call to pop the frame, restart the call
 689       // clear the message so we don&#39;t confuse ourselves later
 690       assert(THREAD-&gt;pop_frame_in_process(), &quot;wrong frame pop state&quot;);
 691       istate-&gt;set_msg(no_request);
 692       if (_compiling) {
 693         // Set MDX back to the ProfileData of the invoke bytecode that will be
 694         // restarted.
 695         SET_MDX(NULL);
 696         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 697       }
 698       THREAD-&gt;clr_pop_frame_in_process();
 699       goto run;
 700     }
 701 
 702     case method_resume: {
 703       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 704         // resume
 705         os::breakpoint();
 706       }
 707       // returned from a java call, continue executing.
 708       if (THREAD-&gt;has_pending_popframe() &amp;&amp; !THREAD-&gt;pop_frame_in_process()) {
 709         goto handle_Pop_Frame;
 710       }
 711       if (THREAD-&gt;jvmti_thread_state() &amp;&amp;
 712           THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) {
 713         goto handle_Early_Return;
 714       }
 715 
 716       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 717       // Update the pc by the saved amount of the invoke bytecode size
 718       UPDATE_PC(istate-&gt;bcp_advance());
 719 
 720       if (_compiling) {
 721         // Get or create profile data. Check for pending (async) exceptions.
 722         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 723       }
 724       goto run;
 725     }
 726 
 727     case deopt_resume2: {
 728       // Returned from an opcode that will reexecute. Deopt was
 729       // a result of a PopFrame request.
 730       //
 731 
 732       if (_compiling) {
 733         // Get or create profile data. Check for pending (async) exceptions.
 734         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 735       }
 736       goto run;
 737     }
 738 
 739     case deopt_resume: {
 740       // Returned from an opcode that has completed. The stack has
 741       // the result all we need to do is skip across the bytecode
 742       // and continue (assuming there is no exception pending)
 743       //
 744       // compute continuation length
 745       //
 746       // Note: it is possible to deopt at a return_register_finalizer opcode
 747       // because this requires entering the vm to do the registering. While the
 748       // opcode is complete we can&#39;t advance because there are no more opcodes
 749       // much like trying to deopt at a poll return. In that has we simply
 750       // get out of here
 751       //
 752       if ( Bytecodes::code_at(METHOD, pc) == Bytecodes::_return_register_finalizer) {
 753         // this will do the right thing even if an exception is pending.
 754         goto handle_return;
 755       }
 756       UPDATE_PC(Bytecodes::length_at(METHOD, pc));
 757       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 758 
 759       if (_compiling) {
 760         // Get or create profile data. Check for pending (async) exceptions.
 761         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 762       }
 763       goto run;
 764     }
 765     case got_monitors: {
 766       // continue locking now that we have a monitor to use
 767       // we expect to find newly allocated monitor at the &quot;top&quot; of the monitor stack.
 768       oop lockee = STACK_OBJECT(-1);
 769       VERIFY_OOP(lockee);
 770       // derefing&#39;s lockee ought to provoke implicit null check
 771       // find a free monitor
 772       BasicObjectLock* entry = (BasicObjectLock*) istate-&gt;stack_base();
 773       assert(entry-&gt;obj() == NULL, &quot;Frame manager didn&#39;t allocate the monitor&quot;);
 774       entry-&gt;set_obj(lockee);
 775       bool success = false;
 776       uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
 777 
 778       markWord mark = lockee-&gt;mark();
 779       intptr_t hash = (intptr_t) markWord::no_hash;
 780       // implies UseBiasedLocking
 781       if (mark.has_bias_pattern()) {
 782         uintptr_t thread_ident;
 783         uintptr_t anticipated_bias_locking_value;
 784         thread_ident = (uintptr_t)istate-&gt;thread();
 785         anticipated_bias_locking_value =
 786           ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
 787           ~(markWord::age_mask_in_place);
 788 
 789         if  (anticipated_bias_locking_value == 0) {
 790           // already biased towards this thread, nothing to do
 791           if (PrintBiasedLockingStatistics) {
 792             (* BiasedLocking::biased_lock_entry_count_addr())++;
 793           }
 794           success = true;
 795         } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
 796           // try revoke bias
 797           markWord header = lockee-&gt;klass()-&gt;prototype_header();
 798           if (hash != markWord::no_hash) {
 799             header = header.copy_set_hash(hash);
 800           }
 801           if (lockee-&gt;cas_set_mark(header, mark) == mark) {
 802             if (PrintBiasedLockingStatistics) {
 803               (*BiasedLocking::revoked_lock_entry_count_addr())++;
 804             }
 805           }
 806         } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
 807           // try rebias
 808           markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);
 809           if (hash != markWord::no_hash) {
 810             new_header = new_header.copy_set_hash(hash);
 811           }
 812           if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
 813             if (PrintBiasedLockingStatistics) {
 814               (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 815             }
 816           } else {
 817             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 818           }
 819           success = true;
 820         } else {
 821           // try to bias towards thread in case object is anonymously biased
 822           markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |
 823                                           markWord::age_mask_in_place | epoch_mask_in_place));
 824           if (hash != markWord::no_hash) {
 825             header = header.copy_set_hash(hash);
 826           }
 827           markWord new_header(header.value() | thread_ident);
 828           // debugging hint
 829           DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
 830           if (lockee-&gt;cas_set_mark(new_header, header) == header) {
 831             if (PrintBiasedLockingStatistics) {
 832               (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 833             }
 834           } else {
 835             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 836           }
 837           success = true;
 838         }
 839       }
 840 
 841       // traditional lightweight locking
 842       if (!success) {
 843         markWord displaced = lockee-&gt;mark().set_unlocked();
 844         entry-&gt;lock()-&gt;set_displaced_header(displaced);
 845         bool call_vm = UseHeavyMonitors;
 846         if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {
 847           // Is it simple recursive case?
 848           if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
 849             entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
 850           } else {
 851             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 852           }
 853         }
 854       }
 855       UPDATE_PC_AND_TOS(1, -1);
 856       goto run;
 857     }
 858     default: {
 859       fatal(&quot;Unexpected message from frame manager&quot;);
 860     }
 861   }
 862 
 863 run:
 864 
 865   DO_UPDATE_INSTRUCTION_COUNT(*pc)
 866   DEBUGGER_SINGLE_STEP_NOTIFY();
 867 #ifdef PREFETCH_OPCCODE
 868   opcode = *pc;  /* prefetch first opcode */
 869 #endif
 870 
 871 #ifndef USELABELS
 872   while (1)
 873 #endif
 874   {
 875 #ifndef PREFETCH_OPCCODE
 876       opcode = *pc;
 877 #endif
 878       // Seems like this happens twice per opcode. At worst this is only
 879       // need at entry to the loop.
 880       // DEBUGGER_SINGLE_STEP_NOTIFY();
 881       /* Using this labels avoids double breakpoints when quickening and
 882        * when returing from transition frames.
 883        */
 884   opcode_switch:
 885       assert(istate == orig, &quot;Corrupted istate&quot;);
 886       /* QQQ Hmm this has knowledge of direction, ought to be a stack method */
 887       assert(topOfStack &gt;= istate-&gt;stack_limit(), &quot;Stack overrun&quot;);
 888       assert(topOfStack &lt; istate-&gt;stack_base(), &quot;Stack underrun&quot;);
 889 
 890 #ifdef USELABELS
 891       DISPATCH(opcode);
 892 #else
 893       switch (opcode)
 894 #endif
 895       {
 896       CASE(_nop):
 897           UPDATE_PC_AND_CONTINUE(1);
 898 
 899           /* Push miscellaneous constants onto the stack. */
 900 
 901       CASE(_aconst_null):
 902           SET_STACK_OBJECT(NULL, 0);
 903           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
 904 
 905 #undef  OPC_CONST_n
 906 #define OPC_CONST_n(opcode, const_type, value)                          \
 907       CASE(opcode):                                                     \
 908           SET_STACK_ ## const_type(value, 0);                           \
 909           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
 910 
 911           OPC_CONST_n(_iconst_m1,   INT,       -1);
 912           OPC_CONST_n(_iconst_0,    INT,        0);
 913           OPC_CONST_n(_iconst_1,    INT,        1);
 914           OPC_CONST_n(_iconst_2,    INT,        2);
 915           OPC_CONST_n(_iconst_3,    INT,        3);
 916           OPC_CONST_n(_iconst_4,    INT,        4);
 917           OPC_CONST_n(_iconst_5,    INT,        5);
 918           OPC_CONST_n(_fconst_0,    FLOAT,      0.0);
 919           OPC_CONST_n(_fconst_1,    FLOAT,      1.0);
 920           OPC_CONST_n(_fconst_2,    FLOAT,      2.0);
 921 
 922 #undef  OPC_CONST2_n
 923 #define OPC_CONST2_n(opcname, value, key, kind)                         \
 924       CASE(_##opcname):                                                 \
 925       {                                                                 \
 926           SET_STACK_ ## kind(VM##key##Const##value(), 1);               \
 927           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);                         \
 928       }
 929          OPC_CONST2_n(dconst_0, Zero, double, DOUBLE);
 930          OPC_CONST2_n(dconst_1, One,  double, DOUBLE);
 931          OPC_CONST2_n(lconst_0, Zero, long, LONG);
 932          OPC_CONST2_n(lconst_1, One,  long, LONG);
 933 
 934          /* Load constant from constant pool: */
 935 
 936           /* Push a 1-byte signed integer value onto the stack. */
 937       CASE(_bipush):
 938           SET_STACK_INT((jbyte)(pc[1]), 0);
 939           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
 940 
 941           /* Push a 2-byte signed integer constant onto the stack. */
 942       CASE(_sipush):
 943           SET_STACK_INT((int16_t)Bytes::get_Java_u2(pc + 1), 0);
 944           UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
 945 
 946           /* load from local variable */
 947 
 948       CASE(_aload):
 949           VERIFY_OOP(LOCALS_OBJECT(pc[1]));
 950           SET_STACK_OBJECT(LOCALS_OBJECT(pc[1]), 0);
 951           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
 952 
 953       CASE(_iload):
 954       CASE(_fload):
 955           SET_STACK_SLOT(LOCALS_SLOT(pc[1]), 0);
 956           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
 957 
 958       CASE(_lload):
 959           SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(pc[1]), 1);
 960           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 2);
 961 
 962       CASE(_dload):
 963           SET_STACK_DOUBLE_FROM_ADDR(LOCALS_DOUBLE_AT(pc[1]), 1);
 964           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 2);
 965 
 966 #undef  OPC_LOAD_n
 967 #define OPC_LOAD_n(num)                                                 \
 968       CASE(_aload_##num):                                               \
 969           VERIFY_OOP(LOCALS_OBJECT(num));                               \
 970           SET_STACK_OBJECT(LOCALS_OBJECT(num), 0);                      \
 971           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);                         \
 972                                                                         \
 973       CASE(_iload_##num):                                               \
 974       CASE(_fload_##num):                                               \
 975           SET_STACK_SLOT(LOCALS_SLOT(num), 0);                          \
 976           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);                         \
 977                                                                         \
 978       CASE(_lload_##num):                                               \
 979           SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(num), 1);             \
 980           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);                         \
 981       CASE(_dload_##num):                                               \
 982           SET_STACK_DOUBLE_FROM_ADDR(LOCALS_DOUBLE_AT(num), 1);         \
 983           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
 984 
 985           OPC_LOAD_n(0);
 986           OPC_LOAD_n(1);
 987           OPC_LOAD_n(2);
 988           OPC_LOAD_n(3);
 989 
 990           /* store to a local variable */
 991 
 992       CASE(_astore):
 993           astore(topOfStack, -1, locals, pc[1]);
 994           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -1);
 995 
 996       CASE(_istore):
 997       CASE(_fstore):
 998           SET_LOCALS_SLOT(STACK_SLOT(-1), pc[1]);
 999           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -1);
1000 
1001       CASE(_lstore):
1002           SET_LOCALS_LONG(STACK_LONG(-1), pc[1]);
1003           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -2);
1004 
1005       CASE(_dstore):
1006           SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), pc[1]);
1007           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -2);
1008 
1009       CASE(_wide): {
1010           uint16_t reg = Bytes::get_Java_u2(pc + 2);
1011 
1012           opcode = pc[1];
1013 
1014           // Wide and it&#39;s sub-bytecode are counted as separate instructions. If we
1015           // don&#39;t account for this here, the bytecode trace skips the next bytecode.
1016           DO_UPDATE_INSTRUCTION_COUNT(opcode);
1017 
1018           switch(opcode) {
1019               case Bytecodes::_aload:
1020                   VERIFY_OOP(LOCALS_OBJECT(reg));
1021                   SET_STACK_OBJECT(LOCALS_OBJECT(reg), 0);
1022                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 1);
1023 
1024               case Bytecodes::_iload:
1025               case Bytecodes::_fload:
1026                   SET_STACK_SLOT(LOCALS_SLOT(reg), 0);
1027                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 1);
1028 
1029               case Bytecodes::_lload:
1030                   SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(reg), 1);
1031                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 2);
1032 
1033               case Bytecodes::_dload:
1034                   SET_STACK_DOUBLE_FROM_ADDR(LOCALS_LONG_AT(reg), 1);
1035                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 2);
1036 
1037               case Bytecodes::_astore:
1038                   astore(topOfStack, -1, locals, reg);
1039                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -1);
1040 
1041               case Bytecodes::_istore:
1042               case Bytecodes::_fstore:
1043                   SET_LOCALS_SLOT(STACK_SLOT(-1), reg);
1044                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -1);
1045 
1046               case Bytecodes::_lstore:
1047                   SET_LOCALS_LONG(STACK_LONG(-1), reg);
1048                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -2);
1049 
1050               case Bytecodes::_dstore:
1051                   SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), reg);
1052                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -2);
1053 
1054               case Bytecodes::_iinc: {
1055                   int16_t offset = (int16_t)Bytes::get_Java_u2(pc+4);
1056                   // Be nice to see what this generates.... QQQ
1057                   SET_LOCALS_INT(LOCALS_INT(reg) + offset, reg);
1058                   UPDATE_PC_AND_CONTINUE(6);
1059               }
1060               case Bytecodes::_ret:
1061                   // Profile ret.
1062                   BI_PROFILE_UPDATE_RET(/*bci=*/((int)(intptr_t)(LOCALS_ADDR(reg))));
1063                   // Now, update the pc.
1064                   pc = istate-&gt;method()-&gt;code_base() + (intptr_t)(LOCALS_ADDR(reg));
1065                   UPDATE_PC_AND_CONTINUE(0);
1066               default:
1067                   VM_JAVA_ERROR(vmSymbols::java_lang_InternalError(), &quot;undefined opcode&quot;);
1068           }
1069       }
1070 
1071 
1072 #undef  OPC_STORE_n
1073 #define OPC_STORE_n(num)                                                \
1074       CASE(_astore_##num):                                              \
1075           astore(topOfStack, -1, locals, num);                          \
1076           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                        \
1077       CASE(_istore_##num):                                              \
1078       CASE(_fstore_##num):                                              \
1079           SET_LOCALS_SLOT(STACK_SLOT(-1), num);                         \
1080           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1081 
1082           OPC_STORE_n(0);
1083           OPC_STORE_n(1);
1084           OPC_STORE_n(2);
1085           OPC_STORE_n(3);
1086 
1087 #undef  OPC_DSTORE_n
1088 #define OPC_DSTORE_n(num)                                               \
1089       CASE(_dstore_##num):                                              \
1090           SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), num);                     \
1091           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                        \
1092       CASE(_lstore_##num):                                              \
1093           SET_LOCALS_LONG(STACK_LONG(-1), num);                         \
1094           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);
1095 
1096           OPC_DSTORE_n(0);
1097           OPC_DSTORE_n(1);
1098           OPC_DSTORE_n(2);
1099           OPC_DSTORE_n(3);
1100 
1101           /* stack pop, dup, and insert opcodes */
1102 
1103 
1104       CASE(_pop):                /* Discard the top item on the stack */
1105           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1106 
1107 
1108       CASE(_pop2):               /* Discard the top 2 items on the stack */
1109           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);
1110 
1111 
1112       CASE(_dup):               /* Duplicate the top item on the stack */
1113           dup(topOfStack);
1114           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1115 
1116       CASE(_dup2):              /* Duplicate the top 2 items on the stack */
1117           dup2(topOfStack);
1118           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1119 
1120       CASE(_dup_x1):    /* insert top word two down */
1121           dup_x1(topOfStack);
1122           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1123 
1124       CASE(_dup_x2):    /* insert top word three down  */
1125           dup_x2(topOfStack);
1126           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1127 
1128       CASE(_dup2_x1):   /* insert top 2 slots three down */
1129           dup2_x1(topOfStack);
1130           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1131 
1132       CASE(_dup2_x2):   /* insert top 2 slots four down */
1133           dup2_x2(topOfStack);
1134           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1135 
1136       CASE(_swap): {        /* swap top two elements on the stack */
1137           swap(topOfStack);
1138           UPDATE_PC_AND_CONTINUE(1);
1139       }
1140 
1141           /* Perform various binary integer operations */
1142 
1143 #undef  OPC_INT_BINARY
1144 #define OPC_INT_BINARY(opcname, opname, test)                           \
1145       CASE(_i##opcname):                                                \
1146           if (test &amp;&amp; (STACK_INT(-1) == 0)) {                           \
1147               VM_JAVA_ERROR(vmSymbols::java_lang_ArithmeticException(), \
1148                             &quot;/ by zero&quot;);                               \
1149           }                                                             \
1150           SET_STACK_INT(VMint##opname(STACK_INT(-2),                    \
1151                                       STACK_INT(-1)),                   \
1152                                       -2);                              \
1153           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                        \
1154       CASE(_l##opcname):                                                \
1155       {                                                                 \
1156           if (test) {                                                   \
1157             jlong l1 = STACK_LONG(-1);                                  \
1158             if (VMlongEqz(l1)) {                                        \
1159               VM_JAVA_ERROR(vmSymbols::java_lang_ArithmeticException(), \
1160                             &quot;/ by long zero&quot;);                          \
1161             }                                                           \
1162           }                                                             \
1163           /* First long at (-1,-2) next long at (-3,-4) */              \
1164           SET_STACK_LONG(VMlong##opname(STACK_LONG(-3),                 \
1165                                         STACK_LONG(-1)),                \
1166                                         -3);                            \
1167           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                        \
1168       }
1169 
1170       OPC_INT_BINARY(add, Add, 0);
1171       OPC_INT_BINARY(sub, Sub, 0);
1172       OPC_INT_BINARY(mul, Mul, 0);
1173       OPC_INT_BINARY(and, And, 0);
1174       OPC_INT_BINARY(or,  Or,  0);
1175       OPC_INT_BINARY(xor, Xor, 0);
1176       OPC_INT_BINARY(div, Div, 1);
1177       OPC_INT_BINARY(rem, Rem, 1);
1178 
1179 
1180       /* Perform various binary floating number operations */
1181       /* On some machine/platforms/compilers div zero check can be implicit */
1182 
1183 #undef  OPC_FLOAT_BINARY
1184 #define OPC_FLOAT_BINARY(opcname, opname)                                  \
1185       CASE(_d##opcname): {                                                 \
1186           SET_STACK_DOUBLE(VMdouble##opname(STACK_DOUBLE(-3),              \
1187                                             STACK_DOUBLE(-1)),             \
1188                                             -3);                           \
1189           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                           \
1190       }                                                                    \
1191       CASE(_f##opcname):                                                   \
1192           SET_STACK_FLOAT(VMfloat##opname(STACK_FLOAT(-2),                 \
1193                                           STACK_FLOAT(-1)),                \
1194                                           -2);                             \
1195           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1196 
1197 
1198      OPC_FLOAT_BINARY(add, Add);
1199      OPC_FLOAT_BINARY(sub, Sub);
1200      OPC_FLOAT_BINARY(mul, Mul);
1201      OPC_FLOAT_BINARY(div, Div);
1202      OPC_FLOAT_BINARY(rem, Rem);
1203 
1204       /* Shift operations
1205        * Shift left int and long: ishl, lshl
1206        * Logical shift right int and long w/zero extension: iushr, lushr
1207        * Arithmetic shift right int and long w/sign extension: ishr, lshr
1208        */
1209 
1210 #undef  OPC_SHIFT_BINARY
1211 #define OPC_SHIFT_BINARY(opcname, opname)                               \
1212       CASE(_i##opcname):                                                \
1213          SET_STACK_INT(VMint##opname(STACK_INT(-2),                     \
1214                                      STACK_INT(-1)),                    \
1215                                      -2);                               \
1216          UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                         \
1217       CASE(_l##opcname):                                                \
1218       {                                                                 \
1219          SET_STACK_LONG(VMlong##opname(STACK_LONG(-2),                  \
1220                                        STACK_INT(-1)),                  \
1221                                        -2);                             \
1222          UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                         \
1223       }
1224 
1225       OPC_SHIFT_BINARY(shl, Shl);
1226       OPC_SHIFT_BINARY(shr, Shr);
1227       OPC_SHIFT_BINARY(ushr, Ushr);
1228 
1229      /* Increment local variable by constant */
1230       CASE(_iinc):
1231       {
1232           // locals[pc[1]].j.i += (jbyte)(pc[2]);
1233           SET_LOCALS_INT(LOCALS_INT(pc[1]) + (jbyte)(pc[2]), pc[1]);
1234           UPDATE_PC_AND_CONTINUE(3);
1235       }
1236 
1237      /* negate the value on the top of the stack */
1238 
1239       CASE(_ineg):
1240          SET_STACK_INT(VMintNeg(STACK_INT(-1)), -1);
1241          UPDATE_PC_AND_CONTINUE(1);
1242 
1243       CASE(_fneg):
1244          SET_STACK_FLOAT(VMfloatNeg(STACK_FLOAT(-1)), -1);
1245          UPDATE_PC_AND_CONTINUE(1);
1246 
1247       CASE(_lneg):
1248       {
1249          SET_STACK_LONG(VMlongNeg(STACK_LONG(-1)), -1);
1250          UPDATE_PC_AND_CONTINUE(1);
1251       }
1252 
1253       CASE(_dneg):
1254       {
1255          SET_STACK_DOUBLE(VMdoubleNeg(STACK_DOUBLE(-1)), -1);
1256          UPDATE_PC_AND_CONTINUE(1);
1257       }
1258 
1259       /* Conversion operations */
1260 
1261       CASE(_i2f):       /* convert top of stack int to float */
1262          SET_STACK_FLOAT(VMint2Float(STACK_INT(-1)), -1);
1263          UPDATE_PC_AND_CONTINUE(1);
1264 
1265       CASE(_i2l):       /* convert top of stack int to long */
1266       {
1267           // this is ugly QQQ
1268           jlong r = VMint2Long(STACK_INT(-1));
1269           MORE_STACK(-1); // Pop
1270           SET_STACK_LONG(r, 1);
1271 
1272           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1273       }
1274 
1275       CASE(_i2d):       /* convert top of stack int to double */
1276       {
1277           // this is ugly QQQ (why cast to jlong?? )
1278           jdouble r = (jlong)STACK_INT(-1);
1279           MORE_STACK(-1); // Pop
1280           SET_STACK_DOUBLE(r, 1);
1281 
1282           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1283       }
1284 
1285       CASE(_l2i):       /* convert top of stack long to int */
1286       {
1287           jint r = VMlong2Int(STACK_LONG(-1));
1288           MORE_STACK(-2); // Pop
1289           SET_STACK_INT(r, 0);
1290           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1291       }
1292 
1293       CASE(_l2f):   /* convert top of stack long to float */
1294       {
1295           jlong r = STACK_LONG(-1);
1296           MORE_STACK(-2); // Pop
1297           SET_STACK_FLOAT(VMlong2Float(r), 0);
1298           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1299       }
1300 
1301       CASE(_l2d):       /* convert top of stack long to double */
1302       {
1303           jlong r = STACK_LONG(-1);
1304           MORE_STACK(-2); // Pop
1305           SET_STACK_DOUBLE(VMlong2Double(r), 1);
1306           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1307       }
1308 
1309       CASE(_f2i):  /* Convert top of stack float to int */
1310           SET_STACK_INT(SharedRuntime::f2i(STACK_FLOAT(-1)), -1);
1311           UPDATE_PC_AND_CONTINUE(1);
1312 
1313       CASE(_f2l):  /* convert top of stack float to long */
1314       {
1315           jlong r = SharedRuntime::f2l(STACK_FLOAT(-1));
1316           MORE_STACK(-1); // POP
1317           SET_STACK_LONG(r, 1);
1318           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1319       }
1320 
1321       CASE(_f2d):  /* convert top of stack float to double */
1322       {
1323           jfloat f;
1324           jdouble r;
1325           f = STACK_FLOAT(-1);
1326           r = (jdouble) f;
1327           MORE_STACK(-1); // POP
1328           SET_STACK_DOUBLE(r, 1);
1329           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1330       }
1331 
1332       CASE(_d2i): /* convert top of stack double to int */
1333       {
1334           jint r1 = SharedRuntime::d2i(STACK_DOUBLE(-1));
1335           MORE_STACK(-2);
1336           SET_STACK_INT(r1, 0);
1337           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1338       }
1339 
1340       CASE(_d2f): /* convert top of stack double to float */
1341       {
1342           jfloat r1 = VMdouble2Float(STACK_DOUBLE(-1));
1343           MORE_STACK(-2);
1344           SET_STACK_FLOAT(r1, 0);
1345           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1346       }
1347 
1348       CASE(_d2l): /* convert top of stack double to long */
1349       {
1350           jlong r1 = SharedRuntime::d2l(STACK_DOUBLE(-1));
1351           MORE_STACK(-2);
1352           SET_STACK_LONG(r1, 1);
1353           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1354       }
1355 
1356       CASE(_i2b):
1357           SET_STACK_INT(VMint2Byte(STACK_INT(-1)), -1);
1358           UPDATE_PC_AND_CONTINUE(1);
1359 
1360       CASE(_i2c):
1361           SET_STACK_INT(VMint2Char(STACK_INT(-1)), -1);
1362           UPDATE_PC_AND_CONTINUE(1);
1363 
1364       CASE(_i2s):
1365           SET_STACK_INT(VMint2Short(STACK_INT(-1)), -1);
1366           UPDATE_PC_AND_CONTINUE(1);
1367 
1368       /* comparison operators */
1369 
1370 
1371 #define COMPARISON_OP(name, comparison)                                      \
1372       CASE(_if_icmp##name): {                                                \
1373           const bool cmp = (STACK_INT(-2) comparison STACK_INT(-1));         \
1374           int skip = cmp                                                     \
1375                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1376           address branch_pc = pc;                                            \
1377           /* Profile branch. */                                              \
1378           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1379           UPDATE_PC_AND_TOS(skip, -2);                                       \
1380           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1381           CONTINUE;                                                          \
1382       }                                                                      \
1383       CASE(_if##name): {                                                     \
1384           const bool cmp = (STACK_INT(-1) comparison 0);                     \
1385           int skip = cmp                                                     \
1386                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1387           address branch_pc = pc;                                            \
1388           /* Profile branch. */                                              \
1389           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1390           UPDATE_PC_AND_TOS(skip, -1);                                       \
1391           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1392           CONTINUE;                                                          \
1393       }
1394 
1395 #define COMPARISON_OP2(name, comparison)                                     \
1396       COMPARISON_OP(name, comparison)                                        \
1397       CASE(_if_acmp##name): {                                                \
1398           const bool cmp = (STACK_OBJECT(-2) comparison STACK_OBJECT(-1));   \
1399           int skip = cmp                                                     \
1400                        ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;            \
1401           address branch_pc = pc;                                            \
1402           /* Profile branch. */                                              \
1403           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1404           UPDATE_PC_AND_TOS(skip, -2);                                       \
1405           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1406           CONTINUE;                                                          \
1407       }
1408 
1409 #define NULL_COMPARISON_NOT_OP(name)                                         \
1410       CASE(_if##name): {                                                     \
1411           const bool cmp = (!(STACK_OBJECT(-1) == NULL));                    \
1412           int skip = cmp                                                     \
1413                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1414           address branch_pc = pc;                                            \
1415           /* Profile branch. */                                              \
1416           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1417           UPDATE_PC_AND_TOS(skip, -1);                                       \
1418           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1419           CONTINUE;                                                          \
1420       }
1421 
1422 #define NULL_COMPARISON_OP(name)                                             \
1423       CASE(_if##name): {                                                     \
1424           const bool cmp = ((STACK_OBJECT(-1) == NULL));                     \
1425           int skip = cmp                                                     \
1426                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1427           address branch_pc = pc;                                            \
1428           /* Profile branch. */                                              \
1429           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1430           UPDATE_PC_AND_TOS(skip, -1);                                       \
1431           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1432           CONTINUE;                                                          \
1433       }
1434       COMPARISON_OP(lt, &lt;);
1435       COMPARISON_OP(gt, &gt;);
1436       COMPARISON_OP(le, &lt;=);
1437       COMPARISON_OP(ge, &gt;=);
1438       COMPARISON_OP2(eq, ==);  /* include ref comparison */
1439       COMPARISON_OP2(ne, !=);  /* include ref comparison */
1440       NULL_COMPARISON_OP(null);
1441       NULL_COMPARISON_NOT_OP(nonnull);
1442 
1443       /* Goto pc at specified offset in switch table. */
1444 
1445       CASE(_tableswitch): {
1446           jint* lpc  = (jint*)VMalignWordUp(pc+1);
1447           int32_t  key  = STACK_INT(-1);
1448           int32_t  low  = Bytes::get_Java_u4((address)&amp;lpc[1]);
1449           int32_t  high = Bytes::get_Java_u4((address)&amp;lpc[2]);
1450           int32_t  skip;
1451           key -= low;
1452           if (((uint32_t) key &gt; (uint32_t)(high - low))) {
1453             key = -1;
1454             skip = Bytes::get_Java_u4((address)&amp;lpc[0]);
1455           } else {
1456             skip = Bytes::get_Java_u4((address)&amp;lpc[key + 3]);
1457           }
1458           // Profile switch.
1459           BI_PROFILE_UPDATE_SWITCH(/*switch_index=*/key);
1460           // Does this really need a full backedge check (osr)?
1461           address branch_pc = pc;
1462           UPDATE_PC_AND_TOS(skip, -1);
1463           DO_BACKEDGE_CHECKS(skip, branch_pc);
1464           CONTINUE;
1465       }
1466 
1467       /* Goto pc whose table entry matches specified key. */
1468 
1469       CASE(_lookupswitch): {
1470           jint* lpc  = (jint*)VMalignWordUp(pc+1);
1471           int32_t  key  = STACK_INT(-1);
1472           int32_t  skip = Bytes::get_Java_u4((address) lpc); /* default amount */
1473           // Remember index.
1474           int      index = -1;
1475           int      newindex = 0;
1476           int32_t  npairs = Bytes::get_Java_u4((address) &amp;lpc[1]);
1477           while (--npairs &gt;= 0) {
1478             lpc += 2;
1479             if (key == (int32_t)Bytes::get_Java_u4((address)lpc)) {
1480               skip = Bytes::get_Java_u4((address)&amp;lpc[1]);
1481               index = newindex;
1482               break;
1483             }
1484             newindex += 1;
1485           }
1486           // Profile switch.
1487           BI_PROFILE_UPDATE_SWITCH(/*switch_index=*/index);
1488           address branch_pc = pc;
1489           UPDATE_PC_AND_TOS(skip, -1);
1490           DO_BACKEDGE_CHECKS(skip, branch_pc);
1491           CONTINUE;
1492       }
1493 
1494       CASE(_fcmpl):
1495       CASE(_fcmpg):
1496       {
1497           SET_STACK_INT(VMfloatCompare(STACK_FLOAT(-2),
1498                                         STACK_FLOAT(-1),
1499                                         (opcode == Bytecodes::_fcmpl ? -1 : 1)),
1500                         -2);
1501           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1502       }
1503 
1504       CASE(_dcmpl):
1505       CASE(_dcmpg):
1506       {
1507           int r = VMdoubleCompare(STACK_DOUBLE(-3),
1508                                   STACK_DOUBLE(-1),
1509                                   (opcode == Bytecodes::_dcmpl ? -1 : 1));
1510           MORE_STACK(-4); // Pop
1511           SET_STACK_INT(r, 0);
1512           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1513       }
1514 
1515       CASE(_lcmp):
1516       {
1517           int r = VMlongCompare(STACK_LONG(-3), STACK_LONG(-1));
1518           MORE_STACK(-4);
1519           SET_STACK_INT(r, 0);
1520           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1521       }
1522 
1523 
1524       /* Return from a method */
1525 
1526       CASE(_areturn):
1527       CASE(_ireturn):
1528       CASE(_freturn):
1529       {
1530           // Allow a safepoint before returning to frame manager.
1531           SAFEPOINT;
1532 
1533           goto handle_return;
1534       }
1535 
1536       CASE(_lreturn):
1537       CASE(_dreturn):
1538       {
1539           // Allow a safepoint before returning to frame manager.
1540           SAFEPOINT;
1541           goto handle_return;
1542       }
1543 
1544       CASE(_return_register_finalizer): {
1545 
1546           oop rcvr = LOCALS_OBJECT(0);
1547           VERIFY_OOP(rcvr);
1548           if (rcvr-&gt;klass()-&gt;has_finalizer()) {
1549             CALL_VM(InterpreterRuntime::register_finalizer(THREAD, rcvr), handle_exception);
1550           }
1551           goto handle_return;
1552       }
1553       CASE(_return): {
1554 
1555           // Allow a safepoint before returning to frame manager.
1556           SAFEPOINT;
1557           goto handle_return;
1558       }
1559 
1560       /* Array access byte-codes */
1561 
1562       /* Every array access byte-code starts out like this */
1563 //        arrayOopDesc* arrObj = (arrayOopDesc*)STACK_OBJECT(arrayOff);
1564 #define ARRAY_INTRO(arrayOff)                                                  \
1565       arrayOop arrObj = (arrayOop)STACK_OBJECT(arrayOff);                      \
1566       jint     index  = STACK_INT(arrayOff + 1);                               \
1567       char message[jintAsStringSize];                                          \
1568       CHECK_NULL(arrObj);                                                      \
1569       if ((uint32_t)index &gt;= (uint32_t)arrObj-&gt;length()) {                     \
1570           sprintf(message, &quot;%d&quot;, index);                                       \
1571           VM_JAVA_ERROR(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), \
1572                         message);                                              \
1573       }
1574 
1575       /* 32-bit loads. These handle conversion from &lt; 32-bit types */
1576 #define ARRAY_LOADTO32(T, T2, format, stackRes, extra)                                \
1577       {                                                                               \
1578           ARRAY_INTRO(-2);                                                            \
1579           (void)extra;                                                                \
1580           SET_ ## stackRes(*(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)), \
1581                            -2);                                                       \
1582           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                                      \
1583       }
1584 
1585       /* 64-bit loads */
1586 #define ARRAY_LOADTO64(T,T2, stackRes, extra)                                              \
1587       {                                                                                    \
1588           ARRAY_INTRO(-2);                                                                 \
1589           SET_ ## stackRes(*(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)), -1); \
1590           (void)extra;                                                                     \
1591           UPDATE_PC_AND_CONTINUE(1);                                                       \
1592       }
1593 
1594       CASE(_iaload):
1595           ARRAY_LOADTO32(T_INT, jint,   &quot;%d&quot;,   STACK_INT, 0);
1596       CASE(_faload):
1597           ARRAY_LOADTO32(T_FLOAT, jfloat, &quot;%f&quot;,   STACK_FLOAT, 0);
1598       CASE(_aaload): {
1599           ARRAY_INTRO(-2);
1600           SET_STACK_OBJECT(((objArrayOop) arrObj)-&gt;obj_at(index), -2);
1601           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1602       }
1603       CASE(_baload):
1604           ARRAY_LOADTO32(T_BYTE, jbyte,  &quot;%d&quot;,   STACK_INT, 0);
1605       CASE(_caload):
1606           ARRAY_LOADTO32(T_CHAR,  jchar, &quot;%d&quot;,   STACK_INT, 0);
1607       CASE(_saload):
1608           ARRAY_LOADTO32(T_SHORT, jshort, &quot;%d&quot;,   STACK_INT, 0);
1609       CASE(_laload):
1610           ARRAY_LOADTO64(T_LONG, jlong, STACK_LONG, 0);
1611       CASE(_daload):
1612           ARRAY_LOADTO64(T_DOUBLE, jdouble, STACK_DOUBLE, 0);
1613 
1614       /* 32-bit stores. These handle conversion to &lt; 32-bit types */
1615 #define ARRAY_STOREFROM32(T, T2, format, stackSrc, extra)                            \
1616       {                                                                              \
1617           ARRAY_INTRO(-3);                                                           \
1618           (void)extra;                                                               \
1619           *(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)) = stackSrc( -1); \
1620           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);                                     \
1621       }
1622 
1623       /* 64-bit stores */
1624 #define ARRAY_STOREFROM64(T, T2, stackSrc, extra)                                    \
1625       {                                                                              \
1626           ARRAY_INTRO(-4);                                                           \
1627           (void)extra;                                                               \
1628           *(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)) = stackSrc( -1); \
1629           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -4);                                     \
1630       }
1631 
1632       CASE(_iastore):
1633           ARRAY_STOREFROM32(T_INT, jint,   &quot;%d&quot;,   STACK_INT, 0);
1634       CASE(_fastore):
1635           ARRAY_STOREFROM32(T_FLOAT, jfloat, &quot;%f&quot;,   STACK_FLOAT, 0);
1636       /*
1637        * This one looks different because of the assignability check
1638        */
1639       CASE(_aastore): {
1640           oop rhsObject = STACK_OBJECT(-1);
1641           VERIFY_OOP(rhsObject);
1642           ARRAY_INTRO( -3);
1643           // arrObj, index are set
1644           if (rhsObject != NULL) {
1645             /* Check assignability of rhsObject into arrObj */
1646             Klass* rhsKlass = rhsObject-&gt;klass(); // EBX (subclass)
1647             Klass* elemKlass = ObjArrayKlass::cast(arrObj-&gt;klass())-&gt;element_klass(); // superklass EAX
1648             //
1649             // Check for compatibilty. This check must not GC!!
1650             // Seems way more expensive now that we must dispatch
1651             //
1652             if (rhsKlass != elemKlass &amp;&amp; !rhsKlass-&gt;is_subtype_of(elemKlass)) { // ebx-&gt;is...
1653               // Decrement counter if subtype check failed.
1654               BI_PROFILE_SUBTYPECHECK_FAILED(rhsKlass);
1655               VM_JAVA_ERROR(vmSymbols::java_lang_ArrayStoreException(), &quot;&quot;);
1656             }
1657             // Profile checkcast with null_seen and receiver.
1658             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/false, rhsKlass);
1659           } else {
1660             // Profile checkcast with null_seen and receiver.
1661             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/true, NULL);
1662           }
1663           ((objArrayOop) arrObj)-&gt;obj_at_put(index, rhsObject);
1664           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);
1665       }
1666       CASE(_bastore): {
1667           ARRAY_INTRO(-3);
1668           int item = STACK_INT(-1);
1669           // if it is a T_BOOLEAN array, mask the stored value to 0/1
1670           if (arrObj-&gt;klass() == Universe::boolArrayKlassObj()) {
1671             item &amp;= 1;
1672           } else {
1673             assert(arrObj-&gt;klass() == Universe::byteArrayKlassObj(),
1674                    &quot;should be byte array otherwise&quot;);
1675           }
1676           ((typeArrayOop)arrObj)-&gt;byte_at_put(index, item);
1677           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);
1678       }
1679       CASE(_castore):
1680           ARRAY_STOREFROM32(T_CHAR, jchar,  &quot;%d&quot;,   STACK_INT, 0);
1681       CASE(_sastore):
1682           ARRAY_STOREFROM32(T_SHORT, jshort, &quot;%d&quot;,   STACK_INT, 0);
1683       CASE(_lastore):
1684           ARRAY_STOREFROM64(T_LONG, jlong, STACK_LONG, 0);
1685       CASE(_dastore):
1686           ARRAY_STOREFROM64(T_DOUBLE, jdouble, STACK_DOUBLE, 0);
1687 
1688       CASE(_arraylength):
1689       {
1690           arrayOop ary = (arrayOop) STACK_OBJECT(-1);
1691           CHECK_NULL(ary);
1692           SET_STACK_INT(ary-&gt;length(), -1);
1693           UPDATE_PC_AND_CONTINUE(1);
1694       }
1695 
1696       /* monitorenter and monitorexit for locking/unlocking an object */
1697 
1698       CASE(_monitorenter): {
1699         oop lockee = STACK_OBJECT(-1);
1700         // derefing&#39;s lockee ought to provoke implicit null check
1701         CHECK_NULL(lockee);
1702         // find a free monitor or one already allocated for this object
1703         // if we find a matching object then we need a new monitor
1704         // since this is recursive enter
1705         BasicObjectLock* limit = istate-&gt;monitor_base();
1706         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1707         BasicObjectLock* entry = NULL;
1708         while (most_recent != limit ) {
1709           if (most_recent-&gt;obj() == NULL) entry = most_recent;
1710           else if (most_recent-&gt;obj() == lockee) break;
1711           most_recent++;
1712         }
1713         if (entry != NULL) {
1714           entry-&gt;set_obj(lockee);
1715           int success = false;
1716           uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
1717 
1718           markWord mark = lockee-&gt;mark();
1719           intptr_t hash = (intptr_t) markWord::no_hash;
1720           // implies UseBiasedLocking
1721           if (mark.has_bias_pattern()) {
1722             uintptr_t thread_ident;
1723             uintptr_t anticipated_bias_locking_value;
1724             thread_ident = (uintptr_t)istate-&gt;thread();
1725             anticipated_bias_locking_value =
1726               ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
1727               ~(markWord::age_mask_in_place);
1728 
1729             if  (anticipated_bias_locking_value == 0) {
1730               // already biased towards this thread, nothing to do
1731               if (PrintBiasedLockingStatistics) {
1732                 (* BiasedLocking::biased_lock_entry_count_addr())++;
1733               }
1734               success = true;
1735             }
1736             else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
1737               // try revoke bias
1738               markWord header = lockee-&gt;klass()-&gt;prototype_header();
1739               if (hash != markWord::no_hash) {
1740                 header = header.copy_set_hash(hash);
1741               }
1742               if (lockee-&gt;cas_set_mark(header, mark) == mark) {
1743                 if (PrintBiasedLockingStatistics)
1744                   (*BiasedLocking::revoked_lock_entry_count_addr())++;
1745               }
1746             }
1747             else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
1748               // try rebias
1749               markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);
1750               if (hash != markWord::no_hash) {
1751                 new_header = new_header.copy_set_hash(hash);
1752               }
1753               if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
1754                 if (PrintBiasedLockingStatistics)
1755                   (* BiasedLocking::rebiased_lock_entry_count_addr())++;
1756               }
1757               else {
1758                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1759               }
1760               success = true;
1761             }
1762             else {
1763               // try to bias towards thread in case object is anonymously biased
1764               markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |
1765                                               markWord::age_mask_in_place |
1766                                               epoch_mask_in_place));
1767               if (hash != markWord::no_hash) {
1768                 header = header.copy_set_hash(hash);
1769               }
1770               markWord new_header(header.value() | thread_ident);
1771               // debugging hint
1772               DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
1773               if (lockee-&gt;cas_set_mark(new_header, header) == header) {
1774                 if (PrintBiasedLockingStatistics)
1775                   (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
1776               }
1777               else {
1778                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1779               }
1780               success = true;
1781             }
1782           }
1783 
1784           // traditional lightweight locking
1785           if (!success) {
1786             markWord displaced = lockee-&gt;mark().set_unlocked();
1787             entry-&gt;lock()-&gt;set_displaced_header(displaced);
1788             bool call_vm = UseHeavyMonitors;
1789             if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {
1790               // Is it simple recursive case?
1791               if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
1792                 entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
1793               } else {
1794                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1795               }
1796             }
1797           }
1798           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1799         } else {
1800           istate-&gt;set_msg(more_monitors);
1801           UPDATE_PC_AND_RETURN(0); // Re-execute
1802         }
1803       }
1804 
1805       CASE(_monitorexit): {
1806         oop lockee = STACK_OBJECT(-1);
1807         CHECK_NULL(lockee);
1808         // derefing&#39;s lockee ought to provoke implicit null check
1809         // find our monitor slot
1810         BasicObjectLock* limit = istate-&gt;monitor_base();
1811         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1812         while (most_recent != limit ) {
1813           if ((most_recent)-&gt;obj() == lockee) {
1814             BasicLock* lock = most_recent-&gt;lock();
1815             markWord header = lock-&gt;displaced_header();
1816             most_recent-&gt;set_obj(NULL);
1817             if (!lockee-&gt;mark().has_bias_pattern()) {
1818               bool call_vm = UseHeavyMonitors;
1819               // If it isn&#39;t recursive we either must swap old header or call the runtime
1820               if (header.to_pointer() != NULL || call_vm) {
1821                 markWord old_header = markWord::encode(lock);
1822                 if (call_vm || lockee-&gt;cas_set_mark(header, old_header) != old_header) {
1823                   // restore object for the slow case
1824                   most_recent-&gt;set_obj(lockee);
1825                   CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception);
1826                 }
1827               }
1828             }
1829             UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1830           }
1831           most_recent++;
1832         }
1833         // Need to throw illegal monitor state exception
1834         CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception);
1835         ShouldNotReachHere();
1836       }
1837 
1838       /* All of the non-quick opcodes. */
1839 
1840       /* -Set clobbersCpIndex true if the quickened opcode clobbers the
1841        *  constant pool index in the instruction.
1842        */
1843       CASE(_getfield):
1844       CASE(_getstatic):
1845         {
1846           u2 index;
1847           ConstantPoolCacheEntry* cache;
1848           index = Bytes::get_native_u2(pc+1);
1849 
1850           // QQQ Need to make this as inlined as possible. Probably need to
1851           // split all the bytecode cases out so c++ compiler has a chance
1852           // for constant prop to fold everything possible away.
1853 
1854           cache = cp-&gt;entry_at(index);
1855           if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
1856             CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
1857                     handle_exception);
1858             cache = cp-&gt;entry_at(index);
1859           }
1860 
1861 #ifdef VM_JVMTI
1862           if (_jvmti_interp_events) {
1863             int *count_addr;
1864             oop obj;
1865             // Check to see if a field modification watch has been set
1866             // before we take the time to call into the VM.
1867             count_addr = (int *)JvmtiExport::get_field_access_count_addr();
1868             if ( *count_addr &gt; 0 ) {
1869               if ((Bytecodes::Code)opcode == Bytecodes::_getstatic) {
1870                 obj = (oop)NULL;
1871               } else {
1872                 obj = (oop) STACK_OBJECT(-1);
1873                 VERIFY_OOP(obj);
1874               }
1875               CALL_VM(InterpreterRuntime::post_field_access(THREAD,
1876                                           obj,
1877                                           cache),
1878                                           handle_exception);
1879             }
1880           }
1881 #endif /* VM_JVMTI */
1882 
1883           oop obj;
1884           if ((Bytecodes::Code)opcode == Bytecodes::_getstatic) {
1885             Klass* k = cache-&gt;f1_as_klass();
1886             obj = k-&gt;java_mirror();
1887             MORE_STACK(1);  // Assume single slot push
1888           } else {
1889             obj = (oop) STACK_OBJECT(-1);
1890             CHECK_NULL(obj);
1891           }
1892 
1893           //
1894           // Now store the result on the stack
1895           //
1896           TosState tos_type = cache-&gt;flag_state();
1897           int field_offset = cache-&gt;f2_as_index();
1898           if (cache-&gt;is_volatile()) {
1899             if (support_IRIW_for_not_multiple_copy_atomic_cpu) {
1900               OrderAccess::fence();
1901             }
1902             if (tos_type == atos) {
1903               VERIFY_OOP(obj-&gt;obj_field_acquire(field_offset));
1904               SET_STACK_OBJECT(obj-&gt;obj_field_acquire(field_offset), -1);
1905             } else if (tos_type == itos) {
1906               SET_STACK_INT(obj-&gt;int_field_acquire(field_offset), -1);
1907             } else if (tos_type == ltos) {
1908               SET_STACK_LONG(obj-&gt;long_field_acquire(field_offset), 0);
1909               MORE_STACK(1);
1910             } else if (tos_type == btos || tos_type == ztos) {
1911               SET_STACK_INT(obj-&gt;byte_field_acquire(field_offset), -1);
1912             } else if (tos_type == ctos) {
1913               SET_STACK_INT(obj-&gt;char_field_acquire(field_offset), -1);
1914             } else if (tos_type == stos) {
1915               SET_STACK_INT(obj-&gt;short_field_acquire(field_offset), -1);
1916             } else if (tos_type == ftos) {
1917               SET_STACK_FLOAT(obj-&gt;float_field_acquire(field_offset), -1);
1918             } else {
1919               SET_STACK_DOUBLE(obj-&gt;double_field_acquire(field_offset), 0);
1920               MORE_STACK(1);
1921             }
1922           } else {
1923             if (tos_type == atos) {
1924               VERIFY_OOP(obj-&gt;obj_field(field_offset));
1925               SET_STACK_OBJECT(obj-&gt;obj_field(field_offset), -1);
1926             } else if (tos_type == itos) {
1927               SET_STACK_INT(obj-&gt;int_field(field_offset), -1);
1928             } else if (tos_type == ltos) {
1929               SET_STACK_LONG(obj-&gt;long_field(field_offset), 0);
1930               MORE_STACK(1);
1931             } else if (tos_type == btos || tos_type == ztos) {
1932               SET_STACK_INT(obj-&gt;byte_field(field_offset), -1);
1933             } else if (tos_type == ctos) {
1934               SET_STACK_INT(obj-&gt;char_field(field_offset), -1);
1935             } else if (tos_type == stos) {
1936               SET_STACK_INT(obj-&gt;short_field(field_offset), -1);
1937             } else if (tos_type == ftos) {
1938               SET_STACK_FLOAT(obj-&gt;float_field(field_offset), -1);
1939             } else {
1940               SET_STACK_DOUBLE(obj-&gt;double_field(field_offset), 0);
1941               MORE_STACK(1);
1942             }
1943           }
1944 
1945           UPDATE_PC_AND_CONTINUE(3);
1946          }
1947 
1948       CASE(_putfield):
1949       CASE(_putstatic):
1950         {
1951           u2 index = Bytes::get_native_u2(pc+1);
1952           ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
1953           if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
1954             CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
1955                     handle_exception);
1956             cache = cp-&gt;entry_at(index);
1957           }
1958 
1959 #ifdef VM_JVMTI
1960           if (_jvmti_interp_events) {
1961             int *count_addr;
1962             oop obj;
1963             // Check to see if a field modification watch has been set
1964             // before we take the time to call into the VM.
1965             count_addr = (int *)JvmtiExport::get_field_modification_count_addr();
1966             if ( *count_addr &gt; 0 ) {
1967               if ((Bytecodes::Code)opcode == Bytecodes::_putstatic) {
1968                 obj = (oop)NULL;
1969               }
1970               else {
1971                 if (cache-&gt;is_long() || cache-&gt;is_double()) {
1972                   obj = (oop) STACK_OBJECT(-3);
1973                 } else {
1974                   obj = (oop) STACK_OBJECT(-2);
1975                 }
1976                 VERIFY_OOP(obj);
1977               }
1978 
1979               CALL_VM(InterpreterRuntime::post_field_modification(THREAD,
1980                                           obj,
1981                                           cache,
1982                                           (jvalue *)STACK_SLOT(-1)),
1983                                           handle_exception);
1984             }
1985           }
1986 #endif /* VM_JVMTI */
1987 
1988           // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
1989           // out so c++ compiler has a chance for constant prop to fold everything possible away.
1990 
1991           oop obj;
1992           int count;
1993           TosState tos_type = cache-&gt;flag_state();
1994 
1995           count = -1;
1996           if (tos_type == ltos || tos_type == dtos) {
1997             --count;
1998           }
1999           if ((Bytecodes::Code)opcode == Bytecodes::_putstatic) {
2000             Klass* k = cache-&gt;f1_as_klass();
2001             obj = k-&gt;java_mirror();
2002           } else {
2003             --count;
2004             obj = (oop) STACK_OBJECT(count);
2005             CHECK_NULL(obj);
2006           }
2007 
2008           //
2009           // Now store the result
2010           //
2011           int field_offset = cache-&gt;f2_as_index();
2012           if (cache-&gt;is_volatile()) {
2013             if (tos_type == itos) {
2014               obj-&gt;release_int_field_put(field_offset, STACK_INT(-1));
2015             } else if (tos_type == atos) {
2016               VERIFY_OOP(STACK_OBJECT(-1));
2017               obj-&gt;release_obj_field_put(field_offset, STACK_OBJECT(-1));
2018             } else if (tos_type == btos) {
2019               obj-&gt;release_byte_field_put(field_offset, STACK_INT(-1));
2020             } else if (tos_type == ztos) {
2021               int bool_field = STACK_INT(-1);  // only store LSB
2022               obj-&gt;release_byte_field_put(field_offset, (bool_field &amp; 1));
2023             } else if (tos_type == ltos) {
2024               obj-&gt;release_long_field_put(field_offset, STACK_LONG(-1));
2025             } else if (tos_type == ctos) {
2026               obj-&gt;release_char_field_put(field_offset, STACK_INT(-1));
2027             } else if (tos_type == stos) {
2028               obj-&gt;release_short_field_put(field_offset, STACK_INT(-1));
2029             } else if (tos_type == ftos) {
2030               obj-&gt;release_float_field_put(field_offset, STACK_FLOAT(-1));
2031             } else {
2032               obj-&gt;release_double_field_put(field_offset, STACK_DOUBLE(-1));
2033             }
2034             OrderAccess::storeload();
2035           } else {
2036             if (tos_type == itos) {
2037               obj-&gt;int_field_put(field_offset, STACK_INT(-1));
2038             } else if (tos_type == atos) {
2039               VERIFY_OOP(STACK_OBJECT(-1));
2040               obj-&gt;obj_field_put(field_offset, STACK_OBJECT(-1));
2041             } else if (tos_type == btos) {
2042               obj-&gt;byte_field_put(field_offset, STACK_INT(-1));
2043             } else if (tos_type == ztos) {
2044               int bool_field = STACK_INT(-1);  // only store LSB
2045               obj-&gt;byte_field_put(field_offset, (bool_field &amp; 1));
2046             } else if (tos_type == ltos) {
2047               obj-&gt;long_field_put(field_offset, STACK_LONG(-1));
2048             } else if (tos_type == ctos) {
2049               obj-&gt;char_field_put(field_offset, STACK_INT(-1));
2050             } else if (tos_type == stos) {
2051               obj-&gt;short_field_put(field_offset, STACK_INT(-1));
2052             } else if (tos_type == ftos) {
2053               obj-&gt;float_field_put(field_offset, STACK_FLOAT(-1));
2054             } else {
2055               obj-&gt;double_field_put(field_offset, STACK_DOUBLE(-1));
2056             }
2057           }
2058 
2059           UPDATE_PC_AND_TOS_AND_CONTINUE(3, count);
2060         }
2061 
2062       CASE(_new): {
2063         u2 index = Bytes::get_Java_u2(pc+1);
2064         ConstantPool* constants = istate-&gt;method()-&gt;constants();
2065         if (!constants-&gt;tag_at(index).is_unresolved_klass()) {
2066           // Make sure klass is initialized and doesn&#39;t have a finalizer
2067           Klass* entry = constants-&gt;resolved_klass_at(index);
2068           InstanceKlass* ik = InstanceKlass::cast(entry);
2069           if (ik-&gt;is_initialized() &amp;&amp; ik-&gt;can_be_fastpath_allocated() ) {
2070             size_t obj_size = ik-&gt;size_helper();
2071             oop result = NULL;
2072             // If the TLAB isn&#39;t pre-zeroed then we&#39;ll have to do it
2073             bool need_zero = !ZeroTLAB;
2074             if (UseTLAB) {
2075               result = (oop) THREAD-&gt;tlab().allocate(obj_size);
2076             }
2077             // Disable non-TLAB-based fast-path, because profiling requires that all
2078             // allocations go through InterpreterRuntime::_new() if THREAD-&gt;tlab().allocate
2079             // returns NULL.
2080             if (result == NULL) {
2081               need_zero = true;
2082               // Try allocate in shared eden
2083             retry:
2084               HeapWord* compare_to = *Universe::heap()-&gt;top_addr();
2085               HeapWord* new_top = compare_to + obj_size;
2086               if (new_top &lt;= *Universe::heap()-&gt;end_addr()) {
2087                 if (Atomic::cmpxchg(Universe::heap()-&gt;top_addr(), compare_to, new_top) != compare_to) {
2088                   goto retry;
2089                 }
2090                 result = (oop) compare_to;
2091               }
2092             }
2093             if (result != NULL) {
2094               // Initialize object (if nonzero size and need) and then the header
2095               if (need_zero ) {
2096                 HeapWord* to_zero = cast_from_oop&lt;HeapWord*&gt;(result) + sizeof(oopDesc) / oopSize;
2097                 obj_size -= sizeof(oopDesc) / oopSize;
2098                 if (obj_size &gt; 0 ) {
2099                   memset(to_zero, 0, obj_size * HeapWordSize);
2100                 }
2101               }
2102               if (UseBiasedLocking) {
2103                 result-&gt;set_mark(ik-&gt;prototype_header());
2104               } else {
2105                 result-&gt;set_mark(markWord::prototype());
2106               }
2107               result-&gt;set_klass_gap(0);
2108               result-&gt;set_klass(ik);
2109               // Must prevent reordering of stores for object initialization
2110               // with stores that publish the new object.
2111               OrderAccess::storestore();
2112               SET_STACK_OBJECT(result, 0);
2113               UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2114             }
2115           }
2116         }
2117         // Slow case allocation
2118         CALL_VM(InterpreterRuntime::_new(THREAD, METHOD-&gt;constants(), index),
2119                 handle_exception);
2120         // Must prevent reordering of stores for object initialization
2121         // with stores that publish the new object.
2122         OrderAccess::storestore();
2123         SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2124         THREAD-&gt;set_vm_result(NULL);
2125         UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2126       }
2127       CASE(_anewarray): {
2128         u2 index = Bytes::get_Java_u2(pc+1);
2129         jint size = STACK_INT(-1);
2130         CALL_VM(InterpreterRuntime::anewarray(THREAD, METHOD-&gt;constants(), index, size),
2131                 handle_exception);
2132         // Must prevent reordering of stores for object initialization
2133         // with stores that publish the new object.
2134         OrderAccess::storestore();
2135         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -1);
2136         THREAD-&gt;set_vm_result(NULL);
2137         UPDATE_PC_AND_CONTINUE(3);
2138       }
2139       CASE(_multianewarray): {
2140         jint dims = *(pc+3);
2141         jint size = STACK_INT(-1);
2142         // stack grows down, dimensions are up!
2143         jint *dimarray =
2144                    (jint*)&amp;topOfStack[dims * Interpreter::stackElementWords+
2145                                       Interpreter::stackElementWords-1];
2146         //adjust pointer to start of stack element
2147         CALL_VM(InterpreterRuntime::multianewarray(THREAD, dimarray),
2148                 handle_exception);
2149         // Must prevent reordering of stores for object initialization
2150         // with stores that publish the new object.
2151         OrderAccess::storestore();
2152         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -dims);
2153         THREAD-&gt;set_vm_result(NULL);
2154         UPDATE_PC_AND_TOS_AND_CONTINUE(4, -(dims-1));
2155       }
2156       CASE(_checkcast):
2157           if (STACK_OBJECT(-1) != NULL) {
2158             VERIFY_OOP(STACK_OBJECT(-1));
2159             u2 index = Bytes::get_Java_u2(pc+1);
2160             // Constant pool may have actual klass or unresolved klass. If it is
2161             // unresolved we must resolve it.
2162             if (METHOD-&gt;constants()-&gt;tag_at(index).is_unresolved_klass()) {
2163               CALL_VM(InterpreterRuntime::quicken_io_cc(THREAD), handle_exception);
2164             }
2165             Klass* klassOf = (Klass*) METHOD-&gt;constants()-&gt;resolved_klass_at(index);
2166             Klass* objKlass = STACK_OBJECT(-1)-&gt;klass(); // ebx
2167             //
2168             // Check for compatibilty. This check must not GC!!
2169             // Seems way more expensive now that we must dispatch.
2170             //
2171             if (objKlass != klassOf &amp;&amp; !objKlass-&gt;is_subtype_of(klassOf)) {
2172               // Decrement counter at checkcast.
2173               BI_PROFILE_SUBTYPECHECK_FAILED(objKlass);
2174               ResourceMark rm(THREAD);
2175               char* message = SharedRuntime::generate_class_cast_message(
2176                 objKlass, klassOf);
2177               VM_JAVA_ERROR(vmSymbols::java_lang_ClassCastException(), message);
2178             }
2179             // Profile checkcast with null_seen and receiver.
2180             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/false, objKlass);
2181           } else {
2182             // Profile checkcast with null_seen and receiver.
2183             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/true, NULL);
2184           }
2185           UPDATE_PC_AND_CONTINUE(3);
2186 
2187       CASE(_instanceof):
2188           if (STACK_OBJECT(-1) == NULL) {
2189             SET_STACK_INT(0, -1);
2190             // Profile instanceof with null_seen and receiver.
2191             BI_PROFILE_UPDATE_INSTANCEOF(/*null_seen=*/true, NULL);
2192           } else {
2193             VERIFY_OOP(STACK_OBJECT(-1));
2194             u2 index = Bytes::get_Java_u2(pc+1);
2195             // Constant pool may have actual klass or unresolved klass. If it is
2196             // unresolved we must resolve it.
2197             if (METHOD-&gt;constants()-&gt;tag_at(index).is_unresolved_klass()) {
2198               CALL_VM(InterpreterRuntime::quicken_io_cc(THREAD), handle_exception);
2199             }
2200             Klass* klassOf = (Klass*) METHOD-&gt;constants()-&gt;resolved_klass_at(index);
2201             Klass* objKlass = STACK_OBJECT(-1)-&gt;klass();
2202             //
2203             // Check for compatibilty. This check must not GC!!
2204             // Seems way more expensive now that we must dispatch.
2205             //
2206             if ( objKlass == klassOf || objKlass-&gt;is_subtype_of(klassOf)) {
2207               SET_STACK_INT(1, -1);
2208             } else {
2209               SET_STACK_INT(0, -1);
2210               // Decrement counter at checkcast.
2211               BI_PROFILE_SUBTYPECHECK_FAILED(objKlass);
2212             }
2213             // Profile instanceof with null_seen and receiver.
2214             BI_PROFILE_UPDATE_INSTANCEOF(/*null_seen=*/false, objKlass);
2215           }
2216           UPDATE_PC_AND_CONTINUE(3);
2217 
2218       CASE(_ldc_w):
2219       CASE(_ldc):
2220         {
2221           u2 index;
2222           bool wide = false;
2223           int incr = 2; // frequent case
2224           if (opcode == Bytecodes::_ldc) {
2225             index = pc[1];
2226           } else {
2227             index = Bytes::get_Java_u2(pc+1);
2228             incr = 3;
2229             wide = true;
2230           }
2231 
2232           ConstantPool* constants = METHOD-&gt;constants();
2233           switch (constants-&gt;tag_at(index).value()) {
2234           case JVM_CONSTANT_Integer:
2235             SET_STACK_INT(constants-&gt;int_at(index), 0);
2236             break;
2237 
2238           case JVM_CONSTANT_Float:
2239             SET_STACK_FLOAT(constants-&gt;float_at(index), 0);
2240             break;
2241 
2242           case JVM_CONSTANT_String:
2243             {
2244               oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2245               if (result == NULL) {
2246                 CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);
2247                 SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2248                 THREAD-&gt;set_vm_result(NULL);
2249               } else {
2250                 VERIFY_OOP(result);
2251                 SET_STACK_OBJECT(result, 0);
2252               }
2253             break;
2254             }
2255 
2256           case JVM_CONSTANT_Class:
2257             VERIFY_OOP(constants-&gt;resolved_klass_at(index)-&gt;java_mirror());
2258             SET_STACK_OBJECT(constants-&gt;resolved_klass_at(index)-&gt;java_mirror(), 0);
2259             break;
2260 
2261           case JVM_CONSTANT_UnresolvedClass:
2262           case JVM_CONSTANT_UnresolvedClassInError:
2263             CALL_VM(InterpreterRuntime::ldc(THREAD, wide), handle_exception);
2264             SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2265             THREAD-&gt;set_vm_result(NULL);
2266             break;
2267 
2268           case JVM_CONSTANT_Dynamic:
2269             {
2270               CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);
2271               oop result = THREAD-&gt;vm_result();
2272               VERIFY_OOP(result);
2273 
2274               jvalue value;
2275               BasicType type = java_lang_boxing_object::get_value(result, &amp;value);
2276               switch (type) {
2277               case T_FLOAT:   SET_STACK_FLOAT(value.f, 0); break;
2278               case T_INT:     SET_STACK_INT(value.i, 0); break;
2279               case T_SHORT:   SET_STACK_INT(value.s, 0); break;
2280               case T_BYTE:    SET_STACK_INT(value.b, 0); break;
2281               case T_CHAR:    SET_STACK_INT(value.c, 0); break;
2282               case T_BOOLEAN: SET_STACK_INT(value.z, 0); break;
2283               default:  ShouldNotReachHere();
2284               }
2285 
2286               break;
2287             }
2288 
2289           default:  ShouldNotReachHere();
2290           }
2291           UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2292         }
2293 
2294       CASE(_ldc2_w):
2295         {
2296           u2 index = Bytes::get_Java_u2(pc+1);
2297 
2298           ConstantPool* constants = METHOD-&gt;constants();
2299           switch (constants-&gt;tag_at(index).value()) {
2300 
2301           case JVM_CONSTANT_Long:
2302              SET_STACK_LONG(constants-&gt;long_at(index), 1);
2303             break;
2304 
2305           case JVM_CONSTANT_Double:
2306              SET_STACK_DOUBLE(constants-&gt;double_at(index), 1);
2307             break;
2308 
2309           case JVM_CONSTANT_Dynamic:
2310             {
2311               CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);
2312               oop result = THREAD-&gt;vm_result();
2313               VERIFY_OOP(result);
2314 
2315               jvalue value;
2316               BasicType type = java_lang_boxing_object::get_value(result, &amp;value);
2317               switch (type) {
2318               case T_DOUBLE: SET_STACK_DOUBLE(value.d, 1); break;
2319               case T_LONG:   SET_STACK_LONG(value.j, 1); break;
2320               default:  ShouldNotReachHere();
2321               }
2322 
2323               break;
2324             }
2325 
2326           default:  ShouldNotReachHere();
2327           }
2328           UPDATE_PC_AND_TOS_AND_CONTINUE(3, 2);
2329         }
2330 
2331       CASE(_fast_aldc_w):
2332       CASE(_fast_aldc): {
2333         u2 index;
2334         int incr;
2335         if (opcode == Bytecodes::_fast_aldc) {
2336           index = pc[1];
2337           incr = 2;
2338         } else {
2339           index = Bytes::get_native_u2(pc+1);
2340           incr = 3;
2341         }
2342 
2343         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2344         // This kind of CP cache entry does not need to match the flags byte, because
2345         // there is a 1-1 relation between bytecode type and CP entry type.
2346         ConstantPool* constants = METHOD-&gt;constants();
2347         oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2348         if (result == NULL) {
2349           CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode),
2350                   handle_exception);
2351           result = THREAD-&gt;vm_result();
2352         }
2353         if (result == Universe::the_null_sentinel())
2354           result = NULL;
2355 
2356         VERIFY_OOP(result);
2357         SET_STACK_OBJECT(result, 0);
2358         UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2359       }
2360 
2361       CASE(_invokedynamic): {
2362 
2363         u4 index = Bytes::get_native_u4(pc+1);
2364         ConstantPoolCacheEntry* cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2365 
2366         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2367         // This kind of CP cache entry does not need to match the flags byte, because
2368         // there is a 1-1 relation between bytecode type and CP entry type.
2369         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2370           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2371                   handle_exception);
2372           cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2373         }
2374 
2375         Method* method = cache-&gt;f1_as_method();
2376         if (VerifyOops) method-&gt;verify();
2377 
2378         if (cache-&gt;has_appendix()) {
2379           constantPoolHandle cp(THREAD, METHOD-&gt;constants());
2380           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);
2381           MORE_STACK(1);
2382         }
2383 
2384         istate-&gt;set_msg(call_method);
2385         istate-&gt;set_callee(method);
2386         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2387         istate-&gt;set_bcp_advance(5);
2388 
2389         // Invokedynamic has got a call counter, just like an invokestatic -&gt; increment!
2390         BI_PROFILE_UPDATE_CALL();
2391 
2392         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2393       }
2394 
2395       CASE(_invokehandle): {
2396 
2397         u2 index = Bytes::get_native_u2(pc+1);
2398         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2399 
2400         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2401           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2402                   handle_exception);
2403           cache = cp-&gt;entry_at(index);
2404         }
2405 
2406         Method* method = cache-&gt;f1_as_method();
2407         if (VerifyOops) method-&gt;verify();
2408 
2409         if (cache-&gt;has_appendix()) {
2410           constantPoolHandle cp(THREAD, METHOD-&gt;constants());
2411           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);
2412           MORE_STACK(1);
2413         }
2414 
2415         istate-&gt;set_msg(call_method);
2416         istate-&gt;set_callee(method);
2417         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2418         istate-&gt;set_bcp_advance(3);
2419 
2420         // Invokehandle has got a call counter, just like a final call -&gt; increment!
2421         BI_PROFILE_UPDATE_FINALCALL();
2422 
2423         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2424       }
2425 
2426       CASE(_invokeinterface): {
2427         u2 index = Bytes::get_native_u2(pc+1);
2428 
2429         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2430         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2431 
2432         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2433         if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
2434           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2435                   handle_exception);
2436           cache = cp-&gt;entry_at(index);
2437         }
2438 
2439         istate-&gt;set_msg(call_method);
2440 
2441         // Special case of invokeinterface called for virtual method of
2442         // java.lang.Object.  See cpCache.cpp for details.
2443         Method* callee = NULL;
2444         if (cache-&gt;is_forced_virtual()) {
2445           CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2446           if (cache-&gt;is_vfinal()) {
2447             callee = cache-&gt;f2_as_vfinal_method();
2448             // Profile &#39;special case of invokeinterface&#39; final call.
2449             BI_PROFILE_UPDATE_FINALCALL();
2450           } else {
2451             // Get receiver.
2452             int parms = cache-&gt;parameter_size();
2453             // Same comments as invokevirtual apply here.
2454             oop rcvr = STACK_OBJECT(-parms);
2455             VERIFY_OOP(rcvr);
2456             Klass* rcvrKlass = rcvr-&gt;klass();
2457             callee = (Method*) rcvrKlass-&gt;method_at_vtable(cache-&gt;f2_as_index());
2458             // Profile &#39;special case of invokeinterface&#39; virtual call.
2459             BI_PROFILE_UPDATE_VIRTUALCALL(rcvrKlass);
2460           }
2461         } else if (cache-&gt;is_vfinal()) {
2462           // private interface method invocations
2463           //
2464           // Ensure receiver class actually implements
2465           // the resolved interface class. The link resolver
2466           // does this, but only for the first time this
2467           // interface is being called.
2468           int parms = cache-&gt;parameter_size();
2469           oop rcvr = STACK_OBJECT(-parms);
2470           CHECK_NULL(rcvr);
2471           Klass* recv_klass = rcvr-&gt;klass();
2472           Klass* resolved_klass = cache-&gt;f1_as_klass();
2473           if (!recv_klass-&gt;is_subtype_of(resolved_klass)) {
2474             ResourceMark rm(THREAD);
2475             char buf[200];
2476             jio_snprintf(buf, sizeof(buf), &quot;Class %s does not implement the requested interface %s&quot;,
2477               recv_klass-&gt;external_name(),
2478               resolved_klass-&gt;external_name());
2479             VM_JAVA_ERROR(vmSymbols::java_lang_IncompatibleClassChangeError(), buf);
2480           }
2481           callee = cache-&gt;f2_as_vfinal_method();
2482         }
2483         if (callee != NULL) {
2484           istate-&gt;set_callee(callee);
2485           istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2486 #ifdef VM_JVMTI
2487           if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2488             istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2489           }
2490 #endif /* VM_JVMTI */
2491           istate-&gt;set_bcp_advance(5);
2492           UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2493         }
2494 
2495         // this could definitely be cleaned up QQQ
2496         Method *interface_method = cache-&gt;f2_as_interface_method();
2497         InstanceKlass* iclass = interface_method-&gt;method_holder();
2498 
2499         // get receiver
2500         int parms = cache-&gt;parameter_size();
2501         oop rcvr = STACK_OBJECT(-parms);
2502         CHECK_NULL(rcvr);
2503         InstanceKlass* int2 = (InstanceKlass*) rcvr-&gt;klass();
2504 
2505         // Receiver subtype check against resolved interface klass (REFC).
2506         {
2507           Klass* refc = cache-&gt;f1_as_klass();
2508           itableOffsetEntry* scan;
2509           for (scan = (itableOffsetEntry*) int2-&gt;start_of_itable();
2510                scan-&gt;interface_klass() != NULL;
2511                scan++) {
2512             if (scan-&gt;interface_klass() == refc) {
2513               break;
2514             }
2515           }
2516           // Check that the entry is non-null.  A null entry means
2517           // that the receiver class doesn&#39;t implement the
2518           // interface, and wasn&#39;t the same as when the caller was
2519           // compiled.
2520           if (scan-&gt;interface_klass() == NULL) {
2521             VM_JAVA_ERROR(vmSymbols::java_lang_IncompatibleClassChangeError(), &quot;&quot;);
2522           }
2523         }
2524 
2525         itableOffsetEntry* ki = (itableOffsetEntry*) int2-&gt;start_of_itable();
2526         int i;
2527         for ( i = 0 ; i &lt; int2-&gt;itable_length() ; i++, ki++ ) {
2528           if (ki-&gt;interface_klass() == iclass) break;
2529         }
2530         // If the interface isn&#39;t found, this class doesn&#39;t implement this
2531         // interface. The link resolver checks this but only for the first
2532         // time this interface is called.
2533         if (i == int2-&gt;itable_length()) {
2534           CALL_VM(InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(THREAD, rcvr-&gt;klass(), iclass),
2535                   handle_exception);
2536         }
2537         int mindex = interface_method-&gt;itable_index();
2538 
2539         itableMethodEntry* im = ki-&gt;first_method_entry(rcvr-&gt;klass());
2540         callee = im[mindex].method();
2541         if (callee == NULL) {
2542           CALL_VM(InterpreterRuntime::throw_AbstractMethodErrorVerbose(THREAD, rcvr-&gt;klass(), interface_method),
2543                   handle_exception);
2544         }
2545 
2546         // Profile virtual call.
2547         BI_PROFILE_UPDATE_VIRTUALCALL(rcvr-&gt;klass());
2548 
2549         istate-&gt;set_callee(callee);
2550         istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2551 #ifdef VM_JVMTI
2552         if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2553           istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2554         }
2555 #endif /* VM_JVMTI */
2556         istate-&gt;set_bcp_advance(5);
2557         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2558       }
2559 
2560       CASE(_invokevirtual):
2561       CASE(_invokespecial):
2562       CASE(_invokestatic): {
2563         u2 index = Bytes::get_native_u2(pc+1);
2564 
2565         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2566         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2567         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2568 
2569         if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
2570           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2571                   handle_exception);
2572           cache = cp-&gt;entry_at(index);
2573         }
2574 
2575         istate-&gt;set_msg(call_method);
2576         {
2577           Method* callee;
2578           if ((Bytecodes::Code)opcode == Bytecodes::_invokevirtual) {
2579             CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2580             if (cache-&gt;is_vfinal()) {
2581               callee = cache-&gt;f2_as_vfinal_method();
2582               // Profile final call.
2583               BI_PROFILE_UPDATE_FINALCALL();
2584             } else {
2585               // get receiver
2586               int parms = cache-&gt;parameter_size();
2587               // this works but needs a resourcemark and seems to create a vtable on every call:
2588               // Method* callee = rcvr-&gt;klass()-&gt;vtable()-&gt;method_at(cache-&gt;f2_as_index());
2589               //
2590               // this fails with an assert
2591               // InstanceKlass* rcvrKlass = InstanceKlass::cast(STACK_OBJECT(-parms)-&gt;klass());
2592               // but this works
2593               oop rcvr = STACK_OBJECT(-parms);
2594               VERIFY_OOP(rcvr);
2595               Klass* rcvrKlass = rcvr-&gt;klass();
2596               /*
2597                 Executing this code in java.lang.String:
2598                     public String(char value[]) {
2599                           this.count = value.length;
2600                           this.value = (char[])value.clone();
2601                      }
2602 
2603                  a find on rcvr-&gt;klass() reports:
2604                  {type array char}{type array class}
2605                   - klass: {other class}
2606 
2607                   but using InstanceKlass::cast(STACK_OBJECT(-parms)-&gt;klass()) causes in assertion failure
2608                   because rcvr-&gt;klass()-&gt;is_instance_klass() == 0
2609                   However it seems to have a vtable in the right location. Huh?
2610                   Because vtables have the same offset for ArrayKlass and InstanceKlass.
2611               */
2612               callee = (Method*) rcvrKlass-&gt;method_at_vtable(cache-&gt;f2_as_index());
2613               // Profile virtual call.
2614               BI_PROFILE_UPDATE_VIRTUALCALL(rcvrKlass);
2615             }
2616           } else {
2617             if ((Bytecodes::Code)opcode == Bytecodes::_invokespecial) {
2618               CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2619             }
2620             callee = cache-&gt;f1_as_method();
2621 
2622             // Profile call.
2623             BI_PROFILE_UPDATE_CALL();
2624           }
2625 
2626           istate-&gt;set_callee(callee);
2627           istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2628 #ifdef VM_JVMTI
2629           if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2630             istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2631           }
2632 #endif /* VM_JVMTI */
2633           istate-&gt;set_bcp_advance(3);
2634           UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2635         }
2636       }
2637 
2638       /* Allocate memory for a new java object. */
2639 
2640       CASE(_newarray): {
2641         BasicType atype = (BasicType) *(pc+1);
2642         jint size = STACK_INT(-1);
2643         CALL_VM(InterpreterRuntime::newarray(THREAD, atype, size),
2644                 handle_exception);
2645         // Must prevent reordering of stores for object initialization
2646         // with stores that publish the new object.
2647         OrderAccess::storestore();
2648         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -1);
2649         THREAD-&gt;set_vm_result(NULL);
2650 
2651         UPDATE_PC_AND_CONTINUE(2);
2652       }
2653 
2654       /* Throw an exception. */
2655 
2656       CASE(_athrow): {
2657           oop except_oop = STACK_OBJECT(-1);
2658           CHECK_NULL(except_oop);
2659           // set pending_exception so we use common code
2660           THREAD-&gt;set_pending_exception(except_oop, NULL, 0);
2661           goto handle_exception;
2662       }
2663 
2664       /* goto and jsr. They are exactly the same except jsr pushes
2665        * the address of the next instruction first.
2666        */
2667 
2668       CASE(_jsr): {
2669           /* push bytecode index on stack */
2670           SET_STACK_ADDR(((address)pc - (intptr_t)(istate-&gt;method()-&gt;code_base()) + 3), 0);
2671           MORE_STACK(1);
2672           /* FALL THROUGH */
2673       }
2674 
2675       CASE(_goto):
2676       {
2677           int16_t offset = (int16_t)Bytes::get_Java_u2(pc + 1);
2678           // Profile jump.
2679           BI_PROFILE_UPDATE_JUMP();
2680           address branch_pc = pc;
2681           UPDATE_PC(offset);
2682           DO_BACKEDGE_CHECKS(offset, branch_pc);
2683           CONTINUE;
2684       }
2685 
2686       CASE(_jsr_w): {
2687           /* push return address on the stack */
2688           SET_STACK_ADDR(((address)pc - (intptr_t)(istate-&gt;method()-&gt;code_base()) + 5), 0);
2689           MORE_STACK(1);
2690           /* FALL THROUGH */
2691       }
2692 
2693       CASE(_goto_w):
2694       {
2695           int32_t offset = Bytes::get_Java_u4(pc + 1);
2696           // Profile jump.
2697           BI_PROFILE_UPDATE_JUMP();
2698           address branch_pc = pc;
2699           UPDATE_PC(offset);
2700           DO_BACKEDGE_CHECKS(offset, branch_pc);
2701           CONTINUE;
2702       }
2703 
2704       /* return from a jsr or jsr_w */
2705 
2706       CASE(_ret): {
2707           // Profile ret.
2708           BI_PROFILE_UPDATE_RET(/*bci=*/((int)(intptr_t)(LOCALS_ADDR(pc[1]))));
2709           // Now, update the pc.
2710           pc = istate-&gt;method()-&gt;code_base() + (intptr_t)(LOCALS_ADDR(pc[1]));
2711           UPDATE_PC_AND_CONTINUE(0);
2712       }
2713 
2714       /* debugger breakpoint */
2715 
2716       CASE(_breakpoint): {
2717           Bytecodes::Code original_bytecode;
2718           DECACHE_STATE();
2719           SET_LAST_JAVA_FRAME();
2720           original_bytecode = InterpreterRuntime::get_original_bytecode_at(THREAD,
2721                               METHOD, pc);
2722           RESET_LAST_JAVA_FRAME();
2723           CACHE_STATE();
2724           if (THREAD-&gt;has_pending_exception()) goto handle_exception;
2725             CALL_VM(InterpreterRuntime::_breakpoint(THREAD, METHOD, pc),
2726                                                     handle_exception);
2727 
2728           opcode = (jubyte)original_bytecode;
2729           goto opcode_switch;
2730       }
2731 
2732       DEFAULT:
2733           fatal(&quot;Unimplemented opcode %d = %s&quot;, opcode,
2734                 Bytecodes::name((Bytecodes::Code)opcode));
2735           goto finish;
2736 
2737       } /* switch(opc) */
2738 
2739 
2740 #ifdef USELABELS
2741     check_for_exception:
2742 #endif
2743     {
2744       if (!THREAD-&gt;has_pending_exception()) {
2745         CONTINUE;
2746       }
2747       /* We will be gcsafe soon, so flush our state. */
2748       DECACHE_PC();
2749       goto handle_exception;
2750     }
2751   do_continue: ;
2752 
2753   } /* while (1) interpreter loop */
2754 
2755 
2756   // An exception exists in the thread state see whether this activation can handle it
2757   handle_exception: {
2758 
2759     HandleMarkCleaner __hmc(THREAD);
2760     Handle except_oop(THREAD, THREAD-&gt;pending_exception());
2761     // Prevent any subsequent HandleMarkCleaner in the VM
2762     // from freeing the except_oop handle.
2763     HandleMark __hm(THREAD);
2764 
2765     THREAD-&gt;clear_pending_exception();
2766     assert(except_oop() != NULL, &quot;No exception to process&quot;);
2767     intptr_t continuation_bci;
2768     // expression stack is emptied
2769     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2770     CALL_VM(continuation_bci = (intptr_t)InterpreterRuntime::exception_handler_for_exception(THREAD, except_oop()),
2771             handle_exception);
2772 
2773     except_oop = Handle(THREAD, THREAD-&gt;vm_result());
2774     THREAD-&gt;set_vm_result(NULL);
2775     if (continuation_bci &gt;= 0) {
2776       // Place exception on top of stack
2777       SET_STACK_OBJECT(except_oop(), 0);
2778       MORE_STACK(1);
2779       pc = METHOD-&gt;code_base() + continuation_bci;
2780       if (log_is_enabled(Info, exceptions)) {
2781         ResourceMark rm(THREAD);
2782         stringStream tempst;
2783         tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2784                      &quot; at bci %d, continuing at %d for thread &quot; INTPTR_FORMAT,
2785                      METHOD-&gt;print_value_string(),
2786                      (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2787                      (int)continuation_bci, p2i(THREAD));
2788         Exceptions::log_exception(except_oop, tempst.as_string());
2789       }
2790       // for AbortVMOnException flag
2791       Exceptions::debug_check_abort(except_oop);
2792 
2793       // Update profiling data.
2794       BI_PROFILE_ALIGN_TO_CURRENT_BCI();
2795       goto run;
2796     }
2797     if (log_is_enabled(Info, exceptions)) {
2798       ResourceMark rm;
2799       stringStream tempst;
2800       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2801              &quot; at bci %d, unwinding for thread &quot; INTPTR_FORMAT,
2802              METHOD-&gt;print_value_string(),
2803              (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2804              p2i(THREAD));
2805       Exceptions::log_exception(except_oop, tempst.as_string());
2806     }
2807     // for AbortVMOnException flag
2808     Exceptions::debug_check_abort(except_oop);
2809 
2810     // No handler in this activation, unwind and try again
2811     THREAD-&gt;set_pending_exception(except_oop(), NULL, 0);
2812     goto handle_return;
2813   }  // handle_exception:
2814 
2815   // Return from an interpreter invocation with the result of the interpretation
2816   // on the top of the Java Stack (or a pending exception)
2817 
2818   handle_Pop_Frame: {
2819 
2820     // We don&#39;t really do anything special here except we must be aware
2821     // that we can get here without ever locking the method (if sync).
2822     // Also we skip the notification of the exit.
2823 
2824     istate-&gt;set_msg(popping_frame);
2825     // Clear pending so while the pop is in process
2826     // we don&#39;t start another one if a call_vm is done.
2827     THREAD-&gt;clear_popframe_condition();
2828     // Let interpreter (only) see the we&#39;re in the process of popping a frame
2829     THREAD-&gt;set_pop_frame_in_process();
2830 
2831     goto handle_return;
2832 
2833   } // handle_Pop_Frame
2834 
2835   // ForceEarlyReturn ends a method, and returns to the caller with a return value
2836   // given by the invoker of the early return.
2837   handle_Early_Return: {
2838 
2839     istate-&gt;set_msg(early_return);
2840 
2841     // Clear expression stack.
2842     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2843 
2844     JvmtiThreadState *ts = THREAD-&gt;jvmti_thread_state();
2845 
2846     // Push the value to be returned.
2847     switch (istate-&gt;method()-&gt;result_type()) {
2848       case T_BOOLEAN:
2849       case T_SHORT:
2850       case T_BYTE:
2851       case T_CHAR:
2852       case T_INT:
2853         SET_STACK_INT(ts-&gt;earlyret_value().i, 0);
2854         MORE_STACK(1);
2855         break;
2856       case T_LONG:
2857         SET_STACK_LONG(ts-&gt;earlyret_value().j, 1);
2858         MORE_STACK(2);
2859         break;
2860       case T_FLOAT:
2861         SET_STACK_FLOAT(ts-&gt;earlyret_value().f, 0);
2862         MORE_STACK(1);
2863         break;
2864       case T_DOUBLE:
2865         SET_STACK_DOUBLE(ts-&gt;earlyret_value().d, 1);
2866         MORE_STACK(2);
2867         break;
2868       case T_ARRAY:
2869       case T_OBJECT:
2870         SET_STACK_OBJECT(ts-&gt;earlyret_oop(), 0);
2871         MORE_STACK(1);
2872         break;
2873     }
2874 
2875     ts-&gt;clr_earlyret_value();
2876     ts-&gt;set_earlyret_oop(NULL);
2877     ts-&gt;clr_earlyret_pending();
2878 
2879     // Fall through to handle_return.
2880 
2881   } // handle_Early_Return
2882 
2883   handle_return: {
2884     // A storestore barrier is required to order initialization of
2885     // final fields with publishing the reference to the object that
2886     // holds the field. Without the barrier the value of final fields
2887     // can be observed to change.
2888     OrderAccess::storestore();
2889 
2890     DECACHE_STATE();
2891 
2892     bool suppress_error = istate-&gt;msg() == popping_frame || istate-&gt;msg() == early_return;
2893     bool suppress_exit_event = THREAD-&gt;has_pending_exception() || istate-&gt;msg() == popping_frame;
2894     Handle original_exception(THREAD, THREAD-&gt;pending_exception());
2895     Handle illegal_state_oop(THREAD, NULL);
2896 
2897     // We&#39;d like a HandleMark here to prevent any subsequent HandleMarkCleaner
2898     // in any following VM entries from freeing our live handles, but illegal_state_oop
2899     // isn&#39;t really allocated yet and so doesn&#39;t become live until later and
2900     // in unpredicatable places. Instead we must protect the places where we enter the
2901     // VM. It would be much simpler (and safer) if we could allocate a real handle with
2902     // a NULL oop in it and then overwrite the oop later as needed. This isn&#39;t
2903     // unfortunately isn&#39;t possible.
2904 
2905     THREAD-&gt;clear_pending_exception();
2906 
2907     //
2908     // As far as we are concerned we have returned. If we have a pending exception
2909     // that will be returned as this invocation&#39;s result. However if we get any
2910     // exception(s) while checking monitor state one of those IllegalMonitorStateExceptions
2911     // will be our final result (i.e. monitor exception trumps a pending exception).
2912     //
2913 
2914     // If we never locked the method (or really passed the point where we would have),
2915     // there is no need to unlock it (or look for other monitors), since that
2916     // could not have happened.
2917 
2918     if (THREAD-&gt;do_not_unlock()) {
2919 
2920       // Never locked, reset the flag now because obviously any caller must
2921       // have passed their point of locking for us to have gotten here.
2922 
2923       THREAD-&gt;clr_do_not_unlock();
2924     } else {
2925       // At this point we consider that we have returned. We now check that the
2926       // locks were properly block structured. If we find that they were not
2927       // used properly we will return with an illegal monitor exception.
2928       // The exception is checked by the caller not the callee since this
2929       // checking is considered to be part of the invocation and therefore
2930       // in the callers scope (JVM spec 8.13).
2931       //
2932       // Another weird thing to watch for is if the method was locked
2933       // recursively and then not exited properly. This means we must
2934       // examine all the entries in reverse time(and stack) order and
2935       // unlock as we find them. If we find the method monitor before
2936       // we are at the initial entry then we should throw an exception.
2937       // It is not clear the template based interpreter does this
2938       // correctly
2939 
2940       BasicObjectLock* base = istate-&gt;monitor_base();
2941       BasicObjectLock* end = (BasicObjectLock*) istate-&gt;stack_base();
2942       bool method_unlock_needed = METHOD-&gt;is_synchronized();
2943       // We know the initial monitor was used for the method don&#39;t check that
2944       // slot in the loop
2945       if (method_unlock_needed) base--;
2946 
2947       // Check all the monitors to see they are unlocked. Install exception if found to be locked.
2948       while (end &lt; base) {
2949         oop lockee = end-&gt;obj();
2950         if (lockee != NULL) {
2951           BasicLock* lock = end-&gt;lock();
2952           markWord header = lock-&gt;displaced_header();
2953           end-&gt;set_obj(NULL);
2954 
2955           if (!lockee-&gt;mark().has_bias_pattern()) {
2956             // If it isn&#39;t recursive we either must swap old header or call the runtime
2957             if (header.to_pointer() != NULL) {
2958               markWord old_header = markWord::encode(lock);
2959               if (lockee-&gt;cas_set_mark(header, old_header) != old_header) {
2960                 // restore object for the slow case
2961                 end-&gt;set_obj(lockee);
2962                 {
2963                   // Prevent any HandleMarkCleaner from freeing our live handles
2964                   HandleMark __hm(THREAD);
2965                   CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, end));
2966                 }
2967               }
2968             }
2969           }
2970           // One error is plenty
2971           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
2972             {
2973               // Prevent any HandleMarkCleaner from freeing our live handles
2974               HandleMark __hm(THREAD);
2975               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
2976             }
2977             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
2978             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
2979             THREAD-&gt;clear_pending_exception();
2980           }
2981         }
2982         end++;
2983       }
2984       // Unlock the method if needed
2985       if (method_unlock_needed) {
2986         if (base-&gt;obj() == NULL) {
2987           // The method is already unlocked this is not good.
2988           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
2989             {
2990               // Prevent any HandleMarkCleaner from freeing our live handles
2991               HandleMark __hm(THREAD);
2992               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
2993             }
2994             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
2995             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
2996             THREAD-&gt;clear_pending_exception();
2997           }
2998         } else {
2999           //
3000           // The initial monitor is always used for the method
3001           // However if that slot is no longer the oop for the method it was unlocked
3002           // and reused by something that wasn&#39;t unlocked!
3003           //
3004           // deopt can come in with rcvr dead because c2 knows
3005           // its value is preserved in the monitor. So we can&#39;t use locals[0] at all
3006           // and must use first monitor slot.
3007           //
3008           oop rcvr = base-&gt;obj();
3009           if (rcvr == NULL) {
3010             if (!suppress_error) {
3011               VM_JAVA_ERROR_NO_JUMP(vmSymbols::java_lang_NullPointerException(), &quot;&quot;);
3012               illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3013               THREAD-&gt;clear_pending_exception();
3014             }
3015           } else if (UseHeavyMonitors) {
3016             {
3017               // Prevent any HandleMarkCleaner from freeing our live handles.
3018               HandleMark __hm(THREAD);
3019               CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3020             }
3021             if (THREAD-&gt;has_pending_exception()) {
3022               if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3023               THREAD-&gt;clear_pending_exception();
3024             }
3025           } else {
3026             BasicLock* lock = base-&gt;lock();
3027             markWord header = lock-&gt;displaced_header();
3028             base-&gt;set_obj(NULL);
3029 
3030             if (!rcvr-&gt;mark().has_bias_pattern()) {
3031               base-&gt;set_obj(NULL);
3032               // If it isn&#39;t recursive we either must swap old header or call the runtime
3033               if (header.to_pointer() != NULL) {
3034                 markWord old_header = markWord::encode(lock);
3035                 if (rcvr-&gt;cas_set_mark(header, old_header) != old_header) {
3036                   // restore object for the slow case
3037                   base-&gt;set_obj(rcvr);
3038                   {
3039                     // Prevent any HandleMarkCleaner from freeing our live handles
3040                     HandleMark __hm(THREAD);
3041                     CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3042                   }
3043                   if (THREAD-&gt;has_pending_exception()) {
3044                     if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3045                     THREAD-&gt;clear_pending_exception();
3046                   }
3047                 }
3048               }
3049             }
3050           }
3051         }
3052       }
3053     }
3054     // Clear the do_not_unlock flag now.
3055     THREAD-&gt;clr_do_not_unlock();
3056 
3057     //
3058     // Notify jvmti/jvmdi
3059     //
3060     // NOTE: we do not notify a method_exit if we have a pending exception,
3061     // including an exception we generate for unlocking checks.  In the former
3062     // case, JVMDI has already been notified by our call for the exception handler
3063     // and in both cases as far as JVMDI is concerned we have already returned.
3064     // If we notify it again JVMDI will be all confused about how many frames
3065     // are still on the stack (4340444).
3066     //
3067     // NOTE Further! It turns out the the JVMTI spec in fact expects to see
3068     // method_exit events whenever we leave an activation unless it was done
3069     // for popframe. This is nothing like jvmdi. However we are passing the
3070     // tests at the moment (apparently because they are jvmdi based) so rather
3071     // than change this code and possibly fail tests we will leave it alone
3072     // (with this note) in anticipation of changing the vm and the tests
3073     // simultaneously.
3074 
3075 
3076     //
3077     suppress_exit_event = suppress_exit_event || illegal_state_oop() != NULL;
3078 
3079 
3080 
3081 #ifdef VM_JVMTI
3082       if (_jvmti_interp_events) {
3083         // Whenever JVMTI puts a thread in interp_only_mode, method
3084         // entry/exit events are sent for that thread to track stack depth.
3085         if ( !suppress_exit_event &amp;&amp; THREAD-&gt;is_interp_only_mode() ) {
3086           {
3087             // Prevent any HandleMarkCleaner from freeing our live handles
3088             HandleMark __hm(THREAD);
3089             CALL_VM_NOCHECK(InterpreterRuntime::post_method_exit(THREAD));
3090           }
3091         }
3092       }
3093 #endif /* VM_JVMTI */
3094 
3095     //
3096     // See if we are returning any exception
3097     // A pending exception that was pending prior to a possible popping frame
3098     // overrides the popping frame.
3099     //
3100     assert(!suppress_error || (suppress_error &amp;&amp; illegal_state_oop() == NULL), &quot;Error was not suppressed&quot;);
3101     if (illegal_state_oop() != NULL || original_exception() != NULL) {
3102       // Inform the frame manager we have no result.
3103       istate-&gt;set_msg(throwing_exception);
3104       if (illegal_state_oop() != NULL)
3105         THREAD-&gt;set_pending_exception(illegal_state_oop(), NULL, 0);
3106       else
3107         THREAD-&gt;set_pending_exception(original_exception(), NULL, 0);
3108       UPDATE_PC_AND_RETURN(0);
3109     }
3110 
3111     if (istate-&gt;msg() == popping_frame) {
3112       // Make it simpler on the assembly code and set the message for the frame pop.
3113       // returns
3114       if (istate-&gt;prev() == NULL) {
3115         // We must be returning to a deoptimized frame (because popframe only happens between
3116         // two interpreted frames). We need to save the current arguments in C heap so that
3117         // the deoptimized frame when it restarts can copy the arguments to its expression
3118         // stack and re-execute the call. We also have to notify deoptimization that this
3119         // has occurred and to pick the preserved args copy them to the deoptimized frame&#39;s
3120         // java expression stack. Yuck.
3121         //
3122         THREAD-&gt;popframe_preserve_args(in_ByteSize(METHOD-&gt;size_of_parameters() * wordSize),
3123                                 LOCALS_SLOT(METHOD-&gt;size_of_parameters() - 1));
3124         THREAD-&gt;set_popframe_condition_bit(JavaThread::popframe_force_deopt_reexecution_bit);
3125       }
3126     } else {
3127       istate-&gt;set_msg(return_from_method);
3128     }
3129 
3130     // Normal return
3131     // Advance the pc and return to frame manager
3132     UPDATE_PC_AND_RETURN(1);
3133   } /* handle_return: */
3134 
3135 // This is really a fatal error return
3136 
3137 finish:
3138   DECACHE_TOS();
3139   DECACHE_PC();
3140 
3141   return;
3142 }
3143 
3144 /*
3145  * All the code following this point is only produced once and is not present
3146  * in the JVMTI version of the interpreter
3147 */
3148 
3149 #ifndef VM_JVMTI
3150 
3151 // This constructor should only be used to contruct the object to signal
3152 // interpreter initialization. All other instances should be created by
3153 // the frame manager.
3154 BytecodeInterpreter::BytecodeInterpreter(messages msg) {
3155   if (msg != initialize) ShouldNotReachHere();
3156   _msg = msg;
3157   _self_link = this;
3158   _prev_link = NULL;
3159 }
3160 
3161 // Inline static functions for Java Stack and Local manipulation
3162 
3163 // The implementations are platform dependent. We have to worry about alignment
3164 // issues on some machines which can change on the same platform depending on
3165 // whether it is an LP64 machine also.
3166 address BytecodeInterpreter::stack_slot(intptr_t *tos, int offset) {
3167   return (address) tos[Interpreter::expr_index_at(-offset)];
3168 }
3169 
3170 jint BytecodeInterpreter::stack_int(intptr_t *tos, int offset) {
3171   return *((jint*) &amp;tos[Interpreter::expr_index_at(-offset)]);
3172 }
3173 
3174 jfloat BytecodeInterpreter::stack_float(intptr_t *tos, int offset) {
3175   return *((jfloat *) &amp;tos[Interpreter::expr_index_at(-offset)]);
3176 }
3177 
3178 oop BytecodeInterpreter::stack_object(intptr_t *tos, int offset) {
3179   return cast_to_oop(tos [Interpreter::expr_index_at(-offset)]);
3180 }
3181 
3182 jdouble BytecodeInterpreter::stack_double(intptr_t *tos, int offset) {
3183   return ((VMJavaVal64*) &amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d;
3184 }
3185 
3186 jlong BytecodeInterpreter::stack_long(intptr_t *tos, int offset) {
3187   return ((VMJavaVal64 *) &amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l;
3188 }
3189 
3190 // only used for value types
3191 void BytecodeInterpreter::set_stack_slot(intptr_t *tos, address value,
3192                                                         int offset) {
3193   *((address *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3194 }
3195 
3196 void BytecodeInterpreter::set_stack_int(intptr_t *tos, int value,
3197                                                        int offset) {
3198   *((jint *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3199 }
3200 
3201 void BytecodeInterpreter::set_stack_float(intptr_t *tos, jfloat value,
3202                                                          int offset) {
3203   *((jfloat *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3204 }
3205 
3206 void BytecodeInterpreter::set_stack_object(intptr_t *tos, oop value,
3207                                                           int offset) {
3208   *((oop *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3209 }
3210 
3211 // needs to be platform dep for the 32 bit platforms.
3212 void BytecodeInterpreter::set_stack_double(intptr_t *tos, jdouble value,
3213                                                           int offset) {
3214   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d = value;
3215 }
3216 
3217 void BytecodeInterpreter::set_stack_double_from_addr(intptr_t *tos,
3218                                               address addr, int offset) {
3219   (((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d =
3220                         ((VMJavaVal64*)addr)-&gt;d);
3221 }
3222 
3223 void BytecodeInterpreter::set_stack_long(intptr_t *tos, jlong value,
3224                                                         int offset) {
3225   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset+1)])-&gt;l = 0xdeedbeeb;
3226   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l = value;
3227 }
3228 
3229 void BytecodeInterpreter::set_stack_long_from_addr(intptr_t *tos,
3230                                             address addr, int offset) {
3231   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset+1)])-&gt;l = 0xdeedbeeb;
3232   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l =
3233                         ((VMJavaVal64*)addr)-&gt;l;
3234 }
3235 
3236 // Locals
3237 
3238 address BytecodeInterpreter::locals_slot(intptr_t* locals, int offset) {
3239   return (address)locals[Interpreter::local_index_at(-offset)];
3240 }
3241 jint BytecodeInterpreter::locals_int(intptr_t* locals, int offset) {
3242   return (jint)locals[Interpreter::local_index_at(-offset)];
3243 }
3244 jfloat BytecodeInterpreter::locals_float(intptr_t* locals, int offset) {
3245   return (jfloat)locals[Interpreter::local_index_at(-offset)];
3246 }
3247 oop BytecodeInterpreter::locals_object(intptr_t* locals, int offset) {
3248   return cast_to_oop(locals[Interpreter::local_index_at(-offset)]);
3249 }
3250 jdouble BytecodeInterpreter::locals_double(intptr_t* locals, int offset) {
3251   return ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d;
3252 }
3253 jlong BytecodeInterpreter::locals_long(intptr_t* locals, int offset) {
3254   return ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l;
3255 }
3256 
3257 // Returns the address of locals value.
3258 address BytecodeInterpreter::locals_long_at(intptr_t* locals, int offset) {
3259   return ((address)&amp;locals[Interpreter::local_index_at(-(offset+1))]);
3260 }
3261 address BytecodeInterpreter::locals_double_at(intptr_t* locals, int offset) {
3262   return ((address)&amp;locals[Interpreter::local_index_at(-(offset+1))]);
3263 }
3264 
3265 // Used for local value or returnAddress
3266 void BytecodeInterpreter::set_locals_slot(intptr_t *locals,
3267                                    address value, int offset) {
3268   *((address*)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3269 }
3270 void BytecodeInterpreter::set_locals_int(intptr_t *locals,
3271                                    jint value, int offset) {
3272   *((jint *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3273 }
3274 void BytecodeInterpreter::set_locals_float(intptr_t *locals,
3275                                    jfloat value, int offset) {
3276   *((jfloat *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3277 }
3278 void BytecodeInterpreter::set_locals_object(intptr_t *locals,
3279                                    oop value, int offset) {
3280   *((oop *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3281 }
3282 void BytecodeInterpreter::set_locals_double(intptr_t *locals,
3283                                    jdouble value, int offset) {
3284   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d = value;
3285 }
3286 void BytecodeInterpreter::set_locals_long(intptr_t *locals,
3287                                    jlong value, int offset) {
3288   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l = value;
3289 }
3290 void BytecodeInterpreter::set_locals_double_from_addr(intptr_t *locals,
3291                                    address addr, int offset) {
3292   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d = ((VMJavaVal64*)addr)-&gt;d;
3293 }
3294 void BytecodeInterpreter::set_locals_long_from_addr(intptr_t *locals,
3295                                    address addr, int offset) {
3296   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l = ((VMJavaVal64*)addr)-&gt;l;
3297 }
3298 
3299 void BytecodeInterpreter::astore(intptr_t* tos,    int stack_offset,
3300                           intptr_t* locals, int locals_offset) {
3301   intptr_t value = tos[Interpreter::expr_index_at(-stack_offset)];
3302   locals[Interpreter::local_index_at(-locals_offset)] = value;
3303 }
3304 
3305 
3306 void BytecodeInterpreter::copy_stack_slot(intptr_t *tos, int from_offset,
3307                                    int to_offset) {
3308   tos[Interpreter::expr_index_at(-to_offset)] =
3309                       (intptr_t)tos[Interpreter::expr_index_at(-from_offset)];
3310 }
3311 
3312 void BytecodeInterpreter::dup(intptr_t *tos) {
3313   copy_stack_slot(tos, -1, 0);
3314 }
3315 void BytecodeInterpreter::dup2(intptr_t *tos) {
3316   copy_stack_slot(tos, -2, 0);
3317   copy_stack_slot(tos, -1, 1);
3318 }
3319 
3320 void BytecodeInterpreter::dup_x1(intptr_t *tos) {
3321   /* insert top word two down */
3322   copy_stack_slot(tos, -1, 0);
3323   copy_stack_slot(tos, -2, -1);
3324   copy_stack_slot(tos, 0, -2);
3325 }
3326 
3327 void BytecodeInterpreter::dup_x2(intptr_t *tos) {
3328   /* insert top word three down  */
3329   copy_stack_slot(tos, -1, 0);
3330   copy_stack_slot(tos, -2, -1);
3331   copy_stack_slot(tos, -3, -2);
3332   copy_stack_slot(tos, 0, -3);
3333 }
3334 void BytecodeInterpreter::dup2_x1(intptr_t *tos) {
3335   /* insert top 2 slots three down */
3336   copy_stack_slot(tos, -1, 1);
3337   copy_stack_slot(tos, -2, 0);
3338   copy_stack_slot(tos, -3, -1);
3339   copy_stack_slot(tos, 1, -2);
3340   copy_stack_slot(tos, 0, -3);
3341 }
3342 void BytecodeInterpreter::dup2_x2(intptr_t *tos) {
3343   /* insert top 2 slots four down */
3344   copy_stack_slot(tos, -1, 1);
3345   copy_stack_slot(tos, -2, 0);
3346   copy_stack_slot(tos, -3, -1);
3347   copy_stack_slot(tos, -4, -2);
3348   copy_stack_slot(tos, 1, -3);
3349   copy_stack_slot(tos, 0, -4);
3350 }
3351 
3352 
3353 void BytecodeInterpreter::swap(intptr_t *tos) {
3354   // swap top two elements
3355   intptr_t val = tos[Interpreter::expr_index_at(1)];
3356   // Copy -2 entry to -1
3357   copy_stack_slot(tos, -2, -1);
3358   // Store saved -1 entry into -2
3359   tos[Interpreter::expr_index_at(2)] = val;
3360 }
3361 // --------------------------------------------------------------------------------
3362 // Non-product code
3363 #ifndef PRODUCT
3364 
3365 const char* BytecodeInterpreter::C_msg(BytecodeInterpreter::messages msg) {
3366   switch (msg) {
3367      case BytecodeInterpreter::no_request:  return(&quot;no_request&quot;);
3368      case BytecodeInterpreter::initialize:  return(&quot;initialize&quot;);
3369      // status message to C++ interpreter
3370      case BytecodeInterpreter::method_entry:  return(&quot;method_entry&quot;);
3371      case BytecodeInterpreter::method_resume:  return(&quot;method_resume&quot;);
3372      case BytecodeInterpreter::got_monitors:  return(&quot;got_monitors&quot;);
3373      case BytecodeInterpreter::rethrow_exception:  return(&quot;rethrow_exception&quot;);
3374      // requests to frame manager from C++ interpreter
3375      case BytecodeInterpreter::call_method:  return(&quot;call_method&quot;);
3376      case BytecodeInterpreter::return_from_method:  return(&quot;return_from_method&quot;);
3377      case BytecodeInterpreter::more_monitors:  return(&quot;more_monitors&quot;);
3378      case BytecodeInterpreter::throwing_exception:  return(&quot;throwing_exception&quot;);
3379      case BytecodeInterpreter::popping_frame:  return(&quot;popping_frame&quot;);
3380      case BytecodeInterpreter::do_osr:  return(&quot;do_osr&quot;);
3381      // deopt
3382      case BytecodeInterpreter::deopt_resume:  return(&quot;deopt_resume&quot;);
3383      case BytecodeInterpreter::deopt_resume2:  return(&quot;deopt_resume2&quot;);
3384      default: return(&quot;BAD MSG&quot;);
3385   }
3386 }
3387 void
3388 BytecodeInterpreter::print() {
3389   tty-&gt;print_cr(&quot;thread: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_thread);
3390   tty-&gt;print_cr(&quot;bcp: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_bcp);
3391   tty-&gt;print_cr(&quot;locals: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_locals);
3392   tty-&gt;print_cr(&quot;constants: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_constants);
3393   {
3394     ResourceMark rm;
3395     char *method_name = _method-&gt;name_and_sig_as_C_string();
3396     tty-&gt;print_cr(&quot;method: &quot; INTPTR_FORMAT &quot;[ %s ]&quot;,  (uintptr_t) this-&gt;_method, method_name);
3397   }
3398   tty-&gt;print_cr(&quot;mdx: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_mdx);
3399   tty-&gt;print_cr(&quot;stack: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack);
3400   tty-&gt;print_cr(&quot;msg: %s&quot;, C_msg(this-&gt;_msg));
3401   tty-&gt;print_cr(&quot;result_to_call._callee: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._to_call._callee);
3402   tty-&gt;print_cr(&quot;result_to_call._callee_entry_point: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._to_call._callee_entry_point);
3403   tty-&gt;print_cr(&quot;result_to_call._bcp_advance: %d &quot;, this-&gt;_result._to_call._bcp_advance);
3404   tty-&gt;print_cr(&quot;osr._osr_buf: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._osr._osr_buf);
3405   tty-&gt;print_cr(&quot;osr._osr_entry: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._osr._osr_entry);
3406   tty-&gt;print_cr(&quot;prev_link: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_prev_link);
3407   tty-&gt;print_cr(&quot;native_mirror: &quot; INTPTR_FORMAT, (uintptr_t) p2i(this-&gt;_oop_temp));
3408   tty-&gt;print_cr(&quot;stack_base: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack_base);
3409   tty-&gt;print_cr(&quot;stack_limit: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack_limit);
3410   tty-&gt;print_cr(&quot;monitor_base: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_monitor_base);
3411   tty-&gt;print_cr(&quot;self_link: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_self_link);
3412 }
3413 
3414 extern &quot;C&quot; {
3415   void PI(uintptr_t arg) {
3416     ((BytecodeInterpreter*)arg)-&gt;print();
3417   }
3418 }
3419 #endif // PRODUCT
3420 
3421 #endif // JVMTI
    </pre>
  </body>
</html>