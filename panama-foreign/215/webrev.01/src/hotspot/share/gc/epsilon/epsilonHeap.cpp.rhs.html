<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/epsilon/epsilonHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2017, 2020, Red Hat, Inc. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/epsilon/epsilonHeap.hpp&quot;
 27 #include &quot;gc/epsilon/epsilonInitLogger.hpp&quot;
 28 #include &quot;gc/epsilon/epsilonMemoryPool.hpp&quot;
 29 #include &quot;gc/epsilon/epsilonThreadLocalData.hpp&quot;
 30 #include &quot;gc/shared/gcArguments.hpp&quot;
 31 #include &quot;gc/shared/locationPrinter.inline.hpp&quot;
 32 #include &quot;memory/allocation.hpp&quot;
 33 #include &quot;memory/allocation.inline.hpp&quot;
 34 #include &quot;memory/resourceArea.hpp&quot;
 35 #include &quot;memory/universe.hpp&quot;
 36 #include &quot;runtime/atomic.hpp&quot;
 37 #include &quot;runtime/globals.hpp&quot;
 38 
 39 jint EpsilonHeap::initialize() {
 40   size_t align = HeapAlignment;
 41   size_t init_byte_size = align_up(InitialHeapSize, align);
 42   size_t max_byte_size  = align_up(MaxHeapSize, align);
 43 
 44   // Initialize backing storage
 45   ReservedHeapSpace heap_rs = Universe::reserve_heap(max_byte_size, align);
 46   _virtual_space.initialize(heap_rs, init_byte_size);
 47 
 48   MemRegion committed_region((HeapWord*)_virtual_space.low(),          (HeapWord*)_virtual_space.high());
 49   MemRegion  reserved_region((HeapWord*)_virtual_space.low_boundary(), (HeapWord*)_virtual_space.high_boundary());
 50 
 51   initialize_reserved_region(heap_rs);
 52 
 53   _space = new ContiguousSpace();
 54   _space-&gt;initialize(committed_region, /* clear_space = */ true, /* mangle_space = */ true);
 55 
 56   // Precompute hot fields
 57   _max_tlab_size = MIN2(CollectedHeap::max_tlab_size(), align_object_size(EpsilonMaxTLABSize / HeapWordSize));
 58   _step_counter_update = MIN2&lt;size_t&gt;(max_byte_size / 16, EpsilonUpdateCountersStep);
 59   _step_heap_print = (EpsilonPrintHeapSteps == 0) ? SIZE_MAX : (max_byte_size / EpsilonPrintHeapSteps);
 60   _decay_time_ns = (int64_t) EpsilonTLABDecayTime * NANOSECS_PER_MILLISEC;
 61 
 62   // Enable monitoring
 63   _monitoring_support = new EpsilonMonitoringSupport(this);
 64   _last_counter_update = 0;
 65   _last_heap_print = 0;
 66 
 67   // Install barrier set
 68   BarrierSet::set_barrier_set(new EpsilonBarrierSet());
 69 
 70   // All done, print out the configuration
 71   EpsilonInitLogger::print();
 72 
 73   return JNI_OK;
 74 }
 75 
 76 void EpsilonHeap::post_initialize() {
 77   CollectedHeap::post_initialize();
 78 }
 79 
 80 void EpsilonHeap::initialize_serviceability() {
 81   _pool = new EpsilonMemoryPool(this);
 82   _memory_manager.add_pool(_pool);
 83 }
 84 
 85 GrowableArray&lt;GCMemoryManager*&gt; EpsilonHeap::memory_managers() {
 86   GrowableArray&lt;GCMemoryManager*&gt; memory_managers(1);
 87   memory_managers.append(&amp;_memory_manager);
 88   return memory_managers;
 89 }
 90 
 91 GrowableArray&lt;MemoryPool*&gt; EpsilonHeap::memory_pools() {
 92   GrowableArray&lt;MemoryPool*&gt; memory_pools(1);
 93   memory_pools.append(_pool);
 94   return memory_pools;
 95 }
 96 
 97 size_t EpsilonHeap::unsafe_max_tlab_alloc(Thread* thr) const {
 98   // Return max allocatable TLAB size, and let allocation path figure out
 99   // the actual allocation size. Note: result should be in bytes.
100   return _max_tlab_size * HeapWordSize;
101 }
102 
103 EpsilonHeap* EpsilonHeap::heap() {
<a name="2" id="anc2"></a><span class="line-modified">104   return named_heap&lt;EpsilonHeap&gt;(CollectedHeap::Epsilon);</span>



105 }
106 
107 HeapWord* EpsilonHeap::allocate_work(size_t size) {
108   assert(is_object_aligned(size), &quot;Allocation size should be aligned: &quot; SIZE_FORMAT, size);
109 
110   HeapWord* res = _space-&gt;par_allocate(size);
111 
112   while (res == NULL) {
113     // Allocation failed, attempt expansion, and retry:
114     MutexLocker ml(Heap_lock);
115 
116     size_t space_left = max_capacity() - capacity();
117     size_t want_space = MAX2(size, EpsilonMinHeapExpand);
118 
119     if (want_space &lt; space_left) {
120       // Enough space to expand in bulk:
121       bool expand = _virtual_space.expand_by(want_space);
122       assert(expand, &quot;Should be able to expand&quot;);
123     } else if (size &lt; space_left) {
124       // No space to expand in bulk, and this allocation is still possible,
125       // take all the remaining space:
126       bool expand = _virtual_space.expand_by(space_left);
127       assert(expand, &quot;Should be able to expand&quot;);
128     } else {
129       // No space left:
130       return NULL;
131     }
132 
133     _space-&gt;set_end((HeapWord *) _virtual_space.high());
134     res = _space-&gt;par_allocate(size);
135   }
136 
137   size_t used = _space-&gt;used();
138 
139   // Allocation successful, update counters
140   {
141     size_t last = _last_counter_update;
142     if ((used - last &gt;= _step_counter_update) &amp;&amp; Atomic::cmpxchg(&amp;_last_counter_update, last, used) == last) {
143       _monitoring_support-&gt;update_counters();
144     }
145   }
146 
147   // ...and print the occupancy line, if needed
148   {
149     size_t last = _last_heap_print;
150     if ((used - last &gt;= _step_heap_print) &amp;&amp; Atomic::cmpxchg(&amp;_last_heap_print, last, used) == last) {
151       print_heap_info(used);
152       print_metaspace_info();
153     }
154   }
155 
156   assert(is_object_aligned(res), &quot;Object should be aligned: &quot; PTR_FORMAT, p2i(res));
157   return res;
158 }
159 
160 HeapWord* EpsilonHeap::allocate_new_tlab(size_t min_size,
161                                          size_t requested_size,
162                                          size_t* actual_size) {
163   Thread* thread = Thread::current();
164 
165   // Defaults in case elastic paths are not taken
166   bool fits = true;
167   size_t size = requested_size;
168   size_t ergo_tlab = requested_size;
169   int64_t time = 0;
170 
171   if (EpsilonElasticTLAB) {
172     ergo_tlab = EpsilonThreadLocalData::ergo_tlab_size(thread);
173 
174     if (EpsilonElasticTLABDecay) {
175       int64_t last_time = EpsilonThreadLocalData::last_tlab_time(thread);
176       time = (int64_t) os::javaTimeNanos();
177 
178       assert(last_time &lt;= time, &quot;time should be monotonic&quot;);
179 
180       // If the thread had not allocated recently, retract the ergonomic size.
181       // This conserves memory when the thread had initial burst of allocations,
182       // and then started allocating only sporadically.
183       if (last_time != 0 &amp;&amp; (time - last_time &gt; _decay_time_ns)) {
184         ergo_tlab = 0;
185         EpsilonThreadLocalData::set_ergo_tlab_size(thread, 0);
186       }
187     }
188 
189     // If we can fit the allocation under current TLAB size, do so.
190     // Otherwise, we want to elastically increase the TLAB size.
191     fits = (requested_size &lt;= ergo_tlab);
192     if (!fits) {
193       size = (size_t) (ergo_tlab * EpsilonTLABElasticity);
194     }
195   }
196 
197   // Always honor boundaries
198   size = clamp(size, min_size, _max_tlab_size);
199 
200   // Always honor alignment
201   size = align_up(size, MinObjAlignment);
202 
203   // Check that adjustments did not break local and global invariants
204   assert(is_object_aligned(size),
205          &quot;Size honors object alignment: &quot; SIZE_FORMAT, size);
206   assert(min_size &lt;= size,
207          &quot;Size honors min size: &quot;  SIZE_FORMAT &quot; &lt;= &quot; SIZE_FORMAT, min_size, size);
208   assert(size &lt;= _max_tlab_size,
209          &quot;Size honors max size: &quot;  SIZE_FORMAT &quot; &lt;= &quot; SIZE_FORMAT, size, _max_tlab_size);
210   assert(size &lt;= CollectedHeap::max_tlab_size(),
211          &quot;Size honors global max size: &quot;  SIZE_FORMAT &quot; &lt;= &quot; SIZE_FORMAT, size, CollectedHeap::max_tlab_size());
212 
213   if (log_is_enabled(Trace, gc)) {
214     ResourceMark rm;
215     log_trace(gc)(&quot;TLAB size for \&quot;%s\&quot; (Requested: &quot; SIZE_FORMAT &quot;K, Min: &quot; SIZE_FORMAT
216                           &quot;K, Max: &quot; SIZE_FORMAT &quot;K, Ergo: &quot; SIZE_FORMAT &quot;K) -&gt; &quot; SIZE_FORMAT &quot;K&quot;,
217                   thread-&gt;name(),
218                   requested_size * HeapWordSize / K,
219                   min_size * HeapWordSize / K,
220                   _max_tlab_size * HeapWordSize / K,
221                   ergo_tlab * HeapWordSize / K,
222                   size * HeapWordSize / K);
223   }
224 
225   // All prepared, let&#39;s do it!
226   HeapWord* res = allocate_work(size);
227 
228   if (res != NULL) {
229     // Allocation successful
230     *actual_size = size;
231     if (EpsilonElasticTLABDecay) {
232       EpsilonThreadLocalData::set_last_tlab_time(thread, time);
233     }
234     if (EpsilonElasticTLAB &amp;&amp; !fits) {
235       // If we requested expansion, this is our new ergonomic TLAB size
236       EpsilonThreadLocalData::set_ergo_tlab_size(thread, size);
237     }
238   } else {
239     // Allocation failed, reset ergonomics to try and fit smaller TLABs
240     if (EpsilonElasticTLAB) {
241       EpsilonThreadLocalData::set_ergo_tlab_size(thread, 0);
242     }
243   }
244 
245   return res;
246 }
247 
248 HeapWord* EpsilonHeap::mem_allocate(size_t size, bool *gc_overhead_limit_was_exceeded) {
249   *gc_overhead_limit_was_exceeded = false;
250   return allocate_work(size);
251 }
252 
253 void EpsilonHeap::collect(GCCause::Cause cause) {
254   switch (cause) {
255     case GCCause::_metadata_GC_threshold:
256     case GCCause::_metadata_GC_clear_soft_refs:
257       // Receiving these causes means the VM itself entered the safepoint for metadata collection.
258       // While Epsilon does not do GC, it has to perform sizing adjustments, otherwise we would
259       // re-enter the safepoint again very soon.
260 
261       assert(SafepointSynchronize::is_at_safepoint(), &quot;Expected at safepoint&quot;);
262       log_info(gc)(&quot;GC request for \&quot;%s\&quot; is handled&quot;, GCCause::to_string(cause));
263       MetaspaceGC::compute_new_size();
264       print_metaspace_info();
265       break;
266     default:
267       log_info(gc)(&quot;GC request for \&quot;%s\&quot; is ignored&quot;, GCCause::to_string(cause));
268   }
269   _monitoring_support-&gt;update_counters();
270 }
271 
272 void EpsilonHeap::do_full_collection(bool clear_all_soft_refs) {
273   collect(gc_cause());
274 }
275 
276 void EpsilonHeap::object_iterate(ObjectClosure *cl) {
277   _space-&gt;object_iterate(cl);
278 }
279 
280 void EpsilonHeap::print_on(outputStream *st) const {
281   st-&gt;print_cr(&quot;Epsilon Heap&quot;);
282 
283   // Cast away constness:
284   ((VirtualSpace)_virtual_space).print_on(st);
285 
286   if (_space != NULL) {
287     st-&gt;print_cr(&quot;Allocation space:&quot;);
288     _space-&gt;print_on(st);
289   }
290 
291   MetaspaceUtils::print_on(st);
292 }
293 
294 bool EpsilonHeap::print_location(outputStream* st, void* addr) const {
295   return BlockLocationPrinter&lt;EpsilonHeap&gt;::print_location(st, addr);
296 }
297 
298 void EpsilonHeap::print_tracing_info() const {
299   print_heap_info(used());
300   print_metaspace_info();
301 }
302 
303 void EpsilonHeap::print_heap_info(size_t used) const {
304   size_t reserved  = max_capacity();
305   size_t committed = capacity();
306 
307   if (reserved != 0) {
308     log_info(gc)(&quot;Heap: &quot; SIZE_FORMAT &quot;%s reserved, &quot; SIZE_FORMAT &quot;%s (%.2f%%) committed, &quot;
309                  SIZE_FORMAT &quot;%s (%.2f%%) used&quot;,
310             byte_size_in_proper_unit(reserved),  proper_unit_for_byte_size(reserved),
311             byte_size_in_proper_unit(committed), proper_unit_for_byte_size(committed),
312             committed * 100.0 / reserved,
313             byte_size_in_proper_unit(used),      proper_unit_for_byte_size(used),
314             used * 100.0 / reserved);
315   } else {
316     log_info(gc)(&quot;Heap: no reliable data&quot;);
317   }
318 }
319 
320 void EpsilonHeap::print_metaspace_info() const {
321   size_t reserved  = MetaspaceUtils::reserved_bytes();
322   size_t committed = MetaspaceUtils::committed_bytes();
323   size_t used      = MetaspaceUtils::used_bytes();
324 
325   if (reserved != 0) {
326     log_info(gc, metaspace)(&quot;Metaspace: &quot; SIZE_FORMAT &quot;%s reserved, &quot; SIZE_FORMAT &quot;%s (%.2f%%) committed, &quot;
327                             SIZE_FORMAT &quot;%s (%.2f%%) used&quot;,
328             byte_size_in_proper_unit(reserved),  proper_unit_for_byte_size(reserved),
329             byte_size_in_proper_unit(committed), proper_unit_for_byte_size(committed),
330             committed * 100.0 / reserved,
331             byte_size_in_proper_unit(used),      proper_unit_for_byte_size(used),
332             used * 100.0 / reserved);
333   } else {
334     log_info(gc, metaspace)(&quot;Metaspace: no reliable data&quot;);
335   }
336 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>