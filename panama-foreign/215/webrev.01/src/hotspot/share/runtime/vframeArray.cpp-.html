<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/runtime/vframeArray.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/vmSymbols.hpp&quot;
 27 #include &quot;code/vmreg.inline.hpp&quot;
 28 #include &quot;interpreter/bytecode.hpp&quot;
 29 #include &quot;interpreter/interpreter.hpp&quot;
 30 #include &quot;memory/allocation.inline.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
 32 #include &quot;oops/methodData.hpp&quot;
 33 #include &quot;oops/oop.inline.hpp&quot;
 34 #include &quot;prims/jvmtiThreadState.hpp&quot;
 35 #include &quot;runtime/frame.inline.hpp&quot;
 36 #include &quot;runtime/handles.inline.hpp&quot;
 37 #include &quot;runtime/monitorChunk.hpp&quot;
 38 #include &quot;runtime/sharedRuntime.hpp&quot;
 39 #include &quot;runtime/vframe.hpp&quot;
 40 #include &quot;runtime/vframeArray.hpp&quot;
 41 #include &quot;runtime/vframe_hp.hpp&quot;
 42 #include &quot;utilities/copy.hpp&quot;
 43 #include &quot;utilities/events.hpp&quot;
 44 #ifdef COMPILER2
 45 #include &quot;opto/runtime.hpp&quot;
 46 #endif
 47 
 48 int vframeArrayElement:: bci(void) const { return (_bci == SynchronizationEntryBCI ? 0 : _bci); }
 49 
 50 void vframeArrayElement::free_monitors(JavaThread* jt) {
 51   if (_monitors != NULL) {
 52      MonitorChunk* chunk = _monitors;
 53      _monitors = NULL;
 54      jt-&gt;remove_monitor_chunk(chunk);
 55      delete chunk;
 56   }
 57 }
 58 
 59 void vframeArrayElement::fill_in(compiledVFrame* vf, bool realloc_failures) {
 60 
 61 // Copy the information from the compiled vframe to the
 62 // interpreter frame we will be creating to replace vf
 63 
 64   _method = vf-&gt;method();
 65   _bci    = vf-&gt;raw_bci();
 66   _reexecute = vf-&gt;should_reexecute();
 67 #ifdef ASSERT
 68   _removed_monitors = false;
 69 #endif
 70 
 71   int index;
 72 
 73   // Get the monitors off-stack
 74 
 75   GrowableArray&lt;MonitorInfo*&gt;* list = vf-&gt;monitors();
 76   if (list-&gt;is_empty()) {
 77     _monitors = NULL;
 78   } else {
 79 
 80     // Allocate monitor chunk
 81     _monitors = new MonitorChunk(list-&gt;length());
 82     vf-&gt;thread()-&gt;add_monitor_chunk(_monitors);
 83 
 84     // Migrate the BasicLocks from the stack to the monitor chunk
 85     for (index = 0; index &lt; list-&gt;length(); index++) {
 86       MonitorInfo* monitor = list-&gt;at(index);
 87       assert(!monitor-&gt;owner_is_scalar_replaced() || realloc_failures, &quot;object should be reallocated already&quot;);
 88       BasicObjectLock* dest = _monitors-&gt;at(index);
 89       if (monitor-&gt;owner_is_scalar_replaced()) {
 90         dest-&gt;set_obj(NULL);
 91       } else {
 92         assert(monitor-&gt;owner() == NULL || (!monitor-&gt;owner()-&gt;is_unlocked() &amp;&amp; !monitor-&gt;owner()-&gt;has_bias_pattern()), &quot;object must be null or locked, and unbiased&quot;);
 93         dest-&gt;set_obj(monitor-&gt;owner());
 94         monitor-&gt;lock()-&gt;move_to(monitor-&gt;owner(), dest-&gt;lock());
 95       }
 96     }
 97   }
 98 
 99   // Convert the vframe locals and expressions to off stack
100   // values. Because we will not gc all oops can be converted to
101   // intptr_t (i.e. a stack slot) and we are fine. This is
102   // good since we are inside a HandleMark and the oops in our
103   // collection would go away between packing them here and
104   // unpacking them in unpack_on_stack.
105 
106   // First the locals go off-stack
107 
108   // FIXME this seems silly it creates a StackValueCollection
109   // in order to get the size to then copy them and
110   // convert the types to intptr_t size slots. Seems like it
111   // could do it in place... Still uses less memory than the
112   // old way though
113 
114   StackValueCollection *locs = vf-&gt;locals();
115   _locals = new StackValueCollection(locs-&gt;size());
116   for(index = 0; index &lt; locs-&gt;size(); index++) {
117     StackValue* value = locs-&gt;at(index);
118     switch(value-&gt;type()) {
119       case T_OBJECT:
120         assert(!value-&gt;obj_is_scalar_replaced() || realloc_failures, &quot;object should be reallocated already&quot;);
121         // preserve object type
122         _locals-&gt;add( new StackValue(cast_from_oop&lt;intptr_t&gt;((value-&gt;get_obj()())), T_OBJECT ));
123         break;
124       case T_CONFLICT:
125         // A dead local.  Will be initialized to null/zero.
126         _locals-&gt;add( new StackValue());
127         break;
128       case T_INT:
129         _locals-&gt;add( new StackValue(value-&gt;get_int()));
130         break;
131       default:
132         ShouldNotReachHere();
133     }
134   }
135 
136   // Now the expressions off-stack
137   // Same silliness as above
138 
139   StackValueCollection *exprs = vf-&gt;expressions();
140   _expressions = new StackValueCollection(exprs-&gt;size());
141   for(index = 0; index &lt; exprs-&gt;size(); index++) {
142     StackValue* value = exprs-&gt;at(index);
143     switch(value-&gt;type()) {
144       case T_OBJECT:
145         assert(!value-&gt;obj_is_scalar_replaced() || realloc_failures, &quot;object should be reallocated already&quot;);
146         // preserve object type
147         _expressions-&gt;add( new StackValue(cast_from_oop&lt;intptr_t&gt;((value-&gt;get_obj()())), T_OBJECT ));
148         break;
149       case T_CONFLICT:
150         // A dead stack element.  Will be initialized to null/zero.
151         // This can occur when the compiler emits a state in which stack
152         // elements are known to be dead (because of an imminent exception).
153         _expressions-&gt;add( new StackValue());
154         break;
155       case T_INT:
156         _expressions-&gt;add( new StackValue(value-&gt;get_int()));
157         break;
158       default:
159         ShouldNotReachHere();
160     }
161   }
162 }
163 
164 int unpack_counter = 0;
165 
166 void vframeArrayElement::unpack_on_stack(int caller_actual_parameters,
167                                          int callee_parameters,
168                                          int callee_locals,
169                                          frame* caller,
170                                          bool is_top_frame,
171                                          bool is_bottom_frame,
172                                          int exec_mode) {
173   JavaThread* thread = (JavaThread*) Thread::current();
174 
175   bool realloc_failure_exception = thread-&gt;frames_to_pop_failed_realloc() &gt; 0;
176 
177   // Look at bci and decide on bcp and continuation pc
178   address bcp;
179   // C++ interpreter doesn&#39;t need a pc since it will figure out what to do when it
180   // begins execution
181   address pc;
182   bool use_next_mdp = false; // true if we should use the mdp associated with the next bci
183                              // rather than the one associated with bcp
184   if (raw_bci() == SynchronizationEntryBCI) {
185     // We are deoptimizing while hanging in prologue code for synchronized method
186     bcp = method()-&gt;bcp_from(0); // first byte code
187     pc  = Interpreter::deopt_entry(vtos, 0); // step = 0 since we don&#39;t skip current bytecode
188   } else if (should_reexecute()) { //reexecute this bytecode
189     assert(is_top_frame, &quot;reexecute allowed only for the top frame&quot;);
190     bcp = method()-&gt;bcp_from(bci());
191     pc  = Interpreter::deopt_reexecute_entry(method(), bcp);
192   } else {
193     bcp = method()-&gt;bcp_from(bci());
194     pc  = Interpreter::deopt_continue_after_entry(method(), bcp, callee_parameters, is_top_frame);
195     use_next_mdp = true;
196   }
197   assert(Bytecodes::is_defined(*bcp), &quot;must be a valid bytecode&quot;);
198 
199   // Monitorenter and pending exceptions:
200   //
201   // For Compiler2, there should be no pending exception when deoptimizing at monitorenter
202   // because there is no safepoint at the null pointer check (it is either handled explicitly
203   // or prior to the monitorenter) and asynchronous exceptions are not made &quot;pending&quot; by the
204   // runtime interface for the slow case (see JRT_ENTRY_FOR_MONITORENTER).  If an asynchronous
205   // exception was processed, the bytecode pointer would have to be extended one bytecode beyond
206   // the monitorenter to place it in the proper exception range.
207   //
208   // For Compiler1, deoptimization can occur while throwing a NullPointerException at monitorenter,
209   // in which case bcp should point to the monitorenter since it is within the exception&#39;s range.
210   //
211   // For realloc failure exception we just pop frames, skip the guarantee.
212 
213   assert(*bcp != Bytecodes::_monitorenter || is_top_frame, &quot;a _monitorenter must be a top frame&quot;);
214   assert(thread-&gt;deopt_compiled_method() != NULL, &quot;compiled method should be known&quot;);
215   guarantee(realloc_failure_exception || !(thread-&gt;deopt_compiled_method()-&gt;is_compiled_by_c2() &amp;&amp;
216               *bcp == Bytecodes::_monitorenter             &amp;&amp;
217               exec_mode == Deoptimization::Unpack_exception),
218             &quot;shouldn&#39;t get exception during monitorenter&quot;);
219 
220   int popframe_preserved_args_size_in_bytes = 0;
221   int popframe_preserved_args_size_in_words = 0;
222   if (is_top_frame) {
223     JvmtiThreadState *state = thread-&gt;jvmti_thread_state();
224     if (JvmtiExport::can_pop_frame() &amp;&amp;
225         (thread-&gt;has_pending_popframe() || thread-&gt;popframe_forcing_deopt_reexecution())) {
226       if (thread-&gt;has_pending_popframe()) {
227         // Pop top frame after deoptimization
228 #ifndef CC_INTERP
229         pc = Interpreter::remove_activation_preserving_args_entry();
230 #else
231         // Do an uncommon trap type entry. c++ interpreter will know
232         // to pop frame and preserve the args
233         pc = Interpreter::deopt_entry(vtos, 0);
234         use_next_mdp = false;
235 #endif
236       } else {
237         // Reexecute invoke in top frame
238         pc = Interpreter::deopt_entry(vtos, 0);
239         use_next_mdp = false;
240         popframe_preserved_args_size_in_bytes = in_bytes(thread-&gt;popframe_preserved_args_size());
241         // Note: the PopFrame-related extension of the expression stack size is done in
242         // Deoptimization::fetch_unroll_info_helper
243         popframe_preserved_args_size_in_words = in_words(thread-&gt;popframe_preserved_args_size_in_words());
244       }
245     } else if (!realloc_failure_exception &amp;&amp; JvmtiExport::can_force_early_return() &amp;&amp; state != NULL &amp;&amp; state-&gt;is_earlyret_pending()) {
246       // Force early return from top frame after deoptimization
247 #ifndef CC_INTERP
248       pc = Interpreter::remove_activation_early_entry(state-&gt;earlyret_tos());
249 #endif
250     } else {
251       if (realloc_failure_exception &amp;&amp; JvmtiExport::can_force_early_return() &amp;&amp; state != NULL &amp;&amp; state-&gt;is_earlyret_pending()) {
252         state-&gt;clr_earlyret_pending();
253         state-&gt;set_earlyret_oop(NULL);
254         state-&gt;clr_earlyret_value();
255       }
256       // Possibly override the previous pc computation of the top (youngest) frame
257       switch (exec_mode) {
258       case Deoptimization::Unpack_deopt:
259         // use what we&#39;ve got
260         break;
261       case Deoptimization::Unpack_exception:
262         // exception is pending
263         pc = SharedRuntime::raw_exception_handler_for_return_address(thread, pc);
264         // [phh] We&#39;re going to end up in some handler or other, so it doesn&#39;t
265         // matter what mdp we point to.  See exception_handler_for_exception()
266         // in interpreterRuntime.cpp.
267         break;
268       case Deoptimization::Unpack_uncommon_trap:
269       case Deoptimization::Unpack_reexecute:
270         // redo last byte code
271         pc  = Interpreter::deopt_entry(vtos, 0);
272         use_next_mdp = false;
273         break;
274       default:
275         ShouldNotReachHere();
276       }
277     }
278   }
279 
280   // Setup the interpreter frame
281 
282   assert(method() != NULL, &quot;method must exist&quot;);
283   int temps = expressions()-&gt;size();
284 
285   int locks = monitors() == NULL ? 0 : monitors()-&gt;number_of_monitors();
286 
287   Interpreter::layout_activation(method(),
288                                  temps + callee_parameters,
289                                  popframe_preserved_args_size_in_words,
290                                  locks,
291                                  caller_actual_parameters,
292                                  callee_parameters,
293                                  callee_locals,
294                                  caller,
295                                  iframe(),
296                                  is_top_frame,
297                                  is_bottom_frame);
298 
299   // Update the pc in the frame object and overwrite the temporary pc
300   // we placed in the skeletal frame now that we finally know the
301   // exact interpreter address we should use.
302 
303   _frame.patch_pc(thread, pc);
304 
305   assert (!method()-&gt;is_synchronized() || locks &gt; 0 || _removed_monitors || raw_bci() == SynchronizationEntryBCI, &quot;synchronized methods must have monitors&quot;);
306 
307   BasicObjectLock* top = iframe()-&gt;interpreter_frame_monitor_begin();
308   for (int index = 0; index &lt; locks; index++) {
309     top = iframe()-&gt;previous_monitor_in_interpreter_frame(top);
310     BasicObjectLock* src = _monitors-&gt;at(index);
311     top-&gt;set_obj(src-&gt;obj());
312     src-&gt;lock()-&gt;move_to(src-&gt;obj(), top-&gt;lock());
313   }
314   if (ProfileInterpreter) {
315     iframe()-&gt;interpreter_frame_set_mdp(0); // clear out the mdp.
316   }
317   iframe()-&gt;interpreter_frame_set_bcp(bcp);
318   if (ProfileInterpreter) {
319     MethodData* mdo = method()-&gt;method_data();
320     if (mdo != NULL) {
321       int bci = iframe()-&gt;interpreter_frame_bci();
322       if (use_next_mdp) ++bci;
323       address mdp = mdo-&gt;bci_to_dp(bci);
324       iframe()-&gt;interpreter_frame_set_mdp(mdp);
325     }
326   }
327 
328   if (PrintDeoptimizationDetails) {
329     tty-&gt;print_cr(&quot;Expressions size: %d&quot;, expressions()-&gt;size());
330   }
331 
332   // Unpack expression stack
333   // If this is an intermediate frame (i.e. not top frame) then this
334   // only unpacks the part of the expression stack not used by callee
335   // as parameters. The callee parameters are unpacked as part of the
336   // callee locals.
337   int i;
338   for(i = 0; i &lt; expressions()-&gt;size(); i++) {
339     StackValue *value = expressions()-&gt;at(i);
340     intptr_t*   addr  = iframe()-&gt;interpreter_frame_expression_stack_at(i);
341     switch(value-&gt;type()) {
342       case T_INT:
343         *addr = value-&gt;get_int();
344 #ifndef PRODUCT
345         if (PrintDeoptimizationDetails) {
346           tty-&gt;print_cr(&quot;Reconstructed expression %d (INT): %d&quot;, i, (int)(*addr));
347         }
348 #endif
349         break;
350       case T_OBJECT:
351         *addr = value-&gt;get_int(T_OBJECT);
352 #ifndef PRODUCT
353         if (PrintDeoptimizationDetails) {
354           tty-&gt;print(&quot;Reconstructed expression %d (OBJECT): &quot;, i);
355           oop o = (oop)(address)(*addr);
356           if (o == NULL) {
357             tty-&gt;print_cr(&quot;NULL&quot;);
358           } else {
359             ResourceMark rm;
360             tty-&gt;print_raw_cr(o-&gt;klass()-&gt;name()-&gt;as_C_string());
361           }
362         }
363 #endif
364         break;
365       case T_CONFLICT:
366         // A dead stack slot.  Initialize to null in case it is an oop.
367         *addr = NULL_WORD;
368         break;
369       default:
370         ShouldNotReachHere();
371     }
372   }
373 
374 
375   // Unpack the locals
376   for(i = 0; i &lt; locals()-&gt;size(); i++) {
377     StackValue *value = locals()-&gt;at(i);
378     intptr_t* addr  = iframe()-&gt;interpreter_frame_local_at(i);
379     switch(value-&gt;type()) {
380       case T_INT:
381         *addr = value-&gt;get_int();
382 #ifndef PRODUCT
383         if (PrintDeoptimizationDetails) {
384           tty-&gt;print_cr(&quot;Reconstructed local %d (INT): %d&quot;, i, (int)(*addr));
385         }
386 #endif
387         break;
388       case T_OBJECT:
389         *addr = value-&gt;get_int(T_OBJECT);
390 #ifndef PRODUCT
391         if (PrintDeoptimizationDetails) {
392           tty-&gt;print(&quot;Reconstructed local %d (OBJECT): &quot;, i);
393           oop o = (oop)(address)(*addr);
394           if (o == NULL) {
395             tty-&gt;print_cr(&quot;NULL&quot;);
396           } else {
397             ResourceMark rm;
398             tty-&gt;print_raw_cr(o-&gt;klass()-&gt;name()-&gt;as_C_string());
399           }
400         }
401 #endif
402         break;
403       case T_CONFLICT:
404         // A dead location. If it is an oop then we need a NULL to prevent GC from following it
405         *addr = NULL_WORD;
406         break;
407       default:
408         ShouldNotReachHere();
409     }
410   }
411 
412   if (is_top_frame &amp;&amp; JvmtiExport::can_pop_frame() &amp;&amp; thread-&gt;popframe_forcing_deopt_reexecution()) {
413     // An interpreted frame was popped but it returns to a deoptimized
414     // frame. The incoming arguments to the interpreted activation
415     // were preserved in thread-local storage by the
416     // remove_activation_preserving_args_entry in the interpreter; now
417     // we put them back into the just-unpacked interpreter frame.
418     // Note that this assumes that the locals arena grows toward lower
419     // addresses.
420     if (popframe_preserved_args_size_in_words != 0) {
421       void* saved_args = thread-&gt;popframe_preserved_args();
422       assert(saved_args != NULL, &quot;must have been saved by interpreter&quot;);
423 #ifdef ASSERT
424       assert(popframe_preserved_args_size_in_words &lt;=
425              iframe()-&gt;interpreter_frame_expression_stack_size()*Interpreter::stackElementWords,
426              &quot;expression stack size should have been extended&quot;);
427 #endif // ASSERT
428       int top_element = iframe()-&gt;interpreter_frame_expression_stack_size()-1;
429       intptr_t* base;
430       if (frame::interpreter_frame_expression_stack_direction() &lt; 0) {
431         base = iframe()-&gt;interpreter_frame_expression_stack_at(top_element);
432       } else {
433         base = iframe()-&gt;interpreter_frame_expression_stack();
434       }
435       Copy::conjoint_jbytes(saved_args,
436                             base,
437                             popframe_preserved_args_size_in_bytes);
438       thread-&gt;popframe_free_preserved_args();
439     }
440   }
441 
442 #ifndef PRODUCT
443   if (PrintDeoptimizationDetails) {
444     ttyLocker ttyl;
445     tty-&gt;print_cr(&quot;[%d Interpreted Frame]&quot;, ++unpack_counter);
446     iframe()-&gt;print_on(tty);
447     RegisterMap map(thread);
448     vframe* f = vframe::new_vframe(iframe(), &amp;map, thread);
449     f-&gt;print();
450 
451     tty-&gt;print_cr(&quot;locals size     %d&quot;, locals()-&gt;size());
452     tty-&gt;print_cr(&quot;expression size %d&quot;, expressions()-&gt;size());
453 
454     method()-&gt;print_value();
455     tty-&gt;cr();
456     // method()-&gt;print_codes();
457   } else if (TraceDeoptimization) {
458     tty-&gt;print(&quot;     &quot;);
459     method()-&gt;print_value();
460     Bytecodes::Code code = Bytecodes::java_code_at(method(), bcp);
461     int bci = method()-&gt;bci_from(bcp);
462     tty-&gt;print(&quot; - %s&quot;, Bytecodes::name(code));
463     tty-&gt;print(&quot; @ bci %d &quot;, bci);
464     tty-&gt;print_cr(&quot;sp = &quot; PTR_FORMAT, p2i(iframe()-&gt;sp()));
465   }
466 #endif // PRODUCT
467 
468   // The expression stack and locals are in the resource area don&#39;t leave
469   // a dangling pointer in the vframeArray we leave around for debug
470   // purposes
471 
472   _locals = _expressions = NULL;
473 
474 }
475 
476 int vframeArrayElement::on_stack_size(int callee_parameters,
477                                       int callee_locals,
478                                       bool is_top_frame,
479                                       int popframe_extra_stack_expression_els) const {
480   assert(method()-&gt;max_locals() == locals()-&gt;size(), &quot;just checking&quot;);
481   int locks = monitors() == NULL ? 0 : monitors()-&gt;number_of_monitors();
482   int temps = expressions()-&gt;size();
483   return Interpreter::size_activation(method()-&gt;max_stack(),
484                                       temps + callee_parameters,
485                                       popframe_extra_stack_expression_els,
486                                       locks,
487                                       callee_parameters,
488                                       callee_locals,
489                                       is_top_frame);
490 }
491 
492 
493 intptr_t* vframeArray::unextended_sp() const {
494   return _original.unextended_sp();
495 }
496 
497 vframeArray* vframeArray::allocate(JavaThread* thread, int frame_size, GrowableArray&lt;compiledVFrame*&gt;* chunk,
498                                    RegisterMap *reg_map, frame sender, frame caller, frame self,
499                                    bool realloc_failures) {
500 
501   // Allocate the vframeArray
502   vframeArray * result = (vframeArray*) AllocateHeap(sizeof(vframeArray) + // fixed part
503                                                      sizeof(vframeArrayElement) * (chunk-&gt;length() - 1), // variable part
504                                                      mtCompiler);
505   result-&gt;_frames = chunk-&gt;length();
506   result-&gt;_owner_thread = thread;
507   result-&gt;_sender = sender;
508   result-&gt;_caller = caller;
509   result-&gt;_original = self;
510   result-&gt;set_unroll_block(NULL); // initialize it
511   result-&gt;fill_in(thread, frame_size, chunk, reg_map, realloc_failures);
512   return result;
513 }
514 
515 void vframeArray::fill_in(JavaThread* thread,
516                           int frame_size,
517                           GrowableArray&lt;compiledVFrame*&gt;* chunk,
518                           const RegisterMap *reg_map,
519                           bool realloc_failures) {
520   // Set owner first, it is used when adding monitor chunks
521 
522   _frame_size = frame_size;
523   for(int i = 0; i &lt; chunk-&gt;length(); i++) {
524     element(i)-&gt;fill_in(chunk-&gt;at(i), realloc_failures);
525   }
526 
527   // Copy registers for callee-saved registers
528   if (reg_map != NULL) {
529     for(int i = 0; i &lt; RegisterMap::reg_count; i++) {
530 #ifdef AMD64
531       // The register map has one entry for every int (32-bit value), so
532       // 64-bit physical registers have two entries in the map, one for
533       // each half.  Ignore the high halves of 64-bit registers, just like
534       // frame::oopmapreg_to_location does.
535       //
536       // [phh] FIXME: this is a temporary hack!  This code *should* work
537       // correctly w/o this hack, possibly by changing RegisterMap::pd_location
538       // in frame_amd64.cpp and the values of the phantom high half registers
539       // in amd64.ad.
540       //      if (VMReg::Name(i) &lt; SharedInfo::stack0 &amp;&amp; is_even(i)) {
541         intptr_t* src = (intptr_t*) reg_map-&gt;location(VMRegImpl::as_VMReg(i));
542         _callee_registers[i] = src != NULL ? *src : NULL_WORD;
543         //      } else {
544         //      jint* src = (jint*) reg_map-&gt;location(VMReg::Name(i));
545         //      _callee_registers[i] = src != NULL ? *src : NULL_WORD;
546         //      }
547 #else
548       jint* src = (jint*) reg_map-&gt;location(VMRegImpl::as_VMReg(i));
549       _callee_registers[i] = src != NULL ? *src : NULL_WORD;
550 #endif
551       if (src == NULL) {
552         set_location_valid(i, false);
553       } else {
554         set_location_valid(i, true);
555         jint* dst = (jint*) register_location(i);
556         *dst = *src;
557       }
558     }
559   }
560 }
561 
562 void vframeArray::unpack_to_stack(frame &amp;unpack_frame, int exec_mode, int caller_actual_parameters) {
563   // stack picture
564   //   unpack_frame
565   //   [new interpreter frames ] (frames are skeletal but walkable)
566   //   caller_frame
567   //
568   //  This routine fills in the missing data for the skeletal interpreter frames
569   //  in the above picture.
570 
571   // Find the skeletal interpreter frames to unpack into
572   JavaThread* THREAD = JavaThread::current();
573   RegisterMap map(THREAD, false);
574   // Get the youngest frame we will unpack (last to be unpacked)
575   frame me = unpack_frame.sender(&amp;map);
576   int index;
577   for (index = 0; index &lt; frames(); index++ ) {
578     *element(index)-&gt;iframe() = me;
579     // Get the caller frame (possibly skeletal)
580     me = me.sender(&amp;map);
581   }
582 
583   // Do the unpacking of interpreter frames; the frame at index 0 represents the top activation, so it has no callee
584   // Unpack the frames from the oldest (frames() -1) to the youngest (0)
585   frame* caller_frame = &amp;me;
586   for (index = frames() - 1; index &gt;= 0 ; index--) {
587     vframeArrayElement* elem = element(index);  // caller
588     int callee_parameters, callee_locals;
589     if (index == 0) {
590       callee_parameters = callee_locals = 0;
591     } else {
592       methodHandle caller(THREAD, elem-&gt;method());
593       methodHandle callee(THREAD, element(index - 1)-&gt;method());
594       Bytecode_invoke inv(caller, elem-&gt;bci());
595       // invokedynamic instructions don&#39;t have a class but obviously don&#39;t have a MemberName appendix.
596       // NOTE:  Use machinery here that avoids resolving of any kind.
597       const bool has_member_arg =
598           !inv.is_invokedynamic() &amp;&amp; MethodHandles::has_member_arg(inv.klass(), inv.name());
599       callee_parameters = callee-&gt;size_of_parameters() + (has_member_arg ? 1 : 0);
600       callee_locals     = callee-&gt;max_locals();
601     }
602     elem-&gt;unpack_on_stack(caller_actual_parameters,
603                           callee_parameters,
604                           callee_locals,
605                           caller_frame,
606                           index == 0,
607                           index == frames() - 1,
608                           exec_mode);
609     if (index == frames() - 1) {
610       Deoptimization::unwind_callee_save_values(elem-&gt;iframe(), this);
611     }
612     caller_frame = elem-&gt;iframe();
613     caller_actual_parameters = callee_parameters;
614   }
615   deallocate_monitor_chunks();
616 }
617 
618 void vframeArray::deallocate_monitor_chunks() {
619   JavaThread* jt = JavaThread::current();
620   for (int index = 0; index &lt; frames(); index++ ) {
621      element(index)-&gt;free_monitors(jt);
622   }
623 }
624 
625 #ifndef PRODUCT
626 
627 bool vframeArray::structural_compare(JavaThread* thread, GrowableArray&lt;compiledVFrame*&gt;* chunk) {
628   if (owner_thread() != thread) return false;
629   int index = 0;
630 #if 0 // FIXME can&#39;t do this comparison
631 
632   // Compare only within vframe array.
633   for (deoptimizedVFrame* vf = deoptimizedVFrame::cast(vframe_at(first_index())); vf; vf = vf-&gt;deoptimized_sender_or_null()) {
634     if (index &gt;= chunk-&gt;length() || !vf-&gt;structural_compare(chunk-&gt;at(index))) return false;
635     index++;
636   }
637   if (index != chunk-&gt;length()) return false;
638 #endif
639 
640   return true;
641 }
642 
643 #endif
644 
645 address vframeArray::register_location(int i) const {
646   assert(0 &lt;= i &amp;&amp; i &lt; RegisterMap::reg_count, &quot;index out of bounds&quot;);
647   return (address) &amp; _callee_registers[i];
648 }
649 
650 
651 #ifndef PRODUCT
652 
653 // Printing
654 
655 // Note: we cannot have print_on as const, as we allocate inside the method
656 void vframeArray::print_on_2(outputStream* st)  {
657   st-&gt;print_cr(&quot; - sp: &quot; INTPTR_FORMAT, p2i(sp()));
658   st-&gt;print(&quot; - thread: &quot;);
659   Thread::current()-&gt;print();
660   st-&gt;print_cr(&quot; - frame size: %d&quot;, frame_size());
661   for (int index = 0; index &lt; frames() ; index++ ) {
662     element(index)-&gt;print(st);
663   }
664 }
665 
666 void vframeArrayElement::print(outputStream* st) {
667   st-&gt;print_cr(&quot; - interpreter_frame -&gt; sp: &quot; INTPTR_FORMAT, p2i(iframe()-&gt;sp()));
668 }
669 
670 void vframeArray::print_value_on(outputStream* st) const {
671   st-&gt;print_cr(&quot;vframeArray [%d] &quot;, frames());
672 }
673 
674 
675 #endif
    </pre>
  </body>
</html>