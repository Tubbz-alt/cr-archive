<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/vmThread.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="vmStructs.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vmThread.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/vmThread.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 88   insert(_queue[prio]-&gt;prev(), op);
 89 }
 90 
 91 
 92 void VMOperationQueue::unlink(VM_Operation* q) {
 93   assert(q-&gt;next()-&gt;prev() == q &amp;&amp; q-&gt;prev()-&gt;next() == q, &quot;sanity check&quot;);
 94   q-&gt;prev()-&gt;set_next(q-&gt;next());
 95   q-&gt;next()-&gt;set_prev(q-&gt;prev());
 96 }
 97 
 98 VM_Operation* VMOperationQueue::queue_remove_front(int prio) {
 99   if (queue_empty(prio)) return NULL;
100   assert(_queue_length[prio] &gt;= 0, &quot;sanity check&quot;);
101   _queue_length[prio]--;
102   VM_Operation* r = _queue[prio]-&gt;next();
103   assert(r != _queue[prio], &quot;cannot remove base element&quot;);
104   unlink(r);
105   return r;
106 }
107 
<span class="line-removed">108 VM_Operation* VMOperationQueue::queue_drain(int prio) {</span>
<span class="line-removed">109   if (queue_empty(prio)) return NULL;</span>
<span class="line-removed">110   DEBUG_ONLY(int length = _queue_length[prio];);</span>
<span class="line-removed">111   assert(length &gt;= 0, &quot;sanity check&quot;);</span>
<span class="line-removed">112   _queue_length[prio] = 0;</span>
<span class="line-removed">113   VM_Operation* r = _queue[prio]-&gt;next();</span>
<span class="line-removed">114   assert(r != _queue[prio], &quot;cannot remove base element&quot;);</span>
<span class="line-removed">115   // remove links to base element from head and tail</span>
<span class="line-removed">116   r-&gt;set_prev(NULL);</span>
<span class="line-removed">117   _queue[prio]-&gt;prev()-&gt;set_next(NULL);</span>
<span class="line-removed">118   // restore queue to empty state</span>
<span class="line-removed">119   _queue[prio]-&gt;set_next(_queue[prio]);</span>
<span class="line-removed">120   _queue[prio]-&gt;set_prev(_queue[prio]);</span>
<span class="line-removed">121   assert(queue_empty(prio), &quot;drain corrupted queue&quot;);</span>
<span class="line-removed">122 #ifdef ASSERT</span>
<span class="line-removed">123   int len = 0;</span>
<span class="line-removed">124   VM_Operation* cur;</span>
<span class="line-removed">125   for(cur = r; cur != NULL; cur=cur-&gt;next()) len++;</span>
<span class="line-removed">126   assert(len == length, &quot;drain lost some ops&quot;);</span>
<span class="line-removed">127 #endif</span>
<span class="line-removed">128   return r;</span>
<span class="line-removed">129 }</span>
<span class="line-removed">130 </span>
131 //-----------------------------------------------------------------
132 // High-level interface
133 void VMOperationQueue::add(VM_Operation *op) {
134 
135   HOTSPOT_VMOPS_REQUEST(
136                    (char *) op-&gt;name(), strlen(op-&gt;name()),
137                    op-&gt;evaluate_at_safepoint() ? 0 : 1);
138 
139   // Encapsulates VM queue policy. Currently, that
140   // only involves putting them on the right list
141   queue_add(op-&gt;evaluate_at_safepoint() ? SafepointPriority : MediumPriority, op);
142 }
143 
144 VM_Operation* VMOperationQueue::remove_next() {
145   // Assuming VMOperation queue is two-level priority queue. If there are
146   // more than two priorities, we need a different scheduling algorithm.
147   assert(SafepointPriority == 0 &amp;&amp; MediumPriority == 1 &amp;&amp; nof_priorities == 2,
148          &quot;current algorithm does not work&quot;);
149 
150   // simple counter based scheduling to prevent starvation of lower priority
</pre>
<hr />
<pre>
182 
183 void VMOperationTimeoutTask::arm() {
184   _arm_time = os::javaTimeNanos();
185   Atomic::release_store_fence(&amp;_armed, 1);
186 }
187 
188 void VMOperationTimeoutTask::disarm() {
189   Atomic::release_store_fence(&amp;_armed, 0);
190 }
191 
192 //------------------------------------------------------------------------------------------------------------------
193 // Implementation of VMThread stuff
194 
195 bool              VMThread::_should_terminate   = false;
196 bool              VMThread::_terminated         = false;
197 Monitor*          VMThread::_terminate_lock     = NULL;
198 VMThread*         VMThread::_vm_thread          = NULL;
199 VM_Operation*     VMThread::_cur_vm_operation   = NULL;
200 VMOperationQueue* VMThread::_vm_queue           = NULL;
201 PerfCounter*      VMThread::_perf_accumulated_vm_operation_time = NULL;
<span class="line-removed">202 uint64_t          VMThread::_coalesced_count = 0;</span>
203 VMOperationTimeoutTask* VMThread::_timeout_task = NULL;
204 
205 
206 void VMThread::create() {
207   assert(vm_thread() == NULL, &quot;we can only allocate one VMThread&quot;);
208   _vm_thread = new VMThread();
209 
210   if (AbortVMOnVMOperationTimeout) {
211     // Make sure we call the timeout task frequently enough, but not too frequent.
212     // Try to make the interval 10% of the timeout delay, so that we miss the timeout
213     // by those 10% at max. Periodic task also expects it to fit min/max intervals.
214     size_t interval = (size_t)AbortVMOnVMOperationTimeoutDelay / 10;
215     interval = interval / PeriodicTask::interval_gran * PeriodicTask::interval_gran;
216     interval = MAX2&lt;size_t&gt;(interval, PeriodicTask::min_interval);
217     interval = MIN2&lt;size_t&gt;(interval, PeriodicTask::max_interval);
218 
219     _timeout_task = new VMOperationTimeoutTask(interval);
220     _timeout_task-&gt;enroll();
221   } else {
222     assert(_timeout_task == NULL, &quot;sanity&quot;);
</pre>
<hr />
<pre>
268   // Note that I cannot call os::set_priority because it expects Java
269   // priorities and I am *explicitly* using OS priorities so that it&#39;s
270   // possible to set the VM thread priority higher than any Java thread.
271   os::set_native_priority( this, prio );
272 
273   // Wait for VM_Operations until termination
274   this-&gt;loop();
275 
276   // Note the intention to exit before safepointing.
277   // 6295565  This has the effect of waiting for any large tty
278   // outputs to finish.
279   if (xtty != NULL) {
280     ttyLocker ttyl;
281     xtty-&gt;begin_elem(&quot;destroy_vm&quot;);
282     xtty-&gt;stamp();
283     xtty-&gt;end_elem();
284     assert(should_terminate(), &quot;termination flag must be set&quot;);
285   }
286 
287   if (AsyncDeflateIdleMonitors &amp;&amp; log_is_enabled(Info, monitorinflation)) {
<span class="line-modified">288     // AsyncDeflateIdleMonitors does a special deflation at the final</span>
<span class="line-modified">289     // safepoint in order to reduce the in-use monitor population that</span>
<span class="line-modified">290     // is reported by ObjectSynchronizer::log_in_use_monitor_details()</span>
<span class="line-modified">291     // at VM exit.</span>
<span class="line-removed">292     ObjectSynchronizer::set_is_special_deflation_requested(true);</span>
293   }
294 
295   // 4526887 let VM thread exit at Safepoint
296   _cur_vm_operation = &amp;halt_op;
297   SafepointSynchronize::begin();
298 
299   if (VerifyBeforeExit) {
300     HandleMark hm(VMThread::vm_thread());
301     // Among other things, this ensures that Eden top is correct.
302     Universe::heap()-&gt;prepare_for_verify();
303     // Silent verification so as not to pollute normal output,
304     // unless we really asked for it.
305     Universe::verify();
306   }
307 
308   CompileBroker::set_should_block();
309 
310   // wait for threads (compiler threads or daemon threads) in the
311   // _thread_in_native state to block.
312   VM_Exit::wait_for_threads_in_native_to_block();
</pre>
<hr />
<pre>
418   // Check for a cleanup before SafepointALot to keep stats correct.
419   long interval_ms = SafepointTracing::time_since_last_safepoint_ms();
420   bool max_time_exceeded = GuaranteedSafepointInterval != 0 &amp;&amp;
421                            (interval_ms &gt;= GuaranteedSafepointInterval);
422   if (max_time_exceeded &amp;&amp; SafepointSynchronize::is_cleanup_needed()) {
423     return &amp;cleanup_op;
424   }
425   if (SafepointALot) {
426     return &amp;safepointALot_op;
427   }
428   // Nothing to be done.
429   return NULL;
430 }
431 
432 void VMThread::loop() {
433   assert(_cur_vm_operation == NULL, &quot;no current one should be executing&quot;);
434 
435   SafepointSynchronize::init(_vm_thread);
436 
437   while(true) {
<span class="line-removed">438     VM_Operation* safepoint_ops = NULL;</span>
439     //
440     // Wait for VM operation
441     //
442     // use no_safepoint_check to get lock without attempting to &quot;sneak&quot;
443     { MonitorLocker mu_queue(VMOperationQueue_lock,
444                              Mutex::_no_safepoint_check_flag);
445 
446       // Look for new operation
447       assert(_cur_vm_operation == NULL, &quot;no current one should be executing&quot;);
448       _cur_vm_operation = _vm_queue-&gt;remove_next();
449 
450       while (!should_terminate() &amp;&amp; _cur_vm_operation == NULL) {
451         // wait with a timeout to guarantee safepoints at regular intervals
452         // (if there is cleanup work to do)
453         (void)mu_queue.wait(GuaranteedSafepointInterval);
454 
455         // Support for self destruction
456         if ((SelfDestructTimer != 0) &amp;&amp; !VMError::is_error_reported() &amp;&amp;
457             (os::elapsedTime() &gt; (double)SelfDestructTimer * 60.0)) {
458           tty-&gt;print_cr(&quot;VM self-destructed&quot;);
</pre>
<hr />
<pre>
463         // clean up will be done so we can skip this part.
464         if (!_vm_queue-&gt;peek_at_safepoint_priority()) {
465 
466           // Have to unlock VMOperationQueue_lock just in case no_op_safepoint()
467           // has to do a handshake when HandshakeALot is enabled.
468           MutexUnlocker mul(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
469           if ((_cur_vm_operation = VMThread::no_op_safepoint()) != NULL) {
470             // Force a safepoint since we have not had one for at least
471             // &#39;GuaranteedSafepointInterval&#39; milliseconds and we need to clean
472             // something. This will run all the clean-up processing that needs
473             // to be done at a safepoint.
474             SafepointSynchronize::begin();
475             #ifdef ASSERT
476             if (GCALotAtAllSafepoints) InterfaceSupport::check_gc_alot();
477             #endif
478             SafepointSynchronize::end();
479             _cur_vm_operation = NULL;
480           }
481         }
482         _cur_vm_operation = _vm_queue-&gt;remove_next();
<span class="line-removed">483 </span>
<span class="line-removed">484         // If we are at a safepoint we will evaluate all the operations that</span>
<span class="line-removed">485         // follow that also require a safepoint</span>
<span class="line-removed">486         if (_cur_vm_operation != NULL &amp;&amp;</span>
<span class="line-removed">487             _cur_vm_operation-&gt;evaluate_at_safepoint()) {</span>
<span class="line-removed">488           safepoint_ops = _vm_queue-&gt;drain_at_safepoint_priority();</span>
<span class="line-removed">489         }</span>
490       }
491 
492       if (should_terminate()) break;
493     } // Release mu_queue_lock
494 
495     //
496     // Execute VM operation
497     //
498     { HandleMark hm(VMThread::vm_thread());
499 
500       EventMark em(&quot;Executing VM operation: %s&quot;, vm_operation()-&gt;name());
501       assert(_cur_vm_operation != NULL, &quot;we should have found an operation to execute&quot;);
502 
503       // If we are at a safepoint we will evaluate all the operations that
504       // follow that also require a safepoint
505       if (_cur_vm_operation-&gt;evaluate_at_safepoint()) {
506         log_debug(vmthread)(&quot;Evaluating safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());
507 
508         SafepointSynchronize::begin();
509 
510         if (_timeout_task != NULL) {
511           _timeout_task-&gt;arm();
512         }
513 
514         evaluate_operation(_cur_vm_operation);
<span class="line-modified">515         // now process all queued safepoint ops, iteratively draining</span>
<span class="line-removed">516         // the queue until there are none left</span>
<span class="line-removed">517         do {</span>
<span class="line-removed">518           _cur_vm_operation = safepoint_ops;</span>
<span class="line-removed">519           if (_cur_vm_operation != NULL) {</span>
<span class="line-removed">520             do {</span>
<span class="line-removed">521               EventMark em(&quot;Executing coalesced safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());</span>
<span class="line-removed">522               log_debug(vmthread)(&quot;Evaluating coalesced safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());</span>
<span class="line-removed">523               // evaluate_operation deletes the op object so we have</span>
<span class="line-removed">524               // to grab the next op now</span>
<span class="line-removed">525               VM_Operation* next = _cur_vm_operation-&gt;next();</span>
<span class="line-removed">526               evaluate_operation(_cur_vm_operation);</span>
<span class="line-removed">527               _cur_vm_operation = next;</span>
<span class="line-removed">528               _coalesced_count++;</span>
<span class="line-removed">529             } while (_cur_vm_operation != NULL);</span>
<span class="line-removed">530           }</span>
<span class="line-removed">531           // There is a chance that a thread enqueued a safepoint op</span>
<span class="line-removed">532           // since we released the op-queue lock and initiated the safepoint.</span>
<span class="line-removed">533           // So we drain the queue again if there is anything there, as an</span>
<span class="line-removed">534           // optimization to try and reduce the number of safepoints.</span>
<span class="line-removed">535           // As the safepoint synchronizes us with JavaThreads we will see</span>
<span class="line-removed">536           // any enqueue made by a JavaThread, but the peek will not</span>
<span class="line-removed">537           // necessarily detect a concurrent enqueue by a GC thread, but</span>
<span class="line-removed">538           // that simply means the op will wait for the next major cycle of the</span>
<span class="line-removed">539           // VMThread - just as it would if the GC thread lost the race for</span>
<span class="line-removed">540           // the lock.</span>
<span class="line-removed">541           if (_vm_queue-&gt;peek_at_safepoint_priority()) {</span>
<span class="line-removed">542             // must hold lock while draining queue</span>
<span class="line-removed">543             MutexLocker mu_queue(VMOperationQueue_lock,</span>
<span class="line-removed">544                                  Mutex::_no_safepoint_check_flag);</span>
<span class="line-removed">545             safepoint_ops = _vm_queue-&gt;drain_at_safepoint_priority();</span>
<span class="line-removed">546           } else {</span>
<span class="line-removed">547             safepoint_ops = NULL;</span>
<span class="line-removed">548           }</span>
<span class="line-removed">549         } while(safepoint_ops != NULL);</span>
550 
551         if (_timeout_task != NULL) {
552           _timeout_task-&gt;disarm();
553         }
554 
555         // Complete safepoint synchronization
556         SafepointSynchronize::end();
557 
558       } else {  // not a safepoint operation
559         log_debug(vmthread)(&quot;Evaluating non-safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());
560         if (TraceLongCompiles) {
561           elapsedTimer t;
562           t.start();
563           evaluate_operation(_cur_vm_operation);
564           t.stop();
565           double secs = t.seconds();
566           if (secs * 1e3 &gt; LongCompileThreshold) {
567             // XXX - _cur_vm_operation should not be accessed after
568             // the completed count has been incremented; the waiting
569             // thread may have already freed this memory.
</pre>
</td>
<td>
<hr />
<pre>
 88   insert(_queue[prio]-&gt;prev(), op);
 89 }
 90 
 91 
 92 void VMOperationQueue::unlink(VM_Operation* q) {
 93   assert(q-&gt;next()-&gt;prev() == q &amp;&amp; q-&gt;prev()-&gt;next() == q, &quot;sanity check&quot;);
 94   q-&gt;prev()-&gt;set_next(q-&gt;next());
 95   q-&gt;next()-&gt;set_prev(q-&gt;prev());
 96 }
 97 
 98 VM_Operation* VMOperationQueue::queue_remove_front(int prio) {
 99   if (queue_empty(prio)) return NULL;
100   assert(_queue_length[prio] &gt;= 0, &quot;sanity check&quot;);
101   _queue_length[prio]--;
102   VM_Operation* r = _queue[prio]-&gt;next();
103   assert(r != _queue[prio], &quot;cannot remove base element&quot;);
104   unlink(r);
105   return r;
106 }
107 























108 //-----------------------------------------------------------------
109 // High-level interface
110 void VMOperationQueue::add(VM_Operation *op) {
111 
112   HOTSPOT_VMOPS_REQUEST(
113                    (char *) op-&gt;name(), strlen(op-&gt;name()),
114                    op-&gt;evaluate_at_safepoint() ? 0 : 1);
115 
116   // Encapsulates VM queue policy. Currently, that
117   // only involves putting them on the right list
118   queue_add(op-&gt;evaluate_at_safepoint() ? SafepointPriority : MediumPriority, op);
119 }
120 
121 VM_Operation* VMOperationQueue::remove_next() {
122   // Assuming VMOperation queue is two-level priority queue. If there are
123   // more than two priorities, we need a different scheduling algorithm.
124   assert(SafepointPriority == 0 &amp;&amp; MediumPriority == 1 &amp;&amp; nof_priorities == 2,
125          &quot;current algorithm does not work&quot;);
126 
127   // simple counter based scheduling to prevent starvation of lower priority
</pre>
<hr />
<pre>
159 
160 void VMOperationTimeoutTask::arm() {
161   _arm_time = os::javaTimeNanos();
162   Atomic::release_store_fence(&amp;_armed, 1);
163 }
164 
165 void VMOperationTimeoutTask::disarm() {
166   Atomic::release_store_fence(&amp;_armed, 0);
167 }
168 
169 //------------------------------------------------------------------------------------------------------------------
170 // Implementation of VMThread stuff
171 
172 bool              VMThread::_should_terminate   = false;
173 bool              VMThread::_terminated         = false;
174 Monitor*          VMThread::_terminate_lock     = NULL;
175 VMThread*         VMThread::_vm_thread          = NULL;
176 VM_Operation*     VMThread::_cur_vm_operation   = NULL;
177 VMOperationQueue* VMThread::_vm_queue           = NULL;
178 PerfCounter*      VMThread::_perf_accumulated_vm_operation_time = NULL;

179 VMOperationTimeoutTask* VMThread::_timeout_task = NULL;
180 
181 
182 void VMThread::create() {
183   assert(vm_thread() == NULL, &quot;we can only allocate one VMThread&quot;);
184   _vm_thread = new VMThread();
185 
186   if (AbortVMOnVMOperationTimeout) {
187     // Make sure we call the timeout task frequently enough, but not too frequent.
188     // Try to make the interval 10% of the timeout delay, so that we miss the timeout
189     // by those 10% at max. Periodic task also expects it to fit min/max intervals.
190     size_t interval = (size_t)AbortVMOnVMOperationTimeoutDelay / 10;
191     interval = interval / PeriodicTask::interval_gran * PeriodicTask::interval_gran;
192     interval = MAX2&lt;size_t&gt;(interval, PeriodicTask::min_interval);
193     interval = MIN2&lt;size_t&gt;(interval, PeriodicTask::max_interval);
194 
195     _timeout_task = new VMOperationTimeoutTask(interval);
196     _timeout_task-&gt;enroll();
197   } else {
198     assert(_timeout_task == NULL, &quot;sanity&quot;);
</pre>
<hr />
<pre>
244   // Note that I cannot call os::set_priority because it expects Java
245   // priorities and I am *explicitly* using OS priorities so that it&#39;s
246   // possible to set the VM thread priority higher than any Java thread.
247   os::set_native_priority( this, prio );
248 
249   // Wait for VM_Operations until termination
250   this-&gt;loop();
251 
252   // Note the intention to exit before safepointing.
253   // 6295565  This has the effect of waiting for any large tty
254   // outputs to finish.
255   if (xtty != NULL) {
256     ttyLocker ttyl;
257     xtty-&gt;begin_elem(&quot;destroy_vm&quot;);
258     xtty-&gt;stamp();
259     xtty-&gt;end_elem();
260     assert(should_terminate(), &quot;termination flag must be set&quot;);
261   }
262 
263   if (AsyncDeflateIdleMonitors &amp;&amp; log_is_enabled(Info, monitorinflation)) {
<span class="line-modified">264     // AsyncDeflateIdleMonitors does a special deflation in order</span>
<span class="line-modified">265     // to reduce the in-use monitor population that is reported by</span>
<span class="line-modified">266     // ObjectSynchronizer::log_in_use_monitor_details() at VM exit.</span>
<span class="line-modified">267     ObjectSynchronizer::request_deflate_idle_monitors();</span>

268   }
269 
270   // 4526887 let VM thread exit at Safepoint
271   _cur_vm_operation = &amp;halt_op;
272   SafepointSynchronize::begin();
273 
274   if (VerifyBeforeExit) {
275     HandleMark hm(VMThread::vm_thread());
276     // Among other things, this ensures that Eden top is correct.
277     Universe::heap()-&gt;prepare_for_verify();
278     // Silent verification so as not to pollute normal output,
279     // unless we really asked for it.
280     Universe::verify();
281   }
282 
283   CompileBroker::set_should_block();
284 
285   // wait for threads (compiler threads or daemon threads) in the
286   // _thread_in_native state to block.
287   VM_Exit::wait_for_threads_in_native_to_block();
</pre>
<hr />
<pre>
393   // Check for a cleanup before SafepointALot to keep stats correct.
394   long interval_ms = SafepointTracing::time_since_last_safepoint_ms();
395   bool max_time_exceeded = GuaranteedSafepointInterval != 0 &amp;&amp;
396                            (interval_ms &gt;= GuaranteedSafepointInterval);
397   if (max_time_exceeded &amp;&amp; SafepointSynchronize::is_cleanup_needed()) {
398     return &amp;cleanup_op;
399   }
400   if (SafepointALot) {
401     return &amp;safepointALot_op;
402   }
403   // Nothing to be done.
404   return NULL;
405 }
406 
407 void VMThread::loop() {
408   assert(_cur_vm_operation == NULL, &quot;no current one should be executing&quot;);
409 
410   SafepointSynchronize::init(_vm_thread);
411 
412   while(true) {

413     //
414     // Wait for VM operation
415     //
416     // use no_safepoint_check to get lock without attempting to &quot;sneak&quot;
417     { MonitorLocker mu_queue(VMOperationQueue_lock,
418                              Mutex::_no_safepoint_check_flag);
419 
420       // Look for new operation
421       assert(_cur_vm_operation == NULL, &quot;no current one should be executing&quot;);
422       _cur_vm_operation = _vm_queue-&gt;remove_next();
423 
424       while (!should_terminate() &amp;&amp; _cur_vm_operation == NULL) {
425         // wait with a timeout to guarantee safepoints at regular intervals
426         // (if there is cleanup work to do)
427         (void)mu_queue.wait(GuaranteedSafepointInterval);
428 
429         // Support for self destruction
430         if ((SelfDestructTimer != 0) &amp;&amp; !VMError::is_error_reported() &amp;&amp;
431             (os::elapsedTime() &gt; (double)SelfDestructTimer * 60.0)) {
432           tty-&gt;print_cr(&quot;VM self-destructed&quot;);
</pre>
<hr />
<pre>
437         // clean up will be done so we can skip this part.
438         if (!_vm_queue-&gt;peek_at_safepoint_priority()) {
439 
440           // Have to unlock VMOperationQueue_lock just in case no_op_safepoint()
441           // has to do a handshake when HandshakeALot is enabled.
442           MutexUnlocker mul(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
443           if ((_cur_vm_operation = VMThread::no_op_safepoint()) != NULL) {
444             // Force a safepoint since we have not had one for at least
445             // &#39;GuaranteedSafepointInterval&#39; milliseconds and we need to clean
446             // something. This will run all the clean-up processing that needs
447             // to be done at a safepoint.
448             SafepointSynchronize::begin();
449             #ifdef ASSERT
450             if (GCALotAtAllSafepoints) InterfaceSupport::check_gc_alot();
451             #endif
452             SafepointSynchronize::end();
453             _cur_vm_operation = NULL;
454           }
455         }
456         _cur_vm_operation = _vm_queue-&gt;remove_next();







457       }
458 
459       if (should_terminate()) break;
460     } // Release mu_queue_lock
461 
462     //
463     // Execute VM operation
464     //
465     { HandleMark hm(VMThread::vm_thread());
466 
467       EventMark em(&quot;Executing VM operation: %s&quot;, vm_operation()-&gt;name());
468       assert(_cur_vm_operation != NULL, &quot;we should have found an operation to execute&quot;);
469 
470       // If we are at a safepoint we will evaluate all the operations that
471       // follow that also require a safepoint
472       if (_cur_vm_operation-&gt;evaluate_at_safepoint()) {
473         log_debug(vmthread)(&quot;Evaluating safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());
474 
475         SafepointSynchronize::begin();
476 
477         if (_timeout_task != NULL) {
478           _timeout_task-&gt;arm();
479         }
480 
481         evaluate_operation(_cur_vm_operation);
<span class="line-modified">482         _cur_vm_operation = NULL;</span>


































483 
484         if (_timeout_task != NULL) {
485           _timeout_task-&gt;disarm();
486         }
487 
488         // Complete safepoint synchronization
489         SafepointSynchronize::end();
490 
491       } else {  // not a safepoint operation
492         log_debug(vmthread)(&quot;Evaluating non-safepoint VM operation: %s&quot;, _cur_vm_operation-&gt;name());
493         if (TraceLongCompiles) {
494           elapsedTimer t;
495           t.start();
496           evaluate_operation(_cur_vm_operation);
497           t.stop();
498           double secs = t.seconds();
499           if (secs * 1e3 &gt; LongCompileThreshold) {
500             // XXX - _cur_vm_operation should not be accessed after
501             // the completed count has been incremented; the waiting
502             // thread may have already freed this memory.
</pre>
</td>
</tr>
</table>
<center><a href="vmStructs.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="vmThread.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>