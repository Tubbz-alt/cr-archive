<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/block.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="arraycopynode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c2_globals.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/block.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_BLOCK_HPP
 26 #define SHARE_OPTO_BLOCK_HPP
 27 
 28 #include &quot;opto/multnode.hpp&quot;
 29 #include &quot;opto/node.hpp&quot;
 30 #include &quot;opto/phase.hpp&quot;

 31 
 32 // Optimization - Graph Style
 33 
 34 class Block;
 35 class CFGLoop;
 36 class MachCallNode;
 37 class Matcher;
 38 class RootNode;
 39 class VectorSet;
 40 class PhaseChaitin;
 41 struct Tarjan;
 42 
 43 //------------------------------Block_Array------------------------------------
 44 // Map dense integer indices to Blocks.  Uses classic doubling-array trick.
 45 // Abstractly provides an infinite array of Block*&#39;s, initialized to NULL.
 46 // Note that the constructor just zeros things, and since I use Arena
 47 // allocation I do not need a destructor to reclaim storage.
 48 class Block_Array : public ResourceObj {
 49   friend class VMStructs;
 50   uint _size;                   // allocated size, as opposed to formal limit
</pre>
<hr />
<pre>
482   Block* insert_anti_dependences(Block* LCA, Node* load, bool verify = false);
483   void verify_anti_dependences(Block* LCA, Node* load) const {
484     assert(LCA == get_block_for_node(load), &quot;should already be scheduled&quot;);
485     const_cast&lt;PhaseCFG*&gt;(this)-&gt;insert_anti_dependences(LCA, load, true);
486   }
487 
488   bool move_to_next(Block* bx, uint b_index);
489   void move_to_end(Block* bx, uint b_index);
490 
491   void insert_goto_at(uint block_no, uint succ_no);
492 
493   // Check for NeverBranch at block end.  This needs to become a GOTO to the
494   // true target.  NeverBranch are treated as a conditional branch that always
495   // goes the same direction for most of the optimizer and are used to give a
496   // fake exit path to infinite loops.  At this late stage they need to turn
497   // into Goto&#39;s so that when you enter the infinite loop you indeed hang.
498   void convert_NeverBranch_to_Goto(Block *b);
499 
500   CFGLoop* create_loop_tree();
501   bool is_dominator(Node* dom_node, Node* node);
<span class="line-modified">502 </span>



503   #ifndef PRODUCT
504   bool _trace_opto_pipelining;  // tracing flag
505   #endif
506 
507  public:
508   PhaseCFG(Arena* arena, RootNode* root, Matcher&amp; matcher);
509 
510   void set_latency_for_node(Node* node, int latency) {
511     _node_latency-&gt;at_put_grow(node-&gt;_idx, latency);
512   }
513 
514   uint get_latency_for_node(Node* node) {
515     return _node_latency-&gt;at_grow(node-&gt;_idx);
516   }
517 
518   // Get the outer most frequency
519   double get_outer_loop_frequency() const {
520     return _outer_loop_frequency;
521   }
522 
</pre>
</td>
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_BLOCK_HPP
 26 #define SHARE_OPTO_BLOCK_HPP
 27 
 28 #include &quot;opto/multnode.hpp&quot;
 29 #include &quot;opto/node.hpp&quot;
 30 #include &quot;opto/phase.hpp&quot;
<span class="line-added"> 31 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
 32 
 33 // Optimization - Graph Style
 34 
 35 class Block;
 36 class CFGLoop;
 37 class MachCallNode;
 38 class Matcher;
 39 class RootNode;
 40 class VectorSet;
 41 class PhaseChaitin;
 42 struct Tarjan;
 43 
 44 //------------------------------Block_Array------------------------------------
 45 // Map dense integer indices to Blocks.  Uses classic doubling-array trick.
 46 // Abstractly provides an infinite array of Block*&#39;s, initialized to NULL.
 47 // Note that the constructor just zeros things, and since I use Arena
 48 // allocation I do not need a destructor to reclaim storage.
 49 class Block_Array : public ResourceObj {
 50   friend class VMStructs;
 51   uint _size;                   // allocated size, as opposed to formal limit
</pre>
<hr />
<pre>
483   Block* insert_anti_dependences(Block* LCA, Node* load, bool verify = false);
484   void verify_anti_dependences(Block* LCA, Node* load) const {
485     assert(LCA == get_block_for_node(load), &quot;should already be scheduled&quot;);
486     const_cast&lt;PhaseCFG*&gt;(this)-&gt;insert_anti_dependences(LCA, load, true);
487   }
488 
489   bool move_to_next(Block* bx, uint b_index);
490   void move_to_end(Block* bx, uint b_index);
491 
492   void insert_goto_at(uint block_no, uint succ_no);
493 
494   // Check for NeverBranch at block end.  This needs to become a GOTO to the
495   // true target.  NeverBranch are treated as a conditional branch that always
496   // goes the same direction for most of the optimizer and are used to give a
497   // fake exit path to infinite loops.  At this late stage they need to turn
498   // into Goto&#39;s so that when you enter the infinite loop you indeed hang.
499   void convert_NeverBranch_to_Goto(Block *b);
500 
501   CFGLoop* create_loop_tree();
502   bool is_dominator(Node* dom_node, Node* node);
<span class="line-modified">503   bool is_CFG(Node* n);</span>
<span class="line-added">504   bool is_control_proj_or_safepoint(Node* n);</span>
<span class="line-added">505   Block* find_block_for_node(Node* n);</span>
<span class="line-added">506   bool is_dominating_control(Node* dom_ctrl, Node* n);</span>
507   #ifndef PRODUCT
508   bool _trace_opto_pipelining;  // tracing flag
509   #endif
510 
511  public:
512   PhaseCFG(Arena* arena, RootNode* root, Matcher&amp; matcher);
513 
514   void set_latency_for_node(Node* node, int latency) {
515     _node_latency-&gt;at_put_grow(node-&gt;_idx, latency);
516   }
517 
518   uint get_latency_for_node(Node* node) {
519     return _node_latency-&gt;at_grow(node-&gt;_idx);
520   }
521 
522   // Get the outer most frequency
523   double get_outer_loop_frequency() const {
524     return _outer_loop_frequency;
525   }
526 
</pre>
</td>
</tr>
</table>
<center><a href="arraycopynode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c2_globals.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>