<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.aarch64/src/org/graalvm/compiler/lir/aarch64/AArch64Move.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2013, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 
 25 package org.graalvm.compiler.lir.aarch64;
 26 
 27 import static jdk.vm.ci.aarch64.AArch64.sp;
 28 import static jdk.vm.ci.aarch64.AArch64.zr;
 29 import static jdk.vm.ci.code.ValueUtil.asAllocatableValue;
 30 import static jdk.vm.ci.code.ValueUtil.asRegister;
 31 import static jdk.vm.ci.code.ValueUtil.asStackSlot;
 32 import static jdk.vm.ci.code.ValueUtil.isRegister;
 33 import static jdk.vm.ci.code.ValueUtil.isStackSlot;
 34 import static org.graalvm.compiler.core.common.GraalOptions.GeneratePIC;
 35 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.COMPOSITE;
 36 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.CONST;
 37 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.HINT;
 38 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.ILLEGAL;
 39 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.REG;
 40 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.STACK;
 41 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.UNINITIALIZED;
 42 import static org.graalvm.compiler.lir.LIRValueUtil.asJavaConstant;
 43 import static org.graalvm.compiler.lir.LIRValueUtil.isJavaConstant;
 44 
 45 import org.graalvm.compiler.asm.Label;
 46 import org.graalvm.compiler.asm.aarch64.AArch64Address;
 47 import org.graalvm.compiler.asm.aarch64.AArch64Assembler;
 48 import org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler;
 49 import org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.ScratchRegister;
 50 import org.graalvm.compiler.core.common.CompressEncoding;
 51 import org.graalvm.compiler.core.common.LIRKind;
 52 import org.graalvm.compiler.core.common.spi.LIRKindTool;
 53 import org.graalvm.compiler.core.common.type.DataPointerConstant;
 54 import org.graalvm.compiler.debug.GraalError;
 55 import org.graalvm.compiler.lir.LIRFrameState;
 56 import org.graalvm.compiler.lir.LIRInstructionClass;
 57 import org.graalvm.compiler.lir.Opcode;
 58 import org.graalvm.compiler.lir.StandardOp;
 59 import org.graalvm.compiler.lir.StandardOp.LoadConstantOp;
 60 import org.graalvm.compiler.lir.StandardOp.NullCheck;
 61 import org.graalvm.compiler.lir.StandardOp.ValueMoveOp;
 62 import org.graalvm.compiler.lir.VirtualStackSlot;
 63 import org.graalvm.compiler.lir.asm.CompilationResultBuilder;
 64 import org.graalvm.compiler.options.OptionValues;
 65 
 66 import jdk.vm.ci.aarch64.AArch64Kind;
 67 import jdk.vm.ci.code.MemoryBarriers;
 68 import jdk.vm.ci.code.Register;
 69 import jdk.vm.ci.code.StackSlot;
 70 import jdk.vm.ci.meta.AllocatableValue;
 71 import jdk.vm.ci.meta.Constant;
 72 import jdk.vm.ci.meta.JavaConstant;
 73 import jdk.vm.ci.meta.PlatformKind;
 74 import jdk.vm.ci.meta.Value;
 75 
 76 public class AArch64Move {
 77 
 78     public static class LoadInlineConstant extends AArch64LIRInstruction implements LoadConstantOp {
 79         public static final LIRInstructionClass&lt;LoadInlineConstant&gt; TYPE = LIRInstructionClass.create(LoadInlineConstant.class);
 80 
 81         private JavaConstant constant;
 82         @Def({REG, STACK}) AllocatableValue result;
 83 
 84         public LoadInlineConstant(JavaConstant constant, AllocatableValue result) {
 85             super(TYPE);
 86             this.constant = constant;
 87             this.result = result;
 88         }
 89 
 90         @Override
 91         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
 92             if (isRegister(result)) {
 93                 const2reg(crb, masm, result, constant);
 94             } else if (isStackSlot(result)) {
 95                 StackSlot slot = asStackSlot(result);
 96                 const2stack(crb, masm, slot, constant);
 97             }
 98         }
 99 
100         @Override
101         public Constant getConstant() {
102             return constant;
103         }
104 
105         @Override
106         public AllocatableValue getResult() {
107             return result;
108         }
109     }
110 
111     @Opcode(&quot;MOVE&quot;)
112     public static class Move extends AArch64LIRInstruction implements ValueMoveOp {
113         public static final LIRInstructionClass&lt;Move&gt; TYPE = LIRInstructionClass.create(Move.class);
114 
115         @Def({REG, STACK, HINT}) protected AllocatableValue result;
116         @Use({REG, STACK}) protected AllocatableValue input;
117 
118         public Move(AllocatableValue result, AllocatableValue input) {
119             super(TYPE);
120             this.result = result;
121             this.input = input;
122             assert !(isStackSlot(result) &amp;&amp; isStackSlot(input));
123         }
124 
125         @Override
126         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
127             move(crb, masm, getResult(), getInput());
128         }
129 
130         @Override
131         public AllocatableValue getInput() {
132             return input;
133         }
134 
135         @Override
136         public AllocatableValue getResult() {
137             return result;
138         }
139     }
140 
141     public static class LoadAddressOp extends AArch64LIRInstruction {
142         public static final LIRInstructionClass&lt;LoadAddressOp&gt; TYPE = LIRInstructionClass.create(LoadAddressOp.class);
143 
144         @Def protected AllocatableValue result;
145         @Use(COMPOSITE) protected AArch64AddressValue address;
146 
147         public LoadAddressOp(AllocatableValue result, AArch64AddressValue address) {
148             super(TYPE);
149             this.result = result;
150             this.address = address;
151         }
152 
153         @Override
154         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
155             Register dst = asRegister(result);
156             AArch64Address adr = address.toAddress();
157             masm.loadAddress(dst, adr, address.getScaleFactor());
158         }
159     }
160 
161     public static class LoadDataOp extends AArch64LIRInstruction {
162         public static final LIRInstructionClass&lt;LoadDataOp&gt; TYPE = LIRInstructionClass.create(LoadDataOp.class);
163 
164         @Def protected AllocatableValue result;
165         private final DataPointerConstant data;
166 
167         public LoadDataOp(AllocatableValue result, DataPointerConstant data) {
168             super(TYPE);
169             this.result = result;
170             this.data = data;
171         }
172 
173         @Override
174         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
175             Register dst = asRegister(result);
176             if (crb.compilationResult.isImmutablePIC()) {
177                 crb.recordDataReferenceInCode(data);
178                 masm.addressOf(dst);
179             } else {
180                 masm.loadAddress(dst, (AArch64Address) crb.recordDataReferenceInCode(data), data.getAlignment());
181             }
182         }
183     }
184 
185     public static class StackLoadAddressOp extends AArch64LIRInstruction {
186         public static final LIRInstructionClass&lt;StackLoadAddressOp&gt; TYPE = LIRInstructionClass.create(StackLoadAddressOp.class);
187 
188         @Def protected AllocatableValue result;
189         @Use({STACK, UNINITIALIZED}) protected AllocatableValue slot;
190 
191         public StackLoadAddressOp(AllocatableValue result, AllocatableValue slot) {
192             super(TYPE);
193             assert slot instanceof VirtualStackSlot || slot instanceof StackSlot;
194             this.result = result;
195             this.slot = slot;
196         }
197 
198         @Override
199         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
200             try (ScratchRegister addrReg = masm.getScratchRegister()) {
201                 AArch64Address address = loadStackSlotAddress(crb, masm, (StackSlot) slot, addrReg.getRegister());
202                 PlatformKind kind = AArch64Kind.QWORD;
203                 masm.loadAddress(asRegister(result, kind), address, kind.getSizeInBytes());
204             }
205         }
206     }
207 
208     public static class MembarOp extends AArch64LIRInstruction {
209         public static final LIRInstructionClass&lt;MembarOp&gt; TYPE = LIRInstructionClass.create(MembarOp.class);
210 
211         // For future use.
212         @SuppressWarnings(&quot;unused&quot;) private final int barriers;
213 
214         public MembarOp(int barriers) {
215             super(TYPE);
216             this.barriers = barriers;
217         }
218 
219         @Override
220         // The odd-looking @SuppressWarnings(&quot;all&quot;) is here because of
221         // a compiler bug which warns that crb is unused, and also
222         // warns that @SuppressWarnings(&quot;unused&quot;) is unnecessary.
223         public void emitCode(@SuppressWarnings(&quot;all&quot;) CompilationResultBuilder crb, AArch64MacroAssembler masm) {
224             assert barriers &gt;= MemoryBarriers.LOAD_LOAD &amp;&amp; barriers &lt;= (MemoryBarriers.STORE_STORE | MemoryBarriers.STORE_LOAD | MemoryBarriers.LOAD_STORE | MemoryBarriers.LOAD_LOAD);
225             switch (barriers) {
226                 case MemoryBarriers.STORE_STORE:
227                     masm.dmb(AArch64MacroAssembler.BarrierKind.STORE_STORE);
228                     break;
229                 case MemoryBarriers.LOAD_LOAD:
230                 case MemoryBarriers.LOAD_STORE:
231                 case MemoryBarriers.LOAD_LOAD | MemoryBarriers.LOAD_STORE:
232                     masm.dmb(AArch64MacroAssembler.BarrierKind.LOAD_LOAD);
233                     break;
234                 default:
235                     masm.dmb(AArch64MacroAssembler.BarrierKind.ANY_ANY);
236                     break;
237             }
238         }
239     }
240 
241     abstract static class MemOp extends AArch64LIRInstruction implements StandardOp.ImplicitNullCheck {
242 
243         protected final AArch64Kind kind;
244         @Use({COMPOSITE}) protected AArch64AddressValue addressValue;
245         @State protected LIRFrameState state;
246 
247         MemOp(LIRInstructionClass&lt;? extends MemOp&gt; c, AArch64Kind kind, AArch64AddressValue address, LIRFrameState state) {
248             super(c);
249             this.kind = kind;
250             this.addressValue = address;
251             this.state = state;
252         }
253 
254         protected abstract void emitMemAccess(CompilationResultBuilder crb, AArch64MacroAssembler masm);
255 
256         @Override
257         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
258             int prePosition = masm.position();
259             emitMemAccess(crb, masm);
260             if (state != null) {
261                 int implicitExceptionPosition = prePosition;
262                 // Adjust implicit exception position if this ldr/str has been merged to ldp/stp.
263                 if (kind.isInteger() &amp;&amp; prePosition == masm.position() &amp;&amp; masm.isImmLoadStoreMerged()) {
264                     implicitExceptionPosition = prePosition - 4;
265                     if (crb.isImplicitExceptionExist(implicitExceptionPosition)) {
266                         return;
267                     }
268                 }
269                 crb.recordImplicitException(implicitExceptionPosition, state);
270             }
271         }
272 
273         @Override
274         public boolean makeNullCheckFor(Value value, LIRFrameState nullCheckState, int implicitNullCheckLimit) {
275             int displacement = addressValue.getDisplacement();
276             if (state == null &amp;&amp; value.equals(addressValue.getBase()) &amp;&amp; addressValue.getOffset().equals(Value.ILLEGAL) &amp;&amp; displacement &gt;= 0 &amp;&amp; displacement &lt; implicitNullCheckLimit) {
277                 state = nullCheckState;
278                 return true;
279             }
280             return false;
281         }
282     }
283 
284     public static final class LoadOp extends MemOp {
285         public static final LIRInstructionClass&lt;LoadOp&gt; TYPE = LIRInstructionClass.create(LoadOp.class);
286 
287         @Def protected AllocatableValue result;
288 
289         public LoadOp(AArch64Kind kind, AllocatableValue result, AArch64AddressValue address, LIRFrameState state) {
290             super(TYPE, kind, address, state);
291             this.result = result;
292         }
293 
294         @Override
295         protected void emitMemAccess(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
296             AArch64Address address = addressValue.toAddress();
297             Register dst = asRegister(result);
298 
299             int destSize = result.getPlatformKind().getSizeInBytes() * Byte.SIZE;
300             int srcSize = kind.getSizeInBytes() * Byte.SIZE;
301             if (kind.isInteger()) {
302                 masm.ldr(srcSize, dst, address);
303             } else {
304                 assert srcSize == destSize;
305                 masm.fldr(srcSize, dst, address);
306             }
307         }
308     }
309 
310     public static class StoreOp extends MemOp {
311         public static final LIRInstructionClass&lt;StoreOp&gt; TYPE = LIRInstructionClass.create(StoreOp.class);
312         @Use protected AllocatableValue input;
313 
314         public StoreOp(AArch64Kind kind, AArch64AddressValue address, AllocatableValue input, LIRFrameState state) {
315             super(TYPE, kind, address, state);
316             this.input = input;
317         }
318 
319         @Override
320         protected void emitMemAccess(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
321             emitStore(crb, masm, kind, addressValue.toAddress(), input);
322         }
323     }
324 
325     public static final class StoreConstantOp extends MemOp {
326         public static final LIRInstructionClass&lt;StoreConstantOp&gt; TYPE = LIRInstructionClass.create(StoreConstantOp.class);
327 
328         protected final JavaConstant input;
329 
330         public StoreConstantOp(AArch64Kind kind, AArch64AddressValue address, JavaConstant input, LIRFrameState state) {
331             super(TYPE, kind, address, state);
332             this.input = input;
333             if (!input.isDefaultForKind()) {
334                 throw GraalError.shouldNotReachHere(&quot;Can only store null constants to memory&quot;);
335             }
336         }
337 
338         @Override
339         public void emitMemAccess(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
340             emitStore(crb, masm, kind, addressValue.toAddress(), zr.asValue(LIRKind.combine(addressValue)));
341         }
342     }
343 
344     public static final class NullCheckOp extends AArch64LIRInstruction implements NullCheck {
345         public static final LIRInstructionClass&lt;NullCheckOp&gt; TYPE = LIRInstructionClass.create(NullCheckOp.class);
346 
347         @Use(COMPOSITE) protected AArch64AddressValue address;
348         @State protected LIRFrameState state;
349 
350         public NullCheckOp(AArch64AddressValue address, LIRFrameState state) {
351             super(TYPE);
352             this.address = address;
353             this.state = state;
354         }
355 
356         @Override
357         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
358             int prePosition = masm.position();
359             masm.ldr(64, zr, address.toAddress());
360             int implicitExceptionPosition = prePosition;
361             // Adjust implicit exception position if this ldr has been merged to ldp.
362             if (prePosition == masm.position() &amp;&amp; masm.isImmLoadStoreMerged()) {
363                 implicitExceptionPosition = prePosition - 4;
364                 if (crb.isImplicitExceptionExist(implicitExceptionPosition)) {
365                     return;
366                 }
367             }
368             crb.recordImplicitException(implicitExceptionPosition, state);
369         }
370 
371         @Override
372         public Value getCheckedValue() {
373             return address.base;
374         }
375 
376         @Override
377         public LIRFrameState getState() {
378             return state;
379         }
380     }
381 
382     private static void emitStore(@SuppressWarnings(&quot;unused&quot;) CompilationResultBuilder crb, AArch64MacroAssembler masm, AArch64Kind kind, AArch64Address dst, Value src) {
383         int destSize = kind.getSizeInBytes() * Byte.SIZE;
384         if (kind.isInteger()) {
385             masm.str(destSize, asRegister(src), dst);
386         } else {
387             masm.fstr(destSize, asRegister(src), dst);
388         }
389     }
390 
391     public static void move(CompilationResultBuilder crb, AArch64MacroAssembler masm, AllocatableValue result, Value input) {
392         if (isRegister(input)) {
393             if (isRegister(result)) {
394                 reg2reg(crb, masm, result, asAllocatableValue(input));
395             } else if (isStackSlot(result)) {
396                 reg2stack(crb, masm, result, asAllocatableValue(input));
397             } else {
398                 throw GraalError.shouldNotReachHere();
399             }
400         } else if (isStackSlot(input)) {
401             if (isRegister(result)) {
402                 stack2reg(crb, masm, result, asAllocatableValue(input));
403             } else if (isStackSlot(result)) {
404                 emitStackMove(crb, masm, result, input);
405             } else {
406                 throw GraalError.shouldNotReachHere();
407             }
408         } else if (isJavaConstant(input)) {
409             if (isRegister(result)) {
410                 const2reg(crb, masm, result, asJavaConstant(input));
411             } else {
412                 throw GraalError.shouldNotReachHere();
413             }
414         } else {
415             throw GraalError.shouldNotReachHere();
416         }
417     }
418 
419     private static void emitStackMove(CompilationResultBuilder crb, AArch64MacroAssembler masm, AllocatableValue result, Value input) {
420         try (ScratchRegister r1 = masm.getScratchRegister()) {
421             try (ScratchRegister r2 = masm.getScratchRegister()) {
422                 Register rscratch1 = r1.getRegister();
423                 Register rscratch2 = r2.getRegister();
424                 // use the slot kind to define the operand size
425                 PlatformKind kind = input.getPlatformKind();
426                 final int size = kind.getSizeInBytes() * Byte.SIZE;
427 
428                 // Always perform stack -&gt; stack copies through integer registers
429                 crb.blockComment(&quot;[stack -&gt; stack copy]&quot;);
430                 AArch64Address src = loadStackSlotAddress(crb, masm, asStackSlot(input), rscratch2);
431                 masm.ldr(size, rscratch1, src);
432                 AArch64Address dst = loadStackSlotAddress(crb, masm, asStackSlot(result), rscratch2);
433                 masm.str(size, rscratch1, dst);
434             }
435         }
436     }
437 
438     private static void reg2reg(@SuppressWarnings(&quot;unused&quot;) CompilationResultBuilder crb, AArch64MacroAssembler masm, AllocatableValue result, AllocatableValue input) {
439         Register dst = asRegister(result);
440         Register src = asRegister(input);
441         if (src.equals(dst)) {
442             return;
443         }
444         AArch64Kind kind = (AArch64Kind) input.getPlatformKind();
445         int size = kind.getSizeInBytes() * Byte.SIZE;
446         if (kind.isInteger()) {
447             masm.mov(size, dst, src);
448         } else {
449             masm.fmov(size, dst, src);
450         }
451     }
452 
453     static void reg2stack(CompilationResultBuilder crb, AArch64MacroAssembler masm, AllocatableValue result, AllocatableValue input) {
454         AArch64Address dest;
455         try (ScratchRegister scratch = masm.getScratchRegister()) {
456             dest = loadStackSlotAddress(crb, masm, asStackSlot(result), scratch.getRegister());
457         }
458         Register src = asRegister(input);
459         // use the slot kind to define the operand size
460         AArch64Kind kind = (AArch64Kind) result.getPlatformKind();
461         final int size = kind.getSizeInBytes() * Byte.SIZE;
462         if (kind.isInteger()) {
463             masm.str(size, src, dest);
464         } else {
465             masm.fstr(size, src, dest);
466         }
467     }
468 
469     static void stack2reg(CompilationResultBuilder crb, AArch64MacroAssembler masm, AllocatableValue result, AllocatableValue input) {
470         AArch64Kind kind = (AArch64Kind) input.getPlatformKind();
471         // use the slot kind to define the operand size
472         final int size = kind.getSizeInBytes() * Byte.SIZE;
473         if (kind.isInteger()) {
474             AArch64Address src = loadStackSlotAddress(crb, masm, asStackSlot(input), result);
475             masm.ldr(size, asRegister(result), src);
476         } else {
477             try (ScratchRegister sc = masm.getScratchRegister()) {
478                 AllocatableValue scratchRegisterValue = sc.getRegister().asValue(LIRKind.combine(input));
479                 AArch64Address src = loadStackSlotAddress(crb, masm, asStackSlot(input), scratchRegisterValue);
480                 masm.fldr(size, asRegister(result), src);
481             }
482         }
483     }
484 
485     private static void const2reg(CompilationResultBuilder crb, AArch64MacroAssembler masm, Value result, JavaConstant input) {
486         Register dst = asRegister(result);
487         switch (input.getJavaKind().getStackKind()) {
488             case Int:
489                 final int value = input.asInt();
490                 int maskedValue;
491                 switch (input.getJavaKind()) {
492                     case Boolean:
493                     case Byte:
494                         maskedValue = value &amp; 0xFF;
495                         break;
496                     case Char:
497                     case Short:
498                         maskedValue = value &amp; 0xFFFF;
499                         break;
500                     case Int:
501                         maskedValue = value;
502                         break;
503                     default:
504                         throw GraalError.shouldNotReachHere();
505                 }
506                 masm.mov(dst, maskedValue);
507                 break;
508             case Long:
509                 masm.mov(dst, input.asLong());
510                 break;
511             case Float:
512                 if (AArch64MacroAssembler.isFloatImmediate(input.asFloat())) {
513                     masm.fmov(32, dst, input.asFloat());
514                 } else if (crb.compilationResult.isImmutablePIC()) {
515                     try (ScratchRegister scr = masm.getScratchRegister()) {
516                         Register scratch = scr.getRegister();
517                         masm.mov(scratch, Float.floatToRawIntBits(input.asFloat()));
518                         masm.fmov(32, dst, scratch);
519                     }
520                 } else {
521                     try (ScratchRegister scr = masm.getScratchRegister()) {
522                         Register scratch = scr.getRegister();
523                         crb.asFloatConstRef(input);
524                         masm.addressOf(scratch);
525                         masm.fldr(32, dst, AArch64Address.createBaseRegisterOnlyAddress(scratch));
526                     }
527                 }
528                 break;
529             case Double:
530                 if (AArch64MacroAssembler.isDoubleImmediate(input.asDouble())) {
531                     masm.fmov(64, dst, input.asDouble());
532                 } else if (crb.compilationResult.isImmutablePIC()) {
533                     try (ScratchRegister scr = masm.getScratchRegister()) {
534                         Register scratch = scr.getRegister();
535                         masm.mov(scratch, Double.doubleToRawLongBits(input.asDouble()));
536                         masm.fmov(64, dst, scratch);
537                     }
538                 } else {
539                     try (ScratchRegister scr = masm.getScratchRegister()) {
540                         Register scratch = scr.getRegister();
541                         crb.asDoubleConstRef(input);
542                         masm.addressOf(scratch);
543                         masm.fldr(64, dst, AArch64Address.createBaseRegisterOnlyAddress(scratch));
544                     }
545                 }
546                 break;
547             case Object:
548                 if (input.isNull()) {
549                     if (crb.mustReplaceWithUncompressedNullRegister(input)) {
550                         masm.mov(64, dst, crb.uncompressedNullRegister);
551                     } else {
552                         masm.mov(dst, 0);
553                     }
554                 } else if (crb.target.inlineObjects) {
555                     crb.recordInlineDataInCode(input);
556                     masm.mov(dst, 0xDEADDEADDEADDEADL, true);
557                 } else {
<a name="2" id="anc2"></a><span class="line-modified">558                     masm.ldr(64, dst, (AArch64Address) crb.recordDataReferenceInCode(input, 8));</span>


559                 }
560                 break;
561             default:
562                 throw GraalError.shouldNotReachHere(&quot;kind=&quot; + input.getJavaKind().getStackKind());
563         }
564     }
565 
566     private static void const2stack(CompilationResultBuilder crb, AArch64MacroAssembler masm, Value result, JavaConstant constant) {
567         try (ScratchRegister addrReg = masm.getScratchRegister()) {
568             StackSlot slot = (StackSlot) result;
569             AArch64Address resultAddress = loadStackSlotAddress(crb, masm, slot, addrReg.getRegister());
570             if (constant.isNull() &amp;&amp; !crb.mustReplaceWithUncompressedNullRegister(constant)) {
571                 emitStore(crb, masm, (AArch64Kind) result.getPlatformKind(), resultAddress, zr.asValue(LIRKind.combine(result)));
572             } else {
573                 try (ScratchRegister sc = masm.getScratchRegister()) {
574                     Value scratchRegisterValue = sc.getRegister().asValue(LIRKind.combine(result));
575                     const2reg(crb, masm, scratchRegisterValue, constant);
576                     emitStore(crb, masm, (AArch64Kind) result.getPlatformKind(), resultAddress, scratchRegisterValue);
577                 }
578             }
579         }
580     }
581 
582     /**
583      * Returns AArch64Address of given StackSlot. We cannot use CompilationResultBuilder.asAddress
584      * since this calls AArch64MacroAssembler.makeAddress with displacements that may be larger than
585      * 9-bit signed, which cannot be handled by that method.
586      *
587      * Instead we create an address ourselves. We use scaled unsigned addressing since we know the
588      * transfersize, which gives us a 15-bit address range (for longs/doubles) respectively a 14-bit
589      * range (for everything else).
590      *
591      * @param scratch Scratch register that can be used to load address. If Value.ILLEGAL this
592      *            instruction fails if we try to access a StackSlot that is too large to be loaded
593      *            directly.
594      * @return AArch64Address of given StackSlot. Uses scratch register if necessary to do so.
595      */
596     private static AArch64Address loadStackSlotAddress(CompilationResultBuilder crb, AArch64MacroAssembler masm, StackSlot slot, AllocatableValue scratch) {
597         Register scratchReg = Value.ILLEGAL.equals(scratch) ? zr : asRegister(scratch);
598         return loadStackSlotAddress(crb, masm, slot, scratchReg);
599     }
600 
601     private static AArch64Address loadStackSlotAddress(CompilationResultBuilder crb, AArch64MacroAssembler masm, StackSlot slot, Register scratchReg) {
602         int displacement = crb.frameMap.offsetForStackSlot(slot);
603         int transferSize = slot.getPlatformKind().getSizeInBytes();
604         return masm.makeAddress(sp, displacement, scratchReg, transferSize, /* allowOverwrite */false);
605     }
606 
607     public abstract static class PointerCompressionOp extends AArch64LIRInstruction {
608 
609         @Def({REG, HINT}) private AllocatableValue result;
610         @Use({REG, CONST}) private Value input;
611         @Alive({REG, ILLEGAL, UNINITIALIZED}) private AllocatableValue baseRegister;
612 
613         protected final CompressEncoding encoding;
614         protected final boolean nonNull;
615         protected final LIRKindTool lirKindTool;
616 
617         protected PointerCompressionOp(LIRInstructionClass&lt;? extends PointerCompressionOp&gt; type, AllocatableValue result, Value input,
618                         AllocatableValue baseRegister, CompressEncoding encoding, boolean nonNull, LIRKindTool lirKindTool) {
619 
620             super(type);
621             this.result = result;
622             this.input = input;
623             this.baseRegister = baseRegister;
624             this.encoding = encoding;
625             this.nonNull = nonNull;
626             this.lirKindTool = lirKindTool;
627         }
628 
629         public static boolean hasBase(OptionValues options, CompressEncoding encoding) {
630             return GeneratePIC.getValue(options) || encoding.hasBase();
631         }
632 
633         public final Value getInput() {
634             return input;
635         }
636 
637         public final AllocatableValue getResult() {
638             return result;
639         }
640 
641         protected final Register getResultRegister() {
642             return asRegister(result);
643         }
644 
645         protected final Register getBaseRegister(CompilationResultBuilder crb) {
646             return hasBase(crb.getOptions(), encoding) ? asRegister(baseRegister) : Register.None;
647         }
648 
649         protected final int getShift() {
650             return encoding.getShift();
651         }
652 
653         protected final void move(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
654             AArch64Move.move(crb, masm, result, input);
655         }
656     }
657 
658     public static class CompressPointerOp extends PointerCompressionOp {
659         public static final LIRInstructionClass&lt;CompressPointerOp&gt; TYPE = LIRInstructionClass.create(CompressPointerOp.class);
660 
661         public CompressPointerOp(AllocatableValue result, Value input, AllocatableValue baseRegister, CompressEncoding encoding, boolean nonNull, LIRKindTool lirKindTool) {
662             this(TYPE, result, input, baseRegister, encoding, nonNull, lirKindTool);
663         }
664 
665         private CompressPointerOp(LIRInstructionClass&lt;? extends PointerCompressionOp&gt; type, AllocatableValue result, Value input,
666                         AllocatableValue baseRegister, CompressEncoding encoding, boolean nonNull, LIRKindTool lirKindTool) {
667 
668             super(type, result, input, baseRegister, encoding, nonNull, lirKindTool);
669         }
670 
671         @Override
672         protected void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
673             Register resultRegister = getResultRegister();
674             Register ptr = asRegister(getInput());
675             Register base = getBaseRegister(crb);
676             // result = (ptr - base) &gt;&gt; shift
677             if (!encoding.hasBase()) {
678                 if (encoding.hasShift()) {
679                     masm.lshr(64, resultRegister, ptr, encoding.getShift());
680                 } else {
681                     masm.movx(resultRegister, ptr);
682                 }
683             } else if (nonNull) {
684                 masm.sub(64, resultRegister, ptr, base);
685                 if (encoding.hasShift()) {
686                     masm.lshr(64, resultRegister, resultRegister, encoding.getShift());
687                 }
688             } else {
689                 // if ptr is null it still has to be null after compression
690                 masm.cmp(64, ptr, 0);
691                 masm.cmov(64, resultRegister, ptr, base, AArch64Assembler.ConditionFlag.NE);
692                 masm.sub(64, resultRegister, resultRegister, base);
693                 if (encoding.hasShift()) {
694                     masm.lshr(64, resultRegister, resultRegister, encoding.getShift());
695                 }
696             }
697         }
698     }
699 
700     public static class UncompressPointerOp extends PointerCompressionOp {
701         public static final LIRInstructionClass&lt;UncompressPointerOp&gt; TYPE = LIRInstructionClass.create(UncompressPointerOp.class);
702 
703         public UncompressPointerOp(AllocatableValue result, Value input, AllocatableValue baseRegister, CompressEncoding encoding, boolean nonNull, LIRKindTool lirKindTool) {
704             this(TYPE, result, input, baseRegister, encoding, nonNull, lirKindTool);
705         }
706 
707         private UncompressPointerOp(LIRInstructionClass&lt;? extends PointerCompressionOp&gt; type, AllocatableValue result, Value input,
708                         AllocatableValue baseRegister, CompressEncoding encoding, boolean nonNull, LIRKindTool lirKindTool) {
709             super(type, result, input, baseRegister, encoding, nonNull, lirKindTool);
710         }
711 
712         @Override
713         protected void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
714             Register inputRegister = asRegister(getInput());
715             Register resultRegister = getResultRegister();
716             Register base = encoding.hasBase() ? getBaseRegister(crb) : null;
717 
718             // result = base + (ptr &lt;&lt; shift)
719             if (nonNull || base == null) {
720                 masm.add(64, resultRegister, base == null ? zr : base, inputRegister, AArch64Assembler.ShiftType.LSL, encoding.getShift());
721             } else {
722                 // if ptr is null it has to be null after decompression
723                 Label done = new Label();
724                 if (!resultRegister.equals(inputRegister)) {
725                     masm.mov(32, resultRegister, inputRegister);
726                 }
727                 masm.cbz(32, resultRegister, done);
728                 masm.add(64, resultRegister, base, resultRegister, AArch64Assembler.ShiftType.LSL, encoding.getShift());
729                 masm.bind(done);
730             }
731         }
732     }
733 
734     private abstract static class ZeroNullConversionOp extends AArch64LIRInstruction {
735         @Def({REG, HINT}) protected AllocatableValue result;
736         @Use({REG}) protected AllocatableValue input;
737 
738         protected ZeroNullConversionOp(LIRInstructionClass&lt;? extends ZeroNullConversionOp&gt; type, AllocatableValue result, AllocatableValue input) {
739             super(type);
740             this.result = result;
741             this.input = input;
742         }
743 
744         @Override
745         public void emitCode(CompilationResultBuilder crb, AArch64MacroAssembler masm) {
746             Register nullRegister = crb.uncompressedNullRegister;
747             if (!nullRegister.equals(Register.None)) {
748                 emitConversion(asRegister(result), asRegister(input), nullRegister, masm);
749             }
750         }
751 
752         protected abstract void emitConversion(Register resultRegister, Register inputRegister, Register nullRegister, AArch64MacroAssembler masm);
753     }
754 
755     public static class ConvertNullToZeroOp extends ZeroNullConversionOp {
756         public static final LIRInstructionClass&lt;ConvertNullToZeroOp&gt; TYPE = LIRInstructionClass.create(ConvertNullToZeroOp.class);
757 
758         public ConvertNullToZeroOp(AllocatableValue result, AllocatableValue input) {
759             super(TYPE, result, input);
760         }
761 
762         @Override
763         protected final void emitConversion(Register resultRegister, Register inputRegister, Register nullRegister, AArch64MacroAssembler masm) {
764             if (inputRegister.equals(resultRegister)) {
765                 masm.subs(64, inputRegister, inputRegister, nullRegister);
766                 Label done = new Label();
767                 masm.branchConditionally(AArch64Assembler.ConditionFlag.EQ, done);
768                 masm.add(64, inputRegister, inputRegister, nullRegister);
769                 masm.bind(done);
770             } else {
771                 masm.subs(64, resultRegister, resultRegister, resultRegister);
772                 masm.cmp(64, inputRegister, nullRegister);
773                 Label done = new Label();
774                 masm.branchConditionally(AArch64Assembler.ConditionFlag.EQ, done);
775                 masm.movx(resultRegister, inputRegister);
776                 masm.bind(done);
777             }
778         }
779     }
780 
781     public static class ConvertZeroToNullOp extends ZeroNullConversionOp {
782         public static final LIRInstructionClass&lt;ConvertZeroToNullOp&gt; TYPE = LIRInstructionClass.create(ConvertZeroToNullOp.class);
783 
784         public ConvertZeroToNullOp(AllocatableValue result, AllocatableValue input) {
785             super(TYPE, result, input);
786         }
787 
788         @Override
789         protected final void emitConversion(Register resultRegister, Register inputRegister, Register nullRegister, AArch64MacroAssembler masm) {
790             if (!inputRegister.equals(resultRegister)) {
791                 masm.movx(resultRegister, inputRegister);
792             }
793             Label done = new Label();
794             masm.ands(64, zr, inputRegister, inputRegister);
795             masm.branchConditionally(AArch64Assembler.ConditionFlag.NE, done);
796             masm.movx(resultRegister, nullRegister);
797             masm.bind(done);
798         }
799     }
800 
801 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>