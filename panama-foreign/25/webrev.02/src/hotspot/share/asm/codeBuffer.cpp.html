<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/asm/codeBuffer.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/codeBuffer.hpp&quot;
  27 #include &quot;code/oopRecorder.inline.hpp&quot;
  28 #include &quot;compiler/disassembler.hpp&quot;
  29 #include &quot;oops/methodData.hpp&quot;
  30 #include &quot;oops/oop.inline.hpp&quot;
  31 #include &quot;runtime/icache.hpp&quot;
  32 #include &quot;runtime/safepointVerifiers.hpp&quot;
  33 #include &quot;utilities/align.hpp&quot;
  34 #include &quot;utilities/copy.hpp&quot;
  35 #include &quot;utilities/powerOfTwo.hpp&quot;
  36 #include &quot;utilities/xmlstream.hpp&quot;
  37 
  38 // The structure of a CodeSection:
  39 //
  40 //    _start -&gt;           +----------------+
  41 //                        | machine code...|
  42 //    _end -&gt;             |----------------|
  43 //                        |                |
  44 //                        |    (empty)     |
  45 //                        |                |
  46 //                        |                |
  47 //                        +----------------+
  48 //    _limit -&gt;           |                |
  49 //
  50 //    _locs_start -&gt;      +----------------+
  51 //                        |reloc records...|
  52 //                        |----------------|
  53 //    _locs_end -&gt;        |                |
  54 //                        |                |
  55 //                        |    (empty)     |
  56 //                        |                |
  57 //                        |                |
  58 //                        +----------------+
  59 //    _locs_limit -&gt;      |                |
  60 // The _end (resp. _limit) pointer refers to the first
  61 // unused (resp. unallocated) byte.
  62 
  63 // The structure of the CodeBuffer while code is being accumulated:
  64 //
  65 //    _total_start -&gt;    \
  66 //    _insts._start -&gt;              +----------------+
  67 //                                  |                |
  68 //                                  |     Code       |
  69 //                                  |                |
  70 //    _stubs._start -&gt;              |----------------|
  71 //                                  |                |
  72 //                                  |    Stubs       | (also handlers for deopt/exception)
  73 //                                  |                |
  74 //    _consts._start -&gt;             |----------------|
  75 //                                  |                |
  76 //                                  |   Constants    |
  77 //                                  |                |
  78 //                                  +----------------+
  79 //    + _total_size -&gt;              |                |
  80 //
  81 // When the code and relocations are copied to the code cache,
  82 // the empty parts of each section are removed, and everything
  83 // is copied into contiguous locations.
  84 
  85 typedef CodeBuffer::csize_t csize_t;  // file-local definition
  86 
  87 // External buffer, in a predefined CodeBlob.
  88 // Important: The code_start must be taken exactly, and not realigned.
  89 CodeBuffer::CodeBuffer(CodeBlob* blob) {
  90   // Provide code buffer with meaningful name
  91   initialize_misc(blob-&gt;name());
  92   initialize(blob-&gt;content_begin(), blob-&gt;content_size());
  93   verify_section_allocation();
  94 }
  95 
  96 void CodeBuffer::initialize(csize_t code_size, csize_t locs_size) {
  97   // Compute maximal alignment.
  98   int align = _insts.alignment();
  99   // Always allow for empty slop around each section.
 100   int slop = (int) CodeSection::end_slop();
 101 
 102   assert(blob() == NULL, &quot;only once&quot;);
 103   set_blob(BufferBlob::create(_name, code_size + (align+slop) * (SECT_LIMIT+1)));
 104   if (blob() == NULL) {
 105     // The assembler constructor will throw a fatal on an empty CodeBuffer.
 106     return;  // caller must test this
 107   }
 108 
 109   // Set up various pointers into the blob.
 110   initialize(_total_start, _total_size);
 111 
 112   assert((uintptr_t)insts_begin() % CodeEntryAlignment == 0, &quot;instruction start not code entry aligned&quot;);
 113 
 114   pd_initialize();
 115 
 116   if (locs_size != 0) {
 117     _insts.initialize_locs(locs_size / sizeof(relocInfo));
 118   }
 119 
 120   verify_section_allocation();
 121 }
 122 
 123 
 124 CodeBuffer::~CodeBuffer() {
 125   verify_section_allocation();
 126 
 127   // If we allocate our code buffer from the CodeCache
 128   // via a BufferBlob, and it&#39;s not permanent, then
 129   // free the BufferBlob.
 130   // The rest of the memory will be freed when the ResourceObj
 131   // is released.
 132   for (CodeBuffer* cb = this; cb != NULL; cb = cb-&gt;before_expand()) {
 133     // Previous incarnations of this buffer are held live, so that internal
 134     // addresses constructed before expansions will not be confused.
 135     cb-&gt;free_blob();
 136   }
 137 
 138   // free any overflow storage
 139   delete _overflow_arena;
 140 
 141   // Claim is that stack allocation ensures resources are cleaned up.
 142   // This is resource clean up, let&#39;s hope that all were properly copied out.
 143   free_strings();
 144 
 145 #ifdef ASSERT
 146   // Save allocation type to execute assert in ~ResourceObj()
 147   // which is called after this destructor.
 148   assert(_default_oop_recorder.allocated_on_stack(), &quot;should be embedded object&quot;);
 149   ResourceObj::allocation_type at = _default_oop_recorder.get_allocation_type();
 150   Copy::fill_to_bytes(this, sizeof(*this), badResourceValue);
 151   ResourceObj::set_allocation_type((address)(&amp;_default_oop_recorder), at);
 152 #endif
 153 }
 154 
 155 void CodeBuffer::initialize_oop_recorder(OopRecorder* r) {
 156   assert(_oop_recorder == &amp;_default_oop_recorder &amp;&amp; _default_oop_recorder.is_unused(), &quot;do this once&quot;);
 157   DEBUG_ONLY(_default_oop_recorder.freeze());  // force unused OR to be frozen
 158   _oop_recorder = r;
 159 }
 160 
 161 void CodeBuffer::initialize_section_size(CodeSection* cs, csize_t size) {
 162   assert(cs != &amp;_insts, &quot;insts is the memory provider, not the consumer&quot;);
 163   csize_t slop = CodeSection::end_slop();  // margin between sections
 164   int align = cs-&gt;alignment();
 165   assert(is_power_of_2(align), &quot;sanity&quot;);
 166   address start  = _insts._start;
 167   address limit  = _insts._limit;
 168   address middle = limit - size;
 169   middle -= (intptr_t)middle &amp; (align-1);  // align the division point downward
 170   guarantee(middle - slop &gt; start, &quot;need enough space to divide up&quot;);
 171   _insts._limit = middle - slop;  // subtract desired space, plus slop
 172   cs-&gt;initialize(middle, limit - middle);
 173   assert(cs-&gt;start() == middle, &quot;sanity&quot;);
 174   assert(cs-&gt;limit() == limit,  &quot;sanity&quot;);
 175   // give it some relocations to start with, if the main section has them
 176   if (_insts.has_locs())  cs-&gt;initialize_locs(1);
 177 }
 178 
 179 void CodeBuffer::freeze_section(CodeSection* cs) {
 180   CodeSection* next_cs = (cs == consts())? NULL: code_section(cs-&gt;index()+1);
 181   csize_t frozen_size = cs-&gt;size();
 182   if (next_cs != NULL) {
 183     frozen_size = next_cs-&gt;align_at_start(frozen_size);
 184   }
 185   address old_limit = cs-&gt;limit();
 186   address new_limit = cs-&gt;start() + frozen_size;
 187   relocInfo* old_locs_limit = cs-&gt;locs_limit();
 188   relocInfo* new_locs_limit = cs-&gt;locs_end();
 189   // Patch the limits.
 190   cs-&gt;_limit = new_limit;
 191   cs-&gt;_locs_limit = new_locs_limit;
 192   cs-&gt;_frozen = true;
 193   if (next_cs != NULL &amp;&amp; !next_cs-&gt;is_allocated() &amp;&amp; !next_cs-&gt;is_frozen()) {
 194     // Give remaining buffer space to the following section.
 195     next_cs-&gt;initialize(new_limit, old_limit - new_limit);
 196     next_cs-&gt;initialize_shared_locs(new_locs_limit,
 197                                     old_locs_limit - new_locs_limit);
 198   }
 199 }
 200 
 201 void CodeBuffer::set_blob(BufferBlob* blob) {
 202   _blob = blob;
 203   if (blob != NULL) {
 204     address start = blob-&gt;content_begin();
 205     address end   = blob-&gt;content_end();
 206     // Round up the starting address.
 207     int align = _insts.alignment();
 208     start += (-(intptr_t)start) &amp; (align-1);
 209     _total_start = start;
 210     _total_size  = end - start;
 211   } else {
 212 #ifdef ASSERT
 213     // Clean out dangling pointers.
 214     _total_start    = badAddress;
 215     _consts._start  = _consts._end  = badAddress;
 216     _insts._start   = _insts._end   = badAddress;
 217     _stubs._start   = _stubs._end   = badAddress;
 218 #endif //ASSERT
 219   }
 220 }
 221 
 222 void CodeBuffer::free_blob() {
 223   if (_blob != NULL) {
 224     BufferBlob::free(_blob);
 225     set_blob(NULL);
 226   }
 227 }
 228 
 229 const char* CodeBuffer::code_section_name(int n) {
 230 #ifdef PRODUCT
 231   return NULL;
 232 #else //PRODUCT
 233   switch (n) {
 234   case SECT_CONSTS:            return &quot;consts&quot;;
 235   case SECT_INSTS:             return &quot;insts&quot;;
 236   case SECT_STUBS:             return &quot;stubs&quot;;
 237   default:                     return NULL;
 238   }
 239 #endif //PRODUCT
 240 }
 241 
 242 int CodeBuffer::section_index_of(address addr) const {
 243   for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
 244     const CodeSection* cs = code_section(n);
 245     if (cs-&gt;allocates(addr))  return n;
 246   }
 247   return SECT_NONE;
 248 }
 249 
 250 int CodeBuffer::locator(address addr) const {
 251   for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
 252     const CodeSection* cs = code_section(n);
 253     if (cs-&gt;allocates(addr)) {
 254       return locator(addr - cs-&gt;start(), n);
 255     }
 256   }
 257   return -1;
 258 }
 259 
 260 address CodeBuffer::locator_address(int locator) const {
 261   if (locator &lt; 0)  return NULL;
 262   address start = code_section(locator_sect(locator))-&gt;start();
 263   return start + locator_pos(locator);
 264 }
 265 
 266 bool CodeBuffer::is_backward_branch(Label&amp; L) {
 267   return L.is_bound() &amp;&amp; insts_end() &lt;= locator_address(L.loc());
 268 }
 269 
 270 address CodeBuffer::decode_begin() {
 271   address begin = _insts.start();
 272   if (_decode_begin != NULL &amp;&amp; _decode_begin &gt; begin)
 273     begin = _decode_begin;
 274   return begin;
 275 }
 276 
 277 
 278 GrowableArray&lt;int&gt;* CodeBuffer::create_patch_overflow() {
 279   if (_overflow_arena == NULL) {
 280     _overflow_arena = new (mtCode) Arena(mtCode);
 281   }
 282   return new (_overflow_arena) GrowableArray&lt;int&gt;(_overflow_arena, 8, 0, 0);
 283 }
 284 
 285 
 286 // Helper function for managing labels and their target addresses.
 287 // Returns a sensible address, and if it is not the label&#39;s final
 288 // address, notes the dependency (at &#39;branch_pc&#39;) on the label.
 289 address CodeSection::target(Label&amp; L, address branch_pc) {
 290   if (L.is_bound()) {
 291     int loc = L.loc();
 292     if (index() == CodeBuffer::locator_sect(loc)) {
 293       return start() + CodeBuffer::locator_pos(loc);
 294     } else {
 295       return outer()-&gt;locator_address(loc);
 296     }
 297   } else {
 298     assert(allocates2(branch_pc), &quot;sanity&quot;);
 299     address base = start();
 300     int patch_loc = CodeBuffer::locator(branch_pc - base, index());
 301     L.add_patch_at(outer(), patch_loc);
 302 
 303     // Need to return a pc, doesn&#39;t matter what it is since it will be
 304     // replaced during resolution later.
 305     // Don&#39;t return NULL or badAddress, since branches shouldn&#39;t overflow.
 306     // Don&#39;t return base either because that could overflow displacements
 307     // for shorter branches.  It will get checked when bound.
 308     return branch_pc;
 309   }
 310 }
 311 
 312 void CodeSection::relocate(address at, relocInfo::relocType rtype, int format, jint method_index) {
 313   RelocationHolder rh;
 314   switch (rtype) {
 315     case relocInfo::none: return;
 316     case relocInfo::opt_virtual_call_type: {
 317       rh = opt_virtual_call_Relocation::spec(method_index);
 318       break;
 319     }
 320     case relocInfo::static_call_type: {
 321       rh = static_call_Relocation::spec(method_index);
 322       break;
 323     }
 324     case relocInfo::virtual_call_type: {
 325       assert(method_index == 0, &quot;resolved method overriding is not supported&quot;);
 326       rh = Relocation::spec_simple(rtype);
 327       break;
 328     }
 329     default: {
 330       rh = Relocation::spec_simple(rtype);
 331       break;
 332     }
 333   }
 334   relocate(at, rh, format);
 335 }
 336 
 337 void CodeSection::relocate(address at, RelocationHolder const&amp; spec, int format) {
 338   // Do not relocate in scratch buffers.
 339   if (scratch_emit()) { return; }
 340   Relocation* reloc = spec.reloc();
 341   relocInfo::relocType rtype = (relocInfo::relocType) reloc-&gt;type();
 342   if (rtype == relocInfo::none)  return;
 343 
 344   // The assertion below has been adjusted, to also work for
 345   // relocation for fixup.  Sometimes we want to put relocation
 346   // information for the next instruction, since it will be patched
 347   // with a call.
 348   assert(start() &lt;= at &amp;&amp; at &lt;= end()+1,
 349          &quot;cannot relocate data outside code boundaries&quot;);
 350 
 351   if (!has_locs()) {
 352     // no space for relocation information provided =&gt; code cannot be
 353     // relocated.  Make sure that relocate is only called with rtypes
 354     // that can be ignored for this kind of code.
 355     assert(rtype == relocInfo::none              ||
 356            rtype == relocInfo::runtime_call_type ||
 357            rtype == relocInfo::internal_word_type||
 358            rtype == relocInfo::section_word_type ||
 359            rtype == relocInfo::external_word_type,
 360            &quot;code needs relocation information&quot;);
 361     // leave behind an indication that we attempted a relocation
 362     DEBUG_ONLY(_locs_start = _locs_limit = (relocInfo*)badAddress);
 363     return;
 364   }
 365 
 366   // Advance the point, noting the offset we&#39;ll have to record.
 367   csize_t offset = at - locs_point();
 368   set_locs_point(at);
 369 
 370   // Test for a couple of overflow conditions; maybe expand the buffer.
 371   relocInfo* end = locs_end();
 372   relocInfo* req = end + relocInfo::length_limit;
 373   // Check for (potential) overflow
 374   if (req &gt;= locs_limit() || offset &gt;= relocInfo::offset_limit()) {
 375     req += (uint)offset / (uint)relocInfo::offset_limit();
 376     if (req &gt;= locs_limit()) {
 377       // Allocate or reallocate.
 378       expand_locs(locs_count() + (req - end));
 379       // reload pointer
 380       end = locs_end();
 381     }
 382   }
 383 
 384   // If the offset is giant, emit filler relocs, of type &#39;none&#39;, but
 385   // each carrying the largest possible offset, to advance the locs_point.
 386   while (offset &gt;= relocInfo::offset_limit()) {
 387     assert(end &lt; locs_limit(), &quot;adjust previous paragraph of code&quot;);
 388     *end++ = filler_relocInfo();
 389     offset -= filler_relocInfo().addr_offset();
 390   }
 391 
 392   // If it&#39;s a simple reloc with no data, we&#39;ll just write (rtype | offset).
 393   (*end) = relocInfo(rtype, offset, format);
 394 
 395   // If it has data, insert the prefix, as (data_prefix_tag | data1), data2.
 396   end-&gt;initialize(this, reloc);
 397 }
 398 
 399 void CodeSection::initialize_locs(int locs_capacity) {
 400   assert(_locs_start == NULL, &quot;only one locs init step, please&quot;);
 401   // Apply a priori lower limits to relocation size:
 402   csize_t min_locs = MAX2(size() / 16, (csize_t)4);
 403   if (locs_capacity &lt; min_locs)  locs_capacity = min_locs;
 404   relocInfo* locs_start = NEW_RESOURCE_ARRAY(relocInfo, locs_capacity);
 405   _locs_start    = locs_start;
 406   _locs_end      = locs_start;
 407   _locs_limit    = locs_start + locs_capacity;
 408   _locs_own      = true;
 409 }
 410 
 411 void CodeSection::initialize_shared_locs(relocInfo* buf, int length) {
 412   assert(_locs_start == NULL, &quot;do this before locs are allocated&quot;);
 413   // Internal invariant:  locs buf must be fully aligned.
 414   // See copy_relocations_to() below.
 415   while ((uintptr_t)buf % HeapWordSize != 0 &amp;&amp; length &gt; 0) {
 416     ++buf; --length;
 417   }
 418   if (length &gt; 0) {
 419     _locs_start = buf;
 420     _locs_end   = buf;
 421     _locs_limit = buf + length;
 422     _locs_own   = false;
 423   }
 424 }
 425 
 426 void CodeSection::initialize_locs_from(const CodeSection* source_cs) {
 427   int lcount = source_cs-&gt;locs_count();
 428   if (lcount != 0) {
 429     initialize_shared_locs(source_cs-&gt;locs_start(), lcount);
 430     _locs_end = _locs_limit = _locs_start + lcount;
 431     assert(is_allocated(), &quot;must have copied code already&quot;);
 432     set_locs_point(start() + source_cs-&gt;locs_point_off());
 433   }
 434   assert(this-&gt;locs_count() == source_cs-&gt;locs_count(), &quot;sanity&quot;);
 435 }
 436 
 437 void CodeSection::expand_locs(int new_capacity) {
 438   if (_locs_start == NULL) {
 439     initialize_locs(new_capacity);
 440     return;
 441   } else {
 442     int old_count    = locs_count();
 443     int old_capacity = locs_capacity();
 444     if (new_capacity &lt; old_capacity * 2)
 445       new_capacity = old_capacity * 2;
 446     relocInfo* locs_start;
 447     if (_locs_own) {
 448       locs_start = REALLOC_RESOURCE_ARRAY(relocInfo, _locs_start, old_capacity, new_capacity);
 449     } else {
 450       locs_start = NEW_RESOURCE_ARRAY(relocInfo, new_capacity);
 451       Copy::conjoint_jbytes(_locs_start, locs_start, old_capacity * sizeof(relocInfo));
 452       _locs_own = true;
 453     }
 454     _locs_start    = locs_start;
 455     _locs_end      = locs_start + old_count;
 456     _locs_limit    = locs_start + new_capacity;
 457   }
 458 }
 459 
 460 
 461 /// Support for emitting the code to its final location.
 462 /// The pattern is the same for all functions.
 463 /// We iterate over all the sections, padding each to alignment.
 464 
 465 csize_t CodeBuffer::total_content_size() const {
 466   csize_t size_so_far = 0;
 467   for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
 468     const CodeSection* cs = code_section(n);
 469     if (cs-&gt;is_empty())  continue;  // skip trivial section
 470     size_so_far = cs-&gt;align_at_start(size_so_far);
 471     size_so_far += cs-&gt;size();
 472   }
 473   return size_so_far;
 474 }
 475 
 476 void CodeBuffer::compute_final_layout(CodeBuffer* dest) const {
 477   address buf = dest-&gt;_total_start;
 478   csize_t buf_offset = 0;
 479   assert(dest-&gt;_total_size &gt;= total_content_size(), &quot;must be big enough&quot;);
 480 
 481   {
 482     // not sure why this is here, but why not...
 483     int alignSize = MAX2((intx) sizeof(jdouble), CodeEntryAlignment);
 484     assert( (dest-&gt;_total_start - _insts.start()) % alignSize == 0, &quot;copy must preserve alignment&quot;);
 485   }
 486 
 487   const CodeSection* prev_cs      = NULL;
 488   CodeSection*       prev_dest_cs = NULL;
 489 
 490   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
 491     // figure compact layout of each section
 492     const CodeSection* cs = code_section(n);
 493     csize_t csize = cs-&gt;size();
 494 
 495     CodeSection* dest_cs = dest-&gt;code_section(n);
 496     if (!cs-&gt;is_empty()) {
 497       // Compute initial padding; assign it to the previous non-empty guy.
 498       // Cf. figure_expanded_capacities.
 499       csize_t padding = cs-&gt;align_at_start(buf_offset) - buf_offset;
 500       if (prev_dest_cs != NULL) {
 501         if (padding != 0) {
 502           buf_offset += padding;
 503           prev_dest_cs-&gt;_limit += padding;
 504         }
 505       } else {
 506         guarantee(padding == 0, &quot;In first iteration no padding should be needed.&quot;);
 507       }
 508       #ifdef ASSERT
 509       if (prev_cs != NULL &amp;&amp; prev_cs-&gt;is_frozen() &amp;&amp; n &lt; (SECT_LIMIT - 1)) {
 510         // Make sure the ends still match up.
 511         // This is important because a branch in a frozen section
 512         // might target code in a following section, via a Label,
 513         // and without a relocation record.  See Label::patch_instructions.
 514         address dest_start = buf+buf_offset;
 515         csize_t start2start = cs-&gt;start() - prev_cs-&gt;start();
 516         csize_t dest_start2start = dest_start - prev_dest_cs-&gt;start();
 517         assert(start2start == dest_start2start, &quot;cannot stretch frozen sect&quot;);
 518       }
 519       #endif //ASSERT
 520       prev_dest_cs = dest_cs;
 521       prev_cs      = cs;
 522     }
 523 
 524     debug_only(dest_cs-&gt;_start = NULL);  // defeat double-initialization assert
 525     dest_cs-&gt;initialize(buf+buf_offset, csize);
 526     dest_cs-&gt;set_end(buf+buf_offset+csize);
 527     assert(dest_cs-&gt;is_allocated(), &quot;must always be allocated&quot;);
 528     assert(cs-&gt;is_empty() == dest_cs-&gt;is_empty(), &quot;sanity&quot;);
 529 
 530     buf_offset += csize;
 531   }
 532 
 533   // Done calculating sections; did it come out to the right end?
 534   assert(buf_offset == total_content_size(), &quot;sanity&quot;);
 535   dest-&gt;verify_section_allocation();
 536 }
 537 
 538 // Append an oop reference that keeps the class alive.
 539 static void append_oop_references(GrowableArray&lt;oop&gt;* oops, Klass* k) {
 540   oop cl = k-&gt;klass_holder();
 541   if (cl != NULL &amp;&amp; !oops-&gt;contains(cl)) {
 542     oops-&gt;append(cl);
 543   }
 544 }
 545 
 546 void CodeBuffer::finalize_oop_references(const methodHandle&amp; mh) {
 547   NoSafepointVerifier nsv;
 548 
 549   GrowableArray&lt;oop&gt; oops;
 550 
 551   // Make sure that immediate metadata records something in the OopRecorder
 552   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
 553     // pull code out of each section
 554     CodeSection* cs = code_section(n);
 555     if (cs-&gt;is_empty())  continue;  // skip trivial section
 556     RelocIterator iter(cs);
 557     while (iter.next()) {
 558       if (iter.type() == relocInfo::metadata_type) {
 559         metadata_Relocation* md = iter.metadata_reloc();
 560         if (md-&gt;metadata_is_immediate()) {
 561           Metadata* m = md-&gt;metadata_value();
 562           if (oop_recorder()-&gt;is_real(m)) {
 563             if (m-&gt;is_methodData()) {
 564               m = ((MethodData*)m)-&gt;method();
 565             }
 566             if (m-&gt;is_method()) {
 567               m = ((Method*)m)-&gt;method_holder();
 568             }
 569             if (m-&gt;is_klass()) {
 570               append_oop_references(&amp;oops, (Klass*)m);
 571             } else {
 572               // XXX This will currently occur for MDO which don&#39;t
 573               // have a backpointer.  This has to be fixed later.
 574               m-&gt;print();
 575               ShouldNotReachHere();
 576             }
 577           }
 578         }
 579       }
 580     }
 581   }
 582 
 583   if (!oop_recorder()-&gt;is_unused()) {
 584     for (int i = 0; i &lt; oop_recorder()-&gt;metadata_count(); i++) {
 585       Metadata* m = oop_recorder()-&gt;metadata_at(i);
 586       if (oop_recorder()-&gt;is_real(m)) {
 587         if (m-&gt;is_methodData()) {
 588           m = ((MethodData*)m)-&gt;method();
 589         }
 590         if (m-&gt;is_method()) {
 591           m = ((Method*)m)-&gt;method_holder();
 592         }
 593         if (m-&gt;is_klass()) {
 594           append_oop_references(&amp;oops, (Klass*)m);
 595         } else {
 596           m-&gt;print();
 597           ShouldNotReachHere();
 598         }
 599       }
 600     }
 601 
 602   }
 603 
 604   // Add the class loader of Method* for the nmethod itself
 605   append_oop_references(&amp;oops, mh-&gt;method_holder());
 606 
 607   // Add any oops that we&#39;ve found
 608   Thread* thread = Thread::current();
 609   for (int i = 0; i &lt; oops.length(); i++) {
 610     oop_recorder()-&gt;find_index((jobject)thread-&gt;handle_area()-&gt;allocate_handle(oops.at(i)));
 611   }
 612 }
 613 
 614 
 615 
 616 csize_t CodeBuffer::total_offset_of(const CodeSection* cs) const {
 617   csize_t size_so_far = 0;
 618   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
 619     const CodeSection* cur_cs = code_section(n);
 620     if (!cur_cs-&gt;is_empty()) {
 621       size_so_far = cur_cs-&gt;align_at_start(size_so_far);
 622     }
 623     if (cur_cs-&gt;index() == cs-&gt;index()) {
 624       return size_so_far;
 625     }
 626     size_so_far += cur_cs-&gt;size();
 627   }
 628   ShouldNotReachHere();
 629   return -1;
 630 }
 631 
 632 csize_t CodeBuffer::total_relocation_size() const {
 633   csize_t total = copy_relocations_to(NULL);  // dry run only
 634   return (csize_t) align_up(total, HeapWordSize);
 635 }
 636 
 637 csize_t CodeBuffer::copy_relocations_to(address buf, csize_t buf_limit, bool only_inst) const {
 638   csize_t buf_offset = 0;
 639   csize_t code_end_so_far = 0;
 640   csize_t code_point_so_far = 0;
 641 
 642   assert((uintptr_t)buf % HeapWordSize == 0, &quot;buf must be fully aligned&quot;);
 643   assert(buf_limit % HeapWordSize == 0, &quot;buf must be evenly sized&quot;);
 644 
 645   for (int n = (int) SECT_FIRST; n &lt; (int)SECT_LIMIT; n++) {
 646     if (only_inst &amp;&amp; (n != (int)SECT_INSTS)) {
 647       // Need only relocation info for code.
 648       continue;
 649     }
 650     // pull relocs out of each section
 651     const CodeSection* cs = code_section(n);
 652     assert(!(cs-&gt;is_empty() &amp;&amp; cs-&gt;locs_count() &gt; 0), &quot;sanity&quot;);
 653     if (cs-&gt;is_empty())  continue;  // skip trivial section
 654     relocInfo* lstart = cs-&gt;locs_start();
 655     relocInfo* lend   = cs-&gt;locs_end();
 656     csize_t    lsize  = (csize_t)( (address)lend - (address)lstart );
 657     csize_t    csize  = cs-&gt;size();
 658     code_end_so_far = cs-&gt;align_at_start(code_end_so_far);
 659 
 660     if (lsize &gt; 0) {
 661       // Figure out how to advance the combined relocation point
 662       // first to the beginning of this section.
 663       // We&#39;ll insert one or more filler relocs to span that gap.
 664       // (Don&#39;t bother to improve this by editing the first reloc&#39;s offset.)
 665       csize_t new_code_point = code_end_so_far;
 666       for (csize_t jump;
 667            code_point_so_far &lt; new_code_point;
 668            code_point_so_far += jump) {
 669         jump = new_code_point - code_point_so_far;
 670         relocInfo filler = filler_relocInfo();
 671         if (jump &gt;= filler.addr_offset()) {
 672           jump = filler.addr_offset();
 673         } else {  // else shrink the filler to fit
 674           filler = relocInfo(relocInfo::none, jump);
 675         }
 676         if (buf != NULL) {
 677           assert(buf_offset + (csize_t)sizeof(filler) &lt;= buf_limit, &quot;filler in bounds&quot;);
 678           *(relocInfo*)(buf+buf_offset) = filler;
 679         }
 680         buf_offset += sizeof(filler);
 681       }
 682 
 683       // Update code point and end to skip past this section:
 684       csize_t last_code_point = code_end_so_far + cs-&gt;locs_point_off();
 685       assert(code_point_so_far &lt;= last_code_point, &quot;sanity&quot;);
 686       code_point_so_far = last_code_point; // advance past this guy&#39;s relocs
 687     }
 688     code_end_so_far += csize;  // advance past this guy&#39;s instructions too
 689 
 690     // Done with filler; emit the real relocations:
 691     if (buf != NULL &amp;&amp; lsize != 0) {
 692       assert(buf_offset + lsize &lt;= buf_limit, &quot;target in bounds&quot;);
 693       assert((uintptr_t)lstart % HeapWordSize == 0, &quot;sane start&quot;);
 694       if (buf_offset % HeapWordSize == 0) {
 695         // Use wordwise copies if possible:
 696         Copy::disjoint_words((HeapWord*)lstart,
 697                              (HeapWord*)(buf+buf_offset),
 698                              (lsize + HeapWordSize-1) / HeapWordSize);
 699       } else {
 700         Copy::conjoint_jbytes(lstart, buf+buf_offset, lsize);
 701       }
 702     }
 703     buf_offset += lsize;
 704   }
 705 
 706   // Align end of relocation info in target.
 707   while (buf_offset % HeapWordSize != 0) {
 708     if (buf != NULL) {
 709       relocInfo padding = relocInfo(relocInfo::none, 0);
 710       assert(buf_offset + (csize_t)sizeof(padding) &lt;= buf_limit, &quot;padding in bounds&quot;);
 711       *(relocInfo*)(buf+buf_offset) = padding;
 712     }
 713     buf_offset += sizeof(relocInfo);
 714   }
 715 
 716   assert(only_inst || code_end_so_far == total_content_size(), &quot;sanity&quot;);
 717 
 718   return buf_offset;
 719 }
 720 
 721 csize_t CodeBuffer::copy_relocations_to(CodeBlob* dest) const {
 722   address buf = NULL;
 723   csize_t buf_offset = 0;
 724   csize_t buf_limit = 0;
 725 
 726   if (dest != NULL) {
 727     buf = (address)dest-&gt;relocation_begin();
 728     buf_limit = (address)dest-&gt;relocation_end() - buf;
 729   }
 730   // if dest == NULL, this is just the sizing pass
 731   //
 732   buf_offset = copy_relocations_to(buf, buf_limit, false);
 733 
 734   return buf_offset;
 735 }
 736 
 737 void CodeBuffer::copy_code_to(CodeBlob* dest_blob) {
 738 #ifndef PRODUCT
 739   if (PrintNMethods &amp;&amp; (WizardMode || Verbose)) {
 740     tty-&gt;print(&quot;done with CodeBuffer:&quot;);
 741     ((CodeBuffer*)this)-&gt;print();
 742   }
 743 #endif //PRODUCT
 744 
 745   CodeBuffer dest(dest_blob);
 746   assert(dest_blob-&gt;content_size() &gt;= total_content_size(), &quot;good sizing&quot;);
 747   this-&gt;compute_final_layout(&amp;dest);
 748 
 749   // Set beginning of constant table before relocating.
 750   dest_blob-&gt;set_ctable_begin(dest.consts()-&gt;start());
 751 
 752   relocate_code_to(&amp;dest);
 753 
 754   // transfer strings and comments from buffer to blob
 755   dest_blob-&gt;set_strings(_code_strings);
 756 
 757   // Done moving code bytes; were they the right size?
 758   assert((int)align_up(dest.total_content_size(), oopSize) == dest_blob-&gt;content_size(), &quot;sanity&quot;);
 759 
 760   // Flush generated code
 761   ICache::invalidate_range(dest_blob-&gt;code_begin(), dest_blob-&gt;code_size());
 762 }
 763 
 764 // Move all my code into another code buffer.  Consult applicable
 765 // relocs to repair embedded addresses.  The layout in the destination
 766 // CodeBuffer is different to the source CodeBuffer: the destination
 767 // CodeBuffer gets the final layout (consts, insts, stubs in order of
 768 // ascending address).
 769 void CodeBuffer::relocate_code_to(CodeBuffer* dest) const {
 770   address dest_end = dest-&gt;_total_start + dest-&gt;_total_size;
 771   address dest_filled = NULL;
 772   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
 773     // pull code out of each section
 774     const CodeSection* cs = code_section(n);
 775     if (cs-&gt;is_empty())  continue;  // skip trivial section
 776     CodeSection* dest_cs = dest-&gt;code_section(n);
 777     assert(cs-&gt;size() == dest_cs-&gt;size(), &quot;sanity&quot;);
 778     csize_t usize = dest_cs-&gt;size();
 779     csize_t wsize = align_up(usize, HeapWordSize);
 780     assert(dest_cs-&gt;start() + wsize &lt;= dest_end, &quot;no overflow&quot;);
 781     // Copy the code as aligned machine words.
 782     // This may also include an uninitialized partial word at the end.
 783     Copy::disjoint_words((HeapWord*)cs-&gt;start(),
 784                          (HeapWord*)dest_cs-&gt;start(),
 785                          wsize / HeapWordSize);
 786 
 787     if (dest-&gt;blob() == NULL) {
 788       // Destination is a final resting place, not just another buffer.
 789       // Normalize uninitialized bytes in the final padding.
 790       Copy::fill_to_bytes(dest_cs-&gt;end(), dest_cs-&gt;remaining(),
 791                           Assembler::code_fill_byte());
 792     }
 793     // Keep track of the highest filled address
 794     dest_filled = MAX2(dest_filled, dest_cs-&gt;end() + dest_cs-&gt;remaining());
 795 
 796     assert(cs-&gt;locs_start() != (relocInfo*)badAddress,
 797            &quot;this section carries no reloc storage, but reloc was attempted&quot;);
 798 
 799     // Make the new code copy use the old copy&#39;s relocations:
 800     dest_cs-&gt;initialize_locs_from(cs);
 801   }
 802 
 803   // Do relocation after all sections are copied.
 804   // This is necessary if the code uses constants in stubs, which are
 805   // relocated when the corresponding instruction in the code (e.g., a
 806   // call) is relocated. Stubs are placed behind the main code
 807   // section, so that section has to be copied before relocating.
 808   for (int n = (int) SECT_FIRST; n &lt; (int)SECT_LIMIT; n++) {
 809     // pull code out of each section
 810     const CodeSection* cs = code_section(n);
 811     if (cs-&gt;is_empty()) continue;  // skip trivial section
 812     CodeSection* dest_cs = dest-&gt;code_section(n);
 813     { // Repair the pc relative information in the code after the move
 814       RelocIterator iter(dest_cs);
 815       while (iter.next()) {
 816         iter.reloc()-&gt;fix_relocation_after_move(this, dest);
 817       }
 818     }
 819   }
 820 
 821   if (dest-&gt;blob() == NULL &amp;&amp; dest_filled != NULL) {
 822     // Destination is a final resting place, not just another buffer.
 823     // Normalize uninitialized bytes in the final padding.
 824     Copy::fill_to_bytes(dest_filled, dest_end - dest_filled,
 825                         Assembler::code_fill_byte());
 826 
 827   }
 828 }
 829 
 830 csize_t CodeBuffer::figure_expanded_capacities(CodeSection* which_cs,
 831                                                csize_t amount,
 832                                                csize_t* new_capacity) {
 833   csize_t new_total_cap = 0;
 834 
 835   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
 836     const CodeSection* sect = code_section(n);
 837 
 838     if (!sect-&gt;is_empty()) {
 839       // Compute initial padding; assign it to the previous section,
 840       // even if it&#39;s empty (e.g. consts section can be empty).
 841       // Cf. compute_final_layout
 842       csize_t padding = sect-&gt;align_at_start(new_total_cap) - new_total_cap;
 843       if (padding != 0) {
 844         new_total_cap += padding;
 845         assert(n - 1 &gt;= SECT_FIRST, &quot;sanity&quot;);
 846         new_capacity[n - 1] += padding;
 847       }
 848     }
 849 
 850     csize_t exp = sect-&gt;size();  // 100% increase
 851     if ((uint)exp &lt; 4*K)  exp = 4*K;       // minimum initial increase
 852     if (sect == which_cs) {
 853       if (exp &lt; amount)  exp = amount;
 854       if (StressCodeBuffers)  exp = amount;  // expand only slightly
 855     } else if (n == SECT_INSTS) {
 856       // scale down inst increases to a more modest 25%
 857       exp = 4*K + ((exp - 4*K) &gt;&gt; 2);
 858       if (StressCodeBuffers)  exp = amount / 2;  // expand only slightly
 859     } else if (sect-&gt;is_empty()) {
 860       // do not grow an empty secondary section
 861       exp = 0;
 862     }
 863     // Allow for inter-section slop:
 864     exp += CodeSection::end_slop();
 865     csize_t new_cap = sect-&gt;size() + exp;
 866     if (new_cap &lt; sect-&gt;capacity()) {
 867       // No need to expand after all.
 868       new_cap = sect-&gt;capacity();
 869     }
 870     new_capacity[n] = new_cap;
 871     new_total_cap += new_cap;
 872   }
 873 
 874   return new_total_cap;
 875 }
 876 
 877 void CodeBuffer::expand(CodeSection* which_cs, csize_t amount) {
 878 #ifndef PRODUCT
 879   if (PrintNMethods &amp;&amp; (WizardMode || Verbose)) {
 880     tty-&gt;print(&quot;expanding CodeBuffer:&quot;);
 881     this-&gt;print();
 882   }
 883 
 884   if (StressCodeBuffers &amp;&amp; blob() != NULL) {
 885     static int expand_count = 0;
 886     if (expand_count &gt;= 0)  expand_count += 1;
 887     if (expand_count &gt; 100 &amp;&amp; is_power_of_2(expand_count)) {
 888       tty-&gt;print_cr(&quot;StressCodeBuffers: have expanded %d times&quot;, expand_count);
 889       // simulate an occasional allocation failure:
 890       free_blob();
 891     }
 892   }
 893 #endif //PRODUCT
 894 
 895   // Resizing must be allowed
 896   {
 897     if (blob() == NULL)  return;  // caller must check for blob == NULL
 898     for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
 899       guarantee(!code_section(n)-&gt;is_frozen(), &quot;resizing not allowed when frozen&quot;);
 900     }
 901   }
 902 
 903   // Figure new capacity for each section.
 904   csize_t new_capacity[SECT_LIMIT];
 905   memset(new_capacity, 0, sizeof(csize_t) * SECT_LIMIT);
 906   csize_t new_total_cap
 907     = figure_expanded_capacities(which_cs, amount, new_capacity);
 908 
 909   // Create a new (temporary) code buffer to hold all the new data
 910   CodeBuffer cb(name(), new_total_cap, 0);
 911   if (cb.blob() == NULL) {
 912     // Failed to allocate in code cache.
 913     free_blob();
 914     return;
 915   }
 916 
 917   // Create an old code buffer to remember which addresses used to go where.
 918   // This will be useful when we do final assembly into the code cache,
 919   // because we will need to know how to warp any internal address that
 920   // has been created at any time in this CodeBuffer&#39;s past.
 921   CodeBuffer* bxp = new CodeBuffer(_total_start, _total_size);
 922   bxp-&gt;take_over_code_from(this);  // remember the old undersized blob
 923   DEBUG_ONLY(this-&gt;_blob = NULL);  // silence a later assert
 924   bxp-&gt;_before_expand = this-&gt;_before_expand;
 925   this-&gt;_before_expand = bxp;
 926 
 927   // Give each section its required (expanded) capacity.
 928   for (int n = (int)SECT_LIMIT-1; n &gt;= SECT_FIRST; n--) {
 929     CodeSection* cb_sect   = cb.code_section(n);
 930     CodeSection* this_sect = code_section(n);
 931     if (new_capacity[n] == 0)  continue;  // already nulled out
 932     if (n != SECT_INSTS) {
 933       cb.initialize_section_size(cb_sect, new_capacity[n]);
 934     }
 935     assert(cb_sect-&gt;capacity() &gt;= new_capacity[n], &quot;big enough&quot;);
 936     address cb_start = cb_sect-&gt;start();
 937     cb_sect-&gt;set_end(cb_start + this_sect-&gt;size());
 938     if (this_sect-&gt;mark() == NULL) {
 939       cb_sect-&gt;clear_mark();
 940     } else {
 941       cb_sect-&gt;set_mark(cb_start + this_sect-&gt;mark_off());
 942     }
 943   }
 944 
 945   // Needs to be initialized when calling fix_relocation_after_move.
 946   cb.blob()-&gt;set_ctable_begin(cb.consts()-&gt;start());
 947 
 948   // Move all the code and relocations to the new blob:
 949   relocate_code_to(&amp;cb);
 950 
 951   // Copy the temporary code buffer into the current code buffer.
 952   // Basically, do {*this = cb}, except for some control information.
 953   this-&gt;take_over_code_from(&amp;cb);
 954   cb.set_blob(NULL);
 955 
 956   // Zap the old code buffer contents, to avoid mistakenly using them.
 957   debug_only(Copy::fill_to_bytes(bxp-&gt;_total_start, bxp-&gt;_total_size,
 958                                  badCodeHeapFreeVal));
 959 
 960   _decode_begin = NULL;  // sanity
 961 
 962   // Make certain that the new sections are all snugly inside the new blob.
 963   verify_section_allocation();
 964 
 965 #ifndef PRODUCT
 966   if (PrintNMethods &amp;&amp; (WizardMode || Verbose)) {
 967     tty-&gt;print(&quot;expanded CodeBuffer:&quot;);
 968     this-&gt;print();
 969   }
 970 #endif //PRODUCT
 971 }
 972 
 973 void CodeBuffer::take_over_code_from(CodeBuffer* cb) {
 974   // Must already have disposed of the old blob somehow.
 975   assert(blob() == NULL, &quot;must be empty&quot;);
 976   // Take the new blob away from cb.
 977   set_blob(cb-&gt;blob());
 978   // Take over all the section pointers.
 979   for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
 980     CodeSection* cb_sect   = cb-&gt;code_section(n);
 981     CodeSection* this_sect = code_section(n);
 982     this_sect-&gt;take_over_code_from(cb_sect);
 983   }
 984   _overflow_arena = cb-&gt;_overflow_arena;
 985   // Make sure the old cb won&#39;t try to use it or free it.
 986   DEBUG_ONLY(cb-&gt;_blob = (BufferBlob*)badAddress);
 987 }
 988 
 989 void CodeBuffer::verify_section_allocation() {
 990   address tstart = _total_start;
 991   if (tstart == badAddress)  return;  // smashed by set_blob(NULL)
 992   address tend   = tstart + _total_size;
 993   if (_blob != NULL) {
 994 
 995     guarantee(tstart &gt;= _blob-&gt;content_begin(), &quot;sanity&quot;);
 996     guarantee(tend   &lt;= _blob-&gt;content_end(),   &quot;sanity&quot;);
 997   }
 998   // Verify disjointness.
 999   for (int n = (int) SECT_FIRST; n &lt; (int) SECT_LIMIT; n++) {
1000     CodeSection* sect = code_section(n);
1001     if (!sect-&gt;is_allocated() || sect-&gt;is_empty())  continue;
1002     guarantee((intptr_t)sect-&gt;start() % sect-&gt;alignment() == 0
1003            || sect-&gt;is_empty() || _blob == NULL,
1004            &quot;start is aligned&quot;);
1005     for (int m = (int) SECT_FIRST; m &lt; (int) SECT_LIMIT; m++) {
1006       CodeSection* other = code_section(m);
1007       if (!other-&gt;is_allocated() || other == sect)  continue;
1008       guarantee(!other-&gt;contains(sect-&gt;start()    ), &quot;sanity&quot;);
1009       // limit is an exclusive address and can be the start of another
1010       // section.
1011       guarantee(!other-&gt;contains(sect-&gt;limit() - 1), &quot;sanity&quot;);
1012     }
1013     guarantee(sect-&gt;end() &lt;= tend, &quot;sanity&quot;);
1014     guarantee(sect-&gt;end() &lt;= sect-&gt;limit(), &quot;sanity&quot;);
1015   }
1016 }
1017 
1018 void CodeBuffer::log_section_sizes(const char* name) {
1019   if (xtty != NULL) {
1020     ttyLocker ttyl;
1021     // log info about buffer usage
1022     xtty-&gt;print_cr(&quot;&lt;blob name=&#39;%s&#39; size=&#39;%d&#39;&gt;&quot;, name, _total_size);
1023     for (int n = (int) CodeBuffer::SECT_FIRST; n &lt; (int) CodeBuffer::SECT_LIMIT; n++) {
1024       CodeSection* sect = code_section(n);
1025       if (!sect-&gt;is_allocated() || sect-&gt;is_empty())  continue;
1026       xtty-&gt;print_cr(&quot;&lt;sect index=&#39;%d&#39; size=&#39;&quot; SIZE_FORMAT &quot;&#39; free=&#39;&quot; SIZE_FORMAT &quot;&#39;/&gt;&quot;,
1027                      n, sect-&gt;limit() - sect-&gt;start(), sect-&gt;limit() - sect-&gt;end());
1028     }
1029     xtty-&gt;print_cr(&quot;&lt;/blob&gt;&quot;);
1030   }
1031 }
1032 
1033 #ifndef PRODUCT
1034 
1035 void CodeSection::decode() {
1036   Disassembler::decode(start(), end());
1037 }
1038 
1039 void CodeBuffer::block_comment(intptr_t offset, const char * comment) {
1040   if (_collect_comments) {
1041     _code_strings.add_comment(offset, comment);
1042   }
1043 }
1044 
1045 const char* CodeBuffer::code_string(const char* str) {
1046   return _code_strings.add_string(str);
1047 }
1048 
1049 class CodeString: public CHeapObj&lt;mtCode&gt; {
1050  private:
1051   friend class CodeStrings;
1052   const char * _string;
1053   CodeString*  _next;
1054   CodeString*  _prev;
1055   intptr_t     _offset;
1056 
1057   ~CodeString() {
1058     assert(_next == NULL &amp;&amp; _prev == NULL, &quot;wrong interface for freeing list&quot;);
1059     os::free((void*)_string);
1060   }
1061 
1062   bool is_comment() const { return _offset &gt;= 0; }
1063 
1064  public:
1065   CodeString(const char * string, intptr_t offset = -1)
1066     : _next(NULL), _prev(NULL), _offset(offset) {
1067     _string = os::strdup(string, mtCode);
1068   }
1069 
1070   const char * string() const { return _string; }
1071   intptr_t     offset() const { assert(_offset &gt;= 0, &quot;offset for non comment?&quot;); return _offset;  }
1072   CodeString* next()    const { return _next; }
1073 
1074   void set_next(CodeString* next) {
1075     _next = next;
1076     if (next != NULL) {
1077       next-&gt;_prev = this;
1078     }
1079   }
1080 
1081   CodeString* first_comment() {
1082     if (is_comment()) {
1083       return this;
1084     } else {
1085       return next_comment();
1086     }
1087   }
1088   CodeString* next_comment() const {
1089     CodeString* s = _next;
1090     while (s != NULL &amp;&amp; !s-&gt;is_comment()) {
1091       s = s-&gt;_next;
1092     }
1093     return s;
1094   }
1095 };
1096 
1097 CodeString* CodeStrings::find(intptr_t offset) const {
1098   CodeString* a = _strings-&gt;first_comment();
1099   while (a != NULL &amp;&amp; a-&gt;offset() != offset) {
1100     a = a-&gt;next_comment();
1101   }
1102   return a;
1103 }
1104 
1105 // Convenience for add_comment.
1106 CodeString* CodeStrings::find_last(intptr_t offset) const {
1107   CodeString* a = _strings_last;
1108   while (a != NULL &amp;&amp; !(a-&gt;is_comment() &amp;&amp; a-&gt;offset() == offset)) {
1109     a = a-&gt;_prev;
1110   }
1111   return a;
1112 }
1113 
1114 void CodeStrings::add_comment(intptr_t offset, const char * comment) {
1115   check_valid();
1116   CodeString* c      = new CodeString(comment, offset);
1117   CodeString* inspos = (_strings == NULL) ? NULL : find_last(offset);
1118 
1119   if (inspos) {
1120     // insert after already existing comments with same offset
1121     c-&gt;set_next(inspos-&gt;next());
1122     inspos-&gt;set_next(c);
1123   } else {
1124     // no comments with such offset, yet. Insert before anything else.
1125     c-&gt;set_next(_strings);
1126     _strings = c;
1127   }
1128   if (c-&gt;next() == NULL) {
1129     _strings_last = c;
1130   }
1131 }
1132 
1133 void CodeStrings::assign(CodeStrings&amp; other) {
1134   other.check_valid();
1135   assert(is_null(), &quot;Cannot assign onto non-empty CodeStrings&quot;);
1136   _strings = other._strings;
1137   _strings_last = other._strings_last;
1138 #ifdef ASSERT
1139   _defunct = false;
1140 #endif
1141   other.set_null_and_invalidate();
1142 }
1143 
1144 // Deep copy of CodeStrings for consistent memory management.
1145 // Only used for actual disassembly so this is cheaper than reference counting
1146 // for the &quot;normal&quot; fastdebug case.
1147 void CodeStrings::copy(CodeStrings&amp; other) {
1148   other.check_valid();
1149   check_valid();
1150   assert(is_null(), &quot;Cannot copy onto non-empty CodeStrings&quot;);
1151   CodeString* n = other._strings;
1152   CodeString** ps = &amp;_strings;
1153   CodeString* prev = NULL;
1154   while (n != NULL) {
1155     *ps = new CodeString(n-&gt;string(),n-&gt;offset());
1156     (*ps)-&gt;_prev = prev;
1157     prev = *ps;
1158     ps = &amp;((*ps)-&gt;_next);
1159     n = n-&gt;next();
1160   }
1161 }
1162 
1163 const char* CodeStrings::_prefix = &quot; ;; &quot;;  // default: can be changed via set_prefix
1164 
1165 // Check if any block comments are pending for the given offset.
1166 bool CodeStrings::has_block_comment(intptr_t offset) const {
1167   if (_strings == NULL) return false;
1168   CodeString* c = find(offset);
1169   return c != NULL;
1170 }
1171 
1172 void CodeStrings::print_block_comment(outputStream* stream, intptr_t offset) const {
1173   check_valid();
1174   if (_strings != NULL) {
1175     CodeString* c = find(offset);
1176     while (c &amp;&amp; c-&gt;offset() == offset) {
1177       stream-&gt;bol();
1178       stream-&gt;print(&quot;%s&quot;, _prefix);
1179       // Don&#39;t interpret as format strings since it could contain %
1180       stream-&gt;print_raw(c-&gt;string());
1181       stream-&gt;bol(); // advance to next line only if string didn&#39;t contain a cr() at the end.
1182       c = c-&gt;next_comment();
1183     }
1184   }
1185 }
1186 
1187 // Also sets isNull()
1188 void CodeStrings::free() {
1189   CodeString* n = _strings;
1190   while (n) {
1191     // unlink the node from the list saving a pointer to the next
1192     CodeString* p = n-&gt;next();
1193     n-&gt;set_next(NULL);
1194     if (p != NULL) {
1195       assert(p-&gt;_prev == n, &quot;missing prev link&quot;);
1196       p-&gt;_prev = NULL;
1197     }
1198     delete n;
1199     n = p;
1200   }
1201   set_null_and_invalidate();
1202 }
1203 
1204 const char* CodeStrings::add_string(const char * string) {
1205   check_valid();
1206   CodeString* s = new CodeString(string);
1207   s-&gt;set_next(_strings);
1208   if (_strings == NULL) {
1209     _strings_last = s;
1210   }
1211   _strings = s;
1212   assert(s-&gt;string() != NULL, &quot;should have a string&quot;);
1213   return s-&gt;string();
1214 }
1215 
1216 void CodeBuffer::decode() {
1217   ttyLocker ttyl;
1218   Disassembler::decode(decode_begin(), insts_end(), tty);
1219   _decode_begin = insts_end();
1220 }
1221 
1222 void CodeSection::print(const char* name) {
1223   csize_t locs_size = locs_end() - locs_start();
1224   tty-&gt;print_cr(&quot; %7s.code = &quot; PTR_FORMAT &quot; : &quot; PTR_FORMAT &quot; : &quot; PTR_FORMAT &quot; (%d of %d)%s&quot;,
1225                 name, p2i(start()), p2i(end()), p2i(limit()), size(), capacity(),
1226                 is_frozen()? &quot; [frozen]&quot;: &quot;&quot;);
1227   tty-&gt;print_cr(&quot; %7s.locs = &quot; PTR_FORMAT &quot; : &quot; PTR_FORMAT &quot; : &quot; PTR_FORMAT &quot; (%d of %d) point=%d&quot;,
1228                 name, p2i(locs_start()), p2i(locs_end()), p2i(locs_limit()), locs_size, locs_capacity(), locs_point_off());
1229   if (PrintRelocations) {
1230     RelocIterator iter(this);
1231     iter.print();
1232   }
1233 }
1234 
1235 void CodeBuffer::print() {
1236   if (this == NULL) {
1237     tty-&gt;print_cr(&quot;NULL CodeBuffer pointer&quot;);
1238     return;
1239   }
1240 
1241   tty-&gt;print_cr(&quot;CodeBuffer:&quot;);
1242   for (int n = 0; n &lt; (int)SECT_LIMIT; n++) {
1243     // print each section
1244     CodeSection* cs = code_section(n);
1245     cs-&gt;print(code_section_name(n));
1246   }
1247 }
1248 
1249 // Directly disassemble code buffer.
1250 void CodeBuffer::decode(address start, address end) {
1251   ttyLocker ttyl;
1252   Disassembler::decode(this, start, end, tty);
1253 }
1254 
1255 #endif // PRODUCT
    </pre>
  </body>
</html>