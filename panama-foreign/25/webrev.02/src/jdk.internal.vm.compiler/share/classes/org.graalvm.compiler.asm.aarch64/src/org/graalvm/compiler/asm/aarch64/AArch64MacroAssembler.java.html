<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.asm.aarch64/src/org/graalvm/compiler/asm/aarch64/AArch64MacroAssembler.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2013, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  */
  23 
  24 
  25 
  26 package org.graalvm.compiler.asm.aarch64;
  27 
  28 import static jdk.vm.ci.aarch64.AArch64.CPU;
  29 import static jdk.vm.ci.aarch64.AArch64.rscratch1;
  30 import static jdk.vm.ci.aarch64.AArch64.rscratch2;
  31 import static jdk.vm.ci.aarch64.AArch64.sp;
  32 import static jdk.vm.ci.aarch64.AArch64.zr;
  33 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.BASE_REGISTER_ONLY;
  34 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.EXTENDED_REGISTER_OFFSET;
  35 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.IMMEDIATE_SCALED;
  36 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.IMMEDIATE_UNSCALED;
  37 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.REGISTER_OFFSET;
  38 import static org.graalvm.compiler.asm.aarch64.AArch64Assembler.Instruction.LDP;
  39 import static org.graalvm.compiler.asm.aarch64.AArch64Assembler.Instruction.STP;
  40 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.ADD_TO_BASE;
  41 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.ADD_TO_INDEX;
  42 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.NO_WORK;
  43 
  44 import org.graalvm.compiler.asm.BranchTargetOutOfBoundsException;
  45 import org.graalvm.compiler.asm.Label;
  46 import org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.MovSequenceAnnotation.MovAction;
  47 import org.graalvm.compiler.core.common.NumUtil;
  48 import org.graalvm.compiler.debug.GraalError;
  49 
  50 import jdk.vm.ci.aarch64.AArch64;
  51 import jdk.vm.ci.code.Register;
  52 import jdk.vm.ci.code.TargetDescription;
  53 
  54 public class AArch64MacroAssembler extends AArch64Assembler {
  55 
  56     private final ScratchRegister[] scratchRegister = new ScratchRegister[]{new ScratchRegister(rscratch1), new ScratchRegister(rscratch2)};
  57 
  58     // Points to the next free scratch register
  59     private int nextFreeScratchRegister = 0;
  60 
  61     // Last immediate ldr/str instruction, which is a candidate to be merged.
  62     private AArch64MemoryEncoding lastImmLoadStoreEncoding;
  63     private boolean isImmLoadStoreMerged = false;
  64 
  65     public AArch64MacroAssembler(TargetDescription target) {
  66         super(target);
  67     }
  68 
  69     public class ScratchRegister implements AutoCloseable {
  70         private final Register register;
  71 
  72         public ScratchRegister(Register register) {
  73             this.register = register;
  74         }
  75 
  76         public Register getRegister() {
  77             return register;
  78         }
  79 
  80         @Override
  81         public void close() {
  82             assert nextFreeScratchRegister &gt; 0 : &quot;Close called too often&quot;;
  83             nextFreeScratchRegister--;
  84         }
  85     }
  86 
  87     public ScratchRegister getScratchRegister() {
  88         return scratchRegister[nextFreeScratchRegister++];
  89     }
  90 
  91     @Override
  92     public void bind(Label l) {
  93         super.bind(l);
  94         // Clear last ldr/str instruction to prevent the labeled ldr/str being merged.
  95         lastImmLoadStoreEncoding = null;
  96     }
  97 
  98     private static class AArch64MemoryEncoding {
  99         private AArch64Address address;
 100         private Register result;
 101         private int sizeInBytes;
 102         private int position;
 103         private boolean isStore;
 104 
 105         AArch64MemoryEncoding(int sizeInBytes, Register result, AArch64Address address, boolean isStore, int position) {
 106             this.sizeInBytes = sizeInBytes;
 107             this.result = result;
 108             this.address = address;
 109             this.isStore = isStore;
 110             this.position = position;
 111             AArch64Address.AddressingMode addressingMode = address.getAddressingMode();
 112             assert addressingMode == IMMEDIATE_SCALED || addressingMode == IMMEDIATE_UNSCALED : &quot;Invalid address mode&quot; +
 113                             &quot;to merge: &quot; + addressingMode;
 114         }
 115 
 116         Register getBase() {
 117             return address.getBase();
 118         }
 119 
 120         int getOffset() {
 121             if (address.getAddressingMode() == IMMEDIATE_UNSCALED) {
 122                 return address.getImmediateRaw();
 123             }
 124             return address.getImmediate() * sizeInBytes;
 125         }
 126     }
 127 
 128     /**
 129      * Specifies what actions have to be taken to turn an arbitrary address of the form
 130      * {@code base + displacement [+ index [&lt;&lt; scale]]} into a valid AArch64Address.
 131      */
 132     public static class AddressGenerationPlan {
 133         public final WorkPlan workPlan;
 134         public final AArch64Address.AddressingMode addressingMode;
 135         public final boolean needsScratch;
 136 
 137         public enum WorkPlan {
 138             /**
 139              * Can be used as-is without extra work.
 140              */
 141             NO_WORK,
 142             /**
 143              * Add scaled displacement to index register.
 144              */
 145             ADD_TO_INDEX,
 146             /**
 147              * Add unscaled displacement to base register.
 148              */
 149             ADD_TO_BASE,
 150         }
 151 
 152         /**
 153          * @param workPlan Work necessary to generate a valid address.
 154          * @param addressingMode Addressing mode of generated address.
 155          * @param needsScratch True if generating address needs a scatch register, false otherwise.
 156          */
 157         public AddressGenerationPlan(WorkPlan workPlan, AArch64Address.AddressingMode addressingMode, boolean needsScratch) {
 158             this.workPlan = workPlan;
 159             this.addressingMode = addressingMode;
 160             this.needsScratch = needsScratch;
 161         }
 162     }
 163 
 164     /**
 165      * Generates an addressplan for an address of the form
 166      * {@code base + displacement [+ index [&lt;&lt; log2(transferSize)]]} with the index register and
 167      * scaling being optional.
 168      *
 169      * @param displacement an arbitrary displacement.
 170      * @param hasIndexRegister true if the address uses an index register, false otherwise. non null
 171      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 172      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 173      * @return AddressGenerationPlan that specifies the actions necessary to generate a valid
 174      *         AArch64Address for the given parameters.
 175      */
 176     public static AddressGenerationPlan generateAddressPlan(long displacement, boolean hasIndexRegister, int transferSize) {
 177         assert transferSize == 0 || transferSize == 1 || transferSize == 2 || transferSize == 4 || transferSize == 8;
 178         boolean indexScaled = transferSize != 0;
 179         int log2Scale = NumUtil.log2Ceil(transferSize);
 180         long scaledDisplacement = displacement &gt;&gt; log2Scale;
 181         boolean displacementScalable = indexScaled &amp;&amp; (displacement &amp; (transferSize - 1)) == 0;
 182         if (displacement == 0) {
 183             // register offset without any work beforehand.
 184             return new AddressGenerationPlan(NO_WORK, REGISTER_OFFSET, false);
 185         } else {
 186             if (hasIndexRegister) {
 187                 if (displacementScalable) {
 188                     boolean needsScratch = !isArithmeticImmediate(scaledDisplacement);
 189                     return new AddressGenerationPlan(ADD_TO_INDEX, REGISTER_OFFSET, needsScratch);
 190                 } else {
 191                     boolean needsScratch = !isArithmeticImmediate(displacement);
 192                     return new AddressGenerationPlan(ADD_TO_BASE, REGISTER_OFFSET, needsScratch);
 193                 }
 194             } else {
 195                 if (displacementScalable &amp;&amp; NumUtil.isUnsignedNbit(12, scaledDisplacement)) {
 196                     return new AddressGenerationPlan(NO_WORK, IMMEDIATE_SCALED, false);
 197                 } else if (NumUtil.isSignedNbit(9, displacement)) {
 198                     return new AddressGenerationPlan(NO_WORK, IMMEDIATE_UNSCALED, false);
 199                 } else {
 200                     boolean needsScratch = !isArithmeticImmediate(displacement);
 201                     return new AddressGenerationPlan(ADD_TO_BASE, REGISTER_OFFSET, needsScratch);
 202                 }
 203             }
 204         }
 205     }
 206 
 207     /**
 208      * Returns an AArch64Address pointing to
 209      * {@code base + displacement + index &lt;&lt; log2(transferSize)}.
 210      *
 211      * @param base general purpose register. May not be null or the zero register.
 212      * @param displacement arbitrary displacement added to base.
 213      * @param index general purpose register. May not be null or the stack pointer.
 214      * @param signExtendIndex if true consider index register a word register that should be
 215      *            sign-extended before being added.
 216      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 217      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 218      * @param additionalReg additional register used either as a scratch register or as part of the
 219      *            final address, depending on whether allowOverwrite is true or not. May not be null
 220      *            or stackpointer.
 221      * @param allowOverwrite if true allows to change value of base or index register to generate
 222      *            address.
 223      * @return AArch64Address pointing to memory at
 224      *         {@code base + displacement + index &lt;&lt; log2(transferSize)}.
 225      */
 226     public AArch64Address makeAddress(Register base, long displacement, Register index, boolean signExtendIndex, int transferSize, Register additionalReg, boolean allowOverwrite) {
 227         AddressGenerationPlan plan = generateAddressPlan(displacement, !index.equals(zr), transferSize);
 228         assert allowOverwrite || !zr.equals(additionalReg) || plan.workPlan == NO_WORK;
 229         assert !plan.needsScratch || !zr.equals(additionalReg);
 230         int log2Scale = NumUtil.log2Ceil(transferSize);
 231         long scaledDisplacement = displacement &gt;&gt; log2Scale;
 232         Register newIndex = index;
 233         Register newBase = base;
 234         int immediate;
 235         switch (plan.workPlan) {
 236             case NO_WORK:
 237                 if (plan.addressingMode == IMMEDIATE_SCALED) {
 238                     immediate = (int) scaledDisplacement;
 239                 } else {
 240                     immediate = (int) displacement;
 241                 }
 242                 break;
 243             case ADD_TO_INDEX:
 244                 newIndex = allowOverwrite ? index : additionalReg;
 245                 assert !newIndex.equals(sp) &amp;&amp; !newIndex.equals(zr);
 246                 if (plan.needsScratch) {
 247                     mov(additionalReg, scaledDisplacement);
 248                     add(signExtendIndex ? 32 : 64, newIndex, index, additionalReg);
 249                 } else {
 250                     add(signExtendIndex ? 32 : 64, newIndex, index, (int) scaledDisplacement);
 251                 }
 252                 immediate = 0;
 253                 break;
 254             case ADD_TO_BASE:
 255                 newBase = allowOverwrite ? base : additionalReg;
 256                 assert !newBase.equals(sp) &amp;&amp; !newBase.equals(zr);
 257                 if (plan.needsScratch) {
 258                     mov(additionalReg, displacement);
 259                     add(64, newBase, base, additionalReg);
 260                 } else {
 261                     add(64, newBase, base, (int) displacement);
 262                 }
 263                 immediate = 0;
 264                 break;
 265             default:
 266                 throw GraalError.shouldNotReachHere();
 267         }
 268         AArch64Address.AddressingMode addressingMode = plan.addressingMode;
 269         ExtendType extendType = null;
 270         if (addressingMode == REGISTER_OFFSET) {
 271             if (newIndex.equals(zr)) {
 272                 addressingMode = BASE_REGISTER_ONLY;
 273             } else if (signExtendIndex) {
 274                 addressingMode = EXTENDED_REGISTER_OFFSET;
 275                 extendType = ExtendType.SXTW;
 276             }
 277         }
 278         return AArch64Address.createAddress(addressingMode, newBase, newIndex, immediate, transferSize != 0, extendType);
 279     }
 280 
 281     /**
 282      * Returns an AArch64Address pointing to {@code base + displacement}. Specifies the memory
 283      * transfer size to allow some optimizations when building the address.
 284      *
 285      * @param base general purpose register. May not be null or the zero register.
 286      * @param displacement arbitrary displacement added to base.
 287      * @param transferSize the memory transfer size in bytes.
 288      * @param additionalReg additional register used either as a scratch register or as part of the
 289      *            final address, depending on whether allowOverwrite is true or not. May not be
 290      *            null, zero register or stackpointer.
 291      * @param allowOverwrite if true allows to change value of base or index register to generate
 292      *            address.
 293      * @return AArch64Address pointing to memory at {@code base + displacement}.
 294      */
 295     public AArch64Address makeAddress(Register base, long displacement, Register additionalReg, int transferSize, boolean allowOverwrite) {
 296         assert additionalReg.getRegisterCategory().equals(CPU);
 297         return makeAddress(base, displacement, zr, /* sign-extend */false, transferSize, additionalReg, allowOverwrite);
 298     }
 299 
 300     /**
 301      * Returns an AArch64Address pointing to {@code base + displacement}. Fails if address cannot be
 302      * represented without overwriting base register or using a scratch register.
 303      *
 304      * @param base general purpose register. May not be null or the zero register.
 305      * @param displacement arbitrary displacement added to base.
 306      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 307      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 308      * @return AArch64Address pointing to memory at {@code base + displacement}.
 309      */
 310     public AArch64Address makeAddress(Register base, long displacement, int transferSize) {
 311         return makeAddress(base, displacement, zr, /* signExtend */false, //
 312                         transferSize, zr, /* allowOverwrite */false);
 313     }
 314 
 315     /**
 316      * Loads memory address into register.
 317      *
 318      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 319      * @param address address whose value is loaded into dst. May not be null,
 320      *            {@link org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode#IMMEDIATE_POST_INDEXED
 321      *            POST_INDEXED} or
 322      *            {@link org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode#IMMEDIATE_PRE_INDEXED
 323      *            IMMEDIATE_PRE_INDEXED}
 324      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 325      *            the index register is scaled. Can be 1, 2, 4 or 8.
 326      */
 327     public void loadAddress(Register dst, AArch64Address address, int transferSize) {
 328         assert transferSize == 1 || transferSize == 2 || transferSize == 4 || transferSize == 8;
 329         assert dst.getRegisterCategory().equals(CPU);
 330         int shiftAmt = NumUtil.log2Ceil(transferSize);
 331         switch (address.getAddressingMode()) {
 332             case IMMEDIATE_SCALED:
 333                 int scaledImmediate = address.getImmediateRaw() &lt;&lt; shiftAmt;
 334                 int lowerBits = scaledImmediate &amp; NumUtil.getNbitNumberInt(12);
 335                 int higherBits = scaledImmediate &amp; ~NumUtil.getNbitNumberInt(12);
 336                 boolean firstAdd = true;
 337                 if (lowerBits != 0) {
 338                     add(64, dst, address.getBase(), lowerBits);
 339                     firstAdd = false;
 340                 }
 341                 if (higherBits != 0) {
 342                     Register src = firstAdd ? address.getBase() : dst;
 343                     add(64, dst, src, higherBits);
 344                 }
 345                 break;
 346             case IMMEDIATE_UNSCALED:
 347                 int immediate = address.getImmediateRaw();
 348                 add(64, dst, address.getBase(), immediate);
 349                 break;
 350             case REGISTER_OFFSET:
 351                 add(64, dst, address.getBase(), address.getOffset(), ShiftType.LSL, address.isScaled() ? shiftAmt : 0);
 352                 break;
 353             case EXTENDED_REGISTER_OFFSET:
 354                 add(64, dst, address.getBase(), address.getOffset(), address.getExtendType(), address.isScaled() ? shiftAmt : 0);
 355                 break;
 356             case PC_LITERAL: {
 357                 addressOf(dst);
 358                 break;
 359             }
 360             case BASE_REGISTER_ONLY:
 361                 movx(dst, address.getBase());
 362                 break;
 363             default:
 364                 throw GraalError.shouldNotReachHere();
 365         }
 366     }
 367 
 368     private boolean tryMerge(int sizeInBytes, Register rt, AArch64Address address, boolean isStore) {
 369         isImmLoadStoreMerged = false;
 370         if (lastImmLoadStoreEncoding == null) {
 371             return false;
 372         }
 373 
 374         // Only immediate scaled/unscaled address can be merged.
 375         // Pre-index and post-index mode can&#39;t be merged.
 376         AArch64Address.AddressingMode addressMode = address.getAddressingMode();
 377         if (addressMode != IMMEDIATE_SCALED &amp;&amp; addressMode != IMMEDIATE_UNSCALED) {
 378             return false;
 379         }
 380 
 381         // Only the two adjacent ldrs/strs can be merged.
 382         int lastPosition = position() - 4;
 383         if (lastPosition &lt; 0 || lastPosition != lastImmLoadStoreEncoding.position) {
 384             return false;
 385         }
 386 
 387         if (isStore != lastImmLoadStoreEncoding.isStore) {
 388             return false;
 389         }
 390 
 391         // Only merge ldr/str with the same size of 32bits or 64bits.
 392         if (sizeInBytes != lastImmLoadStoreEncoding.sizeInBytes || (sizeInBytes != 4 &amp;&amp; sizeInBytes != 8)) {
 393             return false;
 394         }
 395 
 396         // Base register must be the same one.
 397         Register curBase = address.getBase();
 398         Register preBase = lastImmLoadStoreEncoding.getBase();
 399         if (!curBase.equals(preBase)) {
 400             return false;
 401         }
 402 
 403         // If the two ldrs have the same rt register, they can&#39;t be merged.
 404         // If the two ldrs have dependence, they can&#39;t be merged.
 405         Register curRt = rt;
 406         Register preRt = lastImmLoadStoreEncoding.result;
 407         if (!isStore &amp;&amp; (curRt.equals(preRt) || preRt.equals(curBase))) {
 408             return false;
 409         }
 410 
 411         // Offset checking. Offsets of the two ldrs/strs must be continuous.
 412         int curOffset = address.getImmediateRaw();
 413         if (addressMode == IMMEDIATE_SCALED) {
 414             curOffset = curOffset * sizeInBytes;
 415         }
 416         int preOffset = lastImmLoadStoreEncoding.getOffset();
 417         if (Math.abs(curOffset - preOffset) != sizeInBytes) {
 418             return false;
 419         }
 420 
 421         // Offset must be in ldp/stp instruction&#39;s range.
 422         int offset = curOffset &gt; preOffset ? preOffset : curOffset;
 423         int minOffset = -64 * sizeInBytes;
 424         int maxOffset = 63 * sizeInBytes;
 425         if (offset &lt; minOffset || offset &gt; maxOffset) {
 426             return false;
 427         }
 428 
 429         // Alignment checking.
 430         if (isFlagSet(AArch64.Flag.AvoidUnalignedAccesses)) {
 431             // AArch64 sp is 16-bytes aligned.
 432             if (curBase.equals(sp)) {
 433                 long pairMask = sizeInBytes * 2 - 1;
 434                 if ((offset &amp; pairMask) != 0) {
 435                     return false;
 436                 }
 437             } else {
 438                 // If base is not sp, we can&#39;t guarantee the access is aligned.
 439                 return false;
 440             }
 441         } else {
 442             // ldp/stp only supports sizeInBytes aligned offset.
 443             long mask = sizeInBytes - 1;
 444             if ((curOffset &amp; mask) != 0 || (preOffset &amp; mask) != 0) {
 445                 return false;
 446             }
 447         }
 448 
 449         // Merge two ldrs/strs to ldp/stp.
 450         Register rt1 = preRt;
 451         Register rt2 = curRt;
 452         if (curOffset &lt; preOffset) {
 453             rt1 = curRt;
 454             rt2 = preRt;
 455         }
 456         int immediate = offset / sizeInBytes;
 457         Instruction instruction = isStore ? STP : LDP;
 458         int size = sizeInBytes * Byte.SIZE;
 459         insertLdpStp(size, instruction, rt1, rt2, curBase, immediate, lastPosition);
 460         lastImmLoadStoreEncoding = null;
 461         isImmLoadStoreMerged = true;
 462         return true;
 463     }
 464 
 465     /**
 466      * Try to merge two continuous ldr/str to one ldp/stp. If this current ldr/str is not merged,
 467      * save it as the last ldr/str.
 468      */
 469     private boolean tryMergeLoadStore(int srcSize, Register rt, AArch64Address address, boolean isStore) {
 470         int sizeInBytes = srcSize / Byte.SIZE;
 471         if (tryMerge(sizeInBytes, rt, address, isStore)) {
 472             return true;
 473         }
 474 
 475         // Save last ldr/str if it is not merged.
 476         AArch64Address.AddressingMode addressMode = address.getAddressingMode();
 477         if (addressMode == IMMEDIATE_SCALED || addressMode == IMMEDIATE_UNSCALED) {
 478             if (addressMode == IMMEDIATE_UNSCALED) {
 479                 long mask = sizeInBytes - 1;
 480                 int offset = address.getImmediateRaw();
 481                 if ((offset &amp; mask) != 0) {
 482                     return false;
 483                 }
 484             }
 485             lastImmLoadStoreEncoding = new AArch64MemoryEncoding(sizeInBytes, rt, address, isStore, position());
 486         }
 487         return false;
 488     }
 489 
 490     public boolean isImmLoadStoreMerged() {
 491         return isImmLoadStoreMerged;
 492     }
 493 
 494     public void movx(Register dst, Register src) {
 495         mov(64, dst, src);
 496     }
 497 
 498     public void mov(int size, Register dst, Register src) {
 499         if (dst.equals(sp) || src.equals(sp)) {
 500             add(size, dst, src, 0);
 501         } else {
 502             or(size, dst, zr, src);
 503         }
 504     }
 505 
 506     /**
 507      * Generates a 32-bit immediate move code sequence.
 508      *
 509      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 510      * @param imm the value to move into the register.
 511      * @param needsImmAnnotation Flag denoting if annotation should be added.
 512      */
 513     private void mov32(Register dst, int imm, boolean needsImmAnnotation) {
 514         MovAction[] includeSet = {MovAction.SKIPPED, MovAction.SKIPPED};
 515         int pos = position();
 516 
 517         // Split 32-bit imm into low16 and high16 parts.
 518         int low16 = imm &amp; 0xFFFF;
 519         int high16 = (imm &gt;&gt;&gt; 16) &amp; 0xFFFF;
 520 
 521         // Generate code sequence with a combination of MOVZ or MOVN with MOVK.
 522         if (high16 == 0) {
 523             movz(32, dst, low16, 0);
 524             includeSet[0] = MovAction.USED;
 525         } else if (high16 == 0xFFFF) {
 526             movn(32, dst, low16 ^ 0xFFFF, 0);
 527             includeSet[0] = MovAction.NEGATED;
 528         } else if (low16 == 0) {
 529             movz(32, dst, high16, 16);
 530             includeSet[1] = MovAction.USED;
 531         } else if (low16 == 0xFFFF) {
 532             movn(32, dst, high16 ^ 0xFFFF, 16);
 533             includeSet[1] = MovAction.NEGATED;
 534         } else {
 535             // Neither of the 2 parts is all-0s or all-1s. Generate 2 instructions.
 536             movz(32, dst, low16, 0);
 537             movk(32, dst, high16, 16);
 538             includeSet[0] = MovAction.USED;
 539             includeSet[1] = MovAction.USED;
 540         }
 541         if (needsImmAnnotation) {
 542             annotateImmediateMovSequence(pos, includeSet);
 543         }
 544     }
 545 
 546     /**
 547      * Generates a 64-bit immediate move code sequence.
 548      *
 549      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 550      * @param imm the value to move into the register
 551      * @param needsImmAnnotation Flag denoting if annotation should be added.
 552      */
 553     private void mov64(Register dst, long imm, boolean needsImmAnnotation) {
 554         MovAction[] includeSet = {MovAction.SKIPPED, MovAction.SKIPPED, MovAction.SKIPPED, MovAction.SKIPPED};
 555         int pos = position();
 556         int[] chunks = new int[4];
 557         int zeroCount = 0;
 558         int negCount = 0;
 559 
 560         // Split 64-bit imm into 4 chunks and count the numbers of all-0 and all-1 chunks.
 561         for (int i = 0; i &lt; 4; i++) {
 562             int chunk = (int) ((imm &gt;&gt;&gt; (i * 16)) &amp; 0xFFFFL);
 563             if (chunk == 0) {
 564                 zeroCount++;
 565             } else if (chunk == 0xFFFF) {
 566                 negCount++;
 567             }
 568             chunks[i] = chunk;
 569         }
 570 
 571         // Generate code sequence with a combination of MOVZ or MOVN with MOVK.
 572         if (zeroCount == 4) {
 573             // Generate only one MOVZ.
 574             movz(64, dst, 0, 0);
 575             includeSet[0] = MovAction.USED;
 576         } else if (negCount == 4) {
 577             // Generate only one MOVN.
 578             movn(64, dst, 0, 0);
 579             includeSet[0] = MovAction.NEGATED;
 580         } else if (zeroCount == 3) {
 581             // Generate only one MOVZ.
 582             for (int i = 0; i &lt; 4; i++) {
 583                 if (chunks[i] != 0) {
 584                     movz(64, dst, chunks[i], i * 16);
 585                     includeSet[i] = MovAction.USED;
 586                     break;
 587                 }
 588             }
 589         } else if (negCount == 3) {
 590             // Generate only one MOVN.
 591             for (int i = 0; i &lt; 4; i++) {
 592                 if (chunks[i] != 0xFFFF) {
 593                     movn(64, dst, chunks[i] ^ 0xFFFF, i * 16);
 594                     includeSet[i] = MovAction.NEGATED;
 595                     break;
 596                 }
 597             }
 598         } else if (zeroCount == 2) {
 599             // Generate one MOVZ and one MOVK.
 600             int i;
 601             for (i = 0; i &lt; 4; i++) {
 602                 if (chunks[i] != 0) {
 603                     movz(64, dst, chunks[i], i * 16);
 604                     includeSet[i] = MovAction.USED;
 605                     break;
 606                 }
 607             }
 608             for (int k = i + 1; k &lt; 4; k++) {
 609                 if (chunks[k] != 0) {
 610                     movk(64, dst, chunks[k], k * 16);
 611                     includeSet[k] = MovAction.USED;
 612                     break;
 613                 }
 614             }
 615         } else if (negCount == 2) {
 616             // Generate one MOVN and one MOVK.
 617             int i;
 618             for (i = 0; i &lt; 4; i++) {
 619                 if (chunks[i] != 0xFFFF) {
 620                     movn(64, dst, chunks[i] ^ 0xFFFF, i * 16);
 621                     includeSet[i] = MovAction.NEGATED;
 622                     break;
 623                 }
 624             }
 625             for (int k = i + 1; k &lt; 4; k++) {
 626                 if (chunks[k] != 0xFFFF) {
 627                     movk(64, dst, chunks[k], k * 16);
 628                     includeSet[k] = MovAction.USED;
 629                     break;
 630                 }
 631             }
 632         } else if (zeroCount == 1) {
 633             // Generate one MOVZ and two MOVKs.
 634             int i;
 635             for (i = 0; i &lt; 4; i++) {
 636                 if (chunks[i] != 0) {
 637                     movz(64, dst, chunks[i], i * 16);
 638                     includeSet[i] = MovAction.USED;
 639                     break;
 640                 }
 641             }
 642             int numMovks = 0;
 643             for (int k = i + 1; k &lt; 4; k++) {
 644                 if (chunks[k] != 0) {
 645                     movk(64, dst, chunks[k], k * 16);
 646                     includeSet[k] = MovAction.USED;
 647                     numMovks++;
 648                 }
 649             }
 650             assert numMovks == 2;
 651         } else if (negCount == 1) {
 652             // Generate one MOVN and two MOVKs.
 653             int i;
 654             for (i = 0; i &lt; 4; i++) {
 655                 if (chunks[i] != 0xFFFF) {
 656                     movn(64, dst, chunks[i] ^ 0xFFFF, i * 16);
 657                     includeSet[i] = MovAction.NEGATED;
 658                     break;
 659                 }
 660             }
 661             int numMovks = 0;
 662             for (int k = i + 1; k &lt; 4; k++) {
 663                 if (chunks[k] != 0xFFFF) {
 664                     movk(64, dst, chunks[k], k * 16);
 665                     includeSet[k] = MovAction.USED;
 666                     numMovks++;
 667                 }
 668             }
 669             assert numMovks == 2;
 670         } else {
 671             // Generate one MOVZ and three MOVKs
 672             movz(64, dst, chunks[0], 0);
 673             movk(64, dst, chunks[1], 16);
 674             movk(64, dst, chunks[2], 32);
 675             movk(64, dst, chunks[3], 48);
 676             includeSet[0] = MovAction.USED;
 677             includeSet[1] = MovAction.USED;
 678             includeSet[2] = MovAction.USED;
 679             includeSet[3] = MovAction.USED;
 680         }
 681         if (needsImmAnnotation) {
 682             annotateImmediateMovSequence(pos, includeSet);
 683         }
 684     }
 685 
 686     /**
 687      * Loads immediate into register.
 688      *
 689      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 690      * @param imm immediate loaded into register.
 691      */
 692     public void mov(Register dst, int imm) {
 693         mov(dst, imm, false);
 694     }
 695 
 696     /**
 697      * Loads immediate into register.
 698      *
 699      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 700      * @param imm immediate loaded into register.
 701      */
 702     public void mov(Register dst, long imm) {
 703         mov(dst, imm, false);
 704     }
 705 
 706     /**
 707      * Loads immediate into register.
 708      *
 709      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 710      * @param imm immediate loaded into register.
 711      * @param needsImmAnnotation Flag to signal of the immediate value should be annotated.
 712      */
 713     public void mov(Register dst, int imm, boolean needsImmAnnotation) {
 714         if (imm == 0) {
 715             mov(32, dst, zr);
 716         } else if (isLogicalImmediate(imm)) {
 717             or(32, dst, zr, imm);
 718         } else {
 719             mov32(dst, imm, needsImmAnnotation);
 720         }
 721     }
 722 
 723     /**
 724      * Loads immediate into register.
 725      *
 726      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 727      * @param imm immediate loaded into register.
 728      * @param needsImmAnnotation Flag to signal of the immediate value should be annotated.
 729      */
 730     public void mov(Register dst, long imm, boolean needsImmAnnotation) {
 731         assert dst.getRegisterCategory().equals(CPU);
 732         if (imm == 0L) {
 733             movx(dst, zr);
 734         } else if (isLogicalImmediate(imm)) {
 735             or(64, dst, zr, imm);
 736         } else if (imm &gt;&gt; 32 == -1L &amp;&amp; (int) imm &lt; 0 &amp;&amp; LogicalImmediateTable.isRepresentable((int) imm) != LogicalImmediateTable.Representable.NO) {
 737             // If the higher 32-bit are 1s and the sign bit of the lower 32-bits is set *and* we can
 738             // represent the lower 32 bits as a logical immediate we can create the lower 32-bit and
 739             // then sign extend
 740             // them. This allows us to cover immediates like ~1L with 2 instructions.
 741             mov(dst, (int) imm);
 742             sxt(64, 32, dst, dst);
 743         } else {
 744             mov64(dst, imm, needsImmAnnotation);
 745         }
 746     }
 747 
 748     /**
 749      * Generates a 48-bit immediate move code sequence. The immediate may later be updated by
 750      * HotSpot.
 751      *
 752      * In AArch64 mode the virtual address space is 48-bits in size, so we only need three
 753      * instructions to create a patchable instruction sequence that can reach anywhere.
 754      *
 755      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 756      * @param imm
 757      */
 758     public void movNativeAddress(Register dst, long imm) {
 759         movNativeAddress(dst, imm, false);
 760     }
 761 
 762     /**
 763      * Generates a 48-bit immediate move code sequence. The immediate may later be updated by
 764      * HotSpot.
 765      *
 766      * In AArch64 mode the virtual address space is 48-bits in size, so we only need three
 767      * instructions to create a patchable instruction sequence that can reach anywhere.
 768      *
 769      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 770      * @param imm The immediate address
 771      * @param needsImmAnnotation Flag to signal of the immediate value should be annotated.
 772      */
 773     public void movNativeAddress(Register dst, long imm, boolean needsImmAnnotation) {
 774         assert (imm &amp; 0xFFFF_0000_0000_0000L) == 0;
 775         // We have to move all non zero parts of the immediate in 16-bit chunks
 776         boolean firstMove = true;
 777         int pos = position();
 778         for (int offset = 0; offset &lt; 48; offset += 16) {
 779             int chunk = (int) (imm &gt;&gt; offset) &amp; NumUtil.getNbitNumberInt(16);
 780             if (firstMove) {
 781                 movz(64, dst, chunk, offset);
 782                 firstMove = false;
 783             } else {
 784                 movk(64, dst, chunk, offset);
 785             }
 786         }
 787         if (needsImmAnnotation) {
 788             MovAction[] includeSet = {MovAction.USED, MovAction.USED, MovAction.USED};
 789             annotateImmediateMovSequence(pos, includeSet);
 790         }
 791         assert !firstMove;
 792     }
 793 
 794     /**
 795      * Generates a 32-bit immediate move code sequence. The immediate may later be updated by
 796      * HotSpot.
 797      *
 798      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 799      * @param imm
 800      */
 801     public void movNarrowAddress(Register dst, long imm) {
 802         assert (imm &amp; 0xFFFF_FFFF_0000_0000L) == 0;
 803         movz(64, dst, (int) (imm &gt;&gt;&gt; 16), 16);
 804         movk(64, dst, (int) (imm &amp; 0xffff), 0);
 805     }
 806 
 807     /**
 808      * @return Number of instructions necessary to load immediate into register.
 809      */
 810     public static int nrInstructionsToMoveImmediate(long imm) {
 811         if (imm == 0L || LogicalImmediateTable.isRepresentable(true, imm) != LogicalImmediateTable.Representable.NO) {
 812             return 1;
 813         }
 814         if (imm &gt;&gt; 32 == -1L &amp;&amp; (int) imm &lt; 0 &amp;&amp; LogicalImmediateTable.isRepresentable((int) imm) != LogicalImmediateTable.Representable.NO) {
 815             // If the higher 32-bit are 1s and the sign bit of the lower 32-bits is set *and* we can
 816             // represent the lower 32 bits as a logical immediate we can create the lower 32-bit and
 817             // then sign extend
 818             // them. This allows us to cover immediates like ~1L with 2 instructions.
 819             return 2;
 820         }
 821         int nrInstructions = 0;
 822         for (int offset = 0; offset &lt; 64; offset += 16) {
 823             int part = (int) (imm &gt;&gt; offset) &amp; NumUtil.getNbitNumberInt(16);
 824             if (part != 0) {
 825                 nrInstructions++;
 826             }
 827         }
 828         return nrInstructions;
 829     }
 830 
 831     /**
 832      * Loads a srcSize value from address into rt sign-extending it if necessary.
 833      *
 834      * @param targetSize size of target register in bits. Must be 32 or 64.
 835      * @param srcSize size of memory read in bits. Must be 8, 16 or 32 and smaller or equal to
 836      *            targetSize.
 837      * @param rt general purpose register. May not be null or stackpointer.
 838      * @param address all addressing modes allowed. May not be null.
 839      */
 840     @Override
 841     public void ldrs(int targetSize, int srcSize, Register rt, AArch64Address address) {
 842         assert targetSize == 32 || targetSize == 64;
 843         assert srcSize &lt;= targetSize;
 844         if (targetSize == srcSize) {
 845             ldr(srcSize, rt, address);
 846         } else {
 847             super.ldrs(targetSize, srcSize, rt, address);
 848         }
 849     }
 850 
 851     /**
 852      * Loads a srcSize value from address into rt zero-extending it if necessary.
 853      *
 854      * @param srcSize size of memory read in bits. Must be 8, 16 or 32 and smaller or equal to
 855      *            targetSize.
 856      * @param rt general purpose register. May not be null or stackpointer.
 857      * @param address all addressing modes allowed. May not be null.
 858      */
 859     @Override
 860     public void ldr(int srcSize, Register rt, AArch64Address address) {
 861         // Try to merge two adjacent loads into one ldp.
 862         if (!tryMergeLoadStore(srcSize, rt, address, false)) {
 863             super.ldr(srcSize, rt, address);
 864         }
 865     }
 866 
 867     /**
 868      * Stores register rt into memory pointed by address.
 869      *
 870      * @param destSize number of bits written to memory. Must be 8, 16, 32 or 64.
 871      * @param rt general purpose register. May not be null or stackpointer.
 872      * @param address all addressing modes allowed. May not be null.
 873      */
 874     @Override
 875     public void str(int destSize, Register rt, AArch64Address address) {
 876         // Try to merge two adjacent stores into one stp.
 877         if (!tryMergeLoadStore(destSize, rt, address, true)) {
 878             super.str(destSize, rt, address);
 879         }
 880     }
 881 
 882     /**
 883      * Conditional move. dst = src1 if condition else src2.
 884      *
 885      * @param size register size. Has to be 32 or 64.
 886      * @param result general purpose register. May not be null or the stackpointer.
 887      * @param trueValue general purpose register. May not be null or the stackpointer.
 888      * @param falseValue general purpose register. May not be null or the stackpointer.
 889      * @param cond any condition flag. May not be null.
 890      */
 891     public void cmov(int size, Register result, Register trueValue, Register falseValue, ConditionFlag cond) {
 892         super.csel(size, result, trueValue, falseValue, cond);
 893     }
 894 
 895     /**
 896      * Conditional set. dst = 1 if condition else 0.
 897      *
 898      * @param dst general purpose register. May not be null or stackpointer.
 899      * @param condition any condition. May not be null.
 900      */
 901     public void cset(int size, Register dst, ConditionFlag condition) {
 902         super.csinc(size, dst, zr, zr, condition.negate());
 903     }
 904 
 905     /**
 906      * dst = src1 + src2.
 907      *
 908      * @param size register size. Has to be 32 or 64.
 909      * @param dst general purpose register. May not be null.
 910      * @param src1 general purpose register. May not be null.
 911      * @param src2 general purpose register. May not be null or stackpointer.
 912      */
 913     public void add(int size, Register dst, Register src1, Register src2) {
 914         if (dst.equals(sp) || src1.equals(sp)) {
 915             super.add(size, dst, src1, src2, ExtendType.UXTX, 0);
 916         } else {
 917             super.add(size, dst, src1, src2, ShiftType.LSL, 0);
 918         }
 919     }
 920 
 921     /**
 922      * dst = src1 + src2 and sets condition flags.
 923      *
 924      * @param size register size. Has to be 32 or 64.
 925      * @param dst general purpose register. May not be null.
 926      * @param src1 general purpose register. May not be null.
 927      * @param src2 general purpose register. May not be null or stackpointer.
 928      */
 929     public void adds(int size, Register dst, Register src1, Register src2) {
 930         if (dst.equals(sp) || src1.equals(sp)) {
 931             super.adds(size, dst, src1, src2, ExtendType.UXTX, 0);
 932         } else {
 933             super.adds(size, dst, src1, src2, ShiftType.LSL, 0);
 934         }
 935     }
 936 
 937     /**
 938      * dst = src1 - src2 and sets condition flags.
 939      *
 940      * @param size register size. Has to be 32 or 64.
 941      * @param dst general purpose register. May not be null.
 942      * @param src1 general purpose register. May not be null.
 943      * @param src2 general purpose register. May not be null or stackpointer.
 944      */
 945     public void subs(int size, Register dst, Register src1, Register src2) {
 946         if (dst.equals(sp) || src1.equals(sp)) {
 947             super.subs(size, dst, src1, src2, ExtendType.UXTX, 0);
 948         } else {
 949             super.subs(size, dst, src1, src2, ShiftType.LSL, 0);
 950         }
 951     }
 952 
 953     /**
 954      * dst = src1 - src2.
 955      *
 956      * @param size register size. Has to be 32 or 64.
 957      * @param dst general purpose register. May not be null.
 958      * @param src1 general purpose register. May not be null.
 959      * @param src2 general purpose register. May not be null or stackpointer.
 960      */
 961     public void sub(int size, Register dst, Register src1, Register src2) {
 962         if (dst.equals(sp) || src1.equals(sp)) {
 963             super.sub(size, dst, src1, src2, ExtendType.UXTX, 0);
 964         } else {
 965             super.sub(size, dst, src1, src2, ShiftType.LSL, 0);
 966         }
 967     }
 968 
 969     /**
 970      * dst = src1 + shiftType(src2, shiftAmt &amp; (size - 1)).
 971      *
 972      * @param size register size. Has to be 32 or 64.
 973      * @param dst general purpose register. May not be null or stackpointer.
 974      * @param src1 general purpose register. May not be null or stackpointer.
 975      * @param src2 general purpose register. May not be null or stackpointer.
 976      * @param shiftType any type but ROR.
 977      * @param shiftAmt arbitrary shift amount.
 978      */
 979     @Override
 980     public void add(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
 981         int shift = clampShiftAmt(size, shiftAmt);
 982         super.add(size, dst, src1, src2, shiftType, shift);
 983     }
 984 
 985     /**
 986      * dst = src1 + shiftType(src2, shiftAmt &amp; (size-1)) and sets condition flags.
 987      *
 988      * @param size register size. Has to be 32 or 64.
 989      * @param dst general purpose register. May not be null or stackpointer.
 990      * @param src1 general purpose register. May not be null or stackpointer.
 991      * @param src2 general purpose register. May not be null or stackpointer.
 992      * @param shiftType any type but ROR.
 993      * @param shiftAmt arbitrary shift amount.
 994      */
 995     @Override
 996     public void sub(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
 997         int shift = clampShiftAmt(size, shiftAmt);
 998         super.sub(size, dst, src1, src2, shiftType, shift);
 999     }
1000 
1001     /**
1002      * dst = -src1.
1003      *
1004      * @param size register size. Has to be 32 or 64.
1005      * @param dst general purpose register. May not be null or stackpointer.
1006      * @param src general purpose register. May not be null or stackpointer.
1007      */
1008     public void neg(int size, Register dst, Register src) {
1009         sub(size, dst, zr, src);
1010     }
1011 
1012     /**
1013      * dst = src + immediate.
1014      *
1015      * @param size register size. Has to be 32 or 64.
1016      * @param dst general purpose register. May not be null or zero-register.
1017      * @param src general purpose register. May not be null or zero-register.
1018      * @param immediate 32-bit signed int
1019      */
1020     @Override
1021     public void add(int size, Register dst, Register src, int immediate) {
1022         assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
1023         if (immediate &lt; 0) {
1024             sub(size, dst, src, -immediate);
1025         } else if (isAimm(immediate)) {
1026             if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
1027                 super.add(size, dst, src, immediate);
1028             }
1029         } else if (immediate &gt;= -(1 &lt;&lt; 24) &amp;&amp; immediate &lt; (1 &lt;&lt; 24)) {
1030             super.add(size, dst, src, immediate &amp; -(1 &lt;&lt; 12));
1031             super.add(size, dst, dst, immediate &amp; ((1 &lt;&lt; 12) - 1));
1032         } else {
1033             assert !dst.equals(src);
1034             mov(dst, immediate);
1035             add(size, src, dst, dst);
1036         }
1037     }
1038 
1039     /**
1040      * dst = src + immediate.
1041      *
1042      * @param size register size. Has to be 32 or 64.
1043      * @param dst general purpose register. May not be null or zero-register.
1044      * @param src general purpose register. May not be null or zero-register.
1045      * @param immediate 64-bit signed int
1046      */
1047     public void add(int size, Register dst, Register src, long immediate) {
1048         if (NumUtil.isInt(immediate)) {
1049             add(size, dst, src, (int) immediate);
1050         } else {
1051             assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
1052             assert !dst.equals(src);
1053             assert size == 64;
1054             mov(dst, immediate);
1055             add(size, src, dst, dst);
1056         }
1057     }
1058 
1059     /**
1060      * dst = src + aimm and sets condition flags.
1061      *
1062      * @param size register size. Has to be 32 or 64.
1063      * @param dst general purpose register. May not be null or stackpointer.
1064      * @param src general purpose register. May not be null or zero-register.
1065      * @param immediate arithmetic immediate.
1066      */
1067     @Override
1068     public void adds(int size, Register dst, Register src, int immediate) {
1069         assert (!dst.equals(sp) &amp;&amp; !src.equals(zr));
1070         if (immediate &lt; 0) {
1071             subs(size, dst, src, -immediate);
1072         } else if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
1073             super.adds(size, dst, src, immediate);
1074         }
1075     }
1076 
1077     /**
1078      * dst = src - immediate.
1079      *
1080      * @param size register size. Has to be 32 or 64.
1081      * @param dst general purpose register. May not be null or zero-register.
1082      * @param src general purpose register. May not be null or zero-register.
1083      * @param immediate 32-bit signed int
1084      */
1085     @Override
1086     public void sub(int size, Register dst, Register src, int immediate) {
1087         assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
1088         if (immediate &lt; 0) {
1089             add(size, dst, src, -immediate);
1090         } else if (isAimm(immediate)) {
1091             if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
1092                 super.sub(size, dst, src, immediate);
1093             }
1094         } else if (immediate &gt;= -(1 &lt;&lt; 24) &amp;&amp; immediate &lt; (1 &lt;&lt; 24)) {
1095             super.sub(size, dst, src, immediate &amp; -(1 &lt;&lt; 12));
1096             super.sub(size, dst, dst, immediate &amp; ((1 &lt;&lt; 12) - 1));
1097         } else {
1098             assert !dst.equals(src);
1099             mov(dst, immediate);
1100             sub(size, src, dst, dst);
1101         }
1102     }
1103 
1104     /**
1105      * dst = src - aimm and sets condition flags.
1106      *
1107      * @param size register size. Has to be 32 or 64.
1108      * @param dst general purpose register. May not be null or stackpointer.
1109      * @param src general purpose register. May not be null or zero-register.
1110      * @param immediate arithmetic immediate.
1111      */
1112     @Override
1113     public void subs(int size, Register dst, Register src, int immediate) {
1114         assert (!dst.equals(sp) &amp;&amp; !src.equals(zr));
1115         if (immediate &lt; 0) {
1116             adds(size, dst, src, -immediate);
1117         } else if (!dst.equals(src) || immediate != 0) {
1118             super.subs(size, dst, src, immediate);
1119         }
1120     }
1121 
1122     /**
1123      * dst = src1 * src2.
1124      *
1125      * @param size register size. Has to be 32 or 64.
1126      * @param dst general purpose register. May not be null or the stackpointer.
1127      * @param src1 general purpose register. May not be null or the stackpointer.
1128      * @param src2 general purpose register. May not be null or the stackpointer.
1129      */
1130     public void mul(int size, Register dst, Register src1, Register src2) {
1131         super.madd(size, dst, src1, src2, zr);
1132     }
1133 
1134     /**
1135      * dst = src3 + src1 * src2.
1136      *
1137      * @param size register size. Has to be 32 or 64.
1138      * @param dst general purpose register. May not be null or the stackpointer.
1139      * @param src1 general purpose register. May not be null or the stackpointer.
1140      * @param src2 general purpose register. May not be null or the stackpointer.
1141      * @param src3 general purpose register. May not be null or the stackpointer.
1142      */
1143     @Override
1144     public void madd(int size, Register dst, Register src1, Register src2, Register src3) {
1145         super.madd(size, dst, src1, src2, src3);
1146     }
1147 
1148     /**
1149      * dst = src3 - src1 * src2.
1150      *
1151      * @param size register size. Has to be 32 or 64.
1152      * @param dst general purpose register. May not be null or the stackpointer.
1153      * @param src1 general purpose register. May not be null or the stackpointer.
1154      * @param src2 general purpose register. May not be null or the stackpointer.
1155      * @param src3 general purpose register. May not be null or the stackpointer.
1156      */
1157     @Override
1158     public void msub(int size, Register dst, Register src1, Register src2, Register src3) {
1159         super.msub(size, dst, src1, src2, src3);
1160     }
1161 
1162     /**
1163      * dst = 0 - src1 * src2.
1164      *
1165      * @param size register size. Has to be 32 or 64.
1166      * @param dst general purpose register. May not be null or the stackpointer.
1167      * @param src1 general purpose register. May not be null or the stackpointer.
1168      * @param src2 general purpose register. May not be null or the stackpointer.
1169      */
1170     public void mneg(int size, Register dst, Register src1, Register src2) {
1171         super.msub(size, dst, src1, src2, zr);
1172     }
1173 
1174     /**
1175      * Unsigned multiply high. dst = (src1 * src2) &gt;&gt; size
1176      *
1177      * @param size register size. Has to be 32 or 64.
1178      * @param dst general purpose register. May not be null or the stackpointer.
1179      * @param src1 general purpose register. May not be null or the stackpointer.
1180      * @param src2 general purpose register. May not be null or the stackpointer.
1181      */
1182     public void umulh(int size, Register dst, Register src1, Register src2) {
1183         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp));
1184         assert size == 32 || size == 64;
1185         if (size == 64) {
1186             super.umulh(dst, src1, src2);
1187         } else {
1188             // xDst = wSrc1 * wSrc2
1189             super.umaddl(dst, src1, src2, zr);
1190             // xDst = xDst &gt;&gt; 32
1191             lshr(64, dst, dst, 32);
1192         }
1193     }
1194 
1195     /**
1196      * Signed multiply high. dst = (src1 * src2) &gt;&gt; size
1197      *
1198      * @param size register size. Has to be 32 or 64.
1199      * @param dst general purpose register. May not be null or the stackpointer.
1200      * @param src1 general purpose register. May not be null or the stackpointer.
1201      * @param src2 general purpose register. May not be null or the stackpointer.
1202      */
1203     public void smulh(int size, Register dst, Register src1, Register src2) {
1204         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp));
1205         assert size == 32 || size == 64;
1206         if (size == 64) {
1207             super.smulh(dst, src1, src2);
1208         } else {
1209             // xDst = wSrc1 * wSrc2
1210             super.smaddl(dst, src1, src2, zr);
1211             // xDst = xDst &gt;&gt; 32
1212             lshr(64, dst, dst, 32);
1213         }
1214     }
1215 
1216     /**
1217      * Signed multiply long. xDst = wSrc1 * wSrc2
1218      *
1219      * @param size destination register size. Has to be 64.
1220      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1221      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1222      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1223      */
1224     public void smull(int size, Register dst, Register src1, Register src2) {
1225         this.smaddl(size, dst, src1, src2, zr);
1226     }
1227 
1228     /**
1229      * Signed multiply-negate long. xDst = -(wSrc1 * wSrc2)
1230      *
1231      * @param size destination register size. Has to be 64.
1232      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1233      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1234      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1235      */
1236     public void smnegl(int size, Register dst, Register src1, Register src2) {
1237         this.smsubl(size, dst, src1, src2, zr);
1238     }
1239 
1240     /**
1241      * Signed multiply-add long. xDst = xSrc3 + (wSrc1 * wSrc2)
1242      *
1243      * @param size destination register size. Has to be 64.
1244      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1245      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1246      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1247      * @param src3 64-bit general purpose register. May not be null or the stackpointer.
1248      */
1249     public void smaddl(int size, Register dst, Register src1, Register src2, Register src3) {
1250         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp) &amp;&amp; !src3.equals(sp));
1251         assert size == 64;
1252         super.smaddl(dst, src1, src2, src3);
1253     }
1254 
1255     /**
1256      * Signed multiply-sub long. xDst = xSrc3 - (wSrc1 * wSrc2)
1257      *
1258      * @param size destination register size. Has to be 64.
1259      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1260      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1261      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1262      * @param src3 64-bit general purpose register. May not be null or the stackpointer.
1263      */
1264     public void smsubl(int size, Register dst, Register src1, Register src2, Register src3) {
1265         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp) &amp;&amp; !src3.equals(sp));
1266         assert size == 64;
1267         super.smsubl(dst, src1, src2, src3);
1268     }
1269 
1270     /**
1271      * dst = src1 % src2. Signed.
1272      *
1273      * @param size register size. Has to be 32 or 64.
1274      * @param dst general purpose register. May not be null or the stackpointer.
1275      * @param n numerator. General purpose register. May not be null or the stackpointer.
1276      * @param d denominator. General purpose register. Divisor May not be null or the stackpointer.
1277      */
1278     public void rem(int size, Register dst, Register n, Register d) {
1279         assert (!dst.equals(sp) &amp;&amp; !n.equals(sp) &amp;&amp; !d.equals(sp));
1280         // There is no irem or similar instruction. Instead we use the relation:
1281         // n % d = n - Floor(n / d) * d if nd &gt;= 0
1282         // n % d = n - Ceil(n / d) * d else
1283         // Which is equivalent to n - TruncatingDivision(n, d) * d
1284         super.sdiv(size, dst, n, d);
1285         super.msub(size, dst, dst, d, n);
1286     }
1287 
1288     /**
1289      * dst = src1 % src2. Unsigned.
1290      *
1291      * @param size register size. Has to be 32 or 64.
1292      * @param dst general purpose register. May not be null or the stackpointer.
1293      * @param n numerator. General purpose register. May not be null or the stackpointer.
1294      * @param d denominator. General purpose register. Divisor May not be null or the stackpointer.
1295      */
1296     public void urem(int size, Register dst, Register n, Register d) {
1297         // There is no irem or similar instruction. Instead we use the relation:
1298         // n % d = n - Floor(n / d) * d
1299         // Which is equivalent to n - TruncatingDivision(n, d) * d
1300         super.udiv(size, dst, n, d);
1301         super.msub(size, dst, dst, d, n);
1302     }
1303 
1304     /**
1305      * Add/subtract instruction encoding supports 12-bit immediate values.
1306      *
1307      * @param imm immediate value to be tested.
1308      * @return true if immediate can be used directly for arithmetic instructions (add/sub), false
1309      *         otherwise.
1310      */
1311     public static boolean isArithmeticImmediate(long imm) {
1312         // If we have a negative immediate we just use the opposite operator. I.e.: x - (-5) == x +
1313         // 5.
1314         return NumUtil.isInt(Math.abs(imm)) &amp;&amp; isAimm((int) Math.abs(imm));
1315     }
1316 
1317     /**
1318      * Compare instructions are add/subtract instructions and so support 12-bit immediate values.
1319      *
1320      * @param imm immediate value to be tested.
1321      * @return true if immediate can be used directly with comparison instructions, false otherwise.
1322      */
1323     public static boolean isComparisonImmediate(long imm) {
1324         return isArithmeticImmediate(imm);
1325     }
1326 
1327     /**
1328      * Move wide immediate instruction encoding supports 16-bit immediate values which can be
1329      * optionally-shifted by multiples of 16 (i.e. 0, 16, 32, 48).
1330      *
1331      * @return true if immediate can be moved directly into a register, false otherwise.
1332      */
1333     public static boolean isMovableImmediate(long imm) {
1334         // // Positions of first, respectively last set bit.
1335         // int start = Long.numberOfTrailingZeros(imm);
1336         // int end = 64 - Long.numberOfLeadingZeros(imm);
1337         // int length = end - start;
1338         // if (length &gt; 16) {
1339         // return false;
1340         // }
1341         // // We can shift the necessary part of the immediate (i.e. everything between the first
1342         // and
1343         // // last set bit) by as much as 16 - length around to arrive at a valid shift amount
1344         // int tolerance = 16 - length;
1345         // int prevMultiple = NumUtil.roundDown(start, 16);
1346         // int nextMultiple = NumUtil.roundUp(start, 16);
1347         // return start - prevMultiple &lt;= tolerance || nextMultiple - start &lt;= tolerance;
1348         /*
1349          * This is a bit optimistic because the constant could also be for an arithmetic instruction
1350          * which only supports 12-bits. That case needs to be handled in the backend.
1351          */
1352         return NumUtil.isInt(Math.abs(imm)) &amp;&amp; NumUtil.isUnsignedNbit(16, (int) Math.abs(imm));
1353     }
1354 
1355     /**
1356      * dst = src &lt;&lt; (shiftAmt &amp; (size - 1)).
1357      *
1358      * @param size register size. Has to be 32 or 64.
1359      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1360      * @param src general purpose register. May not be null, stackpointer or zero-register.
1361      * @param shiftAmt amount by which src is shifted.
1362      */
1363     public void shl(int size, Register dst, Register src, long shiftAmt) {
1364         int shift = clampShiftAmt(size, shiftAmt);
1365         super.ubfm(size, dst, src, (size - shift) &amp; (size - 1), size - 1 - shift);
1366     }
1367 
1368     /**
1369      * dst = src1 &lt;&lt; (src2 &amp; (size - 1)).
1370      *
1371      * @param size register size. Has to be 32 or 64.
1372      * @param dst general purpose register. May not be null or stackpointer.
1373      * @param src general purpose register. May not be null or stackpointer.
1374      * @param shift general purpose register. May not be null or stackpointer.
1375      */
1376     public void shl(int size, Register dst, Register src, Register shift) {
1377         super.lsl(size, dst, src, shift);
1378     }
1379 
1380     /**
1381      * dst = src &gt;&gt;&gt; (shiftAmt &amp; (size - 1)).
1382      *
1383      * @param size register size. Has to be 32 or 64.
1384      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1385      * @param src general purpose register. May not be null, stackpointer or zero-register.
1386      * @param shiftAmt amount by which src is shifted.
1387      */
1388     public void lshr(int size, Register dst, Register src, long shiftAmt) {
1389         int shift = clampShiftAmt(size, shiftAmt);
1390         super.ubfm(size, dst, src, shift, size - 1);
1391     }
1392 
1393     /**
1394      * dst = src1 &gt;&gt;&gt; (src2 &amp; (size - 1)).
1395      *
1396      * @param size register size. Has to be 32 or 64.
1397      * @param dst general purpose register. May not be null or stackpointer.
1398      * @param src general purpose register. May not be null or stackpointer.
1399      * @param shift general purpose register. May not be null or stackpointer.
1400      */
1401     public void lshr(int size, Register dst, Register src, Register shift) {
1402         super.lsr(size, dst, src, shift);
1403     }
1404 
1405     /**
1406      * dst = src &gt;&gt; (shiftAmt &amp; log2(size)).
1407      *
1408      * @param size register size. Has to be 32 or 64.
1409      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1410      * @param src general purpose register. May not be null, stackpointer or zero-register.
1411      * @param shiftAmt amount by which src is shifted.
1412      */
1413     public void ashr(int size, Register dst, Register src, long shiftAmt) {
1414         int shift = clampShiftAmt(size, shiftAmt);
1415         super.sbfm(size, dst, src, shift, size - 1);
1416     }
1417 
1418     /**
1419      * dst = src1 &gt;&gt; (src2 &amp; log2(size)).
1420      *
1421      * @param size register size. Has to be 32 or 64.
1422      * @param dst general purpose register. May not be null or stackpointer.
1423      * @param src general purpose register. May not be null or stackpointer.
1424      * @param shift general purpose register. May not be null or stackpointer.
1425      */
1426     public void ashr(int size, Register dst, Register src, Register shift) {
1427         super.asr(size, dst, src, shift);
1428     }
1429 
1430     /**
1431      * Rotate right (register). dst = rotateRight(src1, (src2 &amp; (size - 1))).
1432      *
1433      * @param size register size. Has to be 32 or 64.
1434      * @param dst general purpose register. May not be null or stackpointer.
1435      * @param src1 general purpose register. May not be null or stackpointer.
1436      * @param src2 general purpose register. It holds a shift amount from 0 to (size - 1) in its
1437      *            bottom 5 bits. May not be null or stackpointer.
1438      */
1439     @Override
1440     public void rorv(int size, Register dst, Register src1, Register src2) {
1441         super.rorv(size, dst, src1, src2);
1442     }
1443 
1444     /**
1445      * Rotate right (immediate). dst = rotateRight(src1, shift).
1446      *
1447      * @param size register size. Has to be 32 or 64.
1448      * @param dst general purpose register. May not be null or stackpointer.
1449      * @param src general purpose register. May not be null or stackpointer.
1450      * @param shift amount by which src is rotated. The value depends on the instruction variant, it
1451      *            can be 0 to (size - 1).
1452      */
1453     public void ror(int size, Register dst, Register src, int shift) {
1454         assert (0 &lt;= shift &amp;&amp; shift &lt;= (size - 1));
1455         super.extr(size, dst, src, src, shift);
1456     }
1457 
1458     /**
1459      * Clamps shiftAmt into range 0 &lt;= shiftamt &lt; size according to JLS.
1460      *
1461      * @param size size of operation.
1462      * @param shiftAmt arbitrary shift amount.
1463      * @return value between 0 and size - 1 inclusive that is equivalent to shiftAmt according to
1464      *         JLS.
1465      */
1466     private static int clampShiftAmt(int size, long shiftAmt) {
1467         return (int) (shiftAmt &amp; (size - 1));
1468     }
1469 
1470     /**
1471      * dst = src1 &amp; src2.
1472      *
1473      * @param size register size. Has to be 32 or 64.
1474      * @param dst general purpose register. May not be null or stackpointer.
1475      * @param src1 general purpose register. May not be null or stackpointer.
1476      * @param src2 general purpose register. May not be null or stackpointer.
1477      */
1478     public void and(int size, Register dst, Register src1, Register src2) {
1479         super.and(size, dst, src1, src2, ShiftType.LSL, 0);
1480     }
1481 
1482     /**
1483      * dst = src1 ^ src2.
1484      *
1485      * @param size register size. Has to be 32 or 64.
1486      * @param dst general purpose register. May not be null or stackpointer.
1487      * @param src1 general purpose register. May not be null or stackpointer.
1488      * @param src2 general purpose register. May not be null or stackpointer.
1489      */
1490     public void eor(int size, Register dst, Register src1, Register src2) {
1491         super.eor(size, dst, src1, src2, ShiftType.LSL, 0);
1492     }
1493 
1494     /**
1495      * dst = src1 | src2.
1496      *
1497      * @param size register size. Has to be 32 or 64.
1498      * @param dst general purpose register. May not be null or stackpointer.
1499      * @param src1 general purpose register. May not be null or stackpointer.
1500      * @param src2 general purpose register. May not be null or stackpointer.
1501      */
1502     public void or(int size, Register dst, Register src1, Register src2) {
1503         super.orr(size, dst, src1, src2, ShiftType.LSL, 0);
1504     }
1505 
1506     /**
1507      * dst = src | bimm.
1508      *
1509      * @param size register size. Has to be 32 or 64.
1510      * @param dst general purpose register. May not be null or zero-register.
1511      * @param src general purpose register. May not be null or stack-pointer.
1512      * @param bimm logical immediate. See {@link AArch64Assembler.LogicalImmediateTable} for exact
1513      *            definition.
1514      */
1515     public void or(int size, Register dst, Register src, long bimm) {
1516         super.orr(size, dst, src, bimm);
1517     }
1518 
1519     /**
1520      * dst = src1 &amp; (~src2).
1521      *
1522      * @param size register size. Has to be 32 or 64.
1523      * @param dst general purpose register. May not be null or stackpointer.
1524      * @param src1 general purpose register. May not be null or stackpointer.
1525      * @param src2 general purpose register. May not be null or stackpointer.
1526      */
1527     public void bic(int size, Register dst, Register src1, Register src2) {
1528         super.bic(size, dst, src1, src2, ShiftType.LSL, 0);
1529     }
1530 
1531     /**
1532      * dst = src1 ^ (~src2).
1533      *
1534      * @param size register size. Has to be 32 or 64.
1535      * @param dst general purpose register. May not be null or stackpointer.
1536      * @param src1 general purpose register. May not be null or stackpointer.
1537      * @param src2 general purpose register. May not be null or stackpointer.
1538      */
1539     public void eon(int size, Register dst, Register src1, Register src2) {
1540         super.eon(size, dst, src1, src2, ShiftType.LSL, 0);
1541     }
1542 
1543     /**
1544      * dst = src1 | (~src2).
1545      *
1546      * @param size register size. Has to be 32 or 64.
1547      * @param dst general purpose register. May not be null or stackpointer.
1548      * @param src1 general purpose register. May not be null or stackpointer.
1549      * @param src2 general purpose register. May not be null or stackpointer.
1550      */
1551     public void orn(int size, Register dst, Register src1, Register src2) {
1552         super.orn(size, dst, src1, src2, ShiftType.LSL, 0);
1553     }
1554 
1555     /**
1556      * dst = ~src.
1557      *
1558      * @param size register size. Has to be 32 or 64.
1559      * @param dst general purpose register. May not be null or stackpointer.
1560      * @param src general purpose register. May not be null or stackpointer.
1561      */
1562     public void not(int size, Register dst, Register src) {
1563         super.orn(size, dst, zr, src, ShiftType.LSL, 0);
1564     }
1565 
1566     /**
1567      * dst = src1 &amp; shiftType(src2, imm).
1568      *
1569      * @param size register size. Has to be 32 or 64.
1570      * @param dst general purpose register. May not be null or stackpointer.
1571      * @param src1 general purpose register. May not be null or stackpointer.
1572      * @param src2 general purpose register. May not be null or stackpointer.
1573      * @param shiftType all types allowed, may not be null.
1574      * @param shiftAmt must be in range 0 to size - 1.
1575      */
1576     @Override
1577     public void and(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1578         super.and(size, dst, src1, src2, shiftType, shiftAmt);
1579     }
1580 
1581     /**
1582      * dst = src1 ^ shiftType(src2, imm).
1583      *
1584      * @param size register size. Has to be 32 or 64.
1585      * @param dst general purpose register. May not be null or stackpointer.
1586      * @param src1 general purpose register. May not be null or stackpointer.
1587      * @param src2 general purpose register. May not be null or stackpointer.
1588      * @param shiftType all types allowed, may not be null.
1589      * @param shiftAmt must be in range 0 to size - 1.
1590      */
1591     @Override
1592     public void eor(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1593         super.eor(size, dst, src1, src2, shiftType, shiftAmt);
1594     }
1595 
1596     /**
1597      * dst = src1 | shiftType(src2, imm).
1598      *
1599      * @param size register size. Has to be 32 or 64.
1600      * @param dst general purpose register. May not be null or stackpointer.
1601      * @param src1 general purpose register. May not be null or stackpointer.
1602      * @param src2 general purpose register. May not be null or stackpointer.
1603      * @param shiftType all types allowed, may not be null.
1604      * @param shiftAmt must be in range 0 to size - 1.
1605      */
1606     public void or(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1607         super.orr(size, dst, src1, src2, shiftType, shiftAmt);
1608     }
1609 
1610     /**
1611      * dst = src1 &amp; ~(shiftType(src2, imm)).
1612      *
1613      * @param size register size. Has to be 32 or 64.
1614      * @param dst general purpose register. May not be null or stackpointer.
1615      * @param src1 general purpose register. May not be null or stackpointer.
1616      * @param src2 general purpose register. May not be null or stackpointer.
1617      * @param shiftType all types allowed, may not be null.
1618      * @param shiftAmt must be in range 0 to size - 1.
1619      */
1620     @Override
1621     public void bic(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1622         super.bic(size, dst, src1, src2, shiftType, shiftAmt);
1623     }
1624 
1625     /**
1626      * dst = src1 ^ ~(shiftType(src2, imm)).
1627      *
1628      * @param size register size. Has to be 32 or 64.
1629      * @param dst general purpose register. May not be null or stackpointer.
1630      * @param src1 general purpose register. May not be null or stackpointer.
1631      * @param src2 general purpose register. May not be null or stackpointer.
1632      * @param shiftType all types allowed, may not be null.
1633      * @param shiftAmt must be in range 0 to size - 1.
1634      */
1635     @Override
1636     public void eon(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1637         super.eon(size, dst, src1, src2, shiftType, shiftAmt);
1638     }
1639 
1640     /**
1641      * dst = src1 | ~(shiftType(src2, imm)).
1642      *
1643      * @param size register size. Has to be 32 or 64.
1644      * @param dst general purpose register. May not be null or stackpointer.
1645      * @param src1 general purpose register. May not be null or stackpointer.
1646      * @param src2 general purpose register. May not be null or stackpointer.
1647      * @param shiftType all types allowed, may not be null.
1648      * @param shiftAmt must be in range 0 to size - 1.
1649      */
1650     @Override
1651     public void orn(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1652         super.orn(size, dst, src1, src2, shiftType, shiftAmt);
1653     }
1654 
1655     /**
1656      * Sign-extend value from src into dst.
1657      *
1658      * @param destSize destination register size. Must be 32 or 64.
1659      * @param srcSize source register size. Must be smaller than destSize.
1660      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1661      * @param src general purpose register. May not be null, stackpointer or zero-register.
1662      */
1663     public void sxt(int destSize, int srcSize, Register dst, Register src) {
1664         assert (srcSize &lt; destSize &amp;&amp; srcSize &gt; 0);
1665         super.sbfm(destSize, dst, src, 0, srcSize - 1);
1666     }
1667 
1668     /**
1669      * dst = src if condition else -src.
1670      *
1671      * @param size register size. Must be 32 or 64.
1672      * @param dst general purpose register. May not be null or the stackpointer.
1673      * @param src general purpose register. May not be null or the stackpointer.
1674      * @param condition any condition except AV or NV. May not be null.
1675      */
1676     public void csneg(int size, Register dst, Register src, ConditionFlag condition) {
1677         super.csneg(size, dst, src, src, condition.negate());
1678     }
1679 
1680     /**
1681      * @return True if the immediate can be used directly for logical 64-bit instructions.
1682      */
1683     public static boolean isLogicalImmediate(long imm) {
1684         return LogicalImmediateTable.isRepresentable(true, imm) != LogicalImmediateTable.Representable.NO;
1685     }
1686 
1687     /**
1688      * @return True if the immediate can be used directly for logical 32-bit instructions.
1689      */
1690     public static boolean isLogicalImmediate(int imm) {
1691         return LogicalImmediateTable.isRepresentable(imm) == LogicalImmediateTable.Representable.YES;
1692     }
1693 
1694     /* Float instructions */
1695 
1696     /**
1697      * Moves integer to float, float to integer, or float to float. Does not support integer to
1698      * integer moves.
1699      *
1700      * @param size register size. Has to be 32 or 64.
1701      * @param dst Either floating-point or general-purpose register. If general-purpose register may
1702      *            not be stackpointer or zero register. Cannot be null in any case.
1703      * @param src Either floating-point or general-purpose register. If general-purpose register may
1704      *            not be stackpointer. Cannot be null in any case.
1705      */
1706     @Override
1707     public void fmov(int size, Register dst, Register src) {
1708         assert !(dst.getRegisterCategory().equals(CPU) &amp;&amp; src.getRegisterCategory().equals(CPU)) : &quot;src and dst cannot both be integer registers.&quot;;
1709         if (dst.getRegisterCategory().equals(CPU)) {
1710             super.fmovFpu2Cpu(size, dst, src);
1711         } else if (src.getRegisterCategory().equals(CPU)) {
1712             super.fmovCpu2Fpu(size, dst, src);
1713         } else {
1714             super.fmov(size, dst, src);
1715         }
1716     }
1717 
1718     /**
1719      *
1720      * @param size register size. Has to be 32 or 64.
1721      * @param dst floating point register. May not be null.
1722      * @param imm immediate that is loaded into dst. If size is 32 only float immediates can be
1723      *            loaded, i.e. (float) imm == imm must be true. In all cases
1724      *            {@code isFloatImmediate}, respectively {@code #isDoubleImmediate} must be true
1725      *            depending on size.
1726      */
1727     @Override
1728     public void fmov(int size, Register dst, double imm) {
1729         if (imm == 0.0) {
1730             assert Double.doubleToRawLongBits(imm) == 0L : &quot;-0.0 is no valid immediate.&quot;;
1731             super.fmovCpu2Fpu(size, dst, zr);
1732         } else {
1733             super.fmov(size, dst, imm);
1734         }
1735     }
1736 
1737     /**
1738      *
1739      * @return true if immediate can be loaded directly into floating-point register, false
1740      *         otherwise.
1741      */
1742     public static boolean isDoubleImmediate(double imm) {
1743         return Double.doubleToRawLongBits(imm) == 0L || AArch64Assembler.isDoubleImmediate(imm);
1744     }
1745 
1746     /**
1747      *
1748      * @return true if immediate can be loaded directly into floating-point register, false
1749      *         otherwise.
1750      */
1751     public static boolean isFloatImmediate(float imm) {
1752         return Float.floatToRawIntBits(imm) == 0 || AArch64Assembler.isFloatImmediate(imm);
1753     }
1754 
1755     /**
1756      * Conditional move. dst = src1 if condition else src2.
1757      *
1758      * @param size register size.
1759      * @param result floating point register. May not be null.
1760      * @param trueValue floating point register. May not be null.
1761      * @param falseValue floating point register. May not be null.
1762      * @param condition every condition allowed. May not be null.
1763      */
1764     public void fcmov(int size, Register result, Register trueValue, Register falseValue, ConditionFlag condition) {
1765         super.fcsel(size, result, trueValue, falseValue, condition);
1766     }
1767 
1768     /**
1769      * dst = src1 % src2.
1770      *
1771      * @param size register size. Has to be 32 or 64.
1772      * @param dst floating-point register. May not be null.
1773      * @param n numerator. Floating-point register. May not be null.
1774      * @param d denominator. Floating-point register. May not be null.
1775      */
1776     public void frem(int size, Register dst, Register n, Register d) {
1777         // There is no frem instruction, instead we compute the remainder using the relation:
1778         // rem = n - Truncating(n / d) * d
1779         super.fdiv(size, dst, n, d);
1780         super.frintz(size, dst, dst);
1781         super.fmsub(size, dst, dst, d, n);
1782     }
1783 
1784     /**
1785      * dst = src1 * src2 + src3.
1786      *
1787      * @param size register size.
1788      * @param dst floating point register. May not be null.
1789      * @param src1 floating point register. May not be null.
1790      * @param src2 floating point register. May not be null.
1791      * @param src3 floating point register. May not be null.
1792      */
1793     @Override
1794     public void fmadd(int size, Register dst, Register src1, Register src2, Register src3) {
1795         super.fmadd(size, dst, src1, src2, src3);
1796     }
1797 
1798     /* Branches */
1799 
1800     /**
1801      * Compares x and y and sets condition flags.
1802      *
1803      * @param size register size. Has to be 32 or 64.
1804      * @param x general purpose register. May not be null or stackpointer.
1805      * @param y general purpose register. May not be null or stackpointer.
1806      */
1807     public void cmp(int size, Register x, Register y) {
1808         assert size == 32 || size == 64;
1809         super.subs(size, zr, x, y, ShiftType.LSL, 0);
1810     }
1811 
1812     /**
1813      * Compares x to y and sets condition flags.
1814      *
1815      * @param size register size. Has to be 32 or 64.
1816      * @param x general purpose register. May not be null or stackpointer.
1817      * @param y comparison immediate, {@link #isComparisonImmediate(long)} has to be true for it.
1818      */
1819     public void cmp(int size, Register x, int y) {
1820         assert size == 32 || size == 64;
1821         if (y &lt; 0) {
1822             super.adds(size, zr, x, -y);
1823         } else {
1824             super.subs(size, zr, x, y);
1825         }
1826     }
1827 
1828     /**
1829      * Sets condition flags according to result of x &amp; y.
1830      *
1831      * @param size register size. Has to be 32 or 64.
1832      * @param dst general purpose register. May not be null or stack-pointer.
1833      * @param x general purpose register. May not be null or stackpointer.
1834      * @param y general purpose register. May not be null or stackpointer.
1835      */
1836     public void ands(int size, Register dst, Register x, Register y) {
1837         super.ands(size, dst, x, y, ShiftType.LSL, 0);
1838     }
1839 
1840     /**
1841      * Sets overflow flag according to result of x * y.
1842      *
1843      * @param size register size. Has to be 32 or 64.
1844      * @param dst general purpose register. May not be null or stack-pointer.
1845      * @param x general purpose register. May not be null or stackpointer.
1846      * @param y general purpose register. May not be null or stackpointer.
1847      */
1848     public void mulvs(int size, Register dst, Register x, Register y) {
1849         try (ScratchRegister sc1 = getScratchRegister();
1850                         ScratchRegister sc2 = getScratchRegister()) {
1851             switch (size) {
1852                 case 64: {
1853                     // Be careful with registers: it&#39;s possible that x, y, and dst are the same
1854                     // register.
1855                     Register temp1 = sc1.getRegister();
1856                     Register temp2 = sc2.getRegister();
1857                     mul(64, temp1, x, y);     // Result bits 0..63
1858                     smulh(64, temp2, x, y);  // Result bits 64..127
1859                     // Top is pure sign ext
1860                     subs(64, zr, temp2, temp1, ShiftType.ASR, 63);
1861                     // Copy all 64 bits of the result into dst
1862                     mov(64, dst, temp1);
1863                     mov(temp1, 0x80000000);
1864                     // Develop 0 (EQ), or 0x80000000 (NE)
1865                     cmov(32, temp1, temp1, zr, ConditionFlag.NE);
1866                     cmp(32, temp1, 1);
1867                     // 0x80000000 - 1 =&gt; VS
1868                     break;
1869                 }
1870                 case 32: {
1871                     Register temp1 = sc1.getRegister();
1872                     smaddl(temp1, x, y, zr);
1873                     // Copy the low 32 bits of the result into dst
1874                     mov(32, dst, temp1);
1875                     subs(64, zr, temp1, temp1, ExtendType.SXTW, 0);
1876                     // NE =&gt; overflow
1877                     mov(temp1, 0x80000000);
1878                     // Develop 0 (EQ), or 0x80000000 (NE)
1879                     cmov(32, temp1, temp1, zr, ConditionFlag.NE);
1880                     cmp(32, temp1, 1);
1881                     // 0x80000000 - 1 =&gt; VS
1882                     break;
1883                 }
1884             }
1885         }
1886     }
1887 
1888     /**
1889      * When patching up Labels we have to know what kind of code to generate.
1890      */
1891     public enum PatchLabelKind {
1892         BRANCH_CONDITIONALLY(0x0),
1893         BRANCH_UNCONDITIONALLY(0x1),
1894         BRANCH_NONZERO(0x2),
1895         BRANCH_ZERO(0x3),
1896         BRANCH_BIT_NONZERO(0x4),
1897         BRANCH_BIT_ZERO(0x5),
1898         JUMP_ADDRESS(0x6),
1899         ADR(0x7);
1900 
1901         /**
1902          * Offset by which additional information for branch conditionally, branch zero and branch
1903          * non zero has to be shifted.
1904          */
1905         public static final int INFORMATION_OFFSET = 5;
1906 
1907         public final int encoding;
1908 
1909         PatchLabelKind(int encoding) {
1910             this.encoding = encoding;
1911         }
1912 
1913         /**
1914          * @return PatchLabelKind with given encoding.
1915          */
1916         private static PatchLabelKind fromEncoding(int encoding) {
1917             return values()[encoding &amp; NumUtil.getNbitNumberInt(INFORMATION_OFFSET)];
1918         }
1919 
1920     }
1921 
1922     public void adr(Register dst, Label label) {
1923         // TODO Handle case where offset is too large for a single jump instruction
1924         if (label.isBound()) {
1925             int offset = label.position() - position();
1926             super.adr(dst, offset);
1927         } else {
1928             label.addPatchAt(position(), this);
1929             // Encode condition flag so that we know how to patch the instruction later
1930             emitInt(PatchLabelKind.ADR.encoding | dst.encoding &lt;&lt; PatchLabelKind.INFORMATION_OFFSET);
1931         }
1932     }
1933 
1934     /**
1935      * Compare register and branch if non-zero.
1936      *
1937      * @param size Instruction size in bits. Should be either 32 or 64.
1938      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1939      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
1940      */
1941     public void cbnz(int size, Register cmp, Label label) {
1942         // TODO Handle case where offset is too large for a single jump instruction
1943         if (label.isBound()) {
1944             int offset = label.position() - position();
1945             super.cbnz(size, cmp, offset);
1946         } else {
1947             label.addPatchAt(position(), this);
1948             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 1);
1949             int sizeEncoding = (size == 64 ? 1 : 0) &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1950             // Encode condition flag so that we know how to patch the instruction later
1951             emitInt(PatchLabelKind.BRANCH_NONZERO.encoding | regEncoding | sizeEncoding);
1952         }
1953     }
1954 
1955     /**
1956      * Compare register and branch if zero.
1957      *
1958      * @param size Instruction size in bits. Should be either 32 or 64.
1959      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1960      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
1961      */
1962     public void cbz(int size, Register cmp, Label label) {
1963         // TODO Handle case where offset is too large for a single jump instruction
1964         if (label.isBound()) {
1965             int offset = label.position() - position();
1966             super.cbz(size, cmp, offset);
1967         } else {
1968             label.addPatchAt(position(), this);
1969             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 1);
1970             int sizeEncoding = (size == 64 ? 1 : 0) &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1971             // Encode condition flag so that we know how to patch the instruction later
1972             emitInt(PatchLabelKind.BRANCH_ZERO.encoding | regEncoding | sizeEncoding);
1973         }
1974     }
1975 
1976     /**
1977      * Test a single bit and branch if the bit is nonzero.
1978      *
1979      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1980      * @param uimm6 Unsigned 6-bit bit index.
1981      * @param label Can only handle 16-bit word-aligned offsets for now. May be unbound. Non null.
1982      */
1983     public void tbnz(Register cmp, int uimm6, Label label) {
1984         assert NumUtil.isUnsignedNbit(6, uimm6);
1985         if (label.isBound()) {
1986             int offset = label.position() - position();
1987             super.tbnz(cmp, uimm6, offset);
1988         } else {
1989             label.addPatchAt(position(), this);
1990             int indexEncoding = uimm6 &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1991             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 6);
1992             emitInt(PatchLabelKind.BRANCH_BIT_NONZERO.encoding | indexEncoding | regEncoding);
1993         }
1994     }
1995 
1996     /**
1997      * Test a single bit and branch if the bit is zero.
1998      *
1999      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
2000      * @param uimm6 Unsigned 6-bit bit index.
2001      * @param label Can only handle 16-bit word-aligned offsets for now. May be unbound. Non null.
2002      */
2003     public void tbz(Register cmp, int uimm6, Label label) {
2004         assert NumUtil.isUnsignedNbit(6, uimm6);
2005         if (label.isBound()) {
2006             int offset = label.position() - position();
2007             super.tbz(cmp, uimm6, offset);
2008         } else {
2009             label.addPatchAt(position(), this);
2010             int indexEncoding = uimm6 &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
2011             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 6);
2012             emitInt(PatchLabelKind.BRANCH_BIT_ZERO.encoding | indexEncoding | regEncoding);
2013         }
2014     }
2015 
2016     /**
2017      * Branches to label if condition is true.
2018      *
2019      * @param condition any condition value allowed. Non null.
2020      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
2021      */
2022     public void branchConditionally(ConditionFlag condition, Label label) {
2023         // TODO Handle case where offset is too large for a single jump instruction
2024         if (label.isBound()) {
2025             int offset = label.position() - position();
2026             super.b(condition, offset);
2027         } else {
2028             label.addPatchAt(position(), this);
2029             // Encode condition flag so that we know how to patch the instruction later
2030             emitInt(PatchLabelKind.BRANCH_CONDITIONALLY.encoding | condition.encoding &lt;&lt; PatchLabelKind.INFORMATION_OFFSET);
2031         }
2032     }
2033 
2034     /**
2035      * Branches if condition is true. Address of jump is patched up by HotSpot c++ code.
2036      *
2037      * @param condition any condition value allowed. Non null.
2038      */
2039     public void branchConditionally(ConditionFlag condition) {
2040         // Correct offset is fixed up by HotSpot later.
2041         super.b(condition, 0);
2042     }
2043 
2044     /**
2045      * Jumps to label.
2046      *
2047      * param label Can only handle signed 28-bit offsets. May be unbound. Non null.
2048      */
2049     @Override
2050     public void jmp(Label label) {
2051         // TODO Handle case where offset is too large for a single jump instruction
2052         if (label.isBound()) {
2053             int offset = label.position() - position();
2054             super.b(offset);
2055         } else {
2056             label.addPatchAt(position(), this);
2057             emitInt(PatchLabelKind.BRANCH_UNCONDITIONALLY.encoding);
2058         }
2059     }
2060 
2061     /**
2062      * Jump to address in dest.
2063      *
2064      * @param dest General purpose register. May not be null, zero-register or stackpointer.
2065      */
2066     public void jmp(Register dest) {
2067         super.br(dest);
2068     }
2069 
2070     /**
2071      * Immediate jump instruction fixed up by HotSpot c++ code.
2072      */
2073     public void jmp() {
2074         // Offset has to be fixed up by c++ code.
2075         super.b(0);
2076     }
2077 
2078     /**
2079      *
2080      * @return true if immediate offset can be used in a single branch instruction.
2081      */
2082     public static boolean isBranchImmediateOffset(long imm) {
2083         return NumUtil.isSignedNbit(28, imm);
2084     }
2085 
2086     /* system instructions */
2087 
2088     /**
2089      * Exception codes used when calling hlt instruction.
2090      */
2091     public enum AArch64ExceptionCode {
2092         NO_SWITCH_TARGET(0x0),
2093         BREAKPOINT(0x1);
2094 
2095         public final int encoding;
2096 
2097         AArch64ExceptionCode(int encoding) {
2098             this.encoding = encoding;
2099         }
2100     }
2101 
2102     /**
2103      * Halting mode software breakpoint: Enters halting mode debug state if enabled, else treated as
2104      * UNALLOCATED instruction.
2105      *
2106      * @param exceptionCode exception code specifying why halt was called. Non null.
2107      */
2108     public void hlt(AArch64ExceptionCode exceptionCode) {
2109         super.hlt(exceptionCode.encoding);
2110     }
2111 
2112     /**
2113      * Monitor mode software breakpoint: exception routed to a debug monitor executing in a higher
2114      * exception level.
2115      *
2116      * @param exceptionCode exception code specifying why break was called. Non null.
2117      */
2118     public void brk(AArch64ExceptionCode exceptionCode) {
2119         super.brk(exceptionCode.encoding);
2120     }
2121 
2122     public void pause() {
2123         super.hint(SystemHint.YIELD);
2124     }
2125 
2126     /**
2127      * Executes no-op instruction. No registers or flags are updated, except for PC.
2128      */
2129     public void nop() {
2130         super.hint(SystemHint.NOP);
2131     }
2132 
2133     /**
2134      * Consumption of Speculative Data Barrier. This is a memory barrier that controls speculative
2135      * execution and data value prediction.
2136      */
2137     public void csdb() {
2138         super.hint(SystemHint.CSDB);
2139     }
2140 
2141     /**
2142      * Same as {@link #nop()}.
2143      */
2144     @Override
2145     public void ensureUniquePC() {
2146         nop();
2147     }
2148 
2149     /**
2150      * Aligns PC.
2151      *
2152      * @param modulus Has to be positive multiple of 4.
2153      */
2154     @Override
2155     public void align(int modulus) {
2156         assert modulus &gt; 0 &amp;&amp; (modulus &amp; 0x3) == 0 : &quot;Modulus has to be a positive multiple of 4.&quot;;
2157         if (position() % modulus == 0) {
2158             return;
2159         }
2160         int offset = modulus - position() % modulus;
2161         for (int i = 0; i &lt; offset; i += 4) {
2162             nop();
2163         }
2164     }
2165 
2166     /**
2167      * Patches jump targets when label gets bound.
2168      */
2169     @Override
2170     protected void patchJumpTarget(int branch, int jumpTarget) {
2171         int instruction = getInt(branch);
2172         int branchOffset = jumpTarget - branch;
2173         PatchLabelKind type = PatchLabelKind.fromEncoding(instruction);
2174         switch (type) {
2175             case BRANCH_CONDITIONALLY:
2176                 ConditionFlag cf = ConditionFlag.fromEncoding(instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET);
2177                 super.b(cf, branchOffset, branch);
2178                 break;
2179             case BRANCH_UNCONDITIONALLY:
2180                 super.b(branchOffset, branch);
2181                 break;
2182             case JUMP_ADDRESS:
2183                 int offset = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
2184                 emitInt(jumpTarget - offset, branch);
2185                 break;
2186             case BRANCH_NONZERO:
2187             case BRANCH_ZERO: {
2188                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
2189                 int sizeEncoding = information &amp; 1;
2190                 int regEncoding = information &gt;&gt;&gt; 1;
2191                 Register reg = AArch64.cpuRegisters.get(regEncoding);
2192                 // 1 =&gt; 64; 0 =&gt; 32
2193                 int size = sizeEncoding * 32 + 32;
2194                 if (!NumUtil.isSignedNbit(21, branchOffset)) {
2195                     throw new BranchTargetOutOfBoundsException(true, &quot;Branch target %d out of bounds&quot;, branchOffset);
2196                 }
2197                 switch (type) {
2198                     case BRANCH_NONZERO:
2199                         super.cbnz(size, reg, branchOffset, branch);
2200                         break;
2201                     case BRANCH_ZERO:
2202                         super.cbz(size, reg, branchOffset, branch);
2203                         break;
2204                 }
2205                 break;
2206             }
2207             case BRANCH_BIT_NONZERO:
2208             case BRANCH_BIT_ZERO: {
2209                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
2210                 int sizeEncoding = information &amp; NumUtil.getNbitNumberInt(6);
2211                 int regEncoding = information &gt;&gt;&gt; 6;
2212                 Register reg = AArch64.cpuRegisters.get(regEncoding);
2213                 if (!NumUtil.isSignedNbit(16, branchOffset)) {
2214                     throw new BranchTargetOutOfBoundsException(true, &quot;Branch target %d out of bounds&quot;, branchOffset);
2215                 }
2216                 switch (type) {
2217                     case BRANCH_BIT_NONZERO:
2218                         super.tbnz(reg, sizeEncoding, branchOffset, branch);
2219                         break;
2220                     case BRANCH_BIT_ZERO:
2221                         super.tbz(reg, sizeEncoding, branchOffset, branch);
2222                         break;
2223                 }
2224                 break;
2225             }
2226             case ADR: {
2227                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
2228                 int regEncoding = information;
2229                 Register reg = AArch64.cpuRegisters.get(regEncoding);
2230                 super.adr(reg, branchOffset, branch);
2231                 break;
2232             }
2233             default:
2234                 throw GraalError.shouldNotReachHere();
2235         }
2236     }
2237 
2238     /**
2239      * Generates an address of the form {@code base + displacement}.
2240      *
2241      * Does not change base register to fulfill this requirement. Will fail if displacement cannot
2242      * be represented directly as address.
2243      *
2244      * @param base general purpose register. May not be null or the zero register.
2245      * @param displacement arbitrary displacement added to base.
2246      * @return AArch64Address referencing memory at {@code base + displacement}.
2247      */
2248     @Override
2249     public AArch64Address makeAddress(Register base, int displacement) {
2250         return makeAddress(base, displacement, zr, /* signExtend */false, /* transferSize */0, //
2251                         zr, /* allowOverwrite */false);
2252     }
2253 
2254     @Override
2255     public AArch64Address getPlaceholder(int instructionStartPosition) {
2256         return AArch64Address.PLACEHOLDER;
2257     }
2258 
2259     public void addressOf(Register dst) {
2260         if (codePatchingAnnotationConsumer != null) {
2261             codePatchingAnnotationConsumer.accept(new AdrpAddMacroInstruction(position()));
2262         }
2263         super.adrp(dst);
2264         super.add(64, dst, dst, 0);
2265     }
2266 
2267     /**
2268      * Loads an address into Register d.
2269      *
2270      * @param d general purpose register. May not be null.
2271      * @param a AArch64Address the address of an operand.
2272      */
2273     public void lea(Register d, AArch64Address a) {
2274         a.lea(this, d);
2275     }
2276 
2277     /**
2278      * Count the set bits of src register.
2279      *
2280      * @param size src register size. Has to be 32 or 64.
2281      * @param dst general purpose register. Should not be null or zero-register.
2282      * @param src general purpose register. Should not be null.
2283      * @param vreg SIMD register. Should not be null.
2284      */
2285     public void popcnt(int size, Register dst, Register src, Register vreg) {
2286         assert 32 == size || 64 == size : &quot;Invalid data size&quot;;
2287         fmov(size, vreg, src);
2288         final int fixedSize = 64;
2289         cnt(fixedSize, vreg, vreg);
2290         addv(fixedSize, SIMDElementSize.Byte, vreg, vreg);
2291         umov(fixedSize, dst, 0, vreg);
2292     }
2293 
2294     /**
2295      * Emits elf patchable adrp ldr sequence.
2296      */
2297     public void adrpLdr(int srcSize, Register result, AArch64Address a) {
2298         if (codePatchingAnnotationConsumer != null) {
2299             codePatchingAnnotationConsumer.accept(new AdrpLdrMacroInstruction(position(), srcSize));
2300         }
2301         super.adrp(a.getBase());
2302         this.ldr(srcSize, result, a);
2303     }
2304 
2305     public static class AdrpLdrMacroInstruction extends AArch64Assembler.PatchableCodeAnnotation {
2306         public final int srcSize;
2307 
2308         public AdrpLdrMacroInstruction(int position, int srcSize) {
2309             super(position);
2310             this.srcSize = srcSize;
2311         }
2312 
2313         @Override
2314         public String toString() {
2315             return &quot;ADRP_LDR&quot;;
2316         }
2317 
2318         @Override
2319         public void patch(int codePos, int relative, byte[] code) {
2320             int shiftSize = 0;
2321             switch (srcSize) {
2322                 case 64:
2323                     shiftSize = 3;
2324                     break;
2325                 case 32:
2326                     shiftSize = 2;
2327                     break;
2328                 case 16:
2329                     shiftSize = 1;
2330                     break;
2331                 case 8:
2332                     shiftSize = 0;
2333                     break;
2334                 default:
2335                     assert false : &quot;srcSize must be either 8, 16, 32, or 64&quot;;
2336             }
2337 
2338             int pos = instructionPosition;
2339 
2340             int targetAddress = pos + relative;
2341             assert shiftSize == 0 || (targetAddress &amp; ((1 &lt;&lt; shiftSize) - 1)) == 0 : &quot;shift bits must be zero&quot;;
2342 
2343             int relativePageDifference = PatcherUtil.computeRelativePageDifference(targetAddress, pos, 1 &lt;&lt; 12);
2344 
2345             // adrp imm_hi bits
2346             int curValue = (relativePageDifference &gt;&gt; 2) &amp; 0x7FFFF;
2347             int[] adrHiBits = {3, 8, 8};
2348             int[] adrHiOffsets = {5, 0, 0};
2349             PatcherUtil.writeBitSequence(code, pos, curValue, adrHiBits, adrHiOffsets);
2350             // adrp imm_lo bits
2351             curValue = relativePageDifference &amp; 0x3;
2352             int[] adrLoBits = {2};
2353             int[] adrLoOffsets = {5};
2354             PatcherUtil.writeBitSequence(code, pos + 3, curValue, adrLoBits, adrLoOffsets);
2355             // ldr bits
2356             curValue = (targetAddress &gt;&gt; shiftSize) &amp; 0x1FF;
2357             int[] ldrBits = {6, 6};
2358             int[] ldrOffsets = {2, 0};
2359             PatcherUtil.writeBitSequence(code, pos + 5, curValue, ldrBits, ldrOffsets);
2360         }
2361     }
2362 
2363     public static class AdrpAddMacroInstruction extends AArch64Assembler.PatchableCodeAnnotation {
2364         public AdrpAddMacroInstruction(int position) {
2365             super(position);
2366         }
2367 
2368         @Override
2369         public String toString() {
2370             return &quot;ADRP_ADD&quot;;
2371         }
2372 
2373         @Override
2374         public void patch(int codePos, int relative, byte[] code) {
2375             int pos = instructionPosition;
2376             int targetAddress = pos + relative;
2377             int relativePageDifference = PatcherUtil.computeRelativePageDifference(targetAddress, pos, 1 &lt;&lt; 12);
2378             // adrp imm_hi bits
2379             int curValue = (relativePageDifference &gt;&gt; 2) &amp; 0x7FFFF;
2380             int[] adrHiBits = {3, 8, 8};
2381             int[] adrHiOffsets = {5, 0, 0};
2382             PatcherUtil.writeBitSequence(code, pos, curValue, adrHiBits, adrHiOffsets);
2383             // adrp imm_lo bits
2384             curValue = relativePageDifference &amp; 0x3;
2385             int[] adrLoBits = {2};
2386             int[] adrLoOffsets = {5};
2387             PatcherUtil.writeBitSequence(code, pos + 3, curValue, adrLoBits, adrLoOffsets);
2388             // add bits
2389             curValue = targetAddress &amp; 0xFFF;
2390             int[] addBits = {6, 6};
2391             int[] addOffsets = {2, 0};
2392             PatcherUtil.writeBitSequence(code, pos + 5, curValue, addBits, addOffsets);
2393         }
2394     }
2395 
2396     private void annotateImmediateMovSequence(int pos, MovSequenceAnnotation.MovAction[] includeSet) {
2397         if (codePatchingAnnotationConsumer != null) {
2398             codePatchingAnnotationConsumer.accept(new MovSequenceAnnotation(pos, includeSet));
2399         }
2400     }
2401 
2402     public static class MovSequenceAnnotation extends AArch64Assembler.PatchableCodeAnnotation {
2403 
2404         /**
2405          * An enum to indicate how each 16-bit immediate chunk is represented within a sequence of
2406          * mov instructions.
2407          */
2408         public enum MovAction {
2409             USED, // mov instruction is in place for this chunk.
2410             SKIPPED, // no mov instruction is in place for this chunk.
2411             NEGATED; // movn instruction is in place for this chunk.
2412         }
2413 
2414         /**
2415          * The size of the operand, in bytes.
2416          */
2417         public final MovAction[] includeSet;
2418 
2419         MovSequenceAnnotation(int instructionPosition, MovAction[] includeSet) {
2420             super(instructionPosition);
2421             this.includeSet = includeSet;
2422         }
2423 
2424         @Override
2425         public String toString() {
2426             return &quot;MOV_SEQ&quot;;
2427         }
2428 
2429         @Override
2430         public void patch(int codePos, int relative, byte[] code) {
2431             /*
2432              * Each move has a 16 bit immediate operand. We use a series of shifted moves to
2433              * represent immediate values larger than 16 bits.
2434              */
2435             int curValue = relative;
2436             int[] bitsUsed = {3, 8, 5};
2437             int[] offsets = {5, 0, 0};
2438             int siteOffset = 0;
2439             boolean containsNegatedMov = false;
2440             for (MovAction include : includeSet) {
2441                 if (include == MovAction.NEGATED) {
2442                     containsNegatedMov = true;
2443                     break;
2444                 }
2445             }
2446             for (int i = 0; i &lt; includeSet.length; i++) {
2447                 int value = curValue &amp; 0xFFFF;
2448                 curValue = curValue &gt;&gt; 16;
2449                 switch (includeSet[i]) {
2450                     case USED:
2451                         break;
2452                     case SKIPPED:
2453                         assert value == (containsNegatedMov ? 0xFFFF : 0) : &quot;Unable to patch this value.&quot;;
2454                         continue;
2455                     case NEGATED:
2456                         value = value ^ 0xFFFF;
2457                         break;
2458                 }
2459                 int bytePosition = instructionPosition + siteOffset;
2460                 PatcherUtil.writeBitSequence(code, bytePosition, value, bitsUsed, offsets);
2461                 siteOffset += 4;
2462             }
2463         }
2464     }
2465 }
    </pre>
  </body>
</html>