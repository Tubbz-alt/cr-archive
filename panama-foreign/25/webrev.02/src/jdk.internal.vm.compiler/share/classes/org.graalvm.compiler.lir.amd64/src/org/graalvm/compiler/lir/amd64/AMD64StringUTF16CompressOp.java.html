<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64StringUTF16CompressOp.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 
 25 package org.graalvm.compiler.lir.amd64;
 26 
 27 import static jdk.vm.ci.amd64.AMD64.k2;
 28 import static jdk.vm.ci.amd64.AMD64.k3;
 29 import static jdk.vm.ci.amd64.AMD64.rax;
 30 import static jdk.vm.ci.amd64.AMD64.rdi;
 31 import static jdk.vm.ci.amd64.AMD64.rdx;
 32 import static jdk.vm.ci.amd64.AMD64.rsi;
 33 import static jdk.vm.ci.amd64.AMD64.rsp;
 34 import static jdk.vm.ci.code.ValueUtil.asRegister;
 35 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.REG;
 36 import static org.graalvm.compiler.lir.amd64.AMD64StringLatin1InflateOp.useAVX512ForStringInflateCompress;
 37 
 38 import org.graalvm.compiler.asm.Label;
 39 import org.graalvm.compiler.asm.amd64.AMD64Address;
 40 import org.graalvm.compiler.asm.amd64.AMD64Assembler.ConditionFlag;
 41 import org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.EVEXComparisonPredicate;
 42 import org.graalvm.compiler.asm.amd64.AMD64MacroAssembler;
 43 import org.graalvm.compiler.core.common.LIRKind;
 44 import org.graalvm.compiler.lir.LIRInstructionClass;
 45 import org.graalvm.compiler.lir.Opcode;
 46 import org.graalvm.compiler.lir.asm.CompilationResultBuilder;
 47 import org.graalvm.compiler.lir.gen.LIRGeneratorTool;
 48 
 49 import jdk.vm.ci.amd64.AMD64;
 50 import jdk.vm.ci.amd64.AMD64Kind;
 51 import jdk.vm.ci.code.CodeUtil;
 52 import jdk.vm.ci.code.Register;
 53 import jdk.vm.ci.meta.Value;
 54 
 55 @Opcode(&quot;AMD64_STRING_COMPRESS&quot;)
 56 public final class AMD64StringUTF16CompressOp extends AMD64LIRInstruction {
 57     public static final LIRInstructionClass&lt;AMD64StringUTF16CompressOp&gt; TYPE = LIRInstructionClass.create(AMD64StringUTF16CompressOp.class);
 58 
 59     private final int useAVX3Threshold;
 60 
 61     @Def({REG}) private Value rres;
 62     @Use({REG}) private Value rsrc;
 63     @Use({REG}) private Value rdst;
 64     @Use({REG}) private Value rlen;
 65 
 66     @Temp({REG}) private Value rsrcTemp;
 67     @Temp({REG}) private Value rdstTemp;
 68     @Temp({REG}) private Value rlenTemp;
 69 
 70     @Temp({REG}) private Value vtmp1;
 71     @Temp({REG}) private Value vtmp2;
 72     @Temp({REG}) private Value vtmp3;
 73     @Temp({REG}) private Value vtmp4;
 74     @Temp({REG}) private Value rtmp5;
 75 
 76     public AMD64StringUTF16CompressOp(LIRGeneratorTool tool, int useAVX3Threshold, Value res, Value src, Value dst, Value len) {
 77         super(TYPE);
 78 
 79         assert CodeUtil.isPowerOf2(useAVX3Threshold) : &quot;AVX3Threshold must be power of 2&quot;;
 80         this.useAVX3Threshold = useAVX3Threshold;
 81 
 82         assert asRegister(src).equals(rsi);
 83         assert asRegister(dst).equals(rdi);
 84         assert asRegister(len).equals(rdx);
 85         assert asRegister(res).equals(rax);
 86 
 87         rres = res;
 88         rsrcTemp = rsrc = src;
 89         rdstTemp = rdst = dst;
 90         rlenTemp = rlen = len;
 91 
 92         LIRKind vkind = useAVX512ForStringInflateCompress(tool.target()) ? LIRKind.value(AMD64Kind.V512_BYTE) : LIRKind.value(AMD64Kind.V128_BYTE);
 93 
 94         vtmp1 = tool.newVariable(vkind);
 95         vtmp2 = tool.newVariable(vkind);
 96         vtmp3 = tool.newVariable(vkind);
 97         vtmp4 = tool.newVariable(vkind);
 98 
 99         rtmp5 = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
100     }
101 
102     @Override
103     public void emitCode(CompilationResultBuilder crb, AMD64MacroAssembler masm) {
104         Register res = asRegister(rres);
105         Register src = asRegister(rsrc);
106         Register dst = asRegister(rdst);
107         Register len = asRegister(rlen);
108 
109         Register tmp1 = asRegister(vtmp1);
110         Register tmp2 = asRegister(vtmp2);
111         Register tmp3 = asRegister(vtmp3);
112         Register tmp4 = asRegister(vtmp4);
113         Register tmp5 = asRegister(rtmp5);
114 
115         charArrayCompress(masm, src, dst, len, tmp1, tmp2, tmp3, tmp4, tmp5, res);
116     }
117 
118     /**
119      * Compress a UTF16 string which de facto is a Latin1 string into a byte array representation
120      * (buffer).
121      *
122      * @param masm the assembler
123      * @param src (rsi) the start address of source char[] to be compressed
124      * @param dst (rdi) the start address of destination byte[] vector
125      * @param len (rdx) the length
126      * @param tmp1Reg (xmm) temporary xmm register
127      * @param tmp2Reg (xmm) temporary xmm register
128      * @param tmp3Reg (xmm) temporary xmm register
129      * @param tmp4Reg (xmm) temporary xmm register
130      * @param tmp5 (gpr) temporary gpr register
131      * @param result (rax) the result code (length on success, zero otherwise)
132      */
133     private void charArrayCompress(AMD64MacroAssembler masm, Register src, Register dst, Register len, Register tmp1Reg,
134                     Register tmp2Reg, Register tmp3Reg, Register tmp4Reg, Register tmp5, Register result) {
135         assert tmp1Reg.getRegisterCategory().equals(AMD64.XMM);
136         assert tmp2Reg.getRegisterCategory().equals(AMD64.XMM);
137         assert tmp3Reg.getRegisterCategory().equals(AMD64.XMM);
138         assert tmp4Reg.getRegisterCategory().equals(AMD64.XMM);
139 
140         Label labelCopyCharsLoop = new Label();
141         Label labelReturnLength = new Label();
142         Label labelReturnZero = new Label();
143         Label labelDone = new Label();
144 
145         assert len.number != result.number;
146 
147         // Save length for return.
148         masm.push(len);
149 
150         if (useAVX3Threshold == 0 &amp;&amp; useAVX512ForStringInflateCompress(masm.target)) {
151             Label labelCopy32Loop = new Label();
152             Label labelCopyLoopTail = new Label();
153             Label labelBelowThreshold = new Label();
154             Label labelPostAlignment = new Label();
155 
156             // If the length of the string is less than 32, we chose not to use the
157             // AVX512 instructions.
158             masm.testlAndJcc(len, -32, ConditionFlag.Zero, labelBelowThreshold, false);
159 
160             // First check whether a character is compressible (&lt;= 0xff).
161             // Create mask to test for Unicode chars inside (zmm) vector.
162             masm.movl(result, 0x00ff);
163             masm.evpbroadcastw(tmp2Reg, result);
164 
165             masm.testlAndJcc(len, -64, ConditionFlag.Zero, labelPostAlignment, false);
166 
167             masm.movl(tmp5, dst);
168             masm.andl(tmp5, (32 - 1));
169             masm.negl(tmp5);
170             masm.andl(tmp5, (32 - 1));
171 
172             // bail out when there is nothing to be done
173             masm.testlAndJcc(tmp5, tmp5, ConditionFlag.Zero, labelPostAlignment, false);
174 
175             // Compute (1 &lt;&lt; N) - 1 = ~(~0 &lt;&lt; N), where N is the remaining number
176             // of characters to process.
177             masm.movl(result, 0xFFFFFFFF);
178             masm.shlxl(result, result, tmp5);
179             masm.notl(result);
180             masm.kmovd(k3, result);
181 
182             masm.evmovdqu16(tmp1Reg, k3, new AMD64Address(src));
183             masm.evpcmpuw(k2, k3, tmp1Reg, tmp2Reg, EVEXComparisonPredicate.LE);
184             masm.ktestd(k2, k3);
185             masm.jcc(ConditionFlag.CarryClear, labelReturnZero);
186 
187             masm.evpmovwb(new AMD64Address(dst), k3, tmp1Reg);
188 
189             masm.addq(src, tmp5);
190             masm.addq(src, tmp5);
191             masm.addq(dst, tmp5);
192             masm.subl(len, tmp5);
193 
194             masm.bind(labelPostAlignment);
195             // end of alignment
196 
197             masm.movl(tmp5, len);
198             masm.andl(tmp5, 32 - 1);    // The tail count (in chars).
199             // The vector count (in chars).
200             masm.andlAndJcc(len, ~(32 - 1), ConditionFlag.Zero, labelCopyLoopTail, false);
201 
202             masm.leaq(src, new AMD64Address(src, len, AMD64Address.Scale.Times2));
203             masm.leaq(dst, new AMD64Address(dst, len, AMD64Address.Scale.Times1));
204             masm.negq(len);
205 
206             // Test and compress 32 chars per iteration, reading 512-bit vectors and
207             // writing 256-bit compressed ditto.
208             masm.bind(labelCopy32Loop);
209             masm.evmovdqu16(tmp1Reg, new AMD64Address(src, len, AMD64Address.Scale.Times2));
210             masm.evpcmpuw(k2, tmp1Reg, tmp2Reg, EVEXComparisonPredicate.LE);
211             masm.kortestd(k2, k2);
212             masm.jcc(ConditionFlag.CarryClear, labelReturnZero);
213 
214             // All 32 chars in the current vector (chunk) are valid for compression,
215             // write truncated byte elements to memory.
216             masm.evpmovwb(new AMD64Address(dst, len, AMD64Address.Scale.Times1), tmp1Reg);
217             masm.addqAndJcc(len, 32, ConditionFlag.NotZero, labelCopy32Loop, false);
218 
219             masm.bind(labelCopyLoopTail);
220             // All done if the tail count is zero.
221             masm.testlAndJcc(tmp5, tmp5, ConditionFlag.Zero, labelReturnLength, false);
222 
223             masm.movl(len, tmp5);
224 
225             // Compute (1 &lt;&lt; N) - 1 = ~(~0 &lt;&lt; N), where N is the remaining number
226             // of characters to process.
227             masm.movl(result, -1);
228             masm.shlxl(result, result, len);
229             masm.notl(result);
230 
231             masm.kmovd(k3, result);
232 
233             masm.evmovdqu16(tmp1Reg, k3, new AMD64Address(src));
234             masm.evpcmpuw(k2, k3, tmp1Reg, tmp2Reg, EVEXComparisonPredicate.LE);
235             masm.ktestd(k2, k3);
236             masm.jcc(ConditionFlag.CarryClear, labelReturnZero);
237 
238             masm.evpmovwb(new AMD64Address(dst), k3, tmp1Reg);
239             masm.jmp(labelReturnLength);
240 
241             masm.bind(labelBelowThreshold);
242         }
243 
244         if (masm.supports(AMD64.CPUFeature.SSE4_2)) {
245             Label labelCopy32Loop = new Label();
246             Label labelCopy16 = new Label();
247             Label labelCopyTail = new Label();
248 
249             masm.movl(result, len);
250 
251             masm.movl(tmp5, 0xff00ff00);  // Create mask to test for Unicode chars in vectors.
252 
253             // vectored compression
254             masm.andl(len, 0xfffffff0); // vector count (in chars)
255             masm.andl(result, 0x0000000f); // tail count (in chars)
256             masm.testlAndJcc(len, len, ConditionFlag.Zero, labelCopy16, false);
257 
258             // Compress 16 chars per iteration.
259             masm.movdl(tmp1Reg, tmp5);
260             masm.pshufd(tmp1Reg, tmp1Reg, 0);    // Store Unicode mask in &#39;vtmp1&#39;.
261             masm.pxor(tmp4Reg, tmp4Reg);
262 
263             masm.leaq(src, new AMD64Address(src, len, AMD64Address.Scale.Times2));
264             masm.leaq(dst, new AMD64Address(dst, len, AMD64Address.Scale.Times1));
265             masm.negq(len);
266 
267             // Test and compress 16 chars per iteration, reading 128-bit vectors and
268             // writing 64-bit compressed ditto.
269             masm.bind(labelCopy32Loop);
270             // load 1st 8 characters
271             masm.movdqu(tmp2Reg, new AMD64Address(src, len, AMD64Address.Scale.Times2));
272             masm.por(tmp4Reg, tmp2Reg);
273             // load next 8 characters
274             masm.movdqu(tmp3Reg, new AMD64Address(src, len, AMD64Address.Scale.Times2, 16));
275             masm.por(tmp4Reg, tmp3Reg);
276             masm.ptest(tmp4Reg, tmp1Reg);        // Check for Unicode chars in vector.
277             masm.jcc(ConditionFlag.NotZero, labelReturnZero);
278             masm.packuswb(tmp2Reg, tmp3Reg);     // Only ASCII chars; compress each to a byte.
279             masm.movdqu(new AMD64Address(dst, len, AMD64Address.Scale.Times1), tmp2Reg);
280             masm.addqAndJcc(len, 16, ConditionFlag.NotZero, labelCopy32Loop, false);
281 
282             // Test and compress another 8 chars before final tail copy.
283             masm.bind(labelCopy16);
284             masm.movl(len, result);
285             masm.andl(len, 0xfffffff8); // vector count (in chars)
286             masm.andl(result, 0x00000007); // tail count (in chars)
287             masm.testlAndJcc(len, len, ConditionFlag.Zero, labelCopyTail, true);
288 
289             masm.movdl(tmp1Reg, tmp5);
290             masm.pshufd(tmp1Reg, tmp1Reg, 0);    // Store Unicode mask in &#39;vtmp1&#39;.
291             masm.pxor(tmp3Reg, tmp3Reg);
292 
293             masm.movdqu(tmp2Reg, new AMD64Address(src));
294             masm.ptest(tmp2Reg, tmp1Reg);        // Check for Unicode chars in vector.
295             masm.jccb(ConditionFlag.NotZero, labelReturnZero);
296             masm.packuswb(tmp2Reg, tmp3Reg);     // Only ASCII chars; compress each to a byte.
297             masm.movq(new AMD64Address(dst), tmp2Reg);
298             masm.addq(src, 16);
299             masm.addq(dst, 8);
300 
301             masm.bind(labelCopyTail);
302             masm.movl(len, result);
303         }
304 
305         // Compress any remaining characters using a vanilla implementation.
306         masm.testlAndJcc(len, len, ConditionFlag.Zero, labelReturnLength, true);
307         masm.leaq(src, new AMD64Address(src, len, AMD64Address.Scale.Times2));
308         masm.leaq(dst, new AMD64Address(dst, len, AMD64Address.Scale.Times1));
309         masm.negq(len);
310 
311         // Compress a single character per iteration.
312         masm.bind(labelCopyCharsLoop);
313         masm.movzwl(result, new AMD64Address(src, len, AMD64Address.Scale.Times2));
314         // Check if Unicode character.
315         masm.testlAndJcc(result, 0xff00, ConditionFlag.NotZero, labelReturnZero, true);
316         // An ASCII character; compress to a byte.
317         masm.movb(new AMD64Address(dst, len, AMD64Address.Scale.Times1), result);
318         masm.incqAndJcc(len, ConditionFlag.NotZero, labelCopyCharsLoop, false);
319 
320         // If compression succeeded, return the length.
321         masm.bind(labelReturnLength);
322         masm.pop(result);
323         masm.jmpb(labelDone);
324 
325         // If compression failed, return 0.
326         masm.bind(labelReturnZero);
327         masm.xorl(result, result);
328         masm.addq(rsp, 8 /* wordSize */);
329 
330         masm.bind(labelDone);
331     }
332 
333     @Override
334     public boolean needsClearUpperVectorRegisters() {
335         return true;
336     }
337 }
    </pre>
  </body>
</html>