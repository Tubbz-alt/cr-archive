<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.asm.amd64/src/org/graalvm/compiler/asm/amd64/AMD64MacroAssembler.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2009, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 
 25 package org.graalvm.compiler.asm.amd64;
 26 
 27 import static org.graalvm.compiler.asm.amd64.AMD64AsmOptions.UseIncDec;
 28 import static org.graalvm.compiler.asm.amd64.AMD64AsmOptions.UseXmmLoadAndClearUpper;
 29 import static org.graalvm.compiler.asm.amd64.AMD64AsmOptions.UseXmmRegToRegMoveAll;
<a name="2" id="anc2"></a><span class="line-modified"> 30 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic.ADD;</span>
<span class="line-added"> 31 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic.AND;</span>
<span class="line-added"> 32 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic.CMP;</span>
<span class="line-added"> 33 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic.SUB;</span>
<span class="line-added"> 34 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64MOp.DEC;</span>
<span class="line-added"> 35 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64MOp.INC;</span>
<span class="line-added"> 36 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.DWORD;</span>
<span class="line-added"> 37 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.QWORD;</span>
<span class="line-added"> 38 import static org.graalvm.compiler.core.common.NumUtil.isByte;</span>
<span class="line-added"> 39 </span>
<span class="line-added"> 40 import java.util.function.IntConsumer;</span>
<span class="line-added"> 41 import java.util.function.Supplier;</span>
<span class="line-added"> 42 </span>
<span class="line-added"> 43 import org.graalvm.compiler.asm.Label;</span>
 44 import org.graalvm.compiler.asm.amd64.AVXKind.AVXSize;
 45 import org.graalvm.compiler.core.common.NumUtil;
<a name="3" id="anc3"></a><span class="line-added"> 46 import org.graalvm.compiler.options.OptionValues;</span>
 47 
 48 import jdk.vm.ci.amd64.AMD64;
 49 import jdk.vm.ci.amd64.AMD64Kind;
 50 import jdk.vm.ci.code.Register;
 51 import jdk.vm.ci.code.TargetDescription;
 52 
 53 /**
 54  * This class implements commonly used X86 code patterns.
 55  */
 56 public class AMD64MacroAssembler extends AMD64Assembler {
 57 
 58     public AMD64MacroAssembler(TargetDescription target) {
 59         super(target);
 60     }
 61 
<a name="4" id="anc4"></a><span class="line-added"> 62     public AMD64MacroAssembler(TargetDescription target, OptionValues optionValues) {</span>
<span class="line-added"> 63         super(target, optionValues);</span>
<span class="line-added"> 64     }</span>
<span class="line-added"> 65 </span>
 66     public final void decrementq(Register reg, int value) {
 67         if (value == Integer.MIN_VALUE) {
 68             subq(reg, value);
 69             return;
 70         }
 71         if (value &lt; 0) {
 72             incrementq(reg, -value);
 73             return;
 74         }
 75         if (value == 0) {
 76             return;
 77         }
 78         if (value == 1 &amp;&amp; UseIncDec) {
 79             decq(reg);
 80         } else {
 81             subq(reg, value);
 82         }
 83     }
 84 
 85     public final void decrementq(AMD64Address dst, int value) {
 86         if (value == Integer.MIN_VALUE) {
 87             subq(dst, value);
 88             return;
 89         }
 90         if (value &lt; 0) {
 91             incrementq(dst, -value);
 92             return;
 93         }
 94         if (value == 0) {
 95             return;
 96         }
 97         if (value == 1 &amp;&amp; UseIncDec) {
 98             decq(dst);
 99         } else {
100             subq(dst, value);
101         }
102     }
103 
104     public void incrementq(Register reg, int value) {
105         if (value == Integer.MIN_VALUE) {
106             addq(reg, value);
107             return;
108         }
109         if (value &lt; 0) {
110             decrementq(reg, -value);
111             return;
112         }
113         if (value == 0) {
114             return;
115         }
116         if (value == 1 &amp;&amp; UseIncDec) {
117             incq(reg);
118         } else {
119             addq(reg, value);
120         }
121     }
122 
123     public final void incrementq(AMD64Address dst, int value) {
124         if (value == Integer.MIN_VALUE) {
125             addq(dst, value);
126             return;
127         }
128         if (value &lt; 0) {
129             decrementq(dst, -value);
130             return;
131         }
132         if (value == 0) {
133             return;
134         }
135         if (value == 1 &amp;&amp; UseIncDec) {
136             incq(dst);
137         } else {
138             addq(dst, value);
139         }
140     }
141 
142     public final void movptr(Register dst, AMD64Address src) {
143         movq(dst, src);
144     }
145 
146     public final void movptr(AMD64Address dst, Register src) {
147         movq(dst, src);
148     }
149 
150     public final void movptr(AMD64Address dst, int src) {
151         movslq(dst, src);
152     }
153 
154     public final void cmpptr(Register src1, Register src2) {
155         cmpq(src1, src2);
156     }
157 
158     public final void cmpptr(Register src1, AMD64Address src2) {
159         cmpq(src1, src2);
160     }
161 
162     public final void decrementl(Register reg) {
163         decrementl(reg, 1);
164     }
165 
166     public final void decrementl(Register reg, int value) {
167         if (value == Integer.MIN_VALUE) {
168             subl(reg, value);
169             return;
170         }
171         if (value &lt; 0) {
172             incrementl(reg, -value);
173             return;
174         }
175         if (value == 0) {
176             return;
177         }
178         if (value == 1 &amp;&amp; UseIncDec) {
179             decl(reg);
180         } else {
181             subl(reg, value);
182         }
183     }
184 
185     public final void decrementl(AMD64Address dst, int value) {
186         if (value == Integer.MIN_VALUE) {
187             subl(dst, value);
188             return;
189         }
190         if (value &lt; 0) {
191             incrementl(dst, -value);
192             return;
193         }
194         if (value == 0) {
195             return;
196         }
197         if (value == 1 &amp;&amp; UseIncDec) {
198             decl(dst);
199         } else {
200             subl(dst, value);
201         }
202     }
203 
204     public final void incrementl(Register reg, int value) {
205         if (value == Integer.MIN_VALUE) {
206             addl(reg, value);
207             return;
208         }
209         if (value &lt; 0) {
210             decrementl(reg, -value);
211             return;
212         }
213         if (value == 0) {
214             return;
215         }
216         if (value == 1 &amp;&amp; UseIncDec) {
217             incl(reg);
218         } else {
219             addl(reg, value);
220         }
221     }
222 
223     public final void incrementl(AMD64Address dst, int value) {
224         if (value == Integer.MIN_VALUE) {
225             addl(dst, value);
226             return;
227         }
228         if (value &lt; 0) {
229             decrementl(dst, -value);
230             return;
231         }
232         if (value == 0) {
233             return;
234         }
235         if (value == 1 &amp;&amp; UseIncDec) {
236             incl(dst);
237         } else {
238             addl(dst, value);
239         }
240     }
241 
242     public void movflt(Register dst, Register src) {
243         assert dst.getRegisterCategory().equals(AMD64.XMM) &amp;&amp; src.getRegisterCategory().equals(AMD64.XMM);
244         if (UseXmmRegToRegMoveAll) {
245             if (isAVX512Register(dst) || isAVX512Register(src)) {
246                 VexMoveOp.VMOVAPS.emit(this, AVXSize.XMM, dst, src);
247             } else {
248                 movaps(dst, src);
249             }
250         } else {
251             if (isAVX512Register(dst) || isAVX512Register(src)) {
252                 VexMoveOp.VMOVSS.emit(this, AVXSize.XMM, dst, src);
253             } else {
254                 movss(dst, src);
255             }
256         }
257     }
258 
259     public void movflt(Register dst, AMD64Address src) {
260         assert dst.getRegisterCategory().equals(AMD64.XMM);
261         if (isAVX512Register(dst)) {
262             VexMoveOp.VMOVSS.emit(this, AVXSize.XMM, dst, src);
263         } else {
264             movss(dst, src);
265         }
266     }
267 
268     public void movflt(AMD64Address dst, Register src) {
269         assert src.getRegisterCategory().equals(AMD64.XMM);
270         if (isAVX512Register(src)) {
271             VexMoveOp.VMOVSS.emit(this, AVXSize.XMM, dst, src);
272         } else {
273             movss(dst, src);
274         }
275     }
276 
277     public void movdbl(Register dst, Register src) {
278         assert dst.getRegisterCategory().equals(AMD64.XMM) &amp;&amp; src.getRegisterCategory().equals(AMD64.XMM);
279         if (UseXmmRegToRegMoveAll) {
280             if (isAVX512Register(dst) || isAVX512Register(src)) {
281                 VexMoveOp.VMOVAPD.emit(this, AVXSize.XMM, dst, src);
282             } else {
283                 movapd(dst, src);
284             }
285         } else {
286             if (isAVX512Register(dst) || isAVX512Register(src)) {
287                 VexMoveOp.VMOVSD.emit(this, AVXSize.XMM, dst, src);
288             } else {
289                 movsd(dst, src);
290             }
291         }
292     }
293 
294     public void movdbl(Register dst, AMD64Address src) {
295         assert dst.getRegisterCategory().equals(AMD64.XMM);
296         if (UseXmmLoadAndClearUpper) {
297             if (isAVX512Register(dst)) {
298                 VexMoveOp.VMOVSD.emit(this, AVXSize.XMM, dst, src);
299             } else {
300                 movsd(dst, src);
301             }
302         } else {
303             assert !isAVX512Register(dst);
304             movlpd(dst, src);
305         }
306     }
307 
308     public void movdbl(AMD64Address dst, Register src) {
309         assert src.getRegisterCategory().equals(AMD64.XMM);
310         if (isAVX512Register(src)) {
311             VexMoveOp.VMOVSD.emit(this, AVXSize.XMM, dst, src);
312         } else {
313             movsd(dst, src);
314         }
315     }
316 
317     /**
318      * Non-atomic write of a 64-bit constant to memory. Do not use if the address might be a
319      * volatile field!
320      */
321     public final void movlong(AMD64Address dst, long src) {
322         if (NumUtil.isInt(src)) {
323             AMD64MIOp.MOV.emit(this, OperandSize.QWORD, dst, (int) src);
324         } else {
325             AMD64Address high = new AMD64Address(dst.getBase(), dst.getIndex(), dst.getScale(), dst.getDisplacement() + 4);
326             movl(dst, (int) (src &amp; 0xFFFFFFFF));
327             movl(high, (int) (src &gt;&gt; 32));
328         }
329     }
330 
331     public final void setl(ConditionFlag cc, Register dst) {
332         setb(cc, dst);
333         movzbl(dst, dst);
334     }
335 
336     public final void setq(ConditionFlag cc, Register dst) {
337         setb(cc, dst);
338         movzbq(dst, dst);
339     }
340 
341     public final void flog(Register dest, Register value, boolean base10) {
342         if (base10) {
343             fldlg2();
344         } else {
345             fldln2();
346         }
347         AMD64Address tmp = trigPrologue(value);
348         fyl2x();
349         trigEpilogue(dest, tmp);
350     }
351 
352     public final void fsin(Register dest, Register value) {
353         AMD64Address tmp = trigPrologue(value);
354         fsin();
355         trigEpilogue(dest, tmp);
356     }
357 
358     public final void fcos(Register dest, Register value) {
359         AMD64Address tmp = trigPrologue(value);
360         fcos();
361         trigEpilogue(dest, tmp);
362     }
363 
364     public final void ftan(Register dest, Register value) {
365         AMD64Address tmp = trigPrologue(value);
366         fptan();
367         fstp(0); // ftan pushes 1.0 in addition to the actual result, pop
368         trigEpilogue(dest, tmp);
369     }
370 
371     public final void fpop() {
372         ffree(0);
373         fincstp();
374     }
375 
376     private AMD64Address trigPrologue(Register value) {
377         assert value.getRegisterCategory().equals(AMD64.XMM);
378         AMD64Address tmp = new AMD64Address(AMD64.rsp);
379         subq(AMD64.rsp, AMD64Kind.DOUBLE.getSizeInBytes());
380         movdbl(tmp, value);
381         fldd(tmp);
382         return tmp;
383     }
384 
385     private void trigEpilogue(Register dest, AMD64Address tmp) {
386         assert dest.getRegisterCategory().equals(AMD64.XMM);
387         fstpd(tmp);
388         movdbl(dest, tmp);
389         addq(AMD64.rsp, AMD64Kind.DOUBLE.getSizeInBytes());
390     }
391 
<a name="5" id="anc5"></a><span class="line-added">392     /**</span>
<span class="line-added">393      * Emit a direct call to a fixed address, which will be patched later during code installation.</span>
<span class="line-added">394      *</span>
<span class="line-added">395      * @param align indicates whether the displacement bytes (offset by</span>
<span class="line-added">396      *            {@code callDisplacementOffset}) of this call instruction should be aligned to</span>
<span class="line-added">397      *            {@code wordSize}.</span>
<span class="line-added">398      * @return where the actual call instruction starts.</span>
<span class="line-added">399      */</span>
<span class="line-added">400     public final int directCall(boolean align, int callDisplacementOffset, int wordSize) {</span>
<span class="line-added">401         emitAlignmentForDirectCall(align, callDisplacementOffset, wordSize);</span>
<span class="line-added">402         testAndAlign(5);</span>
<span class="line-added">403         // After padding to mitigate JCC erratum, the displacement may be unaligned again. The</span>
<span class="line-added">404         // previous pass is essential because JCC erratum padding may not trigger without the</span>
<span class="line-added">405         // displacement alignment.</span>
<span class="line-added">406         emitAlignmentForDirectCall(align, callDisplacementOffset, wordSize);</span>
<span class="line-added">407         int beforeCall = position();</span>
<span class="line-added">408         call();</span>
<span class="line-added">409         return beforeCall;</span>
<span class="line-added">410     }</span>
<span class="line-added">411 </span>
<span class="line-added">412     private void emitAlignmentForDirectCall(boolean align, int callDisplacementOffset, int wordSize) {</span>
<span class="line-added">413         if (align) {</span>
<span class="line-added">414             // make sure that the displacement word of the call ends up word aligned</span>
<span class="line-added">415             int offset = position();</span>
<span class="line-added">416             offset += callDisplacementOffset;</span>
<span class="line-added">417             int modulus = wordSize;</span>
<span class="line-added">418             if (offset % modulus != 0) {</span>
<span class="line-added">419                 nop(modulus - offset % modulus);</span>
<span class="line-added">420             }</span>
<span class="line-added">421         }</span>
<span class="line-added">422     }</span>
<span class="line-added">423 </span>
<span class="line-added">424     public final int indirectCall(Register callReg) {</span>
<span class="line-added">425         int bytesToEmit = needsRex(callReg) ? 3 : 2;</span>
<span class="line-added">426         testAndAlign(bytesToEmit);</span>
<span class="line-added">427         int beforeCall = position();</span>
<span class="line-added">428         call(callReg);</span>
<span class="line-added">429         assert beforeCall + bytesToEmit == position();</span>
<span class="line-added">430         return beforeCall;</span>
<span class="line-added">431     }</span>
<span class="line-added">432 </span>
<span class="line-added">433     public final int directCall(long address, Register scratch) {</span>
<span class="line-added">434         int bytesToEmit = needsRex(scratch) ? 13 : 12;</span>
<span class="line-added">435         testAndAlign(bytesToEmit);</span>
<span class="line-added">436         int beforeCall = position();</span>
<span class="line-added">437         movq(scratch, address);</span>
<span class="line-added">438         call(scratch);</span>
<span class="line-added">439         assert beforeCall + bytesToEmit == position();</span>
<span class="line-added">440         return beforeCall;</span>
<span class="line-added">441     }</span>
<span class="line-added">442 </span>
<span class="line-added">443     public final int directJmp(long address, Register scratch) {</span>
<span class="line-added">444         int bytesToEmit = needsRex(scratch) ? 13 : 12;</span>
<span class="line-added">445         testAndAlign(bytesToEmit);</span>
<span class="line-added">446         int beforeJmp = position();</span>
<span class="line-added">447         movq(scratch, address);</span>
<span class="line-added">448         jmpWithoutAlignment(scratch);</span>
<span class="line-added">449         assert beforeJmp + bytesToEmit == position();</span>
<span class="line-added">450         return beforeJmp;</span>
<span class="line-added">451     }</span>
<span class="line-added">452 </span>
<span class="line-added">453     // This should guarantee that the alignment in AMD64Assembler.jcc methods will be not triggered.</span>
<span class="line-added">454     private void alignFusedPair(Label branchTarget, boolean isShortJmp, int prevOpInBytes) {</span>
<span class="line-added">455         assert prevOpInBytes &lt; 26 : &quot;Fused pair may be longer than 0x20 bytes.&quot;;</span>
<span class="line-added">456         if (branchTarget == null) {</span>
<span class="line-added">457             testAndAlign(prevOpInBytes + 6);</span>
<span class="line-added">458         } else if (isShortJmp) {</span>
<span class="line-added">459             testAndAlign(prevOpInBytes + 2);</span>
<span class="line-added">460         } else if (!branchTarget.isBound()) {</span>
<span class="line-added">461             testAndAlign(prevOpInBytes + 6);</span>
<span class="line-added">462         } else {</span>
<span class="line-added">463             long disp = branchTarget.position() - (position() + prevOpInBytes);</span>
<span class="line-added">464             // assuming short jump first</span>
<span class="line-added">465             if (isByte(disp - 2)) {</span>
<span class="line-added">466                 testAndAlign(prevOpInBytes + 2);</span>
<span class="line-added">467                 // After alignment, isByte(disp - shortSize) might not hold. Need to check</span>
<span class="line-added">468                 // again.</span>
<span class="line-added">469                 disp = branchTarget.position() - (position() + prevOpInBytes);</span>
<span class="line-added">470                 if (isByte(disp - 2)) {</span>
<span class="line-added">471                     return;</span>
<span class="line-added">472                 }</span>
<span class="line-added">473             }</span>
<span class="line-added">474             testAndAlign(prevOpInBytes + 6);</span>
<span class="line-added">475         }</span>
<span class="line-added">476     }</span>
<span class="line-added">477 </span>
<span class="line-added">478     private void applyMIOpAndJcc(AMD64MIOp op, OperandSize size, Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp, boolean annotateImm,</span>
<span class="line-added">479                     IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">480         final int bytesToEmit = getPrefixInBytes(size, src, op.srcIsByte) + OPCODE_IN_BYTES + MODRM_IN_BYTES + op.immediateSize(size);</span>
<span class="line-added">481         alignFusedPair(branchTarget, isShortJmp, bytesToEmit);</span>
<span class="line-added">482         final int beforeFusedPair = position();</span>
<span class="line-added">483         if (applyBeforeFusedPair != null) {</span>
<span class="line-added">484             applyBeforeFusedPair.accept(beforeFusedPair);</span>
<span class="line-added">485         }</span>
<span class="line-added">486         op.emit(this, size, src, imm32, annotateImm);</span>
<span class="line-added">487         assert beforeFusedPair + bytesToEmit == position();</span>
<span class="line-added">488         jcc(cc, branchTarget, isShortJmp);</span>
<span class="line-added">489         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">490     }</span>
<span class="line-added">491 </span>
<span class="line-added">492     private void applyMIOpAndJcc(AMD64MIOp op, OperandSize size, AMD64Address src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp, boolean annotateImm,</span>
<span class="line-added">493                     IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">494         final int bytesToEmit = getPrefixInBytes(size, src) + OPCODE_IN_BYTES + addressInBytes(src) + op.immediateSize(size);</span>
<span class="line-added">495         alignFusedPair(branchTarget, isShortJmp, bytesToEmit);</span>
<span class="line-added">496         final int beforeFusedPair = position();</span>
<span class="line-added">497         if (applyBeforeFusedPair != null) {</span>
<span class="line-added">498             applyBeforeFusedPair.accept(beforeFusedPair);</span>
<span class="line-added">499         }</span>
<span class="line-added">500         op.emit(this, size, src, imm32, annotateImm);</span>
<span class="line-added">501         assert beforeFusedPair + bytesToEmit == position();</span>
<span class="line-added">502         jcc(cc, branchTarget, isShortJmp);</span>
<span class="line-added">503         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">504     }</span>
<span class="line-added">505 </span>
<span class="line-added">506     private int applyRMOpAndJcc(AMD64RMOp op, OperandSize size, Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">507         final int bytesToEmit = getPrefixInBytes(size, src1, op.dstIsByte, src2, op.srcIsByte) + OPCODE_IN_BYTES + MODRM_IN_BYTES;</span>
<span class="line-added">508         alignFusedPair(branchTarget, isShortJmp, bytesToEmit);</span>
<span class="line-added">509         final int beforeFusedPair = position();</span>
<span class="line-added">510         op.emit(this, size, src1, src2);</span>
<span class="line-added">511         final int beforeJcc = position();</span>
<span class="line-added">512         assert beforeFusedPair + bytesToEmit == beforeJcc;</span>
<span class="line-added">513         jcc(cc, branchTarget, isShortJmp);</span>
<span class="line-added">514         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">515         return beforeJcc;</span>
<span class="line-added">516     }</span>
<span class="line-added">517 </span>
<span class="line-added">518     private int applyRMOpAndJcc(AMD64RMOp op, OperandSize size, Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">519         final int bytesToEmit = getPrefixInBytes(size, src1, op.dstIsByte, src2) + OPCODE_IN_BYTES + addressInBytes(src2);</span>
<span class="line-added">520         alignFusedPair(branchTarget, isShortJmp, bytesToEmit);</span>
<span class="line-added">521         final int beforeFusedPair = position();</span>
<span class="line-added">522         if (applyBeforeFusedPair != null) {</span>
<span class="line-added">523             applyBeforeFusedPair.accept(beforeFusedPair);</span>
<span class="line-added">524         }</span>
<span class="line-added">525         op.emit(this, size, src1, src2);</span>
<span class="line-added">526         final int beforeJcc = position();</span>
<span class="line-added">527         assert beforeFusedPair + bytesToEmit == beforeJcc;</span>
<span class="line-added">528         jcc(cc, branchTarget, isShortJmp);</span>
<span class="line-added">529         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">530         return beforeJcc;</span>
<span class="line-added">531     }</span>
<span class="line-added">532 </span>
<span class="line-added">533     public void applyMOpAndJcc(AMD64MOp op, OperandSize size, Register dst, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">534         final int bytesToEmit = getPrefixInBytes(size, dst, op.srcIsByte) + OPCODE_IN_BYTES + MODRM_IN_BYTES;</span>
<span class="line-added">535         alignFusedPair(branchTarget, isShortJmp, bytesToEmit);</span>
<span class="line-added">536         final int beforeFusedPair = position();</span>
<span class="line-added">537         op.emit(this, size, dst);</span>
<span class="line-added">538         assert beforeFusedPair + bytesToEmit == position();</span>
<span class="line-added">539         jcc(cc, branchTarget, isShortJmp);</span>
<span class="line-added">540         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">541     }</span>
<span class="line-added">542 </span>
<span class="line-added">543     public final void testAndJcc(OperandSize size, Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">544         applyMIOpAndJcc(AMD64MIOp.TEST, size, src, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">545     }</span>
<span class="line-added">546 </span>
<span class="line-added">547     public final void testlAndJcc(Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">548         applyMIOpAndJcc(AMD64MIOp.TEST, DWORD, src, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">549     }</span>
<span class="line-added">550 </span>
<span class="line-added">551     public final void testAndJcc(OperandSize size, AMD64Address src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">552         applyMIOpAndJcc(AMD64MIOp.TEST, size, src, imm32, cc, branchTarget, isShortJmp, false, applyBeforeFusedPair);</span>
<span class="line-added">553     }</span>
<span class="line-added">554 </span>
<span class="line-added">555     public final void testAndJcc(OperandSize size, Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">556         applyRMOpAndJcc(AMD64RMOp.TEST, size, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">557     }</span>
<span class="line-added">558 </span>
<span class="line-added">559     public final void testlAndJcc(Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">560         applyRMOpAndJcc(AMD64RMOp.TEST, DWORD, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">561     }</span>
<span class="line-added">562 </span>
<span class="line-added">563     public final int testqAndJcc(Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">564         return applyRMOpAndJcc(AMD64RMOp.TEST, QWORD, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">565     }</span>
<span class="line-added">566 </span>
<span class="line-added">567     public final void testAndJcc(OperandSize size, Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">568         applyRMOpAndJcc(AMD64RMOp.TEST, size, src1, src2, cc, branchTarget, isShortJmp, applyBeforeFusedPair);</span>
<span class="line-added">569     }</span>
<span class="line-added">570 </span>
<span class="line-added">571     public final void testbAndJcc(Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">572         applyRMOpAndJcc(AMD64RMOp.TESTB, OperandSize.BYTE, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">573     }</span>
<span class="line-added">574 </span>
<span class="line-added">575     public final void testbAndJcc(Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">576         applyRMOpAndJcc(AMD64RMOp.TESTB, OperandSize.BYTE, src1, src2, cc, branchTarget, isShortJmp, null);</span>
<span class="line-added">577     }</span>
<span class="line-added">578 </span>
<span class="line-added">579     public final void cmpAndJcc(OperandSize size, Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp, boolean annotateImm, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">580         applyMIOpAndJcc(CMP.getMIOpcode(size, isByte(imm32)), size, src, imm32, cc, branchTarget, isShortJmp, annotateImm, applyBeforeFusedPair);</span>
<span class="line-added">581     }</span>
<span class="line-added">582 </span>
<span class="line-added">583     public final void cmplAndJcc(Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">584         applyMIOpAndJcc(CMP.getMIOpcode(DWORD, isByte(imm32)), DWORD, src, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">585     }</span>
<span class="line-added">586 </span>
<span class="line-added">587     public final void cmpqAndJcc(Register src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">588         applyMIOpAndJcc(CMP.getMIOpcode(QWORD, isByte(imm32)), QWORD, src, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">589     }</span>
<span class="line-added">590 </span>
<span class="line-added">591     public final void cmpAndJcc(OperandSize size, AMD64Address src, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp, boolean annotateImm, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">592         applyMIOpAndJcc(CMP.getMIOpcode(size, NumUtil.isByte(imm32)), size, src, imm32, cc, branchTarget, isShortJmp, annotateImm, applyBeforeFusedPair);</span>
<span class="line-added">593     }</span>
<span class="line-added">594 </span>
<span class="line-added">595     public final void cmpAndJcc(OperandSize size, Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">596         applyRMOpAndJcc(CMP.getRMOpcode(size), size, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">597     }</span>
<span class="line-added">598 </span>
<span class="line-added">599     public final void cmplAndJcc(Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">600         applyRMOpAndJcc(CMP.getRMOpcode(DWORD), DWORD, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">601     }</span>
<span class="line-added">602 </span>
<span class="line-added">603     public final int cmpqAndJcc(Register src1, Register src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">604         return applyRMOpAndJcc(CMP.getRMOpcode(QWORD), QWORD, src1, src2, cc, branchTarget, isShortJmp);</span>
<span class="line-added">605     }</span>
<span class="line-added">606 </span>
<span class="line-added">607     public final void cmpAndJcc(OperandSize size, Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp, IntConsumer applyBeforeFusedPair) {</span>
<span class="line-added">608         applyRMOpAndJcc(CMP.getRMOpcode(size), size, src1, src2, cc, branchTarget, isShortJmp, applyBeforeFusedPair);</span>
<span class="line-added">609     }</span>
<span class="line-added">610 </span>
<span class="line-added">611     public final void cmplAndJcc(Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">612         applyRMOpAndJcc(CMP.getRMOpcode(DWORD), DWORD, src1, src2, cc, branchTarget, isShortJmp, null);</span>
<span class="line-added">613     }</span>
<span class="line-added">614 </span>
<span class="line-added">615     public final int cmpqAndJcc(Register src1, AMD64Address src2, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">616         return applyRMOpAndJcc(CMP.getRMOpcode(QWORD), QWORD, src1, src2, cc, branchTarget, isShortJmp, null);</span>
<span class="line-added">617     }</span>
<span class="line-added">618 </span>
<span class="line-added">619     public final void cmpAndJcc(OperandSize size, Register src1, Supplier&lt;AMD64Address&gt; src2, ConditionFlag cc, Label branchTarget) {</span>
<span class="line-added">620         AMD64Address placeHolder = getPlaceholder(position());</span>
<span class="line-added">621         final AMD64RMOp op = CMP.getRMOpcode(size);</span>
<span class="line-added">622         final int bytesToEmit = getPrefixInBytes(size, src1, op.dstIsByte, placeHolder) + OPCODE_IN_BYTES + addressInBytes(placeHolder);</span>
<span class="line-added">623         alignFusedPair(branchTarget, false, bytesToEmit);</span>
<span class="line-added">624         final int beforeFusedPair = position();</span>
<span class="line-added">625         AMD64Address src2AsAddress = src2.get();</span>
<span class="line-added">626         op.emit(this, size, src1, src2AsAddress);</span>
<span class="line-added">627         assert beforeFusedPair + bytesToEmit == position();</span>
<span class="line-added">628         jcc(cc, branchTarget, false);</span>
<span class="line-added">629         assert ensureWithinBoundary(beforeFusedPair);</span>
<span class="line-added">630     }</span>
<span class="line-added">631 </span>
<span class="line-added">632     public final void andlAndJcc(Register dst, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">633         applyMIOpAndJcc(AND.getMIOpcode(DWORD, isByte(imm32)), DWORD, dst, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">634     }</span>
<span class="line-added">635 </span>
<span class="line-added">636     public final void addqAndJcc(Register dst, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">637         applyMIOpAndJcc(ADD.getMIOpcode(QWORD, isByte(imm32)), QWORD, dst, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">638     }</span>
<span class="line-added">639 </span>
<span class="line-added">640     public final void sublAndJcc(Register dst, Register src, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">641         applyRMOpAndJcc(SUB.getRMOpcode(DWORD), DWORD, dst, src, cc, branchTarget, isShortJmp);</span>
<span class="line-added">642     }</span>
<span class="line-added">643 </span>
<span class="line-added">644     public final void subqAndJcc(Register dst, Register src, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">645         applyRMOpAndJcc(SUB.getRMOpcode(QWORD), QWORD, dst, src, cc, branchTarget, isShortJmp);</span>
<span class="line-added">646     }</span>
<span class="line-added">647 </span>
<span class="line-added">648     public final void sublAndJcc(Register dst, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">649         applyMIOpAndJcc(SUB.getMIOpcode(DWORD, isByte(imm32)), DWORD, dst, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">650     }</span>
<span class="line-added">651 </span>
<span class="line-added">652     public final void subqAndJcc(Register dst, int imm32, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">653         applyMIOpAndJcc(SUB.getMIOpcode(QWORD, isByte(imm32)), QWORD, dst, imm32, cc, branchTarget, isShortJmp, false, null);</span>
<span class="line-added">654     }</span>
<span class="line-added">655 </span>
<span class="line-added">656     public final void incqAndJcc(Register dst, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">657         applyMOpAndJcc(INC, QWORD, dst, cc, branchTarget, isShortJmp);</span>
<span class="line-added">658     }</span>
<span class="line-added">659 </span>
<span class="line-added">660     public final void decqAndJcc(Register dst, ConditionFlag cc, Label branchTarget, boolean isShortJmp) {</span>
<span class="line-added">661         applyMOpAndJcc(DEC, QWORD, dst, cc, branchTarget, isShortJmp);</span>
<span class="line-added">662     }</span>
663 }
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>