<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 36 #include &quot;runtime/biasedLocking.hpp&quot;
 37 #include &quot;runtime/os.hpp&quot;
 38 #include &quot;runtime/sharedRuntime.hpp&quot;
 39 #include &quot;runtime/stubRoutines.hpp&quot;
 40 
 41 int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register scratch, Label&amp; slow_case) {
 42   const int aligned_mask = BytesPerWord -1;
 43   const int hdr_offset = oopDesc::mark_offset_in_bytes();
 44   assert(hdr == rax, &quot;hdr must be rax, for the cmpxchg instruction&quot;);
 45   assert(hdr != obj &amp;&amp; hdr != disp_hdr &amp;&amp; obj != disp_hdr, &quot;registers must be different&quot;);
 46   Label done;
 47   int null_check_offset = -1;
 48 
 49   verify_oop(obj);
 50 
 51   // save object being locked into the BasicObjectLock
 52   movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);
 53 
 54   if (UseBiasedLocking) {
 55     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
<span class="line-modified"> 56     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, false, done, &amp;slow_case);</span>

 57   } else {
 58     null_check_offset = offset();
 59   }
 60 
 61   // Load object header
 62   movptr(hdr, Address(obj, hdr_offset));
 63   // and mark it as unlocked
 64   orptr(hdr, markWord::unlocked_value);
 65   // save unlocked object header into the displaced header location on the stack
 66   movptr(Address(disp_hdr, 0), hdr);
 67   // test if object header is still the same (i.e. unlocked), and if so, store the
 68   // displaced header address in the object header - if it is not the same, get the
 69   // object header instead
 70   MacroAssembler::lock(); // must be immediately before cmpxchg!
 71   cmpxchgptr(disp_hdr, Address(obj, hdr_offset));
 72   // if the object header was the same, we&#39;re done
 73   if (PrintBiasedLockingStatistics) {
 74     cond_inc32(Assembler::equal,
 75                ExternalAddress((address)BiasedLocking::fast_path_entry_count_addr()));
 76   }
</pre>
<hr />
<pre>
133   // if the object header was not pointing to the displaced header,
134   // we do unlocking via runtime call
135   jcc(Assembler::notEqual, slow_case);
136   // done
137   bind(done);
138 }
139 
140 
141 // Defines obj, preserves var_size_in_bytes
142 void C1_MacroAssembler::try_allocate(Register obj, Register var_size_in_bytes, int con_size_in_bytes, Register t1, Register t2, Label&amp; slow_case) {
143   if (UseTLAB) {
144     tlab_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
145   } else {
146     eden_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
147   }
148 }
149 
150 
151 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register t1, Register t2) {
152   assert_different_registers(obj, klass, len);

153   if (UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {
154     assert_different_registers(obj, klass, len, t1, t2);
155     movptr(t1, Address(klass, Klass::prototype_header_offset()));
156     movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);
157   } else {
158     // This assumes that all prototype bits fit in an int32_t
159     movptr(Address(obj, oopDesc::mark_offset_in_bytes ()), (int32_t)(intptr_t)markWord::prototype().value());
160   }
161 #ifdef _LP64
162   if (UseCompressedClassPointers) { // Take care not to kill klass
163     movptr(t1, klass);
<span class="line-modified">164     encode_klass_not_null(t1);</span>
165     movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);
166   } else
167 #endif
168   {
169     movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);
170   }
171 
172   if (len-&gt;is_valid()) {
173     movl(Address(obj, arrayOopDesc::length_offset_in_bytes()), len);
174   }
175 #ifdef _LP64
176   else if (UseCompressedClassPointers) {
177     xorptr(t1, t1);
178     store_klass_gap(obj, t1);
179   }
180 #endif
181 }
182 
183 
184 // preserves obj, destroys len_in_bytes
</pre>
<hr />
<pre>
279   // clear rest of allocated space
280   const Register len_zero = len;
281   initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);
282 
283   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
284     assert(obj == rax, &quot;must be&quot;);
285     call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
286   }
287 
288   verify_oop(obj);
289 }
290 
291 
292 
293 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
294   verify_oop(receiver);
295   // explicit NULL check not needed since load from [klass_offset] causes a trap
296   // check against inline cache
297   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
298   int start_offset = offset();

299 
300   if (UseCompressedClassPointers) {
<span class="line-modified">301     load_klass(rscratch1, receiver);</span>
302     cmpptr(rscratch1, iCache);
303   } else {
304     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
305   }
306   // if icache check fails, then jump to runtime routine
307   // Note: RECEIVER must still contain the receiver!
308   jump_cc(Assembler::notEqual,
309           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
310   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
311   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
312 }
313 
314 
315 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {
316   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
317   // Make sure there is enough stack space for this method&#39;s activation.
318   // Note that we do this before doing an enter(). This matches the
319   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
320   // the SharedRuntime stack overflow handling to be consistent
321   // between the two compilers.
</pre>
</td>
<td>
<hr />
<pre>
 36 #include &quot;runtime/biasedLocking.hpp&quot;
 37 #include &quot;runtime/os.hpp&quot;
 38 #include &quot;runtime/sharedRuntime.hpp&quot;
 39 #include &quot;runtime/stubRoutines.hpp&quot;
 40 
 41 int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register scratch, Label&amp; slow_case) {
 42   const int aligned_mask = BytesPerWord -1;
 43   const int hdr_offset = oopDesc::mark_offset_in_bytes();
 44   assert(hdr == rax, &quot;hdr must be rax, for the cmpxchg instruction&quot;);
 45   assert(hdr != obj &amp;&amp; hdr != disp_hdr &amp;&amp; obj != disp_hdr, &quot;registers must be different&quot;);
 46   Label done;
 47   int null_check_offset = -1;
 48 
 49   verify_oop(obj);
 50 
 51   // save object being locked into the BasicObjectLock
 52   movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);
 53 
 54   if (UseBiasedLocking) {
 55     assert(scratch != noreg, &quot;should have scratch register at this point&quot;);
<span class="line-modified"> 56     Register rklass_decode_tmp = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
<span class="line-added"> 57     null_check_offset = biased_locking_enter(disp_hdr, obj, hdr, scratch, rklass_decode_tmp, false, done, &amp;slow_case);</span>
 58   } else {
 59     null_check_offset = offset();
 60   }
 61 
 62   // Load object header
 63   movptr(hdr, Address(obj, hdr_offset));
 64   // and mark it as unlocked
 65   orptr(hdr, markWord::unlocked_value);
 66   // save unlocked object header into the displaced header location on the stack
 67   movptr(Address(disp_hdr, 0), hdr);
 68   // test if object header is still the same (i.e. unlocked), and if so, store the
 69   // displaced header address in the object header - if it is not the same, get the
 70   // object header instead
 71   MacroAssembler::lock(); // must be immediately before cmpxchg!
 72   cmpxchgptr(disp_hdr, Address(obj, hdr_offset));
 73   // if the object header was the same, we&#39;re done
 74   if (PrintBiasedLockingStatistics) {
 75     cond_inc32(Assembler::equal,
 76                ExternalAddress((address)BiasedLocking::fast_path_entry_count_addr()));
 77   }
</pre>
<hr />
<pre>
134   // if the object header was not pointing to the displaced header,
135   // we do unlocking via runtime call
136   jcc(Assembler::notEqual, slow_case);
137   // done
138   bind(done);
139 }
140 
141 
142 // Defines obj, preserves var_size_in_bytes
143 void C1_MacroAssembler::try_allocate(Register obj, Register var_size_in_bytes, int con_size_in_bytes, Register t1, Register t2, Label&amp; slow_case) {
144   if (UseTLAB) {
145     tlab_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
146   } else {
147     eden_allocate(noreg, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
148   }
149 }
150 
151 
152 void C1_MacroAssembler::initialize_header(Register obj, Register klass, Register len, Register t1, Register t2) {
153   assert_different_registers(obj, klass, len);
<span class="line-added">154   Register tmp_encode_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
155   if (UseBiasedLocking &amp;&amp; !len-&gt;is_valid()) {
156     assert_different_registers(obj, klass, len, t1, t2);
157     movptr(t1, Address(klass, Klass::prototype_header_offset()));
158     movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);
159   } else {
160     // This assumes that all prototype bits fit in an int32_t
161     movptr(Address(obj, oopDesc::mark_offset_in_bytes ()), (int32_t)(intptr_t)markWord::prototype().value());
162   }
163 #ifdef _LP64
164   if (UseCompressedClassPointers) { // Take care not to kill klass
165     movptr(t1, klass);
<span class="line-modified">166     encode_klass_not_null(t1, tmp_encode_klass);</span>
167     movl(Address(obj, oopDesc::klass_offset_in_bytes()), t1);
168   } else
169 #endif
170   {
171     movptr(Address(obj, oopDesc::klass_offset_in_bytes()), klass);
172   }
173 
174   if (len-&gt;is_valid()) {
175     movl(Address(obj, arrayOopDesc::length_offset_in_bytes()), len);
176   }
177 #ifdef _LP64
178   else if (UseCompressedClassPointers) {
179     xorptr(t1, t1);
180     store_klass_gap(obj, t1);
181   }
182 #endif
183 }
184 
185 
186 // preserves obj, destroys len_in_bytes
</pre>
<hr />
<pre>
281   // clear rest of allocated space
282   const Register len_zero = len;
283   initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);
284 
285   if (CURRENT_ENV-&gt;dtrace_alloc_probes()) {
286     assert(obj == rax, &quot;must be&quot;);
287     call(RuntimeAddress(Runtime1::entry_for(Runtime1::dtrace_object_alloc_id)));
288   }
289 
290   verify_oop(obj);
291 }
292 
293 
294 
295 void C1_MacroAssembler::inline_cache_check(Register receiver, Register iCache) {
296   verify_oop(receiver);
297   // explicit NULL check not needed since load from [klass_offset] causes a trap
298   // check against inline cache
299   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
300   int start_offset = offset();
<span class="line-added">301   Register tmp_load_klass = LP64_ONLY(rscratch2) NOT_LP64(noreg);</span>
302 
303   if (UseCompressedClassPointers) {
<span class="line-modified">304     load_klass(rscratch1, receiver, tmp_load_klass);</span>
305     cmpptr(rscratch1, iCache);
306   } else {
307     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
308   }
309   // if icache check fails, then jump to runtime routine
310   // Note: RECEIVER must still contain the receiver!
311   jump_cc(Assembler::notEqual,
312           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
313   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
314   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
315 }
316 
317 
318 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {
319   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
320   // Make sure there is enough stack space for this method&#39;s activation.
321   // Note that we do this before doing an enter(). This matches the
322   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
323   // the SharedRuntime stack overflow handling to be consistent
324   // between the two compilers.
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>