<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_FrameMap_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1168 #else
1169     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 0));
1170     // push and pop the part at src + wordSize, adding wordSize for the previous push
1171     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1172     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1173     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1174 #endif // _LP64
1175 
1176   } else {
1177     ShouldNotReachHere();
1178   }
1179 }
1180 
1181 
1182 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1183   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1184   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1185 
1186   LIR_Address* addr = src-&gt;as_address_ptr();
1187   Address from_addr = as_Address(addr);

1188 
1189   if (addr-&gt;base()-&gt;type() == T_OBJECT) {
1190     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1191   }
1192 
1193   switch (type) {
1194     case T_BOOLEAN: // fall through
1195     case T_BYTE:    // fall through
1196     case T_CHAR:    // fall through
1197     case T_SHORT:
1198       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1199         // on pre P6 processors we may get partial register stalls
1200         // so blow away the value of to_rinfo before loading a
1201         // partial word into it.  Do it here so that it precedes
1202         // the potential patch point below.
1203         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1204       }
1205       break;
1206    default:
1207      break;
</pre>
<hr />
<pre>
1353   }
1354 
1355   if (patch != NULL) {
1356     patching_epilog(patch, patch_code, addr-&gt;base()-&gt;as_register(), info);
1357   }
1358 
1359   if (is_reference_type(type)) {
1360 #ifdef _LP64
1361     if (UseCompressedOops &amp;&amp; !wide) {
1362       __ decode_heap_oop(dest-&gt;as_register());
1363     }
1364 #endif
1365 
1366     // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1367     if (!UseZGC) {
1368       __ verify_oop(dest-&gt;as_register());
1369     }
1370   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1371 #ifdef _LP64
1372     if (UseCompressedClassPointers) {
<span class="line-modified">1373       __ decode_klass_not_null(dest-&gt;as_register());</span>
1374     }
1375 #endif
1376   }
1377 }
1378 
1379 
1380 NEEDS_CLEANUP; // This could be static?
1381 Address::ScaleFactor LIR_Assembler::array_element_size(BasicType type) const {
1382   int elem_size = type2aelembytes(type);
1383   switch (elem_size) {
1384     case 1: return Address::times_1;
1385     case 2: return Address::times_2;
1386     case 4: return Address::times_4;
1387     case 8: return Address::times_8;
1388   }
1389   ShouldNotReachHere();
1390   return Address::no_scale;
1391 }
1392 
1393 
</pre>
<hr />
<pre>
1681     Label next_test;
1682     Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_offset(i)));
1683     __ cmpptr(recv_addr, (intptr_t)NULL_WORD);
1684     __ jccb(Assembler::notEqual, next_test);
1685     __ movptr(recv_addr, recv);
1686     __ movptr(Address(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);
1687     __ jmp(*update_done);
1688     __ bind(next_test);
1689   }
1690 }
1691 
1692 void LIR_Assembler::emit_typecheck_helper(LIR_OpTypeCheck *op, Label* success, Label* failure, Label* obj_is_null) {
1693   // we always need a stub for the failure case.
1694   CodeStub* stub = op-&gt;stub();
1695   Register obj = op-&gt;object()-&gt;as_register();
1696   Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1697   Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1698   Register dst = op-&gt;result_opr()-&gt;as_register();
1699   ciKlass* k = op-&gt;klass();
1700   Register Rtmp1 = noreg;

1701 
1702   // check if it needs to be profiled
1703   ciMethodData* md = NULL;
1704   ciProfileData* data = NULL;
1705 
1706   if (op-&gt;should_profile()) {
1707     ciMethod* method = op-&gt;profiled_method();
1708     assert(method != NULL, &quot;Should have method&quot;);
1709     int bci = op-&gt;profiled_bci();
1710     md = method-&gt;method_data_or_null();
1711     assert(md != NULL, &quot;Sanity&quot;);
1712     data = md-&gt;bci_to_data(bci);
1713     assert(data != NULL,                &quot;need data for type check&quot;);
1714     assert(data-&gt;is_ReceiverTypeData(), &quot;need ReceiverTypeData for type check&quot;);
1715   }
1716   Label profile_cast_success, profile_cast_failure;
1717   Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : success;
1718   Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : failure;
1719 
1720   if (obj == k_RInfo) {
</pre>
<hr />
<pre>
1744     __ jmp(*obj_is_null);
1745     __ bind(not_null);
1746   } else {
1747     __ jcc(Assembler::equal, *obj_is_null);
1748   }
1749 
1750   if (!k-&gt;is_loaded()) {
1751     klass2reg_with_patching(k_RInfo, op-&gt;info_for_patch());
1752   } else {
1753 #ifdef _LP64
1754     __ mov_metadata(k_RInfo, k-&gt;constant_encoding());
1755 #endif // _LP64
1756   }
1757   __ verify_oop(obj);
1758 
1759   if (op-&gt;fast_check()) {
1760     // get object class
1761     // not a safepoint as obj null check happens earlier
1762 #ifdef _LP64
1763     if (UseCompressedClassPointers) {
<span class="line-modified">1764       __ load_klass(Rtmp1, obj);</span>
1765       __ cmpptr(k_RInfo, Rtmp1);
1766     } else {
1767       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1768     }
1769 #else
1770     if (k-&gt;is_loaded()) {
1771       __ cmpklass(Address(obj, oopDesc::klass_offset_in_bytes()), k-&gt;constant_encoding());
1772     } else {
1773       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1774     }
1775 #endif
1776     __ jcc(Assembler::notEqual, *failure_target);
1777     // successful cast, fall through to profile or jump
1778   } else {
1779     // get object class
1780     // not a safepoint as obj null check happens earlier
<span class="line-modified">1781     __ load_klass(klass_RInfo, obj);</span>
1782     if (k-&gt;is_loaded()) {
1783       // See if we get an immediate positive hit
1784 #ifdef _LP64
1785       __ cmpptr(k_RInfo, Address(klass_RInfo, k-&gt;super_check_offset()));
1786 #else
1787       __ cmpklass(Address(klass_RInfo, k-&gt;super_check_offset()), k-&gt;constant_encoding());
1788 #endif // _LP64
1789       if ((juint)in_bytes(Klass::secondary_super_cache_offset()) != k-&gt;super_check_offset()) {
1790         __ jcc(Assembler::notEqual, *failure_target);
1791         // successful cast, fall through to profile or jump
1792       } else {
1793         // See if we get an immediate positive hit
1794         __ jcc(Assembler::equal, *success_target);
1795         // check for self
1796 #ifdef _LP64
1797         __ cmpptr(klass_RInfo, k_RInfo);
1798 #else
1799         __ cmpklass(klass_RInfo, k-&gt;constant_encoding());
1800 #endif // _LP64
1801         __ jcc(Assembler::equal, *success_target);
</pre>
<hr />
<pre>
1816       }
1817     } else {
1818       // perform the fast part of the checking logic
1819       __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1820       // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1821       __ push(klass_RInfo);
1822       __ push(k_RInfo);
1823       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1824       __ pop(klass_RInfo);
1825       __ pop(k_RInfo);
1826       // result is a boolean
1827       __ cmpl(k_RInfo, 0);
1828       __ jcc(Assembler::equal, *failure_target);
1829       // successful cast, fall through to profile or jump
1830     }
1831   }
1832   if (op-&gt;should_profile()) {
1833     Register mdo  = klass_RInfo, recv = k_RInfo;
1834     __ bind(profile_cast_success);
1835     __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1836     __ load_klass(recv, obj);</span>
1837     type_profile_helper(mdo, md, data, recv, success);
1838     __ jmp(*success);
1839 
1840     __ bind(profile_cast_failure);
1841     __ mov_metadata(mdo, md-&gt;constant_encoding());
1842     Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1843     __ subptr(counter_addr, DataLayout::counter_increment);
1844     __ jmp(*failure);
1845   }
1846   __ jmp(*success);
1847 }
1848 
1849 
1850 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {

1851   LIR_Code code = op-&gt;code();
1852   if (code == lir_store_check) {
1853     Register value = op-&gt;object()-&gt;as_register();
1854     Register array = op-&gt;array()-&gt;as_register();
1855     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1856     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1857     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
1858 
1859     CodeStub* stub = op-&gt;stub();
1860 
1861     // check if it needs to be profiled
1862     ciMethodData* md = NULL;
1863     ciProfileData* data = NULL;
1864 
1865     if (op-&gt;should_profile()) {
1866       ciMethod* method = op-&gt;profiled_method();
1867       assert(method != NULL, &quot;Should have method&quot;);
1868       int bci = op-&gt;profiled_bci();
1869       md = method-&gt;method_data_or_null();
1870       assert(md != NULL, &quot;Sanity&quot;);
</pre>
<hr />
<pre>
1876     Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : &amp;done;
1877     Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : stub-&gt;entry();
1878 
1879     __ cmpptr(value, (int32_t)NULL_WORD);
1880     if (op-&gt;should_profile()) {
1881       Label not_null;
1882       __ jccb(Assembler::notEqual, not_null);
1883       // Object is null; update MDO and exit
1884       Register mdo  = klass_RInfo;
1885       __ mov_metadata(mdo, md-&gt;constant_encoding());
1886       Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, DataLayout::flags_offset()));
1887       int header_bits = BitData::null_seen_byte_constant();
1888       __ orb(data_addr, header_bits);
1889       __ jmp(done);
1890       __ bind(not_null);
1891     } else {
1892       __ jcc(Assembler::equal, done);
1893     }
1894 
1895     add_debug_info_for_null_check_here(op-&gt;info_for_exception());
<span class="line-modified">1896     __ load_klass(k_RInfo, array);</span>
<span class="line-modified">1897     __ load_klass(klass_RInfo, value);</span>
1898 
1899     // get instance klass (it&#39;s already uncompressed)
1900     __ movptr(k_RInfo, Address(k_RInfo, ObjArrayKlass::element_klass_offset()));
1901     // perform the fast part of the checking logic
1902     __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1903     // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1904     __ push(klass_RInfo);
1905     __ push(k_RInfo);
1906     __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1907     __ pop(klass_RInfo);
1908     __ pop(k_RInfo);
1909     // result is a boolean
1910     __ cmpl(k_RInfo, 0);
1911     __ jcc(Assembler::equal, *failure_target);
1912     // fall through to the success case
1913 
1914     if (op-&gt;should_profile()) {
1915       Register mdo  = klass_RInfo, recv = k_RInfo;
1916       __ bind(profile_cast_success);
1917       __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1918       __ load_klass(recv, value);</span>
1919       type_profile_helper(mdo, md, data, recv, &amp;done);
1920       __ jmpb(done);
1921 
1922       __ bind(profile_cast_failure);
1923       __ mov_metadata(mdo, md-&gt;constant_encoding());
1924       Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1925       __ subptr(counter_addr, DataLayout::counter_increment);
1926       __ jmp(*stub-&gt;entry());
1927     }
1928 
1929     __ bind(done);
1930   } else
1931     if (code == lir_checkcast) {
1932       Register obj = op-&gt;object()-&gt;as_register();
1933       Register dst = op-&gt;result_opr()-&gt;as_register();
1934       Label success;
1935       emit_typecheck_helper(op, &amp;success, op-&gt;stub()-&gt;entry(), &amp;success);
1936       __ bind(success);
1937       if (dst != obj) {
1938         __ mov(dst, obj);
</pre>
<hr />
<pre>
3090 
3091 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3092   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3093   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3094   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3095   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3096 }
3097 
3098 
3099 // This code replaces a call to arraycopy; no exception may
3100 // be thrown in this code, they must be thrown in the System.arraycopy
3101 // activation frame; we could save some checks if this would not be the case
3102 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
3103   ciArrayKlass* default_type = op-&gt;expected_type();
3104   Register src = op-&gt;src()-&gt;as_register();
3105   Register dst = op-&gt;dst()-&gt;as_register();
3106   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3107   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3108   Register length  = op-&gt;length()-&gt;as_register();
3109   Register tmp = op-&gt;tmp()-&gt;as_register();

3110 
3111   __ resolve(ACCESS_READ, src);
3112   __ resolve(ACCESS_WRITE, dst);
3113 
3114   CodeStub* stub = op-&gt;stub();
3115   int flags = op-&gt;flags();
3116   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3117   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3118 
3119   // if we don&#39;t know anything, just go through the generic arraycopy
3120   if (default_type == NULL) {
3121     // save outgoing arguments on stack in case call to System.arraycopy is needed
3122     // HACK ALERT. This code used to push the parameters in a hardwired fashion
3123     // for interpreter calling conventions. Now we have to do it in new style conventions.
3124     // For the moment until C1 gets the new register allocator I just force all the
3125     // args to the right place (except the register args) and then on the back side
3126     // reload the register args properly if we go slow path. Yuck
3127 
3128     // These are proper for the calling convention
3129     store_parameter(length, 2);
</pre>
<hr />
<pre>
3237   Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());
3238   Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());
3239 
3240   // length and pos&#39;s are all sign extended at this point on 64bit
3241 
3242   // test for NULL
3243   if (flags &amp; LIR_OpArrayCopy::src_null_check) {
3244     __ testptr(src, src);
3245     __ jcc(Assembler::zero, *stub-&gt;entry());
3246   }
3247   if (flags &amp; LIR_OpArrayCopy::dst_null_check) {
3248     __ testptr(dst, dst);
3249     __ jcc(Assembler::zero, *stub-&gt;entry());
3250   }
3251 
3252   // If the compiler was not able to prove that exact type of the source or the destination
3253   // of the arraycopy is an array type, check at runtime if the source or the destination is
3254   // an instance type.
3255   if (flags &amp; LIR_OpArrayCopy::type_check) {
3256     if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3257       __ load_klass(tmp, dst);</span>
3258       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3259       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3260     }
3261 
3262     if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3263       __ load_klass(tmp, src);</span>
3264       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3265       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3266     }
3267   }
3268 
3269   // check if negative
3270   if (flags &amp; LIR_OpArrayCopy::src_pos_positive_check) {
3271     __ testl(src_pos, src_pos);
3272     __ jcc(Assembler::less, *stub-&gt;entry());
3273   }
3274   if (flags &amp; LIR_OpArrayCopy::dst_pos_positive_check) {
3275     __ testl(dst_pos, dst_pos);
3276     __ jcc(Assembler::less, *stub-&gt;entry());
3277   }
3278 
3279   if (flags &amp; LIR_OpArrayCopy::src_range_check) {
3280     __ lea(tmp, Address(src_pos, length, Address::times_1, 0));
3281     __ cmpl(tmp, src_length_addr);
3282     __ jcc(Assembler::above, *stub-&gt;entry());
3283   }
</pre>
<hr />
<pre>
3300   if (flags &amp; LIR_OpArrayCopy::type_check) {
3301     // We don&#39;t know the array types are compatible
3302     if (basic_type != T_OBJECT) {
3303       // Simple test for basic type arrays
3304       if (UseCompressedClassPointers) {
3305         __ movl(tmp, src_klass_addr);
3306         __ cmpl(tmp, dst_klass_addr);
3307       } else {
3308         __ movptr(tmp, src_klass_addr);
3309         __ cmpptr(tmp, dst_klass_addr);
3310       }
3311       __ jcc(Assembler::notEqual, *stub-&gt;entry());
3312     } else {
3313       // For object arrays, if src is a sub class of dst then we can
3314       // safely do the copy.
3315       Label cont, slow;
3316 
3317       __ push(src);
3318       __ push(dst);
3319 
<span class="line-modified">3320       __ load_klass(src, src);</span>
<span class="line-modified">3321       __ load_klass(dst, dst);</span>
3322 
3323       __ check_klass_subtype_fast_path(src, dst, tmp, &amp;cont, &amp;slow, NULL);
3324 
3325       __ push(src);
3326       __ push(dst);
3327       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
3328       __ pop(dst);
3329       __ pop(src);
3330 
3331       __ cmpl(src, 0);
3332       __ jcc(Assembler::notEqual, cont);
3333 
3334       __ bind(slow);
3335       __ pop(dst);
3336       __ pop(src);
3337 
3338       address copyfunc_addr = StubRoutines::checkcast_arraycopy();
3339       if (copyfunc_addr != NULL) { // use stub if available
3340         // src is not a sub class of dst so we have to do a
3341         // per-element check.
3342 
3343         int mask = LIR_OpArrayCopy::src_objarray|LIR_OpArrayCopy::dst_objarray;
3344         if ((flags &amp; mask) != mask) {
3345           // Check that at least both of them object arrays.
3346           assert(flags &amp; mask, &quot;one of the two should be known to be an object array&quot;);
3347 
3348           if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3349             __ load_klass(tmp, src);</span>
3350           } else if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3351             __ load_klass(tmp, dst);</span>
3352           }
3353           int lh_offset = in_bytes(Klass::layout_helper_offset());
3354           Address klass_lh_addr(tmp, lh_offset);
3355           jint objArray_lh = Klass::array_layout_helper(T_OBJECT);
3356           __ cmpl(klass_lh_addr, objArray_lh);
3357           __ jcc(Assembler::notEqual, *stub-&gt;entry());
3358         }
3359 
3360        // Spill because stubs can use any register they like and it&#39;s
3361        // easier to restore just those that we care about.
3362        store_parameter(dst, 0);
3363        store_parameter(dst_pos, 1);
3364        store_parameter(length, 2);
3365        store_parameter(src_pos, 3);
3366        store_parameter(src, 4);
3367 
3368 #ifndef _LP64
3369         __ movptr(tmp, dst_klass_addr);
3370         __ movptr(tmp, Address(tmp, ObjArrayKlass::element_klass_offset()));
3371         __ push(tmp);
</pre>
<hr />
<pre>
3375         __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3376         __ push(tmp);
3377         __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3378         __ push(tmp);
3379 
3380         __ call_VM_leaf(copyfunc_addr, 5);
3381 #else
3382         __ movl2ptr(length, length); //higher 32bits must be null
3383 
3384         __ lea(c_rarg0, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3385         assert_different_registers(c_rarg0, dst, dst_pos, length);
3386         __ lea(c_rarg1, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3387         assert_different_registers(c_rarg1, dst, length);
3388 
3389         __ mov(c_rarg2, length);
3390         assert_different_registers(c_rarg2, dst);
3391 
3392 #ifdef _WIN64
3393         // Allocate abi space for args but be sure to keep stack aligned
3394         __ subptr(rsp, 6*wordSize);
<span class="line-modified">3395         __ load_klass(c_rarg3, dst);</span>
3396         __ movptr(c_rarg3, Address(c_rarg3, ObjArrayKlass::element_klass_offset()));
3397         store_parameter(c_rarg3, 4);
3398         __ movl(c_rarg3, Address(c_rarg3, Klass::super_check_offset_offset()));
3399         __ call(RuntimeAddress(copyfunc_addr));
3400         __ addptr(rsp, 6*wordSize);
3401 #else
<span class="line-modified">3402         __ load_klass(c_rarg4, dst);</span>
3403         __ movptr(c_rarg4, Address(c_rarg4, ObjArrayKlass::element_klass_offset()));
3404         __ movl(c_rarg3, Address(c_rarg4, Klass::super_check_offset_offset()));
3405         __ call(RuntimeAddress(copyfunc_addr));
3406 #endif
3407 
3408 #endif
3409 
3410 #ifndef PRODUCT
3411         if (PrintC1Statistics) {
3412           Label failed;
3413           __ testl(rax, rax);
3414           __ jcc(Assembler::notZero, failed);
3415           __ incrementl(ExternalAddress((address)&amp;Runtime1::_arraycopy_checkcast_cnt));
3416           __ bind(failed);
3417         }
3418 #endif
3419 
3420         __ testl(rax, rax);
3421         __ jcc(Assembler::zero, *stub-&gt;continuation());
3422 
</pre>
<hr />
<pre>
3447 
3448       __ bind(cont);
3449       __ pop(dst);
3450       __ pop(src);
3451     }
3452   }
3453 
3454 #ifdef ASSERT
3455   if (basic_type != T_OBJECT || !(flags &amp; LIR_OpArrayCopy::type_check)) {
3456     // Sanity check the known type with the incoming class.  For the
3457     // primitive case the types must match exactly with src.klass and
3458     // dst.klass each exactly matching the default type.  For the
3459     // object array case, if no type check is needed then either the
3460     // dst type is exactly the expected type and the src type is a
3461     // subtype which we can&#39;t check or src is the same array as dst
3462     // but not necessarily exactly of type default_type.
3463     Label known_ok, halt;
3464     __ mov_metadata(tmp, default_type-&gt;constant_encoding());
3465 #ifdef _LP64
3466     if (UseCompressedClassPointers) {
<span class="line-modified">3467       __ encode_klass_not_null(tmp);</span>
3468     }
3469 #endif
3470 
3471     if (basic_type != T_OBJECT) {
3472 
3473       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3474       else                   __ cmpptr(tmp, dst_klass_addr);
3475       __ jcc(Assembler::notEqual, halt);
3476       if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);
3477       else                   __ cmpptr(tmp, src_klass_addr);
3478       __ jcc(Assembler::equal, known_ok);
3479     } else {
3480       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3481       else                   __ cmpptr(tmp, dst_klass_addr);
3482       __ jcc(Assembler::equal, known_ok);
3483       __ cmpptr(src, dst);
3484       __ jcc(Assembler::equal, known_ok);
3485     }
3486     __ bind(halt);
3487     __ stop(&quot;incorrect type information in arraycopy&quot;);
</pre>
<hr />
<pre>
3552     // add debug info for NullPointerException only if one is possible
3553     int null_check_offset = __ lock_object(hdr, obj, lock, scratch, *op-&gt;stub()-&gt;entry());
3554     if (op-&gt;info() != NULL) {
3555       add_debug_info_for_null_check(null_check_offset, op-&gt;info());
3556     }
3557     // done
3558   } else if (op-&gt;code() == lir_unlock) {
3559     assert(BasicLock::displaced_header_offset_in_bytes() == 0, &quot;lock_reg must point to the displaced header&quot;);
3560     __ unlock_object(hdr, obj, lock, *op-&gt;stub()-&gt;entry());
3561   } else {
3562     Unimplemented();
3563   }
3564   __ bind(*op-&gt;stub()-&gt;continuation());
3565 }
3566 
3567 
3568 void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {
3569   ciMethod* method = op-&gt;profiled_method();
3570   int bci          = op-&gt;profiled_bci();
3571   ciMethod* callee = op-&gt;profiled_callee();

3572 
3573   // Update counter for all call types
3574   ciMethodData* md = method-&gt;method_data_or_null();
3575   assert(md != NULL, &quot;Sanity&quot;);
3576   ciProfileData* data = md-&gt;bci_to_data(bci);
3577   assert(data != NULL &amp;&amp; data-&gt;is_CounterData(), &quot;need CounterData for calls&quot;);
3578   assert(op-&gt;mdo()-&gt;is_single_cpu(),  &quot;mdo must be allocated&quot;);
3579   Register mdo  = op-&gt;mdo()-&gt;as_register();
3580   __ mov_metadata(mdo, md-&gt;constant_encoding());
3581   Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
3582   // Perform additional virtual call profiling for invokevirtual and
3583   // invokeinterface bytecodes
3584   if (op-&gt;should_profile_receiver_type()) {
3585     assert(op-&gt;recv()-&gt;is_single_cpu(), &quot;recv must be allocated&quot;);
3586     Register recv = op-&gt;recv()-&gt;as_register();
3587     assert_different_registers(mdo, recv);
3588     assert(data-&gt;is_VirtualCallData(), &quot;need VirtualCallData for virtual calls&quot;);
3589     ciKlass* known_klass = op-&gt;known_holder();
3590     if (C1OptimizeVirtualCallProfiling &amp;&amp; known_klass != NULL) {
3591       // We know the type that will be seen at this call site; we can
</pre>
<hr />
<pre>
3604           return;
3605         }
3606       }
3607 
3608       // Receiver type not found in profile data; select an empty slot
3609 
3610       // Note that this is less efficient than it should be because it
3611       // always does a write to the receiver part of the
3612       // VirtualCallData rather than just the first time
3613       for (i = 0; i &lt; VirtualCallData::row_limit(); i++) {
3614         ciKlass* receiver = vc_data-&gt;receiver(i);
3615         if (receiver == NULL) {
3616           Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));
3617           __ mov_metadata(recv_addr, known_klass-&gt;constant_encoding());
3618           Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));
3619           __ addptr(data_addr, DataLayout::counter_increment);
3620           return;
3621         }
3622       }
3623     } else {
<span class="line-modified">3624       __ load_klass(recv, recv);</span>
3625       Label update_done;
3626       type_profile_helper(mdo, md, data, recv, &amp;update_done);
3627       // Receiver did not match any saved receiver and there is no empty row for it.
3628       // Increment total counter to indicate polymorphic case.
3629       __ addptr(counter_addr, DataLayout::counter_increment);
3630 
3631       __ bind(update_done);
3632     }
3633   } else {
3634     // Static call
3635     __ addptr(counter_addr, DataLayout::counter_increment);
3636   }
3637 }
3638 
3639 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3640   Register obj = op-&gt;obj()-&gt;as_register();
3641   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();

3642   Address mdo_addr = as_Address(op-&gt;mdp()-&gt;as_address_ptr());
3643   ciKlass* exact_klass = op-&gt;exact_klass();
3644   intptr_t current_klass = op-&gt;current_klass();
3645   bool not_null = op-&gt;not_null();
3646   bool no_conflict = op-&gt;no_conflict();
3647 
3648   Label update, next, none;
3649 
3650   bool do_null = !not_null;
3651   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3652   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3653 
3654   assert(do_null || do_update, &quot;why are we here?&quot;);
3655   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3656 
3657   __ verify_oop(obj);
3658 
3659   if (tmp != obj) {
3660     __ mov(tmp, obj);
3661   }
</pre>
<hr />
<pre>
3668     if (do_update) {
3669 #ifndef ASSERT
3670       __ jmpb(next);
3671     }
3672 #else
3673       __ jmp(next);
3674     }
3675   } else {
3676     __ testptr(tmp, tmp);
3677     __ jcc(Assembler::notZero, update);
3678     __ stop(&quot;unexpect null obj&quot;);
3679 #endif
3680   }
3681 
3682   __ bind(update);
3683 
3684   if (do_update) {
3685 #ifdef ASSERT
3686     if (exact_klass != NULL) {
3687       Label ok;
<span class="line-modified">3688       __ load_klass(tmp, tmp);</span>
3689       __ push(tmp);
3690       __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3691       __ cmpptr(tmp, Address(rsp, 0));
3692       __ jcc(Assembler::equal, ok);
3693       __ stop(&quot;exact klass and actual klass differ&quot;);
3694       __ bind(ok);
3695       __ pop(tmp);
3696     }
3697 #endif
3698     if (!no_conflict) {
3699       if (exact_klass == NULL || TypeEntries::is_type_none(current_klass)) {
3700         if (exact_klass != NULL) {
3701           __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3702         } else {
<span class="line-modified">3703           __ load_klass(tmp, tmp);</span>
3704         }
3705 
3706         __ xorptr(tmp, mdo_addr);
3707         __ testptr(tmp, TypeEntries::type_klass_mask);
3708         // klass seen before, nothing to do. The unknown bit may have been
3709         // set already but no need to check.
3710         __ jccb(Assembler::zero, next);
3711 
3712         __ testptr(tmp, TypeEntries::type_unknown);
3713         __ jccb(Assembler::notZero, next); // already unknown. Nothing to do anymore.
3714 
3715         if (TypeEntries::is_type_none(current_klass)) {
3716           __ cmpptr(mdo_addr, 0);
3717           __ jccb(Assembler::equal, none);
3718           __ cmpptr(mdo_addr, TypeEntries::null_seen);
3719           __ jccb(Assembler::equal, none);
3720           // There is a chance that the checks above (re-reading profiling
3721           // data from memory) fail if another thread has just set the
3722           // profiling to this obj&#39;s klass
3723           __ xorptr(tmp, mdo_addr);
</pre>
</td>
<td>
<hr />
<pre>
1168 #else
1169     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 0));
1170     // push and pop the part at src + wordSize, adding wordSize for the previous push
1171     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1172     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1173     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1174 #endif // _LP64
1175 
1176   } else {
1177     ShouldNotReachHere();
1178   }
1179 }
1180 
1181 
1182 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1183   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1184   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1185 
1186   LIR_Address* addr = src-&gt;as_address_ptr();
1187   Address from_addr = as_Address(addr);
<span class="line-added">1188   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1189 
1190   if (addr-&gt;base()-&gt;type() == T_OBJECT) {
1191     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1192   }
1193 
1194   switch (type) {
1195     case T_BOOLEAN: // fall through
1196     case T_BYTE:    // fall through
1197     case T_CHAR:    // fall through
1198     case T_SHORT:
1199       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1200         // on pre P6 processors we may get partial register stalls
1201         // so blow away the value of to_rinfo before loading a
1202         // partial word into it.  Do it here so that it precedes
1203         // the potential patch point below.
1204         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1205       }
1206       break;
1207    default:
1208      break;
</pre>
<hr />
<pre>
1354   }
1355 
1356   if (patch != NULL) {
1357     patching_epilog(patch, patch_code, addr-&gt;base()-&gt;as_register(), info);
1358   }
1359 
1360   if (is_reference_type(type)) {
1361 #ifdef _LP64
1362     if (UseCompressedOops &amp;&amp; !wide) {
1363       __ decode_heap_oop(dest-&gt;as_register());
1364     }
1365 #endif
1366 
1367     // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1368     if (!UseZGC) {
1369       __ verify_oop(dest-&gt;as_register());
1370     }
1371   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1372 #ifdef _LP64
1373     if (UseCompressedClassPointers) {
<span class="line-modified">1374       __ decode_klass_not_null(dest-&gt;as_register(), tmp_load_klass);</span>
1375     }
1376 #endif
1377   }
1378 }
1379 
1380 
1381 NEEDS_CLEANUP; // This could be static?
1382 Address::ScaleFactor LIR_Assembler::array_element_size(BasicType type) const {
1383   int elem_size = type2aelembytes(type);
1384   switch (elem_size) {
1385     case 1: return Address::times_1;
1386     case 2: return Address::times_2;
1387     case 4: return Address::times_4;
1388     case 8: return Address::times_8;
1389   }
1390   ShouldNotReachHere();
1391   return Address::no_scale;
1392 }
1393 
1394 
</pre>
<hr />
<pre>
1682     Label next_test;
1683     Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_offset(i)));
1684     __ cmpptr(recv_addr, (intptr_t)NULL_WORD);
1685     __ jccb(Assembler::notEqual, next_test);
1686     __ movptr(recv_addr, recv);
1687     __ movptr(Address(mdo, md-&gt;byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);
1688     __ jmp(*update_done);
1689     __ bind(next_test);
1690   }
1691 }
1692 
1693 void LIR_Assembler::emit_typecheck_helper(LIR_OpTypeCheck *op, Label* success, Label* failure, Label* obj_is_null) {
1694   // we always need a stub for the failure case.
1695   CodeStub* stub = op-&gt;stub();
1696   Register obj = op-&gt;object()-&gt;as_register();
1697   Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1698   Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1699   Register dst = op-&gt;result_opr()-&gt;as_register();
1700   ciKlass* k = op-&gt;klass();
1701   Register Rtmp1 = noreg;
<span class="line-added">1702   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1703 
1704   // check if it needs to be profiled
1705   ciMethodData* md = NULL;
1706   ciProfileData* data = NULL;
1707 
1708   if (op-&gt;should_profile()) {
1709     ciMethod* method = op-&gt;profiled_method();
1710     assert(method != NULL, &quot;Should have method&quot;);
1711     int bci = op-&gt;profiled_bci();
1712     md = method-&gt;method_data_or_null();
1713     assert(md != NULL, &quot;Sanity&quot;);
1714     data = md-&gt;bci_to_data(bci);
1715     assert(data != NULL,                &quot;need data for type check&quot;);
1716     assert(data-&gt;is_ReceiverTypeData(), &quot;need ReceiverTypeData for type check&quot;);
1717   }
1718   Label profile_cast_success, profile_cast_failure;
1719   Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : success;
1720   Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : failure;
1721 
1722   if (obj == k_RInfo) {
</pre>
<hr />
<pre>
1746     __ jmp(*obj_is_null);
1747     __ bind(not_null);
1748   } else {
1749     __ jcc(Assembler::equal, *obj_is_null);
1750   }
1751 
1752   if (!k-&gt;is_loaded()) {
1753     klass2reg_with_patching(k_RInfo, op-&gt;info_for_patch());
1754   } else {
1755 #ifdef _LP64
1756     __ mov_metadata(k_RInfo, k-&gt;constant_encoding());
1757 #endif // _LP64
1758   }
1759   __ verify_oop(obj);
1760 
1761   if (op-&gt;fast_check()) {
1762     // get object class
1763     // not a safepoint as obj null check happens earlier
1764 #ifdef _LP64
1765     if (UseCompressedClassPointers) {
<span class="line-modified">1766       __ load_klass(Rtmp1, obj, tmp_load_klass);</span>
1767       __ cmpptr(k_RInfo, Rtmp1);
1768     } else {
1769       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1770     }
1771 #else
1772     if (k-&gt;is_loaded()) {
1773       __ cmpklass(Address(obj, oopDesc::klass_offset_in_bytes()), k-&gt;constant_encoding());
1774     } else {
1775       __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));
1776     }
1777 #endif
1778     __ jcc(Assembler::notEqual, *failure_target);
1779     // successful cast, fall through to profile or jump
1780   } else {
1781     // get object class
1782     // not a safepoint as obj null check happens earlier
<span class="line-modified">1783     __ load_klass(klass_RInfo, obj, tmp_load_klass);</span>
1784     if (k-&gt;is_loaded()) {
1785       // See if we get an immediate positive hit
1786 #ifdef _LP64
1787       __ cmpptr(k_RInfo, Address(klass_RInfo, k-&gt;super_check_offset()));
1788 #else
1789       __ cmpklass(Address(klass_RInfo, k-&gt;super_check_offset()), k-&gt;constant_encoding());
1790 #endif // _LP64
1791       if ((juint)in_bytes(Klass::secondary_super_cache_offset()) != k-&gt;super_check_offset()) {
1792         __ jcc(Assembler::notEqual, *failure_target);
1793         // successful cast, fall through to profile or jump
1794       } else {
1795         // See if we get an immediate positive hit
1796         __ jcc(Assembler::equal, *success_target);
1797         // check for self
1798 #ifdef _LP64
1799         __ cmpptr(klass_RInfo, k_RInfo);
1800 #else
1801         __ cmpklass(klass_RInfo, k-&gt;constant_encoding());
1802 #endif // _LP64
1803         __ jcc(Assembler::equal, *success_target);
</pre>
<hr />
<pre>
1818       }
1819     } else {
1820       // perform the fast part of the checking logic
1821       __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1822       // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1823       __ push(klass_RInfo);
1824       __ push(k_RInfo);
1825       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1826       __ pop(klass_RInfo);
1827       __ pop(k_RInfo);
1828       // result is a boolean
1829       __ cmpl(k_RInfo, 0);
1830       __ jcc(Assembler::equal, *failure_target);
1831       // successful cast, fall through to profile or jump
1832     }
1833   }
1834   if (op-&gt;should_profile()) {
1835     Register mdo  = klass_RInfo, recv = k_RInfo;
1836     __ bind(profile_cast_success);
1837     __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1838     __ load_klass(recv, obj, tmp_load_klass);</span>
1839     type_profile_helper(mdo, md, data, recv, success);
1840     __ jmp(*success);
1841 
1842     __ bind(profile_cast_failure);
1843     __ mov_metadata(mdo, md-&gt;constant_encoding());
1844     Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1845     __ subptr(counter_addr, DataLayout::counter_increment);
1846     __ jmp(*failure);
1847   }
1848   __ jmp(*success);
1849 }
1850 
1851 
1852 void LIR_Assembler::emit_opTypeCheck(LIR_OpTypeCheck* op) {
<span class="line-added">1853   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
1854   LIR_Code code = op-&gt;code();
1855   if (code == lir_store_check) {
1856     Register value = op-&gt;object()-&gt;as_register();
1857     Register array = op-&gt;array()-&gt;as_register();
1858     Register k_RInfo = op-&gt;tmp1()-&gt;as_register();
1859     Register klass_RInfo = op-&gt;tmp2()-&gt;as_register();
1860     Register Rtmp1 = op-&gt;tmp3()-&gt;as_register();
1861 
1862     CodeStub* stub = op-&gt;stub();
1863 
1864     // check if it needs to be profiled
1865     ciMethodData* md = NULL;
1866     ciProfileData* data = NULL;
1867 
1868     if (op-&gt;should_profile()) {
1869       ciMethod* method = op-&gt;profiled_method();
1870       assert(method != NULL, &quot;Should have method&quot;);
1871       int bci = op-&gt;profiled_bci();
1872       md = method-&gt;method_data_or_null();
1873       assert(md != NULL, &quot;Sanity&quot;);
</pre>
<hr />
<pre>
1879     Label *success_target = op-&gt;should_profile() ? &amp;profile_cast_success : &amp;done;
1880     Label *failure_target = op-&gt;should_profile() ? &amp;profile_cast_failure : stub-&gt;entry();
1881 
1882     __ cmpptr(value, (int32_t)NULL_WORD);
1883     if (op-&gt;should_profile()) {
1884       Label not_null;
1885       __ jccb(Assembler::notEqual, not_null);
1886       // Object is null; update MDO and exit
1887       Register mdo  = klass_RInfo;
1888       __ mov_metadata(mdo, md-&gt;constant_encoding());
1889       Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, DataLayout::flags_offset()));
1890       int header_bits = BitData::null_seen_byte_constant();
1891       __ orb(data_addr, header_bits);
1892       __ jmp(done);
1893       __ bind(not_null);
1894     } else {
1895       __ jcc(Assembler::equal, done);
1896     }
1897 
1898     add_debug_info_for_null_check_here(op-&gt;info_for_exception());
<span class="line-modified">1899     __ load_klass(k_RInfo, array, tmp_load_klass);</span>
<span class="line-modified">1900     __ load_klass(klass_RInfo, value, tmp_load_klass);</span>
1901 
1902     // get instance klass (it&#39;s already uncompressed)
1903     __ movptr(k_RInfo, Address(k_RInfo, ObjArrayKlass::element_klass_offset()));
1904     // perform the fast part of the checking logic
1905     __ check_klass_subtype_fast_path(klass_RInfo, k_RInfo, Rtmp1, success_target, failure_target, NULL);
1906     // call out-of-line instance of __ check_klass_subtype_slow_path(...):
1907     __ push(klass_RInfo);
1908     __ push(k_RInfo);
1909     __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
1910     __ pop(klass_RInfo);
1911     __ pop(k_RInfo);
1912     // result is a boolean
1913     __ cmpl(k_RInfo, 0);
1914     __ jcc(Assembler::equal, *failure_target);
1915     // fall through to the success case
1916 
1917     if (op-&gt;should_profile()) {
1918       Register mdo  = klass_RInfo, recv = k_RInfo;
1919       __ bind(profile_cast_success);
1920       __ mov_metadata(mdo, md-&gt;constant_encoding());
<span class="line-modified">1921       __ load_klass(recv, value, tmp_load_klass);</span>
1922       type_profile_helper(mdo, md, data, recv, &amp;done);
1923       __ jmpb(done);
1924 
1925       __ bind(profile_cast_failure);
1926       __ mov_metadata(mdo, md-&gt;constant_encoding());
1927       Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
1928       __ subptr(counter_addr, DataLayout::counter_increment);
1929       __ jmp(*stub-&gt;entry());
1930     }
1931 
1932     __ bind(done);
1933   } else
1934     if (code == lir_checkcast) {
1935       Register obj = op-&gt;object()-&gt;as_register();
1936       Register dst = op-&gt;result_opr()-&gt;as_register();
1937       Label success;
1938       emit_typecheck_helper(op, &amp;success, op-&gt;stub()-&gt;entry(), &amp;success);
1939       __ bind(success);
1940       if (dst != obj) {
1941         __ mov(dst, obj);
</pre>
<hr />
<pre>
3093 
3094 void LIR_Assembler::store_parameter(Metadata* m,  int offset_from_rsp_in_words) {
3095   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
3096   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
3097   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
3098   __ mov_metadata(Address(rsp, offset_from_rsp_in_bytes), m);
3099 }
3100 
3101 
3102 // This code replaces a call to arraycopy; no exception may
3103 // be thrown in this code, they must be thrown in the System.arraycopy
3104 // activation frame; we could save some checks if this would not be the case
3105 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
3106   ciArrayKlass* default_type = op-&gt;expected_type();
3107   Register src = op-&gt;src()-&gt;as_register();
3108   Register dst = op-&gt;dst()-&gt;as_register();
3109   Register src_pos = op-&gt;src_pos()-&gt;as_register();
3110   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
3111   Register length  = op-&gt;length()-&gt;as_register();
3112   Register tmp = op-&gt;tmp()-&gt;as_register();
<span class="line-added">3113   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3114 
3115   __ resolve(ACCESS_READ, src);
3116   __ resolve(ACCESS_WRITE, dst);
3117 
3118   CodeStub* stub = op-&gt;stub();
3119   int flags = op-&gt;flags();
3120   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
3121   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
3122 
3123   // if we don&#39;t know anything, just go through the generic arraycopy
3124   if (default_type == NULL) {
3125     // save outgoing arguments on stack in case call to System.arraycopy is needed
3126     // HACK ALERT. This code used to push the parameters in a hardwired fashion
3127     // for interpreter calling conventions. Now we have to do it in new style conventions.
3128     // For the moment until C1 gets the new register allocator I just force all the
3129     // args to the right place (except the register args) and then on the back side
3130     // reload the register args properly if we go slow path. Yuck
3131 
3132     // These are proper for the calling convention
3133     store_parameter(length, 2);
</pre>
<hr />
<pre>
3241   Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());
3242   Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());
3243 
3244   // length and pos&#39;s are all sign extended at this point on 64bit
3245 
3246   // test for NULL
3247   if (flags &amp; LIR_OpArrayCopy::src_null_check) {
3248     __ testptr(src, src);
3249     __ jcc(Assembler::zero, *stub-&gt;entry());
3250   }
3251   if (flags &amp; LIR_OpArrayCopy::dst_null_check) {
3252     __ testptr(dst, dst);
3253     __ jcc(Assembler::zero, *stub-&gt;entry());
3254   }
3255 
3256   // If the compiler was not able to prove that exact type of the source or the destination
3257   // of the arraycopy is an array type, check at runtime if the source or the destination is
3258   // an instance type.
3259   if (flags &amp; LIR_OpArrayCopy::type_check) {
3260     if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3261       __ load_klass(tmp, dst, tmp_load_klass);</span>
3262       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3263       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3264     }
3265 
3266     if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3267       __ load_klass(tmp, src, tmp_load_klass);</span>
3268       __ cmpl(Address(tmp, in_bytes(Klass::layout_helper_offset())), Klass::_lh_neutral_value);
3269       __ jcc(Assembler::greaterEqual, *stub-&gt;entry());
3270     }
3271   }
3272 
3273   // check if negative
3274   if (flags &amp; LIR_OpArrayCopy::src_pos_positive_check) {
3275     __ testl(src_pos, src_pos);
3276     __ jcc(Assembler::less, *stub-&gt;entry());
3277   }
3278   if (flags &amp; LIR_OpArrayCopy::dst_pos_positive_check) {
3279     __ testl(dst_pos, dst_pos);
3280     __ jcc(Assembler::less, *stub-&gt;entry());
3281   }
3282 
3283   if (flags &amp; LIR_OpArrayCopy::src_range_check) {
3284     __ lea(tmp, Address(src_pos, length, Address::times_1, 0));
3285     __ cmpl(tmp, src_length_addr);
3286     __ jcc(Assembler::above, *stub-&gt;entry());
3287   }
</pre>
<hr />
<pre>
3304   if (flags &amp; LIR_OpArrayCopy::type_check) {
3305     // We don&#39;t know the array types are compatible
3306     if (basic_type != T_OBJECT) {
3307       // Simple test for basic type arrays
3308       if (UseCompressedClassPointers) {
3309         __ movl(tmp, src_klass_addr);
3310         __ cmpl(tmp, dst_klass_addr);
3311       } else {
3312         __ movptr(tmp, src_klass_addr);
3313         __ cmpptr(tmp, dst_klass_addr);
3314       }
3315       __ jcc(Assembler::notEqual, *stub-&gt;entry());
3316     } else {
3317       // For object arrays, if src is a sub class of dst then we can
3318       // safely do the copy.
3319       Label cont, slow;
3320 
3321       __ push(src);
3322       __ push(dst);
3323 
<span class="line-modified">3324       __ load_klass(src, src, tmp_load_klass);</span>
<span class="line-modified">3325       __ load_klass(dst, dst, tmp_load_klass);</span>
3326 
3327       __ check_klass_subtype_fast_path(src, dst, tmp, &amp;cont, &amp;slow, NULL);
3328 
3329       __ push(src);
3330       __ push(dst);
3331       __ call(RuntimeAddress(Runtime1::entry_for(Runtime1::slow_subtype_check_id)));
3332       __ pop(dst);
3333       __ pop(src);
3334 
3335       __ cmpl(src, 0);
3336       __ jcc(Assembler::notEqual, cont);
3337 
3338       __ bind(slow);
3339       __ pop(dst);
3340       __ pop(src);
3341 
3342       address copyfunc_addr = StubRoutines::checkcast_arraycopy();
3343       if (copyfunc_addr != NULL) { // use stub if available
3344         // src is not a sub class of dst so we have to do a
3345         // per-element check.
3346 
3347         int mask = LIR_OpArrayCopy::src_objarray|LIR_OpArrayCopy::dst_objarray;
3348         if ((flags &amp; mask) != mask) {
3349           // Check that at least both of them object arrays.
3350           assert(flags &amp; mask, &quot;one of the two should be known to be an object array&quot;);
3351 
3352           if (!(flags &amp; LIR_OpArrayCopy::src_objarray)) {
<span class="line-modified">3353             __ load_klass(tmp, src, tmp_load_klass);</span>
3354           } else if (!(flags &amp; LIR_OpArrayCopy::dst_objarray)) {
<span class="line-modified">3355             __ load_klass(tmp, dst, tmp_load_klass);</span>
3356           }
3357           int lh_offset = in_bytes(Klass::layout_helper_offset());
3358           Address klass_lh_addr(tmp, lh_offset);
3359           jint objArray_lh = Klass::array_layout_helper(T_OBJECT);
3360           __ cmpl(klass_lh_addr, objArray_lh);
3361           __ jcc(Assembler::notEqual, *stub-&gt;entry());
3362         }
3363 
3364        // Spill because stubs can use any register they like and it&#39;s
3365        // easier to restore just those that we care about.
3366        store_parameter(dst, 0);
3367        store_parameter(dst_pos, 1);
3368        store_parameter(length, 2);
3369        store_parameter(src_pos, 3);
3370        store_parameter(src, 4);
3371 
3372 #ifndef _LP64
3373         __ movptr(tmp, dst_klass_addr);
3374         __ movptr(tmp, Address(tmp, ObjArrayKlass::element_klass_offset()));
3375         __ push(tmp);
</pre>
<hr />
<pre>
3379         __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3380         __ push(tmp);
3381         __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3382         __ push(tmp);
3383 
3384         __ call_VM_leaf(copyfunc_addr, 5);
3385 #else
3386         __ movl2ptr(length, length); //higher 32bits must be null
3387 
3388         __ lea(c_rarg0, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3389         assert_different_registers(c_rarg0, dst, dst_pos, length);
3390         __ lea(c_rarg1, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));
3391         assert_different_registers(c_rarg1, dst, length);
3392 
3393         __ mov(c_rarg2, length);
3394         assert_different_registers(c_rarg2, dst);
3395 
3396 #ifdef _WIN64
3397         // Allocate abi space for args but be sure to keep stack aligned
3398         __ subptr(rsp, 6*wordSize);
<span class="line-modified">3399         __ load_klass(c_rarg3, dst, tmp_load_klass);</span>
3400         __ movptr(c_rarg3, Address(c_rarg3, ObjArrayKlass::element_klass_offset()));
3401         store_parameter(c_rarg3, 4);
3402         __ movl(c_rarg3, Address(c_rarg3, Klass::super_check_offset_offset()));
3403         __ call(RuntimeAddress(copyfunc_addr));
3404         __ addptr(rsp, 6*wordSize);
3405 #else
<span class="line-modified">3406         __ load_klass(c_rarg4, dst, tmp_load_klass);</span>
3407         __ movptr(c_rarg4, Address(c_rarg4, ObjArrayKlass::element_klass_offset()));
3408         __ movl(c_rarg3, Address(c_rarg4, Klass::super_check_offset_offset()));
3409         __ call(RuntimeAddress(copyfunc_addr));
3410 #endif
3411 
3412 #endif
3413 
3414 #ifndef PRODUCT
3415         if (PrintC1Statistics) {
3416           Label failed;
3417           __ testl(rax, rax);
3418           __ jcc(Assembler::notZero, failed);
3419           __ incrementl(ExternalAddress((address)&amp;Runtime1::_arraycopy_checkcast_cnt));
3420           __ bind(failed);
3421         }
3422 #endif
3423 
3424         __ testl(rax, rax);
3425         __ jcc(Assembler::zero, *stub-&gt;continuation());
3426 
</pre>
<hr />
<pre>
3451 
3452       __ bind(cont);
3453       __ pop(dst);
3454       __ pop(src);
3455     }
3456   }
3457 
3458 #ifdef ASSERT
3459   if (basic_type != T_OBJECT || !(flags &amp; LIR_OpArrayCopy::type_check)) {
3460     // Sanity check the known type with the incoming class.  For the
3461     // primitive case the types must match exactly with src.klass and
3462     // dst.klass each exactly matching the default type.  For the
3463     // object array case, if no type check is needed then either the
3464     // dst type is exactly the expected type and the src type is a
3465     // subtype which we can&#39;t check or src is the same array as dst
3466     // but not necessarily exactly of type default_type.
3467     Label known_ok, halt;
3468     __ mov_metadata(tmp, default_type-&gt;constant_encoding());
3469 #ifdef _LP64
3470     if (UseCompressedClassPointers) {
<span class="line-modified">3471       __ encode_klass_not_null(tmp, rscratch1);</span>
3472     }
3473 #endif
3474 
3475     if (basic_type != T_OBJECT) {
3476 
3477       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3478       else                   __ cmpptr(tmp, dst_klass_addr);
3479       __ jcc(Assembler::notEqual, halt);
3480       if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);
3481       else                   __ cmpptr(tmp, src_klass_addr);
3482       __ jcc(Assembler::equal, known_ok);
3483     } else {
3484       if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);
3485       else                   __ cmpptr(tmp, dst_klass_addr);
3486       __ jcc(Assembler::equal, known_ok);
3487       __ cmpptr(src, dst);
3488       __ jcc(Assembler::equal, known_ok);
3489     }
3490     __ bind(halt);
3491     __ stop(&quot;incorrect type information in arraycopy&quot;);
</pre>
<hr />
<pre>
3556     // add debug info for NullPointerException only if one is possible
3557     int null_check_offset = __ lock_object(hdr, obj, lock, scratch, *op-&gt;stub()-&gt;entry());
3558     if (op-&gt;info() != NULL) {
3559       add_debug_info_for_null_check(null_check_offset, op-&gt;info());
3560     }
3561     // done
3562   } else if (op-&gt;code() == lir_unlock) {
3563     assert(BasicLock::displaced_header_offset_in_bytes() == 0, &quot;lock_reg must point to the displaced header&quot;);
3564     __ unlock_object(hdr, obj, lock, *op-&gt;stub()-&gt;entry());
3565   } else {
3566     Unimplemented();
3567   }
3568   __ bind(*op-&gt;stub()-&gt;continuation());
3569 }
3570 
3571 
3572 void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {
3573   ciMethod* method = op-&gt;profiled_method();
3574   int bci          = op-&gt;profiled_bci();
3575   ciMethod* callee = op-&gt;profiled_callee();
<span class="line-added">3576   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3577 
3578   // Update counter for all call types
3579   ciMethodData* md = method-&gt;method_data_or_null();
3580   assert(md != NULL, &quot;Sanity&quot;);
3581   ciProfileData* data = md-&gt;bci_to_data(bci);
3582   assert(data != NULL &amp;&amp; data-&gt;is_CounterData(), &quot;need CounterData for calls&quot;);
3583   assert(op-&gt;mdo()-&gt;is_single_cpu(),  &quot;mdo must be allocated&quot;);
3584   Register mdo  = op-&gt;mdo()-&gt;as_register();
3585   __ mov_metadata(mdo, md-&gt;constant_encoding());
3586   Address counter_addr(mdo, md-&gt;byte_offset_of_slot(data, CounterData::count_offset()));
3587   // Perform additional virtual call profiling for invokevirtual and
3588   // invokeinterface bytecodes
3589   if (op-&gt;should_profile_receiver_type()) {
3590     assert(op-&gt;recv()-&gt;is_single_cpu(), &quot;recv must be allocated&quot;);
3591     Register recv = op-&gt;recv()-&gt;as_register();
3592     assert_different_registers(mdo, recv);
3593     assert(data-&gt;is_VirtualCallData(), &quot;need VirtualCallData for virtual calls&quot;);
3594     ciKlass* known_klass = op-&gt;known_holder();
3595     if (C1OptimizeVirtualCallProfiling &amp;&amp; known_klass != NULL) {
3596       // We know the type that will be seen at this call site; we can
</pre>
<hr />
<pre>
3609           return;
3610         }
3611       }
3612 
3613       // Receiver type not found in profile data; select an empty slot
3614 
3615       // Note that this is less efficient than it should be because it
3616       // always does a write to the receiver part of the
3617       // VirtualCallData rather than just the first time
3618       for (i = 0; i &lt; VirtualCallData::row_limit(); i++) {
3619         ciKlass* receiver = vc_data-&gt;receiver(i);
3620         if (receiver == NULL) {
3621           Address recv_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));
3622           __ mov_metadata(recv_addr, known_klass-&gt;constant_encoding());
3623           Address data_addr(mdo, md-&gt;byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));
3624           __ addptr(data_addr, DataLayout::counter_increment);
3625           return;
3626         }
3627       }
3628     } else {
<span class="line-modified">3629       __ load_klass(recv, recv, tmp_load_klass);</span>
3630       Label update_done;
3631       type_profile_helper(mdo, md, data, recv, &amp;update_done);
3632       // Receiver did not match any saved receiver and there is no empty row for it.
3633       // Increment total counter to indicate polymorphic case.
3634       __ addptr(counter_addr, DataLayout::counter_increment);
3635 
3636       __ bind(update_done);
3637     }
3638   } else {
3639     // Static call
3640     __ addptr(counter_addr, DataLayout::counter_increment);
3641   }
3642 }
3643 
3644 void LIR_Assembler::emit_profile_type(LIR_OpProfileType* op) {
3645   Register obj = op-&gt;obj()-&gt;as_register();
3646   Register tmp = op-&gt;tmp()-&gt;as_pointer_register();
<span class="line-added">3647   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);</span>
3648   Address mdo_addr = as_Address(op-&gt;mdp()-&gt;as_address_ptr());
3649   ciKlass* exact_klass = op-&gt;exact_klass();
3650   intptr_t current_klass = op-&gt;current_klass();
3651   bool not_null = op-&gt;not_null();
3652   bool no_conflict = op-&gt;no_conflict();
3653 
3654   Label update, next, none;
3655 
3656   bool do_null = !not_null;
3657   bool exact_klass_set = exact_klass != NULL &amp;&amp; ciTypeEntries::valid_ciklass(current_klass) == exact_klass;
3658   bool do_update = !TypeEntries::is_type_unknown(current_klass) &amp;&amp; !exact_klass_set;
3659 
3660   assert(do_null || do_update, &quot;why are we here?&quot;);
3661   assert(!TypeEntries::was_null_seen(current_klass) || do_update, &quot;why are we here?&quot;);
3662 
3663   __ verify_oop(obj);
3664 
3665   if (tmp != obj) {
3666     __ mov(tmp, obj);
3667   }
</pre>
<hr />
<pre>
3674     if (do_update) {
3675 #ifndef ASSERT
3676       __ jmpb(next);
3677     }
3678 #else
3679       __ jmp(next);
3680     }
3681   } else {
3682     __ testptr(tmp, tmp);
3683     __ jcc(Assembler::notZero, update);
3684     __ stop(&quot;unexpect null obj&quot;);
3685 #endif
3686   }
3687 
3688   __ bind(update);
3689 
3690   if (do_update) {
3691 #ifdef ASSERT
3692     if (exact_klass != NULL) {
3693       Label ok;
<span class="line-modified">3694       __ load_klass(tmp, tmp, tmp_load_klass);</span>
3695       __ push(tmp);
3696       __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3697       __ cmpptr(tmp, Address(rsp, 0));
3698       __ jcc(Assembler::equal, ok);
3699       __ stop(&quot;exact klass and actual klass differ&quot;);
3700       __ bind(ok);
3701       __ pop(tmp);
3702     }
3703 #endif
3704     if (!no_conflict) {
3705       if (exact_klass == NULL || TypeEntries::is_type_none(current_klass)) {
3706         if (exact_klass != NULL) {
3707           __ mov_metadata(tmp, exact_klass-&gt;constant_encoding());
3708         } else {
<span class="line-modified">3709           __ load_klass(tmp, tmp, tmp_load_klass);</span>
3710         }
3711 
3712         __ xorptr(tmp, mdo_addr);
3713         __ testptr(tmp, TypeEntries::type_klass_mask);
3714         // klass seen before, nothing to do. The unknown bit may have been
3715         // set already but no need to check.
3716         __ jccb(Assembler::zero, next);
3717 
3718         __ testptr(tmp, TypeEntries::type_unknown);
3719         __ jccb(Assembler::notZero, next); // already unknown. Nothing to do anymore.
3720 
3721         if (TypeEntries::is_type_none(current_klass)) {
3722           __ cmpptr(mdo_addr, 0);
3723           __ jccb(Assembler::equal, none);
3724           __ cmpptr(mdo_addr, TypeEntries::null_seen);
3725           __ jccb(Assembler::equal, none);
3726           // There is a chance that the checks above (re-reading profiling
3727           // data from memory) fail if another thread has just set the
3728           // profiling to this obj&#39;s klass
3729           __ xorptr(tmp, mdo_addr);
</pre>
</td>
</tr>
</table>
<center><a href="c1_FrameMap_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_MacroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>