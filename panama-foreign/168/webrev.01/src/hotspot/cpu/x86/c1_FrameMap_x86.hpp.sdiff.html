<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_FrameMap_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../sparc/globalDefinitions_sparc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_FrameMap_x86.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
131   static LIR_Opr as_pointer_opr(Register r) {
132     return LIR_OprFact::single_cpu(cpu_reg2rnr(r));
133   }
134 #endif // _LP64
135 
136   // VMReg name for spilled physical FPU stack slot n
137   static VMReg fpu_regname (int n);
138 
139   static XMMRegister nr2xmmreg(int rnr);
140 
141   static bool is_caller_save_register (LIR_Opr opr) { return true; }
142   static bool is_caller_save_register (Register r) { return true; }
143 
144   static LIR_Opr caller_save_xmm_reg_at(int i) {
145     assert(i &gt;= 0 &amp;&amp; i &lt; nof_caller_save_xmm_regs, &quot;out of bounds&quot;);
146     return _caller_save_xmm_regs[i];
147   }
148 
149   static int adjust_reg_range(int range) {
150     // Reduce the number of available regs (to free r12) in case of compressed oops
<span class="line-modified">151     if (UseCompressedOops || UseCompressedClassPointers) return range - 1;</span>
152     return range;
153   }
154 
155   static int get_num_caller_save_xmms(void) {
156     int num_caller_save_xmm_regs = nof_caller_save_xmm_regs;
157 #ifdef _LP64
158     if (UseAVX &lt; 3) {
159       num_caller_save_xmm_regs = num_caller_save_xmm_regs / 2;
160     }
161 #endif
162     return num_caller_save_xmm_regs;
163   }
164 
165   static int nof_caller_save_cpu_regs() { return adjust_reg_range(pd_nof_caller_save_cpu_regs_frame_map); }
166   static int last_cpu_reg()             { return adjust_reg_range(pd_last_cpu_reg);  }
167   static int last_byte_reg()            { return adjust_reg_range(pd_last_byte_reg); }
168 
169 #endif // CPU_X86_C1_FRAMEMAP_X86_HPP
</pre>
</td>
<td>
<hr />
<pre>
131   static LIR_Opr as_pointer_opr(Register r) {
132     return LIR_OprFact::single_cpu(cpu_reg2rnr(r));
133   }
134 #endif // _LP64
135 
136   // VMReg name for spilled physical FPU stack slot n
137   static VMReg fpu_regname (int n);
138 
139   static XMMRegister nr2xmmreg(int rnr);
140 
141   static bool is_caller_save_register (LIR_Opr opr) { return true; }
142   static bool is_caller_save_register (Register r) { return true; }
143 
144   static LIR_Opr caller_save_xmm_reg_at(int i) {
145     assert(i &gt;= 0 &amp;&amp; i &lt; nof_caller_save_xmm_regs, &quot;out of bounds&quot;);
146     return _caller_save_xmm_regs[i];
147   }
148 
149   static int adjust_reg_range(int range) {
150     // Reduce the number of available regs (to free r12) in case of compressed oops
<span class="line-modified">151     if (UseCompressedOops) return range - 1;</span>
152     return range;
153   }
154 
155   static int get_num_caller_save_xmms(void) {
156     int num_caller_save_xmm_regs = nof_caller_save_xmm_regs;
157 #ifdef _LP64
158     if (UseAVX &lt; 3) {
159       num_caller_save_xmm_regs = num_caller_save_xmm_regs / 2;
160     }
161 #endif
162     return num_caller_save_xmm_regs;
163   }
164 
165   static int nof_caller_save_cpu_regs() { return adjust_reg_range(pd_nof_caller_save_cpu_regs_frame_map); }
166   static int last_cpu_reg()             { return adjust_reg_range(pd_last_cpu_reg);  }
167   static int last_byte_reg()            { return adjust_reg_range(pd_last_byte_reg); }
168 
169 #endif // CPU_X86_C1_FRAMEMAP_X86_HPP
</pre>
</td>
</tr>
</table>
<center><a href="../sparc/globalDefinitions_sparc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>