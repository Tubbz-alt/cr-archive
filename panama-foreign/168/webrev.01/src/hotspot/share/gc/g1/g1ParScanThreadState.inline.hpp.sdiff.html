<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1ParScanThreadState.inline.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1ParScanThreadState.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1RemSet.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1ParScanThreadState.inline.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2014, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 54   }
 55 
 56   markWord m = obj-&gt;mark_raw();
 57   if (m.is_marked()) {
 58     obj = (oop) m.decode_pointer();
 59   } else {
 60     obj = copy_to_survivor_space(region_attr, obj, m);
 61   }
 62   RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, obj);
 63 
 64   assert(obj != NULL, &quot;Must be&quot;);
 65   if (HeapRegion::is_in_same_region(p, obj)) {
 66     return;
 67   }
 68   HeapRegion* from = _g1h-&gt;heap_region_containing(p);
 69   if (!from-&gt;is_young()) {
 70     enqueue_card_if_tracked(_g1h-&gt;region_attr(obj), p, obj);
 71   }
 72 }
 73 
<span class="line-modified"> 74 template &lt;class T&gt; inline void G1ParScanThreadState::push_on_queue(T* ref) {</span>
<span class="line-modified"> 75   assert(verify_ref(ref), &quot;sanity&quot;);</span>
<span class="line-modified"> 76   _refs-&gt;push(ref);</span>
 77 }
 78 
<span class="line-modified"> 79 inline void G1ParScanThreadState::do_oop_partial_array(oop* p) {</span>
<span class="line-modified"> 80   assert(has_partial_array_mask(p), &quot;invariant&quot;);</span>
<span class="line-removed"> 81   oop from_obj = clear_partial_array_mask(p);</span>
 82 
 83   assert(_g1h-&gt;is_in_reserved(from_obj), &quot;must be in heap.&quot;);
 84   assert(from_obj-&gt;is_objArray(), &quot;must be obj array&quot;);
 85   objArrayOop from_obj_array = objArrayOop(from_obj);
 86   // The from-space object contains the real length.
 87   int length                 = from_obj_array-&gt;length();
 88 
 89   assert(from_obj-&gt;is_forwarded(), &quot;must be forwarded&quot;);
 90   oop to_obj                 = from_obj-&gt;forwardee();
 91   assert(from_obj != to_obj, &quot;should not be chunking self-forwarded objects&quot;);
 92   objArrayOop to_obj_array   = objArrayOop(to_obj);
 93   // We keep track of the next start index in the length field of the
 94   // to-space object.
 95   int next_index             = to_obj_array-&gt;length();
 96   assert(0 &lt;= next_index &amp;&amp; next_index &lt; length,
 97          &quot;invariant, next index: %d, length: %d&quot;, next_index, length);
 98 
 99   int start                  = next_index;
100   int end                    = length;
101   int remainder              = end - start;
102   // We&#39;ll try not to push a range that&#39;s smaller than ParGCArrayScanChunk.
103   if (remainder &gt; 2 * ParGCArrayScanChunk) {
104     end = start + ParGCArrayScanChunk;
105     to_obj_array-&gt;set_length(end);
106     // Push the remainder before we process the range in case another
107     // worker has run out of things to do and can steal it.
<span class="line-modified">108     oop* from_obj_p = set_partial_array_mask(from_obj);</span>
<span class="line-removed">109     push_on_queue(from_obj_p);</span>
110   } else {
111     assert(length == end, &quot;sanity&quot;);
112     // We&#39;ll process the final range for this object. Restore the length
113     // so that the heap remains parsable in case of evacuation failure.
114     to_obj_array-&gt;set_length(end);
115   }
116 
117   HeapRegion* hr = _g1h-&gt;heap_region_containing(to_obj);
118   G1ScanInYoungSetter x(&amp;_scanner, hr-&gt;is_young());
119   // Process indexes [start,end). It will also process the header
120   // along with the first chunk (i.e., the chunk with start == 0).
121   // Note that at this point the length field of to_obj_array is not
122   // correct given that we are using it to keep track of the next
123   // start index. oop_iterate_range() (thankfully!) ignores the length
124   // field and only relies on the start / end parameters.  It does
125   // however return the size of the object which will be incorrect. So
126   // we have to ignore it even if we wanted to use it.
127   to_obj_array-&gt;oop_iterate_range(&amp;_scanner, start, end);
128 }
129 
<span class="line-modified">130 inline void G1ParScanThreadState::deal_with_reference(oop* ref_to_scan) {</span>
<span class="line-modified">131   if (!has_partial_array_mask(ref_to_scan)) {</span>
<span class="line-modified">132     do_oop_evac(ref_to_scan);</span>



133   } else {
<span class="line-modified">134     do_oop_partial_array(ref_to_scan);</span>
135   }
136 }
137 
<span class="line-modified">138 inline void G1ParScanThreadState::deal_with_reference(narrowOop* ref_to_scan) {</span>
<span class="line-modified">139   assert(!has_partial_array_mask(ref_to_scan), &quot;NarrowOop* elements should never be partial arrays.&quot;);</span>
<span class="line-removed">140   do_oop_evac(ref_to_scan);</span>
<span class="line-removed">141 }</span>
<span class="line-removed">142 </span>
<span class="line-removed">143 inline void G1ParScanThreadState::dispatch_reference(StarTask ref) {</span>
<span class="line-removed">144   assert(verify_task(ref), &quot;sanity&quot;);</span>
<span class="line-removed">145   if (ref.is_narrow()) {</span>
<span class="line-removed">146     deal_with_reference((narrowOop*)ref);</span>
<span class="line-removed">147   } else {</span>
<span class="line-removed">148     deal_with_reference((oop*)ref);</span>
<span class="line-removed">149   }</span>
<span class="line-removed">150 }</span>
<span class="line-removed">151 </span>
<span class="line-removed">152 void G1ParScanThreadState::steal_and_trim_queue(RefToScanQueueSet *task_queues) {</span>
<span class="line-removed">153   StarTask stolen_task;</span>
154   while (task_queues-&gt;steal(_worker_id, stolen_task)) {
<span class="line-modified">155     assert(verify_task(stolen_task), &quot;sanity&quot;);</span>
<span class="line-removed">156     dispatch_reference(stolen_task);</span>
157 
<span class="line-modified">158     // We&#39;ve just processed a reference and we might have made</span>
159     // available new entries on the queues. So we have to make sure
160     // we drain the queues as necessary.
161     trim_queue();
162   }
163 }
164 
165 inline bool G1ParScanThreadState::needs_partial_trimming() const {
<span class="line-modified">166   return !_refs-&gt;overflow_empty() || _refs-&gt;size() &gt; _stack_trim_upper_threshold;</span>

167 }
168 
169 inline bool G1ParScanThreadState::is_partially_trimmed() const {
<span class="line-modified">170   return _refs-&gt;overflow_empty() &amp;&amp; _refs-&gt;size() &lt;= _stack_trim_lower_threshold;</span>

171 }
172 
173 inline void G1ParScanThreadState::trim_queue_to_threshold(uint threshold) {
<span class="line-modified">174   StarTask ref;</span>
175   // Drain the overflow stack first, so other threads can potentially steal.
<span class="line-modified">176   while (_refs-&gt;pop_overflow(ref)) {</span>
<span class="line-modified">177     if (!_refs-&gt;try_push_to_taskqueue(ref)) {</span>
<span class="line-modified">178       dispatch_reference(ref);</span>
179     }
180   }
181 
<span class="line-modified">182   while (_refs-&gt;pop_local(ref, threshold)) {</span>
<span class="line-modified">183     dispatch_reference(ref);</span>
184   }
185 }
186 
187 inline void G1ParScanThreadState::trim_queue_partially() {
188   if (!needs_partial_trimming()) {
189     return;
190   }
191 
192   const Ticks start = Ticks::now();
193   do {
194     trim_queue_to_threshold(_stack_trim_lower_threshold);
195   } while (!is_partially_trimmed());
196   _trim_ticks += Ticks::now() - start;
197 }
198 
199 inline Tickspan G1ParScanThreadState::trim_ticks() const {
200   return _trim_ticks;
201 }
202 
203 inline void G1ParScanThreadState::reset_trim_ticks() {
204   _trim_ticks = Tickspan();
205 }
206 
207 template &lt;typename T&gt;
208 inline void G1ParScanThreadState::remember_root_into_optional_region(T* p) {
209   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
210   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
211   assert(index &lt; _num_optional_regions,
212          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
213   _oops_into_optional_regions[index].push_root(p);
214 }
215 
216 template &lt;typename T&gt;
217 inline void G1ParScanThreadState::remember_reference_into_optional_region(T* p) {
218   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
219   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
220   assert(index &lt; _num_optional_regions,
221          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
222   _oops_into_optional_regions[index].push_oop(p);
<span class="line-modified">223   DEBUG_ONLY(verify_ref(p);)</span>
224 }
225 
226 G1OopStarChunkedList* G1ParScanThreadState::oops_into_optional_region(const HeapRegion* hr) {
227   assert(hr-&gt;index_in_opt_cset() &lt; _num_optional_regions,
228          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT &quot; &quot; HR_FORMAT,
229          hr-&gt;index_in_opt_cset(), _num_optional_regions, HR_FORMAT_PARAMS(hr));
230   return &amp;_oops_into_optional_regions[hr-&gt;index_in_opt_cset()];
231 }
232 
233 void G1ParScanThreadState::initialize_numa_stats() {
234   if (_numa-&gt;is_enabled()) {
235     LogTarget(Info, gc, heap, numa) lt;
236 
237     if (lt.is_enabled()) {
238       uint num_nodes = _numa-&gt;num_active_nodes();
239       // Record only if there are multiple active nodes.
240       _obj_alloc_stat = NEW_C_HEAP_ARRAY(size_t, num_nodes, mtGC);
241       memset(_obj_alloc_stat, 0, sizeof(size_t) * num_nodes);
242     }
243   }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2014, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 54   }
 55 
 56   markWord m = obj-&gt;mark_raw();
 57   if (m.is_marked()) {
 58     obj = (oop) m.decode_pointer();
 59   } else {
 60     obj = copy_to_survivor_space(region_attr, obj, m);
 61   }
 62   RawAccess&lt;IS_NOT_NULL&gt;::oop_store(p, obj);
 63 
 64   assert(obj != NULL, &quot;Must be&quot;);
 65   if (HeapRegion::is_in_same_region(p, obj)) {
 66     return;
 67   }
 68   HeapRegion* from = _g1h-&gt;heap_region_containing(p);
 69   if (!from-&gt;is_young()) {
 70     enqueue_card_if_tracked(_g1h-&gt;region_attr(obj), p, obj);
 71   }
 72 }
 73 
<span class="line-modified"> 74 inline void G1ParScanThreadState::push_on_queue(ScannerTask task) {</span>
<span class="line-modified"> 75   verify_task(task);</span>
<span class="line-modified"> 76   _task_queue-&gt;push(task);</span>
 77 }
 78 
<span class="line-modified"> 79 inline void G1ParScanThreadState::do_partial_array(PartialArrayScanTask task) {</span>
<span class="line-modified"> 80   oop from_obj = task.to_source_array();</span>

 81 
 82   assert(_g1h-&gt;is_in_reserved(from_obj), &quot;must be in heap.&quot;);
 83   assert(from_obj-&gt;is_objArray(), &quot;must be obj array&quot;);
 84   objArrayOop from_obj_array = objArrayOop(from_obj);
 85   // The from-space object contains the real length.
 86   int length                 = from_obj_array-&gt;length();
 87 
 88   assert(from_obj-&gt;is_forwarded(), &quot;must be forwarded&quot;);
 89   oop to_obj                 = from_obj-&gt;forwardee();
 90   assert(from_obj != to_obj, &quot;should not be chunking self-forwarded objects&quot;);
 91   objArrayOop to_obj_array   = objArrayOop(to_obj);
 92   // We keep track of the next start index in the length field of the
 93   // to-space object.
 94   int next_index             = to_obj_array-&gt;length();
 95   assert(0 &lt;= next_index &amp;&amp; next_index &lt; length,
 96          &quot;invariant, next index: %d, length: %d&quot;, next_index, length);
 97 
 98   int start                  = next_index;
 99   int end                    = length;
100   int remainder              = end - start;
101   // We&#39;ll try not to push a range that&#39;s smaller than ParGCArrayScanChunk.
102   if (remainder &gt; 2 * ParGCArrayScanChunk) {
103     end = start + ParGCArrayScanChunk;
104     to_obj_array-&gt;set_length(end);
105     // Push the remainder before we process the range in case another
106     // worker has run out of things to do and can steal it.
<span class="line-modified">107     push_on_queue(ScannerTask(PartialArrayScanTask(from_obj)));</span>

108   } else {
109     assert(length == end, &quot;sanity&quot;);
110     // We&#39;ll process the final range for this object. Restore the length
111     // so that the heap remains parsable in case of evacuation failure.
112     to_obj_array-&gt;set_length(end);
113   }
114 
115   HeapRegion* hr = _g1h-&gt;heap_region_containing(to_obj);
116   G1ScanInYoungSetter x(&amp;_scanner, hr-&gt;is_young());
117   // Process indexes [start,end). It will also process the header
118   // along with the first chunk (i.e., the chunk with start == 0).
119   // Note that at this point the length field of to_obj_array is not
120   // correct given that we are using it to keep track of the next
121   // start index. oop_iterate_range() (thankfully!) ignores the length
122   // field and only relies on the start / end parameters.  It does
123   // however return the size of the object which will be incorrect. So
124   // we have to ignore it even if we wanted to use it.
125   to_obj_array-&gt;oop_iterate_range(&amp;_scanner, start, end);
126 }
127 
<span class="line-modified">128 inline void G1ParScanThreadState::dispatch_task(ScannerTask task) {</span>
<span class="line-modified">129   verify_task(task);</span>
<span class="line-modified">130   if (task.is_narrow_oop_ptr()) {</span>
<span class="line-added">131     do_oop_evac(task.to_narrow_oop_ptr());</span>
<span class="line-added">132   } else if (task.is_oop_ptr()) {</span>
<span class="line-added">133     do_oop_evac(task.to_oop_ptr());</span>
134   } else {
<span class="line-modified">135     do_partial_array(task.to_partial_array_task());</span>
136   }
137 }
138 
<span class="line-modified">139 void G1ParScanThreadState::steal_and_trim_queue(ScannerTasksQueueSet *task_queues) {</span>
<span class="line-modified">140   ScannerTask stolen_task;</span>














141   while (task_queues-&gt;steal(_worker_id, stolen_task)) {
<span class="line-modified">142     dispatch_task(stolen_task);</span>

143 
<span class="line-modified">144     // We&#39;ve just processed a task and we might have made</span>
145     // available new entries on the queues. So we have to make sure
146     // we drain the queues as necessary.
147     trim_queue();
148   }
149 }
150 
151 inline bool G1ParScanThreadState::needs_partial_trimming() const {
<span class="line-modified">152   return !_task_queue-&gt;overflow_empty() ||</span>
<span class="line-added">153          (_task_queue-&gt;size() &gt; _stack_trim_upper_threshold);</span>
154 }
155 
156 inline bool G1ParScanThreadState::is_partially_trimmed() const {
<span class="line-modified">157   return _task_queue-&gt;overflow_empty() &amp;&amp;</span>
<span class="line-added">158          (_task_queue-&gt;size() &lt;= _stack_trim_lower_threshold);</span>
159 }
160 
161 inline void G1ParScanThreadState::trim_queue_to_threshold(uint threshold) {
<span class="line-modified">162   ScannerTask task;</span>
163   // Drain the overflow stack first, so other threads can potentially steal.
<span class="line-modified">164   while (_task_queue-&gt;pop_overflow(task)) {</span>
<span class="line-modified">165     if (!_task_queue-&gt;try_push_to_taskqueue(task)) {</span>
<span class="line-modified">166       dispatch_task(task);</span>
167     }
168   }
169 
<span class="line-modified">170   while (_task_queue-&gt;pop_local(task, threshold)) {</span>
<span class="line-modified">171     dispatch_task(task);</span>
172   }
173 }
174 
175 inline void G1ParScanThreadState::trim_queue_partially() {
176   if (!needs_partial_trimming()) {
177     return;
178   }
179 
180   const Ticks start = Ticks::now();
181   do {
182     trim_queue_to_threshold(_stack_trim_lower_threshold);
183   } while (!is_partially_trimmed());
184   _trim_ticks += Ticks::now() - start;
185 }
186 
187 inline Tickspan G1ParScanThreadState::trim_ticks() const {
188   return _trim_ticks;
189 }
190 
191 inline void G1ParScanThreadState::reset_trim_ticks() {
192   _trim_ticks = Tickspan();
193 }
194 
195 template &lt;typename T&gt;
196 inline void G1ParScanThreadState::remember_root_into_optional_region(T* p) {
197   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
198   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
199   assert(index &lt; _num_optional_regions,
200          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
201   _oops_into_optional_regions[index].push_root(p);
202 }
203 
204 template &lt;typename T&gt;
205 inline void G1ParScanThreadState::remember_reference_into_optional_region(T* p) {
206   oop o = RawAccess&lt;IS_NOT_NULL&gt;::oop_load(p);
207   uint index = _g1h-&gt;heap_region_containing(o)-&gt;index_in_opt_cset();
208   assert(index &lt; _num_optional_regions,
209          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT, index, _num_optional_regions);
210   _oops_into_optional_regions[index].push_oop(p);
<span class="line-modified">211   verify_task(p);</span>
212 }
213 
214 G1OopStarChunkedList* G1ParScanThreadState::oops_into_optional_region(const HeapRegion* hr) {
215   assert(hr-&gt;index_in_opt_cset() &lt; _num_optional_regions,
216          &quot;Trying to access optional region idx %u beyond &quot; SIZE_FORMAT &quot; &quot; HR_FORMAT,
217          hr-&gt;index_in_opt_cset(), _num_optional_regions, HR_FORMAT_PARAMS(hr));
218   return &amp;_oops_into_optional_regions[hr-&gt;index_in_opt_cset()];
219 }
220 
221 void G1ParScanThreadState::initialize_numa_stats() {
222   if (_numa-&gt;is_enabled()) {
223     LogTarget(Info, gc, heap, numa) lt;
224 
225     if (lt.is_enabled()) {
226       uint num_nodes = _numa-&gt;num_active_nodes();
227       // Record only if there are multiple active nodes.
228       _obj_alloc_stat = NEW_C_HEAP_ARRAY(size_t, num_nodes, mtGC);
229       memset(_obj_alloc_stat, 0, sizeof(size_t) * num_nodes);
230     }
231   }
</pre>
</td>
</tr>
</table>
<center><a href="g1ParScanThreadState.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1RemSet.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>