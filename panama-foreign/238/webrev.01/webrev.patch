diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -1507,10 +1507,15 @@
   } else {
     return 6 * NativeInstruction::instruction_size;
   }
 }
 
+int MachCallNativeNode::ret_addr_offset() {
+  ShouldNotReachHere();
+  return -1;
+}
+
 // Indicate if the safepoint node needs the polling page as an input
 
 // the shared code plants the oop data at the start of the generated
 // code for the safepoint node and that needs ot be at the load
 // instruction itself. so we cannot plant a mov of the safepoint poll
diff a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
@@ -3044,5 +3044,12 @@
 
   // Set exception blob
   _exception_blob =  ExceptionBlob::create(&buffer, oop_maps, SimpleRuntimeFrame::framesize >> 1);
 }
 #endif // COMPILER2
+
+address SharedRuntime::make_native_invoker(address call_target,
+                                           int shadow_space_bytes,
+                                           const GrowableArray<VMReg>& input_registers,
+                                           const GrowableArray<VMReg>& output_registers) {
+  return NULL;
+}
diff a/src/hotspot/cpu/aarch64/vmreg_aarch64.cpp b/src/hotspot/cpu/aarch64/vmreg_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/vmreg_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/vmreg_aarch64.cpp
@@ -24,11 +24,11 @@
  */
 
 #include "precompiled.hpp"
 #include "asm/assembler.hpp"
 #include "code/vmreg.hpp"
-
+#include "vmreg_aarch64.inline.hpp"
 
 
 void VMRegImpl::set_regName() {
   Register reg = ::as_Register(0);
   int i;
@@ -49,5 +49,19 @@
 
   for ( ; i < ConcreteRegisterImpl::number_of_registers ; i ++ ) {
     regName[i] = "NON-GPR-FPR";
   }
 }
+
+#define INTEGER_TYPE 0
+#define VECTOR_TYPE 1
+#define X87_TYPE 2
+#define STACK_TYPE 3
+
+VMReg VMRegImpl::vmStorageToVMReg(int type, int index) {
+  switch(type) {
+    case INTEGER_TYPE: return ::as_Register(index)->as_VMReg();
+    case VECTOR_TYPE: return ::as_FloatRegister(index)->as_VMReg();
+    case STACK_TYPE: return VMRegImpl::stack2reg(index LP64_ONLY(* 2));
+  }
+  return VMRegImpl::Bad();
+}
diff a/src/hotspot/share/opto/callGenerator.cpp b/src/hotspot/share/opto/callGenerator.cpp
--- a/src/hotspot/share/opto/callGenerator.cpp
+++ b/src/hotspot/share/opto/callGenerator.cpp
@@ -860,10 +860,11 @@
 
 JVMState* NativeCallGenerator::generate(JVMState* jvms) {
   GraphKit kit(jvms);
 
   Node* call = kit.make_native_call(tf(), method()->arg_size(), _nep); // -fallback, - nep
+  if (call == NULL) return NULL;
 
   kit.C->print_inlining_update(this);
   address addr = _nep->entry_point();
   if (kit.C->log() != NULL) {
     kit.C->log()->elem("l2n_intrinsification_success bci='%d' entry_point='" INTPTR_FORMAT "'", jvms->bci(), p2i(addr));
diff a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -2626,10 +2626,11 @@
   address call_addr = nep->entry_point();
   if (nep->need_transition()) {
     call_addr = SharedRuntime::make_native_invoker(call_addr,
                                                    nep->shadow_space(),
                                                    arg_regs, ret_regs);
+    if (call_addr == NULL) return NULL;
     C->add_native_stub(call_addr);
   }
   assert(call_addr != NULL, "sanity");
 
   CallNativeNode* call = new CallNativeNode(new_call_type, call_addr, nep->name(), TypePtr::BOTTOM,
