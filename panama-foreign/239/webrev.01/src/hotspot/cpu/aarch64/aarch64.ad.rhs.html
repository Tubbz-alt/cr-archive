<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 int MachCallNativeNode::ret_addr_offset() {
 1513   ShouldNotReachHere();
 1514   return -1;
 1515 }
 1516 
 1517 // Indicate if the safepoint node needs the polling page as an input
 1518 
 1519 // the shared code plants the oop data at the start of the generated
 1520 // code for the safepoint node and that needs ot be at the load
 1521 // instruction itself. so we cannot plant a mov of the safepoint poll
 1522 // address followed by a load. setting this to true means the mov is
 1523 // scheduled as a prior instruction. that&#39;s better for scheduling
 1524 // anyway.
 1525 
 1526 bool SafePointNode::needs_polling_address_input()
 1527 {
 1528   return true;
 1529 }
 1530 
 1531 //=============================================================================
 1532 
 1533 #ifndef PRODUCT
 1534 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1535   st-&gt;print(&quot;BREAKPOINT&quot;);
 1536 }
 1537 #endif
 1538 
 1539 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1540   C2_MacroAssembler _masm(&amp;cbuf);
 1541   __ brk(0);
 1542 }
 1543 
 1544 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1545   return MachNode::size(ra_);
 1546 }
 1547 
 1548 //=============================================================================
 1549 
 1550 #ifndef PRODUCT
 1551   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1552     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1553   }
 1554 #endif
 1555 
 1556   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1557     C2_MacroAssembler _masm(&amp;cbuf);
 1558     for (int i = 0; i &lt; _count; i++) {
 1559       __ nop();
 1560     }
 1561   }
 1562 
 1563   uint MachNopNode::size(PhaseRegAlloc*) const {
 1564     return _count * NativeInstruction::instruction_size;
 1565   }
 1566 
 1567 //=============================================================================
 1568 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1569 
 1570 int ConstantTable::calculate_table_base_offset() const {
 1571   return 0;  // absolute addressing, no offset
 1572 }
 1573 
 1574 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1575 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1576   ShouldNotReachHere();
 1577 }
 1578 
 1579 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1580   // Empty encoding
 1581 }
 1582 
 1583 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1584   return 0;
 1585 }
 1586 
 1587 #ifndef PRODUCT
 1588 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1589   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1590 }
 1591 #endif
 1592 
 1593 #ifndef PRODUCT
 1594 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1595   Compile* C = ra_-&gt;C;
 1596 
 1597   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1598 
 1599   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1600     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1601 
 1602   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1603     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1604     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1605     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1606   } else {
 1607     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1608     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1609     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1610     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1611   }
 1612   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1613     st-&gt;print(&quot;\n\t&quot;);
 1614     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1615     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1616     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1617     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1618     st-&gt;print(&quot;b.eq skip&quot;);
 1619     st-&gt;print(&quot;\n\t&quot;);
 1620     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1621     st-&gt;print(&quot;b skip\n\t&quot;);
 1622     st-&gt;print(&quot;guard: int\n\t&quot;);
 1623     st-&gt;print(&quot;\n\t&quot;);
 1624     st-&gt;print(&quot;skip:\n\t&quot;);
 1625   }
 1626 }
 1627 #endif
 1628 
 1629 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1630   Compile* C = ra_-&gt;C;
 1631   C2_MacroAssembler _masm(&amp;cbuf);
 1632 
 1633   // n.b. frame size includes space for return pc and rfp
 1634   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1635   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1636 
 1637   // insert a nop at the start of the prolog so we can patch in a
 1638   // branch if we need to invalidate the method later
 1639   __ nop();
 1640 
 1641   if (C-&gt;clinit_barrier_on_entry()) {
 1642     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1643 
 1644     Label L_skip_barrier;
 1645 
 1646     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1647     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1648     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1649     __ bind(L_skip_barrier);
 1650   }
 1651 
 1652   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1653   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1654     __ generate_stack_overflow_check(bangsize);
 1655 
 1656   __ build_frame(framesize);
 1657 
 1658   if (C-&gt;stub_function() == NULL) {
 1659     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1660     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1661   }
 1662 
 1663   if (VerifyStackAtCalls) {
 1664     Unimplemented();
 1665   }
 1666 
 1667   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1668 
 1669   if (C-&gt;has_mach_constant_base_node()) {
 1670     // NOTE: We set the table base offset here because users might be
 1671     // emitted before MachConstantBaseNode.
 1672     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1673     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1674   }
 1675 }
 1676 
 1677 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1678 {
 1679   return MachNode::size(ra_); // too many variables; just compute it
 1680                               // the hard way
 1681 }
 1682 
 1683 int MachPrologNode::reloc() const
 1684 {
 1685   return 0;
 1686 }
 1687 
 1688 //=============================================================================
 1689 
 1690 #ifndef PRODUCT
 1691 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1692   Compile* C = ra_-&gt;C;
 1693   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1694 
 1695   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1696 
 1697   if (framesize == 0) {
 1698     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1699   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1702   } else {
 1703     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1704     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1710     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1711     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1712   }
 1713 }
 1714 #endif
 1715 
 1716 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1717   Compile* C = ra_-&gt;C;
 1718   C2_MacroAssembler _masm(&amp;cbuf);
 1719   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1720 
 1721   __ remove_frame(framesize);
 1722 
 1723   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1724     __ reserved_stack_check();
 1725   }
 1726 
 1727   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1728     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1729   }
 1730 }
 1731 
 1732 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1733   // Variable size. Determine dynamically.
 1734   return MachNode::size(ra_);
 1735 }
 1736 
 1737 int MachEpilogNode::reloc() const {
 1738   // Return number of relocatable values contained in this instruction.
 1739   return 1; // 1 for polling page.
 1740 }
 1741 
 1742 const Pipeline * MachEpilogNode::pipeline() const {
 1743   return MachNode::pipeline_class();
 1744 }
 1745 
 1746 //=============================================================================
 1747 
 1748 // Figure out which register class each belongs in: rc_int, rc_float or
 1749 // rc_stack.
 1750 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1751 
 1752 static enum RC rc_class(OptoReg::Name reg) {
 1753 
 1754   if (reg == OptoReg::Bad) {
 1755     return rc_bad;
 1756   }
 1757 
 1758   // we have 30 int registers * 2 halves
 1759   // (rscratch1 and rscratch2 are omitted)
 1760   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1761 
 1762   if (reg &lt; slots_of_int_registers) {
 1763     return rc_int;
 1764   }
 1765 
 1766   // we have 32 float register * 4 halves
 1767   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1768     return rc_float;
 1769   }
 1770 
 1771   // Between float regs &amp; stack is the flags regs.
 1772   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1773 
 1774   return rc_stack;
 1775 }
 1776 
 1777 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1778   Compile* C = ra_-&gt;C;
 1779 
 1780   // Get registers to move.
 1781   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1782   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1783   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1784   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1785 
 1786   enum RC src_hi_rc = rc_class(src_hi);
 1787   enum RC src_lo_rc = rc_class(src_lo);
 1788   enum RC dst_hi_rc = rc_class(dst_hi);
 1789   enum RC dst_lo_rc = rc_class(dst_lo);
 1790 
 1791   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1792 
 1793   if (src_hi != OptoReg::Bad) {
 1794     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1795            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1796            &quot;expected aligned-adjacent pairs&quot;);
 1797   }
 1798 
 1799   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1800     return 0;            // Self copy, no move.
 1801   }
 1802 
 1803   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1804               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1805   int src_offset = ra_-&gt;reg2offset(src_lo);
 1806   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1807 
 1808   if (bottom_type()-&gt;isa_vect() != NULL) {
 1809     uint ireg = ideal_reg();
 1810     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1811     if (cbuf) {
 1812       C2_MacroAssembler _masm(cbuf);
 1813       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1814       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1815         // stack-&gt;stack
 1816         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1817         if (ireg == Op_VecD) {
 1818           __ unspill(rscratch1, true, src_offset);
 1819           __ spill(rscratch1, true, dst_offset);
 1820         } else {
 1821           __ spill_copy128(src_offset, dst_offset);
 1822         }
 1823       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1824         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1825                ireg == Op_VecD ? __ T8B : __ T16B,
 1826                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1827       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1828         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1829                        ireg == Op_VecD ? __ D : __ Q,
 1830                        ra_-&gt;reg2offset(dst_lo));
 1831       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1832         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1833                        ireg == Op_VecD ? __ D : __ Q,
 1834                        ra_-&gt;reg2offset(src_lo));
 1835       } else {
 1836         ShouldNotReachHere();
 1837       }
 1838     }
 1839   } else if (cbuf) {
 1840     C2_MacroAssembler _masm(cbuf);
 1841     switch (src_lo_rc) {
 1842     case rc_int:
 1843       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1844         if (is64) {
 1845             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1846                    as_Register(Matcher::_regEncode[src_lo]));
 1847         } else {
 1848             C2_MacroAssembler _masm(cbuf);
 1849             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1850                     as_Register(Matcher::_regEncode[src_lo]));
 1851         }
 1852       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1853         if (is64) {
 1854             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         } else {
 1857             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_Register(Matcher::_regEncode[src_lo]));
 1859         }
 1860       } else {                    // gpr --&gt; stack spill
 1861         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1862         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1863       }
 1864       break;
 1865     case rc_float:
 1866       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1867         if (is64) {
 1868             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         } else {
 1871             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         }
 1874       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1875           if (cbuf) {
 1876             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         } else {
 1879             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1880                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1881         }
 1882       } else {                    // fpr --&gt; stack spill
 1883         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1884         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1885                  is64 ? __ D : __ S, dst_offset);
 1886       }
 1887       break;
 1888     case rc_stack:
 1889       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1890         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1891       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1892         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1893                    is64 ? __ D : __ S, src_offset);
 1894       } else {                    // stack --&gt; stack copy
 1895         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1896         __ unspill(rscratch1, is64, src_offset);
 1897         __ spill(rscratch1, is64, dst_offset);
 1898       }
 1899       break;
 1900     default:
 1901       assert(false, &quot;bad rc_class for spill&quot;);
 1902       ShouldNotReachHere();
 1903     }
 1904   }
 1905 
 1906   if (st) {
 1907     st-&gt;print(&quot;spill &quot;);
 1908     if (src_lo_rc == rc_stack) {
 1909       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1910     } else {
 1911       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1912     }
 1913     if (dst_lo_rc == rc_stack) {
 1914       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1915     } else {
 1916       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1917     }
 1918     if (bottom_type()-&gt;isa_vect() != NULL) {
 1919       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1920     } else {
 1921       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1922     }
 1923   }
 1924 
 1925   return 0;
 1926 
 1927 }
 1928 
 1929 #ifndef PRODUCT
 1930 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   if (!ra_)
 1932     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1933   else
 1934     implementation(NULL, ra_, false, st);
 1935 }
 1936 #endif
 1937 
 1938 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   implementation(&amp;cbuf, ra_, false, NULL);
 1940 }
 1941 
 1942 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1943   return MachNode::size(ra_);
 1944 }
 1945 
 1946 //=============================================================================
 1947 
 1948 #ifndef PRODUCT
 1949 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1950   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1951   int reg = ra_-&gt;get_reg_first(this);
 1952   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1953             Matcher::regName[reg], offset);
 1954 }
 1955 #endif
 1956 
 1957 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1958   C2_MacroAssembler _masm(&amp;cbuf);
 1959 
 1960   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1961   int reg    = ra_-&gt;get_encode(this);
 1962 
<a name="1" id="anc1"></a><span class="line-modified"> 1963   // This add will handle any 24-bit signed offset. 24 bits allows an</span>
<span class="line-modified"> 1964   // 8 megabyte stack frame.</span>
<span class="line-modified"> 1965   __ add(as_Register(reg), sp, offset);</span>


 1966 }
 1967 
 1968 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1969   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
<a name="2" id="anc2"></a><span class="line-modified"> 1970   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());</span>
<span class="line-added"> 1971 </span>
<span class="line-added"> 1972   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {</span>
<span class="line-added"> 1973     return NativeInstruction::instruction_size;</span>
<span class="line-added"> 1974   } else {</span>
<span class="line-added"> 1975     return 2 * NativeInstruction::instruction_size;</span>
<span class="line-added"> 1976   }</span>
 1977 }
 1978 
 1979 //=============================================================================
 1980 
 1981 #ifndef PRODUCT
 1982 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1983 {
 1984   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1985   if (UseCompressedClassPointers) {
 1986     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1987     if (CompressedKlassPointers::shift() != 0) {
 1988       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1989     }
 1990   } else {
 1991    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992   }
 1993   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1994   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1995 }
 1996 #endif
 1997 
 1998 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1999 {
 2000   // This is the unverified entry point.
 2001   C2_MacroAssembler _masm(&amp;cbuf);
 2002 
 2003   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2004   Label skip;
 2005   // TODO
 2006   // can we avoid this skip and still use a reloc?
 2007   __ br(Assembler::EQ, skip);
 2008   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2009   __ bind(skip);
 2010 }
 2011 
 2012 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2013 {
 2014   return MachNode::size(ra_);
 2015 }
 2016 
 2017 // REQUIRED EMIT CODE
 2018 
 2019 //=============================================================================
 2020 
 2021 // Emit exception handler code.
 2022 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2023 {
 2024   // mov rscratch1 #exception_blob_entry_point
 2025   // br rscratch1
 2026   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2027   // That&#39;s why we must use the macroassembler to generate a handler.
 2028   C2_MacroAssembler _masm(&amp;cbuf);
 2029   address base = __ start_a_stub(size_exception_handler());
 2030   if (base == NULL) {
 2031     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2032     return 0;  // CodeBuffer::expand failed
 2033   }
 2034   int offset = __ offset();
 2035   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2036   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2037   __ end_a_stub();
 2038   return offset;
 2039 }
 2040 
 2041 // Emit deopt handler code.
 2042 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2043 {
 2044   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2045   // That&#39;s why we must use the macroassembler to generate a handler.
 2046   C2_MacroAssembler _masm(&amp;cbuf);
 2047   address base = __ start_a_stub(size_deopt_handler());
 2048   if (base == NULL) {
 2049     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2050     return 0;  // CodeBuffer::expand failed
 2051   }
 2052   int offset = __ offset();
 2053 
 2054   __ adr(lr, __ pc());
 2055   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2056 
 2057   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2058   __ end_a_stub();
 2059   return offset;
 2060 }
 2061 
 2062 // REQUIRED MATCHER CODE
 2063 
 2064 //=============================================================================
 2065 
 2066 const bool Matcher::match_rule_supported(int opcode) {
 2067   if (!has_match_rule(opcode))
 2068     return false;
 2069 
 2070   bool ret_value = true;
 2071   switch (opcode) {
 2072     case Op_CacheWB:
 2073     case Op_CacheWBPreSync:
 2074     case Op_CacheWBPostSync:
 2075       if (!VM_Version::supports_data_cache_line_flush()) {
 2076         ret_value = false;
 2077       }
 2078       break;
 2079   }
 2080 
 2081   return ret_value; // Per default match rules are supported.
 2082 }
 2083 
 2084 // Identify extra cases that we might want to provide match rules for vector nodes and
 2085 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2086 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2087   if (!match_rule_supported(opcode)) {
 2088     return false;
 2089   }
 2090 
 2091   // Special cases which require vector length
 2092   switch (opcode) {
 2093     case Op_MulAddVS2VI: {
 2094       if (vlen != 4) {
 2095         return false;
 2096       }
 2097       break;
 2098     }
 2099   }
 2100 
 2101   return true; // Per default match rules are supported.
 2102 }
 2103 
 2104 const bool Matcher::has_predicated_vectors(void) {
 2105   return false;
 2106 }
 2107 
 2108 const int Matcher::float_pressure(int default_pressure_threshold) {
 2109   return default_pressure_threshold;
 2110 }
 2111 
 2112 int Matcher::regnum_to_fpu_offset(int regnum)
 2113 {
 2114   Unimplemented();
 2115   return 0;
 2116 }
 2117 
 2118 // Is this branch offset short enough that a short branch can be used?
 2119 //
 2120 // NOTE: If the platform does not provide any short branch variants, then
 2121 //       this method should return false for offset 0.
 2122 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2123   // The passed offset is relative to address of the branch.
 2124 
 2125   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2126 }
 2127 
 2128 const bool Matcher::isSimpleConstant64(jlong value) {
 2129   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2130   // Probably always true, even if a temp register is required.
 2131   return true;
 2132 }
 2133 
 2134 // true just means we have fast l2f conversion
 2135 const bool Matcher::convL2FSupported(void) {
 2136   return true;
 2137 }
 2138 
 2139 // Vector width in bytes.
 2140 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2141   int size = MIN2(16,(int)MaxVectorSize);
 2142   // Minimum 2 values in vector
 2143   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2144   // But never &lt; 4
 2145   if (size &lt; 4) size = 0;
 2146   return size;
 2147 }
 2148 
 2149 // Limits on vector size (number of elements) loaded into vector.
 2150 const int Matcher::max_vector_size(const BasicType bt) {
 2151   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2152 }
 2153 const int Matcher::min_vector_size(const BasicType bt) {
 2154 //  For the moment limit the vector size to 8 bytes
 2155     int size = 8 / type2aelembytes(bt);
 2156     if (size &lt; 2) size = 2;
 2157     return size;
 2158 }
 2159 
 2160 // Vector ideal reg.
 2161 const uint Matcher::vector_ideal_reg(int len) {
 2162   switch(len) {
 2163     case  8: return Op_VecD;
 2164     case 16: return Op_VecX;
 2165   }
 2166   ShouldNotReachHere();
 2167   return 0;
 2168 }
 2169 
 2170 // AES support not yet implemented
 2171 const bool Matcher::pass_original_key_for_aes() {
 2172   return false;
 2173 }
 2174 
 2175 // aarch64 supports misaligned vectors store/load.
 2176 const bool Matcher::misaligned_vectors_ok() {
 2177   return true;
 2178 }
 2179 
 2180 // false =&gt; size gets scaled to BytesPerLong, ok.
 2181 const bool Matcher::init_array_count_is_in_bytes = false;
 2182 
 2183 // Use conditional move (CMOVL)
 2184 const int Matcher::long_cmove_cost() {
 2185   // long cmoves are no more expensive than int cmoves
 2186   return 0;
 2187 }
 2188 
 2189 const int Matcher::float_cmove_cost() {
 2190   // float cmoves are no more expensive than int cmoves
 2191   return 0;
 2192 }
 2193 
 2194 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2195 const bool Matcher::require_postalloc_expand = false;
 2196 
 2197 // Do we need to mask the count passed to shift instructions or does
 2198 // the cpu only look at the lower 5/6 bits anyway?
 2199 const bool Matcher::need_masked_shift_count = false;
 2200 
 2201 // No support for generic vector operands.
 2202 const bool Matcher::supports_generic_vector_operands  = false;
 2203 
 2204 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2205   ShouldNotReachHere(); // generic vector operands not supported
 2206   return NULL;
 2207 }
 2208 
 2209 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2210   ShouldNotReachHere();  // generic vector operands not supported
 2211   return false;
 2212 }
 2213 
 2214 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2215   ShouldNotReachHere();  // generic vector operands not supported
 2216   return false;
 2217 }
 2218 
 2219 // This affects two different things:
 2220 //  - how Decode nodes are matched
 2221 //  - how ImplicitNullCheck opportunities are recognized
 2222 // If true, the matcher will try to remove all Decodes and match them
 2223 // (as operands) into nodes. NullChecks are not prepared to deal with
 2224 // Decodes by final_graph_reshaping().
 2225 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2226 // for a NullCheck. The matcher matches the Decode node into a register.
 2227 // Implicit_null_check optimization moves the Decode along with the
 2228 // memory operation back up before the NullCheck.
 2229 bool Matcher::narrow_oop_use_complex_address() {
 2230   return CompressedOops::shift() == 0;
 2231 }
 2232 
 2233 bool Matcher::narrow_klass_use_complex_address() {
 2234 // TODO
 2235 // decide whether we need to set this to true
 2236   return false;
 2237 }
 2238 
 2239 bool Matcher::const_oop_prefer_decode() {
 2240   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2241   return CompressedOops::base() == NULL;
 2242 }
 2243 
 2244 bool Matcher::const_klass_prefer_decode() {
 2245   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2246   return CompressedKlassPointers::base() == NULL;
 2247 }
 2248 
 2249 // Is it better to copy float constants, or load them directly from
 2250 // memory?  Intel can load a float constant from a direct address,
 2251 // requiring no extra registers.  Most RISCs will have to materialize
 2252 // an address into a register first, so they would do better to copy
 2253 // the constant from stack.
 2254 const bool Matcher::rematerialize_float_constants = false;
 2255 
 2256 // If CPU can load and store mis-aligned doubles directly then no
 2257 // fixup is needed.  Else we split the double into 2 integer pieces
 2258 // and move it piece-by-piece.  Only happens when passing doubles into
 2259 // C code as the Java calling convention forces doubles to be aligned.
 2260 const bool Matcher::misaligned_doubles_ok = true;
 2261 
 2262 // No-op on amd64
 2263 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2264   Unimplemented();
 2265 }
 2266 
 2267 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2268 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2269 
 2270 // Are floats converted to double when stored to stack during
 2271 // deoptimization?
 2272 bool Matcher::float_in_double() { return false; }
 2273 
 2274 // Do ints take an entire long register or just half?
 2275 // The relevant question is how the int is callee-saved:
 2276 // the whole long is written but de-opt&#39;ing will have to extract
 2277 // the relevant 32 bits.
 2278 const bool Matcher::int_in_long = true;
 2279 
 2280 // Return whether or not this register is ever used as an argument.
 2281 // This function is used on startup to build the trampoline stubs in
 2282 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2283 // call in the trampoline, and arguments in those registers not be
 2284 // available to the callee.
 2285 bool Matcher::can_be_java_arg(int reg)
 2286 {
 2287   return
 2288     reg ==  R0_num || reg == R0_H_num ||
 2289     reg ==  R1_num || reg == R1_H_num ||
 2290     reg ==  R2_num || reg == R2_H_num ||
 2291     reg ==  R3_num || reg == R3_H_num ||
 2292     reg ==  R4_num || reg == R4_H_num ||
 2293     reg ==  R5_num || reg == R5_H_num ||
 2294     reg ==  R6_num || reg == R6_H_num ||
 2295     reg ==  R7_num || reg == R7_H_num ||
 2296     reg ==  V0_num || reg == V0_H_num ||
 2297     reg ==  V1_num || reg == V1_H_num ||
 2298     reg ==  V2_num || reg == V2_H_num ||
 2299     reg ==  V3_num || reg == V3_H_num ||
 2300     reg ==  V4_num || reg == V4_H_num ||
 2301     reg ==  V5_num || reg == V5_H_num ||
 2302     reg ==  V6_num || reg == V6_H_num ||
 2303     reg ==  V7_num || reg == V7_H_num;
 2304 }
 2305 
 2306 bool Matcher::is_spillable_arg(int reg)
 2307 {
 2308   return can_be_java_arg(reg);
 2309 }
 2310 
 2311 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2312   return false;
 2313 }
 2314 
 2315 RegMask Matcher::divI_proj_mask() {
 2316   ShouldNotReachHere();
 2317   return RegMask();
 2318 }
 2319 
 2320 // Register for MODI projection of divmodI.
 2321 RegMask Matcher::modI_proj_mask() {
 2322   ShouldNotReachHere();
 2323   return RegMask();
 2324 }
 2325 
 2326 // Register for DIVL projection of divmodL.
 2327 RegMask Matcher::divL_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 // Register for MODL projection of divmodL.
 2333 RegMask Matcher::modL_proj_mask() {
 2334   ShouldNotReachHere();
 2335   return RegMask();
 2336 }
 2337 
 2338 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2339   return FP_REG_mask();
 2340 }
 2341 
 2342 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2343   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2344     Node* u = addp-&gt;fast_out(i);
 2345     if (u-&gt;is_Mem()) {
 2346       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2347       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2348       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2349         return false;
 2350       }
 2351     }
 2352   }
 2353   return true;
 2354 }
 2355 
 2356 const bool Matcher::convi2l_type_required = false;
 2357 
 2358 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2359 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2360   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2361     mstack.push(m, Visit);           // m = ShiftCntV
 2362     return true;
 2363   }
 2364   return false;
 2365 }
 2366 
 2367 // Should the Matcher clone shifts on addressing modes, expecting them
 2368 // to be subsumed into complex addressing expressions or compute them
 2369 // into registers?
 2370 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2371   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2372     return true;
 2373   }
 2374 
 2375   Node *off = m-&gt;in(AddPNode::Offset);
 2376   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2377       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2378       // Are there other uses besides address expressions?
 2379       !is_visited(off)) {
 2380     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2381     mstack.push(off-&gt;in(2), Visit);
 2382     Node *conv = off-&gt;in(1);
 2383     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2384         // Are there other uses besides address expressions?
 2385         !is_visited(conv)) {
 2386       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2387       mstack.push(conv-&gt;in(1), Pre_Visit);
 2388     } else {
 2389       mstack.push(conv, Pre_Visit);
 2390     }
 2391     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2392     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2393     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2394     return true;
 2395   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2396              // Are there other uses besides address expressions?
 2397              !is_visited(off)) {
 2398     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2399     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2400     mstack.push(off-&gt;in(1), Pre_Visit);
 2401     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2402     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2403     return true;
 2404   }
 2405   return false;
 2406 }
 2407 
 2408 void Compile::reshape_address(AddPNode* addp) {
 2409 }
 2410 
 2411 
 2412 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2413   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2414   {                                                                     \
 2415     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2416     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2417     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2418     __ INSN(REG, as_Register(BASE));                                    \
 2419   }
 2420 
 2421 
 2422 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2423   {
 2424     Address::extend scale;
 2425 
 2426     // Hooboy, this is fugly.  We need a way to communicate to the
 2427     // encoder that the index needs to be sign extended, so we have to
 2428     // enumerate all the cases.
 2429     switch (opcode) {
 2430     case INDINDEXSCALEDI2L:
 2431     case INDINDEXSCALEDI2LN:
 2432     case INDINDEXI2L:
 2433     case INDINDEXI2LN:
 2434       scale = Address::sxtw(size);
 2435       break;
 2436     default:
 2437       scale = Address::lsl(size);
 2438     }
 2439 
 2440     if (index == -1) {
 2441       return Address(base, disp);
 2442     } else {
 2443       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2444       return Address(base, as_Register(index), scale);
 2445     }
 2446   }
 2447 
 2448 
 2449 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2450 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2451 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2452 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2453                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2454 
 2455   // Used for all non-volatile memory accesses.  The use of
 2456   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2457   // offsets is something of a kludge.
 2458   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2459                         Register reg, int opcode,
 2460                         Register base, int index, int scale, int disp,
 2461                         int size_in_memory)
 2462   {
 2463     Address addr = mem2address(opcode, base, index, scale, disp);
 2464     if (addr.getMode() == Address::base_plus_offset) {
 2465       /* If we get an out-of-range offset it is a bug in the compiler,
 2466          so we assert here. */
 2467       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2468              &quot;c2 compiler bug&quot;);
 2469       /* Fix up any out-of-range offsets. */
 2470       assert_different_registers(rscratch1, base);
 2471       assert_different_registers(rscratch1, reg);
 2472       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2473     }
 2474     (masm.*insn)(reg, addr);
 2475   }
 2476 
 2477   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2478                         FloatRegister reg, int opcode,
 2479                         Register base, int index, int size, int disp,
 2480                         int size_in_memory)
 2481   {
 2482     Address::extend scale;
 2483 
 2484     switch (opcode) {
 2485     case INDINDEXSCALEDI2L:
 2486     case INDINDEXSCALEDI2LN:
 2487       scale = Address::sxtw(size);
 2488       break;
 2489     default:
 2490       scale = Address::lsl(size);
 2491     }
 2492 
 2493     if (index == -1) {
 2494       /* If we get an out-of-range offset it is a bug in the compiler,
 2495          so we assert here. */
 2496       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2497       /* Fix up any out-of-range offsets. */
 2498       assert_different_registers(rscratch1, base);
 2499       Address addr = Address(base, disp);
 2500       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2501       (masm.*insn)(reg, addr);
 2502     } else {
 2503       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2504       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2505     }
 2506   }
 2507 
 2508   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2509                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2510                         int opcode, Register base, int index, int size, int disp)
 2511   {
 2512     if (index == -1) {
 2513       (masm.*insn)(reg, T, Address(base, disp));
 2514     } else {
 2515       assert(disp == 0, &quot;unsupported address mode&quot;);
 2516       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2517     }
 2518   }
 2519 
 2520 %}
 2521 
 2522 
 2523 
 2524 //----------ENCODING BLOCK-----------------------------------------------------
 2525 // This block specifies the encoding classes used by the compiler to
 2526 // output byte streams.  Encoding classes are parameterized macros
 2527 // used by Machine Instruction Nodes in order to generate the bit
 2528 // encoding of the instruction.  Operands specify their base encoding
 2529 // interface with the interface keyword.  There are currently
 2530 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2531 // COND_INTER.  REG_INTER causes an operand to generate a function
 2532 // which returns its register number when queried.  CONST_INTER causes
 2533 // an operand to generate a function which returns the value of the
 2534 // constant when queried.  MEMORY_INTER causes an operand to generate
 2535 // four functions which return the Base Register, the Index Register,
 2536 // the Scale Value, and the Offset Value of the operand when queried.
 2537 // COND_INTER causes an operand to generate six functions which return
 2538 // the encoding code (ie - encoding bits for the instruction)
 2539 // associated with each basic boolean condition for a conditional
 2540 // instruction.
 2541 //
 2542 // Instructions specify two basic values for encoding.  Again, a
 2543 // function is available to check if the constant displacement is an
 2544 // oop. They use the ins_encode keyword to specify their encoding
 2545 // classes (which must be a sequence of enc_class names, and their
 2546 // parameters, specified in the encoding block), and they use the
 2547 // opcode keyword to specify, in order, their primary, secondary, and
 2548 // tertiary opcode.  Only the opcode sections which a particular
 2549 // instruction needs for encoding need to be specified.
 2550 encode %{
 2551   // Build emit functions for each basic byte or larger field in the
 2552   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2553   // from C++ code in the enc_class source block.  Emit functions will
 2554   // live in the main source block for now.  In future, we can
 2555   // generalize this by adding a syntax that specifies the sizes of
 2556   // fields in an order, so that the adlc can build the emit functions
 2557   // automagically
 2558 
 2559   // catch all for unimplemented encodings
 2560   enc_class enc_unimplemented %{
 2561     C2_MacroAssembler _masm(&amp;cbuf);
 2562     __ unimplemented(&quot;C2 catch all&quot;);
 2563   %}
 2564 
 2565   // BEGIN Non-volatile memory access
 2566 
 2567   // This encoding class is generated automatically from ad_encode.m4.
 2568   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2569   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2570     Register dst_reg = as_Register($dst$$reg);
 2571     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2572                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2573   %}
 2574 
 2575   // This encoding class is generated automatically from ad_encode.m4.
 2576   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2577   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2578     Register dst_reg = as_Register($dst$$reg);
 2579     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2580                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2581   %}
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2666     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2674     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2682     Register src_reg = as_Register($src$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_strb0(memory1 mem) %{
 2690     C2_MacroAssembler _masm(&amp;cbuf);
 2691     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strh0(memory2 mem) %{
 2706     C2_MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strw0(memory4 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     // we sometimes get asked to store the stack pointer into the
 2732     // current thread -- we cannot do that directly on AArch64
 2733     if (src_reg == r31_sp) {
 2734       C2_MacroAssembler _masm(&amp;cbuf);
 2735       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2736       __ mov(rscratch2, sp);
 2737       src_reg = rscratch2;
 2738     }
 2739     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_str0(memory8 mem) %{
 2746     C2_MacroAssembler _masm(&amp;cbuf);
 2747     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2754     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2755     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2762     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2763     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2764                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2765   %}
 2766 
 2767   // This encoding class is generated automatically from ad_encode.m4.
 2768   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2769   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2770     C2_MacroAssembler _masm(&amp;cbuf);
 2771     address con = (address)$src$$constant;
 2772     // need to do this the hard way until we can manage relocs
 2773     // for 32 bit constants
 2774     __ movoop(rscratch2, (jobject)con);
 2775     if (con) __ encode_heap_oop_not_null(rscratch2);
 2776     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2777                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2778   %}
 2779 
 2780   // This encoding class is generated automatically from ad_encode.m4.
 2781   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2782   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2783     C2_MacroAssembler _masm(&amp;cbuf);
 2784     address con = (address)$src$$constant;
 2785     // need to do this the hard way until we can manage relocs
 2786     // for 32 bit constants
 2787     __ movoop(rscratch2, (jobject)con);
 2788     __ encode_klass_not_null(rscratch2);
 2789     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2790                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2791   %}
 2792 
 2793   // This encoding class is generated automatically from ad_encode.m4.
 2794   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2795   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2796       C2_MacroAssembler _masm(&amp;cbuf);
 2797       __ membar(Assembler::StoreStore);
 2798       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2799                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2800   %}
 2801 
 2802   // END Non-volatile memory access
 2803 
 2804   // Vector loads and stores
 2805   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2806     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2807     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2808        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2809   %}
 2810 
 2811   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2813     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2819     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2824     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2825     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2831     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2837     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   // volatile loads and stores
 2842 
 2843   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2844     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2845                  rscratch1, stlrb);
 2846   %}
 2847 
 2848   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2849     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2850                  rscratch1, stlrh);
 2851   %}
 2852 
 2853   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2854     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2855                  rscratch1, stlrw);
 2856   %}
 2857 
 2858 
 2859   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2860     Register dst_reg = as_Register($dst$$reg);
 2861     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2862              rscratch1, ldarb);
 2863     __ sxtbw(dst_reg, dst_reg);
 2864   %}
 2865 
 2866   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2867     Register dst_reg = as_Register($dst$$reg);
 2868     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2869              rscratch1, ldarb);
 2870     __ sxtb(dst_reg, dst_reg);
 2871   %}
 2872 
 2873   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2874     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875              rscratch1, ldarb);
 2876   %}
 2877 
 2878   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2879     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2880              rscratch1, ldarb);
 2881   %}
 2882 
 2883   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2884     Register dst_reg = as_Register($dst$$reg);
 2885     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2886              rscratch1, ldarh);
 2887     __ sxthw(dst_reg, dst_reg);
 2888   %}
 2889 
 2890   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2891     Register dst_reg = as_Register($dst$$reg);
 2892     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2893              rscratch1, ldarh);
 2894     __ sxth(dst_reg, dst_reg);
 2895   %}
 2896 
 2897   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2898     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarh);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2903     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2904              rscratch1, ldarh);
 2905   %}
 2906 
 2907   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2908     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarw);
 2910   %}
 2911 
 2912   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2913     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2914              rscratch1, ldarw);
 2915   %}
 2916 
 2917   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2918     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2919              rscratch1, ldar);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2923     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2924              rscratch1, ldarw);
 2925     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldar);
 2931     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2935     Register src_reg = as_Register($src$$reg);
 2936     // we sometimes get asked to store the stack pointer into the
 2937     // current thread -- we cannot do that directly on AArch64
 2938     if (src_reg == r31_sp) {
 2939       C2_MacroAssembler _masm(&amp;cbuf);
 2940       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2941       __ mov(rscratch2, sp);
 2942       src_reg = rscratch2;
 2943     }
 2944     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2945                  rscratch1, stlr);
 2946   %}
 2947 
 2948   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2949     {
 2950       C2_MacroAssembler _masm(&amp;cbuf);
 2951       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2952       __ fmovs(rscratch2, src_reg);
 2953     }
 2954     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2955                  rscratch1, stlrw);
 2956   %}
 2957 
 2958   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2959     {
 2960       C2_MacroAssembler _masm(&amp;cbuf);
 2961       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2962       __ fmovd(rscratch2, src_reg);
 2963     }
 2964     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2965                  rscratch1, stlr);
 2966   %}
 2967 
 2968   // synchronized read/update encodings
 2969 
 2970   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2971     C2_MacroAssembler _masm(&amp;cbuf);
 2972     Register dst_reg = as_Register($dst$$reg);
 2973     Register base = as_Register($mem$$base);
 2974     int index = $mem$$index;
 2975     int scale = $mem$$scale;
 2976     int disp = $mem$$disp;
 2977     if (index == -1) {
 2978        if (disp != 0) {
 2979         __ lea(rscratch1, Address(base, disp));
 2980         __ ldaxr(dst_reg, rscratch1);
 2981       } else {
 2982         // TODO
 2983         // should we ever get anything other than this case?
 2984         __ ldaxr(dst_reg, base);
 2985       }
 2986     } else {
 2987       Register index_reg = as_Register(index);
 2988       if (disp == 0) {
 2989         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2990         __ ldaxr(dst_reg, rscratch1);
 2991       } else {
 2992         __ lea(rscratch1, Address(base, disp));
 2993         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2994         __ ldaxr(dst_reg, rscratch1);
 2995       }
 2996     }
 2997   %}
 2998 
 2999   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3000     C2_MacroAssembler _masm(&amp;cbuf);
 3001     Register src_reg = as_Register($src$$reg);
 3002     Register base = as_Register($mem$$base);
 3003     int index = $mem$$index;
 3004     int scale = $mem$$scale;
 3005     int disp = $mem$$disp;
 3006     if (index == -1) {
 3007        if (disp != 0) {
 3008         __ lea(rscratch2, Address(base, disp));
 3009         __ stlxr(rscratch1, src_reg, rscratch2);
 3010       } else {
 3011         // TODO
 3012         // should we ever get anything other than this case?
 3013         __ stlxr(rscratch1, src_reg, base);
 3014       }
 3015     } else {
 3016       Register index_reg = as_Register(index);
 3017       if (disp == 0) {
 3018         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3019         __ stlxr(rscratch1, src_reg, rscratch2);
 3020       } else {
 3021         __ lea(rscratch2, Address(base, disp));
 3022         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3023         __ stlxr(rscratch1, src_reg, rscratch2);
 3024       }
 3025     }
 3026     __ cmpw(rscratch1, zr);
 3027   %}
 3028 
 3029   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3030     C2_MacroAssembler _masm(&amp;cbuf);
 3031     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3032     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3033                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3034                /*weak*/ false, noreg);
 3035   %}
 3036 
 3037   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3038     C2_MacroAssembler _masm(&amp;cbuf);
 3039     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3040     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3041                Assembler::word, /*acquire*/ false, /*release*/ true,
 3042                /*weak*/ false, noreg);
 3043   %}
 3044 
 3045   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3046     C2_MacroAssembler _masm(&amp;cbuf);
 3047     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3048     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3049                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3050                /*weak*/ false, noreg);
 3051   %}
 3052 
 3053   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3054     C2_MacroAssembler _masm(&amp;cbuf);
 3055     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3056     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3057                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3058                /*weak*/ false, noreg);
 3059   %}
 3060 
 3061 
 3062   // The only difference between aarch64_enc_cmpxchg and
 3063   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3064   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3065   // lock.
 3066   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3067     C2_MacroAssembler _masm(&amp;cbuf);
 3068     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3069     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3070                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3071                /*weak*/ false, noreg);
 3072   %}
 3073 
 3074   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3075     C2_MacroAssembler _masm(&amp;cbuf);
 3076     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3077     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3078                Assembler::word, /*acquire*/ true, /*release*/ true,
 3079                /*weak*/ false, noreg);
 3080   %}
 3081 
 3082   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3083     C2_MacroAssembler _masm(&amp;cbuf);
 3084     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3085     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3086                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3087                /*weak*/ false, noreg);
 3088   %}
 3089 
 3090   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3091     C2_MacroAssembler _masm(&amp;cbuf);
 3092     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3093     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3094                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3095                /*weak*/ false, noreg);
 3096   %}
 3097 
 3098   // auxiliary used for CompareAndSwapX to set result register
 3099   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3100     C2_MacroAssembler _masm(&amp;cbuf);
 3101     Register res_reg = as_Register($res$$reg);
 3102     __ cset(res_reg, Assembler::EQ);
 3103   %}
 3104 
 3105   // prefetch encodings
 3106 
 3107   enc_class aarch64_enc_prefetchw(memory mem) %{
 3108     C2_MacroAssembler _masm(&amp;cbuf);
 3109     Register base = as_Register($mem$$base);
 3110     int index = $mem$$index;
 3111     int scale = $mem$$scale;
 3112     int disp = $mem$$disp;
 3113     if (index == -1) {
 3114       __ prfm(Address(base, disp), PSTL1KEEP);
 3115     } else {
 3116       Register index_reg = as_Register(index);
 3117       if (disp == 0) {
 3118         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3119       } else {
 3120         __ lea(rscratch1, Address(base, disp));
 3121 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3122       }
 3123     }
 3124   %}
 3125 
 3126   /// mov envcodings
 3127 
 3128   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3129     C2_MacroAssembler _masm(&amp;cbuf);
<a name="3" id="anc3"></a><span class="line-modified"> 3130     uint32_t con = (uint32_t)$src$$constant;</span>
 3131     Register dst_reg = as_Register($dst$$reg);
 3132     if (con == 0) {
 3133       __ movw(dst_reg, zr);
 3134     } else {
 3135       __ movw(dst_reg, con);
 3136     }
 3137   %}
 3138 
 3139   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3140     C2_MacroAssembler _masm(&amp;cbuf);
 3141     Register dst_reg = as_Register($dst$$reg);
<a name="4" id="anc4"></a><span class="line-modified"> 3142     uint64_t con = (uint64_t)$src$$constant;</span>
 3143     if (con == 0) {
 3144       __ mov(dst_reg, zr);
 3145     } else {
 3146       __ mov(dst_reg, con);
 3147     }
 3148   %}
 3149 
 3150   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3151     C2_MacroAssembler _masm(&amp;cbuf);
 3152     Register dst_reg = as_Register($dst$$reg);
 3153     address con = (address)$src$$constant;
 3154     if (con == NULL || con == (address)1) {
 3155       ShouldNotReachHere();
 3156     } else {
 3157       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3158       if (rtype == relocInfo::oop_type) {
 3159         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3160       } else if (rtype == relocInfo::metadata_type) {
 3161         __ mov_metadata(dst_reg, (Metadata*)con);
 3162       } else {
 3163         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3164         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3165           __ mov(dst_reg, con);
 3166         } else {
 3167           unsigned long offset;
 3168           __ adrp(dst_reg, con, offset);
 3169           __ add(dst_reg, dst_reg, offset);
 3170         }
 3171       }
 3172     }
 3173   %}
 3174 
 3175   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3176     C2_MacroAssembler _masm(&amp;cbuf);
 3177     Register dst_reg = as_Register($dst$$reg);
 3178     __ mov(dst_reg, zr);
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3182     C2_MacroAssembler _masm(&amp;cbuf);
 3183     Register dst_reg = as_Register($dst$$reg);
<a name="5" id="anc5"></a><span class="line-modified"> 3184     __ mov(dst_reg, (uint64_t)1);</span>
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3188     C2_MacroAssembler _masm(&amp;cbuf);
 3189     __ load_byte_map_base($dst$$Register);
 3190   %}
 3191 
 3192   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3193     C2_MacroAssembler _masm(&amp;cbuf);
 3194     Register dst_reg = as_Register($dst$$reg);
 3195     address con = (address)$src$$constant;
 3196     if (con == NULL) {
 3197       ShouldNotReachHere();
 3198     } else {
 3199       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3200       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3201       __ set_narrow_oop(dst_reg, (jobject)con);
 3202     }
 3203   %}
 3204 
 3205   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3206     C2_MacroAssembler _masm(&amp;cbuf);
 3207     Register dst_reg = as_Register($dst$$reg);
 3208     __ mov(dst_reg, zr);
 3209   %}
 3210 
 3211   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3212     C2_MacroAssembler _masm(&amp;cbuf);
 3213     Register dst_reg = as_Register($dst$$reg);
 3214     address con = (address)$src$$constant;
 3215     if (con == NULL) {
 3216       ShouldNotReachHere();
 3217     } else {
 3218       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3219       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3220       __ set_narrow_klass(dst_reg, (Klass *)con);
 3221     }
 3222   %}
 3223 
 3224   // arithmetic encodings
 3225 
 3226   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3227     C2_MacroAssembler _masm(&amp;cbuf);
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     Register src_reg = as_Register($src1$$reg);
 3230     int32_t con = (int32_t)$src2$$constant;
 3231     // add has primary == 0, subtract has primary == 1
 3232     if ($primary) { con = -con; }
 3233     if (con &lt; 0) {
 3234       __ subw(dst_reg, src_reg, -con);
 3235     } else {
 3236       __ addw(dst_reg, src_reg, con);
 3237     }
 3238   %}
 3239 
 3240   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3241     C2_MacroAssembler _masm(&amp;cbuf);
 3242     Register dst_reg = as_Register($dst$$reg);
 3243     Register src_reg = as_Register($src1$$reg);
 3244     int32_t con = (int32_t)$src2$$constant;
 3245     // add has primary == 0, subtract has primary == 1
 3246     if ($primary) { con = -con; }
 3247     if (con &lt; 0) {
 3248       __ sub(dst_reg, src_reg, -con);
 3249     } else {
 3250       __ add(dst_reg, src_reg, con);
 3251     }
 3252   %}
 3253 
 3254   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3255     C2_MacroAssembler _masm(&amp;cbuf);
 3256    Register dst_reg = as_Register($dst$$reg);
 3257    Register src1_reg = as_Register($src1$$reg);
 3258    Register src2_reg = as_Register($src2$$reg);
 3259     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3260   %}
 3261 
 3262   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3263     C2_MacroAssembler _masm(&amp;cbuf);
 3264    Register dst_reg = as_Register($dst$$reg);
 3265    Register src1_reg = as_Register($src1$$reg);
 3266    Register src2_reg = as_Register($src2$$reg);
 3267     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3268   %}
 3269 
 3270   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     C2_MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3279     C2_MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3284   %}
 3285 
 3286   // compare instruction encodings
 3287 
 3288   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3289     C2_MacroAssembler _masm(&amp;cbuf);
 3290     Register reg1 = as_Register($src1$$reg);
 3291     Register reg2 = as_Register($src2$$reg);
 3292     __ cmpw(reg1, reg2);
 3293   %}
 3294 
 3295   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3296     C2_MacroAssembler _masm(&amp;cbuf);
 3297     Register reg = as_Register($src1$$reg);
 3298     int32_t val = $src2$$constant;
 3299     if (val &gt;= 0) {
 3300       __ subsw(zr, reg, val);
 3301     } else {
 3302       __ addsw(zr, reg, -val);
 3303     }
 3304   %}
 3305 
 3306   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3307     C2_MacroAssembler _masm(&amp;cbuf);
 3308     Register reg1 = as_Register($src1$$reg);
<a name="6" id="anc6"></a><span class="line-modified"> 3309     uint32_t val = (uint32_t)$src2$$constant;</span>
 3310     __ movw(rscratch1, val);
 3311     __ cmpw(reg1, rscratch1);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3315     C2_MacroAssembler _masm(&amp;cbuf);
 3316     Register reg1 = as_Register($src1$$reg);
 3317     Register reg2 = as_Register($src2$$reg);
 3318     __ cmp(reg1, reg2);
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3322     C2_MacroAssembler _masm(&amp;cbuf);
 3323     Register reg = as_Register($src1$$reg);
 3324     int64_t val = $src2$$constant;
 3325     if (val &gt;= 0) {
 3326       __ subs(zr, reg, val);
 3327     } else if (val != -val) {
 3328       __ adds(zr, reg, -val);
 3329     } else {
 3330     // aargh, Long.MIN_VALUE is a special case
<a name="7" id="anc7"></a><span class="line-modified"> 3331       __ orr(rscratch1, zr, (uint64_t)val);</span>
 3332       __ subs(zr, reg, rscratch1);
 3333     }
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3337     C2_MacroAssembler _masm(&amp;cbuf);
 3338     Register reg1 = as_Register($src1$$reg);
<a name="8" id="anc8"></a><span class="line-modified"> 3339     uint64_t val = (uint64_t)$src2$$constant;</span>
 3340     __ mov(rscratch1, val);
 3341     __ cmp(reg1, rscratch1);
 3342   %}
 3343 
 3344   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3345     C2_MacroAssembler _masm(&amp;cbuf);
 3346     Register reg1 = as_Register($src1$$reg);
 3347     Register reg2 = as_Register($src2$$reg);
 3348     __ cmp(reg1, reg2);
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3352     C2_MacroAssembler _masm(&amp;cbuf);
 3353     Register reg1 = as_Register($src1$$reg);
 3354     Register reg2 = as_Register($src2$$reg);
 3355     __ cmpw(reg1, reg2);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_testp(iRegP src) %{
 3359     C2_MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src$$reg);
 3361     __ cmp(reg, zr);
 3362   %}
 3363 
 3364   enc_class aarch64_enc_testn(iRegN src) %{
 3365     C2_MacroAssembler _masm(&amp;cbuf);
 3366     Register reg = as_Register($src$$reg);
 3367     __ cmpw(reg, zr);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_b(label lbl) %{
 3371     C2_MacroAssembler _masm(&amp;cbuf);
 3372     Label *L = $lbl$$label;
 3373     __ b(*L);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Label *L = $lbl$$label;
 3379     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3383     C2_MacroAssembler _masm(&amp;cbuf);
 3384     Label *L = $lbl$$label;
 3385     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3386   %}
 3387 
 3388   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3389   %{
 3390      Register sub_reg = as_Register($sub$$reg);
 3391      Register super_reg = as_Register($super$$reg);
 3392      Register temp_reg = as_Register($temp$$reg);
 3393      Register result_reg = as_Register($result$$reg);
 3394 
 3395      Label miss;
 3396      C2_MacroAssembler _masm(&amp;cbuf);
 3397      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3398                                      NULL, &amp;miss,
 3399                                      /*set_cond_codes:*/ true);
 3400      if ($primary) {
 3401        __ mov(result_reg, zr);
 3402      }
 3403      __ bind(miss);
 3404   %}
 3405 
 3406   enc_class aarch64_enc_java_static_call(method meth) %{
 3407     C2_MacroAssembler _masm(&amp;cbuf);
 3408 
 3409     address addr = (address)$meth$$method;
 3410     address call;
 3411     if (!_method) {
 3412       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3413       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3414     } else {
 3415       int method_index = resolved_method_index(cbuf);
 3416       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3417                                                   : static_call_Relocation::spec(method_index);
 3418       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3419 
 3420       // Emit stub for static call
 3421       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3422       if (stub == NULL) {
 3423         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3424         return;
 3425       }
 3426     }
 3427     if (call == NULL) {
 3428       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3429       return;
 3430     }
 3431   %}
 3432 
 3433   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3434     C2_MacroAssembler _masm(&amp;cbuf);
 3435     int method_index = resolved_method_index(cbuf);
 3436     address call = __ ic_call((address)$meth$$method, method_index);
 3437     if (call == NULL) {
 3438       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439       return;
 3440     }
 3441   %}
 3442 
 3443   enc_class aarch64_enc_call_epilog() %{
 3444     C2_MacroAssembler _masm(&amp;cbuf);
 3445     if (VerifyStackAtCalls) {
 3446       // Check that stack depth is unchanged: find majik cookie on stack
 3447       __ call_Unimplemented();
 3448     }
 3449   %}
 3450 
 3451   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3452     C2_MacroAssembler _masm(&amp;cbuf);
 3453 
 3454     // some calls to generated routines (arraycopy code) are scheduled
 3455     // by C2 as runtime calls. if so we can call them using a br (they
 3456     // will be in a reachable segment) otherwise we have to use a blr
 3457     // which loads the absolute address into a register.
 3458     address entry = (address)$meth$$method;
 3459     CodeBlob *cb = CodeCache::find_blob(entry);
 3460     if (cb) {
 3461       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3462       if (call == NULL) {
 3463         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3464         return;
 3465       }
 3466     } else {
 3467       Label retaddr;
 3468       __ adr(rscratch2, retaddr);
 3469       __ lea(rscratch1, RuntimeAddress(entry));
 3470       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3471       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3472       __ blr(rscratch1);
 3473       __ bind(retaddr);
 3474       __ add(sp, sp, 2 * wordSize);
 3475     }
 3476   %}
 3477 
 3478   enc_class aarch64_enc_rethrow() %{
 3479     C2_MacroAssembler _masm(&amp;cbuf);
 3480     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3481   %}
 3482 
 3483   enc_class aarch64_enc_ret() %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485     __ ret(lr);
 3486   %}
 3487 
 3488   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3489     C2_MacroAssembler _masm(&amp;cbuf);
 3490     Register target_reg = as_Register($jump_target$$reg);
 3491     __ br(target_reg);
 3492   %}
 3493 
 3494   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3495     C2_MacroAssembler _masm(&amp;cbuf);
 3496     Register target_reg = as_Register($jump_target$$reg);
 3497     // exception oop should be in r0
 3498     // ret addr has been popped into lr
 3499     // callee expects it in r3
 3500     __ mov(r3, lr);
 3501     __ br(target_reg);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3505     C2_MacroAssembler _masm(&amp;cbuf);
 3506     Register oop = as_Register($object$$reg);
 3507     Register box = as_Register($box$$reg);
 3508     Register disp_hdr = as_Register($tmp$$reg);
 3509     Register tmp = as_Register($tmp2$$reg);
 3510     Label cont;
 3511     Label object_has_monitor;
 3512     Label cas_failed;
 3513 
 3514     assert_different_registers(oop, box, tmp, disp_hdr);
 3515 
 3516     // Load markWord from object into displaced_header.
 3517     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3518 
 3519     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3520       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3521     }
 3522 
 3523     // Check for existing monitor
 3524     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3525 
 3526     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3527     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3528 
 3529     // Initialize the box. (Must happen before we update the object mark!)
 3530     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3531 
 3532     // Compare object markWord with an unlocked value (tmp) and if
 3533     // equal exchange the stack address of our box with object markWord.
 3534     // On failure disp_hdr contains the possibly locked markWord.
 3535     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3536                /*release*/ true, /*weak*/ false, disp_hdr);
 3537     __ br(Assembler::EQ, cont);
 3538 
 3539     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3540 
 3541     // If the compare-and-exchange succeeded, then we found an unlocked
 3542     // object, will have now locked it will continue at label cont
 3543 
 3544     __ bind(cas_failed);
 3545     // We did not see an unlocked object so try the fast recursive case.
 3546 
 3547     // Check if the owner is self by comparing the value in the
 3548     // markWord of object (disp_hdr) with the stack pointer.
 3549     __ mov(rscratch1, sp);
 3550     __ sub(disp_hdr, disp_hdr, rscratch1);
 3551     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3552     // If condition is true we are cont and hence we can store 0 as the
 3553     // displaced header in the box, which indicates that it is a recursive lock.
 3554     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3555     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3556 
 3557     __ b(cont);
 3558 
 3559     // Handle existing monitor.
 3560     __ bind(object_has_monitor);
 3561 
 3562     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3563     // otherwise m-&gt;owner may contain a thread or a stack address.
 3564     //
 3565     // Try to CAS m-&gt;owner from NULL to current thread.
 3566     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3567     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3569 
 3570     // Store a non-null value into the box to avoid looking like a re-entrant
 3571     // lock. The fast-path monitor unlock code checks for
 3572     // markWord::monitor_value so use markWord::unused_mark which has the
 3573     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3574     __ mov(tmp, (address)markWord::unused_mark().value());
 3575     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3576 
 3577     __ bind(cont);
 3578     // flag == EQ indicates success
 3579     // flag == NE indicates failure
 3580   %}
 3581 
 3582   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3583     C2_MacroAssembler _masm(&amp;cbuf);
 3584     Register oop = as_Register($object$$reg);
 3585     Register box = as_Register($box$$reg);
 3586     Register disp_hdr = as_Register($tmp$$reg);
 3587     Register tmp = as_Register($tmp2$$reg);
 3588     Label cont;
 3589     Label object_has_monitor;
 3590 
 3591     assert_different_registers(oop, box, tmp, disp_hdr);
 3592 
 3593     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3594       __ biased_locking_exit(oop, tmp, cont);
 3595     }
 3596 
 3597     // Find the lock address and load the displaced header from the stack.
 3598     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3599 
 3600     // If the displaced header is 0, we have a recursive unlock.
 3601     __ cmp(disp_hdr, zr);
 3602     __ br(Assembler::EQ, cont);
 3603 
 3604     // Handle existing monitor.
 3605     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3606     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3607 
 3608     // Check if it is still a light weight lock, this is is true if we
 3609     // see the stack address of the basicLock in the markWord of the
 3610     // object.
 3611 
 3612     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3613                /*release*/ true, /*weak*/ false, tmp);
 3614     __ b(cont);
 3615 
 3616     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3617 
 3618     // Handle existing monitor.
 3619     __ bind(object_has_monitor);
 3620     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3621     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3622     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3623     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3624     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3625     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3626     __ cmp(rscratch1, zr); // Sets flags for result
 3627     __ br(Assembler::NE, cont);
 3628 
 3629     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3630     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3631     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3632     __ cmp(rscratch1, zr); // Sets flags for result
 3633     __ cbnz(rscratch1, cont);
 3634     // need a release store here
 3635     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3636     __ stlr(zr, tmp); // set unowned
 3637 
 3638     __ bind(cont);
 3639     // flag == EQ indicates success
 3640     // flag == NE indicates failure
 3641   %}
 3642 
 3643 %}
 3644 
 3645 //----------FRAME--------------------------------------------------------------
 3646 // Definition of frame structure and management information.
 3647 //
 3648 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3649 //                             |   (to get allocators register number
 3650 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3651 //  r   CALLER     |        |
 3652 //  o     |        +--------+      pad to even-align allocators stack-slot
 3653 //  w     V        |  pad0  |        numbers; owned by CALLER
 3654 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3655 //  h     ^        |   in   |  5
 3656 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3657 //  |     |        |        |  3
 3658 //  |     |        +--------+
 3659 //  V     |        | old out|      Empty on Intel, window on Sparc
 3660 //        |    old |preserve|      Must be even aligned.
 3661 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3662 //        |        |   in   |  3   area for Intel ret address
 3663 //     Owned by    |preserve|      Empty on Sparc.
 3664 //       SELF      +--------+
 3665 //        |        |  pad2  |  2   pad to align old SP
 3666 //        |        +--------+  1
 3667 //        |        | locks  |  0
 3668 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3669 //        |        |  pad1  | 11   pad to align new SP
 3670 //        |        +--------+
 3671 //        |        |        | 10
 3672 //        |        | spills |  9   spills
 3673 //        V        |        |  8   (pad0 slot for callee)
 3674 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3675 //        ^        |  out   |  7
 3676 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3677 //     Owned by    +--------+
 3678 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3679 //        |    new |preserve|      Must be even-aligned.
 3680 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3681 //        |        |        |
 3682 //
 3683 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3684 //         known from SELF&#39;s arguments and the Java calling convention.
 3685 //         Region 6-7 is determined per call site.
 3686 // Note 2: If the calling convention leaves holes in the incoming argument
 3687 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3688 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3689 //         incoming area, as the Java calling convention is completely under
 3690 //         the control of the AD file.  Doubles can be sorted and packed to
 3691 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3692 //         varargs C calling conventions.
 3693 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3694 //         even aligned with pad0 as needed.
 3695 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3696 //           (the latter is true on Intel but is it false on AArch64?)
 3697 //         region 6-11 is even aligned; it may be padded out more so that
 3698 //         the region from SP to FP meets the minimum stack alignment.
 3699 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3700 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3701 //         SP meets the minimum alignment.
 3702 
 3703 frame %{
 3704   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3705   stack_direction(TOWARDS_LOW);
 3706 
 3707   // These three registers define part of the calling convention
 3708   // between compiled code and the interpreter.
 3709 
 3710   // Inline Cache Register or methodOop for I2C.
 3711   inline_cache_reg(R12);
 3712 
 3713   // Method Oop Register when calling interpreter.
 3714   interpreter_method_oop_reg(R12);
 3715 
 3716   // Number of stack slots consumed by locking an object
 3717   sync_stack_slots(2);
 3718 
 3719   // Compiled code&#39;s Frame Pointer
 3720   frame_pointer(R31);
 3721 
 3722   // Interpreter stores its frame pointer in a register which is
 3723   // stored to the stack by I2CAdaptors.
 3724   // I2CAdaptors convert from interpreted java to compiled java.
 3725   interpreter_frame_pointer(R29);
 3726 
 3727   // Stack alignment requirement
 3728   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3729 
 3730   // Number of stack slots between incoming argument block and the start of
 3731   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3732   // EPILOG must remove this many slots. aarch64 needs two slots for
 3733   // return address and fp.
 3734   // TODO think this is correct but check
 3735   in_preserve_stack_slots(4);
 3736 
 3737   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3738   // for calls to C.  Supports the var-args backing area for register parms.
 3739   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3740 
 3741   // The after-PROLOG location of the return address.  Location of
 3742   // return address specifies a type (REG or STACK) and a number
 3743   // representing the register number (i.e. - use a register name) or
 3744   // stack slot.
 3745   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3746   // Otherwise, it is above the locks and verification slot and alignment word
 3747   // TODO this may well be correct but need to check why that - 2 is there
 3748   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3749   // which folds in the space used for monitors
 3750   return_addr(STACK - 2 +
 3751               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3752                         Compile::current()-&gt;fixed_slots()),
 3753                        stack_alignment_in_slots()));
 3754 
 3755   // Body of function which returns an integer array locating
 3756   // arguments either in registers or in stack slots.  Passed an array
 3757   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3758   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3759   // arguments for a CALLEE.  Incoming stack arguments are
 3760   // automatically biased by the preserve_stack_slots field above.
 3761 
 3762   calling_convention
 3763   %{
 3764     // No difference between ingoing/outgoing just pass false
 3765     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3766   %}
 3767 
 3768   c_calling_convention
 3769   %{
 3770     // This is obviously always outgoing
 3771     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3772   %}
 3773 
 3774   // Location of compiled Java return values.  Same as C for now.
 3775   return_value
 3776   %{
 3777     // TODO do we allow ideal_reg == Op_RegN???
 3778     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3779            &quot;only return normal values&quot;);
 3780 
 3781     static const int lo[Op_RegL + 1] = { // enum name
 3782       0,                                 // Op_Node
 3783       0,                                 // Op_Set
 3784       R0_num,                            // Op_RegN
 3785       R0_num,                            // Op_RegI
 3786       R0_num,                            // Op_RegP
 3787       V0_num,                            // Op_RegF
 3788       V0_num,                            // Op_RegD
 3789       R0_num                             // Op_RegL
 3790     };
 3791 
 3792     static const int hi[Op_RegL + 1] = { // enum name
 3793       0,                                 // Op_Node
 3794       0,                                 // Op_Set
 3795       OptoReg::Bad,                      // Op_RegN
 3796       OptoReg::Bad,                      // Op_RegI
 3797       R0_H_num,                          // Op_RegP
 3798       OptoReg::Bad,                      // Op_RegF
 3799       V0_H_num,                          // Op_RegD
 3800       R0_H_num                           // Op_RegL
 3801     };
 3802 
 3803     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3804   %}
 3805 %}
 3806 
 3807 //----------ATTRIBUTES---------------------------------------------------------
 3808 //----------Operand Attributes-------------------------------------------------
 3809 op_attrib op_cost(1);        // Required cost attribute
 3810 
 3811 //----------Instruction Attributes---------------------------------------------
 3812 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3813 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3814 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3815                                 // a non-matching short branch variant
 3816                                 // of some long branch?
 3817 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3818                                 // be a power of 2) specifies the
 3819                                 // alignment that some part of the
 3820                                 // instruction (not necessarily the
 3821                                 // start) requires.  If &gt; 1, a
 3822                                 // compute_padding() function must be
 3823                                 // provided for the instruction
 3824 
 3825 //----------OPERANDS-----------------------------------------------------------
 3826 // Operand definitions must precede instruction definitions for correct parsing
 3827 // in the ADLC because operands constitute user defined types which are used in
 3828 // instruction definitions.
 3829 
 3830 //----------Simple Operands----------------------------------------------------
 3831 
 3832 // Integer operands 32 bit
 3833 // 32 bit immediate
 3834 operand immI()
 3835 %{
 3836   match(ConI);
 3837 
 3838   op_cost(0);
 3839   format %{ %}
 3840   interface(CONST_INTER);
 3841 %}
 3842 
 3843 // 32 bit zero
 3844 operand immI0()
 3845 %{
 3846   predicate(n-&gt;get_int() == 0);
 3847   match(ConI);
 3848 
 3849   op_cost(0);
 3850   format %{ %}
 3851   interface(CONST_INTER);
 3852 %}
 3853 
 3854 // 32 bit unit increment
 3855 operand immI_1()
 3856 %{
 3857   predicate(n-&gt;get_int() == 1);
 3858   match(ConI);
 3859 
 3860   op_cost(0);
 3861   format %{ %}
 3862   interface(CONST_INTER);
 3863 %}
 3864 
 3865 // 32 bit unit decrement
 3866 operand immI_M1()
 3867 %{
 3868   predicate(n-&gt;get_int() == -1);
 3869   match(ConI);
 3870 
 3871   op_cost(0);
 3872   format %{ %}
 3873   interface(CONST_INTER);
 3874 %}
 3875 
 3876 // Shift values for add/sub extension shift
 3877 operand immIExt()
 3878 %{
 3879   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3880   match(ConI);
 3881 
 3882   op_cost(0);
 3883   format %{ %}
 3884   interface(CONST_INTER);
 3885 %}
 3886 
 3887 operand immI_le_4()
 3888 %{
 3889   predicate(n-&gt;get_int() &lt;= 4);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 operand immI_31()
 3898 %{
 3899   predicate(n-&gt;get_int() == 31);
 3900   match(ConI);
 3901 
 3902   op_cost(0);
 3903   format %{ %}
 3904   interface(CONST_INTER);
 3905 %}
 3906 
 3907 operand immI_8()
 3908 %{
 3909   predicate(n-&gt;get_int() == 8);
 3910   match(ConI);
 3911 
 3912   op_cost(0);
 3913   format %{ %}
 3914   interface(CONST_INTER);
 3915 %}
 3916 
 3917 operand immI_16()
 3918 %{
 3919   predicate(n-&gt;get_int() == 16);
 3920   match(ConI);
 3921 
 3922   op_cost(0);
 3923   format %{ %}
 3924   interface(CONST_INTER);
 3925 %}
 3926 
 3927 operand immI_24()
 3928 %{
 3929   predicate(n-&gt;get_int() == 24);
 3930   match(ConI);
 3931 
 3932   op_cost(0);
 3933   format %{ %}
 3934   interface(CONST_INTER);
 3935 %}
 3936 
 3937 operand immI_32()
 3938 %{
 3939   predicate(n-&gt;get_int() == 32);
 3940   match(ConI);
 3941 
 3942   op_cost(0);
 3943   format %{ %}
 3944   interface(CONST_INTER);
 3945 %}
 3946 
 3947 operand immI_48()
 3948 %{
 3949   predicate(n-&gt;get_int() == 48);
 3950   match(ConI);
 3951 
 3952   op_cost(0);
 3953   format %{ %}
 3954   interface(CONST_INTER);
 3955 %}
 3956 
 3957 operand immI_56()
 3958 %{
 3959   predicate(n-&gt;get_int() == 56);
 3960   match(ConI);
 3961 
 3962   op_cost(0);
 3963   format %{ %}
 3964   interface(CONST_INTER);
 3965 %}
 3966 
 3967 operand immI_63()
 3968 %{
 3969   predicate(n-&gt;get_int() == 63);
 3970   match(ConI);
 3971 
 3972   op_cost(0);
 3973   format %{ %}
 3974   interface(CONST_INTER);
 3975 %}
 3976 
 3977 operand immI_64()
 3978 %{
 3979   predicate(n-&gt;get_int() == 64);
 3980   match(ConI);
 3981 
 3982   op_cost(0);
 3983   format %{ %}
 3984   interface(CONST_INTER);
 3985 %}
 3986 
 3987 operand immI_255()
 3988 %{
 3989   predicate(n-&gt;get_int() == 255);
 3990   match(ConI);
 3991 
 3992   op_cost(0);
 3993   format %{ %}
 3994   interface(CONST_INTER);
 3995 %}
 3996 
 3997 operand immI_65535()
 3998 %{
 3999   predicate(n-&gt;get_int() == 65535);
 4000   match(ConI);
 4001 
 4002   op_cost(0);
 4003   format %{ %}
 4004   interface(CONST_INTER);
 4005 %}
 4006 
 4007 operand immL_255()
 4008 %{
 4009   predicate(n-&gt;get_long() == 255L);
 4010   match(ConL);
 4011 
 4012   op_cost(0);
 4013   format %{ %}
 4014   interface(CONST_INTER);
 4015 %}
 4016 
 4017 operand immL_65535()
 4018 %{
 4019   predicate(n-&gt;get_long() == 65535L);
 4020   match(ConL);
 4021 
 4022   op_cost(0);
 4023   format %{ %}
 4024   interface(CONST_INTER);
 4025 %}
 4026 
 4027 operand immL_4294967295()
 4028 %{
 4029   predicate(n-&gt;get_long() == 4294967295L);
 4030   match(ConL);
 4031 
 4032   op_cost(0);
 4033   format %{ %}
 4034   interface(CONST_INTER);
 4035 %}
 4036 
 4037 operand immL_bitmask()
 4038 %{
 4039   predicate((n-&gt;get_long() != 0)
 4040             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4041             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immI_bitmask()
 4050 %{
 4051   predicate((n-&gt;get_int() != 0)
 4052             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4053             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4054   match(ConI);
 4055 
 4056   op_cost(0);
 4057   format %{ %}
 4058   interface(CONST_INTER);
 4059 %}
 4060 
 4061 // Scale values for scaled offset addressing modes (up to long but not quad)
 4062 operand immIScale()
 4063 %{
 4064   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4065   match(ConI);
 4066 
 4067   op_cost(0);
 4068   format %{ %}
 4069   interface(CONST_INTER);
 4070 %}
 4071 
 4072 // 26 bit signed offset -- for pc-relative branches
 4073 operand immI26()
 4074 %{
 4075   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4076   match(ConI);
 4077 
 4078   op_cost(0);
 4079   format %{ %}
 4080   interface(CONST_INTER);
 4081 %}
 4082 
 4083 // 19 bit signed offset -- for pc-relative loads
 4084 operand immI19()
 4085 %{
 4086   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4087   match(ConI);
 4088 
 4089   op_cost(0);
 4090   format %{ %}
 4091   interface(CONST_INTER);
 4092 %}
 4093 
 4094 // 12 bit unsigned offset -- for base plus immediate loads
 4095 operand immIU12()
 4096 %{
 4097   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4098   match(ConI);
 4099 
 4100   op_cost(0);
 4101   format %{ %}
 4102   interface(CONST_INTER);
 4103 %}
 4104 
 4105 operand immLU12()
 4106 %{
 4107   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4108   match(ConL);
 4109 
 4110   op_cost(0);
 4111   format %{ %}
 4112   interface(CONST_INTER);
 4113 %}
 4114 
 4115 // Offset for scaled or unscaled immediate loads and stores
 4116 operand immIOffset()
 4117 %{
 4118   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4119   match(ConI);
 4120 
 4121   op_cost(0);
 4122   format %{ %}
 4123   interface(CONST_INTER);
 4124 %}
 4125 
 4126 operand immIOffset1()
 4127 %{
 4128   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4129   match(ConI);
 4130 
 4131   op_cost(0);
 4132   format %{ %}
 4133   interface(CONST_INTER);
 4134 %}
 4135 
 4136 operand immIOffset2()
 4137 %{
 4138   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4139   match(ConI);
 4140 
 4141   op_cost(0);
 4142   format %{ %}
 4143   interface(CONST_INTER);
 4144 %}
 4145 
 4146 operand immIOffset4()
 4147 %{
 4148   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4149   match(ConI);
 4150 
 4151   op_cost(0);
 4152   format %{ %}
 4153   interface(CONST_INTER);
 4154 %}
 4155 
 4156 operand immIOffset8()
 4157 %{
 4158   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4159   match(ConI);
 4160 
 4161   op_cost(0);
 4162   format %{ %}
 4163   interface(CONST_INTER);
 4164 %}
 4165 
 4166 operand immIOffset16()
 4167 %{
 4168   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4169   match(ConI);
 4170 
 4171   op_cost(0);
 4172   format %{ %}
 4173   interface(CONST_INTER);
 4174 %}
 4175 
 4176 operand immLoffset()
 4177 %{
 4178   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4179   match(ConL);
 4180 
 4181   op_cost(0);
 4182   format %{ %}
 4183   interface(CONST_INTER);
 4184 %}
 4185 
 4186 operand immLoffset1()
 4187 %{
 4188   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4189   match(ConL);
 4190 
 4191   op_cost(0);
 4192   format %{ %}
 4193   interface(CONST_INTER);
 4194 %}
 4195 
 4196 operand immLoffset2()
 4197 %{
 4198   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4199   match(ConL);
 4200 
 4201   op_cost(0);
 4202   format %{ %}
 4203   interface(CONST_INTER);
 4204 %}
 4205 
 4206 operand immLoffset4()
 4207 %{
 4208   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4209   match(ConL);
 4210 
 4211   op_cost(0);
 4212   format %{ %}
 4213   interface(CONST_INTER);
 4214 %}
 4215 
 4216 operand immLoffset8()
 4217 %{
 4218   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4219   match(ConL);
 4220 
 4221   op_cost(0);
 4222   format %{ %}
 4223   interface(CONST_INTER);
 4224 %}
 4225 
 4226 operand immLoffset16()
 4227 %{
 4228   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4229   match(ConL);
 4230 
 4231   op_cost(0);
 4232   format %{ %}
 4233   interface(CONST_INTER);
 4234 %}
 4235 
 4236 // 32 bit integer valid for add sub immediate
 4237 operand immIAddSub()
 4238 %{
 4239   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4240   match(ConI);
 4241   op_cost(0);
 4242   format %{ %}
 4243   interface(CONST_INTER);
 4244 %}
 4245 
 4246 // 32 bit unsigned integer valid for logical immediate
 4247 // TODO -- check this is right when e.g the mask is 0x80000000
 4248 operand immILog()
 4249 %{
 4250   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4251   match(ConI);
 4252 
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 // Integer operands 64 bit
 4259 // 64 bit immediate
 4260 operand immL()
 4261 %{
 4262   match(ConL);
 4263 
 4264   op_cost(0);
 4265   format %{ %}
 4266   interface(CONST_INTER);
 4267 %}
 4268 
 4269 // 64 bit zero
 4270 operand immL0()
 4271 %{
 4272   predicate(n-&gt;get_long() == 0);
 4273   match(ConL);
 4274 
 4275   op_cost(0);
 4276   format %{ %}
 4277   interface(CONST_INTER);
 4278 %}
 4279 
 4280 // 64 bit unit increment
 4281 operand immL_1()
 4282 %{
 4283   predicate(n-&gt;get_long() == 1);
 4284   match(ConL);
 4285 
 4286   op_cost(0);
 4287   format %{ %}
 4288   interface(CONST_INTER);
 4289 %}
 4290 
 4291 // 64 bit unit decrement
 4292 operand immL_M1()
 4293 %{
 4294   predicate(n-&gt;get_long() == -1);
 4295   match(ConL);
 4296 
 4297   op_cost(0);
 4298   format %{ %}
 4299   interface(CONST_INTER);
 4300 %}
 4301 
 4302 // 32 bit offset of pc in thread anchor
 4303 
 4304 operand immL_pc_off()
 4305 %{
 4306   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4307                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4308   match(ConL);
 4309 
 4310   op_cost(0);
 4311   format %{ %}
 4312   interface(CONST_INTER);
 4313 %}
 4314 
 4315 // 64 bit integer valid for add sub immediate
 4316 operand immLAddSub()
 4317 %{
 4318   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4319   match(ConL);
 4320   op_cost(0);
 4321   format %{ %}
 4322   interface(CONST_INTER);
 4323 %}
 4324 
 4325 // 64 bit integer valid for logical immediate
 4326 operand immLLog()
 4327 %{
 4328   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4329   match(ConL);
 4330   op_cost(0);
 4331   format %{ %}
 4332   interface(CONST_INTER);
 4333 %}
 4334 
 4335 // Long Immediate: low 32-bit mask
 4336 operand immL_32bits()
 4337 %{
 4338   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4339   match(ConL);
 4340   op_cost(0);
 4341   format %{ %}
 4342   interface(CONST_INTER);
 4343 %}
 4344 
 4345 // Pointer operands
 4346 // Pointer Immediate
 4347 operand immP()
 4348 %{
 4349   match(ConP);
 4350 
 4351   op_cost(0);
 4352   format %{ %}
 4353   interface(CONST_INTER);
 4354 %}
 4355 
 4356 // NULL Pointer Immediate
 4357 operand immP0()
 4358 %{
 4359   predicate(n-&gt;get_ptr() == 0);
 4360   match(ConP);
 4361 
 4362   op_cost(0);
 4363   format %{ %}
 4364   interface(CONST_INTER);
 4365 %}
 4366 
 4367 // Pointer Immediate One
 4368 // this is used in object initialization (initial object header)
 4369 operand immP_1()
 4370 %{
 4371   predicate(n-&gt;get_ptr() == 1);
 4372   match(ConP);
 4373 
 4374   op_cost(0);
 4375   format %{ %}
 4376   interface(CONST_INTER);
 4377 %}
 4378 
 4379 // Card Table Byte Map Base
 4380 operand immByteMapBase()
 4381 %{
 4382   // Get base of card map
 4383   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4384             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4385   match(ConP);
 4386 
 4387   op_cost(0);
 4388   format %{ %}
 4389   interface(CONST_INTER);
 4390 %}
 4391 
 4392 // Pointer Immediate Minus One
 4393 // this is used when we want to write the current PC to the thread anchor
 4394 operand immP_M1()
 4395 %{
 4396   predicate(n-&gt;get_ptr() == -1);
 4397   match(ConP);
 4398 
 4399   op_cost(0);
 4400   format %{ %}
 4401   interface(CONST_INTER);
 4402 %}
 4403 
 4404 // Pointer Immediate Minus Two
 4405 // this is used when we want to write the current PC to the thread anchor
 4406 operand immP_M2()
 4407 %{
 4408   predicate(n-&gt;get_ptr() == -2);
 4409   match(ConP);
 4410 
 4411   op_cost(0);
 4412   format %{ %}
 4413   interface(CONST_INTER);
 4414 %}
 4415 
 4416 // Float and Double operands
 4417 // Double Immediate
 4418 operand immD()
 4419 %{
 4420   match(ConD);
 4421   op_cost(0);
 4422   format %{ %}
 4423   interface(CONST_INTER);
 4424 %}
 4425 
 4426 // Double Immediate: +0.0d
 4427 operand immD0()
 4428 %{
 4429   predicate(jlong_cast(n-&gt;getd()) == 0);
 4430   match(ConD);
 4431 
 4432   op_cost(0);
 4433   format %{ %}
 4434   interface(CONST_INTER);
 4435 %}
 4436 
 4437 // constant &#39;double +0.0&#39;.
 4438 operand immDPacked()
 4439 %{
 4440   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4441   match(ConD);
 4442   op_cost(0);
 4443   format %{ %}
 4444   interface(CONST_INTER);
 4445 %}
 4446 
 4447 // Float Immediate
 4448 operand immF()
 4449 %{
 4450   match(ConF);
 4451   op_cost(0);
 4452   format %{ %}
 4453   interface(CONST_INTER);
 4454 %}
 4455 
 4456 // Float Immediate: +0.0f.
 4457 operand immF0()
 4458 %{
 4459   predicate(jint_cast(n-&gt;getf()) == 0);
 4460   match(ConF);
 4461 
 4462   op_cost(0);
 4463   format %{ %}
 4464   interface(CONST_INTER);
 4465 %}
 4466 
 4467 //
 4468 operand immFPacked()
 4469 %{
 4470   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4471   match(ConF);
 4472   op_cost(0);
 4473   format %{ %}
 4474   interface(CONST_INTER);
 4475 %}
 4476 
 4477 // Narrow pointer operands
 4478 // Narrow Pointer Immediate
 4479 operand immN()
 4480 %{
 4481   match(ConN);
 4482 
 4483   op_cost(0);
 4484   format %{ %}
 4485   interface(CONST_INTER);
 4486 %}
 4487 
 4488 // Narrow NULL Pointer Immediate
 4489 operand immN0()
 4490 %{
 4491   predicate(n-&gt;get_narrowcon() == 0);
 4492   match(ConN);
 4493 
 4494   op_cost(0);
 4495   format %{ %}
 4496   interface(CONST_INTER);
 4497 %}
 4498 
 4499 operand immNKlass()
 4500 %{
 4501   match(ConNKlass);
 4502 
 4503   op_cost(0);
 4504   format %{ %}
 4505   interface(CONST_INTER);
 4506 %}
 4507 
 4508 // Integer 32 bit Register Operands
 4509 // Integer 32 bitRegister (excludes SP)
 4510 operand iRegI()
 4511 %{
 4512   constraint(ALLOC_IN_RC(any_reg32));
 4513   match(RegI);
 4514   match(iRegINoSp);
 4515   op_cost(0);
 4516   format %{ %}
 4517   interface(REG_INTER);
 4518 %}
 4519 
 4520 // Integer 32 bit Register not Special
 4521 operand iRegINoSp()
 4522 %{
 4523   constraint(ALLOC_IN_RC(no_special_reg32));
 4524   match(RegI);
 4525   op_cost(0);
 4526   format %{ %}
 4527   interface(REG_INTER);
 4528 %}
 4529 
 4530 // Integer 64 bit Register Operands
 4531 // Integer 64 bit Register (includes SP)
 4532 operand iRegL()
 4533 %{
 4534   constraint(ALLOC_IN_RC(any_reg));
 4535   match(RegL);
 4536   match(iRegLNoSp);
 4537   op_cost(0);
 4538   format %{ %}
 4539   interface(REG_INTER);
 4540 %}
 4541 
 4542 // Integer 64 bit Register not Special
 4543 operand iRegLNoSp()
 4544 %{
 4545   constraint(ALLOC_IN_RC(no_special_reg));
 4546   match(RegL);
 4547   match(iRegL_R0);
 4548   format %{ %}
 4549   interface(REG_INTER);
 4550 %}
 4551 
 4552 // Pointer Register Operands
 4553 // Pointer Register
 4554 operand iRegP()
 4555 %{
 4556   constraint(ALLOC_IN_RC(ptr_reg));
 4557   match(RegP);
 4558   match(iRegPNoSp);
 4559   match(iRegP_R0);
 4560   //match(iRegP_R2);
 4561   //match(iRegP_R4);
 4562   //match(iRegP_R5);
 4563   match(thread_RegP);
 4564   op_cost(0);
 4565   format %{ %}
 4566   interface(REG_INTER);
 4567 %}
 4568 
 4569 // Pointer 64 bit Register not Special
 4570 operand iRegPNoSp()
 4571 %{
 4572   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4573   match(RegP);
 4574   // match(iRegP);
 4575   // match(iRegP_R0);
 4576   // match(iRegP_R2);
 4577   // match(iRegP_R4);
 4578   // match(iRegP_R5);
 4579   // match(thread_RegP);
 4580   op_cost(0);
 4581   format %{ %}
 4582   interface(REG_INTER);
 4583 %}
 4584 
 4585 // Pointer 64 bit Register R0 only
 4586 operand iRegP_R0()
 4587 %{
 4588   constraint(ALLOC_IN_RC(r0_reg));
 4589   match(RegP);
 4590   // match(iRegP);
 4591   match(iRegPNoSp);
 4592   op_cost(0);
 4593   format %{ %}
 4594   interface(REG_INTER);
 4595 %}
 4596 
 4597 // Pointer 64 bit Register R1 only
 4598 operand iRegP_R1()
 4599 %{
 4600   constraint(ALLOC_IN_RC(r1_reg));
 4601   match(RegP);
 4602   // match(iRegP);
 4603   match(iRegPNoSp);
 4604   op_cost(0);
 4605   format %{ %}
 4606   interface(REG_INTER);
 4607 %}
 4608 
 4609 // Pointer 64 bit Register R2 only
 4610 operand iRegP_R2()
 4611 %{
 4612   constraint(ALLOC_IN_RC(r2_reg));
 4613   match(RegP);
 4614   // match(iRegP);
 4615   match(iRegPNoSp);
 4616   op_cost(0);
 4617   format %{ %}
 4618   interface(REG_INTER);
 4619 %}
 4620 
 4621 // Pointer 64 bit Register R3 only
 4622 operand iRegP_R3()
 4623 %{
 4624   constraint(ALLOC_IN_RC(r3_reg));
 4625   match(RegP);
 4626   // match(iRegP);
 4627   match(iRegPNoSp);
 4628   op_cost(0);
 4629   format %{ %}
 4630   interface(REG_INTER);
 4631 %}
 4632 
 4633 // Pointer 64 bit Register R4 only
 4634 operand iRegP_R4()
 4635 %{
 4636   constraint(ALLOC_IN_RC(r4_reg));
 4637   match(RegP);
 4638   // match(iRegP);
 4639   match(iRegPNoSp);
 4640   op_cost(0);
 4641   format %{ %}
 4642   interface(REG_INTER);
 4643 %}
 4644 
 4645 // Pointer 64 bit Register R5 only
 4646 operand iRegP_R5()
 4647 %{
 4648   constraint(ALLOC_IN_RC(r5_reg));
 4649   match(RegP);
 4650   // match(iRegP);
 4651   match(iRegPNoSp);
 4652   op_cost(0);
 4653   format %{ %}
 4654   interface(REG_INTER);
 4655 %}
 4656 
 4657 // Pointer 64 bit Register R10 only
 4658 operand iRegP_R10()
 4659 %{
 4660   constraint(ALLOC_IN_RC(r10_reg));
 4661   match(RegP);
 4662   // match(iRegP);
 4663   match(iRegPNoSp);
 4664   op_cost(0);
 4665   format %{ %}
 4666   interface(REG_INTER);
 4667 %}
 4668 
 4669 // Long 64 bit Register R0 only
 4670 operand iRegL_R0()
 4671 %{
 4672   constraint(ALLOC_IN_RC(r0_reg));
 4673   match(RegL);
 4674   match(iRegLNoSp);
 4675   op_cost(0);
 4676   format %{ %}
 4677   interface(REG_INTER);
 4678 %}
 4679 
 4680 // Long 64 bit Register R2 only
 4681 operand iRegL_R2()
 4682 %{
 4683   constraint(ALLOC_IN_RC(r2_reg));
 4684   match(RegL);
 4685   match(iRegLNoSp);
 4686   op_cost(0);
 4687   format %{ %}
 4688   interface(REG_INTER);
 4689 %}
 4690 
 4691 // Long 64 bit Register R3 only
 4692 operand iRegL_R3()
 4693 %{
 4694   constraint(ALLOC_IN_RC(r3_reg));
 4695   match(RegL);
 4696   match(iRegLNoSp);
 4697   op_cost(0);
 4698   format %{ %}
 4699   interface(REG_INTER);
 4700 %}
 4701 
 4702 // Long 64 bit Register R11 only
 4703 operand iRegL_R11()
 4704 %{
 4705   constraint(ALLOC_IN_RC(r11_reg));
 4706   match(RegL);
 4707   match(iRegLNoSp);
 4708   op_cost(0);
 4709   format %{ %}
 4710   interface(REG_INTER);
 4711 %}
 4712 
 4713 // Pointer 64 bit Register FP only
 4714 operand iRegP_FP()
 4715 %{
 4716   constraint(ALLOC_IN_RC(fp_reg));
 4717   match(RegP);
 4718   // match(iRegP);
 4719   op_cost(0);
 4720   format %{ %}
 4721   interface(REG_INTER);
 4722 %}
 4723 
 4724 // Register R0 only
 4725 operand iRegI_R0()
 4726 %{
 4727   constraint(ALLOC_IN_RC(int_r0_reg));
 4728   match(RegI);
 4729   match(iRegINoSp);
 4730   op_cost(0);
 4731   format %{ %}
 4732   interface(REG_INTER);
 4733 %}
 4734 
 4735 // Register R2 only
 4736 operand iRegI_R2()
 4737 %{
 4738   constraint(ALLOC_IN_RC(int_r2_reg));
 4739   match(RegI);
 4740   match(iRegINoSp);
 4741   op_cost(0);
 4742   format %{ %}
 4743   interface(REG_INTER);
 4744 %}
 4745 
 4746 // Register R3 only
 4747 operand iRegI_R3()
 4748 %{
 4749   constraint(ALLOC_IN_RC(int_r3_reg));
 4750   match(RegI);
 4751   match(iRegINoSp);
 4752   op_cost(0);
 4753   format %{ %}
 4754   interface(REG_INTER);
 4755 %}
 4756 
 4757 
 4758 // Register R4 only
 4759 operand iRegI_R4()
 4760 %{
 4761   constraint(ALLOC_IN_RC(int_r4_reg));
 4762   match(RegI);
 4763   match(iRegINoSp);
 4764   op_cost(0);
 4765   format %{ %}
 4766   interface(REG_INTER);
 4767 %}
 4768 
 4769 
 4770 // Pointer Register Operands
 4771 // Narrow Pointer Register
 4772 operand iRegN()
 4773 %{
 4774   constraint(ALLOC_IN_RC(any_reg32));
 4775   match(RegN);
 4776   match(iRegNNoSp);
 4777   op_cost(0);
 4778   format %{ %}
 4779   interface(REG_INTER);
 4780 %}
 4781 
 4782 operand iRegN_R0()
 4783 %{
 4784   constraint(ALLOC_IN_RC(r0_reg));
 4785   match(iRegN);
 4786   op_cost(0);
 4787   format %{ %}
 4788   interface(REG_INTER);
 4789 %}
 4790 
 4791 operand iRegN_R2()
 4792 %{
 4793   constraint(ALLOC_IN_RC(r2_reg));
 4794   match(iRegN);
 4795   op_cost(0);
 4796   format %{ %}
 4797   interface(REG_INTER);
 4798 %}
 4799 
 4800 operand iRegN_R3()
 4801 %{
 4802   constraint(ALLOC_IN_RC(r3_reg));
 4803   match(iRegN);
 4804   op_cost(0);
 4805   format %{ %}
 4806   interface(REG_INTER);
 4807 %}
 4808 
 4809 // Integer 64 bit Register not Special
 4810 operand iRegNNoSp()
 4811 %{
 4812   constraint(ALLOC_IN_RC(no_special_reg32));
 4813   match(RegN);
 4814   op_cost(0);
 4815   format %{ %}
 4816   interface(REG_INTER);
 4817 %}
 4818 
 4819 // heap base register -- used for encoding immN0
 4820 
 4821 operand iRegIHeapbase()
 4822 %{
 4823   constraint(ALLOC_IN_RC(heapbase_reg));
 4824   match(RegI);
 4825   op_cost(0);
 4826   format %{ %}
 4827   interface(REG_INTER);
 4828 %}
 4829 
 4830 // Float Register
 4831 // Float register operands
 4832 operand vRegF()
 4833 %{
 4834   constraint(ALLOC_IN_RC(float_reg));
 4835   match(RegF);
 4836 
 4837   op_cost(0);
 4838   format %{ %}
 4839   interface(REG_INTER);
 4840 %}
 4841 
 4842 // Double Register
 4843 // Double register operands
 4844 operand vRegD()
 4845 %{
 4846   constraint(ALLOC_IN_RC(double_reg));
 4847   match(RegD);
 4848 
 4849   op_cost(0);
 4850   format %{ %}
 4851   interface(REG_INTER);
 4852 %}
 4853 
 4854 operand vecD()
 4855 %{
 4856   constraint(ALLOC_IN_RC(vectord_reg));
 4857   match(VecD);
 4858 
 4859   op_cost(0);
 4860   format %{ %}
 4861   interface(REG_INTER);
 4862 %}
 4863 
 4864 operand vecX()
 4865 %{
 4866   constraint(ALLOC_IN_RC(vectorx_reg));
 4867   match(VecX);
 4868 
 4869   op_cost(0);
 4870   format %{ %}
 4871   interface(REG_INTER);
 4872 %}
 4873 
 4874 operand vRegD_V0()
 4875 %{
 4876   constraint(ALLOC_IN_RC(v0_reg));
 4877   match(RegD);
 4878   op_cost(0);
 4879   format %{ %}
 4880   interface(REG_INTER);
 4881 %}
 4882 
 4883 operand vRegD_V1()
 4884 %{
 4885   constraint(ALLOC_IN_RC(v1_reg));
 4886   match(RegD);
 4887   op_cost(0);
 4888   format %{ %}
 4889   interface(REG_INTER);
 4890 %}
 4891 
 4892 operand vRegD_V2()
 4893 %{
 4894   constraint(ALLOC_IN_RC(v2_reg));
 4895   match(RegD);
 4896   op_cost(0);
 4897   format %{ %}
 4898   interface(REG_INTER);
 4899 %}
 4900 
 4901 operand vRegD_V3()
 4902 %{
 4903   constraint(ALLOC_IN_RC(v3_reg));
 4904   match(RegD);
 4905   op_cost(0);
 4906   format %{ %}
 4907   interface(REG_INTER);
 4908 %}
 4909 
 4910 operand vRegD_V4()
 4911 %{
 4912   constraint(ALLOC_IN_RC(v4_reg));
 4913   match(RegD);
 4914   op_cost(0);
 4915   format %{ %}
 4916   interface(REG_INTER);
 4917 %}
 4918 
 4919 operand vRegD_V5()
 4920 %{
 4921   constraint(ALLOC_IN_RC(v5_reg));
 4922   match(RegD);
 4923   op_cost(0);
 4924   format %{ %}
 4925   interface(REG_INTER);
 4926 %}
 4927 
 4928 operand vRegD_V6()
 4929 %{
 4930   constraint(ALLOC_IN_RC(v6_reg));
 4931   match(RegD);
 4932   op_cost(0);
 4933   format %{ %}
 4934   interface(REG_INTER);
 4935 %}
 4936 
 4937 operand vRegD_V7()
 4938 %{
 4939   constraint(ALLOC_IN_RC(v7_reg));
 4940   match(RegD);
 4941   op_cost(0);
 4942   format %{ %}
 4943   interface(REG_INTER);
 4944 %}
 4945 
 4946 operand vRegD_V8()
 4947 %{
 4948   constraint(ALLOC_IN_RC(v8_reg));
 4949   match(RegD);
 4950   op_cost(0);
 4951   format %{ %}
 4952   interface(REG_INTER);
 4953 %}
 4954 
 4955 operand vRegD_V9()
 4956 %{
 4957   constraint(ALLOC_IN_RC(v9_reg));
 4958   match(RegD);
 4959   op_cost(0);
 4960   format %{ %}
 4961   interface(REG_INTER);
 4962 %}
 4963 
 4964 operand vRegD_V10()
 4965 %{
 4966   constraint(ALLOC_IN_RC(v10_reg));
 4967   match(RegD);
 4968   op_cost(0);
 4969   format %{ %}
 4970   interface(REG_INTER);
 4971 %}
 4972 
 4973 operand vRegD_V11()
 4974 %{
 4975   constraint(ALLOC_IN_RC(v11_reg));
 4976   match(RegD);
 4977   op_cost(0);
 4978   format %{ %}
 4979   interface(REG_INTER);
 4980 %}
 4981 
 4982 operand vRegD_V12()
 4983 %{
 4984   constraint(ALLOC_IN_RC(v12_reg));
 4985   match(RegD);
 4986   op_cost(0);
 4987   format %{ %}
 4988   interface(REG_INTER);
 4989 %}
 4990 
 4991 operand vRegD_V13()
 4992 %{
 4993   constraint(ALLOC_IN_RC(v13_reg));
 4994   match(RegD);
 4995   op_cost(0);
 4996   format %{ %}
 4997   interface(REG_INTER);
 4998 %}
 4999 
 5000 operand vRegD_V14()
 5001 %{
 5002   constraint(ALLOC_IN_RC(v14_reg));
 5003   match(RegD);
 5004   op_cost(0);
 5005   format %{ %}
 5006   interface(REG_INTER);
 5007 %}
 5008 
 5009 operand vRegD_V15()
 5010 %{
 5011   constraint(ALLOC_IN_RC(v15_reg));
 5012   match(RegD);
 5013   op_cost(0);
 5014   format %{ %}
 5015   interface(REG_INTER);
 5016 %}
 5017 
 5018 operand vRegD_V16()
 5019 %{
 5020   constraint(ALLOC_IN_RC(v16_reg));
 5021   match(RegD);
 5022   op_cost(0);
 5023   format %{ %}
 5024   interface(REG_INTER);
 5025 %}
 5026 
 5027 operand vRegD_V17()
 5028 %{
 5029   constraint(ALLOC_IN_RC(v17_reg));
 5030   match(RegD);
 5031   op_cost(0);
 5032   format %{ %}
 5033   interface(REG_INTER);
 5034 %}
 5035 
 5036 operand vRegD_V18()
 5037 %{
 5038   constraint(ALLOC_IN_RC(v18_reg));
 5039   match(RegD);
 5040   op_cost(0);
 5041   format %{ %}
 5042   interface(REG_INTER);
 5043 %}
 5044 
 5045 operand vRegD_V19()
 5046 %{
 5047   constraint(ALLOC_IN_RC(v19_reg));
 5048   match(RegD);
 5049   op_cost(0);
 5050   format %{ %}
 5051   interface(REG_INTER);
 5052 %}
 5053 
 5054 operand vRegD_V20()
 5055 %{
 5056   constraint(ALLOC_IN_RC(v20_reg));
 5057   match(RegD);
 5058   op_cost(0);
 5059   format %{ %}
 5060   interface(REG_INTER);
 5061 %}
 5062 
 5063 operand vRegD_V21()
 5064 %{
 5065   constraint(ALLOC_IN_RC(v21_reg));
 5066   match(RegD);
 5067   op_cost(0);
 5068   format %{ %}
 5069   interface(REG_INTER);
 5070 %}
 5071 
 5072 operand vRegD_V22()
 5073 %{
 5074   constraint(ALLOC_IN_RC(v22_reg));
 5075   match(RegD);
 5076   op_cost(0);
 5077   format %{ %}
 5078   interface(REG_INTER);
 5079 %}
 5080 
 5081 operand vRegD_V23()
 5082 %{
 5083   constraint(ALLOC_IN_RC(v23_reg));
 5084   match(RegD);
 5085   op_cost(0);
 5086   format %{ %}
 5087   interface(REG_INTER);
 5088 %}
 5089 
 5090 operand vRegD_V24()
 5091 %{
 5092   constraint(ALLOC_IN_RC(v24_reg));
 5093   match(RegD);
 5094   op_cost(0);
 5095   format %{ %}
 5096   interface(REG_INTER);
 5097 %}
 5098 
 5099 operand vRegD_V25()
 5100 %{
 5101   constraint(ALLOC_IN_RC(v25_reg));
 5102   match(RegD);
 5103   op_cost(0);
 5104   format %{ %}
 5105   interface(REG_INTER);
 5106 %}
 5107 
 5108 operand vRegD_V26()
 5109 %{
 5110   constraint(ALLOC_IN_RC(v26_reg));
 5111   match(RegD);
 5112   op_cost(0);
 5113   format %{ %}
 5114   interface(REG_INTER);
 5115 %}
 5116 
 5117 operand vRegD_V27()
 5118 %{
 5119   constraint(ALLOC_IN_RC(v27_reg));
 5120   match(RegD);
 5121   op_cost(0);
 5122   format %{ %}
 5123   interface(REG_INTER);
 5124 %}
 5125 
 5126 operand vRegD_V28()
 5127 %{
 5128   constraint(ALLOC_IN_RC(v28_reg));
 5129   match(RegD);
 5130   op_cost(0);
 5131   format %{ %}
 5132   interface(REG_INTER);
 5133 %}
 5134 
 5135 operand vRegD_V29()
 5136 %{
 5137   constraint(ALLOC_IN_RC(v29_reg));
 5138   match(RegD);
 5139   op_cost(0);
 5140   format %{ %}
 5141   interface(REG_INTER);
 5142 %}
 5143 
 5144 operand vRegD_V30()
 5145 %{
 5146   constraint(ALLOC_IN_RC(v30_reg));
 5147   match(RegD);
 5148   op_cost(0);
 5149   format %{ %}
 5150   interface(REG_INTER);
 5151 %}
 5152 
 5153 operand vRegD_V31()
 5154 %{
 5155   constraint(ALLOC_IN_RC(v31_reg));
 5156   match(RegD);
 5157   op_cost(0);
 5158   format %{ %}
 5159   interface(REG_INTER);
 5160 %}
 5161 
 5162 // Flags register, used as output of signed compare instructions
 5163 
 5164 // note that on AArch64 we also use this register as the output for
 5165 // for floating point compare instructions (CmpF CmpD). this ensures
 5166 // that ordered inequality tests use GT, GE, LT or LE none of which
 5167 // pass through cases where the result is unordered i.e. one or both
 5168 // inputs to the compare is a NaN. this means that the ideal code can
 5169 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5170 // (where the comparison should always fail). EQ and NE tests are
 5171 // always generated in ideal code so that unordered folds into the NE
 5172 // case, matching the behaviour of AArch64 NE.
 5173 //
 5174 // This differs from x86 where the outputs of FP compares use a
 5175 // special FP flags registers and where compares based on this
 5176 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5177 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5178 // to explicitly handle the unordered case in branches. x86 also has
 5179 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5180 
 5181 operand rFlagsReg()
 5182 %{
 5183   constraint(ALLOC_IN_RC(int_flags));
 5184   match(RegFlags);
 5185 
 5186   op_cost(0);
 5187   format %{ &quot;RFLAGS&quot; %}
 5188   interface(REG_INTER);
 5189 %}
 5190 
 5191 // Flags register, used as output of unsigned compare instructions
 5192 operand rFlagsRegU()
 5193 %{
 5194   constraint(ALLOC_IN_RC(int_flags));
 5195   match(RegFlags);
 5196 
 5197   op_cost(0);
 5198   format %{ &quot;RFLAGSU&quot; %}
 5199   interface(REG_INTER);
 5200 %}
 5201 
 5202 // Special Registers
 5203 
 5204 // Method Register
 5205 operand inline_cache_RegP(iRegP reg)
 5206 %{
 5207   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5208   match(reg);
 5209   match(iRegPNoSp);
 5210   op_cost(0);
 5211   format %{ %}
 5212   interface(REG_INTER);
 5213 %}
 5214 
 5215 operand interpreter_method_oop_RegP(iRegP reg)
 5216 %{
 5217   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5218   match(reg);
 5219   match(iRegPNoSp);
 5220   op_cost(0);
 5221   format %{ %}
 5222   interface(REG_INTER);
 5223 %}
 5224 
 5225 // Thread Register
 5226 operand thread_RegP(iRegP reg)
 5227 %{
 5228   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5229   match(reg);
 5230   op_cost(0);
 5231   format %{ %}
 5232   interface(REG_INTER);
 5233 %}
 5234 
 5235 operand lr_RegP(iRegP reg)
 5236 %{
 5237   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5238   match(reg);
 5239   op_cost(0);
 5240   format %{ %}
 5241   interface(REG_INTER);
 5242 %}
 5243 
 5244 //----------Memory Operands----------------------------------------------------
 5245 
 5246 operand indirect(iRegP reg)
 5247 %{
 5248   constraint(ALLOC_IN_RC(ptr_reg));
 5249   match(reg);
 5250   op_cost(0);
 5251   format %{ &quot;[$reg]&quot; %}
 5252   interface(MEMORY_INTER) %{
 5253     base($reg);
 5254     index(0xffffffff);
 5255     scale(0x0);
 5256     disp(0x0);
 5257   %}
 5258 %}
 5259 
 5260 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5261 %{
 5262   constraint(ALLOC_IN_RC(ptr_reg));
 5263   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5264   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5265   op_cost(0);
 5266   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5267   interface(MEMORY_INTER) %{
 5268     base($reg);
 5269     index($ireg);
 5270     scale($scale);
 5271     disp(0x0);
 5272   %}
 5273 %}
 5274 
 5275 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5276 %{
 5277   constraint(ALLOC_IN_RC(ptr_reg));
 5278   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5279   match(AddP reg (LShiftL lreg scale));
 5280   op_cost(0);
 5281   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5282   interface(MEMORY_INTER) %{
 5283     base($reg);
 5284     index($lreg);
 5285     scale($scale);
 5286     disp(0x0);
 5287   %}
 5288 %}
 5289 
 5290 operand indIndexI2L(iRegP reg, iRegI ireg)
 5291 %{
 5292   constraint(ALLOC_IN_RC(ptr_reg));
 5293   match(AddP reg (ConvI2L ireg));
 5294   op_cost(0);
 5295   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5296   interface(MEMORY_INTER) %{
 5297     base($reg);
 5298     index($ireg);
 5299     scale(0x0);
 5300     disp(0x0);
 5301   %}
 5302 %}
 5303 
 5304 operand indIndex(iRegP reg, iRegL lreg)
 5305 %{
 5306   constraint(ALLOC_IN_RC(ptr_reg));
 5307   match(AddP reg lreg);
 5308   op_cost(0);
 5309   format %{ &quot;$reg, $lreg&quot; %}
 5310   interface(MEMORY_INTER) %{
 5311     base($reg);
 5312     index($lreg);
 5313     scale(0x0);
 5314     disp(0x0);
 5315   %}
 5316 %}
 5317 
 5318 operand indOffI(iRegP reg, immIOffset off)
 5319 %{
 5320   constraint(ALLOC_IN_RC(ptr_reg));
 5321   match(AddP reg off);
 5322   op_cost(0);
 5323   format %{ &quot;[$reg, $off]&quot; %}
 5324   interface(MEMORY_INTER) %{
 5325     base($reg);
 5326     index(0xffffffff);
 5327     scale(0x0);
 5328     disp($off);
 5329   %}
 5330 %}
 5331 
 5332 operand indOffI1(iRegP reg, immIOffset1 off)
 5333 %{
 5334   constraint(ALLOC_IN_RC(ptr_reg));
 5335   match(AddP reg off);
 5336   op_cost(0);
 5337   format %{ &quot;[$reg, $off]&quot; %}
 5338   interface(MEMORY_INTER) %{
 5339     base($reg);
 5340     index(0xffffffff);
 5341     scale(0x0);
 5342     disp($off);
 5343   %}
 5344 %}
 5345 
 5346 operand indOffI2(iRegP reg, immIOffset2 off)
 5347 %{
 5348   constraint(ALLOC_IN_RC(ptr_reg));
 5349   match(AddP reg off);
 5350   op_cost(0);
 5351   format %{ &quot;[$reg, $off]&quot; %}
 5352   interface(MEMORY_INTER) %{
 5353     base($reg);
 5354     index(0xffffffff);
 5355     scale(0x0);
 5356     disp($off);
 5357   %}
 5358 %}
 5359 
 5360 operand indOffI4(iRegP reg, immIOffset4 off)
 5361 %{
 5362   constraint(ALLOC_IN_RC(ptr_reg));
 5363   match(AddP reg off);
 5364   op_cost(0);
 5365   format %{ &quot;[$reg, $off]&quot; %}
 5366   interface(MEMORY_INTER) %{
 5367     base($reg);
 5368     index(0xffffffff);
 5369     scale(0x0);
 5370     disp($off);
 5371   %}
 5372 %}
 5373 
 5374 operand indOffI8(iRegP reg, immIOffset8 off)
 5375 %{
 5376   constraint(ALLOC_IN_RC(ptr_reg));
 5377   match(AddP reg off);
 5378   op_cost(0);
 5379   format %{ &quot;[$reg, $off]&quot; %}
 5380   interface(MEMORY_INTER) %{
 5381     base($reg);
 5382     index(0xffffffff);
 5383     scale(0x0);
 5384     disp($off);
 5385   %}
 5386 %}
 5387 
 5388 operand indOffI16(iRegP reg, immIOffset16 off)
 5389 %{
 5390   constraint(ALLOC_IN_RC(ptr_reg));
 5391   match(AddP reg off);
 5392   op_cost(0);
 5393   format %{ &quot;[$reg, $off]&quot; %}
 5394   interface(MEMORY_INTER) %{
 5395     base($reg);
 5396     index(0xffffffff);
 5397     scale(0x0);
 5398     disp($off);
 5399   %}
 5400 %}
 5401 
 5402 operand indOffL(iRegP reg, immLoffset off)
 5403 %{
 5404   constraint(ALLOC_IN_RC(ptr_reg));
 5405   match(AddP reg off);
 5406   op_cost(0);
 5407   format %{ &quot;[$reg, $off]&quot; %}
 5408   interface(MEMORY_INTER) %{
 5409     base($reg);
 5410     index(0xffffffff);
 5411     scale(0x0);
 5412     disp($off);
 5413   %}
 5414 %}
 5415 
 5416 operand indOffL1(iRegP reg, immLoffset1 off)
 5417 %{
 5418   constraint(ALLOC_IN_RC(ptr_reg));
 5419   match(AddP reg off);
 5420   op_cost(0);
 5421   format %{ &quot;[$reg, $off]&quot; %}
 5422   interface(MEMORY_INTER) %{
 5423     base($reg);
 5424     index(0xffffffff);
 5425     scale(0x0);
 5426     disp($off);
 5427   %}
 5428 %}
 5429 
 5430 operand indOffL2(iRegP reg, immLoffset2 off)
 5431 %{
 5432   constraint(ALLOC_IN_RC(ptr_reg));
 5433   match(AddP reg off);
 5434   op_cost(0);
 5435   format %{ &quot;[$reg, $off]&quot; %}
 5436   interface(MEMORY_INTER) %{
 5437     base($reg);
 5438     index(0xffffffff);
 5439     scale(0x0);
 5440     disp($off);
 5441   %}
 5442 %}
 5443 
 5444 operand indOffL4(iRegP reg, immLoffset4 off)
 5445 %{
 5446   constraint(ALLOC_IN_RC(ptr_reg));
 5447   match(AddP reg off);
 5448   op_cost(0);
 5449   format %{ &quot;[$reg, $off]&quot; %}
 5450   interface(MEMORY_INTER) %{
 5451     base($reg);
 5452     index(0xffffffff);
 5453     scale(0x0);
 5454     disp($off);
 5455   %}
 5456 %}
 5457 
 5458 operand indOffL8(iRegP reg, immLoffset8 off)
 5459 %{
 5460   constraint(ALLOC_IN_RC(ptr_reg));
 5461   match(AddP reg off);
 5462   op_cost(0);
 5463   format %{ &quot;[$reg, $off]&quot; %}
 5464   interface(MEMORY_INTER) %{
 5465     base($reg);
 5466     index(0xffffffff);
 5467     scale(0x0);
 5468     disp($off);
 5469   %}
 5470 %}
 5471 
 5472 operand indOffL16(iRegP reg, immLoffset16 off)
 5473 %{
 5474   constraint(ALLOC_IN_RC(ptr_reg));
 5475   match(AddP reg off);
 5476   op_cost(0);
 5477   format %{ &quot;[$reg, $off]&quot; %}
 5478   interface(MEMORY_INTER) %{
 5479     base($reg);
 5480     index(0xffffffff);
 5481     scale(0x0);
 5482     disp($off);
 5483   %}
 5484 %}
 5485 
 5486 operand indirectN(iRegN reg)
 5487 %{
 5488   predicate(CompressedOops::shift() == 0);
 5489   constraint(ALLOC_IN_RC(ptr_reg));
 5490   match(DecodeN reg);
 5491   op_cost(0);
 5492   format %{ &quot;[$reg]\t# narrow&quot; %}
 5493   interface(MEMORY_INTER) %{
 5494     base($reg);
 5495     index(0xffffffff);
 5496     scale(0x0);
 5497     disp(0x0);
 5498   %}
 5499 %}
 5500 
 5501 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5502 %{
 5503   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5504   constraint(ALLOC_IN_RC(ptr_reg));
 5505   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5506   op_cost(0);
 5507   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5508   interface(MEMORY_INTER) %{
 5509     base($reg);
 5510     index($ireg);
 5511     scale($scale);
 5512     disp(0x0);
 5513   %}
 5514 %}
 5515 
 5516 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5517 %{
 5518   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5519   constraint(ALLOC_IN_RC(ptr_reg));
 5520   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5521   op_cost(0);
 5522   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5523   interface(MEMORY_INTER) %{
 5524     base($reg);
 5525     index($lreg);
 5526     scale($scale);
 5527     disp(0x0);
 5528   %}
 5529 %}
 5530 
 5531 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5532 %{
 5533   predicate(CompressedOops::shift() == 0);
 5534   constraint(ALLOC_IN_RC(ptr_reg));
 5535   match(AddP (DecodeN reg) (ConvI2L ireg));
 5536   op_cost(0);
 5537   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5538   interface(MEMORY_INTER) %{
 5539     base($reg);
 5540     index($ireg);
 5541     scale(0x0);
 5542     disp(0x0);
 5543   %}
 5544 %}
 5545 
 5546 operand indIndexN(iRegN reg, iRegL lreg)
 5547 %{
 5548   predicate(CompressedOops::shift() == 0);
 5549   constraint(ALLOC_IN_RC(ptr_reg));
 5550   match(AddP (DecodeN reg) lreg);
 5551   op_cost(0);
 5552   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5553   interface(MEMORY_INTER) %{
 5554     base($reg);
 5555     index($lreg);
 5556     scale(0x0);
 5557     disp(0x0);
 5558   %}
 5559 %}
 5560 
 5561 operand indOffIN(iRegN reg, immIOffset off)
 5562 %{
 5563   predicate(CompressedOops::shift() == 0);
 5564   constraint(ALLOC_IN_RC(ptr_reg));
 5565   match(AddP (DecodeN reg) off);
 5566   op_cost(0);
 5567   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5568   interface(MEMORY_INTER) %{
 5569     base($reg);
 5570     index(0xffffffff);
 5571     scale(0x0);
 5572     disp($off);
 5573   %}
 5574 %}
 5575 
 5576 operand indOffLN(iRegN reg, immLoffset off)
 5577 %{
 5578   predicate(CompressedOops::shift() == 0);
 5579   constraint(ALLOC_IN_RC(ptr_reg));
 5580   match(AddP (DecodeN reg) off);
 5581   op_cost(0);
 5582   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5583   interface(MEMORY_INTER) %{
 5584     base($reg);
 5585     index(0xffffffff);
 5586     scale(0x0);
 5587     disp($off);
 5588   %}
 5589 %}
 5590 
 5591 
 5592 
 5593 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5594 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5595 %{
 5596   constraint(ALLOC_IN_RC(ptr_reg));
 5597   match(AddP reg off);
 5598   op_cost(0);
 5599   format %{ &quot;[$reg, $off]&quot; %}
 5600   interface(MEMORY_INTER) %{
 5601     base($reg);
 5602     index(0xffffffff);
 5603     scale(0x0);
 5604     disp($off);
 5605   %}
 5606 %}
 5607 
 5608 //----------Special Memory Operands--------------------------------------------
 5609 // Stack Slot Operand - This operand is used for loading and storing temporary
 5610 //                      values on the stack where a match requires a value to
 5611 //                      flow through memory.
 5612 operand stackSlotP(sRegP reg)
 5613 %{
 5614   constraint(ALLOC_IN_RC(stack_slots));
 5615   op_cost(100);
 5616   // No match rule because this operand is only generated in matching
 5617   // match(RegP);
 5618   format %{ &quot;[$reg]&quot; %}
 5619   interface(MEMORY_INTER) %{
 5620     base(0x1e);  // RSP
 5621     index(0x0);  // No Index
 5622     scale(0x0);  // No Scale
 5623     disp($reg);  // Stack Offset
 5624   %}
 5625 %}
 5626 
 5627 operand stackSlotI(sRegI reg)
 5628 %{
 5629   constraint(ALLOC_IN_RC(stack_slots));
 5630   // No match rule because this operand is only generated in matching
 5631   // match(RegI);
 5632   format %{ &quot;[$reg]&quot; %}
 5633   interface(MEMORY_INTER) %{
 5634     base(0x1e);  // RSP
 5635     index(0x0);  // No Index
 5636     scale(0x0);  // No Scale
 5637     disp($reg);  // Stack Offset
 5638   %}
 5639 %}
 5640 
 5641 operand stackSlotF(sRegF reg)
 5642 %{
 5643   constraint(ALLOC_IN_RC(stack_slots));
 5644   // No match rule because this operand is only generated in matching
 5645   // match(RegF);
 5646   format %{ &quot;[$reg]&quot; %}
 5647   interface(MEMORY_INTER) %{
 5648     base(0x1e);  // RSP
 5649     index(0x0);  // No Index
 5650     scale(0x0);  // No Scale
 5651     disp($reg);  // Stack Offset
 5652   %}
 5653 %}
 5654 
 5655 operand stackSlotD(sRegD reg)
 5656 %{
 5657   constraint(ALLOC_IN_RC(stack_slots));
 5658   // No match rule because this operand is only generated in matching
 5659   // match(RegD);
 5660   format %{ &quot;[$reg]&quot; %}
 5661   interface(MEMORY_INTER) %{
 5662     base(0x1e);  // RSP
 5663     index(0x0);  // No Index
 5664     scale(0x0);  // No Scale
 5665     disp($reg);  // Stack Offset
 5666   %}
 5667 %}
 5668 
 5669 operand stackSlotL(sRegL reg)
 5670 %{
 5671   constraint(ALLOC_IN_RC(stack_slots));
 5672   // No match rule because this operand is only generated in matching
 5673   // match(RegL);
 5674   format %{ &quot;[$reg]&quot; %}
 5675   interface(MEMORY_INTER) %{
 5676     base(0x1e);  // RSP
 5677     index(0x0);  // No Index
 5678     scale(0x0);  // No Scale
 5679     disp($reg);  // Stack Offset
 5680   %}
 5681 %}
 5682 
 5683 // Operands for expressing Control Flow
 5684 // NOTE: Label is a predefined operand which should not be redefined in
 5685 //       the AD file. It is generically handled within the ADLC.
 5686 
 5687 //----------Conditional Branch Operands----------------------------------------
 5688 // Comparison Op  - This is the operation of the comparison, and is limited to
 5689 //                  the following set of codes:
 5690 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5691 //
 5692 // Other attributes of the comparison, such as unsignedness, are specified
 5693 // by the comparison instruction that sets a condition code flags register.
 5694 // That result is represented by a flags operand whose subtype is appropriate
 5695 // to the unsignedness (etc.) of the comparison.
 5696 //
 5697 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5698 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5699 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5700 
 5701 // used for signed integral comparisons and fp comparisons
 5702 
 5703 operand cmpOp()
 5704 %{
 5705   match(Bool);
 5706 
 5707   format %{ &quot;&quot; %}
 5708   interface(COND_INTER) %{
 5709     equal(0x0, &quot;eq&quot;);
 5710     not_equal(0x1, &quot;ne&quot;);
 5711     less(0xb, &quot;lt&quot;);
 5712     greater_equal(0xa, &quot;ge&quot;);
 5713     less_equal(0xd, &quot;le&quot;);
 5714     greater(0xc, &quot;gt&quot;);
 5715     overflow(0x6, &quot;vs&quot;);
 5716     no_overflow(0x7, &quot;vc&quot;);
 5717   %}
 5718 %}
 5719 
 5720 // used for unsigned integral comparisons
 5721 
 5722 operand cmpOpU()
 5723 %{
 5724   match(Bool);
 5725 
 5726   format %{ &quot;&quot; %}
 5727   interface(COND_INTER) %{
 5728     equal(0x0, &quot;eq&quot;);
 5729     not_equal(0x1, &quot;ne&quot;);
 5730     less(0x3, &quot;lo&quot;);
 5731     greater_equal(0x2, &quot;hs&quot;);
 5732     less_equal(0x9, &quot;ls&quot;);
 5733     greater(0x8, &quot;hi&quot;);
 5734     overflow(0x6, &quot;vs&quot;);
 5735     no_overflow(0x7, &quot;vc&quot;);
 5736   %}
 5737 %}
 5738 
 5739 // used for certain integral comparisons which can be
 5740 // converted to cbxx or tbxx instructions
 5741 
 5742 operand cmpOpEqNe()
 5743 %{
 5744   match(Bool);
 5745   op_cost(0);
 5746   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5747             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5748 
 5749   format %{ &quot;&quot; %}
 5750   interface(COND_INTER) %{
 5751     equal(0x0, &quot;eq&quot;);
 5752     not_equal(0x1, &quot;ne&quot;);
 5753     less(0xb, &quot;lt&quot;);
 5754     greater_equal(0xa, &quot;ge&quot;);
 5755     less_equal(0xd, &quot;le&quot;);
 5756     greater(0xc, &quot;gt&quot;);
 5757     overflow(0x6, &quot;vs&quot;);
 5758     no_overflow(0x7, &quot;vc&quot;);
 5759   %}
 5760 %}
 5761 
 5762 // used for certain integral comparisons which can be
 5763 // converted to cbxx or tbxx instructions
 5764 
 5765 operand cmpOpLtGe()
 5766 %{
 5767   match(Bool);
 5768   op_cost(0);
 5769 
 5770   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5771             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5772 
 5773   format %{ &quot;&quot; %}
 5774   interface(COND_INTER) %{
 5775     equal(0x0, &quot;eq&quot;);
 5776     not_equal(0x1, &quot;ne&quot;);
 5777     less(0xb, &quot;lt&quot;);
 5778     greater_equal(0xa, &quot;ge&quot;);
 5779     less_equal(0xd, &quot;le&quot;);
 5780     greater(0xc, &quot;gt&quot;);
 5781     overflow(0x6, &quot;vs&quot;);
 5782     no_overflow(0x7, &quot;vc&quot;);
 5783   %}
 5784 %}
 5785 
 5786 // used for certain unsigned integral comparisons which can be
 5787 // converted to cbxx or tbxx instructions
 5788 
 5789 operand cmpOpUEqNeLtGe()
 5790 %{
 5791   match(Bool);
 5792   op_cost(0);
 5793 
 5794   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5795             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5796             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5797             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5798 
 5799   format %{ &quot;&quot; %}
 5800   interface(COND_INTER) %{
 5801     equal(0x0, &quot;eq&quot;);
 5802     not_equal(0x1, &quot;ne&quot;);
 5803     less(0xb, &quot;lt&quot;);
 5804     greater_equal(0xa, &quot;ge&quot;);
 5805     less_equal(0xd, &quot;le&quot;);
 5806     greater(0xc, &quot;gt&quot;);
 5807     overflow(0x6, &quot;vs&quot;);
 5808     no_overflow(0x7, &quot;vc&quot;);
 5809   %}
 5810 %}
 5811 
 5812 // Special operand allowing long args to int ops to be truncated for free
 5813 
 5814 operand iRegL2I(iRegL reg) %{
 5815 
 5816   op_cost(0);
 5817 
 5818   match(ConvL2I reg);
 5819 
 5820   format %{ &quot;l2i($reg)&quot; %}
 5821 
 5822   interface(REG_INTER)
 5823 %}
 5824 
 5825 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5826 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5827 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5828 
 5829 //----------OPERAND CLASSES----------------------------------------------------
 5830 // Operand Classes are groups of operands that are used as to simplify
 5831 // instruction definitions by not requiring the AD writer to specify
 5832 // separate instructions for every form of operand when the
 5833 // instruction accepts multiple operand types with the same basic
 5834 // encoding and format. The classic case of this is memory operands.
 5835 
 5836 // memory is used to define read/write location for load/store
 5837 // instruction defs. we can turn a memory op into an Address
 5838 
 5839 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5840                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5841 
 5842 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5843                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5844 
 5845 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5846                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5847 
 5848 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5849                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5850 
 5851 // All of the memory operands. For the pipeline description.
 5852 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5853                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5854                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5855 
 5856 
 5857 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5858 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5859 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5860 // can be elided because the 32-bit instruction will just employ the
 5861 // lower 32 bits anyway.
 5862 //
 5863 // n.b. this does not elide all L2I conversions. if the truncated
 5864 // value is consumed by more than one operation then the ConvL2I
 5865 // cannot be bundled into the consuming nodes so an l2i gets planted
 5866 // (actually a movw $dst $src) and the downstream instructions consume
 5867 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5868 // movw is actually redundant but its not too costly.
 5869 
 5870 opclass iRegIorL2I(iRegI, iRegL2I);
 5871 
 5872 //----------PIPELINE-----------------------------------------------------------
 5873 // Rules which define the behavior of the target architectures pipeline.
 5874 
 5875 // For specific pipelines, eg A53, define the stages of that pipeline
 5876 //pipe_desc(ISS, EX1, EX2, WR);
 5877 #define ISS S0
 5878 #define EX1 S1
 5879 #define EX2 S2
 5880 #define WR  S3
 5881 
 5882 // Integer ALU reg operation
 5883 pipeline %{
 5884 
 5885 attributes %{
 5886   // ARM instructions are of fixed length
 5887   fixed_size_instructions;        // Fixed size instructions TODO does
 5888   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5889   // ARM instructions come in 32-bit word units
 5890   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5891   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5892   instruction_fetch_units = 1;       // of 64 bytes
 5893 
 5894   // List of nop instructions
 5895   nops( MachNop );
 5896 %}
 5897 
 5898 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5899 // or description. we do use pipeline classes to introduce fixed
 5900 // latencies
 5901 
 5902 //----------RESOURCES----------------------------------------------------------
 5903 // Resources are the functional units available to the machine
 5904 
 5905 resources( INS0, INS1, INS01 = INS0 | INS1,
 5906            ALU0, ALU1, ALU = ALU0 | ALU1,
 5907            MAC,
 5908            DIV,
 5909            BRANCH,
 5910            LDST,
 5911            NEON_FP);
 5912 
 5913 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5914 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5915 
 5916 // Define the pipeline as a generic 6 stage pipeline
 5917 pipe_desc(S0, S1, S2, S3, S4, S5);
 5918 
 5919 //----------PIPELINE CLASSES---------------------------------------------------
 5920 // Pipeline Classes describe the stages in which input and output are
 5921 // referenced by the hardware pipeline.
 5922 
 5923 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5924 %{
 5925   single_instruction;
 5926   src1   : S1(read);
 5927   src2   : S2(read);
 5928   dst    : S5(write);
 5929   INS01  : ISS;
 5930   NEON_FP : S5;
 5931 %}
 5932 
 5933 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5934 %{
 5935   single_instruction;
 5936   src1   : S1(read);
 5937   src2   : S2(read);
 5938   dst    : S5(write);
 5939   INS01  : ISS;
 5940   NEON_FP : S5;
 5941 %}
 5942 
 5943 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5944 %{
 5945   single_instruction;
 5946   src    : S1(read);
 5947   dst    : S5(write);
 5948   INS01  : ISS;
 5949   NEON_FP : S5;
 5950 %}
 5951 
 5952 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5953 %{
 5954   single_instruction;
 5955   src    : S1(read);
 5956   dst    : S5(write);
 5957   INS01  : ISS;
 5958   NEON_FP : S5;
 5959 %}
 5960 
 5961 pipe_class fp_d2f(vRegF dst, vRegD src)
 5962 %{
 5963   single_instruction;
 5964   src    : S1(read);
 5965   dst    : S5(write);
 5966   INS01  : ISS;
 5967   NEON_FP : S5;
 5968 %}
 5969 
 5970 pipe_class fp_f2d(vRegD dst, vRegF src)
 5971 %{
 5972   single_instruction;
 5973   src    : S1(read);
 5974   dst    : S5(write);
 5975   INS01  : ISS;
 5976   NEON_FP : S5;
 5977 %}
 5978 
 5979 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5980 %{
 5981   single_instruction;
 5982   src    : S1(read);
 5983   dst    : S5(write);
 5984   INS01  : ISS;
 5985   NEON_FP : S5;
 5986 %}
 5987 
 5988 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5989 %{
 5990   single_instruction;
 5991   src    : S1(read);
 5992   dst    : S5(write);
 5993   INS01  : ISS;
 5994   NEON_FP : S5;
 5995 %}
 5996 
 5997 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 5998 %{
 5999   single_instruction;
 6000   src    : S1(read);
 6001   dst    : S5(write);
 6002   INS01  : ISS;
 6003   NEON_FP : S5;
 6004 %}
 6005 
 6006 pipe_class fp_l2f(vRegF dst, iRegL src)
 6007 %{
 6008   single_instruction;
 6009   src    : S1(read);
 6010   dst    : S5(write);
 6011   INS01  : ISS;
 6012   NEON_FP : S5;
 6013 %}
 6014 
 6015 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6016 %{
 6017   single_instruction;
 6018   src    : S1(read);
 6019   dst    : S5(write);
 6020   INS01  : ISS;
 6021   NEON_FP : S5;
 6022 %}
 6023 
 6024 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6025 %{
 6026   single_instruction;
 6027   src    : S1(read);
 6028   dst    : S5(write);
 6029   INS01  : ISS;
 6030   NEON_FP : S5;
 6031 %}
 6032 
 6033 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6034 %{
 6035   single_instruction;
 6036   src    : S1(read);
 6037   dst    : S5(write);
 6038   INS01  : ISS;
 6039   NEON_FP : S5;
 6040 %}
 6041 
 6042 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6043 %{
 6044   single_instruction;
 6045   src    : S1(read);
 6046   dst    : S5(write);
 6047   INS01  : ISS;
 6048   NEON_FP : S5;
 6049 %}
 6050 
 6051 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6052 %{
 6053   single_instruction;
 6054   src1   : S1(read);
 6055   src2   : S2(read);
 6056   dst    : S5(write);
 6057   INS0   : ISS;
 6058   NEON_FP : S5;
 6059 %}
 6060 
 6061 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6062 %{
 6063   single_instruction;
 6064   src1   : S1(read);
 6065   src2   : S2(read);
 6066   dst    : S5(write);
 6067   INS0   : ISS;
 6068   NEON_FP : S5;
 6069 %}
 6070 
 6071 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6072 %{
 6073   single_instruction;
 6074   cr     : S1(read);
 6075   src1   : S1(read);
 6076   src2   : S1(read);
 6077   dst    : S3(write);
 6078   INS01  : ISS;
 6079   NEON_FP : S3;
 6080 %}
 6081 
 6082 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6083 %{
 6084   single_instruction;
 6085   cr     : S1(read);
 6086   src1   : S1(read);
 6087   src2   : S1(read);
 6088   dst    : S3(write);
 6089   INS01  : ISS;
 6090   NEON_FP : S3;
 6091 %}
 6092 
 6093 pipe_class fp_imm_s(vRegF dst)
 6094 %{
 6095   single_instruction;
 6096   dst    : S3(write);
 6097   INS01  : ISS;
 6098   NEON_FP : S3;
 6099 %}
 6100 
 6101 pipe_class fp_imm_d(vRegD dst)
 6102 %{
 6103   single_instruction;
 6104   dst    : S3(write);
 6105   INS01  : ISS;
 6106   NEON_FP : S3;
 6107 %}
 6108 
 6109 pipe_class fp_load_constant_s(vRegF dst)
 6110 %{
 6111   single_instruction;
 6112   dst    : S4(write);
 6113   INS01  : ISS;
 6114   NEON_FP : S4;
 6115 %}
 6116 
 6117 pipe_class fp_load_constant_d(vRegD dst)
 6118 %{
 6119   single_instruction;
 6120   dst    : S4(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S4;
 6123 %}
 6124 
 6125 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6126 %{
 6127   single_instruction;
 6128   dst    : S5(write);
 6129   src1   : S1(read);
 6130   src2   : S1(read);
 6131   INS01  : ISS;
 6132   NEON_FP : S5;
 6133 %}
 6134 
 6135 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6136 %{
 6137   single_instruction;
 6138   dst    : S5(write);
 6139   src1   : S1(read);
 6140   src2   : S1(read);
 6141   INS0   : ISS;
 6142   NEON_FP : S5;
 6143 %}
 6144 
 6145 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6146 %{
 6147   single_instruction;
 6148   dst    : S5(write);
 6149   src1   : S1(read);
 6150   src2   : S1(read);
 6151   dst    : S1(read);
 6152   INS01  : ISS;
 6153   NEON_FP : S5;
 6154 %}
 6155 
 6156 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6157 %{
 6158   single_instruction;
 6159   dst    : S5(write);
 6160   src1   : S1(read);
 6161   src2   : S1(read);
 6162   dst    : S1(read);
 6163   INS0   : ISS;
 6164   NEON_FP : S5;
 6165 %}
 6166 
 6167 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6168 %{
 6169   single_instruction;
 6170   dst    : S4(write);
 6171   src1   : S2(read);
 6172   src2   : S2(read);
 6173   INS01  : ISS;
 6174   NEON_FP : S4;
 6175 %}
 6176 
 6177 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6178 %{
 6179   single_instruction;
 6180   dst    : S4(write);
 6181   src1   : S2(read);
 6182   src2   : S2(read);
 6183   INS0   : ISS;
 6184   NEON_FP : S4;
 6185 %}
 6186 
 6187 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6188 %{
 6189   single_instruction;
 6190   dst    : S3(write);
 6191   src1   : S2(read);
 6192   src2   : S2(read);
 6193   INS01  : ISS;
 6194   NEON_FP : S3;
 6195 %}
 6196 
 6197 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6198 %{
 6199   single_instruction;
 6200   dst    : S3(write);
 6201   src1   : S2(read);
 6202   src2   : S2(read);
 6203   INS0   : ISS;
 6204   NEON_FP : S3;
 6205 %}
 6206 
 6207 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6208 %{
 6209   single_instruction;
 6210   dst    : S3(write);
 6211   src    : S1(read);
 6212   shift  : S1(read);
 6213   INS01  : ISS;
 6214   NEON_FP : S3;
 6215 %}
 6216 
 6217 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6218 %{
 6219   single_instruction;
 6220   dst    : S3(write);
 6221   src    : S1(read);
 6222   shift  : S1(read);
 6223   INS0   : ISS;
 6224   NEON_FP : S3;
 6225 %}
 6226 
 6227 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6228 %{
 6229   single_instruction;
 6230   dst    : S3(write);
 6231   src    : S1(read);
 6232   INS01  : ISS;
 6233   NEON_FP : S3;
 6234 %}
 6235 
 6236 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6237 %{
 6238   single_instruction;
 6239   dst    : S3(write);
 6240   src    : S1(read);
 6241   INS0   : ISS;
 6242   NEON_FP : S3;
 6243 %}
 6244 
 6245 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6246 %{
 6247   single_instruction;
 6248   dst    : S5(write);
 6249   src1   : S1(read);
 6250   src2   : S1(read);
 6251   INS01  : ISS;
 6252   NEON_FP : S5;
 6253 %}
 6254 
 6255 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6256 %{
 6257   single_instruction;
 6258   dst    : S5(write);
 6259   src1   : S1(read);
 6260   src2   : S1(read);
 6261   INS0   : ISS;
 6262   NEON_FP : S5;
 6263 %}
 6264 
 6265 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6266 %{
 6267   single_instruction;
 6268   dst    : S5(write);
 6269   src1   : S1(read);
 6270   src2   : S1(read);
 6271   INS0   : ISS;
 6272   NEON_FP : S5;
 6273 %}
 6274 
 6275 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6276 %{
 6277   single_instruction;
 6278   dst    : S5(write);
 6279   src1   : S1(read);
 6280   src2   : S1(read);
 6281   INS0   : ISS;
 6282   NEON_FP : S5;
 6283 %}
 6284 
 6285 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6286 %{
 6287   single_instruction;
 6288   dst    : S5(write);
 6289   src    : S1(read);
 6290   INS0   : ISS;
 6291   NEON_FP : S5;
 6292 %}
 6293 
 6294 pipe_class vunop_fp64(vecD dst, vecD src)
 6295 %{
 6296   single_instruction;
 6297   dst    : S5(write);
 6298   src    : S1(read);
 6299   INS01  : ISS;
 6300   NEON_FP : S5;
 6301 %}
 6302 
 6303 pipe_class vunop_fp128(vecX dst, vecX src)
 6304 %{
 6305   single_instruction;
 6306   dst    : S5(write);
 6307   src    : S1(read);
 6308   INS0   : ISS;
 6309   NEON_FP : S5;
 6310 %}
 6311 
 6312 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6313 %{
 6314   single_instruction;
 6315   dst    : S3(write);
 6316   src    : S1(read);
 6317   INS01  : ISS;
 6318   NEON_FP : S3;
 6319 %}
 6320 
 6321 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6322 %{
 6323   single_instruction;
 6324   dst    : S3(write);
 6325   src    : S1(read);
 6326   INS01  : ISS;
 6327   NEON_FP : S3;
 6328 %}
 6329 
 6330 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6331 %{
 6332   single_instruction;
 6333   dst    : S3(write);
 6334   src    : S1(read);
 6335   INS01  : ISS;
 6336   NEON_FP : S3;
 6337 %}
 6338 
 6339 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6340 %{
 6341   single_instruction;
 6342   dst    : S3(write);
 6343   src    : S1(read);
 6344   INS01  : ISS;
 6345   NEON_FP : S3;
 6346 %}
 6347 
 6348 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6349 %{
 6350   single_instruction;
 6351   dst    : S3(write);
 6352   src    : S1(read);
 6353   INS01  : ISS;
 6354   NEON_FP : S3;
 6355 %}
 6356 
 6357 pipe_class vmovi_reg_imm64(vecD dst)
 6358 %{
 6359   single_instruction;
 6360   dst    : S3(write);
 6361   INS01  : ISS;
 6362   NEON_FP : S3;
 6363 %}
 6364 
 6365 pipe_class vmovi_reg_imm128(vecX dst)
 6366 %{
 6367   single_instruction;
 6368   dst    : S3(write);
 6369   INS0   : ISS;
 6370   NEON_FP : S3;
 6371 %}
 6372 
 6373 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6374 %{
 6375   single_instruction;
 6376   dst    : S5(write);
 6377   mem    : ISS(read);
 6378   INS01  : ISS;
 6379   NEON_FP : S3;
 6380 %}
 6381 
 6382 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6383 %{
 6384   single_instruction;
 6385   dst    : S5(write);
 6386   mem    : ISS(read);
 6387   INS01  : ISS;
 6388   NEON_FP : S3;
 6389 %}
 6390 
 6391 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6392 %{
 6393   single_instruction;
 6394   mem    : ISS(read);
 6395   src    : S2(read);
 6396   INS01  : ISS;
 6397   NEON_FP : S3;
 6398 %}
 6399 
 6400 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6401 %{
 6402   single_instruction;
 6403   mem    : ISS(read);
 6404   src    : S2(read);
 6405   INS01  : ISS;
 6406   NEON_FP : S3;
 6407 %}
 6408 
 6409 //------- Integer ALU operations --------------------------
 6410 
 6411 // Integer ALU reg-reg operation
 6412 // Operands needed in EX1, result generated in EX2
 6413 // Eg.  ADD     x0, x1, x2
 6414 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6415 %{
 6416   single_instruction;
 6417   dst    : EX2(write);
 6418   src1   : EX1(read);
 6419   src2   : EX1(read);
 6420   INS01  : ISS; // Dual issue as instruction 0 or 1
 6421   ALU    : EX2;
 6422 %}
 6423 
 6424 // Integer ALU reg-reg operation with constant shift
 6425 // Shifted register must be available in LATE_ISS instead of EX1
 6426 // Eg.  ADD     x0, x1, x2, LSL #2
 6427 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6428 %{
 6429   single_instruction;
 6430   dst    : EX2(write);
 6431   src1   : EX1(read);
 6432   src2   : ISS(read);
 6433   INS01  : ISS;
 6434   ALU    : EX2;
 6435 %}
 6436 
 6437 // Integer ALU reg operation with constant shift
 6438 // Eg.  LSL     x0, x1, #shift
 6439 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6440 %{
 6441   single_instruction;
 6442   dst    : EX2(write);
 6443   src1   : ISS(read);
 6444   INS01  : ISS;
 6445   ALU    : EX2;
 6446 %}
 6447 
 6448 // Integer ALU reg-reg operation with variable shift
 6449 // Both operands must be available in LATE_ISS instead of EX1
 6450 // Result is available in EX1 instead of EX2
 6451 // Eg.  LSLV    x0, x1, x2
 6452 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6453 %{
 6454   single_instruction;
 6455   dst    : EX1(write);
 6456   src1   : ISS(read);
 6457   src2   : ISS(read);
 6458   INS01  : ISS;
 6459   ALU    : EX1;
 6460 %}
 6461 
 6462 // Integer ALU reg-reg operation with extract
 6463 // As for _vshift above, but result generated in EX2
 6464 // Eg.  EXTR    x0, x1, x2, #N
 6465 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6466 %{
 6467   single_instruction;
 6468   dst    : EX2(write);
 6469   src1   : ISS(read);
 6470   src2   : ISS(read);
 6471   INS1   : ISS; // Can only dual issue as Instruction 1
 6472   ALU    : EX1;
 6473 %}
 6474 
 6475 // Integer ALU reg operation
 6476 // Eg.  NEG     x0, x1
 6477 pipe_class ialu_reg(iRegI dst, iRegI src)
 6478 %{
 6479   single_instruction;
 6480   dst    : EX2(write);
 6481   src    : EX1(read);
 6482   INS01  : ISS;
 6483   ALU    : EX2;
 6484 %}
 6485 
 6486 // Integer ALU reg mmediate operation
 6487 // Eg.  ADD     x0, x1, #N
 6488 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6489 %{
 6490   single_instruction;
 6491   dst    : EX2(write);
 6492   src1   : EX1(read);
 6493   INS01  : ISS;
 6494   ALU    : EX2;
 6495 %}
 6496 
 6497 // Integer ALU immediate operation (no source operands)
 6498 // Eg.  MOV     x0, #N
 6499 pipe_class ialu_imm(iRegI dst)
 6500 %{
 6501   single_instruction;
 6502   dst    : EX1(write);
 6503   INS01  : ISS;
 6504   ALU    : EX1;
 6505 %}
 6506 
 6507 //------- Compare operation -------------------------------
 6508 
 6509 // Compare reg-reg
 6510 // Eg.  CMP     x0, x1
 6511 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6512 %{
 6513   single_instruction;
 6514 //  fixed_latency(16);
 6515   cr     : EX2(write);
 6516   op1    : EX1(read);
 6517   op2    : EX1(read);
 6518   INS01  : ISS;
 6519   ALU    : EX2;
 6520 %}
 6521 
 6522 // Compare reg-reg
 6523 // Eg.  CMP     x0, #N
 6524 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6525 %{
 6526   single_instruction;
 6527 //  fixed_latency(16);
 6528   cr     : EX2(write);
 6529   op1    : EX1(read);
 6530   INS01  : ISS;
 6531   ALU    : EX2;
 6532 %}
 6533 
 6534 //------- Conditional instructions ------------------------
 6535 
 6536 // Conditional no operands
 6537 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6538 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6539 %{
 6540   single_instruction;
 6541   cr     : EX1(read);
 6542   dst    : EX2(write);
 6543   INS01  : ISS;
 6544   ALU    : EX2;
 6545 %}
 6546 
 6547 // Conditional 2 operand
 6548 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6549 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6550 %{
 6551   single_instruction;
 6552   cr     : EX1(read);
 6553   src1   : EX1(read);
 6554   src2   : EX1(read);
 6555   dst    : EX2(write);
 6556   INS01  : ISS;
 6557   ALU    : EX2;
 6558 %}
 6559 
 6560 // Conditional 2 operand
 6561 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6562 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6563 %{
 6564   single_instruction;
 6565   cr     : EX1(read);
 6566   src    : EX1(read);
 6567   dst    : EX2(write);
 6568   INS01  : ISS;
 6569   ALU    : EX2;
 6570 %}
 6571 
 6572 //------- Multiply pipeline operations --------------------
 6573 
 6574 // Multiply reg-reg
 6575 // Eg.  MUL     w0, w1, w2
 6576 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6577 %{
 6578   single_instruction;
 6579   dst    : WR(write);
 6580   src1   : ISS(read);
 6581   src2   : ISS(read);
 6582   INS01  : ISS;
 6583   MAC    : WR;
 6584 %}
 6585 
 6586 // Multiply accumulate
 6587 // Eg.  MADD    w0, w1, w2, w3
 6588 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6589 %{
 6590   single_instruction;
 6591   dst    : WR(write);
 6592   src1   : ISS(read);
 6593   src2   : ISS(read);
 6594   src3   : ISS(read);
 6595   INS01  : ISS;
 6596   MAC    : WR;
 6597 %}
 6598 
 6599 // Eg.  MUL     w0, w1, w2
 6600 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6601 %{
 6602   single_instruction;
 6603   fixed_latency(3); // Maximum latency for 64 bit mul
 6604   dst    : WR(write);
 6605   src1   : ISS(read);
 6606   src2   : ISS(read);
 6607   INS01  : ISS;
 6608   MAC    : WR;
 6609 %}
 6610 
 6611 // Multiply accumulate
 6612 // Eg.  MADD    w0, w1, w2, w3
 6613 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6614 %{
 6615   single_instruction;
 6616   fixed_latency(3); // Maximum latency for 64 bit mul
 6617   dst    : WR(write);
 6618   src1   : ISS(read);
 6619   src2   : ISS(read);
 6620   src3   : ISS(read);
 6621   INS01  : ISS;
 6622   MAC    : WR;
 6623 %}
 6624 
 6625 //------- Divide pipeline operations --------------------
 6626 
 6627 // Eg.  SDIV    w0, w1, w2
 6628 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6629 %{
 6630   single_instruction;
 6631   fixed_latency(8); // Maximum latency for 32 bit divide
 6632   dst    : WR(write);
 6633   src1   : ISS(read);
 6634   src2   : ISS(read);
 6635   INS0   : ISS; // Can only dual issue as instruction 0
 6636   DIV    : WR;
 6637 %}
 6638 
 6639 // Eg.  SDIV    x0, x1, x2
 6640 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6641 %{
 6642   single_instruction;
 6643   fixed_latency(16); // Maximum latency for 64 bit divide
 6644   dst    : WR(write);
 6645   src1   : ISS(read);
 6646   src2   : ISS(read);
 6647   INS0   : ISS; // Can only dual issue as instruction 0
 6648   DIV    : WR;
 6649 %}
 6650 
 6651 //------- Load pipeline operations ------------------------
 6652 
 6653 // Load - prefetch
 6654 // Eg.  PFRM    &lt;mem&gt;
 6655 pipe_class iload_prefetch(memory mem)
 6656 %{
 6657   single_instruction;
 6658   mem    : ISS(read);
 6659   INS01  : ISS;
 6660   LDST   : WR;
 6661 %}
 6662 
 6663 // Load - reg, mem
 6664 // Eg.  LDR     x0, &lt;mem&gt;
 6665 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6666 %{
 6667   single_instruction;
 6668   dst    : WR(write);
 6669   mem    : ISS(read);
 6670   INS01  : ISS;
 6671   LDST   : WR;
 6672 %}
 6673 
 6674 // Load - reg, reg
 6675 // Eg.  LDR     x0, [sp, x1]
 6676 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6677 %{
 6678   single_instruction;
 6679   dst    : WR(write);
 6680   src    : ISS(read);
 6681   INS01  : ISS;
 6682   LDST   : WR;
 6683 %}
 6684 
 6685 //------- Store pipeline operations -----------------------
 6686 
 6687 // Store - zr, mem
 6688 // Eg.  STR     zr, &lt;mem&gt;
 6689 pipe_class istore_mem(memory mem)
 6690 %{
 6691   single_instruction;
 6692   mem    : ISS(read);
 6693   INS01  : ISS;
 6694   LDST   : WR;
 6695 %}
 6696 
 6697 // Store - reg, mem
 6698 // Eg.  STR     x0, &lt;mem&gt;
 6699 pipe_class istore_reg_mem(iRegI src, memory mem)
 6700 %{
 6701   single_instruction;
 6702   mem    : ISS(read);
 6703   src    : EX2(read);
 6704   INS01  : ISS;
 6705   LDST   : WR;
 6706 %}
 6707 
 6708 // Store - reg, reg
 6709 // Eg. STR      x0, [sp, x1]
 6710 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6711 %{
 6712   single_instruction;
 6713   dst    : ISS(read);
 6714   src    : EX2(read);
 6715   INS01  : ISS;
 6716   LDST   : WR;
 6717 %}
 6718 
 6719 //------- Store pipeline operations -----------------------
 6720 
 6721 // Branch
 6722 pipe_class pipe_branch()
 6723 %{
 6724   single_instruction;
 6725   INS01  : ISS;
 6726   BRANCH : EX1;
 6727 %}
 6728 
 6729 // Conditional branch
 6730 pipe_class pipe_branch_cond(rFlagsReg cr)
 6731 %{
 6732   single_instruction;
 6733   cr     : EX1(read);
 6734   INS01  : ISS;
 6735   BRANCH : EX1;
 6736 %}
 6737 
 6738 // Compare &amp; Branch
 6739 // EG.  CBZ/CBNZ
 6740 pipe_class pipe_cmp_branch(iRegI op1)
 6741 %{
 6742   single_instruction;
 6743   op1    : EX1(read);
 6744   INS01  : ISS;
 6745   BRANCH : EX1;
 6746 %}
 6747 
 6748 //------- Synchronisation operations ----------------------
 6749 
 6750 // Any operation requiring serialization.
 6751 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6752 pipe_class pipe_serial()
 6753 %{
 6754   single_instruction;
 6755   force_serialization;
 6756   fixed_latency(16);
 6757   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6758   LDST   : WR;
 6759 %}
 6760 
 6761 // Generic big/slow expanded idiom - also serialized
 6762 pipe_class pipe_slow()
 6763 %{
 6764   instruction_count(10);
 6765   multiple_bundles;
 6766   force_serialization;
 6767   fixed_latency(16);
 6768   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6769   LDST   : WR;
 6770 %}
 6771 
 6772 // Empty pipeline class
 6773 pipe_class pipe_class_empty()
 6774 %{
 6775   single_instruction;
 6776   fixed_latency(0);
 6777 %}
 6778 
 6779 // Default pipeline class.
 6780 pipe_class pipe_class_default()
 6781 %{
 6782   single_instruction;
 6783   fixed_latency(2);
 6784 %}
 6785 
 6786 // Pipeline class for compares.
 6787 pipe_class pipe_class_compare()
 6788 %{
 6789   single_instruction;
 6790   fixed_latency(16);
 6791 %}
 6792 
 6793 // Pipeline class for memory operations.
 6794 pipe_class pipe_class_memory()
 6795 %{
 6796   single_instruction;
 6797   fixed_latency(16);
 6798 %}
 6799 
 6800 // Pipeline class for call.
 6801 pipe_class pipe_class_call()
 6802 %{
 6803   single_instruction;
 6804   fixed_latency(100);
 6805 %}
 6806 
 6807 // Define the class for the Nop node.
 6808 define %{
 6809    MachNop = pipe_class_empty;
 6810 %}
 6811 
 6812 %}
 6813 //----------INSTRUCTIONS-------------------------------------------------------
 6814 //
 6815 // match      -- States which machine-independent subtree may be replaced
 6816 //               by this instruction.
 6817 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6818 //               selection to identify a minimum cost tree of machine
 6819 //               instructions that matches a tree of machine-independent
 6820 //               instructions.
 6821 // format     -- A string providing the disassembly for this instruction.
 6822 //               The value of an instruction&#39;s operand may be inserted
 6823 //               by referring to it with a &#39;$&#39; prefix.
 6824 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6825 //               to within an encode class as $primary, $secondary, and $tertiary
 6826 //               rrspectively.  The primary opcode is commonly used to
 6827 //               indicate the type of machine instruction, while secondary
 6828 //               and tertiary are often used for prefix options or addressing
 6829 //               modes.
 6830 // ins_encode -- A list of encode classes with parameters. The encode class
 6831 //               name must have been defined in an &#39;enc_class&#39; specification
 6832 //               in the encode section of the architecture description.
 6833 
 6834 // ============================================================================
 6835 // Memory (Load/Store) Instructions
 6836 
 6837 // Load Instructions
 6838 
 6839 // Load Byte (8 bit signed)
 6840 instruct loadB(iRegINoSp dst, memory1 mem)
 6841 %{
 6842   match(Set dst (LoadB mem));
 6843   predicate(!needs_acquiring_load(n));
 6844 
 6845   ins_cost(4 * INSN_COST);
 6846   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6847 
 6848   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6849 
 6850   ins_pipe(iload_reg_mem);
 6851 %}
 6852 
 6853 // Load Byte (8 bit signed) into long
 6854 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6855 %{
 6856   match(Set dst (ConvI2L (LoadB mem)));
 6857   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6858 
 6859   ins_cost(4 * INSN_COST);
 6860   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6861 
 6862   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6863 
 6864   ins_pipe(iload_reg_mem);
 6865 %}
 6866 
 6867 // Load Byte (8 bit unsigned)
 6868 instruct loadUB(iRegINoSp dst, memory1 mem)
 6869 %{
 6870   match(Set dst (LoadUB mem));
 6871   predicate(!needs_acquiring_load(n));
 6872 
 6873   ins_cost(4 * INSN_COST);
 6874   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6875 
 6876   ins_encode(aarch64_enc_ldrb(dst, mem));
 6877 
 6878   ins_pipe(iload_reg_mem);
 6879 %}
 6880 
 6881 // Load Byte (8 bit unsigned) into long
 6882 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6883 %{
 6884   match(Set dst (ConvI2L (LoadUB mem)));
 6885   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6886 
 6887   ins_cost(4 * INSN_COST);
 6888   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6889 
 6890   ins_encode(aarch64_enc_ldrb(dst, mem));
 6891 
 6892   ins_pipe(iload_reg_mem);
 6893 %}
 6894 
 6895 // Load Short (16 bit signed)
 6896 instruct loadS(iRegINoSp dst, memory2 mem)
 6897 %{
 6898   match(Set dst (LoadS mem));
 6899   predicate(!needs_acquiring_load(n));
 6900 
 6901   ins_cost(4 * INSN_COST);
 6902   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6903 
 6904   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6905 
 6906   ins_pipe(iload_reg_mem);
 6907 %}
 6908 
 6909 // Load Short (16 bit signed) into long
 6910 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6911 %{
 6912   match(Set dst (ConvI2L (LoadS mem)));
 6913   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6914 
 6915   ins_cost(4 * INSN_COST);
 6916   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6917 
 6918   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6919 
 6920   ins_pipe(iload_reg_mem);
 6921 %}
 6922 
 6923 // Load Char (16 bit unsigned)
 6924 instruct loadUS(iRegINoSp dst, memory2 mem)
 6925 %{
 6926   match(Set dst (LoadUS mem));
 6927   predicate(!needs_acquiring_load(n));
 6928 
 6929   ins_cost(4 * INSN_COST);
 6930   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6931 
 6932   ins_encode(aarch64_enc_ldrh(dst, mem));
 6933 
 6934   ins_pipe(iload_reg_mem);
 6935 %}
 6936 
 6937 // Load Short/Char (16 bit unsigned) into long
 6938 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6939 %{
 6940   match(Set dst (ConvI2L (LoadUS mem)));
 6941   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6942 
 6943   ins_cost(4 * INSN_COST);
 6944   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6945 
 6946   ins_encode(aarch64_enc_ldrh(dst, mem));
 6947 
 6948   ins_pipe(iload_reg_mem);
 6949 %}
 6950 
 6951 // Load Integer (32 bit signed)
 6952 instruct loadI(iRegINoSp dst, memory4 mem)
 6953 %{
 6954   match(Set dst (LoadI mem));
 6955   predicate(!needs_acquiring_load(n));
 6956 
 6957   ins_cost(4 * INSN_COST);
 6958   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6959 
 6960   ins_encode(aarch64_enc_ldrw(dst, mem));
 6961 
 6962   ins_pipe(iload_reg_mem);
 6963 %}
 6964 
 6965 // Load Integer (32 bit signed) into long
 6966 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6967 %{
 6968   match(Set dst (ConvI2L (LoadI mem)));
 6969   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6970 
 6971   ins_cost(4 * INSN_COST);
 6972   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6973 
 6974   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6975 
 6976   ins_pipe(iload_reg_mem);
 6977 %}
 6978 
 6979 // Load Integer (32 bit unsigned) into long
 6980 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6981 %{
 6982   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6983   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6984 
 6985   ins_cost(4 * INSN_COST);
 6986   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6987 
 6988   ins_encode(aarch64_enc_ldrw(dst, mem));
 6989 
 6990   ins_pipe(iload_reg_mem);
 6991 %}
 6992 
 6993 // Load Long (64 bit signed)
 6994 instruct loadL(iRegLNoSp dst, memory8 mem)
 6995 %{
 6996   match(Set dst (LoadL mem));
 6997   predicate(!needs_acquiring_load(n));
 6998 
 6999   ins_cost(4 * INSN_COST);
 7000   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7001 
 7002   ins_encode(aarch64_enc_ldr(dst, mem));
 7003 
 7004   ins_pipe(iload_reg_mem);
 7005 %}
 7006 
 7007 // Load Range
 7008 instruct loadRange(iRegINoSp dst, memory4 mem)
 7009 %{
 7010   match(Set dst (LoadRange mem));
 7011 
 7012   ins_cost(4 * INSN_COST);
 7013   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7014 
 7015   ins_encode(aarch64_enc_ldrw(dst, mem));
 7016 
 7017   ins_pipe(iload_reg_mem);
 7018 %}
 7019 
 7020 // Load Pointer
 7021 instruct loadP(iRegPNoSp dst, memory8 mem)
 7022 %{
 7023   match(Set dst (LoadP mem));
 7024   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7025 
 7026   ins_cost(4 * INSN_COST);
 7027   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7028 
 7029   ins_encode(aarch64_enc_ldr(dst, mem));
 7030 
 7031   ins_pipe(iload_reg_mem);
 7032 %}
 7033 
 7034 // Load Compressed Pointer
 7035 instruct loadN(iRegNNoSp dst, memory4 mem)
 7036 %{
 7037   match(Set dst (LoadN mem));
 7038   predicate(!needs_acquiring_load(n));
 7039 
 7040   ins_cost(4 * INSN_COST);
 7041   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7042 
 7043   ins_encode(aarch64_enc_ldrw(dst, mem));
 7044 
 7045   ins_pipe(iload_reg_mem);
 7046 %}
 7047 
 7048 // Load Klass Pointer
 7049 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7050 %{
 7051   match(Set dst (LoadKlass mem));
 7052   predicate(!needs_acquiring_load(n));
 7053 
 7054   ins_cost(4 * INSN_COST);
 7055   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7056 
 7057   ins_encode(aarch64_enc_ldr(dst, mem));
 7058 
 7059   ins_pipe(iload_reg_mem);
 7060 %}
 7061 
 7062 // Load Narrow Klass Pointer
 7063 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7064 %{
 7065   match(Set dst (LoadNKlass mem));
 7066   predicate(!needs_acquiring_load(n));
 7067 
 7068   ins_cost(4 * INSN_COST);
 7069   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7070 
 7071   ins_encode(aarch64_enc_ldrw(dst, mem));
 7072 
 7073   ins_pipe(iload_reg_mem);
 7074 %}
 7075 
 7076 // Load Float
 7077 instruct loadF(vRegF dst, memory4 mem)
 7078 %{
 7079   match(Set dst (LoadF mem));
 7080   predicate(!needs_acquiring_load(n));
 7081 
 7082   ins_cost(4 * INSN_COST);
 7083   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7084 
 7085   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7086 
 7087   ins_pipe(pipe_class_memory);
 7088 %}
 7089 
 7090 // Load Double
 7091 instruct loadD(vRegD dst, memory8 mem)
 7092 %{
 7093   match(Set dst (LoadD mem));
 7094   predicate(!needs_acquiring_load(n));
 7095 
 7096   ins_cost(4 * INSN_COST);
 7097   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7098 
 7099   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7100 
 7101   ins_pipe(pipe_class_memory);
 7102 %}
 7103 
 7104 
 7105 // Load Int Constant
 7106 instruct loadConI(iRegINoSp dst, immI src)
 7107 %{
 7108   match(Set dst src);
 7109 
 7110   ins_cost(INSN_COST);
 7111   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7112 
 7113   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7114 
 7115   ins_pipe(ialu_imm);
 7116 %}
 7117 
 7118 // Load Long Constant
 7119 instruct loadConL(iRegLNoSp dst, immL src)
 7120 %{
 7121   match(Set dst src);
 7122 
 7123   ins_cost(INSN_COST);
 7124   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7125 
 7126   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7127 
 7128   ins_pipe(ialu_imm);
 7129 %}
 7130 
 7131 // Load Pointer Constant
 7132 
 7133 instruct loadConP(iRegPNoSp dst, immP con)
 7134 %{
 7135   match(Set dst con);
 7136 
 7137   ins_cost(INSN_COST * 4);
 7138   format %{
 7139     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7140   %}
 7141 
 7142   ins_encode(aarch64_enc_mov_p(dst, con));
 7143 
 7144   ins_pipe(ialu_imm);
 7145 %}
 7146 
 7147 // Load Null Pointer Constant
 7148 
 7149 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7150 %{
 7151   match(Set dst con);
 7152 
 7153   ins_cost(INSN_COST);
 7154   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7155 
 7156   ins_encode(aarch64_enc_mov_p0(dst, con));
 7157 
 7158   ins_pipe(ialu_imm);
 7159 %}
 7160 
 7161 // Load Pointer Constant One
 7162 
 7163 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7164 %{
 7165   match(Set dst con);
 7166 
 7167   ins_cost(INSN_COST);
 7168   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7169 
 7170   ins_encode(aarch64_enc_mov_p1(dst, con));
 7171 
 7172   ins_pipe(ialu_imm);
 7173 %}
 7174 
 7175 // Load Byte Map Base Constant
 7176 
 7177 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7178 %{
 7179   match(Set dst con);
 7180 
 7181   ins_cost(INSN_COST);
 7182   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7183 
 7184   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7185 
 7186   ins_pipe(ialu_imm);
 7187 %}
 7188 
 7189 // Load Narrow Pointer Constant
 7190 
 7191 instruct loadConN(iRegNNoSp dst, immN con)
 7192 %{
 7193   match(Set dst con);
 7194 
 7195   ins_cost(INSN_COST * 4);
 7196   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7197 
 7198   ins_encode(aarch64_enc_mov_n(dst, con));
 7199 
 7200   ins_pipe(ialu_imm);
 7201 %}
 7202 
 7203 // Load Narrow Null Pointer Constant
 7204 
 7205 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7206 %{
 7207   match(Set dst con);
 7208 
 7209   ins_cost(INSN_COST);
 7210   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7211 
 7212   ins_encode(aarch64_enc_mov_n0(dst, con));
 7213 
 7214   ins_pipe(ialu_imm);
 7215 %}
 7216 
 7217 // Load Narrow Klass Constant
 7218 
 7219 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7220 %{
 7221   match(Set dst con);
 7222 
 7223   ins_cost(INSN_COST);
 7224   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7225 
 7226   ins_encode(aarch64_enc_mov_nk(dst, con));
 7227 
 7228   ins_pipe(ialu_imm);
 7229 %}
 7230 
 7231 // Load Packed Float Constant
 7232 
 7233 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7234   match(Set dst con);
 7235   ins_cost(INSN_COST * 4);
 7236   format %{ &quot;fmovs  $dst, $con&quot;%}
 7237   ins_encode %{
 7238     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7239   %}
 7240 
 7241   ins_pipe(fp_imm_s);
 7242 %}
 7243 
 7244 // Load Float Constant
 7245 
 7246 instruct loadConF(vRegF dst, immF con) %{
 7247   match(Set dst con);
 7248 
 7249   ins_cost(INSN_COST * 4);
 7250 
 7251   format %{
 7252     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7253   %}
 7254 
 7255   ins_encode %{
 7256     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7257   %}
 7258 
 7259   ins_pipe(fp_load_constant_s);
 7260 %}
 7261 
 7262 // Load Packed Double Constant
 7263 
 7264 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7265   match(Set dst con);
 7266   ins_cost(INSN_COST);
 7267   format %{ &quot;fmovd  $dst, $con&quot;%}
 7268   ins_encode %{
 7269     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7270   %}
 7271 
 7272   ins_pipe(fp_imm_d);
 7273 %}
 7274 
 7275 // Load Double Constant
 7276 
 7277 instruct loadConD(vRegD dst, immD con) %{
 7278   match(Set dst con);
 7279 
 7280   ins_cost(INSN_COST * 5);
 7281   format %{
 7282     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7283   %}
 7284 
 7285   ins_encode %{
 7286     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7287   %}
 7288 
 7289   ins_pipe(fp_load_constant_d);
 7290 %}
 7291 
 7292 // Store Instructions
 7293 
 7294 // Store CMS card-mark Immediate
 7295 instruct storeimmCM0(immI0 zero, memory1 mem)
 7296 %{
 7297   match(Set mem (StoreCM mem zero));
 7298 
 7299   ins_cost(INSN_COST);
 7300   format %{ &quot;storestore (elided)\n\t&quot;
 7301             &quot;strb zr, $mem\t# byte&quot; %}
 7302 
 7303   ins_encode(aarch64_enc_strb0(mem));
 7304 
 7305   ins_pipe(istore_mem);
 7306 %}
 7307 
 7308 // Store CMS card-mark Immediate with intervening StoreStore
 7309 // needed when using CMS with no conditional card marking
 7310 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7311 %{
 7312   match(Set mem (StoreCM mem zero));
 7313 
 7314   ins_cost(INSN_COST * 2);
 7315   format %{ &quot;storestore\n\t&quot;
 7316             &quot;dmb ishst&quot;
 7317             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7318 
 7319   ins_encode(aarch64_enc_strb0_ordered(mem));
 7320 
 7321   ins_pipe(istore_mem);
 7322 %}
 7323 
 7324 // Store Byte
 7325 instruct storeB(iRegIorL2I src, memory1 mem)
 7326 %{
 7327   match(Set mem (StoreB mem src));
 7328   predicate(!needs_releasing_store(n));
 7329 
 7330   ins_cost(INSN_COST);
 7331   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7332 
 7333   ins_encode(aarch64_enc_strb(src, mem));
 7334 
 7335   ins_pipe(istore_reg_mem);
 7336 %}
 7337 
 7338 
 7339 instruct storeimmB0(immI0 zero, memory1 mem)
 7340 %{
 7341   match(Set mem (StoreB mem zero));
 7342   predicate(!needs_releasing_store(n));
 7343 
 7344   ins_cost(INSN_COST);
 7345   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7346 
 7347   ins_encode(aarch64_enc_strb0(mem));
 7348 
 7349   ins_pipe(istore_mem);
 7350 %}
 7351 
 7352 // Store Char/Short
 7353 instruct storeC(iRegIorL2I src, memory2 mem)
 7354 %{
 7355   match(Set mem (StoreC mem src));
 7356   predicate(!needs_releasing_store(n));
 7357 
 7358   ins_cost(INSN_COST);
 7359   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7360 
 7361   ins_encode(aarch64_enc_strh(src, mem));
 7362 
 7363   ins_pipe(istore_reg_mem);
 7364 %}
 7365 
 7366 instruct storeimmC0(immI0 zero, memory2 mem)
 7367 %{
 7368   match(Set mem (StoreC mem zero));
 7369   predicate(!needs_releasing_store(n));
 7370 
 7371   ins_cost(INSN_COST);
 7372   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7373 
 7374   ins_encode(aarch64_enc_strh0(mem));
 7375 
 7376   ins_pipe(istore_mem);
 7377 %}
 7378 
 7379 // Store Integer
 7380 
 7381 instruct storeI(iRegIorL2I src, memory4 mem)
 7382 %{
 7383   match(Set mem(StoreI mem src));
 7384   predicate(!needs_releasing_store(n));
 7385 
 7386   ins_cost(INSN_COST);
 7387   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7388 
 7389   ins_encode(aarch64_enc_strw(src, mem));
 7390 
 7391   ins_pipe(istore_reg_mem);
 7392 %}
 7393 
 7394 instruct storeimmI0(immI0 zero, memory4 mem)
 7395 %{
 7396   match(Set mem(StoreI mem zero));
 7397   predicate(!needs_releasing_store(n));
 7398 
 7399   ins_cost(INSN_COST);
 7400   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7401 
 7402   ins_encode(aarch64_enc_strw0(mem));
 7403 
 7404   ins_pipe(istore_mem);
 7405 %}
 7406 
 7407 // Store Long (64 bit signed)
 7408 instruct storeL(iRegL src, memory8 mem)
 7409 %{
 7410   match(Set mem (StoreL mem src));
 7411   predicate(!needs_releasing_store(n));
 7412 
 7413   ins_cost(INSN_COST);
 7414   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7415 
 7416   ins_encode(aarch64_enc_str(src, mem));
 7417 
 7418   ins_pipe(istore_reg_mem);
 7419 %}
 7420 
 7421 // Store Long (64 bit signed)
 7422 instruct storeimmL0(immL0 zero, memory8 mem)
 7423 %{
 7424   match(Set mem (StoreL mem zero));
 7425   predicate(!needs_releasing_store(n));
 7426 
 7427   ins_cost(INSN_COST);
 7428   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7429 
 7430   ins_encode(aarch64_enc_str0(mem));
 7431 
 7432   ins_pipe(istore_mem);
 7433 %}
 7434 
 7435 // Store Pointer
 7436 instruct storeP(iRegP src, memory8 mem)
 7437 %{
 7438   match(Set mem (StoreP mem src));
 7439   predicate(!needs_releasing_store(n));
 7440 
 7441   ins_cost(INSN_COST);
 7442   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7443 
 7444   ins_encode(aarch64_enc_str(src, mem));
 7445 
 7446   ins_pipe(istore_reg_mem);
 7447 %}
 7448 
 7449 // Store Pointer
 7450 instruct storeimmP0(immP0 zero, memory8 mem)
 7451 %{
 7452   match(Set mem (StoreP mem zero));
 7453   predicate(!needs_releasing_store(n));
 7454 
 7455   ins_cost(INSN_COST);
 7456   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7457 
 7458   ins_encode(aarch64_enc_str0(mem));
 7459 
 7460   ins_pipe(istore_mem);
 7461 %}
 7462 
 7463 // Store Compressed Pointer
 7464 instruct storeN(iRegN src, memory4 mem)
 7465 %{
 7466   match(Set mem (StoreN mem src));
 7467   predicate(!needs_releasing_store(n));
 7468 
 7469   ins_cost(INSN_COST);
 7470   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7471 
 7472   ins_encode(aarch64_enc_strw(src, mem));
 7473 
 7474   ins_pipe(istore_reg_mem);
 7475 %}
 7476 
 7477 instruct storeImmN0(immN0 zero, memory4 mem)
 7478 %{
 7479   match(Set mem (StoreN mem zero));
 7480   predicate(!needs_releasing_store(n));
 7481 
 7482   ins_cost(INSN_COST);
 7483   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7484 
 7485   ins_encode(aarch64_enc_strw0(mem));
 7486 
 7487   ins_pipe(istore_mem);
 7488 %}
 7489 
 7490 // Store Float
 7491 instruct storeF(vRegF src, memory4 mem)
 7492 %{
 7493   match(Set mem (StoreF mem src));
 7494   predicate(!needs_releasing_store(n));
 7495 
 7496   ins_cost(INSN_COST);
 7497   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7498 
 7499   ins_encode( aarch64_enc_strs(src, mem) );
 7500 
 7501   ins_pipe(pipe_class_memory);
 7502 %}
 7503 
 7504 // TODO
 7505 // implement storeImmF0 and storeFImmPacked
 7506 
 7507 // Store Double
 7508 instruct storeD(vRegD src, memory8 mem)
 7509 %{
 7510   match(Set mem (StoreD mem src));
 7511   predicate(!needs_releasing_store(n));
 7512 
 7513   ins_cost(INSN_COST);
 7514   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7515 
 7516   ins_encode( aarch64_enc_strd(src, mem) );
 7517 
 7518   ins_pipe(pipe_class_memory);
 7519 %}
 7520 
 7521 // Store Compressed Klass Pointer
 7522 instruct storeNKlass(iRegN src, memory4 mem)
 7523 %{
 7524   predicate(!needs_releasing_store(n));
 7525   match(Set mem (StoreNKlass mem src));
 7526 
 7527   ins_cost(INSN_COST);
 7528   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7529 
 7530   ins_encode(aarch64_enc_strw(src, mem));
 7531 
 7532   ins_pipe(istore_reg_mem);
 7533 %}
 7534 
 7535 // TODO
 7536 // implement storeImmD0 and storeDImmPacked
 7537 
 7538 // prefetch instructions
 7539 // Must be safe to execute with invalid address (cannot fault).
 7540 
 7541 instruct prefetchalloc( memory8 mem ) %{
 7542   match(PrefetchAllocation mem);
 7543 
 7544   ins_cost(INSN_COST);
 7545   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7546 
 7547   ins_encode( aarch64_enc_prefetchw(mem) );
 7548 
 7549   ins_pipe(iload_prefetch);
 7550 %}
 7551 
 7552 //  ---------------- volatile loads and stores ----------------
 7553 
 7554 // Load Byte (8 bit signed)
 7555 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7556 %{
 7557   match(Set dst (LoadB mem));
 7558 
 7559   ins_cost(VOLATILE_REF_COST);
 7560   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7561 
 7562   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7563 
 7564   ins_pipe(pipe_serial);
 7565 %}
 7566 
 7567 // Load Byte (8 bit signed) into long
 7568 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7569 %{
 7570   match(Set dst (ConvI2L (LoadB mem)));
 7571 
 7572   ins_cost(VOLATILE_REF_COST);
 7573   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7574 
 7575   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7576 
 7577   ins_pipe(pipe_serial);
 7578 %}
 7579 
 7580 // Load Byte (8 bit unsigned)
 7581 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7582 %{
 7583   match(Set dst (LoadUB mem));
 7584 
 7585   ins_cost(VOLATILE_REF_COST);
 7586   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7587 
 7588   ins_encode(aarch64_enc_ldarb(dst, mem));
 7589 
 7590   ins_pipe(pipe_serial);
 7591 %}
 7592 
 7593 // Load Byte (8 bit unsigned) into long
 7594 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7595 %{
 7596   match(Set dst (ConvI2L (LoadUB mem)));
 7597 
 7598   ins_cost(VOLATILE_REF_COST);
 7599   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7600 
 7601   ins_encode(aarch64_enc_ldarb(dst, mem));
 7602 
 7603   ins_pipe(pipe_serial);
 7604 %}
 7605 
 7606 // Load Short (16 bit signed)
 7607 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7608 %{
 7609   match(Set dst (LoadS mem));
 7610 
 7611   ins_cost(VOLATILE_REF_COST);
 7612   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7613 
 7614   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7615 
 7616   ins_pipe(pipe_serial);
 7617 %}
 7618 
 7619 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7620 %{
 7621   match(Set dst (LoadUS mem));
 7622 
 7623   ins_cost(VOLATILE_REF_COST);
 7624   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7625 
 7626   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7627 
 7628   ins_pipe(pipe_serial);
 7629 %}
 7630 
 7631 // Load Short/Char (16 bit unsigned) into long
 7632 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7633 %{
 7634   match(Set dst (ConvI2L (LoadUS mem)));
 7635 
 7636   ins_cost(VOLATILE_REF_COST);
 7637   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7638 
 7639   ins_encode(aarch64_enc_ldarh(dst, mem));
 7640 
 7641   ins_pipe(pipe_serial);
 7642 %}
 7643 
 7644 // Load Short/Char (16 bit signed) into long
 7645 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7646 %{
 7647   match(Set dst (ConvI2L (LoadS mem)));
 7648 
 7649   ins_cost(VOLATILE_REF_COST);
 7650   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7651 
 7652   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7653 
 7654   ins_pipe(pipe_serial);
 7655 %}
 7656 
 7657 // Load Integer (32 bit signed)
 7658 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7659 %{
 7660   match(Set dst (LoadI mem));
 7661 
 7662   ins_cost(VOLATILE_REF_COST);
 7663   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7664 
 7665   ins_encode(aarch64_enc_ldarw(dst, mem));
 7666 
 7667   ins_pipe(pipe_serial);
 7668 %}
 7669 
 7670 // Load Integer (32 bit unsigned) into long
 7671 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7672 %{
 7673   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7674 
 7675   ins_cost(VOLATILE_REF_COST);
 7676   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7677 
 7678   ins_encode(aarch64_enc_ldarw(dst, mem));
 7679 
 7680   ins_pipe(pipe_serial);
 7681 %}
 7682 
 7683 // Load Long (64 bit signed)
 7684 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7685 %{
 7686   match(Set dst (LoadL mem));
 7687 
 7688   ins_cost(VOLATILE_REF_COST);
 7689   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7690 
 7691   ins_encode(aarch64_enc_ldar(dst, mem));
 7692 
 7693   ins_pipe(pipe_serial);
 7694 %}
 7695 
 7696 // Load Pointer
 7697 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7698 %{
 7699   match(Set dst (LoadP mem));
 7700   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7701 
 7702   ins_cost(VOLATILE_REF_COST);
 7703   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7704 
 7705   ins_encode(aarch64_enc_ldar(dst, mem));
 7706 
 7707   ins_pipe(pipe_serial);
 7708 %}
 7709 
 7710 // Load Compressed Pointer
 7711 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7712 %{
 7713   match(Set dst (LoadN mem));
 7714 
 7715   ins_cost(VOLATILE_REF_COST);
 7716   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7717 
 7718   ins_encode(aarch64_enc_ldarw(dst, mem));
 7719 
 7720   ins_pipe(pipe_serial);
 7721 %}
 7722 
 7723 // Load Float
 7724 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7725 %{
 7726   match(Set dst (LoadF mem));
 7727 
 7728   ins_cost(VOLATILE_REF_COST);
 7729   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7730 
 7731   ins_encode( aarch64_enc_fldars(dst, mem) );
 7732 
 7733   ins_pipe(pipe_serial);
 7734 %}
 7735 
 7736 // Load Double
 7737 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7738 %{
 7739   match(Set dst (LoadD mem));
 7740 
 7741   ins_cost(VOLATILE_REF_COST);
 7742   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7743 
 7744   ins_encode( aarch64_enc_fldard(dst, mem) );
 7745 
 7746   ins_pipe(pipe_serial);
 7747 %}
 7748 
 7749 // Store Byte
 7750 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7751 %{
 7752   match(Set mem (StoreB mem src));
 7753 
 7754   ins_cost(VOLATILE_REF_COST);
 7755   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7756 
 7757   ins_encode(aarch64_enc_stlrb(src, mem));
 7758 
 7759   ins_pipe(pipe_class_memory);
 7760 %}
 7761 
 7762 // Store Char/Short
 7763 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7764 %{
 7765   match(Set mem (StoreC mem src));
 7766 
 7767   ins_cost(VOLATILE_REF_COST);
 7768   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7769 
 7770   ins_encode(aarch64_enc_stlrh(src, mem));
 7771 
 7772   ins_pipe(pipe_class_memory);
 7773 %}
 7774 
 7775 // Store Integer
 7776 
 7777 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7778 %{
 7779   match(Set mem(StoreI mem src));
 7780 
 7781   ins_cost(VOLATILE_REF_COST);
 7782   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7783 
 7784   ins_encode(aarch64_enc_stlrw(src, mem));
 7785 
 7786   ins_pipe(pipe_class_memory);
 7787 %}
 7788 
 7789 // Store Long (64 bit signed)
 7790 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7791 %{
 7792   match(Set mem (StoreL mem src));
 7793 
 7794   ins_cost(VOLATILE_REF_COST);
 7795   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7796 
 7797   ins_encode(aarch64_enc_stlr(src, mem));
 7798 
 7799   ins_pipe(pipe_class_memory);
 7800 %}
 7801 
 7802 // Store Pointer
 7803 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7804 %{
 7805   match(Set mem (StoreP mem src));
 7806 
 7807   ins_cost(VOLATILE_REF_COST);
 7808   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7809 
 7810   ins_encode(aarch64_enc_stlr(src, mem));
 7811 
 7812   ins_pipe(pipe_class_memory);
 7813 %}
 7814 
 7815 // Store Compressed Pointer
 7816 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7817 %{
 7818   match(Set mem (StoreN mem src));
 7819 
 7820   ins_cost(VOLATILE_REF_COST);
 7821   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7822 
 7823   ins_encode(aarch64_enc_stlrw(src, mem));
 7824 
 7825   ins_pipe(pipe_class_memory);
 7826 %}
 7827 
 7828 // Store Float
 7829 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7830 %{
 7831   match(Set mem (StoreF mem src));
 7832 
 7833   ins_cost(VOLATILE_REF_COST);
 7834   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7835 
 7836   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7837 
 7838   ins_pipe(pipe_class_memory);
 7839 %}
 7840 
 7841 // TODO
 7842 // implement storeImmF0 and storeFImmPacked
 7843 
 7844 // Store Double
 7845 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7846 %{
 7847   match(Set mem (StoreD mem src));
 7848 
 7849   ins_cost(VOLATILE_REF_COST);
 7850   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7851 
 7852   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7853 
 7854   ins_pipe(pipe_class_memory);
 7855 %}
 7856 
 7857 //  ---------------- end of volatile loads and stores ----------------
 7858 
 7859 instruct cacheWB(indirect addr)
 7860 %{
 7861   predicate(VM_Version::supports_data_cache_line_flush());
 7862   match(CacheWB addr);
 7863 
 7864   ins_cost(100);
 7865   format %{&quot;cache wb $addr&quot; %}
 7866   ins_encode %{
 7867     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7868     assert($addr$$disp == 0, &quot;should be&quot;);
 7869     __ cache_wb(Address($addr$$base$$Register, 0));
 7870   %}
 7871   ins_pipe(pipe_slow); // XXX
 7872 %}
 7873 
 7874 instruct cacheWBPreSync()
 7875 %{
 7876   predicate(VM_Version::supports_data_cache_line_flush());
 7877   match(CacheWBPreSync);
 7878 
 7879   ins_cost(100);
 7880   format %{&quot;cache wb presync&quot; %}
 7881   ins_encode %{
 7882     __ cache_wbsync(true);
 7883   %}
 7884   ins_pipe(pipe_slow); // XXX
 7885 %}
 7886 
 7887 instruct cacheWBPostSync()
 7888 %{
 7889   predicate(VM_Version::supports_data_cache_line_flush());
 7890   match(CacheWBPostSync);
 7891 
 7892   ins_cost(100);
 7893   format %{&quot;cache wb postsync&quot; %}
 7894   ins_encode %{
 7895     __ cache_wbsync(false);
 7896   %}
 7897   ins_pipe(pipe_slow); // XXX
 7898 %}
 7899 
 7900 // ============================================================================
 7901 // BSWAP Instructions
 7902 
 7903 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7904   match(Set dst (ReverseBytesI src));
 7905 
 7906   ins_cost(INSN_COST);
 7907   format %{ &quot;revw  $dst, $src&quot; %}
 7908 
 7909   ins_encode %{
 7910     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7911   %}
 7912 
 7913   ins_pipe(ialu_reg);
 7914 %}
 7915 
 7916 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7917   match(Set dst (ReverseBytesL src));
 7918 
 7919   ins_cost(INSN_COST);
 7920   format %{ &quot;rev  $dst, $src&quot; %}
 7921 
 7922   ins_encode %{
 7923     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7924   %}
 7925 
 7926   ins_pipe(ialu_reg);
 7927 %}
 7928 
 7929 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7930   match(Set dst (ReverseBytesUS src));
 7931 
 7932   ins_cost(INSN_COST);
 7933   format %{ &quot;rev16w  $dst, $src&quot; %}
 7934 
 7935   ins_encode %{
 7936     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7937   %}
 7938 
 7939   ins_pipe(ialu_reg);
 7940 %}
 7941 
 7942 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7943   match(Set dst (ReverseBytesS src));
 7944 
 7945   ins_cost(INSN_COST);
 7946   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7947             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7948 
 7949   ins_encode %{
 7950     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7951     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7952   %}
 7953 
 7954   ins_pipe(ialu_reg);
 7955 %}
 7956 
 7957 // ============================================================================
 7958 // Zero Count Instructions
 7959 
 7960 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7961   match(Set dst (CountLeadingZerosI src));
 7962 
 7963   ins_cost(INSN_COST);
 7964   format %{ &quot;clzw  $dst, $src&quot; %}
 7965   ins_encode %{
 7966     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7967   %}
 7968 
 7969   ins_pipe(ialu_reg);
 7970 %}
 7971 
 7972 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7973   match(Set dst (CountLeadingZerosL src));
 7974 
 7975   ins_cost(INSN_COST);
 7976   format %{ &quot;clz   $dst, $src&quot; %}
 7977   ins_encode %{
 7978     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7985   match(Set dst (CountTrailingZerosI src));
 7986 
 7987   ins_cost(INSN_COST * 2);
 7988   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7989             &quot;clzw   $dst, $dst&quot; %}
 7990   ins_encode %{
 7991     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7992     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7993   %}
 7994 
 7995   ins_pipe(ialu_reg);
 7996 %}
 7997 
 7998 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 7999   match(Set dst (CountTrailingZerosL src));
 8000 
 8001   ins_cost(INSN_COST * 2);
 8002   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8003             &quot;clz    $dst, $dst&quot; %}
 8004   ins_encode %{
 8005     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8006     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8007   %}
 8008 
 8009   ins_pipe(ialu_reg);
 8010 %}
 8011 
 8012 //---------- Population Count Instructions -------------------------------------
 8013 //
 8014 
 8015 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8016   predicate(UsePopCountInstruction);
 8017   match(Set dst (PopCountI src));
 8018   effect(TEMP tmp);
 8019   ins_cost(INSN_COST * 13);
 8020 
 8021   format %{ &quot;movw   $src, $src\n\t&quot;
 8022             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8023             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8024             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8025             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8026   ins_encode %{
 8027     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8028     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8029     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8030     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8031     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8032   %}
 8033 
 8034   ins_pipe(pipe_class_default);
 8035 %}
 8036 
 8037 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8038   predicate(UsePopCountInstruction);
 8039   match(Set dst (PopCountI (LoadI mem)));
 8040   effect(TEMP tmp);
 8041   ins_cost(INSN_COST * 13);
 8042 
 8043   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8044             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8045             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8046             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8047   ins_encode %{
 8048     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8049     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8050               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8051     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8052     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8053     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8054   %}
 8055 
 8056   ins_pipe(pipe_class_default);
 8057 %}
 8058 
 8059 // Note: Long.bitCount(long) returns an int.
 8060 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8061   predicate(UsePopCountInstruction);
 8062   match(Set dst (PopCountL src));
 8063   effect(TEMP tmp);
 8064   ins_cost(INSN_COST * 13);
 8065 
 8066   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8067             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8068             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8069             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8070   ins_encode %{
 8071     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8072     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8074     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8075   %}
 8076 
 8077   ins_pipe(pipe_class_default);
 8078 %}
 8079 
 8080 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8081   predicate(UsePopCountInstruction);
 8082   match(Set dst (PopCountL (LoadL mem)));
 8083   effect(TEMP tmp);
 8084   ins_cost(INSN_COST * 13);
 8085 
 8086   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8087             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8089             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8090   ins_encode %{
 8091     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8092     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8093               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8094     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8096     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8097   %}
 8098 
 8099   ins_pipe(pipe_class_default);
 8100 %}
 8101 
 8102 // ============================================================================
 8103 // MemBar Instruction
 8104 
 8105 instruct load_fence() %{
 8106   match(LoadFence);
 8107   ins_cost(VOLATILE_REF_COST);
 8108 
 8109   format %{ &quot;load_fence&quot; %}
 8110 
 8111   ins_encode %{
 8112     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8113   %}
 8114   ins_pipe(pipe_serial);
 8115 %}
 8116 
 8117 instruct unnecessary_membar_acquire() %{
 8118   predicate(unnecessary_acquire(n));
 8119   match(MemBarAcquire);
 8120   ins_cost(0);
 8121 
 8122   format %{ &quot;membar_acquire (elided)&quot; %}
 8123 
 8124   ins_encode %{
 8125     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8126   %}
 8127 
 8128   ins_pipe(pipe_class_empty);
 8129 %}
 8130 
 8131 instruct membar_acquire() %{
 8132   match(MemBarAcquire);
 8133   ins_cost(VOLATILE_REF_COST);
 8134 
 8135   format %{ &quot;membar_acquire\n\t&quot;
 8136             &quot;dmb ish&quot; %}
 8137 
 8138   ins_encode %{
 8139     __ block_comment(&quot;membar_acquire&quot;);
 8140     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8141   %}
 8142 
 8143   ins_pipe(pipe_serial);
 8144 %}
 8145 
 8146 
 8147 instruct membar_acquire_lock() %{
 8148   match(MemBarAcquireLock);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8152 
 8153   ins_encode %{
 8154     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8155   %}
 8156 
 8157   ins_pipe(pipe_serial);
 8158 %}
 8159 
 8160 instruct store_fence() %{
 8161   match(StoreFence);
 8162   ins_cost(VOLATILE_REF_COST);
 8163 
 8164   format %{ &quot;store_fence&quot; %}
 8165 
 8166   ins_encode %{
 8167     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8168   %}
 8169   ins_pipe(pipe_serial);
 8170 %}
 8171 
 8172 instruct unnecessary_membar_release() %{
 8173   predicate(unnecessary_release(n));
 8174   match(MemBarRelease);
 8175   ins_cost(0);
 8176 
 8177   format %{ &quot;membar_release (elided)&quot; %}
 8178 
 8179   ins_encode %{
 8180     __ block_comment(&quot;membar_release (elided)&quot;);
 8181   %}
 8182   ins_pipe(pipe_serial);
 8183 %}
 8184 
 8185 instruct membar_release() %{
 8186   match(MemBarRelease);
 8187   ins_cost(VOLATILE_REF_COST);
 8188 
 8189   format %{ &quot;membar_release\n\t&quot;
 8190             &quot;dmb ish&quot; %}
 8191 
 8192   ins_encode %{
 8193     __ block_comment(&quot;membar_release&quot;);
 8194     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8195   %}
 8196   ins_pipe(pipe_serial);
 8197 %}
 8198 
 8199 instruct membar_storestore() %{
 8200   match(MemBarStoreStore);
 8201   ins_cost(VOLATILE_REF_COST);
 8202 
 8203   format %{ &quot;MEMBAR-store-store&quot; %}
 8204 
 8205   ins_encode %{
 8206     __ membar(Assembler::StoreStore);
 8207   %}
 8208   ins_pipe(pipe_serial);
 8209 %}
 8210 
 8211 instruct membar_release_lock() %{
 8212   match(MemBarReleaseLock);
 8213   ins_cost(VOLATILE_REF_COST);
 8214 
 8215   format %{ &quot;membar_release_lock (elided)&quot; %}
 8216 
 8217   ins_encode %{
 8218     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8219   %}
 8220 
 8221   ins_pipe(pipe_serial);
 8222 %}
 8223 
 8224 instruct unnecessary_membar_volatile() %{
 8225   predicate(unnecessary_volatile(n));
 8226   match(MemBarVolatile);
 8227   ins_cost(0);
 8228 
 8229   format %{ &quot;membar_volatile (elided)&quot; %}
 8230 
 8231   ins_encode %{
 8232     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8233   %}
 8234 
 8235   ins_pipe(pipe_serial);
 8236 %}
 8237 
 8238 instruct membar_volatile() %{
 8239   match(MemBarVolatile);
 8240   ins_cost(VOLATILE_REF_COST*100);
 8241 
 8242   format %{ &quot;membar_volatile\n\t&quot;
 8243              &quot;dmb ish&quot;%}
 8244 
 8245   ins_encode %{
 8246     __ block_comment(&quot;membar_volatile&quot;);
 8247     __ membar(Assembler::StoreLoad);
 8248   %}
 8249 
 8250   ins_pipe(pipe_serial);
 8251 %}
 8252 
 8253 // ============================================================================
 8254 // Cast/Convert Instructions
 8255 
 8256 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8257   match(Set dst (CastX2P src));
 8258 
 8259   ins_cost(INSN_COST);
 8260   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8261 
 8262   ins_encode %{
 8263     if ($dst$$reg != $src$$reg) {
 8264       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8265     }
 8266   %}
 8267 
 8268   ins_pipe(ialu_reg);
 8269 %}
 8270 
 8271 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8272   match(Set dst (CastP2X src));
 8273 
 8274   ins_cost(INSN_COST);
 8275   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8276 
 8277   ins_encode %{
 8278     if ($dst$$reg != $src$$reg) {
 8279       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8280     }
 8281   %}
 8282 
 8283   ins_pipe(ialu_reg);
 8284 %}
 8285 
 8286 // Convert oop into int for vectors alignment masking
 8287 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8288   match(Set dst (ConvL2I (CastP2X src)));
 8289 
 8290   ins_cost(INSN_COST);
 8291   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8292   ins_encode %{
 8293     __ movw($dst$$Register, $src$$Register);
 8294   %}
 8295 
 8296   ins_pipe(ialu_reg);
 8297 %}
 8298 
 8299 // Convert compressed oop into int for vectors alignment masking
 8300 // in case of 32bit oops (heap &lt; 4Gb).
 8301 instruct convN2I(iRegINoSp dst, iRegN src)
 8302 %{
 8303   predicate(CompressedOops::shift() == 0);
 8304   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8305 
 8306   ins_cost(INSN_COST);
 8307   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8308   ins_encode %{
 8309     __ movw($dst$$Register, $src$$Register);
 8310   %}
 8311 
 8312   ins_pipe(ialu_reg);
 8313 %}
 8314 
 8315 
 8316 // Convert oop pointer into compressed form
 8317 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8318   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8319   match(Set dst (EncodeP src));
 8320   effect(KILL cr);
 8321   ins_cost(INSN_COST * 3);
 8322   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8323   ins_encode %{
 8324     Register s = $src$$Register;
 8325     Register d = $dst$$Register;
 8326     __ encode_heap_oop(d, s);
 8327   %}
 8328   ins_pipe(ialu_reg);
 8329 %}
 8330 
 8331 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8332   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8333   match(Set dst (EncodeP src));
 8334   ins_cost(INSN_COST * 3);
 8335   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8336   ins_encode %{
 8337     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8338   %}
 8339   ins_pipe(ialu_reg);
 8340 %}
 8341 
 8342 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8343   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8344             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8345   match(Set dst (DecodeN src));
 8346   ins_cost(INSN_COST * 3);
 8347   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8348   ins_encode %{
 8349     Register s = $src$$Register;
 8350     Register d = $dst$$Register;
 8351     __ decode_heap_oop(d, s);
 8352   %}
 8353   ins_pipe(ialu_reg);
 8354 %}
 8355 
 8356 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8357   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8358             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8359   match(Set dst (DecodeN src));
 8360   ins_cost(INSN_COST * 3);
 8361   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8362   ins_encode %{
 8363     Register s = $src$$Register;
 8364     Register d = $dst$$Register;
 8365     __ decode_heap_oop_not_null(d, s);
 8366   %}
 8367   ins_pipe(ialu_reg);
 8368 %}
 8369 
 8370 // n.b. AArch64 implementations of encode_klass_not_null and
 8371 // decode_klass_not_null do not modify the flags register so, unlike
 8372 // Intel, we don&#39;t kill CR as a side effect here
 8373 
 8374 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8375   match(Set dst (EncodePKlass src));
 8376 
 8377   ins_cost(INSN_COST * 3);
 8378   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8379 
 8380   ins_encode %{
 8381     Register src_reg = as_Register($src$$reg);
 8382     Register dst_reg = as_Register($dst$$reg);
 8383     __ encode_klass_not_null(dst_reg, src_reg);
 8384   %}
 8385 
 8386    ins_pipe(ialu_reg);
 8387 %}
 8388 
 8389 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8390   match(Set dst (DecodeNKlass src));
 8391 
 8392   ins_cost(INSN_COST * 3);
 8393   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8394 
 8395   ins_encode %{
 8396     Register src_reg = as_Register($src$$reg);
 8397     Register dst_reg = as_Register($dst$$reg);
 8398     if (dst_reg != src_reg) {
 8399       __ decode_klass_not_null(dst_reg, src_reg);
 8400     } else {
 8401       __ decode_klass_not_null(dst_reg);
 8402     }
 8403   %}
 8404 
 8405    ins_pipe(ialu_reg);
 8406 %}
 8407 
 8408 instruct checkCastPP(iRegPNoSp dst)
 8409 %{
 8410   match(Set dst (CheckCastPP dst));
 8411 
 8412   size(0);
 8413   format %{ &quot;# checkcastPP of $dst&quot; %}
 8414   ins_encode(/* empty encoding */);
 8415   ins_pipe(pipe_class_empty);
 8416 %}
 8417 
 8418 instruct castPP(iRegPNoSp dst)
 8419 %{
 8420   match(Set dst (CastPP dst));
 8421 
 8422   size(0);
 8423   format %{ &quot;# castPP of $dst&quot; %}
 8424   ins_encode(/* empty encoding */);
 8425   ins_pipe(pipe_class_empty);
 8426 %}
 8427 
 8428 instruct castII(iRegI dst)
 8429 %{
 8430   match(Set dst (CastII dst));
 8431 
 8432   size(0);
 8433   format %{ &quot;# castII of $dst&quot; %}
 8434   ins_encode(/* empty encoding */);
 8435   ins_cost(0);
 8436   ins_pipe(pipe_class_empty);
 8437 %}
 8438 
 8439 // ============================================================================
 8440 // Atomic operation instructions
 8441 //
 8442 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8443 // Store{PIL}Conditional instructions using a normal load for the
 8444 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8445 //
 8446 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8447 // pair to lock object allocations from Eden space when not using
 8448 // TLABs.
 8449 //
 8450 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8451 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8452 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8453 // only for 64-bit.
 8454 //
 8455 // We implement LoadPLocked and StorePLocked instructions using,
 8456 // respectively the AArch64 hw load-exclusive and store-conditional
 8457 // instructions. Whereas we must implement each of
 8458 // Store{IL}Conditional using a CAS which employs a pair of
 8459 // instructions comprising a load-exclusive followed by a
 8460 // store-conditional.
 8461 
 8462 
 8463 // Locked-load (linked load) of the current heap-top
 8464 // used when updating the eden heap top
 8465 // implemented using ldaxr on AArch64
 8466 
 8467 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8468 %{
 8469   match(Set dst (LoadPLocked mem));
 8470 
 8471   ins_cost(VOLATILE_REF_COST);
 8472 
 8473   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8474 
 8475   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8476 
 8477   ins_pipe(pipe_serial);
 8478 %}
 8479 
 8480 // Conditional-store of the updated heap-top.
 8481 // Used during allocation of the shared heap.
 8482 // Sets flag (EQ) on success.
 8483 // implemented using stlxr on AArch64.
 8484 
 8485 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8486 %{
 8487   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8488 
 8489   ins_cost(VOLATILE_REF_COST);
 8490 
 8491  // TODO
 8492  // do we need to do a store-conditional release or can we just use a
 8493  // plain store-conditional?
 8494 
 8495   format %{
 8496     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8497     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8498   %}
 8499 
 8500   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8501 
 8502   ins_pipe(pipe_serial);
 8503 %}
 8504 
 8505 
 8506 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8507 // when attempting to rebias a lock towards the current thread.  We
 8508 // must use the acquire form of cmpxchg in order to guarantee acquire
 8509 // semantics in this case.
 8510 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8511 %{
 8512   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8513 
 8514   ins_cost(VOLATILE_REF_COST);
 8515 
 8516   format %{
 8517     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8518     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8519   %}
 8520 
 8521   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8522 
 8523   ins_pipe(pipe_slow);
 8524 %}
 8525 
 8526 // storeIConditional also has acquire semantics, for no better reason
 8527 // than matching storeLConditional.  At the time of writing this
 8528 // comment storeIConditional was not used anywhere by AArch64.
 8529 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8530 %{
 8531   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8532 
 8533   ins_cost(VOLATILE_REF_COST);
 8534 
 8535   format %{
 8536     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8537     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8538   %}
 8539 
 8540   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8541 
 8542   ins_pipe(pipe_slow);
 8543 %}
 8544 
 8545 // standard CompareAndSwapX when we are using barriers
 8546 // these have higher priority than the rules selected by a predicate
 8547 
 8548 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8549 // can&#39;t match them
 8550 
 8551 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8552 
 8553   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8554   ins_cost(2 * VOLATILE_REF_COST);
 8555 
 8556   effect(KILL cr);
 8557 
 8558   format %{
 8559     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8560     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8561   %}
 8562 
 8563   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8564             aarch64_enc_cset_eq(res));
 8565 
 8566   ins_pipe(pipe_slow);
 8567 %}
 8568 
 8569 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8570 
 8571   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8572   ins_cost(2 * VOLATILE_REF_COST);
 8573 
 8574   effect(KILL cr);
 8575 
 8576   format %{
 8577     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8578     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8579   %}
 8580 
 8581   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8582             aarch64_enc_cset_eq(res));
 8583 
 8584   ins_pipe(pipe_slow);
 8585 %}
 8586 
 8587 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8588 
 8589   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8590   ins_cost(2 * VOLATILE_REF_COST);
 8591 
 8592   effect(KILL cr);
 8593 
 8594  format %{
 8595     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8596     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8597  %}
 8598 
 8599  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8600             aarch64_enc_cset_eq(res));
 8601 
 8602   ins_pipe(pipe_slow);
 8603 %}
 8604 
 8605 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8606 
 8607   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8608   ins_cost(2 * VOLATILE_REF_COST);
 8609 
 8610   effect(KILL cr);
 8611 
 8612  format %{
 8613     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8614     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8615  %}
 8616 
 8617  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8618             aarch64_enc_cset_eq(res));
 8619 
 8620   ins_pipe(pipe_slow);
 8621 %}
 8622 
 8623 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8624 
 8625   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8626   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8627   ins_cost(2 * VOLATILE_REF_COST);
 8628 
 8629   effect(KILL cr);
 8630 
 8631  format %{
 8632     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8633     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8634  %}
 8635 
 8636  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8637             aarch64_enc_cset_eq(res));
 8638 
 8639   ins_pipe(pipe_slow);
 8640 %}
 8641 
 8642 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8643 
 8644   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8645   ins_cost(2 * VOLATILE_REF_COST);
 8646 
 8647   effect(KILL cr);
 8648 
 8649  format %{
 8650     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8651     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8652  %}
 8653 
 8654  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8655             aarch64_enc_cset_eq(res));
 8656 
 8657   ins_pipe(pipe_slow);
 8658 %}
 8659 
 8660 // alternative CompareAndSwapX when we are eliding barriers
 8661 
 8662 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8663 
 8664   predicate(needs_acquiring_load_exclusive(n));
 8665   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8666   ins_cost(VOLATILE_REF_COST);
 8667 
 8668   effect(KILL cr);
 8669 
 8670   format %{
 8671     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8672     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8673   %}
 8674 
 8675   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8676             aarch64_enc_cset_eq(res));
 8677 
 8678   ins_pipe(pipe_slow);
 8679 %}
 8680 
 8681 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8682 
 8683   predicate(needs_acquiring_load_exclusive(n));
 8684   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8685   ins_cost(VOLATILE_REF_COST);
 8686 
 8687   effect(KILL cr);
 8688 
 8689   format %{
 8690     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8691     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8692   %}
 8693 
 8694   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8695             aarch64_enc_cset_eq(res));
 8696 
 8697   ins_pipe(pipe_slow);
 8698 %}
 8699 
 8700 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8701 
 8702   predicate(needs_acquiring_load_exclusive(n));
 8703   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8704   ins_cost(VOLATILE_REF_COST);
 8705 
 8706   effect(KILL cr);
 8707 
 8708  format %{
 8709     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8710     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8711  %}
 8712 
 8713  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8714             aarch64_enc_cset_eq(res));
 8715 
 8716   ins_pipe(pipe_slow);
 8717 %}
 8718 
 8719 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8720 
 8721   predicate(needs_acquiring_load_exclusive(n));
 8722   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8723   ins_cost(VOLATILE_REF_COST);
 8724 
 8725   effect(KILL cr);
 8726 
 8727  format %{
 8728     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8729     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8730  %}
 8731 
 8732  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8733             aarch64_enc_cset_eq(res));
 8734 
 8735   ins_pipe(pipe_slow);
 8736 %}
 8737 
 8738 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8739 
 8740   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8741   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8742   ins_cost(VOLATILE_REF_COST);
 8743 
 8744   effect(KILL cr);
 8745 
 8746  format %{
 8747     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8748     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8749  %}
 8750 
 8751  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8752             aarch64_enc_cset_eq(res));
 8753 
 8754   ins_pipe(pipe_slow);
 8755 %}
 8756 
 8757 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8758 
 8759   predicate(needs_acquiring_load_exclusive(n));
 8760   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8761   ins_cost(VOLATILE_REF_COST);
 8762 
 8763   effect(KILL cr);
 8764 
 8765  format %{
 8766     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8767     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8768  %}
 8769 
 8770  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8771             aarch64_enc_cset_eq(res));
 8772 
 8773   ins_pipe(pipe_slow);
 8774 %}
 8775 
 8776 
 8777 // ---------------------------------------------------------------------
 8778 
 8779 
 8780 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8781 
 8782 // Sundry CAS operations.  Note that release is always true,
 8783 // regardless of the memory ordering of the CAS.  This is because we
 8784 // need the volatile case to be sequentially consistent but there is
 8785 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8786 // can&#39;t check the type of memory ordering here, so we always emit a
 8787 // STLXR.
 8788 
 8789 // This section is generated from aarch64_ad_cas.m4
 8790 
 8791 
 8792 
 8793 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8794   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8795   ins_cost(2 * VOLATILE_REF_COST);
 8796   effect(TEMP_DEF res, KILL cr);
 8797   format %{
 8798     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8799   %}
 8800   ins_encode %{
 8801     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8802                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8803                /*weak*/ false, $res$$Register);
 8804     __ sxtbw($res$$Register, $res$$Register);
 8805   %}
 8806   ins_pipe(pipe_slow);
 8807 %}
 8808 
 8809 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8810   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8811   ins_cost(2 * VOLATILE_REF_COST);
 8812   effect(TEMP_DEF res, KILL cr);
 8813   format %{
 8814     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8815   %}
 8816   ins_encode %{
 8817     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8818                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8819                /*weak*/ false, $res$$Register);
 8820     __ sxthw($res$$Register, $res$$Register);
 8821   %}
 8822   ins_pipe(pipe_slow);
 8823 %}
 8824 
 8825 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8826   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8827   ins_cost(2 * VOLATILE_REF_COST);
 8828   effect(TEMP_DEF res, KILL cr);
 8829   format %{
 8830     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8831   %}
 8832   ins_encode %{
 8833     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8834                Assembler::word, /*acquire*/ false, /*release*/ true,
 8835                /*weak*/ false, $res$$Register);
 8836   %}
 8837   ins_pipe(pipe_slow);
 8838 %}
 8839 
 8840 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8841   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8842   ins_cost(2 * VOLATILE_REF_COST);
 8843   effect(TEMP_DEF res, KILL cr);
 8844   format %{
 8845     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8846   %}
 8847   ins_encode %{
 8848     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8849                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8850                /*weak*/ false, $res$$Register);
 8851   %}
 8852   ins_pipe(pipe_slow);
 8853 %}
 8854 
 8855 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8856   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8857   ins_cost(2 * VOLATILE_REF_COST);
 8858   effect(TEMP_DEF res, KILL cr);
 8859   format %{
 8860     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8861   %}
 8862   ins_encode %{
 8863     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8864                Assembler::word, /*acquire*/ false, /*release*/ true,
 8865                /*weak*/ false, $res$$Register);
 8866   %}
 8867   ins_pipe(pipe_slow);
 8868 %}
 8869 
 8870 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8871   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8872   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882   %}
 8883   ins_pipe(pipe_slow);
 8884 %}
 8885 
 8886 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8887   predicate(needs_acquiring_load_exclusive(n));
 8888   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8889   ins_cost(VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898     __ sxtbw($res$$Register, $res$$Register);
 8899   %}
 8900   ins_pipe(pipe_slow);
 8901 %}
 8902 
 8903 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8904   predicate(needs_acquiring_load_exclusive(n));
 8905   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8906   ins_cost(VOLATILE_REF_COST);
 8907   effect(TEMP_DEF res, KILL cr);
 8908   format %{
 8909     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8910   %}
 8911   ins_encode %{
 8912     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8913                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8914                /*weak*/ false, $res$$Register);
 8915     __ sxthw($res$$Register, $res$$Register);
 8916   %}
 8917   ins_pipe(pipe_slow);
 8918 %}
 8919 
 8920 
 8921 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8922   predicate(needs_acquiring_load_exclusive(n));
 8923   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8924   ins_cost(VOLATILE_REF_COST);
 8925   effect(TEMP_DEF res, KILL cr);
 8926   format %{
 8927     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8928   %}
 8929   ins_encode %{
 8930     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8931                Assembler::word, /*acquire*/ true, /*release*/ true,
 8932                /*weak*/ false, $res$$Register);
 8933   %}
 8934   ins_pipe(pipe_slow);
 8935 %}
 8936 
 8937 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8938   predicate(needs_acquiring_load_exclusive(n));
 8939   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8940   ins_cost(VOLATILE_REF_COST);
 8941   effect(TEMP_DEF res, KILL cr);
 8942   format %{
 8943     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8944   %}
 8945   ins_encode %{
 8946     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8947                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8948                /*weak*/ false, $res$$Register);
 8949   %}
 8950   ins_pipe(pipe_slow);
 8951 %}
 8952 
 8953 
 8954 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8955   predicate(needs_acquiring_load_exclusive(n));
 8956   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8957   ins_cost(VOLATILE_REF_COST);
 8958   effect(TEMP_DEF res, KILL cr);
 8959   format %{
 8960     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8961   %}
 8962   ins_encode %{
 8963     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8964                Assembler::word, /*acquire*/ true, /*release*/ true,
 8965                /*weak*/ false, $res$$Register);
 8966   %}
 8967   ins_pipe(pipe_slow);
 8968 %}
 8969 
 8970 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8971   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8972   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8973   ins_cost(VOLATILE_REF_COST);
 8974   effect(TEMP_DEF res, KILL cr);
 8975   format %{
 8976     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8977   %}
 8978   ins_encode %{
 8979     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8980                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8981                /*weak*/ false, $res$$Register);
 8982   %}
 8983   ins_pipe(pipe_slow);
 8984 %}
 8985 
 8986 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8987   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 8988   ins_cost(2 * VOLATILE_REF_COST);
 8989   effect(KILL cr);
 8990   format %{
 8991     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8992     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8993   %}
 8994   ins_encode %{
 8995     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8996                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8997                /*weak*/ true, noreg);
 8998     __ csetw($res$$Register, Assembler::EQ);
 8999   %}
 9000   ins_pipe(pipe_slow);
 9001 %}
 9002 
 9003 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9004   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9005   ins_cost(2 * VOLATILE_REF_COST);
 9006   effect(KILL cr);
 9007   format %{
 9008     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9009     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9010   %}
 9011   ins_encode %{
 9012     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9013                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9014                /*weak*/ true, noreg);
 9015     __ csetw($res$$Register, Assembler::EQ);
 9016   %}
 9017   ins_pipe(pipe_slow);
 9018 %}
 9019 
 9020 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9021   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9022   ins_cost(2 * VOLATILE_REF_COST);
 9023   effect(KILL cr);
 9024   format %{
 9025     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9026     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9027   %}
 9028   ins_encode %{
 9029     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9030                Assembler::word, /*acquire*/ false, /*release*/ true,
 9031                /*weak*/ true, noreg);
 9032     __ csetw($res$$Register, Assembler::EQ);
 9033   %}
 9034   ins_pipe(pipe_slow);
 9035 %}
 9036 
 9037 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9038   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9039   ins_cost(2 * VOLATILE_REF_COST);
 9040   effect(KILL cr);
 9041   format %{
 9042     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9043     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9044   %}
 9045   ins_encode %{
 9046     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9047                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9048                /*weak*/ true, noreg);
 9049     __ csetw($res$$Register, Assembler::EQ);
 9050   %}
 9051   ins_pipe(pipe_slow);
 9052 %}
 9053 
 9054 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9055   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9056   ins_cost(2 * VOLATILE_REF_COST);
 9057   effect(KILL cr);
 9058   format %{
 9059     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9060     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9061   %}
 9062   ins_encode %{
 9063     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9064                Assembler::word, /*acquire*/ false, /*release*/ true,
 9065                /*weak*/ true, noreg);
 9066     __ csetw($res$$Register, Assembler::EQ);
 9067   %}
 9068   ins_pipe(pipe_slow);
 9069 %}
 9070 
 9071 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9072   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9073   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9074   ins_cost(2 * VOLATILE_REF_COST);
 9075   effect(KILL cr);
 9076   format %{
 9077     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9078     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9079   %}
 9080   ins_encode %{
 9081     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9082                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9083                /*weak*/ true, noreg);
 9084     __ csetw($res$$Register, Assembler::EQ);
 9085   %}
 9086   ins_pipe(pipe_slow);
 9087 %}
 9088 
 9089 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9090   predicate(needs_acquiring_load_exclusive(n));
 9091   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9092   ins_cost(VOLATILE_REF_COST);
 9093   effect(KILL cr);
 9094   format %{
 9095     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9096     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9097   %}
 9098   ins_encode %{
 9099     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9100                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9101                /*weak*/ true, noreg);
 9102     __ csetw($res$$Register, Assembler::EQ);
 9103   %}
 9104   ins_pipe(pipe_slow);
 9105 %}
 9106 
 9107 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9108   predicate(needs_acquiring_load_exclusive(n));
 9109   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9110   ins_cost(VOLATILE_REF_COST);
 9111   effect(KILL cr);
 9112   format %{
 9113     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9114     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9115   %}
 9116   ins_encode %{
 9117     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9118                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9119                /*weak*/ true, noreg);
 9120     __ csetw($res$$Register, Assembler::EQ);
 9121   %}
 9122   ins_pipe(pipe_slow);
 9123 %}
 9124 
 9125 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9126   predicate(needs_acquiring_load_exclusive(n));
 9127   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9128   ins_cost(VOLATILE_REF_COST);
 9129   effect(KILL cr);
 9130   format %{
 9131     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9132     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9133   %}
 9134   ins_encode %{
 9135     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9136                Assembler::word, /*acquire*/ true, /*release*/ true,
 9137                /*weak*/ true, noreg);
 9138     __ csetw($res$$Register, Assembler::EQ);
 9139   %}
 9140   ins_pipe(pipe_slow);
 9141 %}
 9142 
 9143 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9144   predicate(needs_acquiring_load_exclusive(n));
 9145   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9146   ins_cost(VOLATILE_REF_COST);
 9147   effect(KILL cr);
 9148   format %{
 9149     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9150     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9151   %}
 9152   ins_encode %{
 9153     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9154                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9155                /*weak*/ true, noreg);
 9156     __ csetw($res$$Register, Assembler::EQ);
 9157   %}
 9158   ins_pipe(pipe_slow);
 9159 %}
 9160 
 9161 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9162   predicate(needs_acquiring_load_exclusive(n));
 9163   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9164   ins_cost(VOLATILE_REF_COST);
 9165   effect(KILL cr);
 9166   format %{
 9167     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9168     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9169   %}
 9170   ins_encode %{
 9171     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9172                Assembler::word, /*acquire*/ true, /*release*/ true,
 9173                /*weak*/ true, noreg);
 9174     __ csetw($res$$Register, Assembler::EQ);
 9175   %}
 9176   ins_pipe(pipe_slow);
 9177 %}
 9178 
 9179 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9180   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9181   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9182   ins_cost(VOLATILE_REF_COST);
 9183   effect(KILL cr);
 9184   format %{
 9185     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9186     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9187   %}
 9188   ins_encode %{
 9189     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9190                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9191                /*weak*/ true, noreg);
 9192     __ csetw($res$$Register, Assembler::EQ);
 9193   %}
 9194   ins_pipe(pipe_slow);
 9195 %}
 9196 
 9197 // END This section of the file is automatically generated. Do not edit --------------
 9198 // ---------------------------------------------------------------------
 9199 
 9200 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9201   match(Set prev (GetAndSetI mem newv));
 9202   ins_cost(2 * VOLATILE_REF_COST);
 9203   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9204   ins_encode %{
 9205     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9206   %}
 9207   ins_pipe(pipe_serial);
 9208 %}
 9209 
 9210 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9211   match(Set prev (GetAndSetL mem newv));
 9212   ins_cost(2 * VOLATILE_REF_COST);
 9213   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9214   ins_encode %{
 9215     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9216   %}
 9217   ins_pipe(pipe_serial);
 9218 %}
 9219 
 9220 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9221   match(Set prev (GetAndSetN mem newv));
 9222   ins_cost(2 * VOLATILE_REF_COST);
 9223   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9224   ins_encode %{
 9225     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9226   %}
 9227   ins_pipe(pipe_serial);
 9228 %}
 9229 
 9230 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9231   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9232   match(Set prev (GetAndSetP mem newv));
 9233   ins_cost(2 * VOLATILE_REF_COST);
 9234   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9235   ins_encode %{
 9236     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9237   %}
 9238   ins_pipe(pipe_serial);
 9239 %}
 9240 
 9241 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9242   predicate(needs_acquiring_load_exclusive(n));
 9243   match(Set prev (GetAndSetI mem newv));
 9244   ins_cost(VOLATILE_REF_COST);
 9245   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9246   ins_encode %{
 9247     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9248   %}
 9249   ins_pipe(pipe_serial);
 9250 %}
 9251 
 9252 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9253   predicate(needs_acquiring_load_exclusive(n));
 9254   match(Set prev (GetAndSetL mem newv));
 9255   ins_cost(VOLATILE_REF_COST);
 9256   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9257   ins_encode %{
 9258     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9259   %}
 9260   ins_pipe(pipe_serial);
 9261 %}
 9262 
 9263 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9264   predicate(needs_acquiring_load_exclusive(n));
 9265   match(Set prev (GetAndSetN mem newv));
 9266   ins_cost(VOLATILE_REF_COST);
 9267   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9268   ins_encode %{
 9269     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9270   %}
 9271   ins_pipe(pipe_serial);
 9272 %}
 9273 
 9274 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9275   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9276   match(Set prev (GetAndSetP mem newv));
 9277   ins_cost(VOLATILE_REF_COST);
 9278   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9279   ins_encode %{
 9280     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9281   %}
 9282   ins_pipe(pipe_serial);
 9283 %}
 9284 
 9285 
 9286 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9287   match(Set newval (GetAndAddL mem incr));
 9288   ins_cost(2 * VOLATILE_REF_COST + 1);
 9289   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9290   ins_encode %{
 9291     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9292   %}
 9293   ins_pipe(pipe_serial);
 9294 %}
 9295 
 9296 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9297   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9298   match(Set dummy (GetAndAddL mem incr));
 9299   ins_cost(2 * VOLATILE_REF_COST);
 9300   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9301   ins_encode %{
 9302     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9303   %}
 9304   ins_pipe(pipe_serial);
 9305 %}
 9306 
 9307 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9308   match(Set newval (GetAndAddL mem incr));
 9309   ins_cost(2 * VOLATILE_REF_COST + 1);
 9310   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9311   ins_encode %{
 9312     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9313   %}
 9314   ins_pipe(pipe_serial);
 9315 %}
 9316 
 9317 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9318   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9319   match(Set dummy (GetAndAddL mem incr));
 9320   ins_cost(2 * VOLATILE_REF_COST);
 9321   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9322   ins_encode %{
 9323     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9324   %}
 9325   ins_pipe(pipe_serial);
 9326 %}
 9327 
 9328 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9329   match(Set newval (GetAndAddI mem incr));
 9330   ins_cost(2 * VOLATILE_REF_COST + 1);
 9331   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9332   ins_encode %{
 9333     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9334   %}
 9335   ins_pipe(pipe_serial);
 9336 %}
 9337 
 9338 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9339   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9340   match(Set dummy (GetAndAddI mem incr));
 9341   ins_cost(2 * VOLATILE_REF_COST);
 9342   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9343   ins_encode %{
 9344     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9345   %}
 9346   ins_pipe(pipe_serial);
 9347 %}
 9348 
 9349 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9350   match(Set newval (GetAndAddI mem incr));
 9351   ins_cost(2 * VOLATILE_REF_COST + 1);
 9352   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9353   ins_encode %{
 9354     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9355   %}
 9356   ins_pipe(pipe_serial);
 9357 %}
 9358 
 9359 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9360   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9361   match(Set dummy (GetAndAddI mem incr));
 9362   ins_cost(2 * VOLATILE_REF_COST);
 9363   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9364   ins_encode %{
 9365     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9366   %}
 9367   ins_pipe(pipe_serial);
 9368 %}
 9369 
 9370 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9371   predicate(needs_acquiring_load_exclusive(n));
 9372   match(Set newval (GetAndAddL mem incr));
 9373   ins_cost(VOLATILE_REF_COST + 1);
 9374   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9375   ins_encode %{
 9376     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9377   %}
 9378   ins_pipe(pipe_serial);
 9379 %}
 9380 
 9381 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9382   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9383   match(Set dummy (GetAndAddL mem incr));
 9384   ins_cost(VOLATILE_REF_COST);
 9385   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9386   ins_encode %{
 9387     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9388   %}
 9389   ins_pipe(pipe_serial);
 9390 %}
 9391 
 9392 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9393   predicate(needs_acquiring_load_exclusive(n));
 9394   match(Set newval (GetAndAddL mem incr));
 9395   ins_cost(VOLATILE_REF_COST + 1);
 9396   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9397   ins_encode %{
 9398     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9399   %}
 9400   ins_pipe(pipe_serial);
 9401 %}
 9402 
 9403 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9404   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9405   match(Set dummy (GetAndAddL mem incr));
 9406   ins_cost(VOLATILE_REF_COST);
 9407   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9408   ins_encode %{
 9409     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9410   %}
 9411   ins_pipe(pipe_serial);
 9412 %}
 9413 
 9414 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9415   predicate(needs_acquiring_load_exclusive(n));
 9416   match(Set newval (GetAndAddI mem incr));
 9417   ins_cost(VOLATILE_REF_COST + 1);
 9418   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9419   ins_encode %{
 9420     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9421   %}
 9422   ins_pipe(pipe_serial);
 9423 %}
 9424 
 9425 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9426   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9427   match(Set dummy (GetAndAddI mem incr));
 9428   ins_cost(VOLATILE_REF_COST);
 9429   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9430   ins_encode %{
 9431     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9432   %}
 9433   ins_pipe(pipe_serial);
 9434 %}
 9435 
 9436 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9437   predicate(needs_acquiring_load_exclusive(n));
 9438   match(Set newval (GetAndAddI mem incr));
 9439   ins_cost(VOLATILE_REF_COST + 1);
 9440   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9441   ins_encode %{
 9442     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9443   %}
 9444   ins_pipe(pipe_serial);
 9445 %}
 9446 
 9447 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9448   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9449   match(Set dummy (GetAndAddI mem incr));
 9450   ins_cost(VOLATILE_REF_COST);
 9451   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9452   ins_encode %{
 9453     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9454   %}
 9455   ins_pipe(pipe_serial);
 9456 %}
 9457 
 9458 // Manifest a CmpL result in an integer register.
 9459 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9460 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9461 %{
 9462   match(Set dst (CmpL3 src1 src2));
 9463   effect(KILL flags);
 9464 
 9465   ins_cost(INSN_COST * 6);
 9466   format %{
 9467       &quot;cmp $src1, $src2&quot;
 9468       &quot;csetw $dst, ne&quot;
 9469       &quot;cnegw $dst, lt&quot;
 9470   %}
 9471   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9472   ins_encode %{
 9473     __ cmp($src1$$Register, $src2$$Register);
 9474     __ csetw($dst$$Register, Assembler::NE);
 9475     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9476   %}
 9477 
 9478   ins_pipe(pipe_class_default);
 9479 %}
 9480 
 9481 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9482 %{
 9483   match(Set dst (CmpL3 src1 src2));
 9484   effect(KILL flags);
 9485 
 9486   ins_cost(INSN_COST * 6);
 9487   format %{
 9488       &quot;cmp $src1, $src2&quot;
 9489       &quot;csetw $dst, ne&quot;
 9490       &quot;cnegw $dst, lt&quot;
 9491   %}
 9492   ins_encode %{
 9493     int32_t con = (int32_t)$src2$$constant;
 9494      if (con &lt; 0) {
 9495       __ adds(zr, $src1$$Register, -con);
 9496     } else {
 9497       __ subs(zr, $src1$$Register, con);
 9498     }
 9499     __ csetw($dst$$Register, Assembler::NE);
 9500     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9501   %}
 9502 
 9503   ins_pipe(pipe_class_default);
 9504 %}
 9505 
 9506 // ============================================================================
 9507 // Conditional Move Instructions
 9508 
 9509 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9510 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9511 // define an op class which merged both inputs and use it to type the
 9512 // argument to a single rule. unfortunatelyt his fails because the
 9513 // opclass does not live up to the COND_INTER interface of its
 9514 // component operands. When the generic code tries to negate the
 9515 // operand it ends up running the generci Machoper::negate method
 9516 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9517 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9518 
 9519 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9520   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9521 
 9522   ins_cost(INSN_COST * 2);
 9523   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9524 
 9525   ins_encode %{
 9526     __ cselw(as_Register($dst$$reg),
 9527              as_Register($src2$$reg),
 9528              as_Register($src1$$reg),
 9529              (Assembler::Condition)$cmp$$cmpcode);
 9530   %}
 9531 
 9532   ins_pipe(icond_reg_reg);
 9533 %}
 9534 
 9535 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9536   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9537 
 9538   ins_cost(INSN_COST * 2);
 9539   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9540 
 9541   ins_encode %{
 9542     __ cselw(as_Register($dst$$reg),
 9543              as_Register($src2$$reg),
 9544              as_Register($src1$$reg),
 9545              (Assembler::Condition)$cmp$$cmpcode);
 9546   %}
 9547 
 9548   ins_pipe(icond_reg_reg);
 9549 %}
 9550 
 9551 // special cases where one arg is zero
 9552 
 9553 // n.b. this is selected in preference to the rule above because it
 9554 // avoids loading constant 0 into a source register
 9555 
 9556 // TODO
 9557 // we ought only to be able to cull one of these variants as the ideal
 9558 // transforms ought always to order the zero consistently (to left/right?)
 9559 
 9560 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9561   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9562 
 9563   ins_cost(INSN_COST * 2);
 9564   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9565 
 9566   ins_encode %{
 9567     __ cselw(as_Register($dst$$reg),
 9568              as_Register($src$$reg),
 9569              zr,
 9570              (Assembler::Condition)$cmp$$cmpcode);
 9571   %}
 9572 
 9573   ins_pipe(icond_reg);
 9574 %}
 9575 
 9576 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9577   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9578 
 9579   ins_cost(INSN_COST * 2);
 9580   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9581 
 9582   ins_encode %{
 9583     __ cselw(as_Register($dst$$reg),
 9584              as_Register($src$$reg),
 9585              zr,
 9586              (Assembler::Condition)$cmp$$cmpcode);
 9587   %}
 9588 
 9589   ins_pipe(icond_reg);
 9590 %}
 9591 
 9592 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9593   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9594 
 9595   ins_cost(INSN_COST * 2);
 9596   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9597 
 9598   ins_encode %{
 9599     __ cselw(as_Register($dst$$reg),
 9600              zr,
 9601              as_Register($src$$reg),
 9602              (Assembler::Condition)$cmp$$cmpcode);
 9603   %}
 9604 
 9605   ins_pipe(icond_reg);
 9606 %}
 9607 
 9608 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9609   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9610 
 9611   ins_cost(INSN_COST * 2);
 9612   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9613 
 9614   ins_encode %{
 9615     __ cselw(as_Register($dst$$reg),
 9616              zr,
 9617              as_Register($src$$reg),
 9618              (Assembler::Condition)$cmp$$cmpcode);
 9619   %}
 9620 
 9621   ins_pipe(icond_reg);
 9622 %}
 9623 
 9624 // special case for creating a boolean 0 or 1
 9625 
 9626 // n.b. this is selected in preference to the rule above because it
 9627 // avoids loading constants 0 and 1 into a source register
 9628 
 9629 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9630   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9631 
 9632   ins_cost(INSN_COST * 2);
 9633   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9634 
 9635   ins_encode %{
 9636     // equivalently
 9637     // cset(as_Register($dst$$reg),
 9638     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9639     __ csincw(as_Register($dst$$reg),
 9640              zr,
 9641              zr,
 9642              (Assembler::Condition)$cmp$$cmpcode);
 9643   %}
 9644 
 9645   ins_pipe(icond_none);
 9646 %}
 9647 
 9648 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9649   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9650 
 9651   ins_cost(INSN_COST * 2);
 9652   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9653 
 9654   ins_encode %{
 9655     // equivalently
 9656     // cset(as_Register($dst$$reg),
 9657     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9658     __ csincw(as_Register($dst$$reg),
 9659              zr,
 9660              zr,
 9661              (Assembler::Condition)$cmp$$cmpcode);
 9662   %}
 9663 
 9664   ins_pipe(icond_none);
 9665 %}
 9666 
 9667 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9668   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9669 
 9670   ins_cost(INSN_COST * 2);
 9671   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9672 
 9673   ins_encode %{
 9674     __ csel(as_Register($dst$$reg),
 9675             as_Register($src2$$reg),
 9676             as_Register($src1$$reg),
 9677             (Assembler::Condition)$cmp$$cmpcode);
 9678   %}
 9679 
 9680   ins_pipe(icond_reg_reg);
 9681 %}
 9682 
 9683 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9684   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9685 
 9686   ins_cost(INSN_COST * 2);
 9687   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9688 
 9689   ins_encode %{
 9690     __ csel(as_Register($dst$$reg),
 9691             as_Register($src2$$reg),
 9692             as_Register($src1$$reg),
 9693             (Assembler::Condition)$cmp$$cmpcode);
 9694   %}
 9695 
 9696   ins_pipe(icond_reg_reg);
 9697 %}
 9698 
 9699 // special cases where one arg is zero
 9700 
 9701 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9702   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9703 
 9704   ins_cost(INSN_COST * 2);
 9705   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9706 
 9707   ins_encode %{
 9708     __ csel(as_Register($dst$$reg),
 9709             zr,
 9710             as_Register($src$$reg),
 9711             (Assembler::Condition)$cmp$$cmpcode);
 9712   %}
 9713 
 9714   ins_pipe(icond_reg);
 9715 %}
 9716 
 9717 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9718   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9719 
 9720   ins_cost(INSN_COST * 2);
 9721   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9722 
 9723   ins_encode %{
 9724     __ csel(as_Register($dst$$reg),
 9725             zr,
 9726             as_Register($src$$reg),
 9727             (Assembler::Condition)$cmp$$cmpcode);
 9728   %}
 9729 
 9730   ins_pipe(icond_reg);
 9731 %}
 9732 
 9733 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9734   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9735 
 9736   ins_cost(INSN_COST * 2);
 9737   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9738 
 9739   ins_encode %{
 9740     __ csel(as_Register($dst$$reg),
 9741             as_Register($src$$reg),
 9742             zr,
 9743             (Assembler::Condition)$cmp$$cmpcode);
 9744   %}
 9745 
 9746   ins_pipe(icond_reg);
 9747 %}
 9748 
 9749 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9750   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9751 
 9752   ins_cost(INSN_COST * 2);
 9753   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9754 
 9755   ins_encode %{
 9756     __ csel(as_Register($dst$$reg),
 9757             as_Register($src$$reg),
 9758             zr,
 9759             (Assembler::Condition)$cmp$$cmpcode);
 9760   %}
 9761 
 9762   ins_pipe(icond_reg);
 9763 %}
 9764 
 9765 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9766   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9767 
 9768   ins_cost(INSN_COST * 2);
 9769   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9770 
 9771   ins_encode %{
 9772     __ csel(as_Register($dst$$reg),
 9773             as_Register($src2$$reg),
 9774             as_Register($src1$$reg),
 9775             (Assembler::Condition)$cmp$$cmpcode);
 9776   %}
 9777 
 9778   ins_pipe(icond_reg_reg);
 9779 %}
 9780 
 9781 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9782   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9783 
 9784   ins_cost(INSN_COST * 2);
 9785   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9786 
 9787   ins_encode %{
 9788     __ csel(as_Register($dst$$reg),
 9789             as_Register($src2$$reg),
 9790             as_Register($src1$$reg),
 9791             (Assembler::Condition)$cmp$$cmpcode);
 9792   %}
 9793 
 9794   ins_pipe(icond_reg_reg);
 9795 %}
 9796 
 9797 // special cases where one arg is zero
 9798 
 9799 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9800   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9801 
 9802   ins_cost(INSN_COST * 2);
 9803   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9804 
 9805   ins_encode %{
 9806     __ csel(as_Register($dst$$reg),
 9807             zr,
 9808             as_Register($src$$reg),
 9809             (Assembler::Condition)$cmp$$cmpcode);
 9810   %}
 9811 
 9812   ins_pipe(icond_reg);
 9813 %}
 9814 
 9815 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9816   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9817 
 9818   ins_cost(INSN_COST * 2);
 9819   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9820 
 9821   ins_encode %{
 9822     __ csel(as_Register($dst$$reg),
 9823             zr,
 9824             as_Register($src$$reg),
 9825             (Assembler::Condition)$cmp$$cmpcode);
 9826   %}
 9827 
 9828   ins_pipe(icond_reg);
 9829 %}
 9830 
 9831 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9832   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9833 
 9834   ins_cost(INSN_COST * 2);
 9835   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9836 
 9837   ins_encode %{
 9838     __ csel(as_Register($dst$$reg),
 9839             as_Register($src$$reg),
 9840             zr,
 9841             (Assembler::Condition)$cmp$$cmpcode);
 9842   %}
 9843 
 9844   ins_pipe(icond_reg);
 9845 %}
 9846 
 9847 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9848   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9849 
 9850   ins_cost(INSN_COST * 2);
 9851   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9852 
 9853   ins_encode %{
 9854     __ csel(as_Register($dst$$reg),
 9855             as_Register($src$$reg),
 9856             zr,
 9857             (Assembler::Condition)$cmp$$cmpcode);
 9858   %}
 9859 
 9860   ins_pipe(icond_reg);
 9861 %}
 9862 
 9863 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9864   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9865 
 9866   ins_cost(INSN_COST * 2);
 9867   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9868 
 9869   ins_encode %{
 9870     __ cselw(as_Register($dst$$reg),
 9871              as_Register($src2$$reg),
 9872              as_Register($src1$$reg),
 9873              (Assembler::Condition)$cmp$$cmpcode);
 9874   %}
 9875 
 9876   ins_pipe(icond_reg_reg);
 9877 %}
 9878 
 9879 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9880   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9881 
 9882   ins_cost(INSN_COST * 2);
 9883   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9884 
 9885   ins_encode %{
 9886     __ cselw(as_Register($dst$$reg),
 9887              as_Register($src2$$reg),
 9888              as_Register($src1$$reg),
 9889              (Assembler::Condition)$cmp$$cmpcode);
 9890   %}
 9891 
 9892   ins_pipe(icond_reg_reg);
 9893 %}
 9894 
 9895 // special cases where one arg is zero
 9896 
 9897 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9898   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9899 
 9900   ins_cost(INSN_COST * 2);
 9901   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9902 
 9903   ins_encode %{
 9904     __ cselw(as_Register($dst$$reg),
 9905              zr,
 9906              as_Register($src$$reg),
 9907              (Assembler::Condition)$cmp$$cmpcode);
 9908   %}
 9909 
 9910   ins_pipe(icond_reg);
 9911 %}
 9912 
 9913 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9914   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9915 
 9916   ins_cost(INSN_COST * 2);
 9917   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9918 
 9919   ins_encode %{
 9920     __ cselw(as_Register($dst$$reg),
 9921              zr,
 9922              as_Register($src$$reg),
 9923              (Assembler::Condition)$cmp$$cmpcode);
 9924   %}
 9925 
 9926   ins_pipe(icond_reg);
 9927 %}
 9928 
 9929 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9930   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9931 
 9932   ins_cost(INSN_COST * 2);
 9933   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9934 
 9935   ins_encode %{
 9936     __ cselw(as_Register($dst$$reg),
 9937              as_Register($src$$reg),
 9938              zr,
 9939              (Assembler::Condition)$cmp$$cmpcode);
 9940   %}
 9941 
 9942   ins_pipe(icond_reg);
 9943 %}
 9944 
 9945 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9946   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9947 
 9948   ins_cost(INSN_COST * 2);
 9949   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9950 
 9951   ins_encode %{
 9952     __ cselw(as_Register($dst$$reg),
 9953              as_Register($src$$reg),
 9954              zr,
 9955              (Assembler::Condition)$cmp$$cmpcode);
 9956   %}
 9957 
 9958   ins_pipe(icond_reg);
 9959 %}
 9960 
 9961 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9962 %{
 9963   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9964 
 9965   ins_cost(INSN_COST * 3);
 9966 
 9967   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9968   ins_encode %{
 9969     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9970     __ fcsels(as_FloatRegister($dst$$reg),
 9971               as_FloatRegister($src2$$reg),
 9972               as_FloatRegister($src1$$reg),
 9973               cond);
 9974   %}
 9975 
 9976   ins_pipe(fp_cond_reg_reg_s);
 9977 %}
 9978 
 9979 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9980 %{
 9981   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9982 
 9983   ins_cost(INSN_COST * 3);
 9984 
 9985   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9986   ins_encode %{
 9987     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9988     __ fcsels(as_FloatRegister($dst$$reg),
 9989               as_FloatRegister($src2$$reg),
 9990               as_FloatRegister($src1$$reg),
 9991               cond);
 9992   %}
 9993 
 9994   ins_pipe(fp_cond_reg_reg_s);
 9995 %}
 9996 
 9997 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
 9998 %{
 9999   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10000 
10001   ins_cost(INSN_COST * 3);
10002 
10003   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10004   ins_encode %{
10005     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10006     __ fcseld(as_FloatRegister($dst$$reg),
10007               as_FloatRegister($src2$$reg),
10008               as_FloatRegister($src1$$reg),
10009               cond);
10010   %}
10011 
10012   ins_pipe(fp_cond_reg_reg_d);
10013 %}
10014 
10015 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10016 %{
10017   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10018 
10019   ins_cost(INSN_COST * 3);
10020 
10021   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10022   ins_encode %{
10023     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10024     __ fcseld(as_FloatRegister($dst$$reg),
10025               as_FloatRegister($src2$$reg),
10026               as_FloatRegister($src1$$reg),
10027               cond);
10028   %}
10029 
10030   ins_pipe(fp_cond_reg_reg_d);
10031 %}
10032 
10033 // ============================================================================
10034 // Arithmetic Instructions
10035 //
10036 
10037 // Integer Addition
10038 
10039 // TODO
10040 // these currently employ operations which do not set CR and hence are
10041 // not flagged as killing CR but we would like to isolate the cases
10042 // where we want to set flags from those where we don&#39;t. need to work
10043 // out how to do that.
10044 
10045 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10046   match(Set dst (AddI src1 src2));
10047 
10048   ins_cost(INSN_COST);
10049   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10050 
10051   ins_encode %{
10052     __ addw(as_Register($dst$$reg),
10053             as_Register($src1$$reg),
10054             as_Register($src2$$reg));
10055   %}
10056 
10057   ins_pipe(ialu_reg_reg);
10058 %}
10059 
10060 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10061   match(Set dst (AddI src1 src2));
10062 
10063   ins_cost(INSN_COST);
10064   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10065 
10066   // use opcode to indicate that this is an add not a sub
10067   opcode(0x0);
10068 
10069   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10070 
10071   ins_pipe(ialu_reg_imm);
10072 %}
10073 
10074 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10075   match(Set dst (AddI (ConvL2I src1) src2));
10076 
10077   ins_cost(INSN_COST);
10078   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10079 
10080   // use opcode to indicate that this is an add not a sub
10081   opcode(0x0);
10082 
10083   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10084 
10085   ins_pipe(ialu_reg_imm);
10086 %}
10087 
10088 // Pointer Addition
10089 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10090   match(Set dst (AddP src1 src2));
10091 
10092   ins_cost(INSN_COST);
10093   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10094 
10095   ins_encode %{
10096     __ add(as_Register($dst$$reg),
10097            as_Register($src1$$reg),
10098            as_Register($src2$$reg));
10099   %}
10100 
10101   ins_pipe(ialu_reg_reg);
10102 %}
10103 
10104 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10105   match(Set dst (AddP src1 (ConvI2L src2)));
10106 
10107   ins_cost(1.9 * INSN_COST);
10108   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10109 
10110   ins_encode %{
10111     __ add(as_Register($dst$$reg),
10112            as_Register($src1$$reg),
10113            as_Register($src2$$reg), ext::sxtw);
10114   %}
10115 
10116   ins_pipe(ialu_reg_reg);
10117 %}
10118 
10119 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10120   match(Set dst (AddP src1 (LShiftL src2 scale)));
10121 
10122   ins_cost(1.9 * INSN_COST);
10123   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10124 
10125   ins_encode %{
10126     __ lea(as_Register($dst$$reg),
10127            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10128                    Address::lsl($scale$$constant)));
10129   %}
10130 
10131   ins_pipe(ialu_reg_reg_shift);
10132 %}
10133 
10134 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10135   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10136 
10137   ins_cost(1.9 * INSN_COST);
10138   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10139 
10140   ins_encode %{
10141     __ lea(as_Register($dst$$reg),
10142            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10143                    Address::sxtw($scale$$constant)));
10144   %}
10145 
10146   ins_pipe(ialu_reg_reg_shift);
10147 %}
10148 
10149 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10150   match(Set dst (LShiftL (ConvI2L src) scale));
10151 
10152   ins_cost(INSN_COST);
10153   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10154 
10155   ins_encode %{
10156     __ sbfiz(as_Register($dst$$reg),
10157           as_Register($src$$reg),
10158           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10159   %}
10160 
10161   ins_pipe(ialu_reg_shift);
10162 %}
10163 
10164 // Pointer Immediate Addition
10165 // n.b. this needs to be more expensive than using an indirect memory
10166 // operand
10167 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10168   match(Set dst (AddP src1 src2));
10169 
10170   ins_cost(INSN_COST);
10171   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10172 
10173   // use opcode to indicate that this is an add not a sub
10174   opcode(0x0);
10175 
10176   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10177 
10178   ins_pipe(ialu_reg_imm);
10179 %}
10180 
10181 // Long Addition
10182 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10183 
10184   match(Set dst (AddL src1 src2));
10185 
10186   ins_cost(INSN_COST);
10187   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10188 
10189   ins_encode %{
10190     __ add(as_Register($dst$$reg),
10191            as_Register($src1$$reg),
10192            as_Register($src2$$reg));
10193   %}
10194 
10195   ins_pipe(ialu_reg_reg);
10196 %}
10197 
10198 // No constant pool entries requiredLong Immediate Addition.
10199 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10200   match(Set dst (AddL src1 src2));
10201 
10202   ins_cost(INSN_COST);
10203   format %{ &quot;add $dst, $src1, $src2&quot; %}
10204 
10205   // use opcode to indicate that this is an add not a sub
10206   opcode(0x0);
10207 
10208   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10209 
10210   ins_pipe(ialu_reg_imm);
10211 %}
10212 
10213 // Integer Subtraction
10214 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10215   match(Set dst (SubI src1 src2));
10216 
10217   ins_cost(INSN_COST);
10218   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10219 
10220   ins_encode %{
10221     __ subw(as_Register($dst$$reg),
10222             as_Register($src1$$reg),
10223             as_Register($src2$$reg));
10224   %}
10225 
10226   ins_pipe(ialu_reg_reg);
10227 %}
10228 
10229 // Immediate Subtraction
10230 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10231   match(Set dst (SubI src1 src2));
10232 
10233   ins_cost(INSN_COST);
10234   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10235 
10236   // use opcode to indicate that this is a sub not an add
10237   opcode(0x1);
10238 
10239   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10240 
10241   ins_pipe(ialu_reg_imm);
10242 %}
10243 
10244 // Long Subtraction
10245 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10246 
10247   match(Set dst (SubL src1 src2));
10248 
10249   ins_cost(INSN_COST);
10250   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10251 
10252   ins_encode %{
10253     __ sub(as_Register($dst$$reg),
10254            as_Register($src1$$reg),
10255            as_Register($src2$$reg));
10256   %}
10257 
10258   ins_pipe(ialu_reg_reg);
10259 %}
10260 
10261 // No constant pool entries requiredLong Immediate Subtraction.
10262 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10263   match(Set dst (SubL src1 src2));
10264 
10265   ins_cost(INSN_COST);
10266   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10267 
10268   // use opcode to indicate that this is a sub not an add
10269   opcode(0x1);
10270 
10271   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10272 
10273   ins_pipe(ialu_reg_imm);
10274 %}
10275 
10276 // Integer Negation (special case for sub)
10277 
10278 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10279   match(Set dst (SubI zero src));
10280 
10281   ins_cost(INSN_COST);
10282   format %{ &quot;negw $dst, $src\t# int&quot; %}
10283 
10284   ins_encode %{
10285     __ negw(as_Register($dst$$reg),
10286             as_Register($src$$reg));
10287   %}
10288 
10289   ins_pipe(ialu_reg);
10290 %}
10291 
10292 // Long Negation
10293 
10294 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10295   match(Set dst (SubL zero src));
10296 
10297   ins_cost(INSN_COST);
10298   format %{ &quot;neg $dst, $src\t# long&quot; %}
10299 
10300   ins_encode %{
10301     __ neg(as_Register($dst$$reg),
10302            as_Register($src$$reg));
10303   %}
10304 
10305   ins_pipe(ialu_reg);
10306 %}
10307 
10308 // Integer Multiply
10309 
10310 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10311   match(Set dst (MulI src1 src2));
10312 
10313   ins_cost(INSN_COST * 3);
10314   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10315 
10316   ins_encode %{
10317     __ mulw(as_Register($dst$$reg),
10318             as_Register($src1$$reg),
10319             as_Register($src2$$reg));
10320   %}
10321 
10322   ins_pipe(imul_reg_reg);
10323 %}
10324 
10325 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10326   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10327 
10328   ins_cost(INSN_COST * 3);
10329   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10330 
10331   ins_encode %{
10332     __ smull(as_Register($dst$$reg),
10333              as_Register($src1$$reg),
10334              as_Register($src2$$reg));
10335   %}
10336 
10337   ins_pipe(imul_reg_reg);
10338 %}
10339 
10340 // Long Multiply
10341 
10342 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10343   match(Set dst (MulL src1 src2));
10344 
10345   ins_cost(INSN_COST * 5);
10346   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10347 
10348   ins_encode %{
10349     __ mul(as_Register($dst$$reg),
10350            as_Register($src1$$reg),
10351            as_Register($src2$$reg));
10352   %}
10353 
10354   ins_pipe(lmul_reg_reg);
10355 %}
10356 
10357 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10358 %{
10359   match(Set dst (MulHiL src1 src2));
10360 
10361   ins_cost(INSN_COST * 7);
10362   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10363 
10364   ins_encode %{
10365     __ smulh(as_Register($dst$$reg),
10366              as_Register($src1$$reg),
10367              as_Register($src2$$reg));
10368   %}
10369 
10370   ins_pipe(lmul_reg_reg);
10371 %}
10372 
10373 // Combined Integer Multiply &amp; Add/Sub
10374 
10375 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10376   match(Set dst (AddI src3 (MulI src1 src2)));
10377 
10378   ins_cost(INSN_COST * 3);
10379   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10380 
10381   ins_encode %{
10382     __ maddw(as_Register($dst$$reg),
10383              as_Register($src1$$reg),
10384              as_Register($src2$$reg),
10385              as_Register($src3$$reg));
10386   %}
10387 
10388   ins_pipe(imac_reg_reg);
10389 %}
10390 
10391 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10392   match(Set dst (SubI src3 (MulI src1 src2)));
10393 
10394   ins_cost(INSN_COST * 3);
10395   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10396 
10397   ins_encode %{
10398     __ msubw(as_Register($dst$$reg),
10399              as_Register($src1$$reg),
10400              as_Register($src2$$reg),
10401              as_Register($src3$$reg));
10402   %}
10403 
10404   ins_pipe(imac_reg_reg);
10405 %}
10406 
10407 // Combined Integer Multiply &amp; Neg
10408 
10409 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10410   match(Set dst (MulI (SubI zero src1) src2));
10411   match(Set dst (MulI src1 (SubI zero src2)));
10412 
10413   ins_cost(INSN_COST * 3);
10414   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10415 
10416   ins_encode %{
10417     __ mnegw(as_Register($dst$$reg),
10418              as_Register($src1$$reg),
10419              as_Register($src2$$reg));
10420   %}
10421 
10422   ins_pipe(imac_reg_reg);
10423 %}
10424 
10425 // Combined Long Multiply &amp; Add/Sub
10426 
10427 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10428   match(Set dst (AddL src3 (MulL src1 src2)));
10429 
10430   ins_cost(INSN_COST * 5);
10431   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10432 
10433   ins_encode %{
10434     __ madd(as_Register($dst$$reg),
10435             as_Register($src1$$reg),
10436             as_Register($src2$$reg),
10437             as_Register($src3$$reg));
10438   %}
10439 
10440   ins_pipe(lmac_reg_reg);
10441 %}
10442 
10443 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10444   match(Set dst (SubL src3 (MulL src1 src2)));
10445 
10446   ins_cost(INSN_COST * 5);
10447   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10448 
10449   ins_encode %{
10450     __ msub(as_Register($dst$$reg),
10451             as_Register($src1$$reg),
10452             as_Register($src2$$reg),
10453             as_Register($src3$$reg));
10454   %}
10455 
10456   ins_pipe(lmac_reg_reg);
10457 %}
10458 
10459 // Combined Long Multiply &amp; Neg
10460 
10461 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10462   match(Set dst (MulL (SubL zero src1) src2));
10463   match(Set dst (MulL src1 (SubL zero src2)));
10464 
10465   ins_cost(INSN_COST * 5);
10466   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10467 
10468   ins_encode %{
10469     __ mneg(as_Register($dst$$reg),
10470             as_Register($src1$$reg),
10471             as_Register($src2$$reg));
10472   %}
10473 
10474   ins_pipe(lmac_reg_reg);
10475 %}
10476 
10477 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10478 
10479 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10480   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10481 
10482   ins_cost(INSN_COST * 3);
10483   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10484 
10485   ins_encode %{
10486     __ smaddl(as_Register($dst$$reg),
10487               as_Register($src1$$reg),
10488               as_Register($src2$$reg),
10489               as_Register($src3$$reg));
10490   %}
10491 
10492   ins_pipe(imac_reg_reg);
10493 %}
10494 
10495 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10496   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10497 
10498   ins_cost(INSN_COST * 3);
10499   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10500 
10501   ins_encode %{
10502     __ smsubl(as_Register($dst$$reg),
10503               as_Register($src1$$reg),
10504               as_Register($src2$$reg),
10505               as_Register($src3$$reg));
10506   %}
10507 
10508   ins_pipe(imac_reg_reg);
10509 %}
10510 
10511 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10512   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10513   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10514 
10515   ins_cost(INSN_COST * 3);
10516   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10517 
10518   ins_encode %{
10519     __ smnegl(as_Register($dst$$reg),
10520               as_Register($src1$$reg),
10521               as_Register($src2$$reg));
10522   %}
10523 
10524   ins_pipe(imac_reg_reg);
10525 %}
10526 
10527 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10528 
10529 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10530   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10531 
10532   ins_cost(INSN_COST * 5);
10533   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10534             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10535 
10536   ins_encode %{
10537     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10538     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10539 
10540   ins_pipe(imac_reg_reg);
10541 %}
10542 
10543 // Integer Divide
10544 
10545 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10546   match(Set dst (DivI src1 src2));
10547 
10548   ins_cost(INSN_COST * 19);
10549   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10550 
10551   ins_encode(aarch64_enc_divw(dst, src1, src2));
10552   ins_pipe(idiv_reg_reg);
10553 %}
10554 
10555 // Long Divide
10556 
10557 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10558   match(Set dst (DivL src1 src2));
10559 
10560   ins_cost(INSN_COST * 35);
10561   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10562 
10563   ins_encode(aarch64_enc_div(dst, src1, src2));
10564   ins_pipe(ldiv_reg_reg);
10565 %}
10566 
10567 // Integer Remainder
10568 
10569 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10570   match(Set dst (ModI src1 src2));
10571 
10572   ins_cost(INSN_COST * 22);
10573   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10574             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10575 
10576   ins_encode(aarch64_enc_modw(dst, src1, src2));
10577   ins_pipe(idiv_reg_reg);
10578 %}
10579 
10580 // Long Remainder
10581 
10582 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10583   match(Set dst (ModL src1 src2));
10584 
10585   ins_cost(INSN_COST * 38);
10586   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10587             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10588 
10589   ins_encode(aarch64_enc_mod(dst, src1, src2));
10590   ins_pipe(ldiv_reg_reg);
10591 %}
10592 
10593 // Integer Shifts
10594 
10595 // Shift Left Register
10596 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10597   match(Set dst (LShiftI src1 src2));
10598 
10599   ins_cost(INSN_COST * 2);
10600   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10601 
10602   ins_encode %{
10603     __ lslvw(as_Register($dst$$reg),
10604              as_Register($src1$$reg),
10605              as_Register($src2$$reg));
10606   %}
10607 
10608   ins_pipe(ialu_reg_reg_vshift);
10609 %}
10610 
10611 // Shift Left Immediate
10612 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10613   match(Set dst (LShiftI src1 src2));
10614 
10615   ins_cost(INSN_COST);
10616   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10617 
10618   ins_encode %{
10619     __ lslw(as_Register($dst$$reg),
10620             as_Register($src1$$reg),
10621             $src2$$constant &amp; 0x1f);
10622   %}
10623 
10624   ins_pipe(ialu_reg_shift);
10625 %}
10626 
10627 // Shift Right Logical Register
10628 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10629   match(Set dst (URShiftI src1 src2));
10630 
10631   ins_cost(INSN_COST * 2);
10632   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10633 
10634   ins_encode %{
10635     __ lsrvw(as_Register($dst$$reg),
10636              as_Register($src1$$reg),
10637              as_Register($src2$$reg));
10638   %}
10639 
10640   ins_pipe(ialu_reg_reg_vshift);
10641 %}
10642 
10643 // Shift Right Logical Immediate
10644 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10645   match(Set dst (URShiftI src1 src2));
10646 
10647   ins_cost(INSN_COST);
10648   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10649 
10650   ins_encode %{
10651     __ lsrw(as_Register($dst$$reg),
10652             as_Register($src1$$reg),
10653             $src2$$constant &amp; 0x1f);
10654   %}
10655 
10656   ins_pipe(ialu_reg_shift);
10657 %}
10658 
10659 // Shift Right Arithmetic Register
10660 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10661   match(Set dst (RShiftI src1 src2));
10662 
10663   ins_cost(INSN_COST * 2);
10664   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10665 
10666   ins_encode %{
10667     __ asrvw(as_Register($dst$$reg),
10668              as_Register($src1$$reg),
10669              as_Register($src2$$reg));
10670   %}
10671 
10672   ins_pipe(ialu_reg_reg_vshift);
10673 %}
10674 
10675 // Shift Right Arithmetic Immediate
10676 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10677   match(Set dst (RShiftI src1 src2));
10678 
10679   ins_cost(INSN_COST);
10680   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10681 
10682   ins_encode %{
10683     __ asrw(as_Register($dst$$reg),
10684             as_Register($src1$$reg),
10685             $src2$$constant &amp; 0x1f);
10686   %}
10687 
10688   ins_pipe(ialu_reg_shift);
10689 %}
10690 
10691 // Combined Int Mask and Right Shift (using UBFM)
10692 // TODO
10693 
10694 // Long Shifts
10695 
10696 // Shift Left Register
10697 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10698   match(Set dst (LShiftL src1 src2));
10699 
10700   ins_cost(INSN_COST * 2);
10701   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10702 
10703   ins_encode %{
10704     __ lslv(as_Register($dst$$reg),
10705             as_Register($src1$$reg),
10706             as_Register($src2$$reg));
10707   %}
10708 
10709   ins_pipe(ialu_reg_reg_vshift);
10710 %}
10711 
10712 // Shift Left Immediate
10713 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10714   match(Set dst (LShiftL src1 src2));
10715 
10716   ins_cost(INSN_COST);
10717   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10718 
10719   ins_encode %{
10720     __ lsl(as_Register($dst$$reg),
10721             as_Register($src1$$reg),
10722             $src2$$constant &amp; 0x3f);
10723   %}
10724 
10725   ins_pipe(ialu_reg_shift);
10726 %}
10727 
10728 // Shift Right Logical Register
10729 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10730   match(Set dst (URShiftL src1 src2));
10731 
10732   ins_cost(INSN_COST * 2);
10733   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10734 
10735   ins_encode %{
10736     __ lsrv(as_Register($dst$$reg),
10737             as_Register($src1$$reg),
10738             as_Register($src2$$reg));
10739   %}
10740 
10741   ins_pipe(ialu_reg_reg_vshift);
10742 %}
10743 
10744 // Shift Right Logical Immediate
10745 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10746   match(Set dst (URShiftL src1 src2));
10747 
10748   ins_cost(INSN_COST);
10749   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10750 
10751   ins_encode %{
10752     __ lsr(as_Register($dst$$reg),
10753            as_Register($src1$$reg),
10754            $src2$$constant &amp; 0x3f);
10755   %}
10756 
10757   ins_pipe(ialu_reg_shift);
10758 %}
10759 
10760 // A special-case pattern for card table stores.
10761 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10762   match(Set dst (URShiftL (CastP2X src1) src2));
10763 
10764   ins_cost(INSN_COST);
10765   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10766 
10767   ins_encode %{
10768     __ lsr(as_Register($dst$$reg),
10769            as_Register($src1$$reg),
10770            $src2$$constant &amp; 0x3f);
10771   %}
10772 
10773   ins_pipe(ialu_reg_shift);
10774 %}
10775 
10776 // Shift Right Arithmetic Register
10777 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10778   match(Set dst (RShiftL src1 src2));
10779 
10780   ins_cost(INSN_COST * 2);
10781   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10782 
10783   ins_encode %{
10784     __ asrv(as_Register($dst$$reg),
10785             as_Register($src1$$reg),
10786             as_Register($src2$$reg));
10787   %}
10788 
10789   ins_pipe(ialu_reg_reg_vshift);
10790 %}
10791 
10792 // Shift Right Arithmetic Immediate
10793 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10794   match(Set dst (RShiftL src1 src2));
10795 
10796   ins_cost(INSN_COST);
10797   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10798 
10799   ins_encode %{
10800     __ asr(as_Register($dst$$reg),
10801            as_Register($src1$$reg),
10802            $src2$$constant &amp; 0x3f);
10803   %}
10804 
10805   ins_pipe(ialu_reg_shift);
10806 %}
10807 
10808 // BEGIN This section of the file is automatically generated. Do not edit --------------
10809 
10810 instruct regL_not_reg(iRegLNoSp dst,
10811                          iRegL src1, immL_M1 m1,
10812                          rFlagsReg cr) %{
10813   match(Set dst (XorL src1 m1));
10814   ins_cost(INSN_COST);
10815   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10816 
10817   ins_encode %{
10818     __ eon(as_Register($dst$$reg),
10819               as_Register($src1$$reg),
10820               zr,
10821               Assembler::LSL, 0);
10822   %}
10823 
10824   ins_pipe(ialu_reg);
10825 %}
10826 instruct regI_not_reg(iRegINoSp dst,
10827                          iRegIorL2I src1, immI_M1 m1,
10828                          rFlagsReg cr) %{
10829   match(Set dst (XorI src1 m1));
10830   ins_cost(INSN_COST);
10831   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10832 
10833   ins_encode %{
10834     __ eonw(as_Register($dst$$reg),
10835               as_Register($src1$$reg),
10836               zr,
10837               Assembler::LSL, 0);
10838   %}
10839 
10840   ins_pipe(ialu_reg);
10841 %}
10842 
10843 instruct AndI_reg_not_reg(iRegINoSp dst,
10844                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10845                          rFlagsReg cr) %{
10846   match(Set dst (AndI src1 (XorI src2 m1)));
10847   ins_cost(INSN_COST);
10848   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10849 
10850   ins_encode %{
10851     __ bicw(as_Register($dst$$reg),
10852               as_Register($src1$$reg),
10853               as_Register($src2$$reg),
10854               Assembler::LSL, 0);
10855   %}
10856 
10857   ins_pipe(ialu_reg_reg);
10858 %}
10859 
10860 instruct AndL_reg_not_reg(iRegLNoSp dst,
10861                          iRegL src1, iRegL src2, immL_M1 m1,
10862                          rFlagsReg cr) %{
10863   match(Set dst (AndL src1 (XorL src2 m1)));
10864   ins_cost(INSN_COST);
10865   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10866 
10867   ins_encode %{
10868     __ bic(as_Register($dst$$reg),
10869               as_Register($src1$$reg),
10870               as_Register($src2$$reg),
10871               Assembler::LSL, 0);
10872   %}
10873 
10874   ins_pipe(ialu_reg_reg);
10875 %}
10876 
10877 instruct OrI_reg_not_reg(iRegINoSp dst,
10878                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10879                          rFlagsReg cr) %{
10880   match(Set dst (OrI src1 (XorI src2 m1)));
10881   ins_cost(INSN_COST);
10882   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10883 
10884   ins_encode %{
10885     __ ornw(as_Register($dst$$reg),
10886               as_Register($src1$$reg),
10887               as_Register($src2$$reg),
10888               Assembler::LSL, 0);
10889   %}
10890 
10891   ins_pipe(ialu_reg_reg);
10892 %}
10893 
10894 instruct OrL_reg_not_reg(iRegLNoSp dst,
10895                          iRegL src1, iRegL src2, immL_M1 m1,
10896                          rFlagsReg cr) %{
10897   match(Set dst (OrL src1 (XorL src2 m1)));
10898   ins_cost(INSN_COST);
10899   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10900 
10901   ins_encode %{
10902     __ orn(as_Register($dst$$reg),
10903               as_Register($src1$$reg),
10904               as_Register($src2$$reg),
10905               Assembler::LSL, 0);
10906   %}
10907 
10908   ins_pipe(ialu_reg_reg);
10909 %}
10910 
10911 instruct XorI_reg_not_reg(iRegINoSp dst,
10912                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10913                          rFlagsReg cr) %{
10914   match(Set dst (XorI m1 (XorI src2 src1)));
10915   ins_cost(INSN_COST);
10916   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10917 
10918   ins_encode %{
10919     __ eonw(as_Register($dst$$reg),
10920               as_Register($src1$$reg),
10921               as_Register($src2$$reg),
10922               Assembler::LSL, 0);
10923   %}
10924 
10925   ins_pipe(ialu_reg_reg);
10926 %}
10927 
10928 instruct XorL_reg_not_reg(iRegLNoSp dst,
10929                          iRegL src1, iRegL src2, immL_M1 m1,
10930                          rFlagsReg cr) %{
10931   match(Set dst (XorL m1 (XorL src2 src1)));
10932   ins_cost(INSN_COST);
10933   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10934 
10935   ins_encode %{
10936     __ eon(as_Register($dst$$reg),
10937               as_Register($src1$$reg),
10938               as_Register($src2$$reg),
10939               Assembler::LSL, 0);
10940   %}
10941 
10942   ins_pipe(ialu_reg_reg);
10943 %}
10944 
10945 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10946                          iRegIorL2I src1, iRegIorL2I src2,
10947                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10948   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
10949   ins_cost(1.9 * INSN_COST);
10950   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
10951 
10952   ins_encode %{
10953     __ bicw(as_Register($dst$$reg),
10954               as_Register($src1$$reg),
10955               as_Register($src2$$reg),
10956               Assembler::LSR,
10957               $src3$$constant &amp; 0x1f);
10958   %}
10959 
10960   ins_pipe(ialu_reg_reg_shift);
10961 %}
10962 
10963 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
10964                          iRegL src1, iRegL src2,
10965                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10966   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
10967   ins_cost(1.9 * INSN_COST);
10968   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
10969 
10970   ins_encode %{
10971     __ bic(as_Register($dst$$reg),
10972               as_Register($src1$$reg),
10973               as_Register($src2$$reg),
10974               Assembler::LSR,
10975               $src3$$constant &amp; 0x3f);
10976   %}
10977 
10978   ins_pipe(ialu_reg_reg_shift);
10979 %}
10980 
10981 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
10982                          iRegIorL2I src1, iRegIorL2I src2,
10983                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10984   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
10985   ins_cost(1.9 * INSN_COST);
10986   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
10987 
10988   ins_encode %{
10989     __ bicw(as_Register($dst$$reg),
10990               as_Register($src1$$reg),
10991               as_Register($src2$$reg),
10992               Assembler::ASR,
10993               $src3$$constant &amp; 0x1f);
10994   %}
10995 
10996   ins_pipe(ialu_reg_reg_shift);
10997 %}
10998 
10999 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11000                          iRegL src1, iRegL src2,
11001                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11002   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11003   ins_cost(1.9 * INSN_COST);
11004   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11005 
11006   ins_encode %{
11007     __ bic(as_Register($dst$$reg),
11008               as_Register($src1$$reg),
11009               as_Register($src2$$reg),
11010               Assembler::ASR,
11011               $src3$$constant &amp; 0x3f);
11012   %}
11013 
11014   ins_pipe(ialu_reg_reg_shift);
11015 %}
11016 
11017 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11018                          iRegIorL2I src1, iRegIorL2I src2,
11019                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11020   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11021   ins_cost(1.9 * INSN_COST);
11022   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11023 
11024   ins_encode %{
11025     __ bicw(as_Register($dst$$reg),
11026               as_Register($src1$$reg),
11027               as_Register($src2$$reg),
11028               Assembler::LSL,
11029               $src3$$constant &amp; 0x1f);
11030   %}
11031 
11032   ins_pipe(ialu_reg_reg_shift);
11033 %}
11034 
11035 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11036                          iRegL src1, iRegL src2,
11037                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11038   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11039   ins_cost(1.9 * INSN_COST);
11040   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11041 
11042   ins_encode %{
11043     __ bic(as_Register($dst$$reg),
11044               as_Register($src1$$reg),
11045               as_Register($src2$$reg),
11046               Assembler::LSL,
11047               $src3$$constant &amp; 0x3f);
11048   %}
11049 
11050   ins_pipe(ialu_reg_reg_shift);
11051 %}
11052 
11053 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11054                          iRegIorL2I src1, iRegIorL2I src2,
11055                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11056   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11057   ins_cost(1.9 * INSN_COST);
11058   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11059 
11060   ins_encode %{
11061     __ eonw(as_Register($dst$$reg),
11062               as_Register($src1$$reg),
11063               as_Register($src2$$reg),
11064               Assembler::LSR,
11065               $src3$$constant &amp; 0x1f);
11066   %}
11067 
11068   ins_pipe(ialu_reg_reg_shift);
11069 %}
11070 
11071 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11072                          iRegL src1, iRegL src2,
11073                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11074   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11075   ins_cost(1.9 * INSN_COST);
11076   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11077 
11078   ins_encode %{
11079     __ eon(as_Register($dst$$reg),
11080               as_Register($src1$$reg),
11081               as_Register($src2$$reg),
11082               Assembler::LSR,
11083               $src3$$constant &amp; 0x3f);
11084   %}
11085 
11086   ins_pipe(ialu_reg_reg_shift);
11087 %}
11088 
11089 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11090                          iRegIorL2I src1, iRegIorL2I src2,
11091                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11092   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11093   ins_cost(1.9 * INSN_COST);
11094   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11095 
11096   ins_encode %{
11097     __ eonw(as_Register($dst$$reg),
11098               as_Register($src1$$reg),
11099               as_Register($src2$$reg),
11100               Assembler::ASR,
11101               $src3$$constant &amp; 0x1f);
11102   %}
11103 
11104   ins_pipe(ialu_reg_reg_shift);
11105 %}
11106 
11107 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11108                          iRegL src1, iRegL src2,
11109                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11110   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11111   ins_cost(1.9 * INSN_COST);
11112   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11113 
11114   ins_encode %{
11115     __ eon(as_Register($dst$$reg),
11116               as_Register($src1$$reg),
11117               as_Register($src2$$reg),
11118               Assembler::ASR,
11119               $src3$$constant &amp; 0x3f);
11120   %}
11121 
11122   ins_pipe(ialu_reg_reg_shift);
11123 %}
11124 
11125 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11126                          iRegIorL2I src1, iRegIorL2I src2,
11127                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11128   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11129   ins_cost(1.9 * INSN_COST);
11130   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11131 
11132   ins_encode %{
11133     __ eonw(as_Register($dst$$reg),
11134               as_Register($src1$$reg),
11135               as_Register($src2$$reg),
11136               Assembler::LSL,
11137               $src3$$constant &amp; 0x1f);
11138   %}
11139 
11140   ins_pipe(ialu_reg_reg_shift);
11141 %}
11142 
11143 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11144                          iRegL src1, iRegL src2,
11145                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11146   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11147   ins_cost(1.9 * INSN_COST);
11148   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11149 
11150   ins_encode %{
11151     __ eon(as_Register($dst$$reg),
11152               as_Register($src1$$reg),
11153               as_Register($src2$$reg),
11154               Assembler::LSL,
11155               $src3$$constant &amp; 0x3f);
11156   %}
11157 
11158   ins_pipe(ialu_reg_reg_shift);
11159 %}
11160 
11161 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11162                          iRegIorL2I src1, iRegIorL2I src2,
11163                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11164   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11165   ins_cost(1.9 * INSN_COST);
11166   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11167 
11168   ins_encode %{
11169     __ ornw(as_Register($dst$$reg),
11170               as_Register($src1$$reg),
11171               as_Register($src2$$reg),
11172               Assembler::LSR,
11173               $src3$$constant &amp; 0x1f);
11174   %}
11175 
11176   ins_pipe(ialu_reg_reg_shift);
11177 %}
11178 
11179 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11180                          iRegL src1, iRegL src2,
11181                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11182   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11183   ins_cost(1.9 * INSN_COST);
11184   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11185 
11186   ins_encode %{
11187     __ orn(as_Register($dst$$reg),
11188               as_Register($src1$$reg),
11189               as_Register($src2$$reg),
11190               Assembler::LSR,
11191               $src3$$constant &amp; 0x3f);
11192   %}
11193 
11194   ins_pipe(ialu_reg_reg_shift);
11195 %}
11196 
11197 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11198                          iRegIorL2I src1, iRegIorL2I src2,
11199                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11200   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11201   ins_cost(1.9 * INSN_COST);
11202   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11203 
11204   ins_encode %{
11205     __ ornw(as_Register($dst$$reg),
11206               as_Register($src1$$reg),
11207               as_Register($src2$$reg),
11208               Assembler::ASR,
11209               $src3$$constant &amp; 0x1f);
11210   %}
11211 
11212   ins_pipe(ialu_reg_reg_shift);
11213 %}
11214 
11215 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11216                          iRegL src1, iRegL src2,
11217                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11218   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11219   ins_cost(1.9 * INSN_COST);
11220   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11221 
11222   ins_encode %{
11223     __ orn(as_Register($dst$$reg),
11224               as_Register($src1$$reg),
11225               as_Register($src2$$reg),
11226               Assembler::ASR,
11227               $src3$$constant &amp; 0x3f);
11228   %}
11229 
11230   ins_pipe(ialu_reg_reg_shift);
11231 %}
11232 
11233 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11234                          iRegIorL2I src1, iRegIorL2I src2,
11235                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11236   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11237   ins_cost(1.9 * INSN_COST);
11238   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11239 
11240   ins_encode %{
11241     __ ornw(as_Register($dst$$reg),
11242               as_Register($src1$$reg),
11243               as_Register($src2$$reg),
11244               Assembler::LSL,
11245               $src3$$constant &amp; 0x1f);
11246   %}
11247 
11248   ins_pipe(ialu_reg_reg_shift);
11249 %}
11250 
11251 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11252                          iRegL src1, iRegL src2,
11253                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11254   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11255   ins_cost(1.9 * INSN_COST);
11256   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11257 
11258   ins_encode %{
11259     __ orn(as_Register($dst$$reg),
11260               as_Register($src1$$reg),
11261               as_Register($src2$$reg),
11262               Assembler::LSL,
11263               $src3$$constant &amp; 0x3f);
11264   %}
11265 
11266   ins_pipe(ialu_reg_reg_shift);
11267 %}
11268 
11269 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11270                          iRegIorL2I src1, iRegIorL2I src2,
11271                          immI src3, rFlagsReg cr) %{
11272   match(Set dst (AndI src1 (URShiftI src2 src3)));
11273 
11274   ins_cost(1.9 * INSN_COST);
11275   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11276 
11277   ins_encode %{
11278     __ andw(as_Register($dst$$reg),
11279               as_Register($src1$$reg),
11280               as_Register($src2$$reg),
11281               Assembler::LSR,
11282               $src3$$constant &amp; 0x1f);
11283   %}
11284 
11285   ins_pipe(ialu_reg_reg_shift);
11286 %}
11287 
11288 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11289                          iRegL src1, iRegL src2,
11290                          immI src3, rFlagsReg cr) %{
11291   match(Set dst (AndL src1 (URShiftL src2 src3)));
11292 
11293   ins_cost(1.9 * INSN_COST);
11294   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11295 
11296   ins_encode %{
11297     __ andr(as_Register($dst$$reg),
11298               as_Register($src1$$reg),
11299               as_Register($src2$$reg),
11300               Assembler::LSR,
11301               $src3$$constant &amp; 0x3f);
11302   %}
11303 
11304   ins_pipe(ialu_reg_reg_shift);
11305 %}
11306 
11307 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11308                          iRegIorL2I src1, iRegIorL2I src2,
11309                          immI src3, rFlagsReg cr) %{
11310   match(Set dst (AndI src1 (RShiftI src2 src3)));
11311 
11312   ins_cost(1.9 * INSN_COST);
11313   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11314 
11315   ins_encode %{
11316     __ andw(as_Register($dst$$reg),
11317               as_Register($src1$$reg),
11318               as_Register($src2$$reg),
11319               Assembler::ASR,
11320               $src3$$constant &amp; 0x1f);
11321   %}
11322 
11323   ins_pipe(ialu_reg_reg_shift);
11324 %}
11325 
11326 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11327                          iRegL src1, iRegL src2,
11328                          immI src3, rFlagsReg cr) %{
11329   match(Set dst (AndL src1 (RShiftL src2 src3)));
11330 
11331   ins_cost(1.9 * INSN_COST);
11332   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11333 
11334   ins_encode %{
11335     __ andr(as_Register($dst$$reg),
11336               as_Register($src1$$reg),
11337               as_Register($src2$$reg),
11338               Assembler::ASR,
11339               $src3$$constant &amp; 0x3f);
11340   %}
11341 
11342   ins_pipe(ialu_reg_reg_shift);
11343 %}
11344 
11345 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11346                          iRegIorL2I src1, iRegIorL2I src2,
11347                          immI src3, rFlagsReg cr) %{
11348   match(Set dst (AndI src1 (LShiftI src2 src3)));
11349 
11350   ins_cost(1.9 * INSN_COST);
11351   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11352 
11353   ins_encode %{
11354     __ andw(as_Register($dst$$reg),
11355               as_Register($src1$$reg),
11356               as_Register($src2$$reg),
11357               Assembler::LSL,
11358               $src3$$constant &amp; 0x1f);
11359   %}
11360 
11361   ins_pipe(ialu_reg_reg_shift);
11362 %}
11363 
11364 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11365                          iRegL src1, iRegL src2,
11366                          immI src3, rFlagsReg cr) %{
11367   match(Set dst (AndL src1 (LShiftL src2 src3)));
11368 
11369   ins_cost(1.9 * INSN_COST);
11370   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11371 
11372   ins_encode %{
11373     __ andr(as_Register($dst$$reg),
11374               as_Register($src1$$reg),
11375               as_Register($src2$$reg),
11376               Assembler::LSL,
11377               $src3$$constant &amp; 0x3f);
11378   %}
11379 
11380   ins_pipe(ialu_reg_reg_shift);
11381 %}
11382 
11383 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11384                          iRegIorL2I src1, iRegIorL2I src2,
11385                          immI src3, rFlagsReg cr) %{
11386   match(Set dst (XorI src1 (URShiftI src2 src3)));
11387 
11388   ins_cost(1.9 * INSN_COST);
11389   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11390 
11391   ins_encode %{
11392     __ eorw(as_Register($dst$$reg),
11393               as_Register($src1$$reg),
11394               as_Register($src2$$reg),
11395               Assembler::LSR,
11396               $src3$$constant &amp; 0x1f);
11397   %}
11398 
11399   ins_pipe(ialu_reg_reg_shift);
11400 %}
11401 
11402 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11403                          iRegL src1, iRegL src2,
11404                          immI src3, rFlagsReg cr) %{
11405   match(Set dst (XorL src1 (URShiftL src2 src3)));
11406 
11407   ins_cost(1.9 * INSN_COST);
11408   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11409 
11410   ins_encode %{
11411     __ eor(as_Register($dst$$reg),
11412               as_Register($src1$$reg),
11413               as_Register($src2$$reg),
11414               Assembler::LSR,
11415               $src3$$constant &amp; 0x3f);
11416   %}
11417 
11418   ins_pipe(ialu_reg_reg_shift);
11419 %}
11420 
11421 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11422                          iRegIorL2I src1, iRegIorL2I src2,
11423                          immI src3, rFlagsReg cr) %{
11424   match(Set dst (XorI src1 (RShiftI src2 src3)));
11425 
11426   ins_cost(1.9 * INSN_COST);
11427   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11428 
11429   ins_encode %{
11430     __ eorw(as_Register($dst$$reg),
11431               as_Register($src1$$reg),
11432               as_Register($src2$$reg),
11433               Assembler::ASR,
11434               $src3$$constant &amp; 0x1f);
11435   %}
11436 
11437   ins_pipe(ialu_reg_reg_shift);
11438 %}
11439 
11440 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11441                          iRegL src1, iRegL src2,
11442                          immI src3, rFlagsReg cr) %{
11443   match(Set dst (XorL src1 (RShiftL src2 src3)));
11444 
11445   ins_cost(1.9 * INSN_COST);
11446   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11447 
11448   ins_encode %{
11449     __ eor(as_Register($dst$$reg),
11450               as_Register($src1$$reg),
11451               as_Register($src2$$reg),
11452               Assembler::ASR,
11453               $src3$$constant &amp; 0x3f);
11454   %}
11455 
11456   ins_pipe(ialu_reg_reg_shift);
11457 %}
11458 
11459 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11460                          iRegIorL2I src1, iRegIorL2I src2,
11461                          immI src3, rFlagsReg cr) %{
11462   match(Set dst (XorI src1 (LShiftI src2 src3)));
11463 
11464   ins_cost(1.9 * INSN_COST);
11465   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11466 
11467   ins_encode %{
11468     __ eorw(as_Register($dst$$reg),
11469               as_Register($src1$$reg),
11470               as_Register($src2$$reg),
11471               Assembler::LSL,
11472               $src3$$constant &amp; 0x1f);
11473   %}
11474 
11475   ins_pipe(ialu_reg_reg_shift);
11476 %}
11477 
11478 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11479                          iRegL src1, iRegL src2,
11480                          immI src3, rFlagsReg cr) %{
11481   match(Set dst (XorL src1 (LShiftL src2 src3)));
11482 
11483   ins_cost(1.9 * INSN_COST);
11484   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11485 
11486   ins_encode %{
11487     __ eor(as_Register($dst$$reg),
11488               as_Register($src1$$reg),
11489               as_Register($src2$$reg),
11490               Assembler::LSL,
11491               $src3$$constant &amp; 0x3f);
11492   %}
11493 
11494   ins_pipe(ialu_reg_reg_shift);
11495 %}
11496 
11497 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11498                          iRegIorL2I src1, iRegIorL2I src2,
11499                          immI src3, rFlagsReg cr) %{
11500   match(Set dst (OrI src1 (URShiftI src2 src3)));
11501 
11502   ins_cost(1.9 * INSN_COST);
11503   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11504 
11505   ins_encode %{
11506     __ orrw(as_Register($dst$$reg),
11507               as_Register($src1$$reg),
11508               as_Register($src2$$reg),
11509               Assembler::LSR,
11510               $src3$$constant &amp; 0x1f);
11511   %}
11512 
11513   ins_pipe(ialu_reg_reg_shift);
11514 %}
11515 
11516 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11517                          iRegL src1, iRegL src2,
11518                          immI src3, rFlagsReg cr) %{
11519   match(Set dst (OrL src1 (URShiftL src2 src3)));
11520 
11521   ins_cost(1.9 * INSN_COST);
11522   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11523 
11524   ins_encode %{
11525     __ orr(as_Register($dst$$reg),
11526               as_Register($src1$$reg),
11527               as_Register($src2$$reg),
11528               Assembler::LSR,
11529               $src3$$constant &amp; 0x3f);
11530   %}
11531 
11532   ins_pipe(ialu_reg_reg_shift);
11533 %}
11534 
11535 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11536                          iRegIorL2I src1, iRegIorL2I src2,
11537                          immI src3, rFlagsReg cr) %{
11538   match(Set dst (OrI src1 (RShiftI src2 src3)));
11539 
11540   ins_cost(1.9 * INSN_COST);
11541   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11542 
11543   ins_encode %{
11544     __ orrw(as_Register($dst$$reg),
11545               as_Register($src1$$reg),
11546               as_Register($src2$$reg),
11547               Assembler::ASR,
11548               $src3$$constant &amp; 0x1f);
11549   %}
11550 
11551   ins_pipe(ialu_reg_reg_shift);
11552 %}
11553 
11554 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11555                          iRegL src1, iRegL src2,
11556                          immI src3, rFlagsReg cr) %{
11557   match(Set dst (OrL src1 (RShiftL src2 src3)));
11558 
11559   ins_cost(1.9 * INSN_COST);
11560   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11561 
11562   ins_encode %{
11563     __ orr(as_Register($dst$$reg),
11564               as_Register($src1$$reg),
11565               as_Register($src2$$reg),
11566               Assembler::ASR,
11567               $src3$$constant &amp; 0x3f);
11568   %}
11569 
11570   ins_pipe(ialu_reg_reg_shift);
11571 %}
11572 
11573 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11574                          iRegIorL2I src1, iRegIorL2I src2,
11575                          immI src3, rFlagsReg cr) %{
11576   match(Set dst (OrI src1 (LShiftI src2 src3)));
11577 
11578   ins_cost(1.9 * INSN_COST);
11579   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11580 
11581   ins_encode %{
11582     __ orrw(as_Register($dst$$reg),
11583               as_Register($src1$$reg),
11584               as_Register($src2$$reg),
11585               Assembler::LSL,
11586               $src3$$constant &amp; 0x1f);
11587   %}
11588 
11589   ins_pipe(ialu_reg_reg_shift);
11590 %}
11591 
11592 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11593                          iRegL src1, iRegL src2,
11594                          immI src3, rFlagsReg cr) %{
11595   match(Set dst (OrL src1 (LShiftL src2 src3)));
11596 
11597   ins_cost(1.9 * INSN_COST);
11598   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11599 
11600   ins_encode %{
11601     __ orr(as_Register($dst$$reg),
11602               as_Register($src1$$reg),
11603               as_Register($src2$$reg),
11604               Assembler::LSL,
11605               $src3$$constant &amp; 0x3f);
11606   %}
11607 
11608   ins_pipe(ialu_reg_reg_shift);
11609 %}
11610 
11611 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11612                          iRegIorL2I src1, iRegIorL2I src2,
11613                          immI src3, rFlagsReg cr) %{
11614   match(Set dst (AddI src1 (URShiftI src2 src3)));
11615 
11616   ins_cost(1.9 * INSN_COST);
11617   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11618 
11619   ins_encode %{
11620     __ addw(as_Register($dst$$reg),
11621               as_Register($src1$$reg),
11622               as_Register($src2$$reg),
11623               Assembler::LSR,
11624               $src3$$constant &amp; 0x1f);
11625   %}
11626 
11627   ins_pipe(ialu_reg_reg_shift);
11628 %}
11629 
11630 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11631                          iRegL src1, iRegL src2,
11632                          immI src3, rFlagsReg cr) %{
11633   match(Set dst (AddL src1 (URShiftL src2 src3)));
11634 
11635   ins_cost(1.9 * INSN_COST);
11636   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11637 
11638   ins_encode %{
11639     __ add(as_Register($dst$$reg),
11640               as_Register($src1$$reg),
11641               as_Register($src2$$reg),
11642               Assembler::LSR,
11643               $src3$$constant &amp; 0x3f);
11644   %}
11645 
11646   ins_pipe(ialu_reg_reg_shift);
11647 %}
11648 
11649 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11650                          iRegIorL2I src1, iRegIorL2I src2,
11651                          immI src3, rFlagsReg cr) %{
11652   match(Set dst (AddI src1 (RShiftI src2 src3)));
11653 
11654   ins_cost(1.9 * INSN_COST);
11655   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11656 
11657   ins_encode %{
11658     __ addw(as_Register($dst$$reg),
11659               as_Register($src1$$reg),
11660               as_Register($src2$$reg),
11661               Assembler::ASR,
11662               $src3$$constant &amp; 0x1f);
11663   %}
11664 
11665   ins_pipe(ialu_reg_reg_shift);
11666 %}
11667 
11668 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11669                          iRegL src1, iRegL src2,
11670                          immI src3, rFlagsReg cr) %{
11671   match(Set dst (AddL src1 (RShiftL src2 src3)));
11672 
11673   ins_cost(1.9 * INSN_COST);
11674   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11675 
11676   ins_encode %{
11677     __ add(as_Register($dst$$reg),
11678               as_Register($src1$$reg),
11679               as_Register($src2$$reg),
11680               Assembler::ASR,
11681               $src3$$constant &amp; 0x3f);
11682   %}
11683 
11684   ins_pipe(ialu_reg_reg_shift);
11685 %}
11686 
11687 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11688                          iRegIorL2I src1, iRegIorL2I src2,
11689                          immI src3, rFlagsReg cr) %{
11690   match(Set dst (AddI src1 (LShiftI src2 src3)));
11691 
11692   ins_cost(1.9 * INSN_COST);
11693   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11694 
11695   ins_encode %{
11696     __ addw(as_Register($dst$$reg),
11697               as_Register($src1$$reg),
11698               as_Register($src2$$reg),
11699               Assembler::LSL,
11700               $src3$$constant &amp; 0x1f);
11701   %}
11702 
11703   ins_pipe(ialu_reg_reg_shift);
11704 %}
11705 
11706 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11707                          iRegL src1, iRegL src2,
11708                          immI src3, rFlagsReg cr) %{
11709   match(Set dst (AddL src1 (LShiftL src2 src3)));
11710 
11711   ins_cost(1.9 * INSN_COST);
11712   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11713 
11714   ins_encode %{
11715     __ add(as_Register($dst$$reg),
11716               as_Register($src1$$reg),
11717               as_Register($src2$$reg),
11718               Assembler::LSL,
11719               $src3$$constant &amp; 0x3f);
11720   %}
11721 
11722   ins_pipe(ialu_reg_reg_shift);
11723 %}
11724 
11725 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11726                          iRegIorL2I src1, iRegIorL2I src2,
11727                          immI src3, rFlagsReg cr) %{
11728   match(Set dst (SubI src1 (URShiftI src2 src3)));
11729 
11730   ins_cost(1.9 * INSN_COST);
11731   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11732 
11733   ins_encode %{
11734     __ subw(as_Register($dst$$reg),
11735               as_Register($src1$$reg),
11736               as_Register($src2$$reg),
11737               Assembler::LSR,
11738               $src3$$constant &amp; 0x1f);
11739   %}
11740 
11741   ins_pipe(ialu_reg_reg_shift);
11742 %}
11743 
11744 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11745                          iRegL src1, iRegL src2,
11746                          immI src3, rFlagsReg cr) %{
11747   match(Set dst (SubL src1 (URShiftL src2 src3)));
11748 
11749   ins_cost(1.9 * INSN_COST);
11750   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11751 
11752   ins_encode %{
11753     __ sub(as_Register($dst$$reg),
11754               as_Register($src1$$reg),
11755               as_Register($src2$$reg),
11756               Assembler::LSR,
11757               $src3$$constant &amp; 0x3f);
11758   %}
11759 
11760   ins_pipe(ialu_reg_reg_shift);
11761 %}
11762 
11763 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11764                          iRegIorL2I src1, iRegIorL2I src2,
11765                          immI src3, rFlagsReg cr) %{
11766   match(Set dst (SubI src1 (RShiftI src2 src3)));
11767 
11768   ins_cost(1.9 * INSN_COST);
11769   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11770 
11771   ins_encode %{
11772     __ subw(as_Register($dst$$reg),
11773               as_Register($src1$$reg),
11774               as_Register($src2$$reg),
11775               Assembler::ASR,
11776               $src3$$constant &amp; 0x1f);
11777   %}
11778 
11779   ins_pipe(ialu_reg_reg_shift);
11780 %}
11781 
11782 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11783                          iRegL src1, iRegL src2,
11784                          immI src3, rFlagsReg cr) %{
11785   match(Set dst (SubL src1 (RShiftL src2 src3)));
11786 
11787   ins_cost(1.9 * INSN_COST);
11788   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11789 
11790   ins_encode %{
11791     __ sub(as_Register($dst$$reg),
11792               as_Register($src1$$reg),
11793               as_Register($src2$$reg),
11794               Assembler::ASR,
11795               $src3$$constant &amp; 0x3f);
11796   %}
11797 
11798   ins_pipe(ialu_reg_reg_shift);
11799 %}
11800 
11801 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11802                          iRegIorL2I src1, iRegIorL2I src2,
11803                          immI src3, rFlagsReg cr) %{
11804   match(Set dst (SubI src1 (LShiftI src2 src3)));
11805 
11806   ins_cost(1.9 * INSN_COST);
11807   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11808 
11809   ins_encode %{
11810     __ subw(as_Register($dst$$reg),
11811               as_Register($src1$$reg),
11812               as_Register($src2$$reg),
11813               Assembler::LSL,
11814               $src3$$constant &amp; 0x1f);
11815   %}
11816 
11817   ins_pipe(ialu_reg_reg_shift);
11818 %}
11819 
11820 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11821                          iRegL src1, iRegL src2,
11822                          immI src3, rFlagsReg cr) %{
11823   match(Set dst (SubL src1 (LShiftL src2 src3)));
11824 
11825   ins_cost(1.9 * INSN_COST);
11826   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11827 
11828   ins_encode %{
11829     __ sub(as_Register($dst$$reg),
11830               as_Register($src1$$reg),
11831               as_Register($src2$$reg),
11832               Assembler::LSL,
11833               $src3$$constant &amp; 0x3f);
11834   %}
11835 
11836   ins_pipe(ialu_reg_reg_shift);
11837 %}
11838 
11839 
11840 
11841 // Shift Left followed by Shift Right.
11842 // This idiom is used by the compiler for the i2b bytecode etc.
11843 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11844 %{
11845   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11846   ins_cost(INSN_COST * 2);
11847   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11848   ins_encode %{
11849     int lshift = $lshift_count$$constant &amp; 63;
11850     int rshift = $rshift_count$$constant &amp; 63;
11851     int s = 63 - lshift;
11852     int r = (rshift - lshift) &amp; 63;
11853     __ sbfm(as_Register($dst$$reg),
11854             as_Register($src$$reg),
11855             r, s);
11856   %}
11857 
11858   ins_pipe(ialu_reg_shift);
11859 %}
11860 
11861 // Shift Left followed by Shift Right.
11862 // This idiom is used by the compiler for the i2b bytecode etc.
11863 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11864 %{
11865   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11866   ins_cost(INSN_COST * 2);
11867   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11868   ins_encode %{
11869     int lshift = $lshift_count$$constant &amp; 31;
11870     int rshift = $rshift_count$$constant &amp; 31;
11871     int s = 31 - lshift;
11872     int r = (rshift - lshift) &amp; 31;
11873     __ sbfmw(as_Register($dst$$reg),
11874             as_Register($src$$reg),
11875             r, s);
11876   %}
11877 
11878   ins_pipe(ialu_reg_shift);
11879 %}
11880 
11881 // Shift Left followed by Shift Right.
11882 // This idiom is used by the compiler for the i2b bytecode etc.
11883 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11884 %{
11885   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11886   ins_cost(INSN_COST * 2);
11887   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11888   ins_encode %{
11889     int lshift = $lshift_count$$constant &amp; 63;
11890     int rshift = $rshift_count$$constant &amp; 63;
11891     int s = 63 - lshift;
11892     int r = (rshift - lshift) &amp; 63;
11893     __ ubfm(as_Register($dst$$reg),
11894             as_Register($src$$reg),
11895             r, s);
11896   %}
11897 
11898   ins_pipe(ialu_reg_shift);
11899 %}
11900 
11901 // Shift Left followed by Shift Right.
11902 // This idiom is used by the compiler for the i2b bytecode etc.
11903 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11904 %{
11905   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11906   ins_cost(INSN_COST * 2);
11907   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11908   ins_encode %{
11909     int lshift = $lshift_count$$constant &amp; 31;
11910     int rshift = $rshift_count$$constant &amp; 31;
11911     int s = 31 - lshift;
11912     int r = (rshift - lshift) &amp; 31;
11913     __ ubfmw(as_Register($dst$$reg),
11914             as_Register($src$$reg),
11915             r, s);
11916   %}
11917 
11918   ins_pipe(ialu_reg_shift);
11919 %}
11920 // Bitfield extract with shift &amp; mask
11921 
11922 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11923 %{
11924   match(Set dst (AndI (URShiftI src rshift) mask));
11925   // Make sure we are not going to exceed what ubfxw can do.
11926   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11927 
11928   ins_cost(INSN_COST);
11929   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11930   ins_encode %{
11931     int rshift = $rshift$$constant &amp; 31;
11932     long mask = $mask$$constant;
11933     int width = exact_log2(mask+1);
11934     __ ubfxw(as_Register($dst$$reg),
11935             as_Register($src$$reg), rshift, width);
11936   %}
11937   ins_pipe(ialu_reg_shift);
11938 %}
11939 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
11940 %{
11941   match(Set dst (AndL (URShiftL src rshift) mask));
11942   // Make sure we are not going to exceed what ubfx can do.
11943   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11944 
11945   ins_cost(INSN_COST);
11946   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11947   ins_encode %{
11948     int rshift = $rshift$$constant &amp; 63;
11949     long mask = $mask$$constant;
11950     int width = exact_log2_long(mask+1);
11951     __ ubfx(as_Register($dst$$reg),
11952             as_Register($src$$reg), rshift, width);
11953   %}
11954   ins_pipe(ialu_reg_shift);
11955 %}
11956 
11957 // We can use ubfx when extending an And with a mask when we know mask
11958 // is positive.  We know that because immI_bitmask guarantees it.
11959 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11960 %{
11961   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
11962   // Make sure we are not going to exceed what ubfxw can do.
11963   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11964 
11965   ins_cost(INSN_COST * 2);
11966   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11967   ins_encode %{
11968     int rshift = $rshift$$constant &amp; 31;
11969     long mask = $mask$$constant;
11970     int width = exact_log2(mask+1);
11971     __ ubfx(as_Register($dst$$reg),
11972             as_Register($src$$reg), rshift, width);
11973   %}
11974   ins_pipe(ialu_reg_shift);
11975 %}
11976 
11977 // We can use ubfiz when masking by a positive number and then left shifting the result.
11978 // We know that the mask is positive because immI_bitmask guarantees it.
11979 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
11980 %{
11981   match(Set dst (LShiftI (AndI src mask) lshift));
11982   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11983 
11984   ins_cost(INSN_COST);
11985   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
11986   ins_encode %{
11987     int lshift = $lshift$$constant &amp; 31;
11988     long mask = $mask$$constant;
11989     int width = exact_log2(mask+1);
11990     __ ubfizw(as_Register($dst$$reg),
11991           as_Register($src$$reg), lshift, width);
11992   %}
11993   ins_pipe(ialu_reg_shift);
11994 %}
11995 // We can use ubfiz when masking by a positive number and then left shifting the result.
11996 // We know that the mask is positive because immL_bitmask guarantees it.
11997 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
11998 %{
11999   match(Set dst (LShiftL (AndL src mask) lshift));
12000   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12001 
12002   ins_cost(INSN_COST);
12003   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12004   ins_encode %{
12005     int lshift = $lshift$$constant &amp; 63;
12006     long mask = $mask$$constant;
12007     int width = exact_log2_long(mask+1);
12008     __ ubfiz(as_Register($dst$$reg),
12009           as_Register($src$$reg), lshift, width);
12010   %}
12011   ins_pipe(ialu_reg_shift);
12012 %}
12013 
12014 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12015 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12016 %{
12017   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12018   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12019 
12020   ins_cost(INSN_COST);
12021   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12022   ins_encode %{
12023     int lshift = $lshift$$constant &amp; 63;
12024     long mask = $mask$$constant;
12025     int width = exact_log2(mask+1);
12026     __ ubfiz(as_Register($dst$$reg),
12027              as_Register($src$$reg), lshift, width);
12028   %}
12029   ins_pipe(ialu_reg_shift);
12030 %}
12031 
12032 // Rotations
12033 
12034 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12035 %{
12036   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12037   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12038 
12039   ins_cost(INSN_COST);
12040   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12041 
12042   ins_encode %{
12043     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12044             $rshift$$constant &amp; 63);
12045   %}
12046   ins_pipe(ialu_reg_reg_extr);
12047 %}
12048 
12049 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12050 %{
12051   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12052   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12053 
12054   ins_cost(INSN_COST);
12055   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12056 
12057   ins_encode %{
12058     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12059             $rshift$$constant &amp; 31);
12060   %}
12061   ins_pipe(ialu_reg_reg_extr);
12062 %}
12063 
12064 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12065 %{
12066   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12067   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12068 
12069   ins_cost(INSN_COST);
12070   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12071 
12072   ins_encode %{
12073     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12074             $rshift$$constant &amp; 63);
12075   %}
12076   ins_pipe(ialu_reg_reg_extr);
12077 %}
12078 
12079 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12080 %{
12081   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12082   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12083 
12084   ins_cost(INSN_COST);
12085   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12086 
12087   ins_encode %{
12088     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12089             $rshift$$constant &amp; 31);
12090   %}
12091   ins_pipe(ialu_reg_reg_extr);
12092 %}
12093 
12094 
12095 // rol expander
12096 
12097 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12098 %{
12099   effect(DEF dst, USE src, USE shift);
12100 
12101   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12102   ins_cost(INSN_COST * 3);
12103   ins_encode %{
12104     __ subw(rscratch1, zr, as_Register($shift$$reg));
12105     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12106             rscratch1);
12107     %}
12108   ins_pipe(ialu_reg_reg_vshift);
12109 %}
12110 
12111 // rol expander
12112 
12113 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12114 %{
12115   effect(DEF dst, USE src, USE shift);
12116 
12117   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12118   ins_cost(INSN_COST * 3);
12119   ins_encode %{
12120     __ subw(rscratch1, zr, as_Register($shift$$reg));
12121     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12122             rscratch1);
12123     %}
12124   ins_pipe(ialu_reg_reg_vshift);
12125 %}
12126 
12127 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12128 %{
12129   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12130 
12131   expand %{
12132     rolL_rReg(dst, src, shift, cr);
12133   %}
12134 %}
12135 
12136 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12137 %{
12138   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12139 
12140   expand %{
12141     rolL_rReg(dst, src, shift, cr);
12142   %}
12143 %}
12144 
12145 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12146 %{
12147   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12148 
12149   expand %{
12150     rolI_rReg(dst, src, shift, cr);
12151   %}
12152 %}
12153 
12154 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12155 %{
12156   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12157 
12158   expand %{
12159     rolI_rReg(dst, src, shift, cr);
12160   %}
12161 %}
12162 
12163 // ror expander
12164 
12165 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12166 %{
12167   effect(DEF dst, USE src, USE shift);
12168 
12169   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12170   ins_cost(INSN_COST);
12171   ins_encode %{
12172     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12173             as_Register($shift$$reg));
12174     %}
12175   ins_pipe(ialu_reg_reg_vshift);
12176 %}
12177 
12178 // ror expander
12179 
12180 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12181 %{
12182   effect(DEF dst, USE src, USE shift);
12183 
12184   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12185   ins_cost(INSN_COST);
12186   ins_encode %{
12187     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12188             as_Register($shift$$reg));
12189     %}
12190   ins_pipe(ialu_reg_reg_vshift);
12191 %}
12192 
12193 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12194 %{
12195   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12196 
12197   expand %{
12198     rorL_rReg(dst, src, shift, cr);
12199   %}
12200 %}
12201 
12202 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12203 %{
12204   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12205 
12206   expand %{
12207     rorL_rReg(dst, src, shift, cr);
12208   %}
12209 %}
12210 
12211 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12212 %{
12213   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12214 
12215   expand %{
12216     rorI_rReg(dst, src, shift, cr);
12217   %}
12218 %}
12219 
12220 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12221 %{
12222   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12223 
12224   expand %{
12225     rorI_rReg(dst, src, shift, cr);
12226   %}
12227 %}
12228 
12229 // Add/subtract (extended)
12230 
12231 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12232 %{
12233   match(Set dst (AddL src1 (ConvI2L src2)));
12234   ins_cost(INSN_COST);
12235   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12236 
12237    ins_encode %{
12238      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12239             as_Register($src2$$reg), ext::sxtw);
12240    %}
12241   ins_pipe(ialu_reg_reg);
12242 %};
12243 
12244 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12245 %{
12246   match(Set dst (SubL src1 (ConvI2L src2)));
12247   ins_cost(INSN_COST);
12248   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12249 
12250    ins_encode %{
12251      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12252             as_Register($src2$$reg), ext::sxtw);
12253    %}
12254   ins_pipe(ialu_reg_reg);
12255 %};
12256 
12257 
12258 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12259 %{
12260   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12261   ins_cost(INSN_COST);
12262   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12263 
12264    ins_encode %{
12265      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12266             as_Register($src2$$reg), ext::sxth);
12267    %}
12268   ins_pipe(ialu_reg_reg);
12269 %}
12270 
12271 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12272 %{
12273   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12274   ins_cost(INSN_COST);
12275   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12276 
12277    ins_encode %{
12278      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12279             as_Register($src2$$reg), ext::sxtb);
12280    %}
12281   ins_pipe(ialu_reg_reg);
12282 %}
12283 
12284 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12285 %{
12286   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12287   ins_cost(INSN_COST);
12288   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12289 
12290    ins_encode %{
12291      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12292             as_Register($src2$$reg), ext::uxtb);
12293    %}
12294   ins_pipe(ialu_reg_reg);
12295 %}
12296 
12297 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12298 %{
12299   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12300   ins_cost(INSN_COST);
12301   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12302 
12303    ins_encode %{
12304      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12305             as_Register($src2$$reg), ext::sxth);
12306    %}
12307   ins_pipe(ialu_reg_reg);
12308 %}
12309 
12310 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12311 %{
12312   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12313   ins_cost(INSN_COST);
12314   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12315 
12316    ins_encode %{
12317      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12318             as_Register($src2$$reg), ext::sxtw);
12319    %}
12320   ins_pipe(ialu_reg_reg);
12321 %}
12322 
12323 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12324 %{
12325   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12326   ins_cost(INSN_COST);
12327   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12328 
12329    ins_encode %{
12330      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12331             as_Register($src2$$reg), ext::sxtb);
12332    %}
12333   ins_pipe(ialu_reg_reg);
12334 %}
12335 
12336 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12337 %{
12338   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12339   ins_cost(INSN_COST);
12340   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12341 
12342    ins_encode %{
12343      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12344             as_Register($src2$$reg), ext::uxtb);
12345    %}
12346   ins_pipe(ialu_reg_reg);
12347 %}
12348 
12349 
12350 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12351 %{
12352   match(Set dst (AddI src1 (AndI src2 mask)));
12353   ins_cost(INSN_COST);
12354   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12355 
12356    ins_encode %{
12357      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12358             as_Register($src2$$reg), ext::uxtb);
12359    %}
12360   ins_pipe(ialu_reg_reg);
12361 %}
12362 
12363 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12364 %{
12365   match(Set dst (AddI src1 (AndI src2 mask)));
12366   ins_cost(INSN_COST);
12367   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12368 
12369    ins_encode %{
12370      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12371             as_Register($src2$$reg), ext::uxth);
12372    %}
12373   ins_pipe(ialu_reg_reg);
12374 %}
12375 
12376 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12377 %{
12378   match(Set dst (AddL src1 (AndL src2 mask)));
12379   ins_cost(INSN_COST);
12380   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12381 
12382    ins_encode %{
12383      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12384             as_Register($src2$$reg), ext::uxtb);
12385    %}
12386   ins_pipe(ialu_reg_reg);
12387 %}
12388 
12389 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12390 %{
12391   match(Set dst (AddL src1 (AndL src2 mask)));
12392   ins_cost(INSN_COST);
12393   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12394 
12395    ins_encode %{
12396      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12397             as_Register($src2$$reg), ext::uxth);
12398    %}
12399   ins_pipe(ialu_reg_reg);
12400 %}
12401 
12402 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12403 %{
12404   match(Set dst (AddL src1 (AndL src2 mask)));
12405   ins_cost(INSN_COST);
12406   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12407 
12408    ins_encode %{
12409      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12410             as_Register($src2$$reg), ext::uxtw);
12411    %}
12412   ins_pipe(ialu_reg_reg);
12413 %}
12414 
12415 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12416 %{
12417   match(Set dst (SubI src1 (AndI src2 mask)));
12418   ins_cost(INSN_COST);
12419   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12420 
12421    ins_encode %{
12422      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12423             as_Register($src2$$reg), ext::uxtb);
12424    %}
12425   ins_pipe(ialu_reg_reg);
12426 %}
12427 
12428 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12429 %{
12430   match(Set dst (SubI src1 (AndI src2 mask)));
12431   ins_cost(INSN_COST);
12432   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12433 
12434    ins_encode %{
12435      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12436             as_Register($src2$$reg), ext::uxth);
12437    %}
12438   ins_pipe(ialu_reg_reg);
12439 %}
12440 
12441 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12442 %{
12443   match(Set dst (SubL src1 (AndL src2 mask)));
12444   ins_cost(INSN_COST);
12445   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12446 
12447    ins_encode %{
12448      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12449             as_Register($src2$$reg), ext::uxtb);
12450    %}
12451   ins_pipe(ialu_reg_reg);
12452 %}
12453 
12454 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12455 %{
12456   match(Set dst (SubL src1 (AndL src2 mask)));
12457   ins_cost(INSN_COST);
12458   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12459 
12460    ins_encode %{
12461      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12462             as_Register($src2$$reg), ext::uxth);
12463    %}
12464   ins_pipe(ialu_reg_reg);
12465 %}
12466 
12467 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12468 %{
12469   match(Set dst (SubL src1 (AndL src2 mask)));
12470   ins_cost(INSN_COST);
12471   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12472 
12473    ins_encode %{
12474      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12475             as_Register($src2$$reg), ext::uxtw);
12476    %}
12477   ins_pipe(ialu_reg_reg);
12478 %}
12479 
12480 
12481 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12482 %{
12483   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12484   ins_cost(1.9 * INSN_COST);
12485   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12486 
12487    ins_encode %{
12488      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12489             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12490    %}
12491   ins_pipe(ialu_reg_reg_shift);
12492 %}
12493 
12494 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12495 %{
12496   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12497   ins_cost(1.9 * INSN_COST);
12498   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12499 
12500    ins_encode %{
12501      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12502             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12503    %}
12504   ins_pipe(ialu_reg_reg_shift);
12505 %}
12506 
12507 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12508 %{
12509   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12510   ins_cost(1.9 * INSN_COST);
12511   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12512 
12513    ins_encode %{
12514      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12515             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12516    %}
12517   ins_pipe(ialu_reg_reg_shift);
12518 %}
12519 
12520 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12521 %{
12522   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12523   ins_cost(1.9 * INSN_COST);
12524   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12525 
12526    ins_encode %{
12527      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12528             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12529    %}
12530   ins_pipe(ialu_reg_reg_shift);
12531 %}
12532 
12533 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12534 %{
12535   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12536   ins_cost(1.9 * INSN_COST);
12537   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12538 
12539    ins_encode %{
12540      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12541             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12542    %}
12543   ins_pipe(ialu_reg_reg_shift);
12544 %}
12545 
12546 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12547 %{
12548   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12549   ins_cost(1.9 * INSN_COST);
12550   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12551 
12552    ins_encode %{
12553      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12554             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12555    %}
12556   ins_pipe(ialu_reg_reg_shift);
12557 %}
12558 
12559 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12560 %{
12561   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12562   ins_cost(1.9 * INSN_COST);
12563   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12564 
12565    ins_encode %{
12566      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12567             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12568    %}
12569   ins_pipe(ialu_reg_reg_shift);
12570 %}
12571 
12572 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12573 %{
12574   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12575   ins_cost(1.9 * INSN_COST);
12576   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12577 
12578    ins_encode %{
12579      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12580             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12581    %}
12582   ins_pipe(ialu_reg_reg_shift);
12583 %}
12584 
12585 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12586 %{
12587   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12588   ins_cost(1.9 * INSN_COST);
12589   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12590 
12591    ins_encode %{
12592      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12593             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12594    %}
12595   ins_pipe(ialu_reg_reg_shift);
12596 %}
12597 
12598 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12599 %{
12600   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12601   ins_cost(1.9 * INSN_COST);
12602   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12603 
12604    ins_encode %{
12605      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12606             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12607    %}
12608   ins_pipe(ialu_reg_reg_shift);
12609 %}
12610 
12611 
12612 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12613 %{
12614   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12615   ins_cost(1.9 * INSN_COST);
12616   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12617 
12618    ins_encode %{
12619      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12620             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12621    %}
12622   ins_pipe(ialu_reg_reg_shift);
12623 %};
12624 
12625 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12626 %{
12627   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12628   ins_cost(1.9 * INSN_COST);
12629   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12630 
12631    ins_encode %{
12632      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12633             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12634    %}
12635   ins_pipe(ialu_reg_reg_shift);
12636 %};
12637 
12638 
12639 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12640 %{
12641   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12642   ins_cost(1.9 * INSN_COST);
12643   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12644 
12645    ins_encode %{
12646      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12647             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12648    %}
12649   ins_pipe(ialu_reg_reg_shift);
12650 %}
12651 
12652 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12653 %{
12654   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12655   ins_cost(1.9 * INSN_COST);
12656   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12657 
12658    ins_encode %{
12659      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12660             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12661    %}
12662   ins_pipe(ialu_reg_reg_shift);
12663 %}
12664 
12665 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12666 %{
12667   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12668   ins_cost(1.9 * INSN_COST);
12669   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12670 
12671    ins_encode %{
12672      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12673             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12674    %}
12675   ins_pipe(ialu_reg_reg_shift);
12676 %}
12677 
12678 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12679 %{
12680   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12681   ins_cost(1.9 * INSN_COST);
12682   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12683 
12684    ins_encode %{
12685      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12686             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12687    %}
12688   ins_pipe(ialu_reg_reg_shift);
12689 %}
12690 
12691 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12692 %{
12693   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12694   ins_cost(1.9 * INSN_COST);
12695   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12696 
12697    ins_encode %{
12698      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12699             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12700    %}
12701   ins_pipe(ialu_reg_reg_shift);
12702 %}
12703 
12704 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12705 %{
12706   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12707   ins_cost(1.9 * INSN_COST);
12708   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12709 
12710    ins_encode %{
12711      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12712             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12713    %}
12714   ins_pipe(ialu_reg_reg_shift);
12715 %}
12716 
12717 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12718 %{
12719   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12720   ins_cost(1.9 * INSN_COST);
12721   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12722 
12723    ins_encode %{
12724      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12725             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12726    %}
12727   ins_pipe(ialu_reg_reg_shift);
12728 %}
12729 
12730 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12731 %{
12732   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12733   ins_cost(1.9 * INSN_COST);
12734   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12735 
12736    ins_encode %{
12737      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12738             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12739    %}
12740   ins_pipe(ialu_reg_reg_shift);
12741 %}
12742 
12743 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12744 %{
12745   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12746   ins_cost(1.9 * INSN_COST);
12747   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12748 
12749    ins_encode %{
12750      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12751             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12752    %}
12753   ins_pipe(ialu_reg_reg_shift);
12754 %}
12755 
12756 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12757 %{
12758   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12759   ins_cost(1.9 * INSN_COST);
12760   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12761 
12762    ins_encode %{
12763      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12764             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12765    %}
12766   ins_pipe(ialu_reg_reg_shift);
12767 %}
12768 // END This section of the file is automatically generated. Do not edit --------------
12769 
12770 // ============================================================================
12771 // Floating Point Arithmetic Instructions
12772 
12773 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12774   match(Set dst (AddF src1 src2));
12775 
12776   ins_cost(INSN_COST * 5);
12777   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12778 
12779   ins_encode %{
12780     __ fadds(as_FloatRegister($dst$$reg),
12781              as_FloatRegister($src1$$reg),
12782              as_FloatRegister($src2$$reg));
12783   %}
12784 
12785   ins_pipe(fp_dop_reg_reg_s);
12786 %}
12787 
12788 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12789   match(Set dst (AddD src1 src2));
12790 
12791   ins_cost(INSN_COST * 5);
12792   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12793 
12794   ins_encode %{
12795     __ faddd(as_FloatRegister($dst$$reg),
12796              as_FloatRegister($src1$$reg),
12797              as_FloatRegister($src2$$reg));
12798   %}
12799 
12800   ins_pipe(fp_dop_reg_reg_d);
12801 %}
12802 
12803 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12804   match(Set dst (SubF src1 src2));
12805 
12806   ins_cost(INSN_COST * 5);
12807   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12808 
12809   ins_encode %{
12810     __ fsubs(as_FloatRegister($dst$$reg),
12811              as_FloatRegister($src1$$reg),
12812              as_FloatRegister($src2$$reg));
12813   %}
12814 
12815   ins_pipe(fp_dop_reg_reg_s);
12816 %}
12817 
12818 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12819   match(Set dst (SubD src1 src2));
12820 
12821   ins_cost(INSN_COST * 5);
12822   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12823 
12824   ins_encode %{
12825     __ fsubd(as_FloatRegister($dst$$reg),
12826              as_FloatRegister($src1$$reg),
12827              as_FloatRegister($src2$$reg));
12828   %}
12829 
12830   ins_pipe(fp_dop_reg_reg_d);
12831 %}
12832 
12833 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12834   match(Set dst (MulF src1 src2));
12835 
12836   ins_cost(INSN_COST * 6);
12837   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12838 
12839   ins_encode %{
12840     __ fmuls(as_FloatRegister($dst$$reg),
12841              as_FloatRegister($src1$$reg),
12842              as_FloatRegister($src2$$reg));
12843   %}
12844 
12845   ins_pipe(fp_dop_reg_reg_s);
12846 %}
12847 
12848 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12849   match(Set dst (MulD src1 src2));
12850 
12851   ins_cost(INSN_COST * 6);
12852   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12853 
12854   ins_encode %{
12855     __ fmuld(as_FloatRegister($dst$$reg),
12856              as_FloatRegister($src1$$reg),
12857              as_FloatRegister($src2$$reg));
12858   %}
12859 
12860   ins_pipe(fp_dop_reg_reg_d);
12861 %}
12862 
12863 // src1 * src2 + src3
12864 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12865   predicate(UseFMA);
12866   match(Set dst (FmaF src3 (Binary src1 src2)));
12867 
12868   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12869 
12870   ins_encode %{
12871     __ fmadds(as_FloatRegister($dst$$reg),
12872              as_FloatRegister($src1$$reg),
12873              as_FloatRegister($src2$$reg),
12874              as_FloatRegister($src3$$reg));
12875   %}
12876 
12877   ins_pipe(pipe_class_default);
12878 %}
12879 
12880 // src1 * src2 + src3
12881 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12882   predicate(UseFMA);
12883   match(Set dst (FmaD src3 (Binary src1 src2)));
12884 
12885   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12886 
12887   ins_encode %{
12888     __ fmaddd(as_FloatRegister($dst$$reg),
12889              as_FloatRegister($src1$$reg),
12890              as_FloatRegister($src2$$reg),
12891              as_FloatRegister($src3$$reg));
12892   %}
12893 
12894   ins_pipe(pipe_class_default);
12895 %}
12896 
12897 // -src1 * src2 + src3
12898 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12899   predicate(UseFMA);
12900   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12901   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12902 
12903   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12904 
12905   ins_encode %{
12906     __ fmsubs(as_FloatRegister($dst$$reg),
12907               as_FloatRegister($src1$$reg),
12908               as_FloatRegister($src2$$reg),
12909               as_FloatRegister($src3$$reg));
12910   %}
12911 
12912   ins_pipe(pipe_class_default);
12913 %}
12914 
12915 // -src1 * src2 + src3
12916 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12917   predicate(UseFMA);
12918   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12919   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12920 
12921   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12922 
12923   ins_encode %{
12924     __ fmsubd(as_FloatRegister($dst$$reg),
12925               as_FloatRegister($src1$$reg),
12926               as_FloatRegister($src2$$reg),
12927               as_FloatRegister($src3$$reg));
12928   %}
12929 
12930   ins_pipe(pipe_class_default);
12931 %}
12932 
12933 // -src1 * src2 - src3
12934 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12935   predicate(UseFMA);
12936   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
12937   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
12938 
12939   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
12940 
12941   ins_encode %{
12942     __ fnmadds(as_FloatRegister($dst$$reg),
12943                as_FloatRegister($src1$$reg),
12944                as_FloatRegister($src2$$reg),
12945                as_FloatRegister($src3$$reg));
12946   %}
12947 
12948   ins_pipe(pipe_class_default);
12949 %}
12950 
12951 // -src1 * src2 - src3
12952 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12953   predicate(UseFMA);
12954   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
12955   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
12956 
12957   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
12958 
12959   ins_encode %{
12960     __ fnmaddd(as_FloatRegister($dst$$reg),
12961                as_FloatRegister($src1$$reg),
12962                as_FloatRegister($src2$$reg),
12963                as_FloatRegister($src3$$reg));
12964   %}
12965 
12966   ins_pipe(pipe_class_default);
12967 %}
12968 
12969 // src1 * src2 - src3
12970 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
12971   predicate(UseFMA);
12972   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
12973 
12974   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
12975 
12976   ins_encode %{
12977     __ fnmsubs(as_FloatRegister($dst$$reg),
12978                as_FloatRegister($src1$$reg),
12979                as_FloatRegister($src2$$reg),
12980                as_FloatRegister($src3$$reg));
12981   %}
12982 
12983   ins_pipe(pipe_class_default);
12984 %}
12985 
12986 // src1 * src2 - src3
12987 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
12988   predicate(UseFMA);
12989   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
12990 
12991   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
12992 
12993   ins_encode %{
12994   // n.b. insn name should be fnmsubd
12995     __ fnmsub(as_FloatRegister($dst$$reg),
12996               as_FloatRegister($src1$$reg),
12997               as_FloatRegister($src2$$reg),
12998               as_FloatRegister($src3$$reg));
12999   %}
13000 
13001   ins_pipe(pipe_class_default);
13002 %}
13003 
13004 
13005 // Math.max(FF)F
13006 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13007   match(Set dst (MaxF src1 src2));
13008 
13009   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13010   ins_encode %{
13011     __ fmaxs(as_FloatRegister($dst$$reg),
13012              as_FloatRegister($src1$$reg),
13013              as_FloatRegister($src2$$reg));
13014   %}
13015 
13016   ins_pipe(fp_dop_reg_reg_s);
13017 %}
13018 
13019 // Math.min(FF)F
13020 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13021   match(Set dst (MinF src1 src2));
13022 
13023   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13024   ins_encode %{
13025     __ fmins(as_FloatRegister($dst$$reg),
13026              as_FloatRegister($src1$$reg),
13027              as_FloatRegister($src2$$reg));
13028   %}
13029 
13030   ins_pipe(fp_dop_reg_reg_s);
13031 %}
13032 
13033 // Math.max(DD)D
13034 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13035   match(Set dst (MaxD src1 src2));
13036 
13037   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13038   ins_encode %{
13039     __ fmaxd(as_FloatRegister($dst$$reg),
13040              as_FloatRegister($src1$$reg),
13041              as_FloatRegister($src2$$reg));
13042   %}
13043 
13044   ins_pipe(fp_dop_reg_reg_d);
13045 %}
13046 
13047 // Math.min(DD)D
13048 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13049   match(Set dst (MinD src1 src2));
13050 
13051   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13052   ins_encode %{
13053     __ fmind(as_FloatRegister($dst$$reg),
13054              as_FloatRegister($src1$$reg),
13055              as_FloatRegister($src2$$reg));
13056   %}
13057 
13058   ins_pipe(fp_dop_reg_reg_d);
13059 %}
13060 
13061 
13062 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13063   match(Set dst (DivF src1  src2));
13064 
13065   ins_cost(INSN_COST * 18);
13066   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13067 
13068   ins_encode %{
13069     __ fdivs(as_FloatRegister($dst$$reg),
13070              as_FloatRegister($src1$$reg),
13071              as_FloatRegister($src2$$reg));
13072   %}
13073 
13074   ins_pipe(fp_div_s);
13075 %}
13076 
13077 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13078   match(Set dst (DivD src1  src2));
13079 
13080   ins_cost(INSN_COST * 32);
13081   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13082 
13083   ins_encode %{
13084     __ fdivd(as_FloatRegister($dst$$reg),
13085              as_FloatRegister($src1$$reg),
13086              as_FloatRegister($src2$$reg));
13087   %}
13088 
13089   ins_pipe(fp_div_d);
13090 %}
13091 
13092 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13093   match(Set dst (NegF src));
13094 
13095   ins_cost(INSN_COST * 3);
13096   format %{ &quot;fneg   $dst, $src&quot; %}
13097 
13098   ins_encode %{
13099     __ fnegs(as_FloatRegister($dst$$reg),
13100              as_FloatRegister($src$$reg));
13101   %}
13102 
13103   ins_pipe(fp_uop_s);
13104 %}
13105 
13106 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13107   match(Set dst (NegD src));
13108 
13109   ins_cost(INSN_COST * 3);
13110   format %{ &quot;fnegd   $dst, $src&quot; %}
13111 
13112   ins_encode %{
13113     __ fnegd(as_FloatRegister($dst$$reg),
13114              as_FloatRegister($src$$reg));
13115   %}
13116 
13117   ins_pipe(fp_uop_d);
13118 %}
13119 
13120 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13121 %{
13122   match(Set dst (AbsI src));
13123 
13124   effect(KILL cr);
13125   ins_cost(INSN_COST * 2);
13126   format %{ &quot;cmpw  $src, zr\n\t&quot;
13127             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13128   %}
13129 
13130   ins_encode %{
13131     __ cmpw(as_Register($src$$reg), zr);
13132     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13133   %}
13134   ins_pipe(pipe_class_default);
13135 %}
13136 
13137 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13138 %{
13139   match(Set dst (AbsL src));
13140 
13141   effect(KILL cr);
13142   ins_cost(INSN_COST * 2);
13143   format %{ &quot;cmp  $src, zr\n\t&quot;
13144             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13145   %}
13146 
13147   ins_encode %{
13148     __ cmp(as_Register($src$$reg), zr);
13149     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13150   %}
13151   ins_pipe(pipe_class_default);
13152 %}
13153 
13154 instruct absF_reg(vRegF dst, vRegF src) %{
13155   match(Set dst (AbsF src));
13156 
13157   ins_cost(INSN_COST * 3);
13158   format %{ &quot;fabss   $dst, $src&quot; %}
13159   ins_encode %{
13160     __ fabss(as_FloatRegister($dst$$reg),
13161              as_FloatRegister($src$$reg));
13162   %}
13163 
13164   ins_pipe(fp_uop_s);
13165 %}
13166 
13167 instruct absD_reg(vRegD dst, vRegD src) %{
13168   match(Set dst (AbsD src));
13169 
13170   ins_cost(INSN_COST * 3);
13171   format %{ &quot;fabsd   $dst, $src&quot; %}
13172   ins_encode %{
13173     __ fabsd(as_FloatRegister($dst$$reg),
13174              as_FloatRegister($src$$reg));
13175   %}
13176 
13177   ins_pipe(fp_uop_d);
13178 %}
13179 
13180 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13181   match(Set dst (SqrtD src));
13182 
13183   ins_cost(INSN_COST * 50);
13184   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13185   ins_encode %{
13186     __ fsqrtd(as_FloatRegister($dst$$reg),
13187              as_FloatRegister($src$$reg));
13188   %}
13189 
13190   ins_pipe(fp_div_s);
13191 %}
13192 
13193 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13194   match(Set dst (SqrtF src));
13195 
13196   ins_cost(INSN_COST * 50);
13197   format %{ &quot;fsqrts  $dst, $src&quot; %}
13198   ins_encode %{
13199     __ fsqrts(as_FloatRegister($dst$$reg),
13200              as_FloatRegister($src$$reg));
13201   %}
13202 
13203   ins_pipe(fp_div_d);
13204 %}
13205 
13206 // Math.rint, floor, ceil
13207 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13208   match(Set dst (RoundDoubleMode src rmode));
13209   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13210   ins_encode %{
13211     switch ($rmode$$constant) {
13212       case RoundDoubleModeNode::rmode_rint:
13213         __ frintnd(as_FloatRegister($dst$$reg),
13214                    as_FloatRegister($src$$reg));
13215         break;
13216       case RoundDoubleModeNode::rmode_floor:
13217         __ frintmd(as_FloatRegister($dst$$reg),
13218                    as_FloatRegister($src$$reg));
13219         break;
13220       case RoundDoubleModeNode::rmode_ceil:
13221         __ frintpd(as_FloatRegister($dst$$reg),
13222                    as_FloatRegister($src$$reg));
13223         break;
13224     }
13225   %}
13226   ins_pipe(fp_uop_d);
13227 %}
13228 
13229 // ============================================================================
13230 // Logical Instructions
13231 
13232 // Integer Logical Instructions
13233 
13234 // And Instructions
13235 
13236 
13237 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13238   match(Set dst (AndI src1 src2));
13239 
13240   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13241 
13242   ins_cost(INSN_COST);
13243   ins_encode %{
13244     __ andw(as_Register($dst$$reg),
13245             as_Register($src1$$reg),
13246             as_Register($src2$$reg));
13247   %}
13248 
13249   ins_pipe(ialu_reg_reg);
13250 %}
13251 
13252 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13253   match(Set dst (AndI src1 src2));
13254 
13255   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13256 
13257   ins_cost(INSN_COST);
13258   ins_encode %{
13259     __ andw(as_Register($dst$$reg),
13260             as_Register($src1$$reg),
13261             (unsigned long)($src2$$constant));
13262   %}
13263 
13264   ins_pipe(ialu_reg_imm);
13265 %}
13266 
13267 // Or Instructions
13268 
13269 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13270   match(Set dst (OrI src1 src2));
13271 
13272   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13273 
13274   ins_cost(INSN_COST);
13275   ins_encode %{
13276     __ orrw(as_Register($dst$$reg),
13277             as_Register($src1$$reg),
13278             as_Register($src2$$reg));
13279   %}
13280 
13281   ins_pipe(ialu_reg_reg);
13282 %}
13283 
13284 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13285   match(Set dst (OrI src1 src2));
13286 
13287   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13288 
13289   ins_cost(INSN_COST);
13290   ins_encode %{
13291     __ orrw(as_Register($dst$$reg),
13292             as_Register($src1$$reg),
13293             (unsigned long)($src2$$constant));
13294   %}
13295 
13296   ins_pipe(ialu_reg_imm);
13297 %}
13298 
13299 // Xor Instructions
13300 
13301 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13302   match(Set dst (XorI src1 src2));
13303 
13304   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13305 
13306   ins_cost(INSN_COST);
13307   ins_encode %{
13308     __ eorw(as_Register($dst$$reg),
13309             as_Register($src1$$reg),
13310             as_Register($src2$$reg));
13311   %}
13312 
13313   ins_pipe(ialu_reg_reg);
13314 %}
13315 
13316 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13317   match(Set dst (XorI src1 src2));
13318 
13319   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13320 
13321   ins_cost(INSN_COST);
13322   ins_encode %{
13323     __ eorw(as_Register($dst$$reg),
13324             as_Register($src1$$reg),
13325             (unsigned long)($src2$$constant));
13326   %}
13327 
13328   ins_pipe(ialu_reg_imm);
13329 %}
13330 
13331 // Long Logical Instructions
13332 // TODO
13333 
13334 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13335   match(Set dst (AndL src1 src2));
13336 
13337   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13338 
13339   ins_cost(INSN_COST);
13340   ins_encode %{
13341     __ andr(as_Register($dst$$reg),
13342             as_Register($src1$$reg),
13343             as_Register($src2$$reg));
13344   %}
13345 
13346   ins_pipe(ialu_reg_reg);
13347 %}
13348 
13349 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13350   match(Set dst (AndL src1 src2));
13351 
13352   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13353 
13354   ins_cost(INSN_COST);
13355   ins_encode %{
13356     __ andr(as_Register($dst$$reg),
13357             as_Register($src1$$reg),
13358             (unsigned long)($src2$$constant));
13359   %}
13360 
13361   ins_pipe(ialu_reg_imm);
13362 %}
13363 
13364 // Or Instructions
13365 
13366 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13367   match(Set dst (OrL src1 src2));
13368 
13369   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13370 
13371   ins_cost(INSN_COST);
13372   ins_encode %{
13373     __ orr(as_Register($dst$$reg),
13374            as_Register($src1$$reg),
13375            as_Register($src2$$reg));
13376   %}
13377 
13378   ins_pipe(ialu_reg_reg);
13379 %}
13380 
13381 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13382   match(Set dst (OrL src1 src2));
13383 
13384   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13385 
13386   ins_cost(INSN_COST);
13387   ins_encode %{
13388     __ orr(as_Register($dst$$reg),
13389            as_Register($src1$$reg),
13390            (unsigned long)($src2$$constant));
13391   %}
13392 
13393   ins_pipe(ialu_reg_imm);
13394 %}
13395 
13396 // Xor Instructions
13397 
13398 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13399   match(Set dst (XorL src1 src2));
13400 
13401   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13402 
13403   ins_cost(INSN_COST);
13404   ins_encode %{
13405     __ eor(as_Register($dst$$reg),
13406            as_Register($src1$$reg),
13407            as_Register($src2$$reg));
13408   %}
13409 
13410   ins_pipe(ialu_reg_reg);
13411 %}
13412 
13413 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13414   match(Set dst (XorL src1 src2));
13415 
13416   ins_cost(INSN_COST);
13417   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13418 
13419   ins_encode %{
13420     __ eor(as_Register($dst$$reg),
13421            as_Register($src1$$reg),
13422            (unsigned long)($src2$$constant));
13423   %}
13424 
13425   ins_pipe(ialu_reg_imm);
13426 %}
13427 
13428 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13429 %{
13430   match(Set dst (ConvI2L src));
13431 
13432   ins_cost(INSN_COST);
13433   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13434   ins_encode %{
13435     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13436   %}
13437   ins_pipe(ialu_reg_shift);
13438 %}
13439 
13440 // this pattern occurs in bigmath arithmetic
13441 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13442 %{
13443   match(Set dst (AndL (ConvI2L src) mask));
13444 
13445   ins_cost(INSN_COST);
13446   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13447   ins_encode %{
13448     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13449   %}
13450 
13451   ins_pipe(ialu_reg_shift);
13452 %}
13453 
13454 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13455   match(Set dst (ConvL2I src));
13456 
13457   ins_cost(INSN_COST);
13458   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13459 
13460   ins_encode %{
13461     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13462   %}
13463 
13464   ins_pipe(ialu_reg);
13465 %}
13466 
13467 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13468 %{
13469   match(Set dst (Conv2B src));
13470   effect(KILL cr);
13471 
13472   format %{
13473     &quot;cmpw $src, zr\n\t&quot;
13474     &quot;cset $dst, ne&quot;
13475   %}
13476 
13477   ins_encode %{
13478     __ cmpw(as_Register($src$$reg), zr);
13479     __ cset(as_Register($dst$$reg), Assembler::NE);
13480   %}
13481 
13482   ins_pipe(ialu_reg);
13483 %}
13484 
13485 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13486 %{
13487   match(Set dst (Conv2B src));
13488   effect(KILL cr);
13489 
13490   format %{
13491     &quot;cmp  $src, zr\n\t&quot;
13492     &quot;cset $dst, ne&quot;
13493   %}
13494 
13495   ins_encode %{
13496     __ cmp(as_Register($src$$reg), zr);
13497     __ cset(as_Register($dst$$reg), Assembler::NE);
13498   %}
13499 
13500   ins_pipe(ialu_reg);
13501 %}
13502 
13503 instruct convD2F_reg(vRegF dst, vRegD src) %{
13504   match(Set dst (ConvD2F src));
13505 
13506   ins_cost(INSN_COST * 5);
13507   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13508 
13509   ins_encode %{
13510     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13511   %}
13512 
13513   ins_pipe(fp_d2f);
13514 %}
13515 
13516 instruct convF2D_reg(vRegD dst, vRegF src) %{
13517   match(Set dst (ConvF2D src));
13518 
13519   ins_cost(INSN_COST * 5);
13520   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13521 
13522   ins_encode %{
13523     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13524   %}
13525 
13526   ins_pipe(fp_f2d);
13527 %}
13528 
13529 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13530   match(Set dst (ConvF2I src));
13531 
13532   ins_cost(INSN_COST * 5);
13533   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13534 
13535   ins_encode %{
13536     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13537   %}
13538 
13539   ins_pipe(fp_f2i);
13540 %}
13541 
13542 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13543   match(Set dst (ConvF2L src));
13544 
13545   ins_cost(INSN_COST * 5);
13546   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13547 
13548   ins_encode %{
13549     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13550   %}
13551 
13552   ins_pipe(fp_f2l);
13553 %}
13554 
13555 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13556   match(Set dst (ConvI2F src));
13557 
13558   ins_cost(INSN_COST * 5);
13559   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13560 
13561   ins_encode %{
13562     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13563   %}
13564 
13565   ins_pipe(fp_i2f);
13566 %}
13567 
13568 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13569   match(Set dst (ConvL2F src));
13570 
13571   ins_cost(INSN_COST * 5);
13572   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13573 
13574   ins_encode %{
13575     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13576   %}
13577 
13578   ins_pipe(fp_l2f);
13579 %}
13580 
13581 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13582   match(Set dst (ConvD2I src));
13583 
13584   ins_cost(INSN_COST * 5);
13585   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13586 
13587   ins_encode %{
13588     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13589   %}
13590 
13591   ins_pipe(fp_d2i);
13592 %}
13593 
13594 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13595   match(Set dst (ConvD2L src));
13596 
13597   ins_cost(INSN_COST * 5);
13598   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13599 
13600   ins_encode %{
13601     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13602   %}
13603 
13604   ins_pipe(fp_d2l);
13605 %}
13606 
13607 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13608   match(Set dst (ConvI2D src));
13609 
13610   ins_cost(INSN_COST * 5);
13611   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13612 
13613   ins_encode %{
13614     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13615   %}
13616 
13617   ins_pipe(fp_i2d);
13618 %}
13619 
13620 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13621   match(Set dst (ConvL2D src));
13622 
13623   ins_cost(INSN_COST * 5);
13624   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13625 
13626   ins_encode %{
13627     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13628   %}
13629 
13630   ins_pipe(fp_l2d);
13631 %}
13632 
13633 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13634 
13635 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13636 
13637   match(Set dst (MoveF2I src));
13638 
13639   effect(DEF dst, USE src);
13640 
13641   ins_cost(4 * INSN_COST);
13642 
13643   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13644 
13645   ins_encode %{
13646     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13647   %}
13648 
13649   ins_pipe(iload_reg_reg);
13650 
13651 %}
13652 
13653 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13654 
13655   match(Set dst (MoveI2F src));
13656 
13657   effect(DEF dst, USE src);
13658 
13659   ins_cost(4 * INSN_COST);
13660 
13661   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13662 
13663   ins_encode %{
13664     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13665   %}
13666 
13667   ins_pipe(pipe_class_memory);
13668 
13669 %}
13670 
13671 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13672 
13673   match(Set dst (MoveD2L src));
13674 
13675   effect(DEF dst, USE src);
13676 
13677   ins_cost(4 * INSN_COST);
13678 
13679   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13680 
13681   ins_encode %{
13682     __ ldr($dst$$Register, Address(sp, $src$$disp));
13683   %}
13684 
13685   ins_pipe(iload_reg_reg);
13686 
13687 %}
13688 
13689 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13690 
13691   match(Set dst (MoveL2D src));
13692 
13693   effect(DEF dst, USE src);
13694 
13695   ins_cost(4 * INSN_COST);
13696 
13697   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13698 
13699   ins_encode %{
13700     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13701   %}
13702 
13703   ins_pipe(pipe_class_memory);
13704 
13705 %}
13706 
13707 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13708 
13709   match(Set dst (MoveF2I src));
13710 
13711   effect(DEF dst, USE src);
13712 
13713   ins_cost(INSN_COST);
13714 
13715   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13716 
13717   ins_encode %{
13718     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13719   %}
13720 
13721   ins_pipe(pipe_class_memory);
13722 
13723 %}
13724 
13725 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13726 
13727   match(Set dst (MoveI2F src));
13728 
13729   effect(DEF dst, USE src);
13730 
13731   ins_cost(INSN_COST);
13732 
13733   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13734 
13735   ins_encode %{
13736     __ strw($src$$Register, Address(sp, $dst$$disp));
13737   %}
13738 
13739   ins_pipe(istore_reg_reg);
13740 
13741 %}
13742 
13743 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13744 
13745   match(Set dst (MoveD2L src));
13746 
13747   effect(DEF dst, USE src);
13748 
13749   ins_cost(INSN_COST);
13750 
13751   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13752 
13753   ins_encode %{
13754     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13755   %}
13756 
13757   ins_pipe(pipe_class_memory);
13758 
13759 %}
13760 
13761 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13762 
13763   match(Set dst (MoveL2D src));
13764 
13765   effect(DEF dst, USE src);
13766 
13767   ins_cost(INSN_COST);
13768 
13769   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13770 
13771   ins_encode %{
13772     __ str($src$$Register, Address(sp, $dst$$disp));
13773   %}
13774 
13775   ins_pipe(istore_reg_reg);
13776 
13777 %}
13778 
13779 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13780 
13781   match(Set dst (MoveF2I src));
13782 
13783   effect(DEF dst, USE src);
13784 
13785   ins_cost(INSN_COST);
13786 
13787   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13788 
13789   ins_encode %{
13790     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13791   %}
13792 
13793   ins_pipe(fp_f2i);
13794 
13795 %}
13796 
13797 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13798 
13799   match(Set dst (MoveI2F src));
13800 
13801   effect(DEF dst, USE src);
13802 
13803   ins_cost(INSN_COST);
13804 
13805   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13806 
13807   ins_encode %{
13808     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13809   %}
13810 
13811   ins_pipe(fp_i2f);
13812 
13813 %}
13814 
13815 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13816 
13817   match(Set dst (MoveD2L src));
13818 
13819   effect(DEF dst, USE src);
13820 
13821   ins_cost(INSN_COST);
13822 
13823   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13824 
13825   ins_encode %{
13826     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13827   %}
13828 
13829   ins_pipe(fp_d2l);
13830 
13831 %}
13832 
13833 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13834 
13835   match(Set dst (MoveL2D src));
13836 
13837   effect(DEF dst, USE src);
13838 
13839   ins_cost(INSN_COST);
13840 
13841   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13842 
13843   ins_encode %{
13844     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13845   %}
13846 
13847   ins_pipe(fp_l2d);
13848 
13849 %}
13850 
13851 // ============================================================================
13852 // clearing of an array
13853 
13854 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13855 %{
13856   match(Set dummy (ClearArray cnt base));
13857   effect(USE_KILL cnt, USE_KILL base, KILL cr);
13858 
13859   ins_cost(4 * INSN_COST);
13860   format %{ &quot;ClearArray $cnt, $base&quot; %}
13861 
13862   ins_encode %{
13863     __ zero_words($base$$Register, $cnt$$Register);
13864   %}
13865 
13866   ins_pipe(pipe_class_memory);
13867 %}
13868 
13869 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13870 %{
<a name="9" id="anc9"></a><span class="line-modified">13871   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()</span>
<span class="line-modified">13872             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));</span>
13873   match(Set dummy (ClearArray cnt base));
13874   effect(USE_KILL base);
13875 
13876   ins_cost(4 * INSN_COST);
13877   format %{ &quot;ClearArray $cnt, $base&quot; %}
13878 
13879   ins_encode %{
<a name="10" id="anc10"></a><span class="line-modified">13880     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);</span>
13881   %}
13882 
13883   ins_pipe(pipe_class_memory);
13884 %}
13885 
13886 // ============================================================================
13887 // Overflow Math Instructions
13888 
13889 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13890 %{
13891   match(Set cr (OverflowAddI op1 op2));
13892 
13893   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13894   ins_cost(INSN_COST);
13895   ins_encode %{
13896     __ cmnw($op1$$Register, $op2$$Register);
13897   %}
13898 
13899   ins_pipe(icmp_reg_reg);
13900 %}
13901 
13902 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13903 %{
13904   match(Set cr (OverflowAddI op1 op2));
13905 
13906   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13907   ins_cost(INSN_COST);
13908   ins_encode %{
13909     __ cmnw($op1$$Register, $op2$$constant);
13910   %}
13911 
13912   ins_pipe(icmp_reg_imm);
13913 %}
13914 
13915 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13916 %{
13917   match(Set cr (OverflowAddL op1 op2));
13918 
13919   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13920   ins_cost(INSN_COST);
13921   ins_encode %{
13922     __ cmn($op1$$Register, $op2$$Register);
13923   %}
13924 
13925   ins_pipe(icmp_reg_reg);
13926 %}
13927 
13928 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13929 %{
13930   match(Set cr (OverflowAddL op1 op2));
13931 
13932   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13933   ins_cost(INSN_COST);
13934   ins_encode %{
13935     __ cmn($op1$$Register, $op2$$constant);
13936   %}
13937 
13938   ins_pipe(icmp_reg_imm);
13939 %}
13940 
13941 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13942 %{
13943   match(Set cr (OverflowSubI op1 op2));
13944 
13945   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13946   ins_cost(INSN_COST);
13947   ins_encode %{
13948     __ cmpw($op1$$Register, $op2$$Register);
13949   %}
13950 
13951   ins_pipe(icmp_reg_reg);
13952 %}
13953 
13954 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13955 %{
13956   match(Set cr (OverflowSubI op1 op2));
13957 
13958   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13959   ins_cost(INSN_COST);
13960   ins_encode %{
13961     __ cmpw($op1$$Register, $op2$$constant);
13962   %}
13963 
13964   ins_pipe(icmp_reg_imm);
13965 %}
13966 
13967 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13968 %{
13969   match(Set cr (OverflowSubL op1 op2));
13970 
13971   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13972   ins_cost(INSN_COST);
13973   ins_encode %{
13974     __ cmp($op1$$Register, $op2$$Register);
13975   %}
13976 
13977   ins_pipe(icmp_reg_reg);
13978 %}
13979 
13980 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13981 %{
13982   match(Set cr (OverflowSubL op1 op2));
13983 
13984   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13985   ins_cost(INSN_COST);
13986   ins_encode %{
13987     __ subs(zr, $op1$$Register, $op2$$constant);
13988   %}
13989 
13990   ins_pipe(icmp_reg_imm);
13991 %}
13992 
13993 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
13994 %{
13995   match(Set cr (OverflowSubI zero op1));
13996 
13997   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
13998   ins_cost(INSN_COST);
13999   ins_encode %{
14000     __ cmpw(zr, $op1$$Register);
14001   %}
14002 
14003   ins_pipe(icmp_reg_imm);
14004 %}
14005 
14006 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14007 %{
14008   match(Set cr (OverflowSubL zero op1));
14009 
14010   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14011   ins_cost(INSN_COST);
14012   ins_encode %{
14013     __ cmp(zr, $op1$$Register);
14014   %}
14015 
14016   ins_pipe(icmp_reg_imm);
14017 %}
14018 
14019 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14020 %{
14021   match(Set cr (OverflowMulI op1 op2));
14022 
14023   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14024             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14025             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14026             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14027             &quot;cmpw  rscratch1, #1&quot; %}
14028   ins_cost(5 * INSN_COST);
14029   ins_encode %{
14030     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14031     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14032     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14033     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14034     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14035   %}
14036 
14037   ins_pipe(pipe_slow);
14038 %}
14039 
14040 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14041 %{
14042   match(If cmp (OverflowMulI op1 op2));
14043   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14044             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14045   effect(USE labl, KILL cr);
14046 
14047   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14048             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14049             &quot;b$cmp   $labl&quot; %}
14050   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14051   ins_encode %{
14052     Label* L = $labl$$label;
14053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14054     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14055     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14056     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14057   %}
14058 
14059   ins_pipe(pipe_serial);
14060 %}
14061 
14062 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14063 %{
14064   match(Set cr (OverflowMulL op1 op2));
14065 
14066   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14067             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14068             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14069             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14070             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14071             &quot;cmpw  rscratch1, #1&quot; %}
14072   ins_cost(6 * INSN_COST);
14073   ins_encode %{
14074     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14075     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14076     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14077     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14078     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14079     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14080   %}
14081 
14082   ins_pipe(pipe_slow);
14083 %}
14084 
14085 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14086 %{
14087   match(If cmp (OverflowMulL op1 op2));
14088   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14089             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14090   effect(USE labl, KILL cr);
14091 
14092   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14093             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14094             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14095             &quot;b$cmp $labl&quot; %}
14096   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14097   ins_encode %{
14098     Label* L = $labl$$label;
14099     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14100     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14101     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14102     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14103     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14104   %}
14105 
14106   ins_pipe(pipe_serial);
14107 %}
14108 
14109 // ============================================================================
14110 // Compare Instructions
14111 
14112 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14113 %{
14114   match(Set cr (CmpI op1 op2));
14115 
14116   effect(DEF cr, USE op1, USE op2);
14117 
14118   ins_cost(INSN_COST);
14119   format %{ &quot;cmpw  $op1, $op2&quot; %}
14120 
14121   ins_encode(aarch64_enc_cmpw(op1, op2));
14122 
14123   ins_pipe(icmp_reg_reg);
14124 %}
14125 
14126 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14127 %{
14128   match(Set cr (CmpI op1 zero));
14129 
14130   effect(DEF cr, USE op1);
14131 
14132   ins_cost(INSN_COST);
14133   format %{ &quot;cmpw $op1, 0&quot; %}
14134 
14135   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14136 
14137   ins_pipe(icmp_reg_imm);
14138 %}
14139 
14140 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14141 %{
14142   match(Set cr (CmpI op1 op2));
14143 
14144   effect(DEF cr, USE op1);
14145 
14146   ins_cost(INSN_COST);
14147   format %{ &quot;cmpw  $op1, $op2&quot; %}
14148 
14149   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14150 
14151   ins_pipe(icmp_reg_imm);
14152 %}
14153 
14154 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14155 %{
14156   match(Set cr (CmpI op1 op2));
14157 
14158   effect(DEF cr, USE op1);
14159 
14160   ins_cost(INSN_COST * 2);
14161   format %{ &quot;cmpw  $op1, $op2&quot; %}
14162 
14163   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14164 
14165   ins_pipe(icmp_reg_imm);
14166 %}
14167 
14168 // Unsigned compare Instructions; really, same as signed compare
14169 // except it should only be used to feed an If or a CMovI which takes a
14170 // cmpOpU.
14171 
14172 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14173 %{
14174   match(Set cr (CmpU op1 op2));
14175 
14176   effect(DEF cr, USE op1, USE op2);
14177 
14178   ins_cost(INSN_COST);
14179   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14180 
14181   ins_encode(aarch64_enc_cmpw(op1, op2));
14182 
14183   ins_pipe(icmp_reg_reg);
14184 %}
14185 
14186 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14187 %{
14188   match(Set cr (CmpU op1 zero));
14189 
14190   effect(DEF cr, USE op1);
14191 
14192   ins_cost(INSN_COST);
14193   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14194 
14195   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14196 
14197   ins_pipe(icmp_reg_imm);
14198 %}
14199 
14200 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14201 %{
14202   match(Set cr (CmpU op1 op2));
14203 
14204   effect(DEF cr, USE op1);
14205 
14206   ins_cost(INSN_COST);
14207   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14208 
14209   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14210 
14211   ins_pipe(icmp_reg_imm);
14212 %}
14213 
14214 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14215 %{
14216   match(Set cr (CmpU op1 op2));
14217 
14218   effect(DEF cr, USE op1);
14219 
14220   ins_cost(INSN_COST * 2);
14221   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14222 
14223   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14224 
14225   ins_pipe(icmp_reg_imm);
14226 %}
14227 
14228 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14229 %{
14230   match(Set cr (CmpL op1 op2));
14231 
14232   effect(DEF cr, USE op1, USE op2);
14233 
14234   ins_cost(INSN_COST);
14235   format %{ &quot;cmp  $op1, $op2&quot; %}
14236 
14237   ins_encode(aarch64_enc_cmp(op1, op2));
14238 
14239   ins_pipe(icmp_reg_reg);
14240 %}
14241 
14242 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14243 %{
14244   match(Set cr (CmpL op1 zero));
14245 
14246   effect(DEF cr, USE op1);
14247 
14248   ins_cost(INSN_COST);
14249   format %{ &quot;tst  $op1&quot; %}
14250 
14251   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14252 
14253   ins_pipe(icmp_reg_imm);
14254 %}
14255 
14256 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14257 %{
14258   match(Set cr (CmpL op1 op2));
14259 
14260   effect(DEF cr, USE op1);
14261 
14262   ins_cost(INSN_COST);
14263   format %{ &quot;cmp  $op1, $op2&quot; %}
14264 
14265   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14266 
14267   ins_pipe(icmp_reg_imm);
14268 %}
14269 
14270 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14271 %{
14272   match(Set cr (CmpL op1 op2));
14273 
14274   effect(DEF cr, USE op1);
14275 
14276   ins_cost(INSN_COST * 2);
14277   format %{ &quot;cmp  $op1, $op2&quot; %}
14278 
14279   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14280 
14281   ins_pipe(icmp_reg_imm);
14282 %}
14283 
14284 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14285 %{
14286   match(Set cr (CmpUL op1 op2));
14287 
14288   effect(DEF cr, USE op1, USE op2);
14289 
14290   ins_cost(INSN_COST);
14291   format %{ &quot;cmp  $op1, $op2&quot; %}
14292 
14293   ins_encode(aarch64_enc_cmp(op1, op2));
14294 
14295   ins_pipe(icmp_reg_reg);
14296 %}
14297 
14298 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14299 %{
14300   match(Set cr (CmpUL op1 zero));
14301 
14302   effect(DEF cr, USE op1);
14303 
14304   ins_cost(INSN_COST);
14305   format %{ &quot;tst  $op1&quot; %}
14306 
14307   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14308 
14309   ins_pipe(icmp_reg_imm);
14310 %}
14311 
14312 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14313 %{
14314   match(Set cr (CmpUL op1 op2));
14315 
14316   effect(DEF cr, USE op1);
14317 
14318   ins_cost(INSN_COST);
14319   format %{ &quot;cmp  $op1, $op2&quot; %}
14320 
14321   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14322 
14323   ins_pipe(icmp_reg_imm);
14324 %}
14325 
14326 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14327 %{
14328   match(Set cr (CmpUL op1 op2));
14329 
14330   effect(DEF cr, USE op1);
14331 
14332   ins_cost(INSN_COST * 2);
14333   format %{ &quot;cmp  $op1, $op2&quot; %}
14334 
14335   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14336 
14337   ins_pipe(icmp_reg_imm);
14338 %}
14339 
14340 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14341 %{
14342   match(Set cr (CmpP op1 op2));
14343 
14344   effect(DEF cr, USE op1, USE op2);
14345 
14346   ins_cost(INSN_COST);
14347   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14348 
14349   ins_encode(aarch64_enc_cmpp(op1, op2));
14350 
14351   ins_pipe(icmp_reg_reg);
14352 %}
14353 
14354 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14355 %{
14356   match(Set cr (CmpN op1 op2));
14357 
14358   effect(DEF cr, USE op1, USE op2);
14359 
14360   ins_cost(INSN_COST);
14361   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14362 
14363   ins_encode(aarch64_enc_cmpn(op1, op2));
14364 
14365   ins_pipe(icmp_reg_reg);
14366 %}
14367 
14368 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14369 %{
14370   match(Set cr (CmpP op1 zero));
14371 
14372   effect(DEF cr, USE op1, USE zero);
14373 
14374   ins_cost(INSN_COST);
14375   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14376 
14377   ins_encode(aarch64_enc_testp(op1));
14378 
14379   ins_pipe(icmp_reg_imm);
14380 %}
14381 
14382 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14383 %{
14384   match(Set cr (CmpN op1 zero));
14385 
14386   effect(DEF cr, USE op1, USE zero);
14387 
14388   ins_cost(INSN_COST);
14389   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14390 
14391   ins_encode(aarch64_enc_testn(op1));
14392 
14393   ins_pipe(icmp_reg_imm);
14394 %}
14395 
14396 // FP comparisons
14397 //
14398 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14399 // using normal cmpOp. See declaration of rFlagsReg for details.
14400 
14401 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14402 %{
14403   match(Set cr (CmpF src1 src2));
14404 
14405   ins_cost(3 * INSN_COST);
14406   format %{ &quot;fcmps $src1, $src2&quot; %}
14407 
14408   ins_encode %{
14409     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14410   %}
14411 
14412   ins_pipe(pipe_class_compare);
14413 %}
14414 
14415 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14416 %{
14417   match(Set cr (CmpF src1 src2));
14418 
14419   ins_cost(3 * INSN_COST);
14420   format %{ &quot;fcmps $src1, 0.0&quot; %}
14421 
14422   ins_encode %{
14423     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14424   %}
14425 
14426   ins_pipe(pipe_class_compare);
14427 %}
14428 // FROM HERE
14429 
14430 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14431 %{
14432   match(Set cr (CmpD src1 src2));
14433 
14434   ins_cost(3 * INSN_COST);
14435   format %{ &quot;fcmpd $src1, $src2&quot; %}
14436 
14437   ins_encode %{
14438     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14439   %}
14440 
14441   ins_pipe(pipe_class_compare);
14442 %}
14443 
14444 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14445 %{
14446   match(Set cr (CmpD src1 src2));
14447 
14448   ins_cost(3 * INSN_COST);
14449   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14450 
14451   ins_encode %{
14452     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14453   %}
14454 
14455   ins_pipe(pipe_class_compare);
14456 %}
14457 
14458 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14459 %{
14460   match(Set dst (CmpF3 src1 src2));
14461   effect(KILL cr);
14462 
14463   ins_cost(5 * INSN_COST);
14464   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14465             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14466             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14467   %}
14468 
14469   ins_encode %{
14470     Label done;
14471     FloatRegister s1 = as_FloatRegister($src1$$reg);
14472     FloatRegister s2 = as_FloatRegister($src2$$reg);
14473     Register d = as_Register($dst$$reg);
14474     __ fcmps(s1, s2);
14475     // installs 0 if EQ else -1
14476     __ csinvw(d, zr, zr, Assembler::EQ);
14477     // keeps -1 if less or unordered else installs 1
14478     __ csnegw(d, d, d, Assembler::LT);
14479     __ bind(done);
14480   %}
14481 
14482   ins_pipe(pipe_class_default);
14483 
14484 %}
14485 
14486 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14487 %{
14488   match(Set dst (CmpD3 src1 src2));
14489   effect(KILL cr);
14490 
14491   ins_cost(5 * INSN_COST);
14492   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14493             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14494             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14495   %}
14496 
14497   ins_encode %{
14498     Label done;
14499     FloatRegister s1 = as_FloatRegister($src1$$reg);
14500     FloatRegister s2 = as_FloatRegister($src2$$reg);
14501     Register d = as_Register($dst$$reg);
14502     __ fcmpd(s1, s2);
14503     // installs 0 if EQ else -1
14504     __ csinvw(d, zr, zr, Assembler::EQ);
14505     // keeps -1 if less or unordered else installs 1
14506     __ csnegw(d, d, d, Assembler::LT);
14507     __ bind(done);
14508   %}
14509   ins_pipe(pipe_class_default);
14510 
14511 %}
14512 
14513 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14514 %{
14515   match(Set dst (CmpF3 src1 zero));
14516   effect(KILL cr);
14517 
14518   ins_cost(5 * INSN_COST);
14519   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14520             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14521             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14522   %}
14523 
14524   ins_encode %{
14525     Label done;
14526     FloatRegister s1 = as_FloatRegister($src1$$reg);
14527     Register d = as_Register($dst$$reg);
14528     __ fcmps(s1, 0.0);
14529     // installs 0 if EQ else -1
14530     __ csinvw(d, zr, zr, Assembler::EQ);
14531     // keeps -1 if less or unordered else installs 1
14532     __ csnegw(d, d, d, Assembler::LT);
14533     __ bind(done);
14534   %}
14535 
14536   ins_pipe(pipe_class_default);
14537 
14538 %}
14539 
14540 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14541 %{
14542   match(Set dst (CmpD3 src1 zero));
14543   effect(KILL cr);
14544 
14545   ins_cost(5 * INSN_COST);
14546   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14547             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14548             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14549   %}
14550 
14551   ins_encode %{
14552     Label done;
14553     FloatRegister s1 = as_FloatRegister($src1$$reg);
14554     Register d = as_Register($dst$$reg);
14555     __ fcmpd(s1, 0.0);
14556     // installs 0 if EQ else -1
14557     __ csinvw(d, zr, zr, Assembler::EQ);
14558     // keeps -1 if less or unordered else installs 1
14559     __ csnegw(d, d, d, Assembler::LT);
14560     __ bind(done);
14561   %}
14562   ins_pipe(pipe_class_default);
14563 
14564 %}
14565 
14566 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14567 %{
14568   match(Set dst (CmpLTMask p q));
14569   effect(KILL cr);
14570 
14571   ins_cost(3 * INSN_COST);
14572 
14573   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14574             &quot;csetw $dst, lt\n\t&quot;
14575             &quot;subw $dst, zr, $dst&quot;
14576   %}
14577 
14578   ins_encode %{
14579     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14580     __ csetw(as_Register($dst$$reg), Assembler::LT);
14581     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14582   %}
14583 
14584   ins_pipe(ialu_reg_reg);
14585 %}
14586 
14587 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14588 %{
14589   match(Set dst (CmpLTMask src zero));
14590   effect(KILL cr);
14591 
14592   ins_cost(INSN_COST);
14593 
14594   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14595 
14596   ins_encode %{
14597     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14598   %}
14599 
14600   ins_pipe(ialu_reg_shift);
14601 %}
14602 
14603 // ============================================================================
14604 // Max and Min
14605 
14606 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14607 %{
14608   effect( DEF dst, USE src1, USE src2, USE cr );
14609 
14610   ins_cost(INSN_COST * 2);
14611   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14612 
14613   ins_encode %{
14614     __ cselw(as_Register($dst$$reg),
14615              as_Register($src1$$reg),
14616              as_Register($src2$$reg),
14617              Assembler::LT);
14618   %}
14619 
14620   ins_pipe(icond_reg_reg);
14621 %}
14622 
14623 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14624 %{
14625   match(Set dst (MinI src1 src2));
14626   ins_cost(INSN_COST * 3);
14627 
14628   expand %{
14629     rFlagsReg cr;
14630     compI_reg_reg(cr, src1, src2);
14631     cmovI_reg_reg_lt(dst, src1, src2, cr);
14632   %}
14633 
14634 %}
14635 // FROM HERE
14636 
14637 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14638 %{
14639   effect( DEF dst, USE src1, USE src2, USE cr );
14640 
14641   ins_cost(INSN_COST * 2);
14642   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14643 
14644   ins_encode %{
14645     __ cselw(as_Register($dst$$reg),
14646              as_Register($src1$$reg),
14647              as_Register($src2$$reg),
14648              Assembler::GT);
14649   %}
14650 
14651   ins_pipe(icond_reg_reg);
14652 %}
14653 
14654 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14655 %{
14656   match(Set dst (MaxI src1 src2));
14657   ins_cost(INSN_COST * 3);
14658   expand %{
14659     rFlagsReg cr;
14660     compI_reg_reg(cr, src1, src2);
14661     cmovI_reg_reg_gt(dst, src1, src2, cr);
14662   %}
14663 %}
14664 
14665 // ============================================================================
14666 // Branch Instructions
14667 
14668 // Direct Branch.
14669 instruct branch(label lbl)
14670 %{
14671   match(Goto);
14672 
14673   effect(USE lbl);
14674 
14675   ins_cost(BRANCH_COST);
14676   format %{ &quot;b  $lbl&quot; %}
14677 
14678   ins_encode(aarch64_enc_b(lbl));
14679 
14680   ins_pipe(pipe_branch);
14681 %}
14682 
14683 // Conditional Near Branch
14684 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14685 %{
14686   // Same match rule as `branchConFar&#39;.
14687   match(If cmp cr);
14688 
14689   effect(USE lbl);
14690 
14691   ins_cost(BRANCH_COST);
14692   // If set to 1 this indicates that the current instruction is a
14693   // short variant of a long branch. This avoids using this
14694   // instruction in first-pass matching. It will then only be used in
14695   // the `Shorten_branches&#39; pass.
14696   // ins_short_branch(1);
14697   format %{ &quot;b$cmp  $lbl&quot; %}
14698 
14699   ins_encode(aarch64_enc_br_con(cmp, lbl));
14700 
14701   ins_pipe(pipe_branch_cond);
14702 %}
14703 
14704 // Conditional Near Branch Unsigned
14705 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14706 %{
14707   // Same match rule as `branchConFar&#39;.
14708   match(If cmp cr);
14709 
14710   effect(USE lbl);
14711 
14712   ins_cost(BRANCH_COST);
14713   // If set to 1 this indicates that the current instruction is a
14714   // short variant of a long branch. This avoids using this
14715   // instruction in first-pass matching. It will then only be used in
14716   // the `Shorten_branches&#39; pass.
14717   // ins_short_branch(1);
14718   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14719 
14720   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14721 
14722   ins_pipe(pipe_branch_cond);
14723 %}
14724 
14725 // Make use of CBZ and CBNZ.  These instructions, as well as being
14726 // shorter than (cmp; branch), have the additional benefit of not
14727 // killing the flags.
14728 
14729 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14730   match(If cmp (CmpI op1 op2));
14731   effect(USE labl);
14732 
14733   ins_cost(BRANCH_COST);
14734   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14735   ins_encode %{
14736     Label* L = $labl$$label;
14737     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14738     if (cond == Assembler::EQ)
14739       __ cbzw($op1$$Register, *L);
14740     else
14741       __ cbnzw($op1$$Register, *L);
14742   %}
14743   ins_pipe(pipe_cmp_branch);
14744 %}
14745 
14746 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14747   match(If cmp (CmpL op1 op2));
14748   effect(USE labl);
14749 
14750   ins_cost(BRANCH_COST);
14751   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14752   ins_encode %{
14753     Label* L = $labl$$label;
14754     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14755     if (cond == Assembler::EQ)
14756       __ cbz($op1$$Register, *L);
14757     else
14758       __ cbnz($op1$$Register, *L);
14759   %}
14760   ins_pipe(pipe_cmp_branch);
14761 %}
14762 
14763 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14764   match(If cmp (CmpP op1 op2));
14765   effect(USE labl);
14766 
14767   ins_cost(BRANCH_COST);
14768   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14769   ins_encode %{
14770     Label* L = $labl$$label;
14771     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14772     if (cond == Assembler::EQ)
14773       __ cbz($op1$$Register, *L);
14774     else
14775       __ cbnz($op1$$Register, *L);
14776   %}
14777   ins_pipe(pipe_cmp_branch);
14778 %}
14779 
14780 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14781   match(If cmp (CmpN op1 op2));
14782   effect(USE labl);
14783 
14784   ins_cost(BRANCH_COST);
14785   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14786   ins_encode %{
14787     Label* L = $labl$$label;
14788     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14789     if (cond == Assembler::EQ)
14790       __ cbzw($op1$$Register, *L);
14791     else
14792       __ cbnzw($op1$$Register, *L);
14793   %}
14794   ins_pipe(pipe_cmp_branch);
14795 %}
14796 
14797 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14798   match(If cmp (CmpP (DecodeN oop) zero));
14799   effect(USE labl);
14800 
14801   ins_cost(BRANCH_COST);
14802   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14803   ins_encode %{
14804     Label* L = $labl$$label;
14805     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14806     if (cond == Assembler::EQ)
14807       __ cbzw($oop$$Register, *L);
14808     else
14809       __ cbnzw($oop$$Register, *L);
14810   %}
14811   ins_pipe(pipe_cmp_branch);
14812 %}
14813 
14814 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14815   match(If cmp (CmpU op1 op2));
14816   effect(USE labl);
14817 
14818   ins_cost(BRANCH_COST);
14819   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14820   ins_encode %{
14821     Label* L = $labl$$label;
14822     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14823     if (cond == Assembler::EQ || cond == Assembler::LS)
14824       __ cbzw($op1$$Register, *L);
14825     else
14826       __ cbnzw($op1$$Register, *L);
14827   %}
14828   ins_pipe(pipe_cmp_branch);
14829 %}
14830 
14831 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14832   match(If cmp (CmpUL op1 op2));
14833   effect(USE labl);
14834 
14835   ins_cost(BRANCH_COST);
14836   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14837   ins_encode %{
14838     Label* L = $labl$$label;
14839     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14840     if (cond == Assembler::EQ || cond == Assembler::LS)
14841       __ cbz($op1$$Register, *L);
14842     else
14843       __ cbnz($op1$$Register, *L);
14844   %}
14845   ins_pipe(pipe_cmp_branch);
14846 %}
14847 
14848 // Test bit and Branch
14849 
14850 // Patterns for short (&lt; 32KiB) variants
14851 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14852   match(If cmp (CmpL op1 op2));
14853   effect(USE labl);
14854 
14855   ins_cost(BRANCH_COST);
14856   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14857   ins_encode %{
14858     Label* L = $labl$$label;
14859     Assembler::Condition cond =
14860       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14861     __ tbr(cond, $op1$$Register, 63, *L);
14862   %}
14863   ins_pipe(pipe_cmp_branch);
14864   ins_short_branch(1);
14865 %}
14866 
14867 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14868   match(If cmp (CmpI op1 op2));
14869   effect(USE labl);
14870 
14871   ins_cost(BRANCH_COST);
14872   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14873   ins_encode %{
14874     Label* L = $labl$$label;
14875     Assembler::Condition cond =
14876       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14877     __ tbr(cond, $op1$$Register, 31, *L);
14878   %}
14879   ins_pipe(pipe_cmp_branch);
14880   ins_short_branch(1);
14881 %}
14882 
14883 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14884   match(If cmp (CmpL (AndL op1 op2) op3));
14885   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14886   effect(USE labl);
14887 
14888   ins_cost(BRANCH_COST);
14889   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14890   ins_encode %{
14891     Label* L = $labl$$label;
14892     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14893     int bit = exact_log2_long($op2$$constant);
14894     __ tbr(cond, $op1$$Register, bit, *L);
14895   %}
14896   ins_pipe(pipe_cmp_branch);
14897   ins_short_branch(1);
14898 %}
14899 
14900 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14901   match(If cmp (CmpI (AndI op1 op2) op3));
14902   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14903   effect(USE labl);
14904 
14905   ins_cost(BRANCH_COST);
14906   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14907   ins_encode %{
14908     Label* L = $labl$$label;
14909     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14910     int bit = exact_log2((juint)$op2$$constant);
14911     __ tbr(cond, $op1$$Register, bit, *L);
14912   %}
14913   ins_pipe(pipe_cmp_branch);
14914   ins_short_branch(1);
14915 %}
14916 
14917 // And far variants
14918 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14919   match(If cmp (CmpL op1 op2));
14920   effect(USE labl);
14921 
14922   ins_cost(BRANCH_COST);
14923   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14924   ins_encode %{
14925     Label* L = $labl$$label;
14926     Assembler::Condition cond =
14927       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14928     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14929   %}
14930   ins_pipe(pipe_cmp_branch);
14931 %}
14932 
14933 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14934   match(If cmp (CmpI op1 op2));
14935   effect(USE labl);
14936 
14937   ins_cost(BRANCH_COST);
14938   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14939   ins_encode %{
14940     Label* L = $labl$$label;
14941     Assembler::Condition cond =
14942       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14943     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14944   %}
14945   ins_pipe(pipe_cmp_branch);
14946 %}
14947 
14948 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14949   match(If cmp (CmpL (AndL op1 op2) op3));
14950   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14951   effect(USE labl);
14952 
14953   ins_cost(BRANCH_COST);
14954   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14955   ins_encode %{
14956     Label* L = $labl$$label;
14957     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14958     int bit = exact_log2_long($op2$$constant);
14959     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14960   %}
14961   ins_pipe(pipe_cmp_branch);
14962 %}
14963 
14964 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14965   match(If cmp (CmpI (AndI op1 op2) op3));
14966   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14967   effect(USE labl);
14968 
14969   ins_cost(BRANCH_COST);
14970   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14971   ins_encode %{
14972     Label* L = $labl$$label;
14973     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14974     int bit = exact_log2((juint)$op2$$constant);
14975     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14976   %}
14977   ins_pipe(pipe_cmp_branch);
14978 %}
14979 
14980 // Test bits
14981 
14982 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
14983   match(Set cr (CmpL (AndL op1 op2) op3));
14984   predicate(Assembler::operand_valid_for_logical_immediate
14985             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14986 
14987   ins_cost(INSN_COST);
14988   format %{ &quot;tst $op1, $op2 # long&quot; %}
14989   ins_encode %{
14990     __ tst($op1$$Register, $op2$$constant);
14991   %}
14992   ins_pipe(ialu_reg_reg);
14993 %}
14994 
14995 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
14996   match(Set cr (CmpI (AndI op1 op2) op3));
14997   predicate(Assembler::operand_valid_for_logical_immediate
14998             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14999 
15000   ins_cost(INSN_COST);
15001   format %{ &quot;tst $op1, $op2 # int&quot; %}
15002   ins_encode %{
15003     __ tstw($op1$$Register, $op2$$constant);
15004   %}
15005   ins_pipe(ialu_reg_reg);
15006 %}
15007 
15008 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15009   match(Set cr (CmpL (AndL op1 op2) op3));
15010 
15011   ins_cost(INSN_COST);
15012   format %{ &quot;tst $op1, $op2 # long&quot; %}
15013   ins_encode %{
15014     __ tst($op1$$Register, $op2$$Register);
15015   %}
15016   ins_pipe(ialu_reg_reg);
15017 %}
15018 
15019 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15020   match(Set cr (CmpI (AndI op1 op2) op3));
15021 
15022   ins_cost(INSN_COST);
15023   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15024   ins_encode %{
15025     __ tstw($op1$$Register, $op2$$Register);
15026   %}
15027   ins_pipe(ialu_reg_reg);
15028 %}
15029 
15030 
15031 // Conditional Far Branch
15032 // Conditional Far Branch Unsigned
15033 // TODO: fixme
15034 
15035 // counted loop end branch near
15036 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15037 %{
15038   match(CountedLoopEnd cmp cr);
15039 
15040   effect(USE lbl);
15041 
15042   ins_cost(BRANCH_COST);
15043   // short variant.
15044   // ins_short_branch(1);
15045   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15046 
15047   ins_encode(aarch64_enc_br_con(cmp, lbl));
15048 
15049   ins_pipe(pipe_branch);
15050 %}
15051 
15052 // counted loop end branch near Unsigned
15053 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15054 %{
15055   match(CountedLoopEnd cmp cr);
15056 
15057   effect(USE lbl);
15058 
15059   ins_cost(BRANCH_COST);
15060   // short variant.
15061   // ins_short_branch(1);
15062   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15063 
15064   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15065 
15066   ins_pipe(pipe_branch);
15067 %}
15068 
15069 // counted loop end branch far
15070 // counted loop end branch far unsigned
15071 // TODO: fixme
15072 
15073 // ============================================================================
15074 // inlined locking and unlocking
15075 
15076 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15077 %{
15078   match(Set cr (FastLock object box));
15079   effect(TEMP tmp, TEMP tmp2);
15080 
15081   // TODO
15082   // identify correct cost
15083   ins_cost(5 * INSN_COST);
15084   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15085 
15086   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15087 
15088   ins_pipe(pipe_serial);
15089 %}
15090 
15091 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15092 %{
15093   match(Set cr (FastUnlock object box));
15094   effect(TEMP tmp, TEMP tmp2);
15095 
15096   ins_cost(5 * INSN_COST);
15097   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15098 
15099   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15100 
15101   ins_pipe(pipe_serial);
15102 %}
15103 
15104 
15105 // ============================================================================
15106 // Safepoint Instructions
15107 
15108 // TODO
15109 // provide a near and far version of this code
15110 
15111 instruct safePoint(rFlagsReg cr, iRegP poll)
15112 %{
15113   match(SafePoint poll);
15114   effect(KILL cr);
15115 
15116   format %{
15117     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15118   %}
15119   ins_encode %{
15120     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15121   %}
15122   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15123 %}
15124 
15125 
15126 // ============================================================================
15127 // Procedure Call/Return Instructions
15128 
15129 // Call Java Static Instruction
15130 
15131 instruct CallStaticJavaDirect(method meth)
15132 %{
15133   match(CallStaticJava);
15134 
15135   effect(USE meth);
15136 
15137   ins_cost(CALL_COST);
15138 
15139   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15140 
15141   ins_encode( aarch64_enc_java_static_call(meth),
15142               aarch64_enc_call_epilog );
15143 
15144   ins_pipe(pipe_class_call);
15145 %}
15146 
15147 // TO HERE
15148 
15149 // Call Java Dynamic Instruction
15150 instruct CallDynamicJavaDirect(method meth)
15151 %{
15152   match(CallDynamicJava);
15153 
15154   effect(USE meth);
15155 
15156   ins_cost(CALL_COST);
15157 
15158   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15159 
15160   ins_encode( aarch64_enc_java_dynamic_call(meth),
15161                aarch64_enc_call_epilog );
15162 
15163   ins_pipe(pipe_class_call);
15164 %}
15165 
15166 // Call Runtime Instruction
15167 
15168 instruct CallRuntimeDirect(method meth)
15169 %{
15170   match(CallRuntime);
15171 
15172   effect(USE meth);
15173 
15174   ins_cost(CALL_COST);
15175 
15176   format %{ &quot;CALL, runtime $meth&quot; %}
15177 
15178   ins_encode( aarch64_enc_java_to_runtime(meth) );
15179 
15180   ins_pipe(pipe_class_call);
15181 %}
15182 
15183 // Call Runtime Instruction
15184 
15185 instruct CallLeafDirect(method meth)
15186 %{
15187   match(CallLeaf);
15188 
15189   effect(USE meth);
15190 
15191   ins_cost(CALL_COST);
15192 
15193   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15194 
15195   ins_encode( aarch64_enc_java_to_runtime(meth) );
15196 
15197   ins_pipe(pipe_class_call);
15198 %}
15199 
15200 // Call Runtime Instruction
15201 
15202 instruct CallLeafNoFPDirect(method meth)
15203 %{
15204   match(CallLeafNoFP);
15205 
15206   effect(USE meth);
15207 
15208   ins_cost(CALL_COST);
15209 
15210   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15211 
15212   ins_encode( aarch64_enc_java_to_runtime(meth) );
15213 
15214   ins_pipe(pipe_class_call);
15215 %}
15216 
15217 // Tail Call; Jump from runtime stub to Java code.
15218 // Also known as an &#39;interprocedural jump&#39;.
15219 // Target of jump will eventually return to caller.
15220 // TailJump below removes the return address.
15221 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15222 %{
15223   match(TailCall jump_target method_oop);
15224 
15225   ins_cost(CALL_COST);
15226 
15227   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15228 
15229   ins_encode(aarch64_enc_tail_call(jump_target));
15230 
15231   ins_pipe(pipe_class_call);
15232 %}
15233 
15234 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15235 %{
15236   match(TailJump jump_target ex_oop);
15237 
15238   ins_cost(CALL_COST);
15239 
15240   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15241 
15242   ins_encode(aarch64_enc_tail_jmp(jump_target));
15243 
15244   ins_pipe(pipe_class_call);
15245 %}
15246 
15247 // Create exception oop: created by stack-crawling runtime code.
15248 // Created exception is now available to this handler, and is setup
15249 // just prior to jumping to this handler. No code emitted.
15250 // TODO check
15251 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15252 instruct CreateException(iRegP_R0 ex_oop)
15253 %{
15254   match(Set ex_oop (CreateEx));
15255 
15256   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15257 
15258   size(0);
15259 
15260   ins_encode( /*empty*/ );
15261 
15262   ins_pipe(pipe_class_empty);
15263 %}
15264 
15265 // Rethrow exception: The exception oop will come in the first
15266 // argument position. Then JUMP (not call) to the rethrow stub code.
15267 instruct RethrowException() %{
15268   match(Rethrow);
15269   ins_cost(CALL_COST);
15270 
15271   format %{ &quot;b rethrow_stub&quot; %}
15272 
15273   ins_encode( aarch64_enc_rethrow() );
15274 
15275   ins_pipe(pipe_class_call);
15276 %}
15277 
15278 
15279 // Return Instruction
15280 // epilog node loads ret address into lr as part of frame pop
15281 instruct Ret()
15282 %{
15283   match(Return);
15284 
15285   format %{ &quot;ret\t// return register&quot; %}
15286 
15287   ins_encode( aarch64_enc_ret() );
15288 
15289   ins_pipe(pipe_branch);
15290 %}
15291 
15292 // Die now.
15293 instruct ShouldNotReachHere() %{
15294   match(Halt);
15295 
15296   ins_cost(CALL_COST);
15297   format %{ &quot;ShouldNotReachHere&quot; %}
15298 
15299   ins_encode %{
15300     if (is_reachable()) {
15301       __ stop(_halt_reason);
15302     }
15303   %}
15304 
15305   ins_pipe(pipe_class_default);
15306 %}
15307 
15308 // ============================================================================
15309 // Partial Subtype Check
15310 //
15311 // superklass array for an instance of the superklass.  Set a hidden
15312 // internal cache on a hit (cache is checked with exposed code in
15313 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15314 // encoding ALSO sets flags.
15315 
15316 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15317 %{
15318   match(Set result (PartialSubtypeCheck sub super));
15319   effect(KILL cr, KILL temp);
15320 
15321   ins_cost(1100);  // slightly larger than the next version
15322   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15323 
15324   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15325 
15326   opcode(0x1); // Force zero of result reg on hit
15327 
15328   ins_pipe(pipe_class_memory);
15329 %}
15330 
15331 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15332 %{
15333   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15334   effect(KILL temp, KILL result);
15335 
15336   ins_cost(1100);  // slightly larger than the next version
15337   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15338 
15339   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15340 
15341   opcode(0x0); // Don&#39;t zero result reg on hit
15342 
15343   ins_pipe(pipe_class_memory);
15344 %}
15345 
15346 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15347                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15348 %{
15349   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15350   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15351   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15352 
15353   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15354   ins_encode %{
15355     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15356     __ string_compare($str1$$Register, $str2$$Register,
15357                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15358                       $tmp1$$Register, $tmp2$$Register,
15359                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15360   %}
15361   ins_pipe(pipe_class_memory);
15362 %}
15363 
15364 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15365                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15366 %{
15367   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15368   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15369   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15370 
15371   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15372   ins_encode %{
15373     __ string_compare($str1$$Register, $str2$$Register,
15374                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15375                       $tmp1$$Register, $tmp2$$Register,
15376                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15377   %}
15378   ins_pipe(pipe_class_memory);
15379 %}
15380 
15381 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15382                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15383                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15384 %{
15385   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15386   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15387   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15388          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15389 
15390   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15391   ins_encode %{
15392     __ string_compare($str1$$Register, $str2$$Register,
15393                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15394                       $tmp1$$Register, $tmp2$$Register,
15395                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15396                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15397   %}
15398   ins_pipe(pipe_class_memory);
15399 %}
15400 
15401 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15402                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15403                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15404 %{
15405   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15406   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15407   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15408          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15409 
15410   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15411   ins_encode %{
15412     __ string_compare($str1$$Register, $str2$$Register,
15413                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15414                       $tmp1$$Register, $tmp2$$Register,
15415                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15416                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15417   %}
15418   ins_pipe(pipe_class_memory);
15419 %}
15420 
15421 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15422        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15423        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15424 %{
15425   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15426   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15427   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15428          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15429   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15430 
15431   ins_encode %{
15432     __ string_indexof($str1$$Register, $str2$$Register,
15433                       $cnt1$$Register, $cnt2$$Register,
15434                       $tmp1$$Register, $tmp2$$Register,
15435                       $tmp3$$Register, $tmp4$$Register,
15436                       $tmp5$$Register, $tmp6$$Register,
15437                       -1, $result$$Register, StrIntrinsicNode::UU);
15438   %}
15439   ins_pipe(pipe_class_memory);
15440 %}
15441 
15442 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15443        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15444        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15445 %{
15446   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15447   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15448   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15449          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15450   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15451 
15452   ins_encode %{
15453     __ string_indexof($str1$$Register, $str2$$Register,
15454                       $cnt1$$Register, $cnt2$$Register,
15455                       $tmp1$$Register, $tmp2$$Register,
15456                       $tmp3$$Register, $tmp4$$Register,
15457                       $tmp5$$Register, $tmp6$$Register,
15458                       -1, $result$$Register, StrIntrinsicNode::LL);
15459   %}
15460   ins_pipe(pipe_class_memory);
15461 %}
15462 
15463 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15464        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15465        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15466 %{
15467   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15468   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15469   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15470          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15471   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15472 
15473   ins_encode %{
15474     __ string_indexof($str1$$Register, $str2$$Register,
15475                       $cnt1$$Register, $cnt2$$Register,
15476                       $tmp1$$Register, $tmp2$$Register,
15477                       $tmp3$$Register, $tmp4$$Register,
15478                       $tmp5$$Register, $tmp6$$Register,
15479                       -1, $result$$Register, StrIntrinsicNode::UL);
15480   %}
15481   ins_pipe(pipe_class_memory);
15482 %}
15483 
15484 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15485                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15486                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15487 %{
15488   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15489   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15490   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15491          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15492   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15493 
15494   ins_encode %{
15495     int icnt2 = (int)$int_cnt2$$constant;
15496     __ string_indexof($str1$$Register, $str2$$Register,
15497                       $cnt1$$Register, zr,
15498                       $tmp1$$Register, $tmp2$$Register,
15499                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15500                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15501   %}
15502   ins_pipe(pipe_class_memory);
15503 %}
15504 
15505 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15506                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15507                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15508 %{
15509   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15510   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15511   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15512          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15513   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15514 
15515   ins_encode %{
15516     int icnt2 = (int)$int_cnt2$$constant;
15517     __ string_indexof($str1$$Register, $str2$$Register,
15518                       $cnt1$$Register, zr,
15519                       $tmp1$$Register, $tmp2$$Register,
15520                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15521                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15522   %}
15523   ins_pipe(pipe_class_memory);
15524 %}
15525 
15526 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15527                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15528                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15529 %{
15530   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15531   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15532   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15533          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15534   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15535 
15536   ins_encode %{
15537     int icnt2 = (int)$int_cnt2$$constant;
15538     __ string_indexof($str1$$Register, $str2$$Register,
15539                       $cnt1$$Register, zr,
15540                       $tmp1$$Register, $tmp2$$Register,
15541                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15542                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15543   %}
15544   ins_pipe(pipe_class_memory);
15545 %}
15546 
15547 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15548                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15549                               iRegINoSp tmp3, rFlagsReg cr)
15550 %{
15551   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15552   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15553          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15554 
15555   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15556 
15557   ins_encode %{
15558     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15559                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15560                            $tmp3$$Register);
15561   %}
15562   ins_pipe(pipe_class_memory);
15563 %}
15564 
15565 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15566                         iRegI_R0 result, rFlagsReg cr)
15567 %{
15568   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15569   match(Set result (StrEquals (Binary str1 str2) cnt));
15570   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15571 
15572   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15573   ins_encode %{
15574     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15575     __ string_equals($str1$$Register, $str2$$Register,
15576                      $result$$Register, $cnt$$Register, 1);
15577   %}
15578   ins_pipe(pipe_class_memory);
15579 %}
15580 
15581 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15582                         iRegI_R0 result, rFlagsReg cr)
15583 %{
15584   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15585   match(Set result (StrEquals (Binary str1 str2) cnt));
15586   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15587 
15588   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15589   ins_encode %{
15590     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15591     __ string_equals($str1$$Register, $str2$$Register,
15592                      $result$$Register, $cnt$$Register, 2);
15593   %}
15594   ins_pipe(pipe_class_memory);
15595 %}
15596 
15597 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15598                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15599                        iRegP_R10 tmp, rFlagsReg cr)
15600 %{
15601   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15602   match(Set result (AryEq ary1 ary2));
15603   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15604 
15605   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15606   ins_encode %{
15607     __ arrays_equals($ary1$$Register, $ary2$$Register,
15608                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15609                      $result$$Register, $tmp$$Register, 1);
15610     %}
15611   ins_pipe(pipe_class_memory);
15612 %}
15613 
15614 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15615                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15616                        iRegP_R10 tmp, rFlagsReg cr)
15617 %{
15618   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15619   match(Set result (AryEq ary1 ary2));
15620   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15621 
15622   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15623   ins_encode %{
15624     __ arrays_equals($ary1$$Register, $ary2$$Register,
15625                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15626                      $result$$Register, $tmp$$Register, 2);
15627   %}
15628   ins_pipe(pipe_class_memory);
15629 %}
15630 
15631 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15632 %{
15633   match(Set result (HasNegatives ary1 len));
15634   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15635   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15636   ins_encode %{
15637     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15638   %}
15639   ins_pipe( pipe_slow );
15640 %}
15641 
15642 // fast char[] to byte[] compression
15643 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15644                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15645                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15646                          iRegI_R0 result, rFlagsReg cr)
15647 %{
15648   match(Set result (StrCompressedCopy src (Binary dst len)));
15649   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15650 
15651   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15652   ins_encode %{
15653     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15654                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15655                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15656                            $result$$Register);
15657   %}
15658   ins_pipe( pipe_slow );
15659 %}
15660 
15661 // fast byte[] to char[] inflation
15662 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15663                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15664 %{
15665   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15666   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15667 
15668   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15669   ins_encode %{
15670     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15671                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15672   %}
15673   ins_pipe(pipe_class_memory);
15674 %}
15675 
15676 // encode char[] to byte[] in ISO_8859_1
15677 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15678                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15679                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15680                           iRegI_R0 result, rFlagsReg cr)
15681 %{
15682   match(Set result (EncodeISOArray src (Binary dst len)));
15683   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15684          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15685 
15686   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15687   ins_encode %{
15688     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15689          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15690          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15691   %}
15692   ins_pipe( pipe_class_memory );
15693 %}
15694 
15695 // ============================================================================
15696 // This name is KNOWN by the ADLC and cannot be changed.
15697 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15698 // for this guy.
15699 instruct tlsLoadP(thread_RegP dst)
15700 %{
15701   match(Set dst (ThreadLocal));
15702 
15703   ins_cost(0);
15704 
15705   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15706 
15707   size(0);
15708 
15709   ins_encode( /*empty*/ );
15710 
15711   ins_pipe(pipe_class_empty);
15712 %}
15713 
15714 // ====================VECTOR INSTRUCTIONS=====================================
15715 
15716 // Load vector (32 bits)
15717 instruct loadV4(vecD dst, vmem4 mem)
15718 %{
15719   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15720   match(Set dst (LoadVector mem));
15721   ins_cost(4 * INSN_COST);
15722   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15723   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15724   ins_pipe(vload_reg_mem64);
15725 %}
15726 
15727 // Load vector (64 bits)
15728 instruct loadV8(vecD dst, vmem8 mem)
15729 %{
15730   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15731   match(Set dst (LoadVector mem));
15732   ins_cost(4 * INSN_COST);
15733   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15734   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15735   ins_pipe(vload_reg_mem64);
15736 %}
15737 
15738 // Load Vector (128 bits)
15739 instruct loadV16(vecX dst, vmem16 mem)
15740 %{
15741   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15742   match(Set dst (LoadVector mem));
15743   ins_cost(4 * INSN_COST);
15744   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15745   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15746   ins_pipe(vload_reg_mem128);
15747 %}
15748 
15749 // Store Vector (32 bits)
15750 instruct storeV4(vecD src, vmem4 mem)
15751 %{
15752   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15753   match(Set mem (StoreVector mem src));
15754   ins_cost(4 * INSN_COST);
15755   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15756   ins_encode( aarch64_enc_strvS(src, mem) );
15757   ins_pipe(vstore_reg_mem64);
15758 %}
15759 
15760 // Store Vector (64 bits)
15761 instruct storeV8(vecD src, vmem8 mem)
15762 %{
15763   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15764   match(Set mem (StoreVector mem src));
15765   ins_cost(4 * INSN_COST);
15766   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15767   ins_encode( aarch64_enc_strvD(src, mem) );
15768   ins_pipe(vstore_reg_mem64);
15769 %}
15770 
15771 // Store Vector (128 bits)
15772 instruct storeV16(vecX src, vmem16 mem)
15773 %{
15774   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15775   match(Set mem (StoreVector mem src));
15776   ins_cost(4 * INSN_COST);
15777   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15778   ins_encode( aarch64_enc_strvQ(src, mem) );
15779   ins_pipe(vstore_reg_mem128);
15780 %}
15781 
15782 instruct replicate8B(vecD dst, iRegIorL2I src)
15783 %{
15784   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15785             n-&gt;as_Vector()-&gt;length() == 8);
15786   match(Set dst (ReplicateB src));
15787   ins_cost(INSN_COST);
15788   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15789   ins_encode %{
15790     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15791   %}
15792   ins_pipe(vdup_reg_reg64);
15793 %}
15794 
15795 instruct replicate16B(vecX dst, iRegIorL2I src)
15796 %{
15797   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15798   match(Set dst (ReplicateB src));
15799   ins_cost(INSN_COST);
15800   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15801   ins_encode %{
15802     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15803   %}
15804   ins_pipe(vdup_reg_reg128);
15805 %}
15806 
15807 instruct replicate8B_imm(vecD dst, immI con)
15808 %{
15809   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15810             n-&gt;as_Vector()-&gt;length() == 8);
15811   match(Set dst (ReplicateB con));
15812   ins_cost(INSN_COST);
15813   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15814   ins_encode %{
15815     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15816   %}
15817   ins_pipe(vmovi_reg_imm64);
15818 %}
15819 
15820 instruct replicate16B_imm(vecX dst, immI con)
15821 %{
15822   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15823   match(Set dst (ReplicateB con));
15824   ins_cost(INSN_COST);
15825   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15826   ins_encode %{
15827     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15828   %}
15829   ins_pipe(vmovi_reg_imm128);
15830 %}
15831 
15832 instruct replicate4S(vecD dst, iRegIorL2I src)
15833 %{
15834   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15835             n-&gt;as_Vector()-&gt;length() == 4);
15836   match(Set dst (ReplicateS src));
15837   ins_cost(INSN_COST);
15838   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15839   ins_encode %{
15840     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15841   %}
15842   ins_pipe(vdup_reg_reg64);
15843 %}
15844 
15845 instruct replicate8S(vecX dst, iRegIorL2I src)
15846 %{
15847   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15848   match(Set dst (ReplicateS src));
15849   ins_cost(INSN_COST);
15850   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15851   ins_encode %{
15852     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15853   %}
15854   ins_pipe(vdup_reg_reg128);
15855 %}
15856 
15857 instruct replicate4S_imm(vecD dst, immI con)
15858 %{
15859   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15860             n-&gt;as_Vector()-&gt;length() == 4);
15861   match(Set dst (ReplicateS con));
15862   ins_cost(INSN_COST);
15863   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15864   ins_encode %{
15865     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15866   %}
15867   ins_pipe(vmovi_reg_imm64);
15868 %}
15869 
15870 instruct replicate8S_imm(vecX dst, immI con)
15871 %{
15872   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15873   match(Set dst (ReplicateS con));
15874   ins_cost(INSN_COST);
15875   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15876   ins_encode %{
15877     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15878   %}
15879   ins_pipe(vmovi_reg_imm128);
15880 %}
15881 
15882 instruct replicate2I(vecD dst, iRegIorL2I src)
15883 %{
15884   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15885   match(Set dst (ReplicateI src));
15886   ins_cost(INSN_COST);
15887   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15888   ins_encode %{
15889     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15890   %}
15891   ins_pipe(vdup_reg_reg64);
15892 %}
15893 
15894 instruct replicate4I(vecX dst, iRegIorL2I src)
15895 %{
15896   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15897   match(Set dst (ReplicateI src));
15898   ins_cost(INSN_COST);
15899   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15900   ins_encode %{
15901     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15902   %}
15903   ins_pipe(vdup_reg_reg128);
15904 %}
15905 
15906 instruct replicate2I_imm(vecD dst, immI con)
15907 %{
15908   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15909   match(Set dst (ReplicateI con));
15910   ins_cost(INSN_COST);
15911   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15912   ins_encode %{
15913     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15914   %}
15915   ins_pipe(vmovi_reg_imm64);
15916 %}
15917 
15918 instruct replicate4I_imm(vecX dst, immI con)
15919 %{
15920   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15921   match(Set dst (ReplicateI con));
15922   ins_cost(INSN_COST);
15923   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15924   ins_encode %{
15925     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15926   %}
15927   ins_pipe(vmovi_reg_imm128);
15928 %}
15929 
15930 instruct replicate2L(vecX dst, iRegL src)
15931 %{
15932   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15933   match(Set dst (ReplicateL src));
15934   ins_cost(INSN_COST);
15935   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15936   ins_encode %{
15937     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15938   %}
15939   ins_pipe(vdup_reg_reg128);
15940 %}
15941 
15942 instruct replicate2L_zero(vecX dst, immI0 zero)
15943 %{
15944   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15945   match(Set dst (ReplicateI zero));
15946   ins_cost(INSN_COST);
15947   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15948   ins_encode %{
15949     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15950            as_FloatRegister($dst$$reg),
15951            as_FloatRegister($dst$$reg));
15952   %}
15953   ins_pipe(vmovi_reg_imm128);
15954 %}
15955 
15956 instruct replicate2F(vecD dst, vRegF src)
15957 %{
15958   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15959   match(Set dst (ReplicateF src));
15960   ins_cost(INSN_COST);
15961   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15962   ins_encode %{
15963     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15964            as_FloatRegister($src$$reg));
15965   %}
15966   ins_pipe(vdup_reg_freg64);
15967 %}
15968 
15969 instruct replicate4F(vecX dst, vRegF src)
15970 %{
15971   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15972   match(Set dst (ReplicateF src));
15973   ins_cost(INSN_COST);
15974   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
15975   ins_encode %{
15976     __ dup(as_FloatRegister($dst$$reg), __ T4S,
15977            as_FloatRegister($src$$reg));
15978   %}
15979   ins_pipe(vdup_reg_freg128);
15980 %}
15981 
15982 instruct replicate2D(vecX dst, vRegD src)
15983 %{
15984   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15985   match(Set dst (ReplicateD src));
15986   ins_cost(INSN_COST);
15987   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
15988   ins_encode %{
15989     __ dup(as_FloatRegister($dst$$reg), __ T2D,
15990            as_FloatRegister($src$$reg));
15991   %}
15992   ins_pipe(vdup_reg_dreg128);
15993 %}
15994 
15995 // ====================REDUCTION ARITHMETIC====================================
15996 
15997 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
15998 %{
15999   match(Set dst (AddReductionVI isrc vsrc));
16000   ins_cost(INSN_COST);
16001   effect(TEMP tmp, TEMP tmp2);
16002   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16003             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16004             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16005             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16006   %}
16007   ins_encode %{
16008     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16009     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16010     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16011     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16012   %}
16013   ins_pipe(pipe_class_default);
16014 %}
16015 
16016 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16017 %{
16018   match(Set dst (AddReductionVI isrc vsrc));
16019   ins_cost(INSN_COST);
16020   effect(TEMP vtmp, TEMP itmp);
16021   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16022             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16023             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16024   %}
16025   ins_encode %{
16026     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16027             as_FloatRegister($vsrc$$reg));
16028     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16029     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16030   %}
16031   ins_pipe(pipe_class_default);
16032 %}
16033 
16034 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16035 %{
16036   match(Set dst (MulReductionVI isrc vsrc));
16037   ins_cost(INSN_COST);
16038   effect(TEMP tmp, TEMP dst);
16039   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16040             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16041             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16042             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16043   %}
16044   ins_encode %{
16045     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16046     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16047     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16048     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16049   %}
16050   ins_pipe(pipe_class_default);
16051 %}
16052 
16053 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16054 %{
16055   match(Set dst (MulReductionVI isrc vsrc));
16056   ins_cost(INSN_COST);
16057   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16058   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16059             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16060             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16061             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16062             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16063             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16064   %}
16065   ins_encode %{
16066     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16067            as_FloatRegister($vsrc$$reg), 0, 1);
16068     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16069             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16070     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16071     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16072     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16073     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16074   %}
16075   ins_pipe(pipe_class_default);
16076 %}
16077 
16078 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16079 %{
16080   match(Set dst (AddReductionVF fsrc vsrc));
16081   ins_cost(INSN_COST);
16082   effect(TEMP tmp, TEMP dst);
16083   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16084             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16085             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16086   %}
16087   ins_encode %{
16088     __ fadds(as_FloatRegister($dst$$reg),
16089              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16090     __ ins(as_FloatRegister($tmp$$reg), __ S,
16091            as_FloatRegister($vsrc$$reg), 0, 1);
16092     __ fadds(as_FloatRegister($dst$$reg),
16093              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16094   %}
16095   ins_pipe(pipe_class_default);
16096 %}
16097 
16098 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16099 %{
16100   match(Set dst (AddReductionVF fsrc vsrc));
16101   ins_cost(INSN_COST);
16102   effect(TEMP tmp, TEMP dst);
16103   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16104             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16105             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16106             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16107             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16108             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16109             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16110   %}
16111   ins_encode %{
16112     __ fadds(as_FloatRegister($dst$$reg),
16113              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16114     __ ins(as_FloatRegister($tmp$$reg), __ S,
16115            as_FloatRegister($vsrc$$reg), 0, 1);
16116     __ fadds(as_FloatRegister($dst$$reg),
16117              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16118     __ ins(as_FloatRegister($tmp$$reg), __ S,
16119            as_FloatRegister($vsrc$$reg), 0, 2);
16120     __ fadds(as_FloatRegister($dst$$reg),
16121              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16122     __ ins(as_FloatRegister($tmp$$reg), __ S,
16123            as_FloatRegister($vsrc$$reg), 0, 3);
16124     __ fadds(as_FloatRegister($dst$$reg),
16125              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16126   %}
16127   ins_pipe(pipe_class_default);
16128 %}
16129 
16130 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16131 %{
16132   match(Set dst (MulReductionVF fsrc vsrc));
16133   ins_cost(INSN_COST);
16134   effect(TEMP tmp, TEMP dst);
16135   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16136             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16137             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16138   %}
16139   ins_encode %{
16140     __ fmuls(as_FloatRegister($dst$$reg),
16141              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16142     __ ins(as_FloatRegister($tmp$$reg), __ S,
16143            as_FloatRegister($vsrc$$reg), 0, 1);
16144     __ fmuls(as_FloatRegister($dst$$reg),
16145              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16146   %}
16147   ins_pipe(pipe_class_default);
16148 %}
16149 
16150 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16151 %{
16152   match(Set dst (MulReductionVF fsrc vsrc));
16153   ins_cost(INSN_COST);
16154   effect(TEMP tmp, TEMP dst);
16155   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16156             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16157             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16158             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16159             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16160             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16161             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16162   %}
16163   ins_encode %{
16164     __ fmuls(as_FloatRegister($dst$$reg),
16165              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16166     __ ins(as_FloatRegister($tmp$$reg), __ S,
16167            as_FloatRegister($vsrc$$reg), 0, 1);
16168     __ fmuls(as_FloatRegister($dst$$reg),
16169              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16170     __ ins(as_FloatRegister($tmp$$reg), __ S,
16171            as_FloatRegister($vsrc$$reg), 0, 2);
16172     __ fmuls(as_FloatRegister($dst$$reg),
16173              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16174     __ ins(as_FloatRegister($tmp$$reg), __ S,
16175            as_FloatRegister($vsrc$$reg), 0, 3);
16176     __ fmuls(as_FloatRegister($dst$$reg),
16177              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16178   %}
16179   ins_pipe(pipe_class_default);
16180 %}
16181 
16182 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16183 %{
16184   match(Set dst (AddReductionVD dsrc vsrc));
16185   ins_cost(INSN_COST);
16186   effect(TEMP tmp, TEMP dst);
16187   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16188             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16189             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16190   %}
16191   ins_encode %{
16192     __ faddd(as_FloatRegister($dst$$reg),
16193              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16194     __ ins(as_FloatRegister($tmp$$reg), __ D,
16195            as_FloatRegister($vsrc$$reg), 0, 1);
16196     __ faddd(as_FloatRegister($dst$$reg),
16197              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16198   %}
16199   ins_pipe(pipe_class_default);
16200 %}
16201 
16202 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16203 %{
16204   match(Set dst (MulReductionVD dsrc vsrc));
16205   ins_cost(INSN_COST);
16206   effect(TEMP tmp, TEMP dst);
16207   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16208             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16209             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16210   %}
16211   ins_encode %{
16212     __ fmuld(as_FloatRegister($dst$$reg),
16213              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16214     __ ins(as_FloatRegister($tmp$$reg), __ D,
16215            as_FloatRegister($vsrc$$reg), 0, 1);
16216     __ fmuld(as_FloatRegister($dst$$reg),
16217              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16218   %}
16219   ins_pipe(pipe_class_default);
16220 %}
16221 
16222 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16223   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16224   match(Set dst (MaxReductionV fsrc vsrc));
16225   ins_cost(INSN_COST);
16226   effect(TEMP_DEF dst, TEMP tmp);
16227   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16228             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16229             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16230   ins_encode %{
16231     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16232     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16233     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16234   %}
16235   ins_pipe(pipe_class_default);
16236 %}
16237 
16238 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16239   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16240   match(Set dst (MaxReductionV fsrc vsrc));
16241   ins_cost(INSN_COST);
16242   effect(TEMP_DEF dst);
16243   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16244             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16245   ins_encode %{
16246     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16247     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16248   %}
16249   ins_pipe(pipe_class_default);
16250 %}
16251 
16252 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16253   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16254   match(Set dst (MaxReductionV dsrc vsrc));
16255   ins_cost(INSN_COST);
16256   effect(TEMP_DEF dst, TEMP tmp);
16257   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16258             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16259             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16260   ins_encode %{
16261     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16262     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16263     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16264   %}
16265   ins_pipe(pipe_class_default);
16266 %}
16267 
16268 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16269   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16270   match(Set dst (MinReductionV fsrc vsrc));
16271   ins_cost(INSN_COST);
16272   effect(TEMP_DEF dst, TEMP tmp);
16273   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16274             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16275             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16276   ins_encode %{
16277     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16278     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16279     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16280   %}
16281   ins_pipe(pipe_class_default);
16282 %}
16283 
16284 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16285   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16286   match(Set dst (MinReductionV fsrc vsrc));
16287   ins_cost(INSN_COST);
16288   effect(TEMP_DEF dst);
16289   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16290             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16291   ins_encode %{
16292     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16293     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16294   %}
16295   ins_pipe(pipe_class_default);
16296 %}
16297 
16298 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16299   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16300   match(Set dst (MinReductionV dsrc vsrc));
16301   ins_cost(INSN_COST);
16302   effect(TEMP_DEF dst, TEMP tmp);
16303   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16304             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16305             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16306   ins_encode %{
16307     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16308     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16309     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16310   %}
16311   ins_pipe(pipe_class_default);
16312 %}
16313 
16314 // ====================VECTOR ARITHMETIC=======================================
16315 
16316 // --------------------------------- ADD --------------------------------------
16317 
16318 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16319 %{
16320   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16321             n-&gt;as_Vector()-&gt;length() == 8);
16322   match(Set dst (AddVB src1 src2));
16323   ins_cost(INSN_COST);
16324   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16325   ins_encode %{
16326     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16327             as_FloatRegister($src1$$reg),
16328             as_FloatRegister($src2$$reg));
16329   %}
16330   ins_pipe(vdop64);
16331 %}
16332 
16333 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16334 %{
16335   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16336   match(Set dst (AddVB src1 src2));
16337   ins_cost(INSN_COST);
16338   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16339   ins_encode %{
16340     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16341             as_FloatRegister($src1$$reg),
16342             as_FloatRegister($src2$$reg));
16343   %}
16344   ins_pipe(vdop128);
16345 %}
16346 
16347 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16348 %{
16349   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16350             n-&gt;as_Vector()-&gt;length() == 4);
16351   match(Set dst (AddVS src1 src2));
16352   ins_cost(INSN_COST);
16353   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16354   ins_encode %{
16355     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16356             as_FloatRegister($src1$$reg),
16357             as_FloatRegister($src2$$reg));
16358   %}
16359   ins_pipe(vdop64);
16360 %}
16361 
16362 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16363 %{
16364   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16365   match(Set dst (AddVS src1 src2));
16366   ins_cost(INSN_COST);
16367   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16368   ins_encode %{
16369     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16370             as_FloatRegister($src1$$reg),
16371             as_FloatRegister($src2$$reg));
16372   %}
16373   ins_pipe(vdop128);
16374 %}
16375 
16376 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16377 %{
16378   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16379   match(Set dst (AddVI src1 src2));
16380   ins_cost(INSN_COST);
16381   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16382   ins_encode %{
16383     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16384             as_FloatRegister($src1$$reg),
16385             as_FloatRegister($src2$$reg));
16386   %}
16387   ins_pipe(vdop64);
16388 %}
16389 
16390 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16391 %{
16392   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16393   match(Set dst (AddVI src1 src2));
16394   ins_cost(INSN_COST);
16395   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16396   ins_encode %{
16397     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16398             as_FloatRegister($src1$$reg),
16399             as_FloatRegister($src2$$reg));
16400   %}
16401   ins_pipe(vdop128);
16402 %}
16403 
16404 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16405 %{
16406   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16407   match(Set dst (AddVL src1 src2));
16408   ins_cost(INSN_COST);
16409   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16410   ins_encode %{
16411     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16412             as_FloatRegister($src1$$reg),
16413             as_FloatRegister($src2$$reg));
16414   %}
16415   ins_pipe(vdop128);
16416 %}
16417 
16418 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16419 %{
16420   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16421   match(Set dst (AddVF src1 src2));
16422   ins_cost(INSN_COST);
16423   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16424   ins_encode %{
16425     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16426             as_FloatRegister($src1$$reg),
16427             as_FloatRegister($src2$$reg));
16428   %}
16429   ins_pipe(vdop_fp64);
16430 %}
16431 
16432 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16433 %{
16434   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16435   match(Set dst (AddVF src1 src2));
16436   ins_cost(INSN_COST);
16437   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16438   ins_encode %{
16439     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16440             as_FloatRegister($src1$$reg),
16441             as_FloatRegister($src2$$reg));
16442   %}
16443   ins_pipe(vdop_fp128);
16444 %}
16445 
16446 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16447 %{
16448   match(Set dst (AddVD src1 src2));
16449   ins_cost(INSN_COST);
16450   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16451   ins_encode %{
16452     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16453             as_FloatRegister($src1$$reg),
16454             as_FloatRegister($src2$$reg));
16455   %}
16456   ins_pipe(vdop_fp128);
16457 %}
16458 
16459 // --------------------------------- SUB --------------------------------------
16460 
16461 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16462 %{
16463   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16464             n-&gt;as_Vector()-&gt;length() == 8);
16465   match(Set dst (SubVB src1 src2));
16466   ins_cost(INSN_COST);
16467   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16468   ins_encode %{
16469     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16470             as_FloatRegister($src1$$reg),
16471             as_FloatRegister($src2$$reg));
16472   %}
16473   ins_pipe(vdop64);
16474 %}
16475 
16476 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16477 %{
16478   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16479   match(Set dst (SubVB src1 src2));
16480   ins_cost(INSN_COST);
16481   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16482   ins_encode %{
16483     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16484             as_FloatRegister($src1$$reg),
16485             as_FloatRegister($src2$$reg));
16486   %}
16487   ins_pipe(vdop128);
16488 %}
16489 
16490 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16491 %{
16492   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16493             n-&gt;as_Vector()-&gt;length() == 4);
16494   match(Set dst (SubVS src1 src2));
16495   ins_cost(INSN_COST);
16496   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16497   ins_encode %{
16498     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16499             as_FloatRegister($src1$$reg),
16500             as_FloatRegister($src2$$reg));
16501   %}
16502   ins_pipe(vdop64);
16503 %}
16504 
16505 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16506 %{
16507   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16508   match(Set dst (SubVS src1 src2));
16509   ins_cost(INSN_COST);
16510   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16511   ins_encode %{
16512     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16513             as_FloatRegister($src1$$reg),
16514             as_FloatRegister($src2$$reg));
16515   %}
16516   ins_pipe(vdop128);
16517 %}
16518 
16519 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16520 %{
16521   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16522   match(Set dst (SubVI src1 src2));
16523   ins_cost(INSN_COST);
16524   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16525   ins_encode %{
16526     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16527             as_FloatRegister($src1$$reg),
16528             as_FloatRegister($src2$$reg));
16529   %}
16530   ins_pipe(vdop64);
16531 %}
16532 
16533 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16534 %{
16535   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16536   match(Set dst (SubVI src1 src2));
16537   ins_cost(INSN_COST);
16538   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16539   ins_encode %{
16540     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16541             as_FloatRegister($src1$$reg),
16542             as_FloatRegister($src2$$reg));
16543   %}
16544   ins_pipe(vdop128);
16545 %}
16546 
16547 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16548 %{
16549   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16550   match(Set dst (SubVL src1 src2));
16551   ins_cost(INSN_COST);
16552   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16553   ins_encode %{
16554     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16555             as_FloatRegister($src1$$reg),
16556             as_FloatRegister($src2$$reg));
16557   %}
16558   ins_pipe(vdop128);
16559 %}
16560 
16561 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16562 %{
16563   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16564   match(Set dst (SubVF src1 src2));
16565   ins_cost(INSN_COST);
16566   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16567   ins_encode %{
16568     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16569             as_FloatRegister($src1$$reg),
16570             as_FloatRegister($src2$$reg));
16571   %}
16572   ins_pipe(vdop_fp64);
16573 %}
16574 
16575 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16576 %{
16577   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16578   match(Set dst (SubVF src1 src2));
16579   ins_cost(INSN_COST);
16580   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16581   ins_encode %{
16582     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16583             as_FloatRegister($src1$$reg),
16584             as_FloatRegister($src2$$reg));
16585   %}
16586   ins_pipe(vdop_fp128);
16587 %}
16588 
16589 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16590 %{
16591   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16592   match(Set dst (SubVD src1 src2));
16593   ins_cost(INSN_COST);
16594   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16595   ins_encode %{
16596     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16597             as_FloatRegister($src1$$reg),
16598             as_FloatRegister($src2$$reg));
16599   %}
16600   ins_pipe(vdop_fp128);
16601 %}
16602 
16603 // --------------------------------- MUL --------------------------------------
16604 
16605 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16606 %{
16607   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16608             n-&gt;as_Vector()-&gt;length() == 8);
16609   match(Set dst (MulVB src1 src2));
16610   ins_cost(INSN_COST);
16611   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16612   ins_encode %{
16613     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16614             as_FloatRegister($src1$$reg),
16615             as_FloatRegister($src2$$reg));
16616   %}
16617   ins_pipe(vmul64);
16618 %}
16619 
16620 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16621 %{
16622   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16623   match(Set dst (MulVB src1 src2));
16624   ins_cost(INSN_COST);
16625   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16626   ins_encode %{
16627     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16628             as_FloatRegister($src1$$reg),
16629             as_FloatRegister($src2$$reg));
16630   %}
16631   ins_pipe(vmul128);
16632 %}
16633 
16634 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16635 %{
16636   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16637             n-&gt;as_Vector()-&gt;length() == 4);
16638   match(Set dst (MulVS src1 src2));
16639   ins_cost(INSN_COST);
16640   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16641   ins_encode %{
16642     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16643             as_FloatRegister($src1$$reg),
16644             as_FloatRegister($src2$$reg));
16645   %}
16646   ins_pipe(vmul64);
16647 %}
16648 
16649 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16650 %{
16651   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16652   match(Set dst (MulVS src1 src2));
16653   ins_cost(INSN_COST);
16654   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16655   ins_encode %{
16656     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16657             as_FloatRegister($src1$$reg),
16658             as_FloatRegister($src2$$reg));
16659   %}
16660   ins_pipe(vmul128);
16661 %}
16662 
16663 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16664 %{
16665   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16666   match(Set dst (MulVI src1 src2));
16667   ins_cost(INSN_COST);
16668   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16669   ins_encode %{
16670     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16671             as_FloatRegister($src1$$reg),
16672             as_FloatRegister($src2$$reg));
16673   %}
16674   ins_pipe(vmul64);
16675 %}
16676 
16677 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16678 %{
16679   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16680   match(Set dst (MulVI src1 src2));
16681   ins_cost(INSN_COST);
16682   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16683   ins_encode %{
16684     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16685             as_FloatRegister($src1$$reg),
16686             as_FloatRegister($src2$$reg));
16687   %}
16688   ins_pipe(vmul128);
16689 %}
16690 
16691 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16692 %{
16693   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16694   match(Set dst (MulVF src1 src2));
16695   ins_cost(INSN_COST);
16696   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16697   ins_encode %{
16698     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16699             as_FloatRegister($src1$$reg),
16700             as_FloatRegister($src2$$reg));
16701   %}
16702   ins_pipe(vmuldiv_fp64);
16703 %}
16704 
16705 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16706 %{
16707   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16708   match(Set dst (MulVF src1 src2));
16709   ins_cost(INSN_COST);
16710   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16711   ins_encode %{
16712     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16713             as_FloatRegister($src1$$reg),
16714             as_FloatRegister($src2$$reg));
16715   %}
16716   ins_pipe(vmuldiv_fp128);
16717 %}
16718 
16719 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16720 %{
16721   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16722   match(Set dst (MulVD src1 src2));
16723   ins_cost(INSN_COST);
16724   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16725   ins_encode %{
16726     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16727             as_FloatRegister($src1$$reg),
16728             as_FloatRegister($src2$$reg));
16729   %}
16730   ins_pipe(vmuldiv_fp128);
16731 %}
16732 
16733 // --------------------------------- MLA --------------------------------------
16734 
16735 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16736 %{
16737   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16738             n-&gt;as_Vector()-&gt;length() == 4);
16739   match(Set dst (AddVS dst (MulVS src1 src2)));
16740   ins_cost(INSN_COST);
16741   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16742   ins_encode %{
16743     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16744             as_FloatRegister($src1$$reg),
16745             as_FloatRegister($src2$$reg));
16746   %}
16747   ins_pipe(vmla64);
16748 %}
16749 
16750 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16751 %{
16752   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16753   match(Set dst (AddVS dst (MulVS src1 src2)));
16754   ins_cost(INSN_COST);
16755   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16756   ins_encode %{
16757     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16758             as_FloatRegister($src1$$reg),
16759             as_FloatRegister($src2$$reg));
16760   %}
16761   ins_pipe(vmla128);
16762 %}
16763 
16764 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16765 %{
16766   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16767   match(Set dst (AddVI dst (MulVI src1 src2)));
16768   ins_cost(INSN_COST);
16769   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16770   ins_encode %{
16771     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16772             as_FloatRegister($src1$$reg),
16773             as_FloatRegister($src2$$reg));
16774   %}
16775   ins_pipe(vmla64);
16776 %}
16777 
16778 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16779 %{
16780   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16781   match(Set dst (AddVI dst (MulVI src1 src2)));
16782   ins_cost(INSN_COST);
16783   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16784   ins_encode %{
16785     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16786             as_FloatRegister($src1$$reg),
16787             as_FloatRegister($src2$$reg));
16788   %}
16789   ins_pipe(vmla128);
16790 %}
16791 
16792 // dst + src1 * src2
16793 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16794   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16795   match(Set dst (FmaVF  dst (Binary src1 src2)));
16796   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16797   ins_cost(INSN_COST);
16798   ins_encode %{
16799     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16800             as_FloatRegister($src1$$reg),
16801             as_FloatRegister($src2$$reg));
16802   %}
16803   ins_pipe(vmuldiv_fp64);
16804 %}
16805 
16806 // dst + src1 * src2
16807 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16808   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16809   match(Set dst (FmaVF  dst (Binary src1 src2)));
16810   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16811   ins_cost(INSN_COST);
16812   ins_encode %{
16813     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16814             as_FloatRegister($src1$$reg),
16815             as_FloatRegister($src2$$reg));
16816   %}
16817   ins_pipe(vmuldiv_fp128);
16818 %}
16819 
16820 // dst + src1 * src2
16821 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16822   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16823   match(Set dst (FmaVD  dst (Binary src1 src2)));
16824   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16825   ins_cost(INSN_COST);
16826   ins_encode %{
16827     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16828             as_FloatRegister($src1$$reg),
16829             as_FloatRegister($src2$$reg));
16830   %}
16831   ins_pipe(vmuldiv_fp128);
16832 %}
16833 
16834 // --------------------------------- MLS --------------------------------------
16835 
16836 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16837 %{
16838   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16839             n-&gt;as_Vector()-&gt;length() == 4);
16840   match(Set dst (SubVS dst (MulVS src1 src2)));
16841   ins_cost(INSN_COST);
16842   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16843   ins_encode %{
16844     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16845             as_FloatRegister($src1$$reg),
16846             as_FloatRegister($src2$$reg));
16847   %}
16848   ins_pipe(vmla64);
16849 %}
16850 
16851 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16852 %{
16853   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16854   match(Set dst (SubVS dst (MulVS src1 src2)));
16855   ins_cost(INSN_COST);
16856   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16857   ins_encode %{
16858     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16859             as_FloatRegister($src1$$reg),
16860             as_FloatRegister($src2$$reg));
16861   %}
16862   ins_pipe(vmla128);
16863 %}
16864 
16865 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16866 %{
16867   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16868   match(Set dst (SubVI dst (MulVI src1 src2)));
16869   ins_cost(INSN_COST);
16870   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16871   ins_encode %{
16872     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16873             as_FloatRegister($src1$$reg),
16874             as_FloatRegister($src2$$reg));
16875   %}
16876   ins_pipe(vmla64);
16877 %}
16878 
16879 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16880 %{
16881   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16882   match(Set dst (SubVI dst (MulVI src1 src2)));
16883   ins_cost(INSN_COST);
16884   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16885   ins_encode %{
16886     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16887             as_FloatRegister($src1$$reg),
16888             as_FloatRegister($src2$$reg));
16889   %}
16890   ins_pipe(vmla128);
16891 %}
16892 
16893 // dst - src1 * src2
16894 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16895   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16896   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16897   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16898   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16899   ins_cost(INSN_COST);
16900   ins_encode %{
16901     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16902             as_FloatRegister($src1$$reg),
16903             as_FloatRegister($src2$$reg));
16904   %}
16905   ins_pipe(vmuldiv_fp64);
16906 %}
16907 
16908 // dst - src1 * src2
16909 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16910   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16911   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16912   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16913   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16914   ins_cost(INSN_COST);
16915   ins_encode %{
16916     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16917             as_FloatRegister($src1$$reg),
16918             as_FloatRegister($src2$$reg));
16919   %}
16920   ins_pipe(vmuldiv_fp128);
16921 %}
16922 
16923 // dst - src1 * src2
16924 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16925   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16926   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16927   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16928   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16929   ins_cost(INSN_COST);
16930   ins_encode %{
16931     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16932             as_FloatRegister($src1$$reg),
16933             as_FloatRegister($src2$$reg));
16934   %}
16935   ins_pipe(vmuldiv_fp128);
16936 %}
16937 
16938 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16939 
16940 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16941   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16942   match(Set dst (MulAddVS2VI src1 src2));
16943   ins_cost(INSN_COST);
16944   effect(TEMP_DEF dst, TEMP tmp);
16945   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16946             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16947             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16948   ins_encode %{
16949     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16950               as_FloatRegister($src1$$reg),
16951               as_FloatRegister($src2$$reg));
16952     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16953               as_FloatRegister($src1$$reg),
16954               as_FloatRegister($src2$$reg));
16955     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16956              as_FloatRegister($tmp$$reg),
16957              as_FloatRegister($dst$$reg));
16958   %}
16959   ins_pipe(vmuldiv_fp128);
16960 %}
16961 
16962 // --------------------------------- DIV --------------------------------------
16963 
16964 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16965 %{
16966   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16967   match(Set dst (DivVF src1 src2));
16968   ins_cost(INSN_COST);
16969   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16970   ins_encode %{
16971     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16972             as_FloatRegister($src1$$reg),
16973             as_FloatRegister($src2$$reg));
16974   %}
16975   ins_pipe(vmuldiv_fp64);
16976 %}
16977 
16978 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16979 %{
16980   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16981   match(Set dst (DivVF src1 src2));
16982   ins_cost(INSN_COST);
16983   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16984   ins_encode %{
16985     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16986             as_FloatRegister($src1$$reg),
16987             as_FloatRegister($src2$$reg));
16988   %}
16989   ins_pipe(vmuldiv_fp128);
16990 %}
16991 
16992 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16993 %{
16994   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16995   match(Set dst (DivVD src1 src2));
16996   ins_cost(INSN_COST);
16997   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16998   ins_encode %{
16999     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17000             as_FloatRegister($src1$$reg),
17001             as_FloatRegister($src2$$reg));
17002   %}
17003   ins_pipe(vmuldiv_fp128);
17004 %}
17005 
17006 // --------------------------------- SQRT -------------------------------------
17007 
17008 instruct vsqrt2F(vecD dst, vecD src)
17009 %{
17010   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17011   match(Set dst (SqrtVF src));
17012   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17013   ins_encode %{
17014     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17015   %}
17016   ins_pipe(vunop_fp64);
17017 %}
17018 
17019 instruct vsqrt4F(vecX dst, vecX src)
17020 %{
17021   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17022   match(Set dst (SqrtVF src));
17023   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17024   ins_encode %{
17025     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17026   %}
17027   ins_pipe(vsqrt_fp128);
17028 %}
17029 
17030 instruct vsqrt2D(vecX dst, vecX src)
17031 %{
17032   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17033   match(Set dst (SqrtVD src));
17034   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17035   ins_encode %{
17036     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17037              as_FloatRegister($src$$reg));
17038   %}
17039   ins_pipe(vsqrt_fp128);
17040 %}
17041 
17042 // --------------------------------- ABS --------------------------------------
17043 
17044 instruct vabs8B(vecD dst, vecD src)
17045 %{
17046   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17047             n-&gt;as_Vector()-&gt;length() == 8);
17048   match(Set dst (AbsVB src));
17049   ins_cost(INSN_COST);
17050   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17051   ins_encode %{
17052     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17053   %}
17054   ins_pipe(vlogical64);
17055 %}
17056 
17057 instruct vabs16B(vecX dst, vecX src)
17058 %{
17059   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17060   match(Set dst (AbsVB src));
17061   ins_cost(INSN_COST);
17062   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17063   ins_encode %{
17064     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17065   %}
17066   ins_pipe(vlogical128);
17067 %}
17068 
17069 instruct vabs4S(vecD dst, vecD src)
17070 %{
17071   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17072   match(Set dst (AbsVS src));
17073   ins_cost(INSN_COST);
17074   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17075   ins_encode %{
17076     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17077   %}
17078   ins_pipe(vlogical64);
17079 %}
17080 
17081 instruct vabs8S(vecX dst, vecX src)
17082 %{
17083   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17084   match(Set dst (AbsVS src));
17085   ins_cost(INSN_COST);
17086   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17087   ins_encode %{
17088     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17089   %}
17090   ins_pipe(vlogical128);
17091 %}
17092 
17093 instruct vabs2I(vecD dst, vecD src)
17094 %{
17095   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17096   match(Set dst (AbsVI src));
17097   ins_cost(INSN_COST);
17098   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17099   ins_encode %{
17100     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17101   %}
17102   ins_pipe(vlogical64);
17103 %}
17104 
17105 instruct vabs4I(vecX dst, vecX src)
17106 %{
17107   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17108   match(Set dst (AbsVI src));
17109   ins_cost(INSN_COST);
17110   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17111   ins_encode %{
17112     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17113   %}
17114   ins_pipe(vlogical128);
17115 %}
17116 
17117 instruct vabs2L(vecX dst, vecX src)
17118 %{
17119   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17120   match(Set dst (AbsVL src));
17121   ins_cost(INSN_COST);
17122   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17123   ins_encode %{
17124     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17125   %}
17126   ins_pipe(vlogical128);
17127 %}
17128 
17129 instruct vabs2F(vecD dst, vecD src)
17130 %{
17131   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17132   match(Set dst (AbsVF src));
17133   ins_cost(INSN_COST * 3);
17134   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17135   ins_encode %{
17136     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17137             as_FloatRegister($src$$reg));
17138   %}
17139   ins_pipe(vunop_fp64);
17140 %}
17141 
17142 instruct vabs4F(vecX dst, vecX src)
17143 %{
17144   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17145   match(Set dst (AbsVF src));
17146   ins_cost(INSN_COST * 3);
17147   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17148   ins_encode %{
17149     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17150             as_FloatRegister($src$$reg));
17151   %}
17152   ins_pipe(vunop_fp128);
17153 %}
17154 
17155 instruct vabs2D(vecX dst, vecX src)
17156 %{
17157   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17158   match(Set dst (AbsVD src));
17159   ins_cost(INSN_COST * 3);
17160   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17161   ins_encode %{
17162     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17163             as_FloatRegister($src$$reg));
17164   %}
17165   ins_pipe(vunop_fp128);
17166 %}
17167 
17168 // --------------------------------- NEG --------------------------------------
17169 
17170 instruct vneg2F(vecD dst, vecD src)
17171 %{
17172   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17173   match(Set dst (NegVF src));
17174   ins_cost(INSN_COST * 3);
17175   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17176   ins_encode %{
17177     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17178             as_FloatRegister($src$$reg));
17179   %}
17180   ins_pipe(vunop_fp64);
17181 %}
17182 
17183 instruct vneg4F(vecX dst, vecX src)
17184 %{
17185   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17186   match(Set dst (NegVF src));
17187   ins_cost(INSN_COST * 3);
17188   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17189   ins_encode %{
17190     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17191             as_FloatRegister($src$$reg));
17192   %}
17193   ins_pipe(vunop_fp128);
17194 %}
17195 
17196 instruct vneg2D(vecX dst, vecX src)
17197 %{
17198   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17199   match(Set dst (NegVD src));
17200   ins_cost(INSN_COST * 3);
17201   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17202   ins_encode %{
17203     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17204             as_FloatRegister($src$$reg));
17205   %}
17206   ins_pipe(vunop_fp128);
17207 %}
17208 
17209 // --------------------------------- AND --------------------------------------
17210 
17211 instruct vand8B(vecD dst, vecD src1, vecD src2)
17212 %{
17213   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17214             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17215   match(Set dst (AndV src1 src2));
17216   ins_cost(INSN_COST);
17217   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17218   ins_encode %{
17219     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17220             as_FloatRegister($src1$$reg),
17221             as_FloatRegister($src2$$reg));
17222   %}
17223   ins_pipe(vlogical64);
17224 %}
17225 
17226 instruct vand16B(vecX dst, vecX src1, vecX src2)
17227 %{
17228   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17229   match(Set dst (AndV src1 src2));
17230   ins_cost(INSN_COST);
17231   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17232   ins_encode %{
17233     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17234             as_FloatRegister($src1$$reg),
17235             as_FloatRegister($src2$$reg));
17236   %}
17237   ins_pipe(vlogical128);
17238 %}
17239 
17240 // --------------------------------- OR ---------------------------------------
17241 
17242 instruct vor8B(vecD dst, vecD src1, vecD src2)
17243 %{
17244   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17245             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17246   match(Set dst (OrV src1 src2));
17247   ins_cost(INSN_COST);
17248   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17249   ins_encode %{
17250     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17251             as_FloatRegister($src1$$reg),
17252             as_FloatRegister($src2$$reg));
17253   %}
17254   ins_pipe(vlogical64);
17255 %}
17256 
17257 instruct vor16B(vecX dst, vecX src1, vecX src2)
17258 %{
17259   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17260   match(Set dst (OrV src1 src2));
17261   ins_cost(INSN_COST);
17262   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17263   ins_encode %{
17264     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17265             as_FloatRegister($src1$$reg),
17266             as_FloatRegister($src2$$reg));
17267   %}
17268   ins_pipe(vlogical128);
17269 %}
17270 
17271 // --------------------------------- XOR --------------------------------------
17272 
17273 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17274 %{
17275   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17276             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17277   match(Set dst (XorV src1 src2));
17278   ins_cost(INSN_COST);
17279   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17280   ins_encode %{
17281     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17282             as_FloatRegister($src1$$reg),
17283             as_FloatRegister($src2$$reg));
17284   %}
17285   ins_pipe(vlogical64);
17286 %}
17287 
17288 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17289 %{
17290   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17291   match(Set dst (XorV src1 src2));
17292   ins_cost(INSN_COST);
17293   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17294   ins_encode %{
17295     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17296             as_FloatRegister($src1$$reg),
17297             as_FloatRegister($src2$$reg));
17298   %}
17299   ins_pipe(vlogical128);
17300 %}
17301 
17302 // ------------------------------ Shift ---------------------------------------
17303 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17304   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17305   match(Set dst (LShiftCntV cnt));
17306   match(Set dst (RShiftCntV cnt));
17307   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17308   ins_encode %{
17309     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17310   %}
17311   ins_pipe(vdup_reg_reg64);
17312 %}
17313 
17314 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17315   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17316   match(Set dst (LShiftCntV cnt));
17317   match(Set dst (RShiftCntV cnt));
17318   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17319   ins_encode %{
17320     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17321   %}
17322   ins_pipe(vdup_reg_reg128);
17323 %}
17324 
17325 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17326   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17327             n-&gt;as_Vector()-&gt;length() == 8);
17328   match(Set dst (LShiftVB src shift));
17329   ins_cost(INSN_COST);
17330   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17331   ins_encode %{
17332     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17333             as_FloatRegister($src$$reg),
17334             as_FloatRegister($shift$$reg));
17335   %}
17336   ins_pipe(vshift64);
17337 %}
17338 
17339 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17340   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17341   match(Set dst (LShiftVB src shift));
17342   ins_cost(INSN_COST);
17343   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17344   ins_encode %{
17345     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17346             as_FloatRegister($src$$reg),
17347             as_FloatRegister($shift$$reg));
17348   %}
17349   ins_pipe(vshift128);
17350 %}
17351 
17352 // Right shifts with vector shift count on aarch64 SIMD are implemented
17353 // as left shift by negative shift count.
17354 // There are two cases for vector shift count.
17355 //
17356 // Case 1: The vector shift count is from replication.
17357 //        |            |
17358 //    LoadVector  RShiftCntV
17359 //        |       /
17360 //     RShiftVI
17361 // Note: In inner loop, multiple neg instructions are used, which can be
17362 // moved to outer loop and merge into one neg instruction.
17363 //
17364 // Case 2: The vector shift count is from loading.
17365 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17366 // panama/vectorIntrinsics(JEP 338: Vector API).
17367 //        |            |
17368 //    LoadVector  LoadVector
17369 //        |       /
17370 //     RShiftVI
17371 //
17372 
17373 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17374   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17375             n-&gt;as_Vector()-&gt;length() == 8);
17376   match(Set dst (RShiftVB src shift));
17377   ins_cost(INSN_COST);
17378   effect(TEMP tmp);
17379   format %{ &quot;negr  $tmp,$shift\t&quot;
17380             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17381   ins_encode %{
17382     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17383             as_FloatRegister($shift$$reg));
17384     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17385             as_FloatRegister($src$$reg),
17386             as_FloatRegister($tmp$$reg));
17387   %}
17388   ins_pipe(vshift64);
17389 %}
17390 
17391 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17392   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17393   match(Set dst (RShiftVB src shift));
17394   ins_cost(INSN_COST);
17395   effect(TEMP tmp);
17396   format %{ &quot;negr  $tmp,$shift\t&quot;
17397             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17398   ins_encode %{
17399     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17400             as_FloatRegister($shift$$reg));
17401     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17402             as_FloatRegister($src$$reg),
17403             as_FloatRegister($tmp$$reg));
17404   %}
17405   ins_pipe(vshift128);
17406 %}
17407 
17408 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17409   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17410             n-&gt;as_Vector()-&gt;length() == 8);
17411   match(Set dst (URShiftVB src shift));
17412   ins_cost(INSN_COST);
17413   effect(TEMP tmp);
17414   format %{ &quot;negr  $tmp,$shift\t&quot;
17415             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17416   ins_encode %{
17417     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17418             as_FloatRegister($shift$$reg));
17419     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17420             as_FloatRegister($src$$reg),
17421             as_FloatRegister($tmp$$reg));
17422   %}
17423   ins_pipe(vshift64);
17424 %}
17425 
17426 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17427   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17428   match(Set dst (URShiftVB src shift));
17429   ins_cost(INSN_COST);
17430   effect(TEMP tmp);
17431   format %{ &quot;negr  $tmp,$shift\t&quot;
17432             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17433   ins_encode %{
17434     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17435             as_FloatRegister($shift$$reg));
17436     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17437             as_FloatRegister($src$$reg),
17438             as_FloatRegister($tmp$$reg));
17439   %}
17440   ins_pipe(vshift128);
17441 %}
17442 
17443 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17444   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17445             n-&gt;as_Vector()-&gt;length() == 8);
17446   match(Set dst (LShiftVB src (LShiftCntV shift)));
17447   ins_cost(INSN_COST);
17448   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17449   ins_encode %{
17450     int sh = (int)$shift$$constant;
17451     if (sh &gt;= 8) {
17452       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17453              as_FloatRegister($src$$reg),
17454              as_FloatRegister($src$$reg));
17455     } else {
17456       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17457              as_FloatRegister($src$$reg), sh);
17458     }
17459   %}
17460   ins_pipe(vshift64_imm);
17461 %}
17462 
17463 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17464   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17465   match(Set dst (LShiftVB src (LShiftCntV shift)));
17466   ins_cost(INSN_COST);
17467   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17468   ins_encode %{
17469     int sh = (int)$shift$$constant;
17470     if (sh &gt;= 8) {
17471       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17472              as_FloatRegister($src$$reg),
17473              as_FloatRegister($src$$reg));
17474     } else {
17475       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17476              as_FloatRegister($src$$reg), sh);
17477     }
17478   %}
17479   ins_pipe(vshift128_imm);
17480 %}
17481 
17482 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17483   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17484             n-&gt;as_Vector()-&gt;length() == 8);
17485   match(Set dst (RShiftVB src (RShiftCntV shift)));
17486   ins_cost(INSN_COST);
17487   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17488   ins_encode %{
17489     int sh = (int)$shift$$constant;
17490     if (sh &gt;= 8) sh = 7;
17491     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17492            as_FloatRegister($src$$reg), sh);
17493   %}
17494   ins_pipe(vshift64_imm);
17495 %}
17496 
17497 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17498   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17499   match(Set dst (RShiftVB src (RShiftCntV shift)));
17500   ins_cost(INSN_COST);
17501   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17502   ins_encode %{
17503     int sh = (int)$shift$$constant;
17504     if (sh &gt;= 8) sh = 7;
17505     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17506            as_FloatRegister($src$$reg), sh);
17507   %}
17508   ins_pipe(vshift128_imm);
17509 %}
17510 
17511 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17512   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17513             n-&gt;as_Vector()-&gt;length() == 8);
17514   match(Set dst (URShiftVB src (RShiftCntV shift)));
17515   ins_cost(INSN_COST);
17516   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17517   ins_encode %{
17518     int sh = (int)$shift$$constant;
17519     if (sh &gt;= 8) {
17520       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17521              as_FloatRegister($src$$reg),
17522              as_FloatRegister($src$$reg));
17523     } else {
17524       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17525              as_FloatRegister($src$$reg), sh);
17526     }
17527   %}
17528   ins_pipe(vshift64_imm);
17529 %}
17530 
17531 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17532   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17533   match(Set dst (URShiftVB src (RShiftCntV shift)));
17534   ins_cost(INSN_COST);
17535   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17536   ins_encode %{
17537     int sh = (int)$shift$$constant;
17538     if (sh &gt;= 8) {
17539       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17540              as_FloatRegister($src$$reg),
17541              as_FloatRegister($src$$reg));
17542     } else {
17543       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17544              as_FloatRegister($src$$reg), sh);
17545     }
17546   %}
17547   ins_pipe(vshift128_imm);
17548 %}
17549 
17550 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17551   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17552             n-&gt;as_Vector()-&gt;length() == 4);
17553   match(Set dst (LShiftVS src shift));
17554   ins_cost(INSN_COST);
17555   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17556   ins_encode %{
17557     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17558             as_FloatRegister($src$$reg),
17559             as_FloatRegister($shift$$reg));
17560   %}
17561   ins_pipe(vshift64);
17562 %}
17563 
17564 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17565   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17566   match(Set dst (LShiftVS src shift));
17567   ins_cost(INSN_COST);
17568   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17569   ins_encode %{
17570     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17571             as_FloatRegister($src$$reg),
17572             as_FloatRegister($shift$$reg));
17573   %}
17574   ins_pipe(vshift128);
17575 %}
17576 
17577 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17578   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17579             n-&gt;as_Vector()-&gt;length() == 4);
17580   match(Set dst (RShiftVS src shift));
17581   ins_cost(INSN_COST);
17582   effect(TEMP tmp);
17583   format %{ &quot;negr  $tmp,$shift\t&quot;
17584             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17585   ins_encode %{
17586     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17587             as_FloatRegister($shift$$reg));
17588     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17589             as_FloatRegister($src$$reg),
17590             as_FloatRegister($tmp$$reg));
17591   %}
17592   ins_pipe(vshift64);
17593 %}
17594 
17595 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17596   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17597   match(Set dst (RShiftVS src shift));
17598   ins_cost(INSN_COST);
17599   effect(TEMP tmp);
17600   format %{ &quot;negr  $tmp,$shift\t&quot;
17601             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17602   ins_encode %{
17603     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17604             as_FloatRegister($shift$$reg));
17605     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17606             as_FloatRegister($src$$reg),
17607             as_FloatRegister($tmp$$reg));
17608   %}
17609   ins_pipe(vshift128);
17610 %}
17611 
17612 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17613   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17614             n-&gt;as_Vector()-&gt;length() == 4);
17615   match(Set dst (URShiftVS src shift));
17616   ins_cost(INSN_COST);
17617   effect(TEMP tmp);
17618   format %{ &quot;negr  $tmp,$shift\t&quot;
17619             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17620   ins_encode %{
17621     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17622             as_FloatRegister($shift$$reg));
17623     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17624             as_FloatRegister($src$$reg),
17625             as_FloatRegister($tmp$$reg));
17626   %}
17627   ins_pipe(vshift64);
17628 %}
17629 
17630 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17631   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17632   match(Set dst (URShiftVS src shift));
17633   ins_cost(INSN_COST);
17634   effect(TEMP tmp);
17635   format %{ &quot;negr  $tmp,$shift\t&quot;
17636             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17637   ins_encode %{
17638     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17639             as_FloatRegister($shift$$reg));
17640     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17641             as_FloatRegister($src$$reg),
17642             as_FloatRegister($tmp$$reg));
17643   %}
17644   ins_pipe(vshift128);
17645 %}
17646 
17647 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17648   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17649             n-&gt;as_Vector()-&gt;length() == 4);
17650   match(Set dst (LShiftVS src (LShiftCntV shift)));
17651   ins_cost(INSN_COST);
17652   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17653   ins_encode %{
17654     int sh = (int)$shift$$constant;
17655     if (sh &gt;= 16) {
17656       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17657              as_FloatRegister($src$$reg),
17658              as_FloatRegister($src$$reg));
17659     } else {
17660       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17661              as_FloatRegister($src$$reg), sh);
17662     }
17663   %}
17664   ins_pipe(vshift64_imm);
17665 %}
17666 
17667 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17668   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17669   match(Set dst (LShiftVS src (LShiftCntV shift)));
17670   ins_cost(INSN_COST);
17671   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17672   ins_encode %{
17673     int sh = (int)$shift$$constant;
17674     if (sh &gt;= 16) {
17675       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17676              as_FloatRegister($src$$reg),
17677              as_FloatRegister($src$$reg));
17678     } else {
17679       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17680              as_FloatRegister($src$$reg), sh);
17681     }
17682   %}
17683   ins_pipe(vshift128_imm);
17684 %}
17685 
17686 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17687   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17688             n-&gt;as_Vector()-&gt;length() == 4);
17689   match(Set dst (RShiftVS src (RShiftCntV shift)));
17690   ins_cost(INSN_COST);
17691   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17692   ins_encode %{
17693     int sh = (int)$shift$$constant;
17694     if (sh &gt;= 16) sh = 15;
17695     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17696            as_FloatRegister($src$$reg), sh);
17697   %}
17698   ins_pipe(vshift64_imm);
17699 %}
17700 
17701 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17702   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17703   match(Set dst (RShiftVS src (RShiftCntV shift)));
17704   ins_cost(INSN_COST);
17705   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17706   ins_encode %{
17707     int sh = (int)$shift$$constant;
17708     if (sh &gt;= 16) sh = 15;
17709     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17710            as_FloatRegister($src$$reg), sh);
17711   %}
17712   ins_pipe(vshift128_imm);
17713 %}
17714 
17715 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17716   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17717             n-&gt;as_Vector()-&gt;length() == 4);
17718   match(Set dst (URShiftVS src (RShiftCntV shift)));
17719   ins_cost(INSN_COST);
17720   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17721   ins_encode %{
17722     int sh = (int)$shift$$constant;
17723     if (sh &gt;= 16) {
17724       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17725              as_FloatRegister($src$$reg),
17726              as_FloatRegister($src$$reg));
17727     } else {
17728       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17729              as_FloatRegister($src$$reg), sh);
17730     }
17731   %}
17732   ins_pipe(vshift64_imm);
17733 %}
17734 
17735 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17736   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17737   match(Set dst (URShiftVS src (RShiftCntV shift)));
17738   ins_cost(INSN_COST);
17739   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17740   ins_encode %{
17741     int sh = (int)$shift$$constant;
17742     if (sh &gt;= 16) {
17743       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17744              as_FloatRegister($src$$reg),
17745              as_FloatRegister($src$$reg));
17746     } else {
17747       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17748              as_FloatRegister($src$$reg), sh);
17749     }
17750   %}
17751   ins_pipe(vshift128_imm);
17752 %}
17753 
17754 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17755   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17756   match(Set dst (LShiftVI src shift));
17757   ins_cost(INSN_COST);
17758   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17759   ins_encode %{
17760     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17761             as_FloatRegister($src$$reg),
17762             as_FloatRegister($shift$$reg));
17763   %}
17764   ins_pipe(vshift64);
17765 %}
17766 
17767 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17768   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17769   match(Set dst (LShiftVI src shift));
17770   ins_cost(INSN_COST);
17771   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17772   ins_encode %{
17773     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17774             as_FloatRegister($src$$reg),
17775             as_FloatRegister($shift$$reg));
17776   %}
17777   ins_pipe(vshift128);
17778 %}
17779 
17780 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17781   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17782   match(Set dst (RShiftVI src shift));
17783   ins_cost(INSN_COST);
17784   effect(TEMP tmp);
17785   format %{ &quot;negr  $tmp,$shift\t&quot;
17786             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17787   ins_encode %{
17788     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17789             as_FloatRegister($shift$$reg));
17790     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17791             as_FloatRegister($src$$reg),
17792             as_FloatRegister($tmp$$reg));
17793   %}
17794   ins_pipe(vshift64);
17795 %}
17796 
17797 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17798   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17799   match(Set dst (RShiftVI src shift));
17800   ins_cost(INSN_COST);
17801   effect(TEMP tmp);
17802   format %{ &quot;negr  $tmp,$shift\t&quot;
17803             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17804   ins_encode %{
17805     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17806             as_FloatRegister($shift$$reg));
17807     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17808             as_FloatRegister($src$$reg),
17809             as_FloatRegister($tmp$$reg));
17810   %}
17811   ins_pipe(vshift128);
17812 %}
17813 
17814 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17815   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17816   match(Set dst (URShiftVI src shift));
17817   ins_cost(INSN_COST);
17818   effect(TEMP tmp);
17819   format %{ &quot;negr  $tmp,$shift\t&quot;
17820             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17821   ins_encode %{
17822     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17823             as_FloatRegister($shift$$reg));
17824     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17825             as_FloatRegister($src$$reg),
17826             as_FloatRegister($tmp$$reg));
17827   %}
17828   ins_pipe(vshift64);
17829 %}
17830 
17831 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17832   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17833   match(Set dst (URShiftVI src shift));
17834   ins_cost(INSN_COST);
17835   effect(TEMP tmp);
17836   format %{ &quot;negr  $tmp,$shift\t&quot;
17837             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17838   ins_encode %{
17839     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17840             as_FloatRegister($shift$$reg));
17841     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17842             as_FloatRegister($src$$reg),
17843             as_FloatRegister($tmp$$reg));
17844   %}
17845   ins_pipe(vshift128);
17846 %}
17847 
17848 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17849   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17850   match(Set dst (LShiftVI src (LShiftCntV shift)));
17851   ins_cost(INSN_COST);
17852   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17853   ins_encode %{
17854     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17855            as_FloatRegister($src$$reg),
17856            (int)$shift$$constant);
17857   %}
17858   ins_pipe(vshift64_imm);
17859 %}
17860 
17861 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17862   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17863   match(Set dst (LShiftVI src (LShiftCntV shift)));
17864   ins_cost(INSN_COST);
17865   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17866   ins_encode %{
17867     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17868            as_FloatRegister($src$$reg),
17869            (int)$shift$$constant);
17870   %}
17871   ins_pipe(vshift128_imm);
17872 %}
17873 
17874 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17875   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17876   match(Set dst (RShiftVI src (RShiftCntV shift)));
17877   ins_cost(INSN_COST);
17878   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17879   ins_encode %{
17880     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17881             as_FloatRegister($src$$reg),
17882             (int)$shift$$constant);
17883   %}
17884   ins_pipe(vshift64_imm);
17885 %}
17886 
17887 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17888   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17889   match(Set dst (RShiftVI src (RShiftCntV shift)));
17890   ins_cost(INSN_COST);
17891   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17892   ins_encode %{
17893     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17894             as_FloatRegister($src$$reg),
17895             (int)$shift$$constant);
17896   %}
17897   ins_pipe(vshift128_imm);
17898 %}
17899 
17900 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17901   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17902   match(Set dst (URShiftVI src (RShiftCntV shift)));
17903   ins_cost(INSN_COST);
17904   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17905   ins_encode %{
17906     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17907             as_FloatRegister($src$$reg),
17908             (int)$shift$$constant);
17909   %}
17910   ins_pipe(vshift64_imm);
17911 %}
17912 
17913 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17914   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17915   match(Set dst (URShiftVI src (RShiftCntV shift)));
17916   ins_cost(INSN_COST);
17917   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17918   ins_encode %{
17919     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17920             as_FloatRegister($src$$reg),
17921             (int)$shift$$constant);
17922   %}
17923   ins_pipe(vshift128_imm);
17924 %}
17925 
17926 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17927   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17928   match(Set dst (LShiftVL src shift));
17929   ins_cost(INSN_COST);
17930   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17931   ins_encode %{
17932     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17933             as_FloatRegister($src$$reg),
17934             as_FloatRegister($shift$$reg));
17935   %}
17936   ins_pipe(vshift128);
17937 %}
17938 
17939 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17940   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17941   match(Set dst (RShiftVL src shift));
17942   ins_cost(INSN_COST);
17943   effect(TEMP tmp);
17944   format %{ &quot;negr  $tmp,$shift\t&quot;
17945             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17946   ins_encode %{
17947     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17948             as_FloatRegister($shift$$reg));
17949     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17950             as_FloatRegister($src$$reg),
17951             as_FloatRegister($tmp$$reg));
17952   %}
17953   ins_pipe(vshift128);
17954 %}
17955 
17956 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17957   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17958   match(Set dst (URShiftVL src shift));
17959   ins_cost(INSN_COST);
17960   effect(TEMP tmp);
17961   format %{ &quot;negr  $tmp,$shift\t&quot;
17962             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17963   ins_encode %{
17964     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17965             as_FloatRegister($shift$$reg));
17966     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17967             as_FloatRegister($src$$reg),
17968             as_FloatRegister($tmp$$reg));
17969   %}
17970   ins_pipe(vshift128);
17971 %}
17972 
17973 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17974   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17975   match(Set dst (LShiftVL src (LShiftCntV shift)));
17976   ins_cost(INSN_COST);
17977   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17978   ins_encode %{
17979     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17980            as_FloatRegister($src$$reg),
17981            (int)$shift$$constant);
17982   %}
17983   ins_pipe(vshift128_imm);
17984 %}
17985 
17986 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17987   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17988   match(Set dst (RShiftVL src (RShiftCntV shift)));
17989   ins_cost(INSN_COST);
17990   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17991   ins_encode %{
17992     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17993             as_FloatRegister($src$$reg),
17994             (int)$shift$$constant);
17995   %}
17996   ins_pipe(vshift128_imm);
17997 %}
17998 
17999 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
18000   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18001   match(Set dst (URShiftVL src (RShiftCntV shift)));
18002   ins_cost(INSN_COST);
18003   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18004   ins_encode %{
18005     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18006             as_FloatRegister($src$$reg),
18007             (int)$shift$$constant);
18008   %}
18009   ins_pipe(vshift128_imm);
18010 %}
18011 
18012 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18013 %{
18014   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18015   match(Set dst (MaxV src1 src2));
18016   ins_cost(INSN_COST);
18017   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18018   ins_encode %{
18019     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18020             as_FloatRegister($src1$$reg),
18021             as_FloatRegister($src2$$reg));
18022   %}
18023   ins_pipe(vdop_fp64);
18024 %}
18025 
18026 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18027 %{
18028   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18029   match(Set dst (MaxV src1 src2));
18030   ins_cost(INSN_COST);
18031   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18032   ins_encode %{
18033     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18034             as_FloatRegister($src1$$reg),
18035             as_FloatRegister($src2$$reg));
18036   %}
18037   ins_pipe(vdop_fp128);
18038 %}
18039 
18040 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18041 %{
18042   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18043   match(Set dst (MaxV src1 src2));
18044   ins_cost(INSN_COST);
18045   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18046   ins_encode %{
18047     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18048             as_FloatRegister($src1$$reg),
18049             as_FloatRegister($src2$$reg));
18050   %}
18051   ins_pipe(vdop_fp128);
18052 %}
18053 
18054 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18055 %{
18056   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18057   match(Set dst (MinV src1 src2));
18058   ins_cost(INSN_COST);
18059   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18060   ins_encode %{
18061     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18062             as_FloatRegister($src1$$reg),
18063             as_FloatRegister($src2$$reg));
18064   %}
18065   ins_pipe(vdop_fp64);
18066 %}
18067 
18068 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18069 %{
18070   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18071   match(Set dst (MinV src1 src2));
18072   ins_cost(INSN_COST);
18073   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18074   ins_encode %{
18075     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18076             as_FloatRegister($src1$$reg),
18077             as_FloatRegister($src2$$reg));
18078   %}
18079   ins_pipe(vdop_fp128);
18080 %}
18081 
18082 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18083 %{
18084   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18085   match(Set dst (MinV src1 src2));
18086   ins_cost(INSN_COST);
18087   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18088   ins_encode %{
18089     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18090             as_FloatRegister($src1$$reg),
18091             as_FloatRegister($src2$$reg));
18092   %}
18093   ins_pipe(vdop_fp128);
18094 %}
18095 
18096 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18097   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18098   match(Set dst (RoundDoubleModeV src rmode));
18099   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18100   ins_encode %{
18101     switch ($rmode$$constant) {
18102       case RoundDoubleModeNode::rmode_rint:
18103         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18104                   as_FloatRegister($src$$reg));
18105         break;
18106       case RoundDoubleModeNode::rmode_floor:
18107         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18108                   as_FloatRegister($src$$reg));
18109         break;
18110       case RoundDoubleModeNode::rmode_ceil:
18111         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18112                   as_FloatRegister($src$$reg));
18113         break;
18114     }
18115   %}
18116   ins_pipe(vdop_fp128);
18117 %}
18118 
18119 instruct vpopcount4I(vecX dst, vecX src) %{
18120   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18121   match(Set dst (PopCountVI src));
18122   format %{
18123     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18124     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18125     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18126   %}
18127   ins_encode %{
18128      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18129             as_FloatRegister($src$$reg));
18130      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18131                as_FloatRegister($dst$$reg));
18132      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18133                as_FloatRegister($dst$$reg));
18134   %}
18135   ins_pipe(pipe_class_default);
18136 %}
18137 
18138 instruct vpopcount2I(vecD dst, vecD src) %{
18139   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18140   match(Set dst (PopCountVI src));
18141   format %{
18142     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18143     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18144     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18145   %}
18146   ins_encode %{
18147      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18148             as_FloatRegister($src$$reg));
18149      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18150                as_FloatRegister($dst$$reg));
18151      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18152                as_FloatRegister($dst$$reg));
18153   %}
18154   ins_pipe(pipe_class_default);
18155 %}
18156 
18157 //----------PEEPHOLE RULES-----------------------------------------------------
18158 // These must follow all instruction definitions as they use the names
18159 // defined in the instructions definitions.
18160 //
18161 // peepmatch ( root_instr_name [preceding_instruction]* );
18162 //
18163 // peepconstraint %{
18164 // (instruction_number.operand_name relational_op instruction_number.operand_name
18165 //  [, ...] );
18166 // // instruction numbers are zero-based using left to right order in peepmatch
18167 //
18168 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18169 // // provide an instruction_number.operand_name for each operand that appears
18170 // // in the replacement instruction&#39;s match rule
18171 //
18172 // ---------VM FLAGS---------------------------------------------------------
18173 //
18174 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18175 //
18176 // Each peephole rule is given an identifying number starting with zero and
18177 // increasing by one in the order seen by the parser.  An individual peephole
18178 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18179 // on the command-line.
18180 //
18181 // ---------CURRENT LIMITATIONS----------------------------------------------
18182 //
18183 // Only match adjacent instructions in same basic block
18184 // Only equality constraints
18185 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18186 // Only one replacement instruction
18187 //
18188 // ---------EXAMPLE----------------------------------------------------------
18189 //
18190 // // pertinent parts of existing instructions in architecture description
18191 // instruct movI(iRegINoSp dst, iRegI src)
18192 // %{
18193 //   match(Set dst (CopyI src));
18194 // %}
18195 //
18196 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18197 // %{
18198 //   match(Set dst (AddI dst src));
18199 //   effect(KILL cr);
18200 // %}
18201 //
18202 // // Change (inc mov) to lea
18203 // peephole %{
18204 //   // increment preceeded by register-register move
18205 //   peepmatch ( incI_iReg movI );
18206 //   // require that the destination register of the increment
18207 //   // match the destination register of the move
18208 //   peepconstraint ( 0.dst == 1.dst );
18209 //   // construct a replacement instruction that sets
18210 //   // the destination to ( move&#39;s source register + one )
18211 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18212 // %}
18213 //
18214 
18215 // Implementation no longer uses movX instructions since
18216 // machine-independent system no longer uses CopyX nodes.
18217 //
18218 // peephole
18219 // %{
18220 //   peepmatch (incI_iReg movI);
18221 //   peepconstraint (0.dst == 1.dst);
18222 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18223 // %}
18224 
18225 // peephole
18226 // %{
18227 //   peepmatch (decI_iReg movI);
18228 //   peepconstraint (0.dst == 1.dst);
18229 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18230 // %}
18231 
18232 // peephole
18233 // %{
18234 //   peepmatch (addI_iReg_imm movI);
18235 //   peepconstraint (0.dst == 1.dst);
18236 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18237 // %}
18238 
18239 // peephole
18240 // %{
18241 //   peepmatch (incL_iReg movL);
18242 //   peepconstraint (0.dst == 1.dst);
18243 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18244 // %}
18245 
18246 // peephole
18247 // %{
18248 //   peepmatch (decL_iReg movL);
18249 //   peepconstraint (0.dst == 1.dst);
18250 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18251 // %}
18252 
18253 // peephole
18254 // %{
18255 //   peepmatch (addL_iReg_imm movL);
18256 //   peepconstraint (0.dst == 1.dst);
18257 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18258 // %}
18259 
18260 // peephole
18261 // %{
18262 //   peepmatch (addP_iReg_imm movP);
18263 //   peepconstraint (0.dst == 1.dst);
18264 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18265 // %}
18266 
18267 // // Change load of spilled value to only a spill
18268 // instruct storeI(memory mem, iRegI src)
18269 // %{
18270 //   match(Set mem (StoreI mem src));
18271 // %}
18272 //
18273 // instruct loadI(iRegINoSp dst, memory mem)
18274 // %{
18275 //   match(Set dst (LoadI mem));
18276 // %}
18277 //
18278 
18279 //----------SMARTSPILL RULES---------------------------------------------------
18280 // These must follow all instruction definitions as they use the names
18281 // defined in the instructions definitions.
18282 
18283 // Local Variables:
18284 // mode: c++
18285 // End:
<a name="11" id="anc11"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="11" type="hidden" />
</body>
</html>