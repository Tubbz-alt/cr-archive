<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 int MachCallNativeNode::ret_addr_offset() {
 1513   ShouldNotReachHere();
 1514   return -1;
 1515 }
 1516 
 1517 // Indicate if the safepoint node needs the polling page as an input
 1518 
 1519 // the shared code plants the oop data at the start of the generated
 1520 // code for the safepoint node and that needs ot be at the load
 1521 // instruction itself. so we cannot plant a mov of the safepoint poll
 1522 // address followed by a load. setting this to true means the mov is
 1523 // scheduled as a prior instruction. that&#39;s better for scheduling
 1524 // anyway.
 1525 
 1526 bool SafePointNode::needs_polling_address_input()
 1527 {
 1528   return true;
 1529 }
 1530 
 1531 //=============================================================================
 1532 
 1533 #ifndef PRODUCT
 1534 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1535   st-&gt;print(&quot;BREAKPOINT&quot;);
 1536 }
 1537 #endif
 1538 
 1539 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1540   C2_MacroAssembler _masm(&amp;cbuf);
 1541   __ brk(0);
 1542 }
 1543 
 1544 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1545   return MachNode::size(ra_);
 1546 }
 1547 
 1548 //=============================================================================
 1549 
 1550 #ifndef PRODUCT
 1551   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1552     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1553   }
 1554 #endif
 1555 
 1556   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1557     C2_MacroAssembler _masm(&amp;cbuf);
 1558     for (int i = 0; i &lt; _count; i++) {
 1559       __ nop();
 1560     }
 1561   }
 1562 
 1563   uint MachNopNode::size(PhaseRegAlloc*) const {
 1564     return _count * NativeInstruction::instruction_size;
 1565   }
 1566 
 1567 //=============================================================================
 1568 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1569 
 1570 int ConstantTable::calculate_table_base_offset() const {
 1571   return 0;  // absolute addressing, no offset
 1572 }
 1573 
 1574 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1575 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1576   ShouldNotReachHere();
 1577 }
 1578 
 1579 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1580   // Empty encoding
 1581 }
 1582 
 1583 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1584   return 0;
 1585 }
 1586 
 1587 #ifndef PRODUCT
 1588 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1589   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1590 }
 1591 #endif
 1592 
 1593 #ifndef PRODUCT
 1594 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1595   Compile* C = ra_-&gt;C;
 1596 
 1597   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1598 
 1599   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1600     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1601 
 1602   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1603     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1604     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1605     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1606   } else {
 1607     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1608     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1609     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1610     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1611   }
 1612   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1613     st-&gt;print(&quot;\n\t&quot;);
 1614     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1615     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1616     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1617     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1618     st-&gt;print(&quot;b.eq skip&quot;);
 1619     st-&gt;print(&quot;\n\t&quot;);
 1620     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1621     st-&gt;print(&quot;b skip\n\t&quot;);
 1622     st-&gt;print(&quot;guard: int\n\t&quot;);
 1623     st-&gt;print(&quot;\n\t&quot;);
 1624     st-&gt;print(&quot;skip:\n\t&quot;);
 1625   }
 1626 }
 1627 #endif
 1628 
 1629 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1630   Compile* C = ra_-&gt;C;
 1631   C2_MacroAssembler _masm(&amp;cbuf);
 1632 
 1633   // n.b. frame size includes space for return pc and rfp
 1634   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1635   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1636 
 1637   // insert a nop at the start of the prolog so we can patch in a
 1638   // branch if we need to invalidate the method later
 1639   __ nop();
 1640 
 1641   if (C-&gt;clinit_barrier_on_entry()) {
 1642     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1643 
 1644     Label L_skip_barrier;
 1645 
 1646     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1647     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1648     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1649     __ bind(L_skip_barrier);
 1650   }
 1651 
 1652   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1653   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1654     __ generate_stack_overflow_check(bangsize);
 1655 
 1656   __ build_frame(framesize);
 1657 
 1658   if (C-&gt;stub_function() == NULL) {
 1659     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1660     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1661   }
 1662 
 1663   if (VerifyStackAtCalls) {
 1664     Unimplemented();
 1665   }
 1666 
 1667   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1668 
 1669   if (C-&gt;has_mach_constant_base_node()) {
 1670     // NOTE: We set the table base offset here because users might be
 1671     // emitted before MachConstantBaseNode.
 1672     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1673     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1674   }
 1675 }
 1676 
 1677 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1678 {
 1679   return MachNode::size(ra_); // too many variables; just compute it
 1680                               // the hard way
 1681 }
 1682 
 1683 int MachPrologNode::reloc() const
 1684 {
 1685   return 0;
 1686 }
 1687 
 1688 //=============================================================================
 1689 
 1690 #ifndef PRODUCT
 1691 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1692   Compile* C = ra_-&gt;C;
 1693   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1694 
 1695   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1696 
 1697   if (framesize == 0) {
 1698     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1699   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1702   } else {
 1703     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1704     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1710     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1711     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1712   }
 1713 }
 1714 #endif
 1715 
 1716 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1717   Compile* C = ra_-&gt;C;
 1718   C2_MacroAssembler _masm(&amp;cbuf);
 1719   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1720 
 1721   __ remove_frame(framesize);
 1722 
 1723   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1724     __ reserved_stack_check();
 1725   }
 1726 
 1727   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1728     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1729   }
 1730 }
 1731 
 1732 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1733   // Variable size. Determine dynamically.
 1734   return MachNode::size(ra_);
 1735 }
 1736 
 1737 int MachEpilogNode::reloc() const {
 1738   // Return number of relocatable values contained in this instruction.
 1739   return 1; // 1 for polling page.
 1740 }
 1741 
 1742 const Pipeline * MachEpilogNode::pipeline() const {
 1743   return MachNode::pipeline_class();
 1744 }
 1745 
 1746 //=============================================================================
 1747 
 1748 // Figure out which register class each belongs in: rc_int, rc_float or
 1749 // rc_stack.
 1750 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1751 
 1752 static enum RC rc_class(OptoReg::Name reg) {
 1753 
 1754   if (reg == OptoReg::Bad) {
 1755     return rc_bad;
 1756   }
 1757 
 1758   // we have 30 int registers * 2 halves
 1759   // (rscratch1 and rscratch2 are omitted)
 1760   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1761 
 1762   if (reg &lt; slots_of_int_registers) {
 1763     return rc_int;
 1764   }
 1765 
 1766   // we have 32 float register * 4 halves
 1767   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1768     return rc_float;
 1769   }
 1770 
 1771   // Between float regs &amp; stack is the flags regs.
 1772   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1773 
 1774   return rc_stack;
 1775 }
 1776 
 1777 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1778   Compile* C = ra_-&gt;C;
 1779 
 1780   // Get registers to move.
 1781   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1782   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1783   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1784   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1785 
 1786   enum RC src_hi_rc = rc_class(src_hi);
 1787   enum RC src_lo_rc = rc_class(src_lo);
 1788   enum RC dst_hi_rc = rc_class(dst_hi);
 1789   enum RC dst_lo_rc = rc_class(dst_lo);
 1790 
 1791   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1792 
 1793   if (src_hi != OptoReg::Bad) {
 1794     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1795            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1796            &quot;expected aligned-adjacent pairs&quot;);
 1797   }
 1798 
 1799   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1800     return 0;            // Self copy, no move.
 1801   }
 1802 
 1803   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1804               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1805   int src_offset = ra_-&gt;reg2offset(src_lo);
 1806   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1807 
 1808   if (bottom_type()-&gt;isa_vect() != NULL) {
 1809     uint ireg = ideal_reg();
 1810     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1811     if (cbuf) {
 1812       C2_MacroAssembler _masm(cbuf);
 1813       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1814       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1815         // stack-&gt;stack
 1816         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1817         if (ireg == Op_VecD) {
 1818           __ unspill(rscratch1, true, src_offset);
 1819           __ spill(rscratch1, true, dst_offset);
 1820         } else {
 1821           __ spill_copy128(src_offset, dst_offset);
 1822         }
 1823       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1824         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1825                ireg == Op_VecD ? __ T8B : __ T16B,
 1826                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1827       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1828         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1829                        ireg == Op_VecD ? __ D : __ Q,
 1830                        ra_-&gt;reg2offset(dst_lo));
 1831       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1832         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1833                        ireg == Op_VecD ? __ D : __ Q,
 1834                        ra_-&gt;reg2offset(src_lo));
 1835       } else {
 1836         ShouldNotReachHere();
 1837       }
 1838     }
 1839   } else if (cbuf) {
 1840     C2_MacroAssembler _masm(cbuf);
 1841     switch (src_lo_rc) {
 1842     case rc_int:
 1843       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1844         if (is64) {
 1845             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1846                    as_Register(Matcher::_regEncode[src_lo]));
 1847         } else {
 1848             C2_MacroAssembler _masm(cbuf);
 1849             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1850                     as_Register(Matcher::_regEncode[src_lo]));
 1851         }
 1852       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1853         if (is64) {
 1854             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         } else {
 1857             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_Register(Matcher::_regEncode[src_lo]));
 1859         }
 1860       } else {                    // gpr --&gt; stack spill
 1861         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1862         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1863       }
 1864       break;
 1865     case rc_float:
 1866       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1867         if (is64) {
 1868             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         } else {
 1871             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         }
 1874       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1875           if (cbuf) {
 1876             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         } else {
 1879             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1880                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1881         }
 1882       } else {                    // fpr --&gt; stack spill
 1883         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1884         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1885                  is64 ? __ D : __ S, dst_offset);
 1886       }
 1887       break;
 1888     case rc_stack:
 1889       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1890         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1891       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1892         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1893                    is64 ? __ D : __ S, src_offset);
 1894       } else {                    // stack --&gt; stack copy
 1895         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1896         __ unspill(rscratch1, is64, src_offset);
 1897         __ spill(rscratch1, is64, dst_offset);
 1898       }
 1899       break;
 1900     default:
 1901       assert(false, &quot;bad rc_class for spill&quot;);
 1902       ShouldNotReachHere();
 1903     }
 1904   }
 1905 
 1906   if (st) {
 1907     st-&gt;print(&quot;spill &quot;);
 1908     if (src_lo_rc == rc_stack) {
 1909       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1910     } else {
 1911       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1912     }
 1913     if (dst_lo_rc == rc_stack) {
 1914       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1915     } else {
 1916       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1917     }
 1918     if (bottom_type()-&gt;isa_vect() != NULL) {
 1919       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1920     } else {
 1921       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1922     }
 1923   }
 1924 
 1925   return 0;
 1926 
 1927 }
 1928 
 1929 #ifndef PRODUCT
 1930 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   if (!ra_)
 1932     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1933   else
 1934     implementation(NULL, ra_, false, st);
 1935 }
 1936 #endif
 1937 
 1938 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   implementation(&amp;cbuf, ra_, false, NULL);
 1940 }
 1941 
 1942 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1943   return MachNode::size(ra_);
 1944 }
 1945 
 1946 //=============================================================================
 1947 
 1948 #ifndef PRODUCT
 1949 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1950   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1951   int reg = ra_-&gt;get_reg_first(this);
 1952   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1953             Matcher::regName[reg], offset);
 1954 }
 1955 #endif
 1956 
 1957 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1958   C2_MacroAssembler _masm(&amp;cbuf);
 1959 
 1960   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1961   int reg    = ra_-&gt;get_encode(this);
 1962 
 1963   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1964     __ add(as_Register(reg), sp, offset);
 1965   } else {
 1966     ShouldNotReachHere();
 1967   }
 1968 }
 1969 
 1970 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1971   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1972   return 4;
 1973 }
 1974 
 1975 //=============================================================================
 1976 
 1977 #ifndef PRODUCT
 1978 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1979 {
 1980   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1981   if (UseCompressedClassPointers) {
 1982     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1983     if (CompressedKlassPointers::shift() != 0) {
 1984       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1985     }
 1986   } else {
 1987    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1988   }
 1989   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1990   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1991 }
 1992 #endif
 1993 
 1994 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1995 {
 1996   // This is the unverified entry point.
 1997   C2_MacroAssembler _masm(&amp;cbuf);
 1998 
 1999   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2000   Label skip;
 2001   // TODO
 2002   // can we avoid this skip and still use a reloc?
 2003   __ br(Assembler::EQ, skip);
 2004   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2005   __ bind(skip);
 2006 }
 2007 
 2008 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2009 {
 2010   return MachNode::size(ra_);
 2011 }
 2012 
 2013 // REQUIRED EMIT CODE
 2014 
 2015 //=============================================================================
 2016 
 2017 // Emit exception handler code.
 2018 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2019 {
 2020   // mov rscratch1 #exception_blob_entry_point
 2021   // br rscratch1
 2022   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2023   // That&#39;s why we must use the macroassembler to generate a handler.
 2024   C2_MacroAssembler _masm(&amp;cbuf);
 2025   address base = __ start_a_stub(size_exception_handler());
 2026   if (base == NULL) {
 2027     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2028     return 0;  // CodeBuffer::expand failed
 2029   }
 2030   int offset = __ offset();
 2031   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2032   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2033   __ end_a_stub();
 2034   return offset;
 2035 }
 2036 
 2037 // Emit deopt handler code.
 2038 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2039 {
 2040   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2041   // That&#39;s why we must use the macroassembler to generate a handler.
 2042   C2_MacroAssembler _masm(&amp;cbuf);
 2043   address base = __ start_a_stub(size_deopt_handler());
 2044   if (base == NULL) {
 2045     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2046     return 0;  // CodeBuffer::expand failed
 2047   }
 2048   int offset = __ offset();
 2049 
 2050   __ adr(lr, __ pc());
 2051   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2052 
 2053   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2054   __ end_a_stub();
 2055   return offset;
 2056 }
 2057 
 2058 // REQUIRED MATCHER CODE
 2059 
 2060 //=============================================================================
 2061 
 2062 const bool Matcher::match_rule_supported(int opcode) {
 2063   if (!has_match_rule(opcode))
 2064     return false;
 2065 
 2066   bool ret_value = true;
 2067   switch (opcode) {
 2068     case Op_CacheWB:
 2069     case Op_CacheWBPreSync:
 2070     case Op_CacheWBPostSync:
 2071       if (!VM_Version::supports_data_cache_line_flush()) {
 2072         ret_value = false;
 2073       }
 2074       break;
 2075   }
 2076 
 2077   return ret_value; // Per default match rules are supported.
 2078 }
 2079 
 2080 // Identify extra cases that we might want to provide match rules for vector nodes and
 2081 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2082 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2083   if (!match_rule_supported(opcode)) {
 2084     return false;
 2085   }
 2086 
 2087   // Special cases which require vector length
 2088   switch (opcode) {
 2089     case Op_MulAddVS2VI: {
 2090       if (vlen != 4) {
 2091         return false;
 2092       }
 2093       break;
 2094     }
 2095   }
 2096 
 2097   return true; // Per default match rules are supported.
 2098 }
 2099 
 2100 const bool Matcher::has_predicated_vectors(void) {
 2101   return false;
 2102 }
 2103 
 2104 const int Matcher::float_pressure(int default_pressure_threshold) {
 2105   return default_pressure_threshold;
 2106 }
 2107 
 2108 int Matcher::regnum_to_fpu_offset(int regnum)
 2109 {
 2110   Unimplemented();
 2111   return 0;
 2112 }
 2113 
 2114 // Is this branch offset short enough that a short branch can be used?
 2115 //
 2116 // NOTE: If the platform does not provide any short branch variants, then
 2117 //       this method should return false for offset 0.
 2118 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2119   // The passed offset is relative to address of the branch.
 2120 
 2121   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2122 }
 2123 
 2124 const bool Matcher::isSimpleConstant64(jlong value) {
 2125   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2126   // Probably always true, even if a temp register is required.
 2127   return true;
 2128 }
 2129 
 2130 // true just means we have fast l2f conversion
 2131 const bool Matcher::convL2FSupported(void) {
 2132   return true;
 2133 }
 2134 
 2135 // Vector width in bytes.
 2136 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2137   int size = MIN2(16,(int)MaxVectorSize);
 2138   // Minimum 2 values in vector
 2139   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2140   // But never &lt; 4
 2141   if (size &lt; 4) size = 0;
 2142   return size;
 2143 }
 2144 
 2145 // Limits on vector size (number of elements) loaded into vector.
 2146 const int Matcher::max_vector_size(const BasicType bt) {
 2147   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2148 }
 2149 const int Matcher::min_vector_size(const BasicType bt) {
 2150 //  For the moment limit the vector size to 8 bytes
 2151     int size = 8 / type2aelembytes(bt);
 2152     if (size &lt; 2) size = 2;
 2153     return size;
 2154 }
 2155 
 2156 // Vector ideal reg.
 2157 const uint Matcher::vector_ideal_reg(int len) {
 2158   switch(len) {
 2159     case  8: return Op_VecD;
 2160     case 16: return Op_VecX;
 2161   }
 2162   ShouldNotReachHere();
 2163   return 0;
 2164 }
 2165 
 2166 // AES support not yet implemented
 2167 const bool Matcher::pass_original_key_for_aes() {
 2168   return false;
 2169 }
 2170 
 2171 // aarch64 supports misaligned vectors store/load.
 2172 const bool Matcher::misaligned_vectors_ok() {
 2173   return true;
 2174 }
 2175 
 2176 // false =&gt; size gets scaled to BytesPerLong, ok.
 2177 const bool Matcher::init_array_count_is_in_bytes = false;
 2178 
 2179 // Use conditional move (CMOVL)
 2180 const int Matcher::long_cmove_cost() {
 2181   // long cmoves are no more expensive than int cmoves
 2182   return 0;
 2183 }
 2184 
 2185 const int Matcher::float_cmove_cost() {
 2186   // float cmoves are no more expensive than int cmoves
 2187   return 0;
 2188 }
 2189 
 2190 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2191 const bool Matcher::require_postalloc_expand = false;
 2192 
 2193 // Do we need to mask the count passed to shift instructions or does
 2194 // the cpu only look at the lower 5/6 bits anyway?
 2195 const bool Matcher::need_masked_shift_count = false;
 2196 
 2197 // No support for generic vector operands.
 2198 const bool Matcher::supports_generic_vector_operands  = false;
 2199 
 2200 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2201   ShouldNotReachHere(); // generic vector operands not supported
 2202   return NULL;
 2203 }
 2204 
 2205 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2206   ShouldNotReachHere();  // generic vector operands not supported
 2207   return false;
 2208 }
 2209 
 2210 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2211   ShouldNotReachHere();  // generic vector operands not supported
 2212   return false;
 2213 }
 2214 
 2215 // This affects two different things:
 2216 //  - how Decode nodes are matched
 2217 //  - how ImplicitNullCheck opportunities are recognized
 2218 // If true, the matcher will try to remove all Decodes and match them
 2219 // (as operands) into nodes. NullChecks are not prepared to deal with
 2220 // Decodes by final_graph_reshaping().
 2221 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2222 // for a NullCheck. The matcher matches the Decode node into a register.
 2223 // Implicit_null_check optimization moves the Decode along with the
 2224 // memory operation back up before the NullCheck.
 2225 bool Matcher::narrow_oop_use_complex_address() {
 2226   return CompressedOops::shift() == 0;
 2227 }
 2228 
 2229 bool Matcher::narrow_klass_use_complex_address() {
 2230 // TODO
 2231 // decide whether we need to set this to true
 2232   return false;
 2233 }
 2234 
 2235 bool Matcher::const_oop_prefer_decode() {
 2236   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2237   return CompressedOops::base() == NULL;
 2238 }
 2239 
 2240 bool Matcher::const_klass_prefer_decode() {
 2241   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2242   return CompressedKlassPointers::base() == NULL;
 2243 }
 2244 
 2245 // Is it better to copy float constants, or load them directly from
 2246 // memory?  Intel can load a float constant from a direct address,
 2247 // requiring no extra registers.  Most RISCs will have to materialize
 2248 // an address into a register first, so they would do better to copy
 2249 // the constant from stack.
 2250 const bool Matcher::rematerialize_float_constants = false;
 2251 
 2252 // If CPU can load and store mis-aligned doubles directly then no
 2253 // fixup is needed.  Else we split the double into 2 integer pieces
 2254 // and move it piece-by-piece.  Only happens when passing doubles into
 2255 // C code as the Java calling convention forces doubles to be aligned.
 2256 const bool Matcher::misaligned_doubles_ok = true;
 2257 
 2258 // No-op on amd64
 2259 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2260   Unimplemented();
 2261 }
 2262 
 2263 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2264 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2265 
 2266 // Are floats converted to double when stored to stack during
 2267 // deoptimization?
 2268 bool Matcher::float_in_double() { return false; }
 2269 
 2270 // Do ints take an entire long register or just half?
 2271 // The relevant question is how the int is callee-saved:
 2272 // the whole long is written but de-opt&#39;ing will have to extract
 2273 // the relevant 32 bits.
 2274 const bool Matcher::int_in_long = true;
 2275 
 2276 // Return whether or not this register is ever used as an argument.
 2277 // This function is used on startup to build the trampoline stubs in
 2278 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2279 // call in the trampoline, and arguments in those registers not be
 2280 // available to the callee.
 2281 bool Matcher::can_be_java_arg(int reg)
 2282 {
 2283   return
 2284     reg ==  R0_num || reg == R0_H_num ||
 2285     reg ==  R1_num || reg == R1_H_num ||
 2286     reg ==  R2_num || reg == R2_H_num ||
 2287     reg ==  R3_num || reg == R3_H_num ||
 2288     reg ==  R4_num || reg == R4_H_num ||
 2289     reg ==  R5_num || reg == R5_H_num ||
 2290     reg ==  R6_num || reg == R6_H_num ||
 2291     reg ==  R7_num || reg == R7_H_num ||
 2292     reg ==  V0_num || reg == V0_H_num ||
 2293     reg ==  V1_num || reg == V1_H_num ||
 2294     reg ==  V2_num || reg == V2_H_num ||
 2295     reg ==  V3_num || reg == V3_H_num ||
 2296     reg ==  V4_num || reg == V4_H_num ||
 2297     reg ==  V5_num || reg == V5_H_num ||
 2298     reg ==  V6_num || reg == V6_H_num ||
 2299     reg ==  V7_num || reg == V7_H_num;
 2300 }
 2301 
 2302 bool Matcher::is_spillable_arg(int reg)
 2303 {
 2304   return can_be_java_arg(reg);
 2305 }
 2306 
 2307 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2308   return false;
 2309 }
 2310 
 2311 RegMask Matcher::divI_proj_mask() {
 2312   ShouldNotReachHere();
 2313   return RegMask();
 2314 }
 2315 
 2316 // Register for MODI projection of divmodI.
 2317 RegMask Matcher::modI_proj_mask() {
 2318   ShouldNotReachHere();
 2319   return RegMask();
 2320 }
 2321 
 2322 // Register for DIVL projection of divmodL.
 2323 RegMask Matcher::divL_proj_mask() {
 2324   ShouldNotReachHere();
 2325   return RegMask();
 2326 }
 2327 
 2328 // Register for MODL projection of divmodL.
 2329 RegMask Matcher::modL_proj_mask() {
 2330   ShouldNotReachHere();
 2331   return RegMask();
 2332 }
 2333 
 2334 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2335   return FP_REG_mask();
 2336 }
 2337 
 2338 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2339   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2340     Node* u = addp-&gt;fast_out(i);
 2341     if (u-&gt;is_Mem()) {
 2342       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2343       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2344       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2345         return false;
 2346       }
 2347     }
 2348   }
 2349   return true;
 2350 }
 2351 
 2352 const bool Matcher::convi2l_type_required = false;
 2353 
 2354 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2355 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2356   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2357     mstack.push(m, Visit);           // m = ShiftCntV
 2358     return true;
 2359   }
 2360   return false;
 2361 }
 2362 
 2363 // Should the Matcher clone shifts on addressing modes, expecting them
 2364 // to be subsumed into complex addressing expressions or compute them
 2365 // into registers?
 2366 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2367   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2368     return true;
 2369   }
 2370 
 2371   Node *off = m-&gt;in(AddPNode::Offset);
 2372   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2373       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2374       // Are there other uses besides address expressions?
 2375       !is_visited(off)) {
 2376     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2377     mstack.push(off-&gt;in(2), Visit);
 2378     Node *conv = off-&gt;in(1);
 2379     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2380         // Are there other uses besides address expressions?
 2381         !is_visited(conv)) {
 2382       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2383       mstack.push(conv-&gt;in(1), Pre_Visit);
 2384     } else {
 2385       mstack.push(conv, Pre_Visit);
 2386     }
 2387     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2388     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2389     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2390     return true;
 2391   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2392              // Are there other uses besides address expressions?
 2393              !is_visited(off)) {
 2394     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2395     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2396     mstack.push(off-&gt;in(1), Pre_Visit);
 2397     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2398     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2399     return true;
 2400   }
 2401   return false;
 2402 }
 2403 
 2404 void Compile::reshape_address(AddPNode* addp) {
 2405 }
 2406 
 2407 
 2408 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2409   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2410   {                                                                     \
 2411     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2412     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2413     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2414     __ INSN(REG, as_Register(BASE));                                    \
 2415   }
 2416 
 2417 
 2418 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2419   {
 2420     Address::extend scale;
 2421 
 2422     // Hooboy, this is fugly.  We need a way to communicate to the
 2423     // encoder that the index needs to be sign extended, so we have to
 2424     // enumerate all the cases.
 2425     switch (opcode) {
 2426     case INDINDEXSCALEDI2L:
 2427     case INDINDEXSCALEDI2LN:
 2428     case INDINDEXI2L:
 2429     case INDINDEXI2LN:
 2430       scale = Address::sxtw(size);
 2431       break;
 2432     default:
 2433       scale = Address::lsl(size);
 2434     }
 2435 
 2436     if (index == -1) {
 2437       return Address(base, disp);
 2438     } else {
 2439       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2440       return Address(base, as_Register(index), scale);
 2441     }
 2442   }
 2443 
 2444 
 2445 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2446 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2447 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2448 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2449                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2450 
 2451   // Used for all non-volatile memory accesses.  The use of
 2452   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2453   // offsets is something of a kludge.
 2454   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2455                         Register reg, int opcode,
 2456                         Register base, int index, int scale, int disp,
 2457                         int size_in_memory)
 2458   {
 2459     Address addr = mem2address(opcode, base, index, scale, disp);
 2460     if (addr.getMode() == Address::base_plus_offset) {
 2461       /* If we get an out-of-range offset it is a bug in the compiler,
 2462          so we assert here. */
 2463       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2464              &quot;c2 compiler bug&quot;);
 2465       /* Fix up any out-of-range offsets. */
 2466       assert_different_registers(rscratch1, base);
 2467       assert_different_registers(rscratch1, reg);
 2468       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2469     }
 2470     (masm.*insn)(reg, addr);
 2471   }
 2472 
 2473   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2474                         FloatRegister reg, int opcode,
 2475                         Register base, int index, int size, int disp,
 2476                         int size_in_memory)
 2477   {
 2478     Address::extend scale;
 2479 
 2480     switch (opcode) {
 2481     case INDINDEXSCALEDI2L:
 2482     case INDINDEXSCALEDI2LN:
 2483       scale = Address::sxtw(size);
 2484       break;
 2485     default:
 2486       scale = Address::lsl(size);
 2487     }
 2488 
 2489     if (index == -1) {
 2490       /* If we get an out-of-range offset it is a bug in the compiler,
 2491          so we assert here. */
 2492       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2493       /* Fix up any out-of-range offsets. */
 2494       assert_different_registers(rscratch1, base);
 2495       Address addr = Address(base, disp);
 2496       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2497       (masm.*insn)(reg, addr);
 2498     } else {
 2499       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2500       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2501     }
 2502   }
 2503 
 2504   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2505                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2506                         int opcode, Register base, int index, int size, int disp)
 2507   {
 2508     if (index == -1) {
 2509       (masm.*insn)(reg, T, Address(base, disp));
 2510     } else {
 2511       assert(disp == 0, &quot;unsupported address mode&quot;);
 2512       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2513     }
 2514   }
 2515 
 2516 %}
 2517 
 2518 
 2519 
 2520 //----------ENCODING BLOCK-----------------------------------------------------
 2521 // This block specifies the encoding classes used by the compiler to
 2522 // output byte streams.  Encoding classes are parameterized macros
 2523 // used by Machine Instruction Nodes in order to generate the bit
 2524 // encoding of the instruction.  Operands specify their base encoding
 2525 // interface with the interface keyword.  There are currently
 2526 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2527 // COND_INTER.  REG_INTER causes an operand to generate a function
 2528 // which returns its register number when queried.  CONST_INTER causes
 2529 // an operand to generate a function which returns the value of the
 2530 // constant when queried.  MEMORY_INTER causes an operand to generate
 2531 // four functions which return the Base Register, the Index Register,
 2532 // the Scale Value, and the Offset Value of the operand when queried.
 2533 // COND_INTER causes an operand to generate six functions which return
 2534 // the encoding code (ie - encoding bits for the instruction)
 2535 // associated with each basic boolean condition for a conditional
 2536 // instruction.
 2537 //
 2538 // Instructions specify two basic values for encoding.  Again, a
 2539 // function is available to check if the constant displacement is an
 2540 // oop. They use the ins_encode keyword to specify their encoding
 2541 // classes (which must be a sequence of enc_class names, and their
 2542 // parameters, specified in the encoding block), and they use the
 2543 // opcode keyword to specify, in order, their primary, secondary, and
 2544 // tertiary opcode.  Only the opcode sections which a particular
 2545 // instruction needs for encoding need to be specified.
 2546 encode %{
 2547   // Build emit functions for each basic byte or larger field in the
 2548   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2549   // from C++ code in the enc_class source block.  Emit functions will
 2550   // live in the main source block for now.  In future, we can
 2551   // generalize this by adding a syntax that specifies the sizes of
 2552   // fields in an order, so that the adlc can build the emit functions
 2553   // automagically
 2554 
 2555   // catch all for unimplemented encodings
 2556   enc_class enc_unimplemented %{
 2557     C2_MacroAssembler _masm(&amp;cbuf);
 2558     __ unimplemented(&quot;C2 catch all&quot;);
 2559   %}
 2560 
 2561   // BEGIN Non-volatile memory access
 2562 
 2563   // This encoding class is generated automatically from ad_encode.m4.
 2564   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2565   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2566     Register dst_reg = as_Register($dst$$reg);
 2567     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2568                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2569   %}
 2570 
 2571   // This encoding class is generated automatically from ad_encode.m4.
 2572   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2573   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2574     Register dst_reg = as_Register($dst$$reg);
 2575     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2576                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2577   %}
 2578 
 2579   // This encoding class is generated automatically from ad_encode.m4.
 2580   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2581   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2582     Register dst_reg = as_Register($dst$$reg);
 2583     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2584                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2585   %}
 2586 
 2587   // This encoding class is generated automatically from ad_encode.m4.
 2588   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2589   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2590     Register dst_reg = as_Register($dst$$reg);
 2591     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2592                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2593   %}
 2594 
 2595   // This encoding class is generated automatically from ad_encode.m4.
 2596   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2597   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2598     Register dst_reg = as_Register($dst$$reg);
 2599     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2600                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2601   %}
 2602 
 2603   // This encoding class is generated automatically from ad_encode.m4.
 2604   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2605   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2606     Register dst_reg = as_Register($dst$$reg);
 2607     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2608                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2609   %}
 2610 
 2611   // This encoding class is generated automatically from ad_encode.m4.
 2612   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2613   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2614     Register dst_reg = as_Register($dst$$reg);
 2615     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2616                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2617   %}
 2618 
 2619   // This encoding class is generated automatically from ad_encode.m4.
 2620   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2621   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2622     Register dst_reg = as_Register($dst$$reg);
 2623     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2624                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2625   %}
 2626 
 2627   // This encoding class is generated automatically from ad_encode.m4.
 2628   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2629   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2630     Register dst_reg = as_Register($dst$$reg);
 2631     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2632                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2633   %}
 2634 
 2635   // This encoding class is generated automatically from ad_encode.m4.
 2636   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2637   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2638     Register dst_reg = as_Register($dst$$reg);
 2639     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2640                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2641   %}
 2642 
 2643   // This encoding class is generated automatically from ad_encode.m4.
 2644   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2645   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2646     Register dst_reg = as_Register($dst$$reg);
 2647     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2648                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2649   %}
 2650 
 2651   // This encoding class is generated automatically from ad_encode.m4.
 2652   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2653   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2654     Register dst_reg = as_Register($dst$$reg);
 2655     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2656                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2657   %}
 2658 
 2659   // This encoding class is generated automatically from ad_encode.m4.
 2660   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2661   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2662     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2663     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2664                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2665   %}
 2666 
 2667   // This encoding class is generated automatically from ad_encode.m4.
 2668   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2669   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2670     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2671     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2672                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2673   %}
 2674 
 2675   // This encoding class is generated automatically from ad_encode.m4.
 2676   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2677   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2678     Register src_reg = as_Register($src$$reg);
 2679     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2680                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2681   %}
 2682 
 2683   // This encoding class is generated automatically from ad_encode.m4.
 2684   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2685   enc_class aarch64_enc_strb0(memory1 mem) %{
 2686     C2_MacroAssembler _masm(&amp;cbuf);
 2687     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2688                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2689   %}
 2690 
 2691   // This encoding class is generated automatically from ad_encode.m4.
 2692   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2693   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2694     Register src_reg = as_Register($src$$reg);
 2695     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2696                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2697   %}
 2698 
 2699   // This encoding class is generated automatically from ad_encode.m4.
 2700   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2701   enc_class aarch64_enc_strh0(memory2 mem) %{
 2702     C2_MacroAssembler _masm(&amp;cbuf);
 2703     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2704                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2705   %}
 2706 
 2707   // This encoding class is generated automatically from ad_encode.m4.
 2708   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2709   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2710     Register src_reg = as_Register($src$$reg);
 2711     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2712                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2713   %}
 2714 
 2715   // This encoding class is generated automatically from ad_encode.m4.
 2716   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2717   enc_class aarch64_enc_strw0(memory4 mem) %{
 2718     C2_MacroAssembler _masm(&amp;cbuf);
 2719     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2720                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2721   %}
 2722 
 2723   // This encoding class is generated automatically from ad_encode.m4.
 2724   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2725   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2726     Register src_reg = as_Register($src$$reg);
 2727     // we sometimes get asked to store the stack pointer into the
 2728     // current thread -- we cannot do that directly on AArch64
 2729     if (src_reg == r31_sp) {
 2730       C2_MacroAssembler _masm(&amp;cbuf);
 2731       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2732       __ mov(rscratch2, sp);
 2733       src_reg = rscratch2;
 2734     }
 2735     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2736                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2737   %}
 2738 
 2739   // This encoding class is generated automatically from ad_encode.m4.
 2740   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2741   enc_class aarch64_enc_str0(memory8 mem) %{
 2742     C2_MacroAssembler _masm(&amp;cbuf);
 2743     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2744                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2745   %}
 2746 
 2747   // This encoding class is generated automatically from ad_encode.m4.
 2748   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2749   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2750     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2751     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2752                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2753   %}
 2754 
 2755   // This encoding class is generated automatically from ad_encode.m4.
 2756   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2757   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2758     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2759     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2760                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2761   %}
 2762 
 2763   // This encoding class is generated automatically from ad_encode.m4.
 2764   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2765   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2766     C2_MacroAssembler _masm(&amp;cbuf);
 2767     address con = (address)$src$$constant;
 2768     // need to do this the hard way until we can manage relocs
 2769     // for 32 bit constants
 2770     __ movoop(rscratch2, (jobject)con);
 2771     if (con) __ encode_heap_oop_not_null(rscratch2);
 2772     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2773                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2774   %}
 2775 
 2776   // This encoding class is generated automatically from ad_encode.m4.
 2777   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2778   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2779     C2_MacroAssembler _masm(&amp;cbuf);
 2780     address con = (address)$src$$constant;
 2781     // need to do this the hard way until we can manage relocs
 2782     // for 32 bit constants
 2783     __ movoop(rscratch2, (jobject)con);
 2784     __ encode_klass_not_null(rscratch2);
 2785     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2786                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2787   %}
 2788 
 2789   // This encoding class is generated automatically from ad_encode.m4.
 2790   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2791   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2792       C2_MacroAssembler _masm(&amp;cbuf);
 2793       __ membar(Assembler::StoreStore);
 2794       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2795                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2796   %}
 2797 
 2798   // END Non-volatile memory access
 2799 
 2800   // Vector loads and stores
 2801   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2802     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2803     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2804        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2805   %}
 2806 
 2807   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2808     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2809     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2810        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2811   %}
 2812 
 2813   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2814     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2815     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2816        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2817   %}
 2818 
 2819   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2820     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2821     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2822        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2823   %}
 2824 
 2825   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2826     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2827     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2828        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2829   %}
 2830 
 2831   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2832     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2833     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2834        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2835   %}
 2836 
 2837   // volatile loads and stores
 2838 
 2839   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2840     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2841                  rscratch1, stlrb);
 2842   %}
 2843 
 2844   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2845     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2846                  rscratch1, stlrh);
 2847   %}
 2848 
 2849   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2850     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2851                  rscratch1, stlrw);
 2852   %}
 2853 
 2854 
 2855   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2856     Register dst_reg = as_Register($dst$$reg);
 2857     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2858              rscratch1, ldarb);
 2859     __ sxtbw(dst_reg, dst_reg);
 2860   %}
 2861 
 2862   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2863     Register dst_reg = as_Register($dst$$reg);
 2864     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2865              rscratch1, ldarb);
 2866     __ sxtb(dst_reg, dst_reg);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2870     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2871              rscratch1, ldarb);
 2872   %}
 2873 
 2874   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2875     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2876              rscratch1, ldarb);
 2877   %}
 2878 
 2879   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2880     Register dst_reg = as_Register($dst$$reg);
 2881     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2882              rscratch1, ldarh);
 2883     __ sxthw(dst_reg, dst_reg);
 2884   %}
 2885 
 2886   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2887     Register dst_reg = as_Register($dst$$reg);
 2888     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2889              rscratch1, ldarh);
 2890     __ sxth(dst_reg, dst_reg);
 2891   %}
 2892 
 2893   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2894     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2895              rscratch1, ldarh);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2899     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2900              rscratch1, ldarh);
 2901   %}
 2902 
 2903   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2904     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2905              rscratch1, ldarw);
 2906   %}
 2907 
 2908   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2909     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2910              rscratch1, ldarw);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2914     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldar);
 2916   %}
 2917 
 2918   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2919     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2920              rscratch1, ldarw);
 2921     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2922   %}
 2923 
 2924   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2925     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2926              rscratch1, ldar);
 2927     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2928   %}
 2929 
 2930   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2931     Register src_reg = as_Register($src$$reg);
 2932     // we sometimes get asked to store the stack pointer into the
 2933     // current thread -- we cannot do that directly on AArch64
 2934     if (src_reg == r31_sp) {
 2935       C2_MacroAssembler _masm(&amp;cbuf);
 2936       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2937       __ mov(rscratch2, sp);
 2938       src_reg = rscratch2;
 2939     }
 2940     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2941                  rscratch1, stlr);
 2942   %}
 2943 
 2944   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2945     {
 2946       C2_MacroAssembler _masm(&amp;cbuf);
 2947       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2948       __ fmovs(rscratch2, src_reg);
 2949     }
 2950     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951                  rscratch1, stlrw);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2955     {
 2956       C2_MacroAssembler _masm(&amp;cbuf);
 2957       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2958       __ fmovd(rscratch2, src_reg);
 2959     }
 2960     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlr);
 2962   %}
 2963 
 2964   // synchronized read/update encodings
 2965 
 2966   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2967     C2_MacroAssembler _masm(&amp;cbuf);
 2968     Register dst_reg = as_Register($dst$$reg);
 2969     Register base = as_Register($mem$$base);
 2970     int index = $mem$$index;
 2971     int scale = $mem$$scale;
 2972     int disp = $mem$$disp;
 2973     if (index == -1) {
 2974        if (disp != 0) {
 2975         __ lea(rscratch1, Address(base, disp));
 2976         __ ldaxr(dst_reg, rscratch1);
 2977       } else {
 2978         // TODO
 2979         // should we ever get anything other than this case?
 2980         __ ldaxr(dst_reg, base);
 2981       }
 2982     } else {
 2983       Register index_reg = as_Register(index);
 2984       if (disp == 0) {
 2985         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2986         __ ldaxr(dst_reg, rscratch1);
 2987       } else {
 2988         __ lea(rscratch1, Address(base, disp));
 2989         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2990         __ ldaxr(dst_reg, rscratch1);
 2991       }
 2992     }
 2993   %}
 2994 
 2995   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 2996     C2_MacroAssembler _masm(&amp;cbuf);
 2997     Register src_reg = as_Register($src$$reg);
 2998     Register base = as_Register($mem$$base);
 2999     int index = $mem$$index;
 3000     int scale = $mem$$scale;
 3001     int disp = $mem$$disp;
 3002     if (index == -1) {
 3003        if (disp != 0) {
 3004         __ lea(rscratch2, Address(base, disp));
 3005         __ stlxr(rscratch1, src_reg, rscratch2);
 3006       } else {
 3007         // TODO
 3008         // should we ever get anything other than this case?
 3009         __ stlxr(rscratch1, src_reg, base);
 3010       }
 3011     } else {
 3012       Register index_reg = as_Register(index);
 3013       if (disp == 0) {
 3014         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3015         __ stlxr(rscratch1, src_reg, rscratch2);
 3016       } else {
 3017         __ lea(rscratch2, Address(base, disp));
 3018         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3019         __ stlxr(rscratch1, src_reg, rscratch2);
 3020       }
 3021     }
 3022     __ cmpw(rscratch1, zr);
 3023   %}
 3024 
 3025   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3026     C2_MacroAssembler _masm(&amp;cbuf);
 3027     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3028     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3029                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3030                /*weak*/ false, noreg);
 3031   %}
 3032 
 3033   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3034     C2_MacroAssembler _masm(&amp;cbuf);
 3035     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3036     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3037                Assembler::word, /*acquire*/ false, /*release*/ true,
 3038                /*weak*/ false, noreg);
 3039   %}
 3040 
 3041   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3042     C2_MacroAssembler _masm(&amp;cbuf);
 3043     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3044     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3045                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3046                /*weak*/ false, noreg);
 3047   %}
 3048 
 3049   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3050     C2_MacroAssembler _masm(&amp;cbuf);
 3051     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3052     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3053                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3054                /*weak*/ false, noreg);
 3055   %}
 3056 
 3057 
 3058   // The only difference between aarch64_enc_cmpxchg and
 3059   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3060   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3061   // lock.
 3062   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3063     C2_MacroAssembler _masm(&amp;cbuf);
 3064     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3065     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3066                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3067                /*weak*/ false, noreg);
 3068   %}
 3069 
 3070   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3071     C2_MacroAssembler _masm(&amp;cbuf);
 3072     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3073     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3074                Assembler::word, /*acquire*/ true, /*release*/ true,
 3075                /*weak*/ false, noreg);
 3076   %}
 3077 
 3078   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3079     C2_MacroAssembler _masm(&amp;cbuf);
 3080     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3081     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3082                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3083                /*weak*/ false, noreg);
 3084   %}
 3085 
 3086   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3087     C2_MacroAssembler _masm(&amp;cbuf);
 3088     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3089     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3090                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3091                /*weak*/ false, noreg);
 3092   %}
 3093 
 3094   // auxiliary used for CompareAndSwapX to set result register
 3095   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3096     C2_MacroAssembler _masm(&amp;cbuf);
 3097     Register res_reg = as_Register($res$$reg);
 3098     __ cset(res_reg, Assembler::EQ);
 3099   %}
 3100 
 3101   // prefetch encodings
 3102 
 3103   enc_class aarch64_enc_prefetchw(memory mem) %{
 3104     C2_MacroAssembler _masm(&amp;cbuf);
 3105     Register base = as_Register($mem$$base);
 3106     int index = $mem$$index;
 3107     int scale = $mem$$scale;
 3108     int disp = $mem$$disp;
 3109     if (index == -1) {
 3110       __ prfm(Address(base, disp), PSTL1KEEP);
 3111     } else {
 3112       Register index_reg = as_Register(index);
 3113       if (disp == 0) {
 3114         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3115       } else {
 3116         __ lea(rscratch1, Address(base, disp));
 3117 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3118       }
 3119     }
 3120   %}
 3121 
 3122   /// mov envcodings
 3123 
 3124   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3125     C2_MacroAssembler _masm(&amp;cbuf);
 3126     u_int32_t con = (u_int32_t)$src$$constant;
 3127     Register dst_reg = as_Register($dst$$reg);
 3128     if (con == 0) {
 3129       __ movw(dst_reg, zr);
 3130     } else {
 3131       __ movw(dst_reg, con);
 3132     }
 3133   %}
 3134 
 3135   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3136     C2_MacroAssembler _masm(&amp;cbuf);
 3137     Register dst_reg = as_Register($dst$$reg);
 3138     u_int64_t con = (u_int64_t)$src$$constant;
 3139     if (con == 0) {
 3140       __ mov(dst_reg, zr);
 3141     } else {
 3142       __ mov(dst_reg, con);
 3143     }
 3144   %}
 3145 
 3146   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3147     C2_MacroAssembler _masm(&amp;cbuf);
 3148     Register dst_reg = as_Register($dst$$reg);
 3149     address con = (address)$src$$constant;
 3150     if (con == NULL || con == (address)1) {
 3151       ShouldNotReachHere();
 3152     } else {
 3153       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3154       if (rtype == relocInfo::oop_type) {
 3155         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3156       } else if (rtype == relocInfo::metadata_type) {
 3157         __ mov_metadata(dst_reg, (Metadata*)con);
 3158       } else {
 3159         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3160         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3161           __ mov(dst_reg, con);
 3162         } else {
 3163           unsigned long offset;
 3164           __ adrp(dst_reg, con, offset);
 3165           __ add(dst_reg, dst_reg, offset);
 3166         }
 3167       }
 3168     }
 3169   %}
 3170 
 3171   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3172     C2_MacroAssembler _masm(&amp;cbuf);
 3173     Register dst_reg = as_Register($dst$$reg);
 3174     __ mov(dst_reg, zr);
 3175   %}
 3176 
 3177   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3178     C2_MacroAssembler _masm(&amp;cbuf);
 3179     Register dst_reg = as_Register($dst$$reg);
 3180     __ mov(dst_reg, (u_int64_t)1);
 3181   %}
 3182 
 3183   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3184     C2_MacroAssembler _masm(&amp;cbuf);
 3185     __ load_byte_map_base($dst$$Register);
 3186   %}
 3187 
 3188   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3189     C2_MacroAssembler _masm(&amp;cbuf);
 3190     Register dst_reg = as_Register($dst$$reg);
 3191     address con = (address)$src$$constant;
 3192     if (con == NULL) {
 3193       ShouldNotReachHere();
 3194     } else {
 3195       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3196       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3197       __ set_narrow_oop(dst_reg, (jobject)con);
 3198     }
 3199   %}
 3200 
 3201   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3202     C2_MacroAssembler _masm(&amp;cbuf);
 3203     Register dst_reg = as_Register($dst$$reg);
 3204     __ mov(dst_reg, zr);
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3208     C2_MacroAssembler _masm(&amp;cbuf);
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     address con = (address)$src$$constant;
 3211     if (con == NULL) {
 3212       ShouldNotReachHere();
 3213     } else {
 3214       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3215       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3216       __ set_narrow_klass(dst_reg, (Klass *)con);
 3217     }
 3218   %}
 3219 
 3220   // arithmetic encodings
 3221 
 3222   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3223     C2_MacroAssembler _masm(&amp;cbuf);
 3224     Register dst_reg = as_Register($dst$$reg);
 3225     Register src_reg = as_Register($src1$$reg);
 3226     int32_t con = (int32_t)$src2$$constant;
 3227     // add has primary == 0, subtract has primary == 1
 3228     if ($primary) { con = -con; }
 3229     if (con &lt; 0) {
 3230       __ subw(dst_reg, src_reg, -con);
 3231     } else {
 3232       __ addw(dst_reg, src_reg, con);
 3233     }
 3234   %}
 3235 
 3236   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3237     C2_MacroAssembler _masm(&amp;cbuf);
 3238     Register dst_reg = as_Register($dst$$reg);
 3239     Register src_reg = as_Register($src1$$reg);
 3240     int32_t con = (int32_t)$src2$$constant;
 3241     // add has primary == 0, subtract has primary == 1
 3242     if ($primary) { con = -con; }
 3243     if (con &lt; 0) {
 3244       __ sub(dst_reg, src_reg, -con);
 3245     } else {
 3246       __ add(dst_reg, src_reg, con);
 3247     }
 3248   %}
 3249 
 3250   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3251     C2_MacroAssembler _masm(&amp;cbuf);
 3252    Register dst_reg = as_Register($dst$$reg);
 3253    Register src1_reg = as_Register($src1$$reg);
 3254    Register src2_reg = as_Register($src2$$reg);
 3255     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3256   %}
 3257 
 3258   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3259     C2_MacroAssembler _masm(&amp;cbuf);
 3260    Register dst_reg = as_Register($dst$$reg);
 3261    Register src1_reg = as_Register($src1$$reg);
 3262    Register src2_reg = as_Register($src2$$reg);
 3263     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3264   %}
 3265 
 3266   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3267     C2_MacroAssembler _masm(&amp;cbuf);
 3268    Register dst_reg = as_Register($dst$$reg);
 3269    Register src1_reg = as_Register($src1$$reg);
 3270    Register src2_reg = as_Register($src2$$reg);
 3271     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3272   %}
 3273 
 3274   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3275     C2_MacroAssembler _masm(&amp;cbuf);
 3276    Register dst_reg = as_Register($dst$$reg);
 3277    Register src1_reg = as_Register($src1$$reg);
 3278    Register src2_reg = as_Register($src2$$reg);
 3279     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3280   %}
 3281 
 3282   // compare instruction encodings
 3283 
 3284   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3285     C2_MacroAssembler _masm(&amp;cbuf);
 3286     Register reg1 = as_Register($src1$$reg);
 3287     Register reg2 = as_Register($src2$$reg);
 3288     __ cmpw(reg1, reg2);
 3289   %}
 3290 
 3291   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3292     C2_MacroAssembler _masm(&amp;cbuf);
 3293     Register reg = as_Register($src1$$reg);
 3294     int32_t val = $src2$$constant;
 3295     if (val &gt;= 0) {
 3296       __ subsw(zr, reg, val);
 3297     } else {
 3298       __ addsw(zr, reg, -val);
 3299     }
 3300   %}
 3301 
 3302   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3303     C2_MacroAssembler _masm(&amp;cbuf);
 3304     Register reg1 = as_Register($src1$$reg);
 3305     u_int32_t val = (u_int32_t)$src2$$constant;
 3306     __ movw(rscratch1, val);
 3307     __ cmpw(reg1, rscratch1);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3311     C2_MacroAssembler _masm(&amp;cbuf);
 3312     Register reg1 = as_Register($src1$$reg);
 3313     Register reg2 = as_Register($src2$$reg);
 3314     __ cmp(reg1, reg2);
 3315   %}
 3316 
 3317   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3318     C2_MacroAssembler _masm(&amp;cbuf);
 3319     Register reg = as_Register($src1$$reg);
 3320     int64_t val = $src2$$constant;
 3321     if (val &gt;= 0) {
 3322       __ subs(zr, reg, val);
 3323     } else if (val != -val) {
 3324       __ adds(zr, reg, -val);
 3325     } else {
 3326     // aargh, Long.MIN_VALUE is a special case
 3327       __ orr(rscratch1, zr, (u_int64_t)val);
 3328       __ subs(zr, reg, rscratch1);
 3329     }
 3330   %}
 3331 
 3332   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3333     C2_MacroAssembler _masm(&amp;cbuf);
 3334     Register reg1 = as_Register($src1$$reg);
 3335     u_int64_t val = (u_int64_t)$src2$$constant;
 3336     __ mov(rscratch1, val);
 3337     __ cmp(reg1, rscratch1);
 3338   %}
 3339 
 3340   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3341     C2_MacroAssembler _masm(&amp;cbuf);
 3342     Register reg1 = as_Register($src1$$reg);
 3343     Register reg2 = as_Register($src2$$reg);
 3344     __ cmp(reg1, reg2);
 3345   %}
 3346 
 3347   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3348     C2_MacroAssembler _masm(&amp;cbuf);
 3349     Register reg1 = as_Register($src1$$reg);
 3350     Register reg2 = as_Register($src2$$reg);
 3351     __ cmpw(reg1, reg2);
 3352   %}
 3353 
 3354   enc_class aarch64_enc_testp(iRegP src) %{
 3355     C2_MacroAssembler _masm(&amp;cbuf);
 3356     Register reg = as_Register($src$$reg);
 3357     __ cmp(reg, zr);
 3358   %}
 3359 
 3360   enc_class aarch64_enc_testn(iRegN src) %{
 3361     C2_MacroAssembler _masm(&amp;cbuf);
 3362     Register reg = as_Register($src$$reg);
 3363     __ cmpw(reg, zr);
 3364   %}
 3365 
 3366   enc_class aarch64_enc_b(label lbl) %{
 3367     C2_MacroAssembler _masm(&amp;cbuf);
 3368     Label *L = $lbl$$label;
 3369     __ b(*L);
 3370   %}
 3371 
 3372   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3373     C2_MacroAssembler _masm(&amp;cbuf);
 3374     Label *L = $lbl$$label;
 3375     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3376   %}
 3377 
 3378   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3379     C2_MacroAssembler _masm(&amp;cbuf);
 3380     Label *L = $lbl$$label;
 3381     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3382   %}
 3383 
 3384   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3385   %{
 3386      Register sub_reg = as_Register($sub$$reg);
 3387      Register super_reg = as_Register($super$$reg);
 3388      Register temp_reg = as_Register($temp$$reg);
 3389      Register result_reg = as_Register($result$$reg);
 3390 
 3391      Label miss;
 3392      C2_MacroAssembler _masm(&amp;cbuf);
 3393      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3394                                      NULL, &amp;miss,
 3395                                      /*set_cond_codes:*/ true);
 3396      if ($primary) {
 3397        __ mov(result_reg, zr);
 3398      }
 3399      __ bind(miss);
 3400   %}
 3401 
 3402   enc_class aarch64_enc_java_static_call(method meth) %{
 3403     C2_MacroAssembler _masm(&amp;cbuf);
 3404 
 3405     address addr = (address)$meth$$method;
 3406     address call;
 3407     if (!_method) {
 3408       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3409       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3410     } else {
 3411       int method_index = resolved_method_index(cbuf);
 3412       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3413                                                   : static_call_Relocation::spec(method_index);
 3414       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3415 
 3416       // Emit stub for static call
 3417       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3418       if (stub == NULL) {
 3419         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3420         return;
 3421       }
 3422     }
 3423     if (call == NULL) {
 3424       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3425       return;
 3426     }
 3427   %}
 3428 
 3429   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3430     C2_MacroAssembler _masm(&amp;cbuf);
 3431     int method_index = resolved_method_index(cbuf);
 3432     address call = __ ic_call((address)$meth$$method, method_index);
 3433     if (call == NULL) {
 3434       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3435       return;
 3436     }
 3437   %}
 3438 
 3439   enc_class aarch64_enc_call_epilog() %{
 3440     C2_MacroAssembler _masm(&amp;cbuf);
 3441     if (VerifyStackAtCalls) {
 3442       // Check that stack depth is unchanged: find majik cookie on stack
 3443       __ call_Unimplemented();
 3444     }
 3445   %}
 3446 
 3447   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3448     C2_MacroAssembler _masm(&amp;cbuf);
 3449 
 3450     // some calls to generated routines (arraycopy code) are scheduled
 3451     // by C2 as runtime calls. if so we can call them using a br (they
 3452     // will be in a reachable segment) otherwise we have to use a blr
 3453     // which loads the absolute address into a register.
 3454     address entry = (address)$meth$$method;
 3455     CodeBlob *cb = CodeCache::find_blob(entry);
 3456     if (cb) {
 3457       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3458       if (call == NULL) {
 3459         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3460         return;
 3461       }
 3462     } else {
 3463       Label retaddr;
 3464       __ adr(rscratch2, retaddr);
 3465       __ lea(rscratch1, RuntimeAddress(entry));
 3466       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3467       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3468       __ blr(rscratch1);
 3469       __ bind(retaddr);
 3470       __ add(sp, sp, 2 * wordSize);
 3471     }
 3472   %}
 3473 
 3474   enc_class aarch64_enc_rethrow() %{
 3475     C2_MacroAssembler _masm(&amp;cbuf);
 3476     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3477   %}
 3478 
 3479   enc_class aarch64_enc_ret() %{
 3480     C2_MacroAssembler _masm(&amp;cbuf);
 3481     __ ret(lr);
 3482   %}
 3483 
 3484   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3485     C2_MacroAssembler _masm(&amp;cbuf);
 3486     Register target_reg = as_Register($jump_target$$reg);
 3487     __ br(target_reg);
 3488   %}
 3489 
 3490   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3491     C2_MacroAssembler _masm(&amp;cbuf);
 3492     Register target_reg = as_Register($jump_target$$reg);
 3493     // exception oop should be in r0
 3494     // ret addr has been popped into lr
 3495     // callee expects it in r3
 3496     __ mov(r3, lr);
 3497     __ br(target_reg);
 3498   %}
 3499 
 3500   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3501     C2_MacroAssembler _masm(&amp;cbuf);
 3502     Register oop = as_Register($object$$reg);
 3503     Register box = as_Register($box$$reg);
 3504     Register disp_hdr = as_Register($tmp$$reg);
 3505     Register tmp = as_Register($tmp2$$reg);
 3506     Label cont;
 3507     Label object_has_monitor;
 3508     Label cas_failed;
 3509 
 3510     assert_different_registers(oop, box, tmp, disp_hdr);
 3511 
 3512     // Load markWord from object into displaced_header.
 3513     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3514 
 3515     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3516       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3517     }
 3518 
 3519     // Check for existing monitor
 3520     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3521 
 3522     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3523     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3524 
 3525     // Initialize the box. (Must happen before we update the object mark!)
 3526     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3527 
 3528     // Compare object markWord with an unlocked value (tmp) and if
 3529     // equal exchange the stack address of our box with object markWord.
 3530     // On failure disp_hdr contains the possibly locked markWord.
 3531     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3532                /*release*/ true, /*weak*/ false, disp_hdr);
 3533     __ br(Assembler::EQ, cont);
 3534 
 3535     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3536 
 3537     // If the compare-and-exchange succeeded, then we found an unlocked
 3538     // object, will have now locked it will continue at label cont
 3539 
 3540     __ bind(cas_failed);
 3541     // We did not see an unlocked object so try the fast recursive case.
 3542 
 3543     // Check if the owner is self by comparing the value in the
 3544     // markWord of object (disp_hdr) with the stack pointer.
 3545     __ mov(rscratch1, sp);
 3546     __ sub(disp_hdr, disp_hdr, rscratch1);
 3547     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3548     // If condition is true we are cont and hence we can store 0 as the
 3549     // displaced header in the box, which indicates that it is a recursive lock.
 3550     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3551     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3552 
 3553     __ b(cont);
 3554 
 3555     // Handle existing monitor.
 3556     __ bind(object_has_monitor);
 3557 
 3558     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3559     // otherwise m-&gt;owner may contain a thread or a stack address.
 3560     //
 3561     // Try to CAS m-&gt;owner from NULL to current thread.
 3562     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3563     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3564                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3565 
 3566     // Store a non-null value into the box to avoid looking like a re-entrant
 3567     // lock. The fast-path monitor unlock code checks for
 3568     // markWord::monitor_value so use markWord::unused_mark which has the
 3569     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3570     __ mov(tmp, (address)markWord::unused_mark().value());
 3571     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3572 
 3573     __ bind(cont);
 3574     // flag == EQ indicates success
 3575     // flag == NE indicates failure
 3576   %}
 3577 
 3578   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3579     C2_MacroAssembler _masm(&amp;cbuf);
 3580     Register oop = as_Register($object$$reg);
 3581     Register box = as_Register($box$$reg);
 3582     Register disp_hdr = as_Register($tmp$$reg);
 3583     Register tmp = as_Register($tmp2$$reg);
 3584     Label cont;
 3585     Label object_has_monitor;
 3586 
 3587     assert_different_registers(oop, box, tmp, disp_hdr);
 3588 
 3589     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3590       __ biased_locking_exit(oop, tmp, cont);
 3591     }
 3592 
 3593     // Find the lock address and load the displaced header from the stack.
 3594     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3595 
 3596     // If the displaced header is 0, we have a recursive unlock.
 3597     __ cmp(disp_hdr, zr);
 3598     __ br(Assembler::EQ, cont);
 3599 
 3600     // Handle existing monitor.
 3601     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3602     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3603 
 3604     // Check if it is still a light weight lock, this is is true if we
 3605     // see the stack address of the basicLock in the markWord of the
 3606     // object.
 3607 
 3608     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3609                /*release*/ true, /*weak*/ false, tmp);
 3610     __ b(cont);
 3611 
 3612     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3613 
 3614     // Handle existing monitor.
 3615     __ bind(object_has_monitor);
 3616     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3617     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3618     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3619     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3620     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3621     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3622     __ cmp(rscratch1, zr); // Sets flags for result
 3623     __ br(Assembler::NE, cont);
 3624 
 3625     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3626     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3627     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3628     __ cmp(rscratch1, zr); // Sets flags for result
 3629     __ cbnz(rscratch1, cont);
 3630     // need a release store here
 3631     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3632     __ stlr(zr, tmp); // set unowned
 3633 
 3634     __ bind(cont);
 3635     // flag == EQ indicates success
 3636     // flag == NE indicates failure
 3637   %}
 3638 
 3639 %}
 3640 
 3641 //----------FRAME--------------------------------------------------------------
 3642 // Definition of frame structure and management information.
 3643 //
 3644 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3645 //                             |   (to get allocators register number
 3646 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3647 //  r   CALLER     |        |
 3648 //  o     |        +--------+      pad to even-align allocators stack-slot
 3649 //  w     V        |  pad0  |        numbers; owned by CALLER
 3650 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3651 //  h     ^        |   in   |  5
 3652 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3653 //  |     |        |        |  3
 3654 //  |     |        +--------+
 3655 //  V     |        | old out|      Empty on Intel, window on Sparc
 3656 //        |    old |preserve|      Must be even aligned.
 3657 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3658 //        |        |   in   |  3   area for Intel ret address
 3659 //     Owned by    |preserve|      Empty on Sparc.
 3660 //       SELF      +--------+
 3661 //        |        |  pad2  |  2   pad to align old SP
 3662 //        |        +--------+  1
 3663 //        |        | locks  |  0
 3664 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3665 //        |        |  pad1  | 11   pad to align new SP
 3666 //        |        +--------+
 3667 //        |        |        | 10
 3668 //        |        | spills |  9   spills
 3669 //        V        |        |  8   (pad0 slot for callee)
 3670 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3671 //        ^        |  out   |  7
 3672 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3673 //     Owned by    +--------+
 3674 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3675 //        |    new |preserve|      Must be even-aligned.
 3676 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3677 //        |        |        |
 3678 //
 3679 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3680 //         known from SELF&#39;s arguments and the Java calling convention.
 3681 //         Region 6-7 is determined per call site.
 3682 // Note 2: If the calling convention leaves holes in the incoming argument
 3683 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3684 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3685 //         incoming area, as the Java calling convention is completely under
 3686 //         the control of the AD file.  Doubles can be sorted and packed to
 3687 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3688 //         varargs C calling conventions.
 3689 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3690 //         even aligned with pad0 as needed.
 3691 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3692 //           (the latter is true on Intel but is it false on AArch64?)
 3693 //         region 6-11 is even aligned; it may be padded out more so that
 3694 //         the region from SP to FP meets the minimum stack alignment.
 3695 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3696 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3697 //         SP meets the minimum alignment.
 3698 
 3699 frame %{
 3700   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3701   stack_direction(TOWARDS_LOW);
 3702 
 3703   // These three registers define part of the calling convention
 3704   // between compiled code and the interpreter.
 3705 
 3706   // Inline Cache Register or methodOop for I2C.
 3707   inline_cache_reg(R12);
 3708 
 3709   // Method Oop Register when calling interpreter.
 3710   interpreter_method_oop_reg(R12);
 3711 
 3712   // Number of stack slots consumed by locking an object
 3713   sync_stack_slots(2);
 3714 
 3715   // Compiled code&#39;s Frame Pointer
 3716   frame_pointer(R31);
 3717 
 3718   // Interpreter stores its frame pointer in a register which is
 3719   // stored to the stack by I2CAdaptors.
 3720   // I2CAdaptors convert from interpreted java to compiled java.
 3721   interpreter_frame_pointer(R29);
 3722 
 3723   // Stack alignment requirement
 3724   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3725 
 3726   // Number of stack slots between incoming argument block and the start of
 3727   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3728   // EPILOG must remove this many slots. aarch64 needs two slots for
 3729   // return address and fp.
 3730   // TODO think this is correct but check
 3731   in_preserve_stack_slots(4);
 3732 
 3733   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3734   // for calls to C.  Supports the var-args backing area for register parms.
 3735   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3736 
 3737   // The after-PROLOG location of the return address.  Location of
 3738   // return address specifies a type (REG or STACK) and a number
 3739   // representing the register number (i.e. - use a register name) or
 3740   // stack slot.
 3741   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3742   // Otherwise, it is above the locks and verification slot and alignment word
 3743   // TODO this may well be correct but need to check why that - 2 is there
 3744   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3745   // which folds in the space used for monitors
 3746   return_addr(STACK - 2 +
 3747               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3748                         Compile::current()-&gt;fixed_slots()),
 3749                        stack_alignment_in_slots()));
 3750 
 3751   // Body of function which returns an integer array locating
 3752   // arguments either in registers or in stack slots.  Passed an array
 3753   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3754   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3755   // arguments for a CALLEE.  Incoming stack arguments are
 3756   // automatically biased by the preserve_stack_slots field above.
 3757 
 3758   calling_convention
 3759   %{
 3760     // No difference between ingoing/outgoing just pass false
 3761     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3762   %}
 3763 
 3764   c_calling_convention
 3765   %{
 3766     // This is obviously always outgoing
 3767     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3768   %}
 3769 
 3770   // Location of compiled Java return values.  Same as C for now.
 3771   return_value
 3772   %{
 3773     // TODO do we allow ideal_reg == Op_RegN???
 3774     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3775            &quot;only return normal values&quot;);
 3776 
 3777     static const int lo[Op_RegL + 1] = { // enum name
 3778       0,                                 // Op_Node
 3779       0,                                 // Op_Set
 3780       R0_num,                            // Op_RegN
 3781       R0_num,                            // Op_RegI
 3782       R0_num,                            // Op_RegP
 3783       V0_num,                            // Op_RegF
 3784       V0_num,                            // Op_RegD
 3785       R0_num                             // Op_RegL
 3786     };
 3787 
 3788     static const int hi[Op_RegL + 1] = { // enum name
 3789       0,                                 // Op_Node
 3790       0,                                 // Op_Set
 3791       OptoReg::Bad,                      // Op_RegN
 3792       OptoReg::Bad,                      // Op_RegI
 3793       R0_H_num,                          // Op_RegP
 3794       OptoReg::Bad,                      // Op_RegF
 3795       V0_H_num,                          // Op_RegD
 3796       R0_H_num                           // Op_RegL
 3797     };
 3798 
 3799     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3800   %}
 3801 %}
 3802 
 3803 //----------ATTRIBUTES---------------------------------------------------------
 3804 //----------Operand Attributes-------------------------------------------------
 3805 op_attrib op_cost(1);        // Required cost attribute
 3806 
 3807 //----------Instruction Attributes---------------------------------------------
 3808 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3809 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3810 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3811                                 // a non-matching short branch variant
 3812                                 // of some long branch?
 3813 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3814                                 // be a power of 2) specifies the
 3815                                 // alignment that some part of the
 3816                                 // instruction (not necessarily the
 3817                                 // start) requires.  If &gt; 1, a
 3818                                 // compute_padding() function must be
 3819                                 // provided for the instruction
 3820 
 3821 //----------OPERANDS-----------------------------------------------------------
 3822 // Operand definitions must precede instruction definitions for correct parsing
 3823 // in the ADLC because operands constitute user defined types which are used in
 3824 // instruction definitions.
 3825 
 3826 //----------Simple Operands----------------------------------------------------
 3827 
 3828 // Integer operands 32 bit
 3829 // 32 bit immediate
 3830 operand immI()
 3831 %{
 3832   match(ConI);
 3833 
 3834   op_cost(0);
 3835   format %{ %}
 3836   interface(CONST_INTER);
 3837 %}
 3838 
 3839 // 32 bit zero
 3840 operand immI0()
 3841 %{
 3842   predicate(n-&gt;get_int() == 0);
 3843   match(ConI);
 3844 
 3845   op_cost(0);
 3846   format %{ %}
 3847   interface(CONST_INTER);
 3848 %}
 3849 
 3850 // 32 bit unit increment
 3851 operand immI_1()
 3852 %{
 3853   predicate(n-&gt;get_int() == 1);
 3854   match(ConI);
 3855 
 3856   op_cost(0);
 3857   format %{ %}
 3858   interface(CONST_INTER);
 3859 %}
 3860 
 3861 // 32 bit unit decrement
 3862 operand immI_M1()
 3863 %{
 3864   predicate(n-&gt;get_int() == -1);
 3865   match(ConI);
 3866 
 3867   op_cost(0);
 3868   format %{ %}
 3869   interface(CONST_INTER);
 3870 %}
 3871 
 3872 // Shift values for add/sub extension shift
 3873 operand immIExt()
 3874 %{
 3875   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3876   match(ConI);
 3877 
 3878   op_cost(0);
 3879   format %{ %}
 3880   interface(CONST_INTER);
 3881 %}
 3882 
 3883 operand immI_le_4()
 3884 %{
 3885   predicate(n-&gt;get_int() &lt;= 4);
 3886   match(ConI);
 3887 
 3888   op_cost(0);
 3889   format %{ %}
 3890   interface(CONST_INTER);
 3891 %}
 3892 
 3893 operand immI_31()
 3894 %{
 3895   predicate(n-&gt;get_int() == 31);
 3896   match(ConI);
 3897 
 3898   op_cost(0);
 3899   format %{ %}
 3900   interface(CONST_INTER);
 3901 %}
 3902 
 3903 operand immI_8()
 3904 %{
 3905   predicate(n-&gt;get_int() == 8);
 3906   match(ConI);
 3907 
 3908   op_cost(0);
 3909   format %{ %}
 3910   interface(CONST_INTER);
 3911 %}
 3912 
 3913 operand immI_16()
 3914 %{
 3915   predicate(n-&gt;get_int() == 16);
 3916   match(ConI);
 3917 
 3918   op_cost(0);
 3919   format %{ %}
 3920   interface(CONST_INTER);
 3921 %}
 3922 
 3923 operand immI_24()
 3924 %{
 3925   predicate(n-&gt;get_int() == 24);
 3926   match(ConI);
 3927 
 3928   op_cost(0);
 3929   format %{ %}
 3930   interface(CONST_INTER);
 3931 %}
 3932 
 3933 operand immI_32()
 3934 %{
 3935   predicate(n-&gt;get_int() == 32);
 3936   match(ConI);
 3937 
 3938   op_cost(0);
 3939   format %{ %}
 3940   interface(CONST_INTER);
 3941 %}
 3942 
 3943 operand immI_48()
 3944 %{
 3945   predicate(n-&gt;get_int() == 48);
 3946   match(ConI);
 3947 
 3948   op_cost(0);
 3949   format %{ %}
 3950   interface(CONST_INTER);
 3951 %}
 3952 
 3953 operand immI_56()
 3954 %{
 3955   predicate(n-&gt;get_int() == 56);
 3956   match(ConI);
 3957 
 3958   op_cost(0);
 3959   format %{ %}
 3960   interface(CONST_INTER);
 3961 %}
 3962 
 3963 operand immI_63()
 3964 %{
 3965   predicate(n-&gt;get_int() == 63);
 3966   match(ConI);
 3967 
 3968   op_cost(0);
 3969   format %{ %}
 3970   interface(CONST_INTER);
 3971 %}
 3972 
 3973 operand immI_64()
 3974 %{
 3975   predicate(n-&gt;get_int() == 64);
 3976   match(ConI);
 3977 
 3978   op_cost(0);
 3979   format %{ %}
 3980   interface(CONST_INTER);
 3981 %}
 3982 
 3983 operand immI_255()
 3984 %{
 3985   predicate(n-&gt;get_int() == 255);
 3986   match(ConI);
 3987 
 3988   op_cost(0);
 3989   format %{ %}
 3990   interface(CONST_INTER);
 3991 %}
 3992 
 3993 operand immI_65535()
 3994 %{
 3995   predicate(n-&gt;get_int() == 65535);
 3996   match(ConI);
 3997 
 3998   op_cost(0);
 3999   format %{ %}
 4000   interface(CONST_INTER);
 4001 %}
 4002 
 4003 operand immL_255()
 4004 %{
 4005   predicate(n-&gt;get_long() == 255L);
 4006   match(ConL);
 4007 
 4008   op_cost(0);
 4009   format %{ %}
 4010   interface(CONST_INTER);
 4011 %}
 4012 
 4013 operand immL_65535()
 4014 %{
 4015   predicate(n-&gt;get_long() == 65535L);
 4016   match(ConL);
 4017 
 4018   op_cost(0);
 4019   format %{ %}
 4020   interface(CONST_INTER);
 4021 %}
 4022 
 4023 operand immL_4294967295()
 4024 %{
 4025   predicate(n-&gt;get_long() == 4294967295L);
 4026   match(ConL);
 4027 
 4028   op_cost(0);
 4029   format %{ %}
 4030   interface(CONST_INTER);
 4031 %}
 4032 
 4033 operand immL_bitmask()
 4034 %{
 4035   predicate((n-&gt;get_long() != 0)
 4036             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4037             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4038   match(ConL);
 4039 
 4040   op_cost(0);
 4041   format %{ %}
 4042   interface(CONST_INTER);
 4043 %}
 4044 
 4045 operand immI_bitmask()
 4046 %{
 4047   predicate((n-&gt;get_int() != 0)
 4048             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4049             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4050   match(ConI);
 4051 
 4052   op_cost(0);
 4053   format %{ %}
 4054   interface(CONST_INTER);
 4055 %}
 4056 
 4057 // Scale values for scaled offset addressing modes (up to long but not quad)
 4058 operand immIScale()
 4059 %{
 4060   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4061   match(ConI);
 4062 
 4063   op_cost(0);
 4064   format %{ %}
 4065   interface(CONST_INTER);
 4066 %}
 4067 
 4068 // 26 bit signed offset -- for pc-relative branches
 4069 operand immI26()
 4070 %{
 4071   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4072   match(ConI);
 4073 
 4074   op_cost(0);
 4075   format %{ %}
 4076   interface(CONST_INTER);
 4077 %}
 4078 
 4079 // 19 bit signed offset -- for pc-relative loads
 4080 operand immI19()
 4081 %{
 4082   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4083   match(ConI);
 4084 
 4085   op_cost(0);
 4086   format %{ %}
 4087   interface(CONST_INTER);
 4088 %}
 4089 
 4090 // 12 bit unsigned offset -- for base plus immediate loads
 4091 operand immIU12()
 4092 %{
 4093   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4094   match(ConI);
 4095 
 4096   op_cost(0);
 4097   format %{ %}
 4098   interface(CONST_INTER);
 4099 %}
 4100 
 4101 operand immLU12()
 4102 %{
 4103   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4104   match(ConL);
 4105 
 4106   op_cost(0);
 4107   format %{ %}
 4108   interface(CONST_INTER);
 4109 %}
 4110 
 4111 // Offset for scaled or unscaled immediate loads and stores
 4112 operand immIOffset()
 4113 %{
 4114   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4115   match(ConI);
 4116 
 4117   op_cost(0);
 4118   format %{ %}
 4119   interface(CONST_INTER);
 4120 %}
 4121 
 4122 operand immIOffset1()
 4123 %{
 4124   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4125   match(ConI);
 4126 
 4127   op_cost(0);
 4128   format %{ %}
 4129   interface(CONST_INTER);
 4130 %}
 4131 
 4132 operand immIOffset2()
 4133 %{
 4134   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4135   match(ConI);
 4136 
 4137   op_cost(0);
 4138   format %{ %}
 4139   interface(CONST_INTER);
 4140 %}
 4141 
 4142 operand immIOffset4()
 4143 %{
 4144   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4145   match(ConI);
 4146 
 4147   op_cost(0);
 4148   format %{ %}
 4149   interface(CONST_INTER);
 4150 %}
 4151 
 4152 operand immIOffset8()
 4153 %{
 4154   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4155   match(ConI);
 4156 
 4157   op_cost(0);
 4158   format %{ %}
 4159   interface(CONST_INTER);
 4160 %}
 4161 
 4162 operand immIOffset16()
 4163 %{
 4164   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4165   match(ConI);
 4166 
 4167   op_cost(0);
 4168   format %{ %}
 4169   interface(CONST_INTER);
 4170 %}
 4171 
 4172 operand immLoffset()
 4173 %{
 4174   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4175   match(ConL);
 4176 
 4177   op_cost(0);
 4178   format %{ %}
 4179   interface(CONST_INTER);
 4180 %}
 4181 
 4182 operand immLoffset1()
 4183 %{
 4184   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4185   match(ConL);
 4186 
 4187   op_cost(0);
 4188   format %{ %}
 4189   interface(CONST_INTER);
 4190 %}
 4191 
 4192 operand immLoffset2()
 4193 %{
 4194   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4195   match(ConL);
 4196 
 4197   op_cost(0);
 4198   format %{ %}
 4199   interface(CONST_INTER);
 4200 %}
 4201 
 4202 operand immLoffset4()
 4203 %{
 4204   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4205   match(ConL);
 4206 
 4207   op_cost(0);
 4208   format %{ %}
 4209   interface(CONST_INTER);
 4210 %}
 4211 
 4212 operand immLoffset8()
 4213 %{
 4214   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4215   match(ConL);
 4216 
 4217   op_cost(0);
 4218   format %{ %}
 4219   interface(CONST_INTER);
 4220 %}
 4221 
 4222 operand immLoffset16()
 4223 %{
 4224   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4225   match(ConL);
 4226 
 4227   op_cost(0);
 4228   format %{ %}
 4229   interface(CONST_INTER);
 4230 %}
 4231 
 4232 // 32 bit integer valid for add sub immediate
 4233 operand immIAddSub()
 4234 %{
 4235   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4236   match(ConI);
 4237   op_cost(0);
 4238   format %{ %}
 4239   interface(CONST_INTER);
 4240 %}
 4241 
 4242 // 32 bit unsigned integer valid for logical immediate
 4243 // TODO -- check this is right when e.g the mask is 0x80000000
 4244 operand immILog()
 4245 %{
 4246   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4247   match(ConI);
 4248 
 4249   op_cost(0);
 4250   format %{ %}
 4251   interface(CONST_INTER);
 4252 %}
 4253 
 4254 // Integer operands 64 bit
 4255 // 64 bit immediate
 4256 operand immL()
 4257 %{
 4258   match(ConL);
 4259 
 4260   op_cost(0);
 4261   format %{ %}
 4262   interface(CONST_INTER);
 4263 %}
 4264 
 4265 // 64 bit zero
 4266 operand immL0()
 4267 %{
 4268   predicate(n-&gt;get_long() == 0);
 4269   match(ConL);
 4270 
 4271   op_cost(0);
 4272   format %{ %}
 4273   interface(CONST_INTER);
 4274 %}
 4275 
 4276 // 64 bit unit increment
 4277 operand immL_1()
 4278 %{
 4279   predicate(n-&gt;get_long() == 1);
 4280   match(ConL);
 4281 
 4282   op_cost(0);
 4283   format %{ %}
 4284   interface(CONST_INTER);
 4285 %}
 4286 
 4287 // 64 bit unit decrement
 4288 operand immL_M1()
 4289 %{
 4290   predicate(n-&gt;get_long() == -1);
 4291   match(ConL);
 4292 
 4293   op_cost(0);
 4294   format %{ %}
 4295   interface(CONST_INTER);
 4296 %}
 4297 
 4298 // 32 bit offset of pc in thread anchor
 4299 
 4300 operand immL_pc_off()
 4301 %{
 4302   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4303                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4304   match(ConL);
 4305 
 4306   op_cost(0);
 4307   format %{ %}
 4308   interface(CONST_INTER);
 4309 %}
 4310 
 4311 // 64 bit integer valid for add sub immediate
 4312 operand immLAddSub()
 4313 %{
 4314   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4315   match(ConL);
 4316   op_cost(0);
 4317   format %{ %}
 4318   interface(CONST_INTER);
 4319 %}
 4320 
 4321 // 64 bit integer valid for logical immediate
 4322 operand immLLog()
 4323 %{
 4324   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4325   match(ConL);
 4326   op_cost(0);
 4327   format %{ %}
 4328   interface(CONST_INTER);
 4329 %}
 4330 
 4331 // Long Immediate: low 32-bit mask
 4332 operand immL_32bits()
 4333 %{
 4334   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4335   match(ConL);
 4336   op_cost(0);
 4337   format %{ %}
 4338   interface(CONST_INTER);
 4339 %}
 4340 
 4341 // Pointer operands
 4342 // Pointer Immediate
 4343 operand immP()
 4344 %{
 4345   match(ConP);
 4346 
 4347   op_cost(0);
 4348   format %{ %}
 4349   interface(CONST_INTER);
 4350 %}
 4351 
 4352 // NULL Pointer Immediate
 4353 operand immP0()
 4354 %{
 4355   predicate(n-&gt;get_ptr() == 0);
 4356   match(ConP);
 4357 
 4358   op_cost(0);
 4359   format %{ %}
 4360   interface(CONST_INTER);
 4361 %}
 4362 
 4363 // Pointer Immediate One
 4364 // this is used in object initialization (initial object header)
 4365 operand immP_1()
 4366 %{
 4367   predicate(n-&gt;get_ptr() == 1);
 4368   match(ConP);
 4369 
 4370   op_cost(0);
 4371   format %{ %}
 4372   interface(CONST_INTER);
 4373 %}
 4374 
 4375 // Card Table Byte Map Base
 4376 operand immByteMapBase()
 4377 %{
 4378   // Get base of card map
 4379   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4380             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4381   match(ConP);
 4382 
 4383   op_cost(0);
 4384   format %{ %}
 4385   interface(CONST_INTER);
 4386 %}
 4387 
 4388 // Pointer Immediate Minus One
 4389 // this is used when we want to write the current PC to the thread anchor
 4390 operand immP_M1()
 4391 %{
 4392   predicate(n-&gt;get_ptr() == -1);
 4393   match(ConP);
 4394 
 4395   op_cost(0);
 4396   format %{ %}
 4397   interface(CONST_INTER);
 4398 %}
 4399 
 4400 // Pointer Immediate Minus Two
 4401 // this is used when we want to write the current PC to the thread anchor
 4402 operand immP_M2()
 4403 %{
 4404   predicate(n-&gt;get_ptr() == -2);
 4405   match(ConP);
 4406 
 4407   op_cost(0);
 4408   format %{ %}
 4409   interface(CONST_INTER);
 4410 %}
 4411 
 4412 // Float and Double operands
 4413 // Double Immediate
 4414 operand immD()
 4415 %{
 4416   match(ConD);
 4417   op_cost(0);
 4418   format %{ %}
 4419   interface(CONST_INTER);
 4420 %}
 4421 
 4422 // Double Immediate: +0.0d
 4423 operand immD0()
 4424 %{
 4425   predicate(jlong_cast(n-&gt;getd()) == 0);
 4426   match(ConD);
 4427 
 4428   op_cost(0);
 4429   format %{ %}
 4430   interface(CONST_INTER);
 4431 %}
 4432 
 4433 // constant &#39;double +0.0&#39;.
 4434 operand immDPacked()
 4435 %{
 4436   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4437   match(ConD);
 4438   op_cost(0);
 4439   format %{ %}
 4440   interface(CONST_INTER);
 4441 %}
 4442 
 4443 // Float Immediate
 4444 operand immF()
 4445 %{
 4446   match(ConF);
 4447   op_cost(0);
 4448   format %{ %}
 4449   interface(CONST_INTER);
 4450 %}
 4451 
 4452 // Float Immediate: +0.0f.
 4453 operand immF0()
 4454 %{
 4455   predicate(jint_cast(n-&gt;getf()) == 0);
 4456   match(ConF);
 4457 
 4458   op_cost(0);
 4459   format %{ %}
 4460   interface(CONST_INTER);
 4461 %}
 4462 
 4463 //
 4464 operand immFPacked()
 4465 %{
 4466   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4467   match(ConF);
 4468   op_cost(0);
 4469   format %{ %}
 4470   interface(CONST_INTER);
 4471 %}
 4472 
 4473 // Narrow pointer operands
 4474 // Narrow Pointer Immediate
 4475 operand immN()
 4476 %{
 4477   match(ConN);
 4478 
 4479   op_cost(0);
 4480   format %{ %}
 4481   interface(CONST_INTER);
 4482 %}
 4483 
 4484 // Narrow NULL Pointer Immediate
 4485 operand immN0()
 4486 %{
 4487   predicate(n-&gt;get_narrowcon() == 0);
 4488   match(ConN);
 4489 
 4490   op_cost(0);
 4491   format %{ %}
 4492   interface(CONST_INTER);
 4493 %}
 4494 
 4495 operand immNKlass()
 4496 %{
 4497   match(ConNKlass);
 4498 
 4499   op_cost(0);
 4500   format %{ %}
 4501   interface(CONST_INTER);
 4502 %}
 4503 
 4504 // Integer 32 bit Register Operands
 4505 // Integer 32 bitRegister (excludes SP)
 4506 operand iRegI()
 4507 %{
 4508   constraint(ALLOC_IN_RC(any_reg32));
 4509   match(RegI);
 4510   match(iRegINoSp);
 4511   op_cost(0);
 4512   format %{ %}
 4513   interface(REG_INTER);
 4514 %}
 4515 
 4516 // Integer 32 bit Register not Special
 4517 operand iRegINoSp()
 4518 %{
 4519   constraint(ALLOC_IN_RC(no_special_reg32));
 4520   match(RegI);
 4521   op_cost(0);
 4522   format %{ %}
 4523   interface(REG_INTER);
 4524 %}
 4525 
 4526 // Integer 64 bit Register Operands
 4527 // Integer 64 bit Register (includes SP)
 4528 operand iRegL()
 4529 %{
 4530   constraint(ALLOC_IN_RC(any_reg));
 4531   match(RegL);
 4532   match(iRegLNoSp);
 4533   op_cost(0);
 4534   format %{ %}
 4535   interface(REG_INTER);
 4536 %}
 4537 
 4538 // Integer 64 bit Register not Special
 4539 operand iRegLNoSp()
 4540 %{
 4541   constraint(ALLOC_IN_RC(no_special_reg));
 4542   match(RegL);
 4543   match(iRegL_R0);
 4544   format %{ %}
 4545   interface(REG_INTER);
 4546 %}
 4547 
 4548 // Pointer Register Operands
 4549 // Pointer Register
 4550 operand iRegP()
 4551 %{
 4552   constraint(ALLOC_IN_RC(ptr_reg));
 4553   match(RegP);
 4554   match(iRegPNoSp);
 4555   match(iRegP_R0);
 4556   //match(iRegP_R2);
 4557   //match(iRegP_R4);
 4558   //match(iRegP_R5);
 4559   match(thread_RegP);
 4560   op_cost(0);
 4561   format %{ %}
 4562   interface(REG_INTER);
 4563 %}
 4564 
 4565 // Pointer 64 bit Register not Special
 4566 operand iRegPNoSp()
 4567 %{
 4568   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4569   match(RegP);
 4570   // match(iRegP);
 4571   // match(iRegP_R0);
 4572   // match(iRegP_R2);
 4573   // match(iRegP_R4);
 4574   // match(iRegP_R5);
 4575   // match(thread_RegP);
 4576   op_cost(0);
 4577   format %{ %}
 4578   interface(REG_INTER);
 4579 %}
 4580 
 4581 // Pointer 64 bit Register R0 only
 4582 operand iRegP_R0()
 4583 %{
 4584   constraint(ALLOC_IN_RC(r0_reg));
 4585   match(RegP);
 4586   // match(iRegP);
 4587   match(iRegPNoSp);
 4588   op_cost(0);
 4589   format %{ %}
 4590   interface(REG_INTER);
 4591 %}
 4592 
 4593 // Pointer 64 bit Register R1 only
 4594 operand iRegP_R1()
 4595 %{
 4596   constraint(ALLOC_IN_RC(r1_reg));
 4597   match(RegP);
 4598   // match(iRegP);
 4599   match(iRegPNoSp);
 4600   op_cost(0);
 4601   format %{ %}
 4602   interface(REG_INTER);
 4603 %}
 4604 
 4605 // Pointer 64 bit Register R2 only
 4606 operand iRegP_R2()
 4607 %{
 4608   constraint(ALLOC_IN_RC(r2_reg));
 4609   match(RegP);
 4610   // match(iRegP);
 4611   match(iRegPNoSp);
 4612   op_cost(0);
 4613   format %{ %}
 4614   interface(REG_INTER);
 4615 %}
 4616 
 4617 // Pointer 64 bit Register R3 only
 4618 operand iRegP_R3()
 4619 %{
 4620   constraint(ALLOC_IN_RC(r3_reg));
 4621   match(RegP);
 4622   // match(iRegP);
 4623   match(iRegPNoSp);
 4624   op_cost(0);
 4625   format %{ %}
 4626   interface(REG_INTER);
 4627 %}
 4628 
 4629 // Pointer 64 bit Register R4 only
 4630 operand iRegP_R4()
 4631 %{
 4632   constraint(ALLOC_IN_RC(r4_reg));
 4633   match(RegP);
 4634   // match(iRegP);
 4635   match(iRegPNoSp);
 4636   op_cost(0);
 4637   format %{ %}
 4638   interface(REG_INTER);
 4639 %}
 4640 
 4641 // Pointer 64 bit Register R5 only
 4642 operand iRegP_R5()
 4643 %{
 4644   constraint(ALLOC_IN_RC(r5_reg));
 4645   match(RegP);
 4646   // match(iRegP);
 4647   match(iRegPNoSp);
 4648   op_cost(0);
 4649   format %{ %}
 4650   interface(REG_INTER);
 4651 %}
 4652 
 4653 // Pointer 64 bit Register R10 only
 4654 operand iRegP_R10()
 4655 %{
 4656   constraint(ALLOC_IN_RC(r10_reg));
 4657   match(RegP);
 4658   // match(iRegP);
 4659   match(iRegPNoSp);
 4660   op_cost(0);
 4661   format %{ %}
 4662   interface(REG_INTER);
 4663 %}
 4664 
 4665 // Long 64 bit Register R0 only
 4666 operand iRegL_R0()
 4667 %{
 4668   constraint(ALLOC_IN_RC(r0_reg));
 4669   match(RegL);
 4670   match(iRegLNoSp);
 4671   op_cost(0);
 4672   format %{ %}
 4673   interface(REG_INTER);
 4674 %}
 4675 
 4676 // Long 64 bit Register R2 only
 4677 operand iRegL_R2()
 4678 %{
 4679   constraint(ALLOC_IN_RC(r2_reg));
 4680   match(RegL);
 4681   match(iRegLNoSp);
 4682   op_cost(0);
 4683   format %{ %}
 4684   interface(REG_INTER);
 4685 %}
 4686 
 4687 // Long 64 bit Register R3 only
 4688 operand iRegL_R3()
 4689 %{
 4690   constraint(ALLOC_IN_RC(r3_reg));
 4691   match(RegL);
 4692   match(iRegLNoSp);
 4693   op_cost(0);
 4694   format %{ %}
 4695   interface(REG_INTER);
 4696 %}
 4697 
 4698 // Long 64 bit Register R11 only
 4699 operand iRegL_R11()
 4700 %{
 4701   constraint(ALLOC_IN_RC(r11_reg));
 4702   match(RegL);
 4703   match(iRegLNoSp);
 4704   op_cost(0);
 4705   format %{ %}
 4706   interface(REG_INTER);
 4707 %}
 4708 
 4709 // Pointer 64 bit Register FP only
 4710 operand iRegP_FP()
 4711 %{
 4712   constraint(ALLOC_IN_RC(fp_reg));
 4713   match(RegP);
 4714   // match(iRegP);
 4715   op_cost(0);
 4716   format %{ %}
 4717   interface(REG_INTER);
 4718 %}
 4719 
 4720 // Register R0 only
 4721 operand iRegI_R0()
 4722 %{
 4723   constraint(ALLOC_IN_RC(int_r0_reg));
 4724   match(RegI);
 4725   match(iRegINoSp);
 4726   op_cost(0);
 4727   format %{ %}
 4728   interface(REG_INTER);
 4729 %}
 4730 
 4731 // Register R2 only
 4732 operand iRegI_R2()
 4733 %{
 4734   constraint(ALLOC_IN_RC(int_r2_reg));
 4735   match(RegI);
 4736   match(iRegINoSp);
 4737   op_cost(0);
 4738   format %{ %}
 4739   interface(REG_INTER);
 4740 %}
 4741 
 4742 // Register R3 only
 4743 operand iRegI_R3()
 4744 %{
 4745   constraint(ALLOC_IN_RC(int_r3_reg));
 4746   match(RegI);
 4747   match(iRegINoSp);
 4748   op_cost(0);
 4749   format %{ %}
 4750   interface(REG_INTER);
 4751 %}
 4752 
 4753 
 4754 // Register R4 only
 4755 operand iRegI_R4()
 4756 %{
 4757   constraint(ALLOC_IN_RC(int_r4_reg));
 4758   match(RegI);
 4759   match(iRegINoSp);
 4760   op_cost(0);
 4761   format %{ %}
 4762   interface(REG_INTER);
 4763 %}
 4764 
 4765 
 4766 // Pointer Register Operands
 4767 // Narrow Pointer Register
 4768 operand iRegN()
 4769 %{
 4770   constraint(ALLOC_IN_RC(any_reg32));
 4771   match(RegN);
 4772   match(iRegNNoSp);
 4773   op_cost(0);
 4774   format %{ %}
 4775   interface(REG_INTER);
 4776 %}
 4777 
 4778 operand iRegN_R0()
 4779 %{
 4780   constraint(ALLOC_IN_RC(r0_reg));
 4781   match(iRegN);
 4782   op_cost(0);
 4783   format %{ %}
 4784   interface(REG_INTER);
 4785 %}
 4786 
 4787 operand iRegN_R2()
 4788 %{
 4789   constraint(ALLOC_IN_RC(r2_reg));
 4790   match(iRegN);
 4791   op_cost(0);
 4792   format %{ %}
 4793   interface(REG_INTER);
 4794 %}
 4795 
 4796 operand iRegN_R3()
 4797 %{
 4798   constraint(ALLOC_IN_RC(r3_reg));
 4799   match(iRegN);
 4800   op_cost(0);
 4801   format %{ %}
 4802   interface(REG_INTER);
 4803 %}
 4804 
 4805 // Integer 64 bit Register not Special
 4806 operand iRegNNoSp()
 4807 %{
 4808   constraint(ALLOC_IN_RC(no_special_reg32));
 4809   match(RegN);
 4810   op_cost(0);
 4811   format %{ %}
 4812   interface(REG_INTER);
 4813 %}
 4814 
 4815 // heap base register -- used for encoding immN0
 4816 
 4817 operand iRegIHeapbase()
 4818 %{
 4819   constraint(ALLOC_IN_RC(heapbase_reg));
 4820   match(RegI);
 4821   op_cost(0);
 4822   format %{ %}
 4823   interface(REG_INTER);
 4824 %}
 4825 
 4826 // Float Register
 4827 // Float register operands
 4828 operand vRegF()
 4829 %{
 4830   constraint(ALLOC_IN_RC(float_reg));
 4831   match(RegF);
 4832 
 4833   op_cost(0);
 4834   format %{ %}
 4835   interface(REG_INTER);
 4836 %}
 4837 
 4838 // Double Register
 4839 // Double register operands
 4840 operand vRegD()
 4841 %{
 4842   constraint(ALLOC_IN_RC(double_reg));
 4843   match(RegD);
 4844 
 4845   op_cost(0);
 4846   format %{ %}
 4847   interface(REG_INTER);
 4848 %}
 4849 
 4850 operand vecD()
 4851 %{
 4852   constraint(ALLOC_IN_RC(vectord_reg));
 4853   match(VecD);
 4854 
 4855   op_cost(0);
 4856   format %{ %}
 4857   interface(REG_INTER);
 4858 %}
 4859 
 4860 operand vecX()
 4861 %{
 4862   constraint(ALLOC_IN_RC(vectorx_reg));
 4863   match(VecX);
 4864 
 4865   op_cost(0);
 4866   format %{ %}
 4867   interface(REG_INTER);
 4868 %}
 4869 
 4870 operand vRegD_V0()
 4871 %{
 4872   constraint(ALLOC_IN_RC(v0_reg));
 4873   match(RegD);
 4874   op_cost(0);
 4875   format %{ %}
 4876   interface(REG_INTER);
 4877 %}
 4878 
 4879 operand vRegD_V1()
 4880 %{
 4881   constraint(ALLOC_IN_RC(v1_reg));
 4882   match(RegD);
 4883   op_cost(0);
 4884   format %{ %}
 4885   interface(REG_INTER);
 4886 %}
 4887 
 4888 operand vRegD_V2()
 4889 %{
 4890   constraint(ALLOC_IN_RC(v2_reg));
 4891   match(RegD);
 4892   op_cost(0);
 4893   format %{ %}
 4894   interface(REG_INTER);
 4895 %}
 4896 
 4897 operand vRegD_V3()
 4898 %{
 4899   constraint(ALLOC_IN_RC(v3_reg));
 4900   match(RegD);
 4901   op_cost(0);
 4902   format %{ %}
 4903   interface(REG_INTER);
 4904 %}
 4905 
 4906 operand vRegD_V4()
 4907 %{
 4908   constraint(ALLOC_IN_RC(v4_reg));
 4909   match(RegD);
 4910   op_cost(0);
 4911   format %{ %}
 4912   interface(REG_INTER);
 4913 %}
 4914 
 4915 operand vRegD_V5()
 4916 %{
 4917   constraint(ALLOC_IN_RC(v5_reg));
 4918   match(RegD);
 4919   op_cost(0);
 4920   format %{ %}
 4921   interface(REG_INTER);
 4922 %}
 4923 
 4924 operand vRegD_V6()
 4925 %{
 4926   constraint(ALLOC_IN_RC(v6_reg));
 4927   match(RegD);
 4928   op_cost(0);
 4929   format %{ %}
 4930   interface(REG_INTER);
 4931 %}
 4932 
 4933 operand vRegD_V7()
 4934 %{
 4935   constraint(ALLOC_IN_RC(v7_reg));
 4936   match(RegD);
 4937   op_cost(0);
 4938   format %{ %}
 4939   interface(REG_INTER);
 4940 %}
 4941 
 4942 operand vRegD_V8()
 4943 %{
 4944   constraint(ALLOC_IN_RC(v8_reg));
 4945   match(RegD);
 4946   op_cost(0);
 4947   format %{ %}
 4948   interface(REG_INTER);
 4949 %}
 4950 
 4951 operand vRegD_V9()
 4952 %{
 4953   constraint(ALLOC_IN_RC(v9_reg));
 4954   match(RegD);
 4955   op_cost(0);
 4956   format %{ %}
 4957   interface(REG_INTER);
 4958 %}
 4959 
 4960 operand vRegD_V10()
 4961 %{
 4962   constraint(ALLOC_IN_RC(v10_reg));
 4963   match(RegD);
 4964   op_cost(0);
 4965   format %{ %}
 4966   interface(REG_INTER);
 4967 %}
 4968 
 4969 operand vRegD_V11()
 4970 %{
 4971   constraint(ALLOC_IN_RC(v11_reg));
 4972   match(RegD);
 4973   op_cost(0);
 4974   format %{ %}
 4975   interface(REG_INTER);
 4976 %}
 4977 
 4978 operand vRegD_V12()
 4979 %{
 4980   constraint(ALLOC_IN_RC(v12_reg));
 4981   match(RegD);
 4982   op_cost(0);
 4983   format %{ %}
 4984   interface(REG_INTER);
 4985 %}
 4986 
 4987 operand vRegD_V13()
 4988 %{
 4989   constraint(ALLOC_IN_RC(v13_reg));
 4990   match(RegD);
 4991   op_cost(0);
 4992   format %{ %}
 4993   interface(REG_INTER);
 4994 %}
 4995 
 4996 operand vRegD_V14()
 4997 %{
 4998   constraint(ALLOC_IN_RC(v14_reg));
 4999   match(RegD);
 5000   op_cost(0);
 5001   format %{ %}
 5002   interface(REG_INTER);
 5003 %}
 5004 
 5005 operand vRegD_V15()
 5006 %{
 5007   constraint(ALLOC_IN_RC(v15_reg));
 5008   match(RegD);
 5009   op_cost(0);
 5010   format %{ %}
 5011   interface(REG_INTER);
 5012 %}
 5013 
 5014 operand vRegD_V16()
 5015 %{
 5016   constraint(ALLOC_IN_RC(v16_reg));
 5017   match(RegD);
 5018   op_cost(0);
 5019   format %{ %}
 5020   interface(REG_INTER);
 5021 %}
 5022 
 5023 operand vRegD_V17()
 5024 %{
 5025   constraint(ALLOC_IN_RC(v17_reg));
 5026   match(RegD);
 5027   op_cost(0);
 5028   format %{ %}
 5029   interface(REG_INTER);
 5030 %}
 5031 
 5032 operand vRegD_V18()
 5033 %{
 5034   constraint(ALLOC_IN_RC(v18_reg));
 5035   match(RegD);
 5036   op_cost(0);
 5037   format %{ %}
 5038   interface(REG_INTER);
 5039 %}
 5040 
 5041 operand vRegD_V19()
 5042 %{
 5043   constraint(ALLOC_IN_RC(v19_reg));
 5044   match(RegD);
 5045   op_cost(0);
 5046   format %{ %}
 5047   interface(REG_INTER);
 5048 %}
 5049 
 5050 operand vRegD_V20()
 5051 %{
 5052   constraint(ALLOC_IN_RC(v20_reg));
 5053   match(RegD);
 5054   op_cost(0);
 5055   format %{ %}
 5056   interface(REG_INTER);
 5057 %}
 5058 
 5059 operand vRegD_V21()
 5060 %{
 5061   constraint(ALLOC_IN_RC(v21_reg));
 5062   match(RegD);
 5063   op_cost(0);
 5064   format %{ %}
 5065   interface(REG_INTER);
 5066 %}
 5067 
 5068 operand vRegD_V22()
 5069 %{
 5070   constraint(ALLOC_IN_RC(v22_reg));
 5071   match(RegD);
 5072   op_cost(0);
 5073   format %{ %}
 5074   interface(REG_INTER);
 5075 %}
 5076 
 5077 operand vRegD_V23()
 5078 %{
 5079   constraint(ALLOC_IN_RC(v23_reg));
 5080   match(RegD);
 5081   op_cost(0);
 5082   format %{ %}
 5083   interface(REG_INTER);
 5084 %}
 5085 
 5086 operand vRegD_V24()
 5087 %{
 5088   constraint(ALLOC_IN_RC(v24_reg));
 5089   match(RegD);
 5090   op_cost(0);
 5091   format %{ %}
 5092   interface(REG_INTER);
 5093 %}
 5094 
 5095 operand vRegD_V25()
 5096 %{
 5097   constraint(ALLOC_IN_RC(v25_reg));
 5098   match(RegD);
 5099   op_cost(0);
 5100   format %{ %}
 5101   interface(REG_INTER);
 5102 %}
 5103 
 5104 operand vRegD_V26()
 5105 %{
 5106   constraint(ALLOC_IN_RC(v26_reg));
 5107   match(RegD);
 5108   op_cost(0);
 5109   format %{ %}
 5110   interface(REG_INTER);
 5111 %}
 5112 
 5113 operand vRegD_V27()
 5114 %{
 5115   constraint(ALLOC_IN_RC(v27_reg));
 5116   match(RegD);
 5117   op_cost(0);
 5118   format %{ %}
 5119   interface(REG_INTER);
 5120 %}
 5121 
 5122 operand vRegD_V28()
 5123 %{
 5124   constraint(ALLOC_IN_RC(v28_reg));
 5125   match(RegD);
 5126   op_cost(0);
 5127   format %{ %}
 5128   interface(REG_INTER);
 5129 %}
 5130 
 5131 operand vRegD_V29()
 5132 %{
 5133   constraint(ALLOC_IN_RC(v29_reg));
 5134   match(RegD);
 5135   op_cost(0);
 5136   format %{ %}
 5137   interface(REG_INTER);
 5138 %}
 5139 
 5140 operand vRegD_V30()
 5141 %{
 5142   constraint(ALLOC_IN_RC(v30_reg));
 5143   match(RegD);
 5144   op_cost(0);
 5145   format %{ %}
 5146   interface(REG_INTER);
 5147 %}
 5148 
 5149 operand vRegD_V31()
 5150 %{
 5151   constraint(ALLOC_IN_RC(v31_reg));
 5152   match(RegD);
 5153   op_cost(0);
 5154   format %{ %}
 5155   interface(REG_INTER);
 5156 %}
 5157 
 5158 // Flags register, used as output of signed compare instructions
 5159 
 5160 // note that on AArch64 we also use this register as the output for
 5161 // for floating point compare instructions (CmpF CmpD). this ensures
 5162 // that ordered inequality tests use GT, GE, LT or LE none of which
 5163 // pass through cases where the result is unordered i.e. one or both
 5164 // inputs to the compare is a NaN. this means that the ideal code can
 5165 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5166 // (where the comparison should always fail). EQ and NE tests are
 5167 // always generated in ideal code so that unordered folds into the NE
 5168 // case, matching the behaviour of AArch64 NE.
 5169 //
 5170 // This differs from x86 where the outputs of FP compares use a
 5171 // special FP flags registers and where compares based on this
 5172 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5173 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5174 // to explicitly handle the unordered case in branches. x86 also has
 5175 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5176 
 5177 operand rFlagsReg()
 5178 %{
 5179   constraint(ALLOC_IN_RC(int_flags));
 5180   match(RegFlags);
 5181 
 5182   op_cost(0);
 5183   format %{ &quot;RFLAGS&quot; %}
 5184   interface(REG_INTER);
 5185 %}
 5186 
 5187 // Flags register, used as output of unsigned compare instructions
 5188 operand rFlagsRegU()
 5189 %{
 5190   constraint(ALLOC_IN_RC(int_flags));
 5191   match(RegFlags);
 5192 
 5193   op_cost(0);
 5194   format %{ &quot;RFLAGSU&quot; %}
 5195   interface(REG_INTER);
 5196 %}
 5197 
 5198 // Special Registers
 5199 
 5200 // Method Register
 5201 operand inline_cache_RegP(iRegP reg)
 5202 %{
 5203   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5204   match(reg);
 5205   match(iRegPNoSp);
 5206   op_cost(0);
 5207   format %{ %}
 5208   interface(REG_INTER);
 5209 %}
 5210 
 5211 operand interpreter_method_oop_RegP(iRegP reg)
 5212 %{
 5213   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5214   match(reg);
 5215   match(iRegPNoSp);
 5216   op_cost(0);
 5217   format %{ %}
 5218   interface(REG_INTER);
 5219 %}
 5220 
 5221 // Thread Register
 5222 operand thread_RegP(iRegP reg)
 5223 %{
 5224   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5225   match(reg);
 5226   op_cost(0);
 5227   format %{ %}
 5228   interface(REG_INTER);
 5229 %}
 5230 
 5231 operand lr_RegP(iRegP reg)
 5232 %{
 5233   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5234   match(reg);
 5235   op_cost(0);
 5236   format %{ %}
 5237   interface(REG_INTER);
 5238 %}
 5239 
 5240 //----------Memory Operands----------------------------------------------------
 5241 
 5242 operand indirect(iRegP reg)
 5243 %{
 5244   constraint(ALLOC_IN_RC(ptr_reg));
 5245   match(reg);
 5246   op_cost(0);
 5247   format %{ &quot;[$reg]&quot; %}
 5248   interface(MEMORY_INTER) %{
 5249     base($reg);
 5250     index(0xffffffff);
 5251     scale(0x0);
 5252     disp(0x0);
 5253   %}
 5254 %}
 5255 
 5256 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5257 %{
 5258   constraint(ALLOC_IN_RC(ptr_reg));
 5259   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5260   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5261   op_cost(0);
 5262   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5263   interface(MEMORY_INTER) %{
 5264     base($reg);
 5265     index($ireg);
 5266     scale($scale);
 5267     disp(0x0);
 5268   %}
 5269 %}
 5270 
 5271 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5272 %{
 5273   constraint(ALLOC_IN_RC(ptr_reg));
 5274   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5275   match(AddP reg (LShiftL lreg scale));
 5276   op_cost(0);
 5277   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5278   interface(MEMORY_INTER) %{
 5279     base($reg);
 5280     index($lreg);
 5281     scale($scale);
 5282     disp(0x0);
 5283   %}
 5284 %}
 5285 
 5286 operand indIndexI2L(iRegP reg, iRegI ireg)
 5287 %{
 5288   constraint(ALLOC_IN_RC(ptr_reg));
 5289   match(AddP reg (ConvI2L ireg));
 5290   op_cost(0);
 5291   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5292   interface(MEMORY_INTER) %{
 5293     base($reg);
 5294     index($ireg);
 5295     scale(0x0);
 5296     disp(0x0);
 5297   %}
 5298 %}
 5299 
 5300 operand indIndex(iRegP reg, iRegL lreg)
 5301 %{
 5302   constraint(ALLOC_IN_RC(ptr_reg));
 5303   match(AddP reg lreg);
 5304   op_cost(0);
 5305   format %{ &quot;$reg, $lreg&quot; %}
 5306   interface(MEMORY_INTER) %{
 5307     base($reg);
 5308     index($lreg);
 5309     scale(0x0);
 5310     disp(0x0);
 5311   %}
 5312 %}
 5313 
 5314 operand indOffI(iRegP reg, immIOffset off)
 5315 %{
 5316   constraint(ALLOC_IN_RC(ptr_reg));
 5317   match(AddP reg off);
 5318   op_cost(0);
 5319   format %{ &quot;[$reg, $off]&quot; %}
 5320   interface(MEMORY_INTER) %{
 5321     base($reg);
 5322     index(0xffffffff);
 5323     scale(0x0);
 5324     disp($off);
 5325   %}
 5326 %}
 5327 
 5328 operand indOffI1(iRegP reg, immIOffset1 off)
 5329 %{
 5330   constraint(ALLOC_IN_RC(ptr_reg));
 5331   match(AddP reg off);
 5332   op_cost(0);
 5333   format %{ &quot;[$reg, $off]&quot; %}
 5334   interface(MEMORY_INTER) %{
 5335     base($reg);
 5336     index(0xffffffff);
 5337     scale(0x0);
 5338     disp($off);
 5339   %}
 5340 %}
 5341 
 5342 operand indOffI2(iRegP reg, immIOffset2 off)
 5343 %{
 5344   constraint(ALLOC_IN_RC(ptr_reg));
 5345   match(AddP reg off);
 5346   op_cost(0);
 5347   format %{ &quot;[$reg, $off]&quot; %}
 5348   interface(MEMORY_INTER) %{
 5349     base($reg);
 5350     index(0xffffffff);
 5351     scale(0x0);
 5352     disp($off);
 5353   %}
 5354 %}
 5355 
 5356 operand indOffI4(iRegP reg, immIOffset4 off)
 5357 %{
 5358   constraint(ALLOC_IN_RC(ptr_reg));
 5359   match(AddP reg off);
 5360   op_cost(0);
 5361   format %{ &quot;[$reg, $off]&quot; %}
 5362   interface(MEMORY_INTER) %{
 5363     base($reg);
 5364     index(0xffffffff);
 5365     scale(0x0);
 5366     disp($off);
 5367   %}
 5368 %}
 5369 
 5370 operand indOffI8(iRegP reg, immIOffset8 off)
 5371 %{
 5372   constraint(ALLOC_IN_RC(ptr_reg));
 5373   match(AddP reg off);
 5374   op_cost(0);
 5375   format %{ &quot;[$reg, $off]&quot; %}
 5376   interface(MEMORY_INTER) %{
 5377     base($reg);
 5378     index(0xffffffff);
 5379     scale(0x0);
 5380     disp($off);
 5381   %}
 5382 %}
 5383 
 5384 operand indOffI16(iRegP reg, immIOffset16 off)
 5385 %{
 5386   constraint(ALLOC_IN_RC(ptr_reg));
 5387   match(AddP reg off);
 5388   op_cost(0);
 5389   format %{ &quot;[$reg, $off]&quot; %}
 5390   interface(MEMORY_INTER) %{
 5391     base($reg);
 5392     index(0xffffffff);
 5393     scale(0x0);
 5394     disp($off);
 5395   %}
 5396 %}
 5397 
 5398 operand indOffL(iRegP reg, immLoffset off)
 5399 %{
 5400   constraint(ALLOC_IN_RC(ptr_reg));
 5401   match(AddP reg off);
 5402   op_cost(0);
 5403   format %{ &quot;[$reg, $off]&quot; %}
 5404   interface(MEMORY_INTER) %{
 5405     base($reg);
 5406     index(0xffffffff);
 5407     scale(0x0);
 5408     disp($off);
 5409   %}
 5410 %}
 5411 
 5412 operand indOffL1(iRegP reg, immLoffset1 off)
 5413 %{
 5414   constraint(ALLOC_IN_RC(ptr_reg));
 5415   match(AddP reg off);
 5416   op_cost(0);
 5417   format %{ &quot;[$reg, $off]&quot; %}
 5418   interface(MEMORY_INTER) %{
 5419     base($reg);
 5420     index(0xffffffff);
 5421     scale(0x0);
 5422     disp($off);
 5423   %}
 5424 %}
 5425 
 5426 operand indOffL2(iRegP reg, immLoffset2 off)
 5427 %{
 5428   constraint(ALLOC_IN_RC(ptr_reg));
 5429   match(AddP reg off);
 5430   op_cost(0);
 5431   format %{ &quot;[$reg, $off]&quot; %}
 5432   interface(MEMORY_INTER) %{
 5433     base($reg);
 5434     index(0xffffffff);
 5435     scale(0x0);
 5436     disp($off);
 5437   %}
 5438 %}
 5439 
 5440 operand indOffL4(iRegP reg, immLoffset4 off)
 5441 %{
 5442   constraint(ALLOC_IN_RC(ptr_reg));
 5443   match(AddP reg off);
 5444   op_cost(0);
 5445   format %{ &quot;[$reg, $off]&quot; %}
 5446   interface(MEMORY_INTER) %{
 5447     base($reg);
 5448     index(0xffffffff);
 5449     scale(0x0);
 5450     disp($off);
 5451   %}
 5452 %}
 5453 
 5454 operand indOffL8(iRegP reg, immLoffset8 off)
 5455 %{
 5456   constraint(ALLOC_IN_RC(ptr_reg));
 5457   match(AddP reg off);
 5458   op_cost(0);
 5459   format %{ &quot;[$reg, $off]&quot; %}
 5460   interface(MEMORY_INTER) %{
 5461     base($reg);
 5462     index(0xffffffff);
 5463     scale(0x0);
 5464     disp($off);
 5465   %}
 5466 %}
 5467 
 5468 operand indOffL16(iRegP reg, immLoffset16 off)
 5469 %{
 5470   constraint(ALLOC_IN_RC(ptr_reg));
 5471   match(AddP reg off);
 5472   op_cost(0);
 5473   format %{ &quot;[$reg, $off]&quot; %}
 5474   interface(MEMORY_INTER) %{
 5475     base($reg);
 5476     index(0xffffffff);
 5477     scale(0x0);
 5478     disp($off);
 5479   %}
 5480 %}
 5481 
 5482 operand indirectN(iRegN reg)
 5483 %{
 5484   predicate(CompressedOops::shift() == 0);
 5485   constraint(ALLOC_IN_RC(ptr_reg));
 5486   match(DecodeN reg);
 5487   op_cost(0);
 5488   format %{ &quot;[$reg]\t# narrow&quot; %}
 5489   interface(MEMORY_INTER) %{
 5490     base($reg);
 5491     index(0xffffffff);
 5492     scale(0x0);
 5493     disp(0x0);
 5494   %}
 5495 %}
 5496 
 5497 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5498 %{
 5499   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5500   constraint(ALLOC_IN_RC(ptr_reg));
 5501   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5502   op_cost(0);
 5503   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5504   interface(MEMORY_INTER) %{
 5505     base($reg);
 5506     index($ireg);
 5507     scale($scale);
 5508     disp(0x0);
 5509   %}
 5510 %}
 5511 
 5512 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5513 %{
 5514   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5515   constraint(ALLOC_IN_RC(ptr_reg));
 5516   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5517   op_cost(0);
 5518   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5519   interface(MEMORY_INTER) %{
 5520     base($reg);
 5521     index($lreg);
 5522     scale($scale);
 5523     disp(0x0);
 5524   %}
 5525 %}
 5526 
 5527 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5528 %{
 5529   predicate(CompressedOops::shift() == 0);
 5530   constraint(ALLOC_IN_RC(ptr_reg));
 5531   match(AddP (DecodeN reg) (ConvI2L ireg));
 5532   op_cost(0);
 5533   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5534   interface(MEMORY_INTER) %{
 5535     base($reg);
 5536     index($ireg);
 5537     scale(0x0);
 5538     disp(0x0);
 5539   %}
 5540 %}
 5541 
 5542 operand indIndexN(iRegN reg, iRegL lreg)
 5543 %{
 5544   predicate(CompressedOops::shift() == 0);
 5545   constraint(ALLOC_IN_RC(ptr_reg));
 5546   match(AddP (DecodeN reg) lreg);
 5547   op_cost(0);
 5548   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5549   interface(MEMORY_INTER) %{
 5550     base($reg);
 5551     index($lreg);
 5552     scale(0x0);
 5553     disp(0x0);
 5554   %}
 5555 %}
 5556 
 5557 operand indOffIN(iRegN reg, immIOffset off)
 5558 %{
 5559   predicate(CompressedOops::shift() == 0);
 5560   constraint(ALLOC_IN_RC(ptr_reg));
 5561   match(AddP (DecodeN reg) off);
 5562   op_cost(0);
 5563   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5564   interface(MEMORY_INTER) %{
 5565     base($reg);
 5566     index(0xffffffff);
 5567     scale(0x0);
 5568     disp($off);
 5569   %}
 5570 %}
 5571 
 5572 operand indOffLN(iRegN reg, immLoffset off)
 5573 %{
 5574   predicate(CompressedOops::shift() == 0);
 5575   constraint(ALLOC_IN_RC(ptr_reg));
 5576   match(AddP (DecodeN reg) off);
 5577   op_cost(0);
 5578   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5579   interface(MEMORY_INTER) %{
 5580     base($reg);
 5581     index(0xffffffff);
 5582     scale(0x0);
 5583     disp($off);
 5584   %}
 5585 %}
 5586 
 5587 
 5588 
 5589 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5590 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5591 %{
 5592   constraint(ALLOC_IN_RC(ptr_reg));
 5593   match(AddP reg off);
 5594   op_cost(0);
 5595   format %{ &quot;[$reg, $off]&quot; %}
 5596   interface(MEMORY_INTER) %{
 5597     base($reg);
 5598     index(0xffffffff);
 5599     scale(0x0);
 5600     disp($off);
 5601   %}
 5602 %}
 5603 
 5604 //----------Special Memory Operands--------------------------------------------
 5605 // Stack Slot Operand - This operand is used for loading and storing temporary
 5606 //                      values on the stack where a match requires a value to
 5607 //                      flow through memory.
 5608 operand stackSlotP(sRegP reg)
 5609 %{
 5610   constraint(ALLOC_IN_RC(stack_slots));
 5611   op_cost(100);
 5612   // No match rule because this operand is only generated in matching
 5613   // match(RegP);
 5614   format %{ &quot;[$reg]&quot; %}
 5615   interface(MEMORY_INTER) %{
 5616     base(0x1e);  // RSP
 5617     index(0x0);  // No Index
 5618     scale(0x0);  // No Scale
 5619     disp($reg);  // Stack Offset
 5620   %}
 5621 %}
 5622 
 5623 operand stackSlotI(sRegI reg)
 5624 %{
 5625   constraint(ALLOC_IN_RC(stack_slots));
 5626   // No match rule because this operand is only generated in matching
 5627   // match(RegI);
 5628   format %{ &quot;[$reg]&quot; %}
 5629   interface(MEMORY_INTER) %{
 5630     base(0x1e);  // RSP
 5631     index(0x0);  // No Index
 5632     scale(0x0);  // No Scale
 5633     disp($reg);  // Stack Offset
 5634   %}
 5635 %}
 5636 
 5637 operand stackSlotF(sRegF reg)
 5638 %{
 5639   constraint(ALLOC_IN_RC(stack_slots));
 5640   // No match rule because this operand is only generated in matching
 5641   // match(RegF);
 5642   format %{ &quot;[$reg]&quot; %}
 5643   interface(MEMORY_INTER) %{
 5644     base(0x1e);  // RSP
 5645     index(0x0);  // No Index
 5646     scale(0x0);  // No Scale
 5647     disp($reg);  // Stack Offset
 5648   %}
 5649 %}
 5650 
 5651 operand stackSlotD(sRegD reg)
 5652 %{
 5653   constraint(ALLOC_IN_RC(stack_slots));
 5654   // No match rule because this operand is only generated in matching
 5655   // match(RegD);
 5656   format %{ &quot;[$reg]&quot; %}
 5657   interface(MEMORY_INTER) %{
 5658     base(0x1e);  // RSP
 5659     index(0x0);  // No Index
 5660     scale(0x0);  // No Scale
 5661     disp($reg);  // Stack Offset
 5662   %}
 5663 %}
 5664 
 5665 operand stackSlotL(sRegL reg)
 5666 %{
 5667   constraint(ALLOC_IN_RC(stack_slots));
 5668   // No match rule because this operand is only generated in matching
 5669   // match(RegL);
 5670   format %{ &quot;[$reg]&quot; %}
 5671   interface(MEMORY_INTER) %{
 5672     base(0x1e);  // RSP
 5673     index(0x0);  // No Index
 5674     scale(0x0);  // No Scale
 5675     disp($reg);  // Stack Offset
 5676   %}
 5677 %}
 5678 
 5679 // Operands for expressing Control Flow
 5680 // NOTE: Label is a predefined operand which should not be redefined in
 5681 //       the AD file. It is generically handled within the ADLC.
 5682 
 5683 //----------Conditional Branch Operands----------------------------------------
 5684 // Comparison Op  - This is the operation of the comparison, and is limited to
 5685 //                  the following set of codes:
 5686 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5687 //
 5688 // Other attributes of the comparison, such as unsignedness, are specified
 5689 // by the comparison instruction that sets a condition code flags register.
 5690 // That result is represented by a flags operand whose subtype is appropriate
 5691 // to the unsignedness (etc.) of the comparison.
 5692 //
 5693 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5694 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5695 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5696 
 5697 // used for signed integral comparisons and fp comparisons
 5698 
 5699 operand cmpOp()
 5700 %{
 5701   match(Bool);
 5702 
 5703   format %{ &quot;&quot; %}
 5704   interface(COND_INTER) %{
 5705     equal(0x0, &quot;eq&quot;);
 5706     not_equal(0x1, &quot;ne&quot;);
 5707     less(0xb, &quot;lt&quot;);
 5708     greater_equal(0xa, &quot;ge&quot;);
 5709     less_equal(0xd, &quot;le&quot;);
 5710     greater(0xc, &quot;gt&quot;);
 5711     overflow(0x6, &quot;vs&quot;);
 5712     no_overflow(0x7, &quot;vc&quot;);
 5713   %}
 5714 %}
 5715 
 5716 // used for unsigned integral comparisons
 5717 
 5718 operand cmpOpU()
 5719 %{
 5720   match(Bool);
 5721 
 5722   format %{ &quot;&quot; %}
 5723   interface(COND_INTER) %{
 5724     equal(0x0, &quot;eq&quot;);
 5725     not_equal(0x1, &quot;ne&quot;);
 5726     less(0x3, &quot;lo&quot;);
 5727     greater_equal(0x2, &quot;hs&quot;);
 5728     less_equal(0x9, &quot;ls&quot;);
 5729     greater(0x8, &quot;hi&quot;);
 5730     overflow(0x6, &quot;vs&quot;);
 5731     no_overflow(0x7, &quot;vc&quot;);
 5732   %}
 5733 %}
 5734 
 5735 // used for certain integral comparisons which can be
 5736 // converted to cbxx or tbxx instructions
 5737 
 5738 operand cmpOpEqNe()
 5739 %{
 5740   match(Bool);
 5741   op_cost(0);
 5742   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5743             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5744 
 5745   format %{ &quot;&quot; %}
 5746   interface(COND_INTER) %{
 5747     equal(0x0, &quot;eq&quot;);
 5748     not_equal(0x1, &quot;ne&quot;);
 5749     less(0xb, &quot;lt&quot;);
 5750     greater_equal(0xa, &quot;ge&quot;);
 5751     less_equal(0xd, &quot;le&quot;);
 5752     greater(0xc, &quot;gt&quot;);
 5753     overflow(0x6, &quot;vs&quot;);
 5754     no_overflow(0x7, &quot;vc&quot;);
 5755   %}
 5756 %}
 5757 
 5758 // used for certain integral comparisons which can be
 5759 // converted to cbxx or tbxx instructions
 5760 
 5761 operand cmpOpLtGe()
 5762 %{
 5763   match(Bool);
 5764   op_cost(0);
 5765 
 5766   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5767             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5768 
 5769   format %{ &quot;&quot; %}
 5770   interface(COND_INTER) %{
 5771     equal(0x0, &quot;eq&quot;);
 5772     not_equal(0x1, &quot;ne&quot;);
 5773     less(0xb, &quot;lt&quot;);
 5774     greater_equal(0xa, &quot;ge&quot;);
 5775     less_equal(0xd, &quot;le&quot;);
 5776     greater(0xc, &quot;gt&quot;);
 5777     overflow(0x6, &quot;vs&quot;);
 5778     no_overflow(0x7, &quot;vc&quot;);
 5779   %}
 5780 %}
 5781 
 5782 // used for certain unsigned integral comparisons which can be
 5783 // converted to cbxx or tbxx instructions
 5784 
 5785 operand cmpOpUEqNeLtGe()
 5786 %{
 5787   match(Bool);
 5788   op_cost(0);
 5789 
 5790   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5791             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5792             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5793             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5794 
 5795   format %{ &quot;&quot; %}
 5796   interface(COND_INTER) %{
 5797     equal(0x0, &quot;eq&quot;);
 5798     not_equal(0x1, &quot;ne&quot;);
 5799     less(0xb, &quot;lt&quot;);
 5800     greater_equal(0xa, &quot;ge&quot;);
 5801     less_equal(0xd, &quot;le&quot;);
 5802     greater(0xc, &quot;gt&quot;);
 5803     overflow(0x6, &quot;vs&quot;);
 5804     no_overflow(0x7, &quot;vc&quot;);
 5805   %}
 5806 %}
 5807 
 5808 // Special operand allowing long args to int ops to be truncated for free
 5809 
 5810 operand iRegL2I(iRegL reg) %{
 5811 
 5812   op_cost(0);
 5813 
 5814   match(ConvL2I reg);
 5815 
 5816   format %{ &quot;l2i($reg)&quot; %}
 5817 
 5818   interface(REG_INTER)
 5819 %}
 5820 
 5821 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5822 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5823 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5824 
 5825 //----------OPERAND CLASSES----------------------------------------------------
 5826 // Operand Classes are groups of operands that are used as to simplify
 5827 // instruction definitions by not requiring the AD writer to specify
 5828 // separate instructions for every form of operand when the
 5829 // instruction accepts multiple operand types with the same basic
 5830 // encoding and format. The classic case of this is memory operands.
 5831 
 5832 // memory is used to define read/write location for load/store
 5833 // instruction defs. we can turn a memory op into an Address
 5834 
 5835 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5836                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5837 
 5838 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5839                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5840 
 5841 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5842                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5843 
 5844 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5845                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5846 
 5847 // All of the memory operands. For the pipeline description.
 5848 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5849                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5850                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5851 
 5852 
 5853 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5854 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5855 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5856 // can be elided because the 32-bit instruction will just employ the
 5857 // lower 32 bits anyway.
 5858 //
 5859 // n.b. this does not elide all L2I conversions. if the truncated
 5860 // value is consumed by more than one operation then the ConvL2I
 5861 // cannot be bundled into the consuming nodes so an l2i gets planted
 5862 // (actually a movw $dst $src) and the downstream instructions consume
 5863 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5864 // movw is actually redundant but its not too costly.
 5865 
 5866 opclass iRegIorL2I(iRegI, iRegL2I);
 5867 
 5868 //----------PIPELINE-----------------------------------------------------------
 5869 // Rules which define the behavior of the target architectures pipeline.
 5870 
 5871 // For specific pipelines, eg A53, define the stages of that pipeline
 5872 //pipe_desc(ISS, EX1, EX2, WR);
 5873 #define ISS S0
 5874 #define EX1 S1
 5875 #define EX2 S2
 5876 #define WR  S3
 5877 
 5878 // Integer ALU reg operation
 5879 pipeline %{
 5880 
 5881 attributes %{
 5882   // ARM instructions are of fixed length
 5883   fixed_size_instructions;        // Fixed size instructions TODO does
 5884   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5885   // ARM instructions come in 32-bit word units
 5886   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5887   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5888   instruction_fetch_units = 1;       // of 64 bytes
 5889 
 5890   // List of nop instructions
 5891   nops( MachNop );
 5892 %}
 5893 
 5894 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5895 // or description. we do use pipeline classes to introduce fixed
 5896 // latencies
 5897 
 5898 //----------RESOURCES----------------------------------------------------------
 5899 // Resources are the functional units available to the machine
 5900 
 5901 resources( INS0, INS1, INS01 = INS0 | INS1,
 5902            ALU0, ALU1, ALU = ALU0 | ALU1,
 5903            MAC,
 5904            DIV,
 5905            BRANCH,
 5906            LDST,
 5907            NEON_FP);
 5908 
 5909 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5910 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5911 
 5912 // Define the pipeline as a generic 6 stage pipeline
 5913 pipe_desc(S0, S1, S2, S3, S4, S5);
 5914 
 5915 //----------PIPELINE CLASSES---------------------------------------------------
 5916 // Pipeline Classes describe the stages in which input and output are
 5917 // referenced by the hardware pipeline.
 5918 
 5919 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5920 %{
 5921   single_instruction;
 5922   src1   : S1(read);
 5923   src2   : S2(read);
 5924   dst    : S5(write);
 5925   INS01  : ISS;
 5926   NEON_FP : S5;
 5927 %}
 5928 
 5929 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5930 %{
 5931   single_instruction;
 5932   src1   : S1(read);
 5933   src2   : S2(read);
 5934   dst    : S5(write);
 5935   INS01  : ISS;
 5936   NEON_FP : S5;
 5937 %}
 5938 
 5939 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5940 %{
 5941   single_instruction;
 5942   src    : S1(read);
 5943   dst    : S5(write);
 5944   INS01  : ISS;
 5945   NEON_FP : S5;
 5946 %}
 5947 
 5948 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5949 %{
 5950   single_instruction;
 5951   src    : S1(read);
 5952   dst    : S5(write);
 5953   INS01  : ISS;
 5954   NEON_FP : S5;
 5955 %}
 5956 
 5957 pipe_class fp_d2f(vRegF dst, vRegD src)
 5958 %{
 5959   single_instruction;
 5960   src    : S1(read);
 5961   dst    : S5(write);
 5962   INS01  : ISS;
 5963   NEON_FP : S5;
 5964 %}
 5965 
 5966 pipe_class fp_f2d(vRegD dst, vRegF src)
 5967 %{
 5968   single_instruction;
 5969   src    : S1(read);
 5970   dst    : S5(write);
 5971   INS01  : ISS;
 5972   NEON_FP : S5;
 5973 %}
 5974 
 5975 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5976 %{
 5977   single_instruction;
 5978   src    : S1(read);
 5979   dst    : S5(write);
 5980   INS01  : ISS;
 5981   NEON_FP : S5;
 5982 %}
 5983 
 5984 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5985 %{
 5986   single_instruction;
 5987   src    : S1(read);
 5988   dst    : S5(write);
 5989   INS01  : ISS;
 5990   NEON_FP : S5;
 5991 %}
 5992 
 5993 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 5994 %{
 5995   single_instruction;
 5996   src    : S1(read);
 5997   dst    : S5(write);
 5998   INS01  : ISS;
 5999   NEON_FP : S5;
 6000 %}
 6001 
 6002 pipe_class fp_l2f(vRegF dst, iRegL src)
 6003 %{
 6004   single_instruction;
 6005   src    : S1(read);
 6006   dst    : S5(write);
 6007   INS01  : ISS;
 6008   NEON_FP : S5;
 6009 %}
 6010 
 6011 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6012 %{
 6013   single_instruction;
 6014   src    : S1(read);
 6015   dst    : S5(write);
 6016   INS01  : ISS;
 6017   NEON_FP : S5;
 6018 %}
 6019 
 6020 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6021 %{
 6022   single_instruction;
 6023   src    : S1(read);
 6024   dst    : S5(write);
 6025   INS01  : ISS;
 6026   NEON_FP : S5;
 6027 %}
 6028 
 6029 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6030 %{
 6031   single_instruction;
 6032   src    : S1(read);
 6033   dst    : S5(write);
 6034   INS01  : ISS;
 6035   NEON_FP : S5;
 6036 %}
 6037 
 6038 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6039 %{
 6040   single_instruction;
 6041   src    : S1(read);
 6042   dst    : S5(write);
 6043   INS01  : ISS;
 6044   NEON_FP : S5;
 6045 %}
 6046 
 6047 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6048 %{
 6049   single_instruction;
 6050   src1   : S1(read);
 6051   src2   : S2(read);
 6052   dst    : S5(write);
 6053   INS0   : ISS;
 6054   NEON_FP : S5;
 6055 %}
 6056 
 6057 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6058 %{
 6059   single_instruction;
 6060   src1   : S1(read);
 6061   src2   : S2(read);
 6062   dst    : S5(write);
 6063   INS0   : ISS;
 6064   NEON_FP : S5;
 6065 %}
 6066 
 6067 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6068 %{
 6069   single_instruction;
 6070   cr     : S1(read);
 6071   src1   : S1(read);
 6072   src2   : S1(read);
 6073   dst    : S3(write);
 6074   INS01  : ISS;
 6075   NEON_FP : S3;
 6076 %}
 6077 
 6078 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6079 %{
 6080   single_instruction;
 6081   cr     : S1(read);
 6082   src1   : S1(read);
 6083   src2   : S1(read);
 6084   dst    : S3(write);
 6085   INS01  : ISS;
 6086   NEON_FP : S3;
 6087 %}
 6088 
 6089 pipe_class fp_imm_s(vRegF dst)
 6090 %{
 6091   single_instruction;
 6092   dst    : S3(write);
 6093   INS01  : ISS;
 6094   NEON_FP : S3;
 6095 %}
 6096 
 6097 pipe_class fp_imm_d(vRegD dst)
 6098 %{
 6099   single_instruction;
 6100   dst    : S3(write);
 6101   INS01  : ISS;
 6102   NEON_FP : S3;
 6103 %}
 6104 
 6105 pipe_class fp_load_constant_s(vRegF dst)
 6106 %{
 6107   single_instruction;
 6108   dst    : S4(write);
 6109   INS01  : ISS;
 6110   NEON_FP : S4;
 6111 %}
 6112 
 6113 pipe_class fp_load_constant_d(vRegD dst)
 6114 %{
 6115   single_instruction;
 6116   dst    : S4(write);
 6117   INS01  : ISS;
 6118   NEON_FP : S4;
 6119 %}
 6120 
 6121 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6122 %{
 6123   single_instruction;
 6124   dst    : S5(write);
 6125   src1   : S1(read);
 6126   src2   : S1(read);
 6127   INS01  : ISS;
 6128   NEON_FP : S5;
 6129 %}
 6130 
 6131 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6132 %{
 6133   single_instruction;
 6134   dst    : S5(write);
 6135   src1   : S1(read);
 6136   src2   : S1(read);
 6137   INS0   : ISS;
 6138   NEON_FP : S5;
 6139 %}
 6140 
 6141 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6142 %{
 6143   single_instruction;
 6144   dst    : S5(write);
 6145   src1   : S1(read);
 6146   src2   : S1(read);
 6147   dst    : S1(read);
 6148   INS01  : ISS;
 6149   NEON_FP : S5;
 6150 %}
 6151 
 6152 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6153 %{
 6154   single_instruction;
 6155   dst    : S5(write);
 6156   src1   : S1(read);
 6157   src2   : S1(read);
 6158   dst    : S1(read);
 6159   INS0   : ISS;
 6160   NEON_FP : S5;
 6161 %}
 6162 
 6163 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6164 %{
 6165   single_instruction;
 6166   dst    : S4(write);
 6167   src1   : S2(read);
 6168   src2   : S2(read);
 6169   INS01  : ISS;
 6170   NEON_FP : S4;
 6171 %}
 6172 
 6173 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6174 %{
 6175   single_instruction;
 6176   dst    : S4(write);
 6177   src1   : S2(read);
 6178   src2   : S2(read);
 6179   INS0   : ISS;
 6180   NEON_FP : S4;
 6181 %}
 6182 
 6183 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6184 %{
 6185   single_instruction;
 6186   dst    : S3(write);
 6187   src1   : S2(read);
 6188   src2   : S2(read);
 6189   INS01  : ISS;
 6190   NEON_FP : S3;
 6191 %}
 6192 
 6193 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6194 %{
 6195   single_instruction;
 6196   dst    : S3(write);
 6197   src1   : S2(read);
 6198   src2   : S2(read);
 6199   INS0   : ISS;
 6200   NEON_FP : S3;
 6201 %}
 6202 
 6203 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6204 %{
 6205   single_instruction;
 6206   dst    : S3(write);
 6207   src    : S1(read);
 6208   shift  : S1(read);
 6209   INS01  : ISS;
 6210   NEON_FP : S3;
 6211 %}
 6212 
 6213 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6214 %{
 6215   single_instruction;
 6216   dst    : S3(write);
 6217   src    : S1(read);
 6218   shift  : S1(read);
 6219   INS0   : ISS;
 6220   NEON_FP : S3;
 6221 %}
 6222 
 6223 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6224 %{
 6225   single_instruction;
 6226   dst    : S3(write);
 6227   src    : S1(read);
 6228   INS01  : ISS;
 6229   NEON_FP : S3;
 6230 %}
 6231 
 6232 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6233 %{
 6234   single_instruction;
 6235   dst    : S3(write);
 6236   src    : S1(read);
 6237   INS0   : ISS;
 6238   NEON_FP : S3;
 6239 %}
 6240 
 6241 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6242 %{
 6243   single_instruction;
 6244   dst    : S5(write);
 6245   src1   : S1(read);
 6246   src2   : S1(read);
 6247   INS01  : ISS;
 6248   NEON_FP : S5;
 6249 %}
 6250 
 6251 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6252 %{
 6253   single_instruction;
 6254   dst    : S5(write);
 6255   src1   : S1(read);
 6256   src2   : S1(read);
 6257   INS0   : ISS;
 6258   NEON_FP : S5;
 6259 %}
 6260 
 6261 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6262 %{
 6263   single_instruction;
 6264   dst    : S5(write);
 6265   src1   : S1(read);
 6266   src2   : S1(read);
 6267   INS0   : ISS;
 6268   NEON_FP : S5;
 6269 %}
 6270 
 6271 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6272 %{
 6273   single_instruction;
 6274   dst    : S5(write);
 6275   src1   : S1(read);
 6276   src2   : S1(read);
 6277   INS0   : ISS;
 6278   NEON_FP : S5;
 6279 %}
 6280 
 6281 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6282 %{
 6283   single_instruction;
 6284   dst    : S5(write);
 6285   src    : S1(read);
 6286   INS0   : ISS;
 6287   NEON_FP : S5;
 6288 %}
 6289 
 6290 pipe_class vunop_fp64(vecD dst, vecD src)
 6291 %{
 6292   single_instruction;
 6293   dst    : S5(write);
 6294   src    : S1(read);
 6295   INS01  : ISS;
 6296   NEON_FP : S5;
 6297 %}
 6298 
 6299 pipe_class vunop_fp128(vecX dst, vecX src)
 6300 %{
 6301   single_instruction;
 6302   dst    : S5(write);
 6303   src    : S1(read);
 6304   INS0   : ISS;
 6305   NEON_FP : S5;
 6306 %}
 6307 
 6308 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6309 %{
 6310   single_instruction;
 6311   dst    : S3(write);
 6312   src    : S1(read);
 6313   INS01  : ISS;
 6314   NEON_FP : S3;
 6315 %}
 6316 
 6317 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6318 %{
 6319   single_instruction;
 6320   dst    : S3(write);
 6321   src    : S1(read);
 6322   INS01  : ISS;
 6323   NEON_FP : S3;
 6324 %}
 6325 
 6326 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6327 %{
 6328   single_instruction;
 6329   dst    : S3(write);
 6330   src    : S1(read);
 6331   INS01  : ISS;
 6332   NEON_FP : S3;
 6333 %}
 6334 
 6335 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6336 %{
 6337   single_instruction;
 6338   dst    : S3(write);
 6339   src    : S1(read);
 6340   INS01  : ISS;
 6341   NEON_FP : S3;
 6342 %}
 6343 
 6344 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6345 %{
 6346   single_instruction;
 6347   dst    : S3(write);
 6348   src    : S1(read);
 6349   INS01  : ISS;
 6350   NEON_FP : S3;
 6351 %}
 6352 
 6353 pipe_class vmovi_reg_imm64(vecD dst)
 6354 %{
 6355   single_instruction;
 6356   dst    : S3(write);
 6357   INS01  : ISS;
 6358   NEON_FP : S3;
 6359 %}
 6360 
 6361 pipe_class vmovi_reg_imm128(vecX dst)
 6362 %{
 6363   single_instruction;
 6364   dst    : S3(write);
 6365   INS0   : ISS;
 6366   NEON_FP : S3;
 6367 %}
 6368 
 6369 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6370 %{
 6371   single_instruction;
 6372   dst    : S5(write);
 6373   mem    : ISS(read);
 6374   INS01  : ISS;
 6375   NEON_FP : S3;
 6376 %}
 6377 
 6378 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6379 %{
 6380   single_instruction;
 6381   dst    : S5(write);
 6382   mem    : ISS(read);
 6383   INS01  : ISS;
 6384   NEON_FP : S3;
 6385 %}
 6386 
 6387 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6388 %{
 6389   single_instruction;
 6390   mem    : ISS(read);
 6391   src    : S2(read);
 6392   INS01  : ISS;
 6393   NEON_FP : S3;
 6394 %}
 6395 
 6396 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6397 %{
 6398   single_instruction;
 6399   mem    : ISS(read);
 6400   src    : S2(read);
 6401   INS01  : ISS;
 6402   NEON_FP : S3;
 6403 %}
 6404 
 6405 //------- Integer ALU operations --------------------------
 6406 
 6407 // Integer ALU reg-reg operation
 6408 // Operands needed in EX1, result generated in EX2
 6409 // Eg.  ADD     x0, x1, x2
 6410 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6411 %{
 6412   single_instruction;
 6413   dst    : EX2(write);
 6414   src1   : EX1(read);
 6415   src2   : EX1(read);
 6416   INS01  : ISS; // Dual issue as instruction 0 or 1
 6417   ALU    : EX2;
 6418 %}
 6419 
 6420 // Integer ALU reg-reg operation with constant shift
 6421 // Shifted register must be available in LATE_ISS instead of EX1
 6422 // Eg.  ADD     x0, x1, x2, LSL #2
 6423 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6424 %{
 6425   single_instruction;
 6426   dst    : EX2(write);
 6427   src1   : EX1(read);
 6428   src2   : ISS(read);
 6429   INS01  : ISS;
 6430   ALU    : EX2;
 6431 %}
 6432 
 6433 // Integer ALU reg operation with constant shift
 6434 // Eg.  LSL     x0, x1, #shift
 6435 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6436 %{
 6437   single_instruction;
 6438   dst    : EX2(write);
 6439   src1   : ISS(read);
 6440   INS01  : ISS;
 6441   ALU    : EX2;
 6442 %}
 6443 
 6444 // Integer ALU reg-reg operation with variable shift
 6445 // Both operands must be available in LATE_ISS instead of EX1
 6446 // Result is available in EX1 instead of EX2
 6447 // Eg.  LSLV    x0, x1, x2
 6448 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6449 %{
 6450   single_instruction;
 6451   dst    : EX1(write);
 6452   src1   : ISS(read);
 6453   src2   : ISS(read);
 6454   INS01  : ISS;
 6455   ALU    : EX1;
 6456 %}
 6457 
 6458 // Integer ALU reg-reg operation with extract
 6459 // As for _vshift above, but result generated in EX2
 6460 // Eg.  EXTR    x0, x1, x2, #N
 6461 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6462 %{
 6463   single_instruction;
 6464   dst    : EX2(write);
 6465   src1   : ISS(read);
 6466   src2   : ISS(read);
 6467   INS1   : ISS; // Can only dual issue as Instruction 1
 6468   ALU    : EX1;
 6469 %}
 6470 
 6471 // Integer ALU reg operation
 6472 // Eg.  NEG     x0, x1
 6473 pipe_class ialu_reg(iRegI dst, iRegI src)
 6474 %{
 6475   single_instruction;
 6476   dst    : EX2(write);
 6477   src    : EX1(read);
 6478   INS01  : ISS;
 6479   ALU    : EX2;
 6480 %}
 6481 
 6482 // Integer ALU reg mmediate operation
 6483 // Eg.  ADD     x0, x1, #N
 6484 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6485 %{
 6486   single_instruction;
 6487   dst    : EX2(write);
 6488   src1   : EX1(read);
 6489   INS01  : ISS;
 6490   ALU    : EX2;
 6491 %}
 6492 
 6493 // Integer ALU immediate operation (no source operands)
 6494 // Eg.  MOV     x0, #N
 6495 pipe_class ialu_imm(iRegI dst)
 6496 %{
 6497   single_instruction;
 6498   dst    : EX1(write);
 6499   INS01  : ISS;
 6500   ALU    : EX1;
 6501 %}
 6502 
 6503 //------- Compare operation -------------------------------
 6504 
 6505 // Compare reg-reg
 6506 // Eg.  CMP     x0, x1
 6507 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6508 %{
 6509   single_instruction;
 6510 //  fixed_latency(16);
 6511   cr     : EX2(write);
 6512   op1    : EX1(read);
 6513   op2    : EX1(read);
 6514   INS01  : ISS;
 6515   ALU    : EX2;
 6516 %}
 6517 
 6518 // Compare reg-reg
 6519 // Eg.  CMP     x0, #N
 6520 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6521 %{
 6522   single_instruction;
 6523 //  fixed_latency(16);
 6524   cr     : EX2(write);
 6525   op1    : EX1(read);
 6526   INS01  : ISS;
 6527   ALU    : EX2;
 6528 %}
 6529 
 6530 //------- Conditional instructions ------------------------
 6531 
 6532 // Conditional no operands
 6533 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6534 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6535 %{
 6536   single_instruction;
 6537   cr     : EX1(read);
 6538   dst    : EX2(write);
 6539   INS01  : ISS;
 6540   ALU    : EX2;
 6541 %}
 6542 
 6543 // Conditional 2 operand
 6544 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6545 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6546 %{
 6547   single_instruction;
 6548   cr     : EX1(read);
 6549   src1   : EX1(read);
 6550   src2   : EX1(read);
 6551   dst    : EX2(write);
 6552   INS01  : ISS;
 6553   ALU    : EX2;
 6554 %}
 6555 
 6556 // Conditional 2 operand
 6557 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6558 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6559 %{
 6560   single_instruction;
 6561   cr     : EX1(read);
 6562   src    : EX1(read);
 6563   dst    : EX2(write);
 6564   INS01  : ISS;
 6565   ALU    : EX2;
 6566 %}
 6567 
 6568 //------- Multiply pipeline operations --------------------
 6569 
 6570 // Multiply reg-reg
 6571 // Eg.  MUL     w0, w1, w2
 6572 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6573 %{
 6574   single_instruction;
 6575   dst    : WR(write);
 6576   src1   : ISS(read);
 6577   src2   : ISS(read);
 6578   INS01  : ISS;
 6579   MAC    : WR;
 6580 %}
 6581 
 6582 // Multiply accumulate
 6583 // Eg.  MADD    w0, w1, w2, w3
 6584 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6585 %{
 6586   single_instruction;
 6587   dst    : WR(write);
 6588   src1   : ISS(read);
 6589   src2   : ISS(read);
 6590   src3   : ISS(read);
 6591   INS01  : ISS;
 6592   MAC    : WR;
 6593 %}
 6594 
 6595 // Eg.  MUL     w0, w1, w2
 6596 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6597 %{
 6598   single_instruction;
 6599   fixed_latency(3); // Maximum latency for 64 bit mul
 6600   dst    : WR(write);
 6601   src1   : ISS(read);
 6602   src2   : ISS(read);
 6603   INS01  : ISS;
 6604   MAC    : WR;
 6605 %}
 6606 
 6607 // Multiply accumulate
 6608 // Eg.  MADD    w0, w1, w2, w3
 6609 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6610 %{
 6611   single_instruction;
 6612   fixed_latency(3); // Maximum latency for 64 bit mul
 6613   dst    : WR(write);
 6614   src1   : ISS(read);
 6615   src2   : ISS(read);
 6616   src3   : ISS(read);
 6617   INS01  : ISS;
 6618   MAC    : WR;
 6619 %}
 6620 
 6621 //------- Divide pipeline operations --------------------
 6622 
 6623 // Eg.  SDIV    w0, w1, w2
 6624 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6625 %{
 6626   single_instruction;
 6627   fixed_latency(8); // Maximum latency for 32 bit divide
 6628   dst    : WR(write);
 6629   src1   : ISS(read);
 6630   src2   : ISS(read);
 6631   INS0   : ISS; // Can only dual issue as instruction 0
 6632   DIV    : WR;
 6633 %}
 6634 
 6635 // Eg.  SDIV    x0, x1, x2
 6636 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6637 %{
 6638   single_instruction;
 6639   fixed_latency(16); // Maximum latency for 64 bit divide
 6640   dst    : WR(write);
 6641   src1   : ISS(read);
 6642   src2   : ISS(read);
 6643   INS0   : ISS; // Can only dual issue as instruction 0
 6644   DIV    : WR;
 6645 %}
 6646 
 6647 //------- Load pipeline operations ------------------------
 6648 
 6649 // Load - prefetch
 6650 // Eg.  PFRM    &lt;mem&gt;
 6651 pipe_class iload_prefetch(memory mem)
 6652 %{
 6653   single_instruction;
 6654   mem    : ISS(read);
 6655   INS01  : ISS;
 6656   LDST   : WR;
 6657 %}
 6658 
 6659 // Load - reg, mem
 6660 // Eg.  LDR     x0, &lt;mem&gt;
 6661 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6662 %{
 6663   single_instruction;
 6664   dst    : WR(write);
 6665   mem    : ISS(read);
 6666   INS01  : ISS;
 6667   LDST   : WR;
 6668 %}
 6669 
 6670 // Load - reg, reg
 6671 // Eg.  LDR     x0, [sp, x1]
 6672 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6673 %{
 6674   single_instruction;
 6675   dst    : WR(write);
 6676   src    : ISS(read);
 6677   INS01  : ISS;
 6678   LDST   : WR;
 6679 %}
 6680 
 6681 //------- Store pipeline operations -----------------------
 6682 
 6683 // Store - zr, mem
 6684 // Eg.  STR     zr, &lt;mem&gt;
 6685 pipe_class istore_mem(memory mem)
 6686 %{
 6687   single_instruction;
 6688   mem    : ISS(read);
 6689   INS01  : ISS;
 6690   LDST   : WR;
 6691 %}
 6692 
 6693 // Store - reg, mem
 6694 // Eg.  STR     x0, &lt;mem&gt;
 6695 pipe_class istore_reg_mem(iRegI src, memory mem)
 6696 %{
 6697   single_instruction;
 6698   mem    : ISS(read);
 6699   src    : EX2(read);
 6700   INS01  : ISS;
 6701   LDST   : WR;
 6702 %}
 6703 
 6704 // Store - reg, reg
 6705 // Eg. STR      x0, [sp, x1]
 6706 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6707 %{
 6708   single_instruction;
 6709   dst    : ISS(read);
 6710   src    : EX2(read);
 6711   INS01  : ISS;
 6712   LDST   : WR;
 6713 %}
 6714 
 6715 //------- Store pipeline operations -----------------------
 6716 
 6717 // Branch
 6718 pipe_class pipe_branch()
 6719 %{
 6720   single_instruction;
 6721   INS01  : ISS;
 6722   BRANCH : EX1;
 6723 %}
 6724 
 6725 // Conditional branch
 6726 pipe_class pipe_branch_cond(rFlagsReg cr)
 6727 %{
 6728   single_instruction;
 6729   cr     : EX1(read);
 6730   INS01  : ISS;
 6731   BRANCH : EX1;
 6732 %}
 6733 
 6734 // Compare &amp; Branch
 6735 // EG.  CBZ/CBNZ
 6736 pipe_class pipe_cmp_branch(iRegI op1)
 6737 %{
 6738   single_instruction;
 6739   op1    : EX1(read);
 6740   INS01  : ISS;
 6741   BRANCH : EX1;
 6742 %}
 6743 
 6744 //------- Synchronisation operations ----------------------
 6745 
 6746 // Any operation requiring serialization.
 6747 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6748 pipe_class pipe_serial()
 6749 %{
 6750   single_instruction;
 6751   force_serialization;
 6752   fixed_latency(16);
 6753   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6754   LDST   : WR;
 6755 %}
 6756 
 6757 // Generic big/slow expanded idiom - also serialized
 6758 pipe_class pipe_slow()
 6759 %{
 6760   instruction_count(10);
 6761   multiple_bundles;
 6762   force_serialization;
 6763   fixed_latency(16);
 6764   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6765   LDST   : WR;
 6766 %}
 6767 
 6768 // Empty pipeline class
 6769 pipe_class pipe_class_empty()
 6770 %{
 6771   single_instruction;
 6772   fixed_latency(0);
 6773 %}
 6774 
 6775 // Default pipeline class.
 6776 pipe_class pipe_class_default()
 6777 %{
 6778   single_instruction;
 6779   fixed_latency(2);
 6780 %}
 6781 
 6782 // Pipeline class for compares.
 6783 pipe_class pipe_class_compare()
 6784 %{
 6785   single_instruction;
 6786   fixed_latency(16);
 6787 %}
 6788 
 6789 // Pipeline class for memory operations.
 6790 pipe_class pipe_class_memory()
 6791 %{
 6792   single_instruction;
 6793   fixed_latency(16);
 6794 %}
 6795 
 6796 // Pipeline class for call.
 6797 pipe_class pipe_class_call()
 6798 %{
 6799   single_instruction;
 6800   fixed_latency(100);
 6801 %}
 6802 
 6803 // Define the class for the Nop node.
 6804 define %{
 6805    MachNop = pipe_class_empty;
 6806 %}
 6807 
 6808 %}
 6809 //----------INSTRUCTIONS-------------------------------------------------------
 6810 //
 6811 // match      -- States which machine-independent subtree may be replaced
 6812 //               by this instruction.
 6813 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6814 //               selection to identify a minimum cost tree of machine
 6815 //               instructions that matches a tree of machine-independent
 6816 //               instructions.
 6817 // format     -- A string providing the disassembly for this instruction.
 6818 //               The value of an instruction&#39;s operand may be inserted
 6819 //               by referring to it with a &#39;$&#39; prefix.
 6820 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6821 //               to within an encode class as $primary, $secondary, and $tertiary
 6822 //               rrspectively.  The primary opcode is commonly used to
 6823 //               indicate the type of machine instruction, while secondary
 6824 //               and tertiary are often used for prefix options or addressing
 6825 //               modes.
 6826 // ins_encode -- A list of encode classes with parameters. The encode class
 6827 //               name must have been defined in an &#39;enc_class&#39; specification
 6828 //               in the encode section of the architecture description.
 6829 
 6830 // ============================================================================
 6831 // Memory (Load/Store) Instructions
 6832 
 6833 // Load Instructions
 6834 
 6835 // Load Byte (8 bit signed)
 6836 instruct loadB(iRegINoSp dst, memory1 mem)
 6837 %{
 6838   match(Set dst (LoadB mem));
 6839   predicate(!needs_acquiring_load(n));
 6840 
 6841   ins_cost(4 * INSN_COST);
 6842   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6843 
 6844   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6845 
 6846   ins_pipe(iload_reg_mem);
 6847 %}
 6848 
 6849 // Load Byte (8 bit signed) into long
 6850 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6851 %{
 6852   match(Set dst (ConvI2L (LoadB mem)));
 6853   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6854 
 6855   ins_cost(4 * INSN_COST);
 6856   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6857 
 6858   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6859 
 6860   ins_pipe(iload_reg_mem);
 6861 %}
 6862 
 6863 // Load Byte (8 bit unsigned)
 6864 instruct loadUB(iRegINoSp dst, memory1 mem)
 6865 %{
 6866   match(Set dst (LoadUB mem));
 6867   predicate(!needs_acquiring_load(n));
 6868 
 6869   ins_cost(4 * INSN_COST);
 6870   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6871 
 6872   ins_encode(aarch64_enc_ldrb(dst, mem));
 6873 
 6874   ins_pipe(iload_reg_mem);
 6875 %}
 6876 
 6877 // Load Byte (8 bit unsigned) into long
 6878 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6879 %{
 6880   match(Set dst (ConvI2L (LoadUB mem)));
 6881   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6882 
 6883   ins_cost(4 * INSN_COST);
 6884   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6885 
 6886   ins_encode(aarch64_enc_ldrb(dst, mem));
 6887 
 6888   ins_pipe(iload_reg_mem);
 6889 %}
 6890 
 6891 // Load Short (16 bit signed)
 6892 instruct loadS(iRegINoSp dst, memory2 mem)
 6893 %{
 6894   match(Set dst (LoadS mem));
 6895   predicate(!needs_acquiring_load(n));
 6896 
 6897   ins_cost(4 * INSN_COST);
 6898   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6899 
 6900   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6901 
 6902   ins_pipe(iload_reg_mem);
 6903 %}
 6904 
 6905 // Load Short (16 bit signed) into long
 6906 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6907 %{
 6908   match(Set dst (ConvI2L (LoadS mem)));
 6909   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6910 
 6911   ins_cost(4 * INSN_COST);
 6912   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6913 
 6914   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6915 
 6916   ins_pipe(iload_reg_mem);
 6917 %}
 6918 
 6919 // Load Char (16 bit unsigned)
 6920 instruct loadUS(iRegINoSp dst, memory2 mem)
 6921 %{
 6922   match(Set dst (LoadUS mem));
 6923   predicate(!needs_acquiring_load(n));
 6924 
 6925   ins_cost(4 * INSN_COST);
 6926   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6927 
 6928   ins_encode(aarch64_enc_ldrh(dst, mem));
 6929 
 6930   ins_pipe(iload_reg_mem);
 6931 %}
 6932 
 6933 // Load Short/Char (16 bit unsigned) into long
 6934 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6935 %{
 6936   match(Set dst (ConvI2L (LoadUS mem)));
 6937   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6938 
 6939   ins_cost(4 * INSN_COST);
 6940   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6941 
 6942   ins_encode(aarch64_enc_ldrh(dst, mem));
 6943 
 6944   ins_pipe(iload_reg_mem);
 6945 %}
 6946 
 6947 // Load Integer (32 bit signed)
 6948 instruct loadI(iRegINoSp dst, memory4 mem)
 6949 %{
 6950   match(Set dst (LoadI mem));
 6951   predicate(!needs_acquiring_load(n));
 6952 
 6953   ins_cost(4 * INSN_COST);
 6954   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6955 
 6956   ins_encode(aarch64_enc_ldrw(dst, mem));
 6957 
 6958   ins_pipe(iload_reg_mem);
 6959 %}
 6960 
 6961 // Load Integer (32 bit signed) into long
 6962 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6963 %{
 6964   match(Set dst (ConvI2L (LoadI mem)));
 6965   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6966 
 6967   ins_cost(4 * INSN_COST);
 6968   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6969 
 6970   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6971 
 6972   ins_pipe(iload_reg_mem);
 6973 %}
 6974 
 6975 // Load Integer (32 bit unsigned) into long
 6976 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6977 %{
 6978   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6979   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6980 
 6981   ins_cost(4 * INSN_COST);
 6982   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6983 
 6984   ins_encode(aarch64_enc_ldrw(dst, mem));
 6985 
 6986   ins_pipe(iload_reg_mem);
 6987 %}
 6988 
 6989 // Load Long (64 bit signed)
 6990 instruct loadL(iRegLNoSp dst, memory8 mem)
 6991 %{
 6992   match(Set dst (LoadL mem));
 6993   predicate(!needs_acquiring_load(n));
 6994 
 6995   ins_cost(4 * INSN_COST);
 6996   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 6997 
 6998   ins_encode(aarch64_enc_ldr(dst, mem));
 6999 
 7000   ins_pipe(iload_reg_mem);
 7001 %}
 7002 
 7003 // Load Range
 7004 instruct loadRange(iRegINoSp dst, memory4 mem)
 7005 %{
 7006   match(Set dst (LoadRange mem));
 7007 
 7008   ins_cost(4 * INSN_COST);
 7009   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7010 
 7011   ins_encode(aarch64_enc_ldrw(dst, mem));
 7012 
 7013   ins_pipe(iload_reg_mem);
 7014 %}
 7015 
 7016 // Load Pointer
 7017 instruct loadP(iRegPNoSp dst, memory8 mem)
 7018 %{
 7019   match(Set dst (LoadP mem));
 7020   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7021 
 7022   ins_cost(4 * INSN_COST);
 7023   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7024 
 7025   ins_encode(aarch64_enc_ldr(dst, mem));
 7026 
 7027   ins_pipe(iload_reg_mem);
 7028 %}
 7029 
 7030 // Load Compressed Pointer
 7031 instruct loadN(iRegNNoSp dst, memory4 mem)
 7032 %{
 7033   match(Set dst (LoadN mem));
 7034   predicate(!needs_acquiring_load(n));
 7035 
 7036   ins_cost(4 * INSN_COST);
 7037   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7038 
 7039   ins_encode(aarch64_enc_ldrw(dst, mem));
 7040 
 7041   ins_pipe(iload_reg_mem);
 7042 %}
 7043 
 7044 // Load Klass Pointer
 7045 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7046 %{
 7047   match(Set dst (LoadKlass mem));
 7048   predicate(!needs_acquiring_load(n));
 7049 
 7050   ins_cost(4 * INSN_COST);
 7051   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7052 
 7053   ins_encode(aarch64_enc_ldr(dst, mem));
 7054 
 7055   ins_pipe(iload_reg_mem);
 7056 %}
 7057 
 7058 // Load Narrow Klass Pointer
 7059 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7060 %{
 7061   match(Set dst (LoadNKlass mem));
 7062   predicate(!needs_acquiring_load(n));
 7063 
 7064   ins_cost(4 * INSN_COST);
 7065   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7066 
 7067   ins_encode(aarch64_enc_ldrw(dst, mem));
 7068 
 7069   ins_pipe(iload_reg_mem);
 7070 %}
 7071 
 7072 // Load Float
 7073 instruct loadF(vRegF dst, memory4 mem)
 7074 %{
 7075   match(Set dst (LoadF mem));
 7076   predicate(!needs_acquiring_load(n));
 7077 
 7078   ins_cost(4 * INSN_COST);
 7079   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7080 
 7081   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7082 
 7083   ins_pipe(pipe_class_memory);
 7084 %}
 7085 
 7086 // Load Double
 7087 instruct loadD(vRegD dst, memory8 mem)
 7088 %{
 7089   match(Set dst (LoadD mem));
 7090   predicate(!needs_acquiring_load(n));
 7091 
 7092   ins_cost(4 * INSN_COST);
 7093   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7094 
 7095   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7096 
 7097   ins_pipe(pipe_class_memory);
 7098 %}
 7099 
 7100 
 7101 // Load Int Constant
 7102 instruct loadConI(iRegINoSp dst, immI src)
 7103 %{
 7104   match(Set dst src);
 7105 
 7106   ins_cost(INSN_COST);
 7107   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7108 
 7109   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7110 
 7111   ins_pipe(ialu_imm);
 7112 %}
 7113 
 7114 // Load Long Constant
 7115 instruct loadConL(iRegLNoSp dst, immL src)
 7116 %{
 7117   match(Set dst src);
 7118 
 7119   ins_cost(INSN_COST);
 7120   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7121 
 7122   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7123 
 7124   ins_pipe(ialu_imm);
 7125 %}
 7126 
 7127 // Load Pointer Constant
 7128 
 7129 instruct loadConP(iRegPNoSp dst, immP con)
 7130 %{
 7131   match(Set dst con);
 7132 
 7133   ins_cost(INSN_COST * 4);
 7134   format %{
 7135     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7136   %}
 7137 
 7138   ins_encode(aarch64_enc_mov_p(dst, con));
 7139 
 7140   ins_pipe(ialu_imm);
 7141 %}
 7142 
 7143 // Load Null Pointer Constant
 7144 
 7145 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7146 %{
 7147   match(Set dst con);
 7148 
 7149   ins_cost(INSN_COST);
 7150   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7151 
 7152   ins_encode(aarch64_enc_mov_p0(dst, con));
 7153 
 7154   ins_pipe(ialu_imm);
 7155 %}
 7156 
 7157 // Load Pointer Constant One
 7158 
 7159 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7160 %{
 7161   match(Set dst con);
 7162 
 7163   ins_cost(INSN_COST);
 7164   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7165 
 7166   ins_encode(aarch64_enc_mov_p1(dst, con));
 7167 
 7168   ins_pipe(ialu_imm);
 7169 %}
 7170 
 7171 // Load Byte Map Base Constant
 7172 
 7173 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7174 %{
 7175   match(Set dst con);
 7176 
 7177   ins_cost(INSN_COST);
 7178   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7179 
 7180   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7181 
 7182   ins_pipe(ialu_imm);
 7183 %}
 7184 
 7185 // Load Narrow Pointer Constant
 7186 
 7187 instruct loadConN(iRegNNoSp dst, immN con)
 7188 %{
 7189   match(Set dst con);
 7190 
 7191   ins_cost(INSN_COST * 4);
 7192   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7193 
 7194   ins_encode(aarch64_enc_mov_n(dst, con));
 7195 
 7196   ins_pipe(ialu_imm);
 7197 %}
 7198 
 7199 // Load Narrow Null Pointer Constant
 7200 
 7201 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7202 %{
 7203   match(Set dst con);
 7204 
 7205   ins_cost(INSN_COST);
 7206   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7207 
 7208   ins_encode(aarch64_enc_mov_n0(dst, con));
 7209 
 7210   ins_pipe(ialu_imm);
 7211 %}
 7212 
 7213 // Load Narrow Klass Constant
 7214 
 7215 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7216 %{
 7217   match(Set dst con);
 7218 
 7219   ins_cost(INSN_COST);
 7220   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7221 
 7222   ins_encode(aarch64_enc_mov_nk(dst, con));
 7223 
 7224   ins_pipe(ialu_imm);
 7225 %}
 7226 
 7227 // Load Packed Float Constant
 7228 
 7229 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7230   match(Set dst con);
 7231   ins_cost(INSN_COST * 4);
 7232   format %{ &quot;fmovs  $dst, $con&quot;%}
 7233   ins_encode %{
 7234     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7235   %}
 7236 
 7237   ins_pipe(fp_imm_s);
 7238 %}
 7239 
 7240 // Load Float Constant
 7241 
 7242 instruct loadConF(vRegF dst, immF con) %{
 7243   match(Set dst con);
 7244 
 7245   ins_cost(INSN_COST * 4);
 7246 
 7247   format %{
 7248     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7249   %}
 7250 
 7251   ins_encode %{
 7252     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7253   %}
 7254 
 7255   ins_pipe(fp_load_constant_s);
 7256 %}
 7257 
 7258 // Load Packed Double Constant
 7259 
 7260 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7261   match(Set dst con);
 7262   ins_cost(INSN_COST);
 7263   format %{ &quot;fmovd  $dst, $con&quot;%}
 7264   ins_encode %{
 7265     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7266   %}
 7267 
 7268   ins_pipe(fp_imm_d);
 7269 %}
 7270 
 7271 // Load Double Constant
 7272 
 7273 instruct loadConD(vRegD dst, immD con) %{
 7274   match(Set dst con);
 7275 
 7276   ins_cost(INSN_COST * 5);
 7277   format %{
 7278     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7279   %}
 7280 
 7281   ins_encode %{
 7282     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7283   %}
 7284 
 7285   ins_pipe(fp_load_constant_d);
 7286 %}
 7287 
 7288 // Store Instructions
 7289 
 7290 // Store CMS card-mark Immediate
 7291 instruct storeimmCM0(immI0 zero, memory1 mem)
 7292 %{
 7293   match(Set mem (StoreCM mem zero));
 7294 
 7295   ins_cost(INSN_COST);
 7296   format %{ &quot;storestore (elided)\n\t&quot;
 7297             &quot;strb zr, $mem\t# byte&quot; %}
 7298 
 7299   ins_encode(aarch64_enc_strb0(mem));
 7300 
 7301   ins_pipe(istore_mem);
 7302 %}
 7303 
 7304 // Store CMS card-mark Immediate with intervening StoreStore
 7305 // needed when using CMS with no conditional card marking
 7306 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7307 %{
 7308   match(Set mem (StoreCM mem zero));
 7309 
 7310   ins_cost(INSN_COST * 2);
 7311   format %{ &quot;storestore\n\t&quot;
 7312             &quot;dmb ishst&quot;
 7313             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7314 
 7315   ins_encode(aarch64_enc_strb0_ordered(mem));
 7316 
 7317   ins_pipe(istore_mem);
 7318 %}
 7319 
 7320 // Store Byte
 7321 instruct storeB(iRegIorL2I src, memory1 mem)
 7322 %{
 7323   match(Set mem (StoreB mem src));
 7324   predicate(!needs_releasing_store(n));
 7325 
 7326   ins_cost(INSN_COST);
 7327   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7328 
 7329   ins_encode(aarch64_enc_strb(src, mem));
 7330 
 7331   ins_pipe(istore_reg_mem);
 7332 %}
 7333 
 7334 
 7335 instruct storeimmB0(immI0 zero, memory1 mem)
 7336 %{
 7337   match(Set mem (StoreB mem zero));
 7338   predicate(!needs_releasing_store(n));
 7339 
 7340   ins_cost(INSN_COST);
 7341   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7342 
 7343   ins_encode(aarch64_enc_strb0(mem));
 7344 
 7345   ins_pipe(istore_mem);
 7346 %}
 7347 
 7348 // Store Char/Short
 7349 instruct storeC(iRegIorL2I src, memory2 mem)
 7350 %{
 7351   match(Set mem (StoreC mem src));
 7352   predicate(!needs_releasing_store(n));
 7353 
 7354   ins_cost(INSN_COST);
 7355   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7356 
 7357   ins_encode(aarch64_enc_strh(src, mem));
 7358 
 7359   ins_pipe(istore_reg_mem);
 7360 %}
 7361 
 7362 instruct storeimmC0(immI0 zero, memory2 mem)
 7363 %{
 7364   match(Set mem (StoreC mem zero));
 7365   predicate(!needs_releasing_store(n));
 7366 
 7367   ins_cost(INSN_COST);
 7368   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7369 
 7370   ins_encode(aarch64_enc_strh0(mem));
 7371 
 7372   ins_pipe(istore_mem);
 7373 %}
 7374 
 7375 // Store Integer
 7376 
 7377 instruct storeI(iRegIorL2I src, memory4 mem)
 7378 %{
 7379   match(Set mem(StoreI mem src));
 7380   predicate(!needs_releasing_store(n));
 7381 
 7382   ins_cost(INSN_COST);
 7383   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7384 
 7385   ins_encode(aarch64_enc_strw(src, mem));
 7386 
 7387   ins_pipe(istore_reg_mem);
 7388 %}
 7389 
 7390 instruct storeimmI0(immI0 zero, memory4 mem)
 7391 %{
 7392   match(Set mem(StoreI mem zero));
 7393   predicate(!needs_releasing_store(n));
 7394 
 7395   ins_cost(INSN_COST);
 7396   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7397 
 7398   ins_encode(aarch64_enc_strw0(mem));
 7399 
 7400   ins_pipe(istore_mem);
 7401 %}
 7402 
 7403 // Store Long (64 bit signed)
 7404 instruct storeL(iRegL src, memory8 mem)
 7405 %{
 7406   match(Set mem (StoreL mem src));
 7407   predicate(!needs_releasing_store(n));
 7408 
 7409   ins_cost(INSN_COST);
 7410   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7411 
 7412   ins_encode(aarch64_enc_str(src, mem));
 7413 
 7414   ins_pipe(istore_reg_mem);
 7415 %}
 7416 
 7417 // Store Long (64 bit signed)
 7418 instruct storeimmL0(immL0 zero, memory8 mem)
 7419 %{
 7420   match(Set mem (StoreL mem zero));
 7421   predicate(!needs_releasing_store(n));
 7422 
 7423   ins_cost(INSN_COST);
 7424   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7425 
 7426   ins_encode(aarch64_enc_str0(mem));
 7427 
 7428   ins_pipe(istore_mem);
 7429 %}
 7430 
 7431 // Store Pointer
 7432 instruct storeP(iRegP src, memory8 mem)
 7433 %{
 7434   match(Set mem (StoreP mem src));
 7435   predicate(!needs_releasing_store(n));
 7436 
 7437   ins_cost(INSN_COST);
 7438   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7439 
 7440   ins_encode(aarch64_enc_str(src, mem));
 7441 
 7442   ins_pipe(istore_reg_mem);
 7443 %}
 7444 
 7445 // Store Pointer
 7446 instruct storeimmP0(immP0 zero, memory8 mem)
 7447 %{
 7448   match(Set mem (StoreP mem zero));
 7449   predicate(!needs_releasing_store(n));
 7450 
 7451   ins_cost(INSN_COST);
 7452   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7453 
 7454   ins_encode(aarch64_enc_str0(mem));
 7455 
 7456   ins_pipe(istore_mem);
 7457 %}
 7458 
 7459 // Store Compressed Pointer
 7460 instruct storeN(iRegN src, memory4 mem)
 7461 %{
 7462   match(Set mem (StoreN mem src));
 7463   predicate(!needs_releasing_store(n));
 7464 
 7465   ins_cost(INSN_COST);
 7466   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7467 
 7468   ins_encode(aarch64_enc_strw(src, mem));
 7469 
 7470   ins_pipe(istore_reg_mem);
 7471 %}
 7472 
 7473 instruct storeImmN0(immN0 zero, memory4 mem)
 7474 %{
 7475   match(Set mem (StoreN mem zero));
 7476   predicate(!needs_releasing_store(n));
 7477 
 7478   ins_cost(INSN_COST);
 7479   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7480 
 7481   ins_encode(aarch64_enc_strw0(mem));
 7482 
 7483   ins_pipe(istore_mem);
 7484 %}
 7485 
 7486 // Store Float
 7487 instruct storeF(vRegF src, memory4 mem)
 7488 %{
 7489   match(Set mem (StoreF mem src));
 7490   predicate(!needs_releasing_store(n));
 7491 
 7492   ins_cost(INSN_COST);
 7493   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7494 
 7495   ins_encode( aarch64_enc_strs(src, mem) );
 7496 
 7497   ins_pipe(pipe_class_memory);
 7498 %}
 7499 
 7500 // TODO
 7501 // implement storeImmF0 and storeFImmPacked
 7502 
 7503 // Store Double
 7504 instruct storeD(vRegD src, memory8 mem)
 7505 %{
 7506   match(Set mem (StoreD mem src));
 7507   predicate(!needs_releasing_store(n));
 7508 
 7509   ins_cost(INSN_COST);
 7510   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7511 
 7512   ins_encode( aarch64_enc_strd(src, mem) );
 7513 
 7514   ins_pipe(pipe_class_memory);
 7515 %}
 7516 
 7517 // Store Compressed Klass Pointer
 7518 instruct storeNKlass(iRegN src, memory4 mem)
 7519 %{
 7520   predicate(!needs_releasing_store(n));
 7521   match(Set mem (StoreNKlass mem src));
 7522 
 7523   ins_cost(INSN_COST);
 7524   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7525 
 7526   ins_encode(aarch64_enc_strw(src, mem));
 7527 
 7528   ins_pipe(istore_reg_mem);
 7529 %}
 7530 
 7531 // TODO
 7532 // implement storeImmD0 and storeDImmPacked
 7533 
 7534 // prefetch instructions
 7535 // Must be safe to execute with invalid address (cannot fault).
 7536 
 7537 instruct prefetchalloc( memory8 mem ) %{
 7538   match(PrefetchAllocation mem);
 7539 
 7540   ins_cost(INSN_COST);
 7541   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7542 
 7543   ins_encode( aarch64_enc_prefetchw(mem) );
 7544 
 7545   ins_pipe(iload_prefetch);
 7546 %}
 7547 
 7548 //  ---------------- volatile loads and stores ----------------
 7549 
 7550 // Load Byte (8 bit signed)
 7551 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7552 %{
 7553   match(Set dst (LoadB mem));
 7554 
 7555   ins_cost(VOLATILE_REF_COST);
 7556   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7557 
 7558   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7559 
 7560   ins_pipe(pipe_serial);
 7561 %}
 7562 
 7563 // Load Byte (8 bit signed) into long
 7564 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7565 %{
 7566   match(Set dst (ConvI2L (LoadB mem)));
 7567 
 7568   ins_cost(VOLATILE_REF_COST);
 7569   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7570 
 7571   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7572 
 7573   ins_pipe(pipe_serial);
 7574 %}
 7575 
 7576 // Load Byte (8 bit unsigned)
 7577 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7578 %{
 7579   match(Set dst (LoadUB mem));
 7580 
 7581   ins_cost(VOLATILE_REF_COST);
 7582   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7583 
 7584   ins_encode(aarch64_enc_ldarb(dst, mem));
 7585 
 7586   ins_pipe(pipe_serial);
 7587 %}
 7588 
 7589 // Load Byte (8 bit unsigned) into long
 7590 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7591 %{
 7592   match(Set dst (ConvI2L (LoadUB mem)));
 7593 
 7594   ins_cost(VOLATILE_REF_COST);
 7595   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7596 
 7597   ins_encode(aarch64_enc_ldarb(dst, mem));
 7598 
 7599   ins_pipe(pipe_serial);
 7600 %}
 7601 
 7602 // Load Short (16 bit signed)
 7603 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7604 %{
 7605   match(Set dst (LoadS mem));
 7606 
 7607   ins_cost(VOLATILE_REF_COST);
 7608   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7609 
 7610   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7611 
 7612   ins_pipe(pipe_serial);
 7613 %}
 7614 
 7615 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7616 %{
 7617   match(Set dst (LoadUS mem));
 7618 
 7619   ins_cost(VOLATILE_REF_COST);
 7620   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7621 
 7622   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7623 
 7624   ins_pipe(pipe_serial);
 7625 %}
 7626 
 7627 // Load Short/Char (16 bit unsigned) into long
 7628 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7629 %{
 7630   match(Set dst (ConvI2L (LoadUS mem)));
 7631 
 7632   ins_cost(VOLATILE_REF_COST);
 7633   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7634 
 7635   ins_encode(aarch64_enc_ldarh(dst, mem));
 7636 
 7637   ins_pipe(pipe_serial);
 7638 %}
 7639 
 7640 // Load Short/Char (16 bit signed) into long
 7641 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7642 %{
 7643   match(Set dst (ConvI2L (LoadS mem)));
 7644 
 7645   ins_cost(VOLATILE_REF_COST);
 7646   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7647 
 7648   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7649 
 7650   ins_pipe(pipe_serial);
 7651 %}
 7652 
 7653 // Load Integer (32 bit signed)
 7654 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7655 %{
 7656   match(Set dst (LoadI mem));
 7657 
 7658   ins_cost(VOLATILE_REF_COST);
 7659   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7660 
 7661   ins_encode(aarch64_enc_ldarw(dst, mem));
 7662 
 7663   ins_pipe(pipe_serial);
 7664 %}
 7665 
 7666 // Load Integer (32 bit unsigned) into long
 7667 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7668 %{
 7669   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7670 
 7671   ins_cost(VOLATILE_REF_COST);
 7672   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7673 
 7674   ins_encode(aarch64_enc_ldarw(dst, mem));
 7675 
 7676   ins_pipe(pipe_serial);
 7677 %}
 7678 
 7679 // Load Long (64 bit signed)
 7680 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7681 %{
 7682   match(Set dst (LoadL mem));
 7683 
 7684   ins_cost(VOLATILE_REF_COST);
 7685   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7686 
 7687   ins_encode(aarch64_enc_ldar(dst, mem));
 7688 
 7689   ins_pipe(pipe_serial);
 7690 %}
 7691 
 7692 // Load Pointer
 7693 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7694 %{
 7695   match(Set dst (LoadP mem));
 7696   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7697 
 7698   ins_cost(VOLATILE_REF_COST);
 7699   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7700 
 7701   ins_encode(aarch64_enc_ldar(dst, mem));
 7702 
 7703   ins_pipe(pipe_serial);
 7704 %}
 7705 
 7706 // Load Compressed Pointer
 7707 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7708 %{
 7709   match(Set dst (LoadN mem));
 7710 
 7711   ins_cost(VOLATILE_REF_COST);
 7712   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7713 
 7714   ins_encode(aarch64_enc_ldarw(dst, mem));
 7715 
 7716   ins_pipe(pipe_serial);
 7717 %}
 7718 
 7719 // Load Float
 7720 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7721 %{
 7722   match(Set dst (LoadF mem));
 7723 
 7724   ins_cost(VOLATILE_REF_COST);
 7725   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7726 
 7727   ins_encode( aarch64_enc_fldars(dst, mem) );
 7728 
 7729   ins_pipe(pipe_serial);
 7730 %}
 7731 
 7732 // Load Double
 7733 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7734 %{
 7735   match(Set dst (LoadD mem));
 7736 
 7737   ins_cost(VOLATILE_REF_COST);
 7738   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7739 
 7740   ins_encode( aarch64_enc_fldard(dst, mem) );
 7741 
 7742   ins_pipe(pipe_serial);
 7743 %}
 7744 
 7745 // Store Byte
 7746 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7747 %{
 7748   match(Set mem (StoreB mem src));
 7749 
 7750   ins_cost(VOLATILE_REF_COST);
 7751   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7752 
 7753   ins_encode(aarch64_enc_stlrb(src, mem));
 7754 
 7755   ins_pipe(pipe_class_memory);
 7756 %}
 7757 
 7758 // Store Char/Short
 7759 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7760 %{
 7761   match(Set mem (StoreC mem src));
 7762 
 7763   ins_cost(VOLATILE_REF_COST);
 7764   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7765 
 7766   ins_encode(aarch64_enc_stlrh(src, mem));
 7767 
 7768   ins_pipe(pipe_class_memory);
 7769 %}
 7770 
 7771 // Store Integer
 7772 
 7773 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7774 %{
 7775   match(Set mem(StoreI mem src));
 7776 
 7777   ins_cost(VOLATILE_REF_COST);
 7778   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7779 
 7780   ins_encode(aarch64_enc_stlrw(src, mem));
 7781 
 7782   ins_pipe(pipe_class_memory);
 7783 %}
 7784 
 7785 // Store Long (64 bit signed)
 7786 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7787 %{
 7788   match(Set mem (StoreL mem src));
 7789 
 7790   ins_cost(VOLATILE_REF_COST);
 7791   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7792 
 7793   ins_encode(aarch64_enc_stlr(src, mem));
 7794 
 7795   ins_pipe(pipe_class_memory);
 7796 %}
 7797 
 7798 // Store Pointer
 7799 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7800 %{
 7801   match(Set mem (StoreP mem src));
 7802 
 7803   ins_cost(VOLATILE_REF_COST);
 7804   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7805 
 7806   ins_encode(aarch64_enc_stlr(src, mem));
 7807 
 7808   ins_pipe(pipe_class_memory);
 7809 %}
 7810 
 7811 // Store Compressed Pointer
 7812 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7813 %{
 7814   match(Set mem (StoreN mem src));
 7815 
 7816   ins_cost(VOLATILE_REF_COST);
 7817   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7818 
 7819   ins_encode(aarch64_enc_stlrw(src, mem));
 7820 
 7821   ins_pipe(pipe_class_memory);
 7822 %}
 7823 
 7824 // Store Float
 7825 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7826 %{
 7827   match(Set mem (StoreF mem src));
 7828 
 7829   ins_cost(VOLATILE_REF_COST);
 7830   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7831 
 7832   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7833 
 7834   ins_pipe(pipe_class_memory);
 7835 %}
 7836 
 7837 // TODO
 7838 // implement storeImmF0 and storeFImmPacked
 7839 
 7840 // Store Double
 7841 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7842 %{
 7843   match(Set mem (StoreD mem src));
 7844 
 7845   ins_cost(VOLATILE_REF_COST);
 7846   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7847 
 7848   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7849 
 7850   ins_pipe(pipe_class_memory);
 7851 %}
 7852 
 7853 //  ---------------- end of volatile loads and stores ----------------
 7854 
 7855 instruct cacheWB(indirect addr)
 7856 %{
 7857   predicate(VM_Version::supports_data_cache_line_flush());
 7858   match(CacheWB addr);
 7859 
 7860   ins_cost(100);
 7861   format %{&quot;cache wb $addr&quot; %}
 7862   ins_encode %{
 7863     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7864     assert($addr$$disp == 0, &quot;should be&quot;);
 7865     __ cache_wb(Address($addr$$base$$Register, 0));
 7866   %}
 7867   ins_pipe(pipe_slow); // XXX
 7868 %}
 7869 
 7870 instruct cacheWBPreSync()
 7871 %{
 7872   predicate(VM_Version::supports_data_cache_line_flush());
 7873   match(CacheWBPreSync);
 7874 
 7875   ins_cost(100);
 7876   format %{&quot;cache wb presync&quot; %}
 7877   ins_encode %{
 7878     __ cache_wbsync(true);
 7879   %}
 7880   ins_pipe(pipe_slow); // XXX
 7881 %}
 7882 
 7883 instruct cacheWBPostSync()
 7884 %{
 7885   predicate(VM_Version::supports_data_cache_line_flush());
 7886   match(CacheWBPostSync);
 7887 
 7888   ins_cost(100);
 7889   format %{&quot;cache wb postsync&quot; %}
 7890   ins_encode %{
 7891     __ cache_wbsync(false);
 7892   %}
 7893   ins_pipe(pipe_slow); // XXX
 7894 %}
 7895 
 7896 // ============================================================================
 7897 // BSWAP Instructions
 7898 
 7899 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7900   match(Set dst (ReverseBytesI src));
 7901 
 7902   ins_cost(INSN_COST);
 7903   format %{ &quot;revw  $dst, $src&quot; %}
 7904 
 7905   ins_encode %{
 7906     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7907   %}
 7908 
 7909   ins_pipe(ialu_reg);
 7910 %}
 7911 
 7912 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7913   match(Set dst (ReverseBytesL src));
 7914 
 7915   ins_cost(INSN_COST);
 7916   format %{ &quot;rev  $dst, $src&quot; %}
 7917 
 7918   ins_encode %{
 7919     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7920   %}
 7921 
 7922   ins_pipe(ialu_reg);
 7923 %}
 7924 
 7925 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7926   match(Set dst (ReverseBytesUS src));
 7927 
 7928   ins_cost(INSN_COST);
 7929   format %{ &quot;rev16w  $dst, $src&quot; %}
 7930 
 7931   ins_encode %{
 7932     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7933   %}
 7934 
 7935   ins_pipe(ialu_reg);
 7936 %}
 7937 
 7938 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7939   match(Set dst (ReverseBytesS src));
 7940 
 7941   ins_cost(INSN_COST);
 7942   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7943             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7944 
 7945   ins_encode %{
 7946     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7947     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7948   %}
 7949 
 7950   ins_pipe(ialu_reg);
 7951 %}
 7952 
 7953 // ============================================================================
 7954 // Zero Count Instructions
 7955 
 7956 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7957   match(Set dst (CountLeadingZerosI src));
 7958 
 7959   ins_cost(INSN_COST);
 7960   format %{ &quot;clzw  $dst, $src&quot; %}
 7961   ins_encode %{
 7962     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7963   %}
 7964 
 7965   ins_pipe(ialu_reg);
 7966 %}
 7967 
 7968 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7969   match(Set dst (CountLeadingZerosL src));
 7970 
 7971   ins_cost(INSN_COST);
 7972   format %{ &quot;clz   $dst, $src&quot; %}
 7973   ins_encode %{
 7974     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7975   %}
 7976 
 7977   ins_pipe(ialu_reg);
 7978 %}
 7979 
 7980 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7981   match(Set dst (CountTrailingZerosI src));
 7982 
 7983   ins_cost(INSN_COST * 2);
 7984   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7985             &quot;clzw   $dst, $dst&quot; %}
 7986   ins_encode %{
 7987     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7988     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7989   %}
 7990 
 7991   ins_pipe(ialu_reg);
 7992 %}
 7993 
 7994 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 7995   match(Set dst (CountTrailingZerosL src));
 7996 
 7997   ins_cost(INSN_COST * 2);
 7998   format %{ &quot;rbit   $dst, $src\n\t&quot;
 7999             &quot;clz    $dst, $dst&quot; %}
 8000   ins_encode %{
 8001     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8002     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8003   %}
 8004 
 8005   ins_pipe(ialu_reg);
 8006 %}
 8007 
 8008 //---------- Population Count Instructions -------------------------------------
 8009 //
 8010 
 8011 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8012   predicate(UsePopCountInstruction);
 8013   match(Set dst (PopCountI src));
 8014   effect(TEMP tmp);
 8015   ins_cost(INSN_COST * 13);
 8016 
 8017   format %{ &quot;movw   $src, $src\n\t&quot;
 8018             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8019             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8020             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8021             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8022   ins_encode %{
 8023     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8024     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8025     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8026     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8027     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8028   %}
 8029 
 8030   ins_pipe(pipe_class_default);
 8031 %}
 8032 
 8033 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8034   predicate(UsePopCountInstruction);
 8035   match(Set dst (PopCountI (LoadI mem)));
 8036   effect(TEMP tmp);
 8037   ins_cost(INSN_COST * 13);
 8038 
 8039   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8040             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8041             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8042             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8043   ins_encode %{
 8044     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8045     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8046               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8047     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8048     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8049     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8050   %}
 8051 
 8052   ins_pipe(pipe_class_default);
 8053 %}
 8054 
 8055 // Note: Long.bitCount(long) returns an int.
 8056 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8057   predicate(UsePopCountInstruction);
 8058   match(Set dst (PopCountL src));
 8059   effect(TEMP tmp);
 8060   ins_cost(INSN_COST * 13);
 8061 
 8062   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8063             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8064             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8065             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8066   ins_encode %{
 8067     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8068     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8069     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8070     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8071   %}
 8072 
 8073   ins_pipe(pipe_class_default);
 8074 %}
 8075 
 8076 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8077   predicate(UsePopCountInstruction);
 8078   match(Set dst (PopCountL (LoadL mem)));
 8079   effect(TEMP tmp);
 8080   ins_cost(INSN_COST * 13);
 8081 
 8082   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8083             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8084             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8085             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8086   ins_encode %{
 8087     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8088     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8089               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8090     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8091     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8092     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8093   %}
 8094 
 8095   ins_pipe(pipe_class_default);
 8096 %}
 8097 
 8098 // ============================================================================
 8099 // MemBar Instruction
 8100 
 8101 instruct load_fence() %{
 8102   match(LoadFence);
 8103   ins_cost(VOLATILE_REF_COST);
 8104 
 8105   format %{ &quot;load_fence&quot; %}
 8106 
 8107   ins_encode %{
 8108     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8109   %}
 8110   ins_pipe(pipe_serial);
 8111 %}
 8112 
 8113 instruct unnecessary_membar_acquire() %{
 8114   predicate(unnecessary_acquire(n));
 8115   match(MemBarAcquire);
 8116   ins_cost(0);
 8117 
 8118   format %{ &quot;membar_acquire (elided)&quot; %}
 8119 
 8120   ins_encode %{
 8121     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8122   %}
 8123 
 8124   ins_pipe(pipe_class_empty);
 8125 %}
 8126 
 8127 instruct membar_acquire() %{
 8128   match(MemBarAcquire);
 8129   ins_cost(VOLATILE_REF_COST);
 8130 
 8131   format %{ &quot;membar_acquire\n\t&quot;
 8132             &quot;dmb ish&quot; %}
 8133 
 8134   ins_encode %{
 8135     __ block_comment(&quot;membar_acquire&quot;);
 8136     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8137   %}
 8138 
 8139   ins_pipe(pipe_serial);
 8140 %}
 8141 
 8142 
 8143 instruct membar_acquire_lock() %{
 8144   match(MemBarAcquireLock);
 8145   ins_cost(VOLATILE_REF_COST);
 8146 
 8147   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8148 
 8149   ins_encode %{
 8150     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8151   %}
 8152 
 8153   ins_pipe(pipe_serial);
 8154 %}
 8155 
 8156 instruct store_fence() %{
 8157   match(StoreFence);
 8158   ins_cost(VOLATILE_REF_COST);
 8159 
 8160   format %{ &quot;store_fence&quot; %}
 8161 
 8162   ins_encode %{
 8163     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8164   %}
 8165   ins_pipe(pipe_serial);
 8166 %}
 8167 
 8168 instruct unnecessary_membar_release() %{
 8169   predicate(unnecessary_release(n));
 8170   match(MemBarRelease);
 8171   ins_cost(0);
 8172 
 8173   format %{ &quot;membar_release (elided)&quot; %}
 8174 
 8175   ins_encode %{
 8176     __ block_comment(&quot;membar_release (elided)&quot;);
 8177   %}
 8178   ins_pipe(pipe_serial);
 8179 %}
 8180 
 8181 instruct membar_release() %{
 8182   match(MemBarRelease);
 8183   ins_cost(VOLATILE_REF_COST);
 8184 
 8185   format %{ &quot;membar_release\n\t&quot;
 8186             &quot;dmb ish&quot; %}
 8187 
 8188   ins_encode %{
 8189     __ block_comment(&quot;membar_release&quot;);
 8190     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8191   %}
 8192   ins_pipe(pipe_serial);
 8193 %}
 8194 
 8195 instruct membar_storestore() %{
 8196   match(MemBarStoreStore);
 8197   ins_cost(VOLATILE_REF_COST);
 8198 
 8199   format %{ &quot;MEMBAR-store-store&quot; %}
 8200 
 8201   ins_encode %{
 8202     __ membar(Assembler::StoreStore);
 8203   %}
 8204   ins_pipe(pipe_serial);
 8205 %}
 8206 
 8207 instruct membar_release_lock() %{
 8208   match(MemBarReleaseLock);
 8209   ins_cost(VOLATILE_REF_COST);
 8210 
 8211   format %{ &quot;membar_release_lock (elided)&quot; %}
 8212 
 8213   ins_encode %{
 8214     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8215   %}
 8216 
 8217   ins_pipe(pipe_serial);
 8218 %}
 8219 
 8220 instruct unnecessary_membar_volatile() %{
 8221   predicate(unnecessary_volatile(n));
 8222   match(MemBarVolatile);
 8223   ins_cost(0);
 8224 
 8225   format %{ &quot;membar_volatile (elided)&quot; %}
 8226 
 8227   ins_encode %{
 8228     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8229   %}
 8230 
 8231   ins_pipe(pipe_serial);
 8232 %}
 8233 
 8234 instruct membar_volatile() %{
 8235   match(MemBarVolatile);
 8236   ins_cost(VOLATILE_REF_COST*100);
 8237 
 8238   format %{ &quot;membar_volatile\n\t&quot;
 8239              &quot;dmb ish&quot;%}
 8240 
 8241   ins_encode %{
 8242     __ block_comment(&quot;membar_volatile&quot;);
 8243     __ membar(Assembler::StoreLoad);
 8244   %}
 8245 
 8246   ins_pipe(pipe_serial);
 8247 %}
 8248 
 8249 // ============================================================================
 8250 // Cast/Convert Instructions
 8251 
 8252 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8253   match(Set dst (CastX2P src));
 8254 
 8255   ins_cost(INSN_COST);
 8256   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8257 
 8258   ins_encode %{
 8259     if ($dst$$reg != $src$$reg) {
 8260       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8261     }
 8262   %}
 8263 
 8264   ins_pipe(ialu_reg);
 8265 %}
 8266 
 8267 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8268   match(Set dst (CastP2X src));
 8269 
 8270   ins_cost(INSN_COST);
 8271   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8272 
 8273   ins_encode %{
 8274     if ($dst$$reg != $src$$reg) {
 8275       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8276     }
 8277   %}
 8278 
 8279   ins_pipe(ialu_reg);
 8280 %}
 8281 
 8282 // Convert oop into int for vectors alignment masking
 8283 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8284   match(Set dst (ConvL2I (CastP2X src)));
 8285 
 8286   ins_cost(INSN_COST);
 8287   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8288   ins_encode %{
 8289     __ movw($dst$$Register, $src$$Register);
 8290   %}
 8291 
 8292   ins_pipe(ialu_reg);
 8293 %}
 8294 
 8295 // Convert compressed oop into int for vectors alignment masking
 8296 // in case of 32bit oops (heap &lt; 4Gb).
 8297 instruct convN2I(iRegINoSp dst, iRegN src)
 8298 %{
 8299   predicate(CompressedOops::shift() == 0);
 8300   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8301 
 8302   ins_cost(INSN_COST);
 8303   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8304   ins_encode %{
 8305     __ movw($dst$$Register, $src$$Register);
 8306   %}
 8307 
 8308   ins_pipe(ialu_reg);
 8309 %}
 8310 
 8311 
 8312 // Convert oop pointer into compressed form
 8313 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8314   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8315   match(Set dst (EncodeP src));
 8316   effect(KILL cr);
 8317   ins_cost(INSN_COST * 3);
 8318   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8319   ins_encode %{
 8320     Register s = $src$$Register;
 8321     Register d = $dst$$Register;
 8322     __ encode_heap_oop(d, s);
 8323   %}
 8324   ins_pipe(ialu_reg);
 8325 %}
 8326 
 8327 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8328   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8329   match(Set dst (EncodeP src));
 8330   ins_cost(INSN_COST * 3);
 8331   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8332   ins_encode %{
 8333     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8334   %}
 8335   ins_pipe(ialu_reg);
 8336 %}
 8337 
 8338 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8339   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8340             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8341   match(Set dst (DecodeN src));
 8342   ins_cost(INSN_COST * 3);
 8343   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8344   ins_encode %{
 8345     Register s = $src$$Register;
 8346     Register d = $dst$$Register;
 8347     __ decode_heap_oop(d, s);
 8348   %}
 8349   ins_pipe(ialu_reg);
 8350 %}
 8351 
 8352 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8353   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8354             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8355   match(Set dst (DecodeN src));
 8356   ins_cost(INSN_COST * 3);
 8357   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8358   ins_encode %{
 8359     Register s = $src$$Register;
 8360     Register d = $dst$$Register;
 8361     __ decode_heap_oop_not_null(d, s);
 8362   %}
 8363   ins_pipe(ialu_reg);
 8364 %}
 8365 
 8366 // n.b. AArch64 implementations of encode_klass_not_null and
 8367 // decode_klass_not_null do not modify the flags register so, unlike
 8368 // Intel, we don&#39;t kill CR as a side effect here
 8369 
 8370 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8371   match(Set dst (EncodePKlass src));
 8372 
 8373   ins_cost(INSN_COST * 3);
 8374   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8375 
 8376   ins_encode %{
 8377     Register src_reg = as_Register($src$$reg);
 8378     Register dst_reg = as_Register($dst$$reg);
 8379     __ encode_klass_not_null(dst_reg, src_reg);
 8380   %}
 8381 
 8382    ins_pipe(ialu_reg);
 8383 %}
 8384 
 8385 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8386   match(Set dst (DecodeNKlass src));
 8387 
 8388   ins_cost(INSN_COST * 3);
 8389   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8390 
 8391   ins_encode %{
 8392     Register src_reg = as_Register($src$$reg);
 8393     Register dst_reg = as_Register($dst$$reg);
 8394     if (dst_reg != src_reg) {
 8395       __ decode_klass_not_null(dst_reg, src_reg);
 8396     } else {
 8397       __ decode_klass_not_null(dst_reg);
 8398     }
 8399   %}
 8400 
 8401    ins_pipe(ialu_reg);
 8402 %}
 8403 
 8404 instruct checkCastPP(iRegPNoSp dst)
 8405 %{
 8406   match(Set dst (CheckCastPP dst));
 8407 
 8408   size(0);
 8409   format %{ &quot;# checkcastPP of $dst&quot; %}
 8410   ins_encode(/* empty encoding */);
 8411   ins_pipe(pipe_class_empty);
 8412 %}
 8413 
 8414 instruct castPP(iRegPNoSp dst)
 8415 %{
 8416   match(Set dst (CastPP dst));
 8417 
 8418   size(0);
 8419   format %{ &quot;# castPP of $dst&quot; %}
 8420   ins_encode(/* empty encoding */);
 8421   ins_pipe(pipe_class_empty);
 8422 %}
 8423 
 8424 instruct castII(iRegI dst)
 8425 %{
 8426   match(Set dst (CastII dst));
 8427 
 8428   size(0);
 8429   format %{ &quot;# castII of $dst&quot; %}
 8430   ins_encode(/* empty encoding */);
 8431   ins_cost(0);
 8432   ins_pipe(pipe_class_empty);
 8433 %}
 8434 
 8435 // ============================================================================
 8436 // Atomic operation instructions
 8437 //
 8438 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8439 // Store{PIL}Conditional instructions using a normal load for the
 8440 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8441 //
 8442 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8443 // pair to lock object allocations from Eden space when not using
 8444 // TLABs.
 8445 //
 8446 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8447 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8448 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8449 // only for 64-bit.
 8450 //
 8451 // We implement LoadPLocked and StorePLocked instructions using,
 8452 // respectively the AArch64 hw load-exclusive and store-conditional
 8453 // instructions. Whereas we must implement each of
 8454 // Store{IL}Conditional using a CAS which employs a pair of
 8455 // instructions comprising a load-exclusive followed by a
 8456 // store-conditional.
 8457 
 8458 
 8459 // Locked-load (linked load) of the current heap-top
 8460 // used when updating the eden heap top
 8461 // implemented using ldaxr on AArch64
 8462 
 8463 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8464 %{
 8465   match(Set dst (LoadPLocked mem));
 8466 
 8467   ins_cost(VOLATILE_REF_COST);
 8468 
 8469   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8470 
 8471   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8472 
 8473   ins_pipe(pipe_serial);
 8474 %}
 8475 
 8476 // Conditional-store of the updated heap-top.
 8477 // Used during allocation of the shared heap.
 8478 // Sets flag (EQ) on success.
 8479 // implemented using stlxr on AArch64.
 8480 
 8481 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8482 %{
 8483   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8484 
 8485   ins_cost(VOLATILE_REF_COST);
 8486 
 8487  // TODO
 8488  // do we need to do a store-conditional release or can we just use a
 8489  // plain store-conditional?
 8490 
 8491   format %{
 8492     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8493     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8494   %}
 8495 
 8496   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8497 
 8498   ins_pipe(pipe_serial);
 8499 %}
 8500 
 8501 
 8502 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8503 // when attempting to rebias a lock towards the current thread.  We
 8504 // must use the acquire form of cmpxchg in order to guarantee acquire
 8505 // semantics in this case.
 8506 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8507 %{
 8508   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8509 
 8510   ins_cost(VOLATILE_REF_COST);
 8511 
 8512   format %{
 8513     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8514     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8515   %}
 8516 
 8517   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8518 
 8519   ins_pipe(pipe_slow);
 8520 %}
 8521 
 8522 // storeIConditional also has acquire semantics, for no better reason
 8523 // than matching storeLConditional.  At the time of writing this
 8524 // comment storeIConditional was not used anywhere by AArch64.
 8525 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8526 %{
 8527   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8528 
 8529   ins_cost(VOLATILE_REF_COST);
 8530 
 8531   format %{
 8532     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8533     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8534   %}
 8535 
 8536   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8537 
 8538   ins_pipe(pipe_slow);
 8539 %}
 8540 
 8541 // standard CompareAndSwapX when we are using barriers
 8542 // these have higher priority than the rules selected by a predicate
 8543 
 8544 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8545 // can&#39;t match them
 8546 
 8547 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8548 
 8549   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8550   ins_cost(2 * VOLATILE_REF_COST);
 8551 
 8552   effect(KILL cr);
 8553 
 8554   format %{
 8555     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8556     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8557   %}
 8558 
 8559   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8560             aarch64_enc_cset_eq(res));
 8561 
 8562   ins_pipe(pipe_slow);
 8563 %}
 8564 
 8565 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8566 
 8567   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8568   ins_cost(2 * VOLATILE_REF_COST);
 8569 
 8570   effect(KILL cr);
 8571 
 8572   format %{
 8573     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8574     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8575   %}
 8576 
 8577   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8578             aarch64_enc_cset_eq(res));
 8579 
 8580   ins_pipe(pipe_slow);
 8581 %}
 8582 
 8583 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8584 
 8585   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8586   ins_cost(2 * VOLATILE_REF_COST);
 8587 
 8588   effect(KILL cr);
 8589 
 8590  format %{
 8591     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8592     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8593  %}
 8594 
 8595  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8596             aarch64_enc_cset_eq(res));
 8597 
 8598   ins_pipe(pipe_slow);
 8599 %}
 8600 
 8601 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8602 
 8603   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8604   ins_cost(2 * VOLATILE_REF_COST);
 8605 
 8606   effect(KILL cr);
 8607 
 8608  format %{
 8609     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8610     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8611  %}
 8612 
 8613  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8614             aarch64_enc_cset_eq(res));
 8615 
 8616   ins_pipe(pipe_slow);
 8617 %}
 8618 
 8619 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8620 
 8621   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8622   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8623   ins_cost(2 * VOLATILE_REF_COST);
 8624 
 8625   effect(KILL cr);
 8626 
 8627  format %{
 8628     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8629     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8630  %}
 8631 
 8632  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8633             aarch64_enc_cset_eq(res));
 8634 
 8635   ins_pipe(pipe_slow);
 8636 %}
 8637 
 8638 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8639 
 8640   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8641   ins_cost(2 * VOLATILE_REF_COST);
 8642 
 8643   effect(KILL cr);
 8644 
 8645  format %{
 8646     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8647     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8648  %}
 8649 
 8650  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8651             aarch64_enc_cset_eq(res));
 8652 
 8653   ins_pipe(pipe_slow);
 8654 %}
 8655 
 8656 // alternative CompareAndSwapX when we are eliding barriers
 8657 
 8658 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8659 
 8660   predicate(needs_acquiring_load_exclusive(n));
 8661   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8662   ins_cost(VOLATILE_REF_COST);
 8663 
 8664   effect(KILL cr);
 8665 
 8666   format %{
 8667     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8668     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8669   %}
 8670 
 8671   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8672             aarch64_enc_cset_eq(res));
 8673 
 8674   ins_pipe(pipe_slow);
 8675 %}
 8676 
 8677 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8678 
 8679   predicate(needs_acquiring_load_exclusive(n));
 8680   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8681   ins_cost(VOLATILE_REF_COST);
 8682 
 8683   effect(KILL cr);
 8684 
 8685   format %{
 8686     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8687     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8688   %}
 8689 
 8690   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8691             aarch64_enc_cset_eq(res));
 8692 
 8693   ins_pipe(pipe_slow);
 8694 %}
 8695 
 8696 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8697 
 8698   predicate(needs_acquiring_load_exclusive(n));
 8699   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8700   ins_cost(VOLATILE_REF_COST);
 8701 
 8702   effect(KILL cr);
 8703 
 8704  format %{
 8705     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8706     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8707  %}
 8708 
 8709  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8710             aarch64_enc_cset_eq(res));
 8711 
 8712   ins_pipe(pipe_slow);
 8713 %}
 8714 
 8715 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8716 
 8717   predicate(needs_acquiring_load_exclusive(n));
 8718   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8719   ins_cost(VOLATILE_REF_COST);
 8720 
 8721   effect(KILL cr);
 8722 
 8723  format %{
 8724     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8725     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8726  %}
 8727 
 8728  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8729             aarch64_enc_cset_eq(res));
 8730 
 8731   ins_pipe(pipe_slow);
 8732 %}
 8733 
 8734 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8735 
 8736   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8737   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8738   ins_cost(VOLATILE_REF_COST);
 8739 
 8740   effect(KILL cr);
 8741 
 8742  format %{
 8743     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8744     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8745  %}
 8746 
 8747  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8748             aarch64_enc_cset_eq(res));
 8749 
 8750   ins_pipe(pipe_slow);
 8751 %}
 8752 
 8753 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8754 
 8755   predicate(needs_acquiring_load_exclusive(n));
 8756   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8757   ins_cost(VOLATILE_REF_COST);
 8758 
 8759   effect(KILL cr);
 8760 
 8761  format %{
 8762     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8763     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8764  %}
 8765 
 8766  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8767             aarch64_enc_cset_eq(res));
 8768 
 8769   ins_pipe(pipe_slow);
 8770 %}
 8771 
 8772 
 8773 // ---------------------------------------------------------------------
 8774 
 8775 
 8776 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8777 
 8778 // Sundry CAS operations.  Note that release is always true,
 8779 // regardless of the memory ordering of the CAS.  This is because we
 8780 // need the volatile case to be sequentially consistent but there is
 8781 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8782 // can&#39;t check the type of memory ordering here, so we always emit a
 8783 // STLXR.
 8784 
 8785 // This section is generated from aarch64_ad_cas.m4
 8786 
 8787 
 8788 
 8789 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8790   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8791   ins_cost(2 * VOLATILE_REF_COST);
 8792   effect(TEMP_DEF res, KILL cr);
 8793   format %{
 8794     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8795   %}
 8796   ins_encode %{
 8797     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8798                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8799                /*weak*/ false, $res$$Register);
 8800     __ sxtbw($res$$Register, $res$$Register);
 8801   %}
 8802   ins_pipe(pipe_slow);
 8803 %}
 8804 
 8805 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8806   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8807   ins_cost(2 * VOLATILE_REF_COST);
 8808   effect(TEMP_DEF res, KILL cr);
 8809   format %{
 8810     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8811   %}
 8812   ins_encode %{
 8813     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8814                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8815                /*weak*/ false, $res$$Register);
 8816     __ sxthw($res$$Register, $res$$Register);
 8817   %}
 8818   ins_pipe(pipe_slow);
 8819 %}
 8820 
 8821 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8822   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8823   ins_cost(2 * VOLATILE_REF_COST);
 8824   effect(TEMP_DEF res, KILL cr);
 8825   format %{
 8826     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8827   %}
 8828   ins_encode %{
 8829     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8830                Assembler::word, /*acquire*/ false, /*release*/ true,
 8831                /*weak*/ false, $res$$Register);
 8832   %}
 8833   ins_pipe(pipe_slow);
 8834 %}
 8835 
 8836 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8837   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8838   ins_cost(2 * VOLATILE_REF_COST);
 8839   effect(TEMP_DEF res, KILL cr);
 8840   format %{
 8841     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8842   %}
 8843   ins_encode %{
 8844     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8845                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8846                /*weak*/ false, $res$$Register);
 8847   %}
 8848   ins_pipe(pipe_slow);
 8849 %}
 8850 
 8851 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8852   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8853   ins_cost(2 * VOLATILE_REF_COST);
 8854   effect(TEMP_DEF res, KILL cr);
 8855   format %{
 8856     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8857   %}
 8858   ins_encode %{
 8859     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8860                Assembler::word, /*acquire*/ false, /*release*/ true,
 8861                /*weak*/ false, $res$$Register);
 8862   %}
 8863   ins_pipe(pipe_slow);
 8864 %}
 8865 
 8866 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8867   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8868   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8869   ins_cost(2 * VOLATILE_REF_COST);
 8870   effect(TEMP_DEF res, KILL cr);
 8871   format %{
 8872     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8873   %}
 8874   ins_encode %{
 8875     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8876                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8877                /*weak*/ false, $res$$Register);
 8878   %}
 8879   ins_pipe(pipe_slow);
 8880 %}
 8881 
 8882 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8883   predicate(needs_acquiring_load_exclusive(n));
 8884   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8885   ins_cost(VOLATILE_REF_COST);
 8886   effect(TEMP_DEF res, KILL cr);
 8887   format %{
 8888     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8889   %}
 8890   ins_encode %{
 8891     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8892                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8893                /*weak*/ false, $res$$Register);
 8894     __ sxtbw($res$$Register, $res$$Register);
 8895   %}
 8896   ins_pipe(pipe_slow);
 8897 %}
 8898 
 8899 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8900   predicate(needs_acquiring_load_exclusive(n));
 8901   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8902   ins_cost(VOLATILE_REF_COST);
 8903   effect(TEMP_DEF res, KILL cr);
 8904   format %{
 8905     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8906   %}
 8907   ins_encode %{
 8908     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8909                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8910                /*weak*/ false, $res$$Register);
 8911     __ sxthw($res$$Register, $res$$Register);
 8912   %}
 8913   ins_pipe(pipe_slow);
 8914 %}
 8915 
 8916 
 8917 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8918   predicate(needs_acquiring_load_exclusive(n));
 8919   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8920   ins_cost(VOLATILE_REF_COST);
 8921   effect(TEMP_DEF res, KILL cr);
 8922   format %{
 8923     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8924   %}
 8925   ins_encode %{
 8926     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8927                Assembler::word, /*acquire*/ true, /*release*/ true,
 8928                /*weak*/ false, $res$$Register);
 8929   %}
 8930   ins_pipe(pipe_slow);
 8931 %}
 8932 
 8933 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8934   predicate(needs_acquiring_load_exclusive(n));
 8935   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8936   ins_cost(VOLATILE_REF_COST);
 8937   effect(TEMP_DEF res, KILL cr);
 8938   format %{
 8939     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8940   %}
 8941   ins_encode %{
 8942     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8943                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8944                /*weak*/ false, $res$$Register);
 8945   %}
 8946   ins_pipe(pipe_slow);
 8947 %}
 8948 
 8949 
 8950 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8951   predicate(needs_acquiring_load_exclusive(n));
 8952   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8953   ins_cost(VOLATILE_REF_COST);
 8954   effect(TEMP_DEF res, KILL cr);
 8955   format %{
 8956     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8957   %}
 8958   ins_encode %{
 8959     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8960                Assembler::word, /*acquire*/ true, /*release*/ true,
 8961                /*weak*/ false, $res$$Register);
 8962   %}
 8963   ins_pipe(pipe_slow);
 8964 %}
 8965 
 8966 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8967   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8968   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8969   ins_cost(VOLATILE_REF_COST);
 8970   effect(TEMP_DEF res, KILL cr);
 8971   format %{
 8972     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8973   %}
 8974   ins_encode %{
 8975     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8976                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8977                /*weak*/ false, $res$$Register);
 8978   %}
 8979   ins_pipe(pipe_slow);
 8980 %}
 8981 
 8982 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8983   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 8984   ins_cost(2 * VOLATILE_REF_COST);
 8985   effect(KILL cr);
 8986   format %{
 8987     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8988     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8989   %}
 8990   ins_encode %{
 8991     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8992                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8993                /*weak*/ true, noreg);
 8994     __ csetw($res$$Register, Assembler::EQ);
 8995   %}
 8996   ins_pipe(pipe_slow);
 8997 %}
 8998 
 8999 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9000   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9001   ins_cost(2 * VOLATILE_REF_COST);
 9002   effect(KILL cr);
 9003   format %{
 9004     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9005     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9006   %}
 9007   ins_encode %{
 9008     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9009                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9010                /*weak*/ true, noreg);
 9011     __ csetw($res$$Register, Assembler::EQ);
 9012   %}
 9013   ins_pipe(pipe_slow);
 9014 %}
 9015 
 9016 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9017   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9018   ins_cost(2 * VOLATILE_REF_COST);
 9019   effect(KILL cr);
 9020   format %{
 9021     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9022     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9023   %}
 9024   ins_encode %{
 9025     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9026                Assembler::word, /*acquire*/ false, /*release*/ true,
 9027                /*weak*/ true, noreg);
 9028     __ csetw($res$$Register, Assembler::EQ);
 9029   %}
 9030   ins_pipe(pipe_slow);
 9031 %}
 9032 
 9033 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9034   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9035   ins_cost(2 * VOLATILE_REF_COST);
 9036   effect(KILL cr);
 9037   format %{
 9038     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9039     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9040   %}
 9041   ins_encode %{
 9042     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9043                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9044                /*weak*/ true, noreg);
 9045     __ csetw($res$$Register, Assembler::EQ);
 9046   %}
 9047   ins_pipe(pipe_slow);
 9048 %}
 9049 
 9050 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9051   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9052   ins_cost(2 * VOLATILE_REF_COST);
 9053   effect(KILL cr);
 9054   format %{
 9055     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9056     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9057   %}
 9058   ins_encode %{
 9059     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9060                Assembler::word, /*acquire*/ false, /*release*/ true,
 9061                /*weak*/ true, noreg);
 9062     __ csetw($res$$Register, Assembler::EQ);
 9063   %}
 9064   ins_pipe(pipe_slow);
 9065 %}
 9066 
 9067 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9068   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9069   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9070   ins_cost(2 * VOLATILE_REF_COST);
 9071   effect(KILL cr);
 9072   format %{
 9073     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9074     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9075   %}
 9076   ins_encode %{
 9077     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9078                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9079                /*weak*/ true, noreg);
 9080     __ csetw($res$$Register, Assembler::EQ);
 9081   %}
 9082   ins_pipe(pipe_slow);
 9083 %}
 9084 
 9085 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9086   predicate(needs_acquiring_load_exclusive(n));
 9087   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9088   ins_cost(VOLATILE_REF_COST);
 9089   effect(KILL cr);
 9090   format %{
 9091     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9092     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9093   %}
 9094   ins_encode %{
 9095     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9096                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9097                /*weak*/ true, noreg);
 9098     __ csetw($res$$Register, Assembler::EQ);
 9099   %}
 9100   ins_pipe(pipe_slow);
 9101 %}
 9102 
 9103 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9104   predicate(needs_acquiring_load_exclusive(n));
 9105   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9106   ins_cost(VOLATILE_REF_COST);
 9107   effect(KILL cr);
 9108   format %{
 9109     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9110     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9111   %}
 9112   ins_encode %{
 9113     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9114                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9115                /*weak*/ true, noreg);
 9116     __ csetw($res$$Register, Assembler::EQ);
 9117   %}
 9118   ins_pipe(pipe_slow);
 9119 %}
 9120 
 9121 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9122   predicate(needs_acquiring_load_exclusive(n));
 9123   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9124   ins_cost(VOLATILE_REF_COST);
 9125   effect(KILL cr);
 9126   format %{
 9127     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9128     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9129   %}
 9130   ins_encode %{
 9131     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9132                Assembler::word, /*acquire*/ true, /*release*/ true,
 9133                /*weak*/ true, noreg);
 9134     __ csetw($res$$Register, Assembler::EQ);
 9135   %}
 9136   ins_pipe(pipe_slow);
 9137 %}
 9138 
 9139 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9140   predicate(needs_acquiring_load_exclusive(n));
 9141   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9142   ins_cost(VOLATILE_REF_COST);
 9143   effect(KILL cr);
 9144   format %{
 9145     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9146     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9147   %}
 9148   ins_encode %{
 9149     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9150                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9151                /*weak*/ true, noreg);
 9152     __ csetw($res$$Register, Assembler::EQ);
 9153   %}
 9154   ins_pipe(pipe_slow);
 9155 %}
 9156 
 9157 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9158   predicate(needs_acquiring_load_exclusive(n));
 9159   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9160   ins_cost(VOLATILE_REF_COST);
 9161   effect(KILL cr);
 9162   format %{
 9163     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9164     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9165   %}
 9166   ins_encode %{
 9167     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9168                Assembler::word, /*acquire*/ true, /*release*/ true,
 9169                /*weak*/ true, noreg);
 9170     __ csetw($res$$Register, Assembler::EQ);
 9171   %}
 9172   ins_pipe(pipe_slow);
 9173 %}
 9174 
 9175 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9176   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9177   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9178   ins_cost(VOLATILE_REF_COST);
 9179   effect(KILL cr);
 9180   format %{
 9181     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9182     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9183   %}
 9184   ins_encode %{
 9185     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9186                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9187                /*weak*/ true, noreg);
 9188     __ csetw($res$$Register, Assembler::EQ);
 9189   %}
 9190   ins_pipe(pipe_slow);
 9191 %}
 9192 
 9193 // END This section of the file is automatically generated. Do not edit --------------
 9194 // ---------------------------------------------------------------------
 9195 
 9196 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9197   match(Set prev (GetAndSetI mem newv));
 9198   ins_cost(2 * VOLATILE_REF_COST);
 9199   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9200   ins_encode %{
 9201     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9202   %}
 9203   ins_pipe(pipe_serial);
 9204 %}
 9205 
 9206 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9207   match(Set prev (GetAndSetL mem newv));
 9208   ins_cost(2 * VOLATILE_REF_COST);
 9209   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9210   ins_encode %{
 9211     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9212   %}
 9213   ins_pipe(pipe_serial);
 9214 %}
 9215 
 9216 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9217   match(Set prev (GetAndSetN mem newv));
 9218   ins_cost(2 * VOLATILE_REF_COST);
 9219   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9220   ins_encode %{
 9221     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9222   %}
 9223   ins_pipe(pipe_serial);
 9224 %}
 9225 
 9226 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9227   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9228   match(Set prev (GetAndSetP mem newv));
 9229   ins_cost(2 * VOLATILE_REF_COST);
 9230   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9231   ins_encode %{
 9232     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9233   %}
 9234   ins_pipe(pipe_serial);
 9235 %}
 9236 
 9237 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9238   predicate(needs_acquiring_load_exclusive(n));
 9239   match(Set prev (GetAndSetI mem newv));
 9240   ins_cost(VOLATILE_REF_COST);
 9241   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9242   ins_encode %{
 9243     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9244   %}
 9245   ins_pipe(pipe_serial);
 9246 %}
 9247 
 9248 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9249   predicate(needs_acquiring_load_exclusive(n));
 9250   match(Set prev (GetAndSetL mem newv));
 9251   ins_cost(VOLATILE_REF_COST);
 9252   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9253   ins_encode %{
 9254     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9255   %}
 9256   ins_pipe(pipe_serial);
 9257 %}
 9258 
 9259 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9260   predicate(needs_acquiring_load_exclusive(n));
 9261   match(Set prev (GetAndSetN mem newv));
 9262   ins_cost(VOLATILE_REF_COST);
 9263   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9264   ins_encode %{
 9265     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9266   %}
 9267   ins_pipe(pipe_serial);
 9268 %}
 9269 
 9270 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9271   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9272   match(Set prev (GetAndSetP mem newv));
 9273   ins_cost(VOLATILE_REF_COST);
 9274   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9275   ins_encode %{
 9276     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9277   %}
 9278   ins_pipe(pipe_serial);
 9279 %}
 9280 
 9281 
 9282 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9283   match(Set newval (GetAndAddL mem incr));
 9284   ins_cost(2 * VOLATILE_REF_COST + 1);
 9285   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9286   ins_encode %{
 9287     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9288   %}
 9289   ins_pipe(pipe_serial);
 9290 %}
 9291 
 9292 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9293   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9294   match(Set dummy (GetAndAddL mem incr));
 9295   ins_cost(2 * VOLATILE_REF_COST);
 9296   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9297   ins_encode %{
 9298     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9299   %}
 9300   ins_pipe(pipe_serial);
 9301 %}
 9302 
 9303 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9304   match(Set newval (GetAndAddL mem incr));
 9305   ins_cost(2 * VOLATILE_REF_COST + 1);
 9306   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9307   ins_encode %{
 9308     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9309   %}
 9310   ins_pipe(pipe_serial);
 9311 %}
 9312 
 9313 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9314   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9315   match(Set dummy (GetAndAddL mem incr));
 9316   ins_cost(2 * VOLATILE_REF_COST);
 9317   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9318   ins_encode %{
 9319     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9320   %}
 9321   ins_pipe(pipe_serial);
 9322 %}
 9323 
 9324 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9325   match(Set newval (GetAndAddI mem incr));
 9326   ins_cost(2 * VOLATILE_REF_COST + 1);
 9327   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9328   ins_encode %{
 9329     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9330   %}
 9331   ins_pipe(pipe_serial);
 9332 %}
 9333 
 9334 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9335   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9336   match(Set dummy (GetAndAddI mem incr));
 9337   ins_cost(2 * VOLATILE_REF_COST);
 9338   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9339   ins_encode %{
 9340     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9341   %}
 9342   ins_pipe(pipe_serial);
 9343 %}
 9344 
 9345 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9346   match(Set newval (GetAndAddI mem incr));
 9347   ins_cost(2 * VOLATILE_REF_COST + 1);
 9348   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9349   ins_encode %{
 9350     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9351   %}
 9352   ins_pipe(pipe_serial);
 9353 %}
 9354 
 9355 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9356   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9357   match(Set dummy (GetAndAddI mem incr));
 9358   ins_cost(2 * VOLATILE_REF_COST);
 9359   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9360   ins_encode %{
 9361     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9362   %}
 9363   ins_pipe(pipe_serial);
 9364 %}
 9365 
 9366 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9367   predicate(needs_acquiring_load_exclusive(n));
 9368   match(Set newval (GetAndAddL mem incr));
 9369   ins_cost(VOLATILE_REF_COST + 1);
 9370   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9371   ins_encode %{
 9372     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9373   %}
 9374   ins_pipe(pipe_serial);
 9375 %}
 9376 
 9377 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9378   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9379   match(Set dummy (GetAndAddL mem incr));
 9380   ins_cost(VOLATILE_REF_COST);
 9381   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9382   ins_encode %{
 9383     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9384   %}
 9385   ins_pipe(pipe_serial);
 9386 %}
 9387 
 9388 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9389   predicate(needs_acquiring_load_exclusive(n));
 9390   match(Set newval (GetAndAddL mem incr));
 9391   ins_cost(VOLATILE_REF_COST + 1);
 9392   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9393   ins_encode %{
 9394     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9395   %}
 9396   ins_pipe(pipe_serial);
 9397 %}
 9398 
 9399 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9400   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9401   match(Set dummy (GetAndAddL mem incr));
 9402   ins_cost(VOLATILE_REF_COST);
 9403   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9404   ins_encode %{
 9405     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9406   %}
 9407   ins_pipe(pipe_serial);
 9408 %}
 9409 
 9410 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9411   predicate(needs_acquiring_load_exclusive(n));
 9412   match(Set newval (GetAndAddI mem incr));
 9413   ins_cost(VOLATILE_REF_COST + 1);
 9414   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9415   ins_encode %{
 9416     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9417   %}
 9418   ins_pipe(pipe_serial);
 9419 %}
 9420 
 9421 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9422   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9423   match(Set dummy (GetAndAddI mem incr));
 9424   ins_cost(VOLATILE_REF_COST);
 9425   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9426   ins_encode %{
 9427     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9428   %}
 9429   ins_pipe(pipe_serial);
 9430 %}
 9431 
 9432 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9433   predicate(needs_acquiring_load_exclusive(n));
 9434   match(Set newval (GetAndAddI mem incr));
 9435   ins_cost(VOLATILE_REF_COST + 1);
 9436   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9437   ins_encode %{
 9438     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9439   %}
 9440   ins_pipe(pipe_serial);
 9441 %}
 9442 
 9443 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9444   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9445   match(Set dummy (GetAndAddI mem incr));
 9446   ins_cost(VOLATILE_REF_COST);
 9447   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9448   ins_encode %{
 9449     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9450   %}
 9451   ins_pipe(pipe_serial);
 9452 %}
 9453 
 9454 // Manifest a CmpL result in an integer register.
 9455 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9456 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9457 %{
 9458   match(Set dst (CmpL3 src1 src2));
 9459   effect(KILL flags);
 9460 
 9461   ins_cost(INSN_COST * 6);
 9462   format %{
 9463       &quot;cmp $src1, $src2&quot;
 9464       &quot;csetw $dst, ne&quot;
 9465       &quot;cnegw $dst, lt&quot;
 9466   %}
 9467   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9468   ins_encode %{
 9469     __ cmp($src1$$Register, $src2$$Register);
 9470     __ csetw($dst$$Register, Assembler::NE);
 9471     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9472   %}
 9473 
 9474   ins_pipe(pipe_class_default);
 9475 %}
 9476 
 9477 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9478 %{
 9479   match(Set dst (CmpL3 src1 src2));
 9480   effect(KILL flags);
 9481 
 9482   ins_cost(INSN_COST * 6);
 9483   format %{
 9484       &quot;cmp $src1, $src2&quot;
 9485       &quot;csetw $dst, ne&quot;
 9486       &quot;cnegw $dst, lt&quot;
 9487   %}
 9488   ins_encode %{
 9489     int32_t con = (int32_t)$src2$$constant;
 9490      if (con &lt; 0) {
 9491       __ adds(zr, $src1$$Register, -con);
 9492     } else {
 9493       __ subs(zr, $src1$$Register, con);
 9494     }
 9495     __ csetw($dst$$Register, Assembler::NE);
 9496     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9497   %}
 9498 
 9499   ins_pipe(pipe_class_default);
 9500 %}
 9501 
 9502 // ============================================================================
 9503 // Conditional Move Instructions
 9504 
 9505 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9506 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9507 // define an op class which merged both inputs and use it to type the
 9508 // argument to a single rule. unfortunatelyt his fails because the
 9509 // opclass does not live up to the COND_INTER interface of its
 9510 // component operands. When the generic code tries to negate the
 9511 // operand it ends up running the generci Machoper::negate method
 9512 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9513 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9514 
 9515 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9516   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9517 
 9518   ins_cost(INSN_COST * 2);
 9519   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9520 
 9521   ins_encode %{
 9522     __ cselw(as_Register($dst$$reg),
 9523              as_Register($src2$$reg),
 9524              as_Register($src1$$reg),
 9525              (Assembler::Condition)$cmp$$cmpcode);
 9526   %}
 9527 
 9528   ins_pipe(icond_reg_reg);
 9529 %}
 9530 
 9531 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9532   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9533 
 9534   ins_cost(INSN_COST * 2);
 9535   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9536 
 9537   ins_encode %{
 9538     __ cselw(as_Register($dst$$reg),
 9539              as_Register($src2$$reg),
 9540              as_Register($src1$$reg),
 9541              (Assembler::Condition)$cmp$$cmpcode);
 9542   %}
 9543 
 9544   ins_pipe(icond_reg_reg);
 9545 %}
 9546 
 9547 // special cases where one arg is zero
 9548 
 9549 // n.b. this is selected in preference to the rule above because it
 9550 // avoids loading constant 0 into a source register
 9551 
 9552 // TODO
 9553 // we ought only to be able to cull one of these variants as the ideal
 9554 // transforms ought always to order the zero consistently (to left/right?)
 9555 
 9556 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9557   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9558 
 9559   ins_cost(INSN_COST * 2);
 9560   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9561 
 9562   ins_encode %{
 9563     __ cselw(as_Register($dst$$reg),
 9564              as_Register($src$$reg),
 9565              zr,
 9566              (Assembler::Condition)$cmp$$cmpcode);
 9567   %}
 9568 
 9569   ins_pipe(icond_reg);
 9570 %}
 9571 
 9572 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9573   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9574 
 9575   ins_cost(INSN_COST * 2);
 9576   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9577 
 9578   ins_encode %{
 9579     __ cselw(as_Register($dst$$reg),
 9580              as_Register($src$$reg),
 9581              zr,
 9582              (Assembler::Condition)$cmp$$cmpcode);
 9583   %}
 9584 
 9585   ins_pipe(icond_reg);
 9586 %}
 9587 
 9588 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9589   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9590 
 9591   ins_cost(INSN_COST * 2);
 9592   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9593 
 9594   ins_encode %{
 9595     __ cselw(as_Register($dst$$reg),
 9596              zr,
 9597              as_Register($src$$reg),
 9598              (Assembler::Condition)$cmp$$cmpcode);
 9599   %}
 9600 
 9601   ins_pipe(icond_reg);
 9602 %}
 9603 
 9604 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9605   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9606 
 9607   ins_cost(INSN_COST * 2);
 9608   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9609 
 9610   ins_encode %{
 9611     __ cselw(as_Register($dst$$reg),
 9612              zr,
 9613              as_Register($src$$reg),
 9614              (Assembler::Condition)$cmp$$cmpcode);
 9615   %}
 9616 
 9617   ins_pipe(icond_reg);
 9618 %}
 9619 
 9620 // special case for creating a boolean 0 or 1
 9621 
 9622 // n.b. this is selected in preference to the rule above because it
 9623 // avoids loading constants 0 and 1 into a source register
 9624 
 9625 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9626   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9627 
 9628   ins_cost(INSN_COST * 2);
 9629   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9630 
 9631   ins_encode %{
 9632     // equivalently
 9633     // cset(as_Register($dst$$reg),
 9634     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9635     __ csincw(as_Register($dst$$reg),
 9636              zr,
 9637              zr,
 9638              (Assembler::Condition)$cmp$$cmpcode);
 9639   %}
 9640 
 9641   ins_pipe(icond_none);
 9642 %}
 9643 
 9644 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9645   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9646 
 9647   ins_cost(INSN_COST * 2);
 9648   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9649 
 9650   ins_encode %{
 9651     // equivalently
 9652     // cset(as_Register($dst$$reg),
 9653     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9654     __ csincw(as_Register($dst$$reg),
 9655              zr,
 9656              zr,
 9657              (Assembler::Condition)$cmp$$cmpcode);
 9658   %}
 9659 
 9660   ins_pipe(icond_none);
 9661 %}
 9662 
 9663 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9664   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9665 
 9666   ins_cost(INSN_COST * 2);
 9667   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9668 
 9669   ins_encode %{
 9670     __ csel(as_Register($dst$$reg),
 9671             as_Register($src2$$reg),
 9672             as_Register($src1$$reg),
 9673             (Assembler::Condition)$cmp$$cmpcode);
 9674   %}
 9675 
 9676   ins_pipe(icond_reg_reg);
 9677 %}
 9678 
 9679 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9680   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9681 
 9682   ins_cost(INSN_COST * 2);
 9683   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9684 
 9685   ins_encode %{
 9686     __ csel(as_Register($dst$$reg),
 9687             as_Register($src2$$reg),
 9688             as_Register($src1$$reg),
 9689             (Assembler::Condition)$cmp$$cmpcode);
 9690   %}
 9691 
 9692   ins_pipe(icond_reg_reg);
 9693 %}
 9694 
 9695 // special cases where one arg is zero
 9696 
 9697 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9698   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9699 
 9700   ins_cost(INSN_COST * 2);
 9701   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9702 
 9703   ins_encode %{
 9704     __ csel(as_Register($dst$$reg),
 9705             zr,
 9706             as_Register($src$$reg),
 9707             (Assembler::Condition)$cmp$$cmpcode);
 9708   %}
 9709 
 9710   ins_pipe(icond_reg);
 9711 %}
 9712 
 9713 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9714   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9715 
 9716   ins_cost(INSN_COST * 2);
 9717   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9718 
 9719   ins_encode %{
 9720     __ csel(as_Register($dst$$reg),
 9721             zr,
 9722             as_Register($src$$reg),
 9723             (Assembler::Condition)$cmp$$cmpcode);
 9724   %}
 9725 
 9726   ins_pipe(icond_reg);
 9727 %}
 9728 
 9729 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9730   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9731 
 9732   ins_cost(INSN_COST * 2);
 9733   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9734 
 9735   ins_encode %{
 9736     __ csel(as_Register($dst$$reg),
 9737             as_Register($src$$reg),
 9738             zr,
 9739             (Assembler::Condition)$cmp$$cmpcode);
 9740   %}
 9741 
 9742   ins_pipe(icond_reg);
 9743 %}
 9744 
 9745 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9746   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9747 
 9748   ins_cost(INSN_COST * 2);
 9749   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9750 
 9751   ins_encode %{
 9752     __ csel(as_Register($dst$$reg),
 9753             as_Register($src$$reg),
 9754             zr,
 9755             (Assembler::Condition)$cmp$$cmpcode);
 9756   %}
 9757 
 9758   ins_pipe(icond_reg);
 9759 %}
 9760 
 9761 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9762   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9763 
 9764   ins_cost(INSN_COST * 2);
 9765   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9766 
 9767   ins_encode %{
 9768     __ csel(as_Register($dst$$reg),
 9769             as_Register($src2$$reg),
 9770             as_Register($src1$$reg),
 9771             (Assembler::Condition)$cmp$$cmpcode);
 9772   %}
 9773 
 9774   ins_pipe(icond_reg_reg);
 9775 %}
 9776 
 9777 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9778   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9779 
 9780   ins_cost(INSN_COST * 2);
 9781   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9782 
 9783   ins_encode %{
 9784     __ csel(as_Register($dst$$reg),
 9785             as_Register($src2$$reg),
 9786             as_Register($src1$$reg),
 9787             (Assembler::Condition)$cmp$$cmpcode);
 9788   %}
 9789 
 9790   ins_pipe(icond_reg_reg);
 9791 %}
 9792 
 9793 // special cases where one arg is zero
 9794 
 9795 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9796   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9797 
 9798   ins_cost(INSN_COST * 2);
 9799   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9800 
 9801   ins_encode %{
 9802     __ csel(as_Register($dst$$reg),
 9803             zr,
 9804             as_Register($src$$reg),
 9805             (Assembler::Condition)$cmp$$cmpcode);
 9806   %}
 9807 
 9808   ins_pipe(icond_reg);
 9809 %}
 9810 
 9811 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9812   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9813 
 9814   ins_cost(INSN_COST * 2);
 9815   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9816 
 9817   ins_encode %{
 9818     __ csel(as_Register($dst$$reg),
 9819             zr,
 9820             as_Register($src$$reg),
 9821             (Assembler::Condition)$cmp$$cmpcode);
 9822   %}
 9823 
 9824   ins_pipe(icond_reg);
 9825 %}
 9826 
 9827 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9828   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9829 
 9830   ins_cost(INSN_COST * 2);
 9831   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9832 
 9833   ins_encode %{
 9834     __ csel(as_Register($dst$$reg),
 9835             as_Register($src$$reg),
 9836             zr,
 9837             (Assembler::Condition)$cmp$$cmpcode);
 9838   %}
 9839 
 9840   ins_pipe(icond_reg);
 9841 %}
 9842 
 9843 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9844   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9845 
 9846   ins_cost(INSN_COST * 2);
 9847   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9848 
 9849   ins_encode %{
 9850     __ csel(as_Register($dst$$reg),
 9851             as_Register($src$$reg),
 9852             zr,
 9853             (Assembler::Condition)$cmp$$cmpcode);
 9854   %}
 9855 
 9856   ins_pipe(icond_reg);
 9857 %}
 9858 
 9859 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9860   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9861 
 9862   ins_cost(INSN_COST * 2);
 9863   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9864 
 9865   ins_encode %{
 9866     __ cselw(as_Register($dst$$reg),
 9867              as_Register($src2$$reg),
 9868              as_Register($src1$$reg),
 9869              (Assembler::Condition)$cmp$$cmpcode);
 9870   %}
 9871 
 9872   ins_pipe(icond_reg_reg);
 9873 %}
 9874 
 9875 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9876   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9877 
 9878   ins_cost(INSN_COST * 2);
 9879   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9880 
 9881   ins_encode %{
 9882     __ cselw(as_Register($dst$$reg),
 9883              as_Register($src2$$reg),
 9884              as_Register($src1$$reg),
 9885              (Assembler::Condition)$cmp$$cmpcode);
 9886   %}
 9887 
 9888   ins_pipe(icond_reg_reg);
 9889 %}
 9890 
 9891 // special cases where one arg is zero
 9892 
 9893 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9894   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9895 
 9896   ins_cost(INSN_COST * 2);
 9897   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9898 
 9899   ins_encode %{
 9900     __ cselw(as_Register($dst$$reg),
 9901              zr,
 9902              as_Register($src$$reg),
 9903              (Assembler::Condition)$cmp$$cmpcode);
 9904   %}
 9905 
 9906   ins_pipe(icond_reg);
 9907 %}
 9908 
 9909 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9910   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9911 
 9912   ins_cost(INSN_COST * 2);
 9913   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9914 
 9915   ins_encode %{
 9916     __ cselw(as_Register($dst$$reg),
 9917              zr,
 9918              as_Register($src$$reg),
 9919              (Assembler::Condition)$cmp$$cmpcode);
 9920   %}
 9921 
 9922   ins_pipe(icond_reg);
 9923 %}
 9924 
 9925 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9926   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9927 
 9928   ins_cost(INSN_COST * 2);
 9929   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9930 
 9931   ins_encode %{
 9932     __ cselw(as_Register($dst$$reg),
 9933              as_Register($src$$reg),
 9934              zr,
 9935              (Assembler::Condition)$cmp$$cmpcode);
 9936   %}
 9937 
 9938   ins_pipe(icond_reg);
 9939 %}
 9940 
 9941 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9942   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9943 
 9944   ins_cost(INSN_COST * 2);
 9945   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9946 
 9947   ins_encode %{
 9948     __ cselw(as_Register($dst$$reg),
 9949              as_Register($src$$reg),
 9950              zr,
 9951              (Assembler::Condition)$cmp$$cmpcode);
 9952   %}
 9953 
 9954   ins_pipe(icond_reg);
 9955 %}
 9956 
 9957 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9958 %{
 9959   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9960 
 9961   ins_cost(INSN_COST * 3);
 9962 
 9963   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9964   ins_encode %{
 9965     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9966     __ fcsels(as_FloatRegister($dst$$reg),
 9967               as_FloatRegister($src2$$reg),
 9968               as_FloatRegister($src1$$reg),
 9969               cond);
 9970   %}
 9971 
 9972   ins_pipe(fp_cond_reg_reg_s);
 9973 %}
 9974 
 9975 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9976 %{
 9977   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9978 
 9979   ins_cost(INSN_COST * 3);
 9980 
 9981   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
 9982   ins_encode %{
 9983     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9984     __ fcsels(as_FloatRegister($dst$$reg),
 9985               as_FloatRegister($src2$$reg),
 9986               as_FloatRegister($src1$$reg),
 9987               cond);
 9988   %}
 9989 
 9990   ins_pipe(fp_cond_reg_reg_s);
 9991 %}
 9992 
 9993 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
 9994 %{
 9995   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
 9996 
 9997   ins_cost(INSN_COST * 3);
 9998 
 9999   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10000   ins_encode %{
10001     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10002     __ fcseld(as_FloatRegister($dst$$reg),
10003               as_FloatRegister($src2$$reg),
10004               as_FloatRegister($src1$$reg),
10005               cond);
10006   %}
10007 
10008   ins_pipe(fp_cond_reg_reg_d);
10009 %}
10010 
10011 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10012 %{
10013   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10014 
10015   ins_cost(INSN_COST * 3);
10016 
10017   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10018   ins_encode %{
10019     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10020     __ fcseld(as_FloatRegister($dst$$reg),
10021               as_FloatRegister($src2$$reg),
10022               as_FloatRegister($src1$$reg),
10023               cond);
10024   %}
10025 
10026   ins_pipe(fp_cond_reg_reg_d);
10027 %}
10028 
10029 // ============================================================================
10030 // Arithmetic Instructions
10031 //
10032 
10033 // Integer Addition
10034 
10035 // TODO
10036 // these currently employ operations which do not set CR and hence are
10037 // not flagged as killing CR but we would like to isolate the cases
10038 // where we want to set flags from those where we don&#39;t. need to work
10039 // out how to do that.
10040 
10041 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10042   match(Set dst (AddI src1 src2));
10043 
10044   ins_cost(INSN_COST);
10045   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10046 
10047   ins_encode %{
10048     __ addw(as_Register($dst$$reg),
10049             as_Register($src1$$reg),
10050             as_Register($src2$$reg));
10051   %}
10052 
10053   ins_pipe(ialu_reg_reg);
10054 %}
10055 
10056 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10057   match(Set dst (AddI src1 src2));
10058 
10059   ins_cost(INSN_COST);
10060   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10061 
10062   // use opcode to indicate that this is an add not a sub
10063   opcode(0x0);
10064 
10065   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10066 
10067   ins_pipe(ialu_reg_imm);
10068 %}
10069 
10070 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10071   match(Set dst (AddI (ConvL2I src1) src2));
10072 
10073   ins_cost(INSN_COST);
10074   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10075 
10076   // use opcode to indicate that this is an add not a sub
10077   opcode(0x0);
10078 
10079   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10080 
10081   ins_pipe(ialu_reg_imm);
10082 %}
10083 
10084 // Pointer Addition
10085 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10086   match(Set dst (AddP src1 src2));
10087 
10088   ins_cost(INSN_COST);
10089   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10090 
10091   ins_encode %{
10092     __ add(as_Register($dst$$reg),
10093            as_Register($src1$$reg),
10094            as_Register($src2$$reg));
10095   %}
10096 
10097   ins_pipe(ialu_reg_reg);
10098 %}
10099 
10100 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10101   match(Set dst (AddP src1 (ConvI2L src2)));
10102 
10103   ins_cost(1.9 * INSN_COST);
10104   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10105 
10106   ins_encode %{
10107     __ add(as_Register($dst$$reg),
10108            as_Register($src1$$reg),
10109            as_Register($src2$$reg), ext::sxtw);
10110   %}
10111 
10112   ins_pipe(ialu_reg_reg);
10113 %}
10114 
10115 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10116   match(Set dst (AddP src1 (LShiftL src2 scale)));
10117 
10118   ins_cost(1.9 * INSN_COST);
10119   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10120 
10121   ins_encode %{
10122     __ lea(as_Register($dst$$reg),
10123            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10124                    Address::lsl($scale$$constant)));
10125   %}
10126 
10127   ins_pipe(ialu_reg_reg_shift);
10128 %}
10129 
10130 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10131   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10132 
10133   ins_cost(1.9 * INSN_COST);
10134   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10135 
10136   ins_encode %{
10137     __ lea(as_Register($dst$$reg),
10138            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10139                    Address::sxtw($scale$$constant)));
10140   %}
10141 
10142   ins_pipe(ialu_reg_reg_shift);
10143 %}
10144 
10145 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10146   match(Set dst (LShiftL (ConvI2L src) scale));
10147 
10148   ins_cost(INSN_COST);
10149   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10150 
10151   ins_encode %{
10152     __ sbfiz(as_Register($dst$$reg),
10153           as_Register($src$$reg),
10154           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10155   %}
10156 
10157   ins_pipe(ialu_reg_shift);
10158 %}
10159 
10160 // Pointer Immediate Addition
10161 // n.b. this needs to be more expensive than using an indirect memory
10162 // operand
10163 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10164   match(Set dst (AddP src1 src2));
10165 
10166   ins_cost(INSN_COST);
10167   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10168 
10169   // use opcode to indicate that this is an add not a sub
10170   opcode(0x0);
10171 
10172   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10173 
10174   ins_pipe(ialu_reg_imm);
10175 %}
10176 
10177 // Long Addition
10178 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10179 
10180   match(Set dst (AddL src1 src2));
10181 
10182   ins_cost(INSN_COST);
10183   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10184 
10185   ins_encode %{
10186     __ add(as_Register($dst$$reg),
10187            as_Register($src1$$reg),
10188            as_Register($src2$$reg));
10189   %}
10190 
10191   ins_pipe(ialu_reg_reg);
10192 %}
10193 
10194 // No constant pool entries requiredLong Immediate Addition.
10195 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10196   match(Set dst (AddL src1 src2));
10197 
10198   ins_cost(INSN_COST);
10199   format %{ &quot;add $dst, $src1, $src2&quot; %}
10200 
10201   // use opcode to indicate that this is an add not a sub
10202   opcode(0x0);
10203 
10204   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10205 
10206   ins_pipe(ialu_reg_imm);
10207 %}
10208 
10209 // Integer Subtraction
10210 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10211   match(Set dst (SubI src1 src2));
10212 
10213   ins_cost(INSN_COST);
10214   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10215 
10216   ins_encode %{
10217     __ subw(as_Register($dst$$reg),
10218             as_Register($src1$$reg),
10219             as_Register($src2$$reg));
10220   %}
10221 
10222   ins_pipe(ialu_reg_reg);
10223 %}
10224 
10225 // Immediate Subtraction
10226 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10227   match(Set dst (SubI src1 src2));
10228 
10229   ins_cost(INSN_COST);
10230   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10231 
10232   // use opcode to indicate that this is a sub not an add
10233   opcode(0x1);
10234 
10235   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10236 
10237   ins_pipe(ialu_reg_imm);
10238 %}
10239 
10240 // Long Subtraction
10241 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10242 
10243   match(Set dst (SubL src1 src2));
10244 
10245   ins_cost(INSN_COST);
10246   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10247 
10248   ins_encode %{
10249     __ sub(as_Register($dst$$reg),
10250            as_Register($src1$$reg),
10251            as_Register($src2$$reg));
10252   %}
10253 
10254   ins_pipe(ialu_reg_reg);
10255 %}
10256 
10257 // No constant pool entries requiredLong Immediate Subtraction.
10258 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10259   match(Set dst (SubL src1 src2));
10260 
10261   ins_cost(INSN_COST);
10262   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10263 
10264   // use opcode to indicate that this is a sub not an add
10265   opcode(0x1);
10266 
10267   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10268 
10269   ins_pipe(ialu_reg_imm);
10270 %}
10271 
10272 // Integer Negation (special case for sub)
10273 
10274 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10275   match(Set dst (SubI zero src));
10276 
10277   ins_cost(INSN_COST);
10278   format %{ &quot;negw $dst, $src\t# int&quot; %}
10279 
10280   ins_encode %{
10281     __ negw(as_Register($dst$$reg),
10282             as_Register($src$$reg));
10283   %}
10284 
10285   ins_pipe(ialu_reg);
10286 %}
10287 
10288 // Long Negation
10289 
10290 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10291   match(Set dst (SubL zero src));
10292 
10293   ins_cost(INSN_COST);
10294   format %{ &quot;neg $dst, $src\t# long&quot; %}
10295 
10296   ins_encode %{
10297     __ neg(as_Register($dst$$reg),
10298            as_Register($src$$reg));
10299   %}
10300 
10301   ins_pipe(ialu_reg);
10302 %}
10303 
10304 // Integer Multiply
10305 
10306 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10307   match(Set dst (MulI src1 src2));
10308 
10309   ins_cost(INSN_COST * 3);
10310   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10311 
10312   ins_encode %{
10313     __ mulw(as_Register($dst$$reg),
10314             as_Register($src1$$reg),
10315             as_Register($src2$$reg));
10316   %}
10317 
10318   ins_pipe(imul_reg_reg);
10319 %}
10320 
10321 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10322   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10323 
10324   ins_cost(INSN_COST * 3);
10325   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10326 
10327   ins_encode %{
10328     __ smull(as_Register($dst$$reg),
10329              as_Register($src1$$reg),
10330              as_Register($src2$$reg));
10331   %}
10332 
10333   ins_pipe(imul_reg_reg);
10334 %}
10335 
10336 // Long Multiply
10337 
10338 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10339   match(Set dst (MulL src1 src2));
10340 
10341   ins_cost(INSN_COST * 5);
10342   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10343 
10344   ins_encode %{
10345     __ mul(as_Register($dst$$reg),
10346            as_Register($src1$$reg),
10347            as_Register($src2$$reg));
10348   %}
10349 
10350   ins_pipe(lmul_reg_reg);
10351 %}
10352 
10353 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10354 %{
10355   match(Set dst (MulHiL src1 src2));
10356 
10357   ins_cost(INSN_COST * 7);
10358   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10359 
10360   ins_encode %{
10361     __ smulh(as_Register($dst$$reg),
10362              as_Register($src1$$reg),
10363              as_Register($src2$$reg));
10364   %}
10365 
10366   ins_pipe(lmul_reg_reg);
10367 %}
10368 
10369 // Combined Integer Multiply &amp; Add/Sub
10370 
10371 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10372   match(Set dst (AddI src3 (MulI src1 src2)));
10373 
10374   ins_cost(INSN_COST * 3);
10375   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10376 
10377   ins_encode %{
10378     __ maddw(as_Register($dst$$reg),
10379              as_Register($src1$$reg),
10380              as_Register($src2$$reg),
10381              as_Register($src3$$reg));
10382   %}
10383 
10384   ins_pipe(imac_reg_reg);
10385 %}
10386 
10387 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10388   match(Set dst (SubI src3 (MulI src1 src2)));
10389 
10390   ins_cost(INSN_COST * 3);
10391   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10392 
10393   ins_encode %{
10394     __ msubw(as_Register($dst$$reg),
10395              as_Register($src1$$reg),
10396              as_Register($src2$$reg),
10397              as_Register($src3$$reg));
10398   %}
10399 
10400   ins_pipe(imac_reg_reg);
10401 %}
10402 
10403 // Combined Integer Multiply &amp; Neg
10404 
10405 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10406   match(Set dst (MulI (SubI zero src1) src2));
10407   match(Set dst (MulI src1 (SubI zero src2)));
10408 
10409   ins_cost(INSN_COST * 3);
10410   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10411 
10412   ins_encode %{
10413     __ mnegw(as_Register($dst$$reg),
10414              as_Register($src1$$reg),
10415              as_Register($src2$$reg));
10416   %}
10417 
10418   ins_pipe(imac_reg_reg);
10419 %}
10420 
10421 // Combined Long Multiply &amp; Add/Sub
10422 
10423 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10424   match(Set dst (AddL src3 (MulL src1 src2)));
10425 
10426   ins_cost(INSN_COST * 5);
10427   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10428 
10429   ins_encode %{
10430     __ madd(as_Register($dst$$reg),
10431             as_Register($src1$$reg),
10432             as_Register($src2$$reg),
10433             as_Register($src3$$reg));
10434   %}
10435 
10436   ins_pipe(lmac_reg_reg);
10437 %}
10438 
10439 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10440   match(Set dst (SubL src3 (MulL src1 src2)));
10441 
10442   ins_cost(INSN_COST * 5);
10443   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10444 
10445   ins_encode %{
10446     __ msub(as_Register($dst$$reg),
10447             as_Register($src1$$reg),
10448             as_Register($src2$$reg),
10449             as_Register($src3$$reg));
10450   %}
10451 
10452   ins_pipe(lmac_reg_reg);
10453 %}
10454 
10455 // Combined Long Multiply &amp; Neg
10456 
10457 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10458   match(Set dst (MulL (SubL zero src1) src2));
10459   match(Set dst (MulL src1 (SubL zero src2)));
10460 
10461   ins_cost(INSN_COST * 5);
10462   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10463 
10464   ins_encode %{
10465     __ mneg(as_Register($dst$$reg),
10466             as_Register($src1$$reg),
10467             as_Register($src2$$reg));
10468   %}
10469 
10470   ins_pipe(lmac_reg_reg);
10471 %}
10472 
10473 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10474 
10475 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10476   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10477 
10478   ins_cost(INSN_COST * 3);
10479   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10480 
10481   ins_encode %{
10482     __ smaddl(as_Register($dst$$reg),
10483               as_Register($src1$$reg),
10484               as_Register($src2$$reg),
10485               as_Register($src3$$reg));
10486   %}
10487 
10488   ins_pipe(imac_reg_reg);
10489 %}
10490 
10491 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10492   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10493 
10494   ins_cost(INSN_COST * 3);
10495   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10496 
10497   ins_encode %{
10498     __ smsubl(as_Register($dst$$reg),
10499               as_Register($src1$$reg),
10500               as_Register($src2$$reg),
10501               as_Register($src3$$reg));
10502   %}
10503 
10504   ins_pipe(imac_reg_reg);
10505 %}
10506 
10507 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10508   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10509   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10510 
10511   ins_cost(INSN_COST * 3);
10512   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10513 
10514   ins_encode %{
10515     __ smnegl(as_Register($dst$$reg),
10516               as_Register($src1$$reg),
10517               as_Register($src2$$reg));
10518   %}
10519 
10520   ins_pipe(imac_reg_reg);
10521 %}
10522 
10523 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10524 
10525 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10526   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10527 
10528   ins_cost(INSN_COST * 5);
10529   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10530             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10531 
10532   ins_encode %{
10533     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10534     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10535 
10536   ins_pipe(imac_reg_reg);
10537 %}
10538 
10539 // Integer Divide
10540 
10541 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10542   match(Set dst (DivI src1 src2));
10543 
10544   ins_cost(INSN_COST * 19);
10545   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10546 
10547   ins_encode(aarch64_enc_divw(dst, src1, src2));
10548   ins_pipe(idiv_reg_reg);
10549 %}
10550 
10551 // Long Divide
10552 
10553 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10554   match(Set dst (DivL src1 src2));
10555 
10556   ins_cost(INSN_COST * 35);
10557   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10558 
10559   ins_encode(aarch64_enc_div(dst, src1, src2));
10560   ins_pipe(ldiv_reg_reg);
10561 %}
10562 
10563 // Integer Remainder
10564 
10565 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10566   match(Set dst (ModI src1 src2));
10567 
10568   ins_cost(INSN_COST * 22);
10569   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10570             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10571 
10572   ins_encode(aarch64_enc_modw(dst, src1, src2));
10573   ins_pipe(idiv_reg_reg);
10574 %}
10575 
10576 // Long Remainder
10577 
10578 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10579   match(Set dst (ModL src1 src2));
10580 
10581   ins_cost(INSN_COST * 38);
10582   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10583             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10584 
10585   ins_encode(aarch64_enc_mod(dst, src1, src2));
10586   ins_pipe(ldiv_reg_reg);
10587 %}
10588 
10589 // Integer Shifts
10590 
10591 // Shift Left Register
10592 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10593   match(Set dst (LShiftI src1 src2));
10594 
10595   ins_cost(INSN_COST * 2);
10596   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10597 
10598   ins_encode %{
10599     __ lslvw(as_Register($dst$$reg),
10600              as_Register($src1$$reg),
10601              as_Register($src2$$reg));
10602   %}
10603 
10604   ins_pipe(ialu_reg_reg_vshift);
10605 %}
10606 
10607 // Shift Left Immediate
10608 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10609   match(Set dst (LShiftI src1 src2));
10610 
10611   ins_cost(INSN_COST);
10612   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10613 
10614   ins_encode %{
10615     __ lslw(as_Register($dst$$reg),
10616             as_Register($src1$$reg),
10617             $src2$$constant &amp; 0x1f);
10618   %}
10619 
10620   ins_pipe(ialu_reg_shift);
10621 %}
10622 
10623 // Shift Right Logical Register
10624 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10625   match(Set dst (URShiftI src1 src2));
10626 
10627   ins_cost(INSN_COST * 2);
10628   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10629 
10630   ins_encode %{
10631     __ lsrvw(as_Register($dst$$reg),
10632              as_Register($src1$$reg),
10633              as_Register($src2$$reg));
10634   %}
10635 
10636   ins_pipe(ialu_reg_reg_vshift);
10637 %}
10638 
10639 // Shift Right Logical Immediate
10640 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10641   match(Set dst (URShiftI src1 src2));
10642 
10643   ins_cost(INSN_COST);
10644   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10645 
10646   ins_encode %{
10647     __ lsrw(as_Register($dst$$reg),
10648             as_Register($src1$$reg),
10649             $src2$$constant &amp; 0x1f);
10650   %}
10651 
10652   ins_pipe(ialu_reg_shift);
10653 %}
10654 
10655 // Shift Right Arithmetic Register
10656 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10657   match(Set dst (RShiftI src1 src2));
10658 
10659   ins_cost(INSN_COST * 2);
10660   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10661 
10662   ins_encode %{
10663     __ asrvw(as_Register($dst$$reg),
10664              as_Register($src1$$reg),
10665              as_Register($src2$$reg));
10666   %}
10667 
10668   ins_pipe(ialu_reg_reg_vshift);
10669 %}
10670 
10671 // Shift Right Arithmetic Immediate
10672 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10673   match(Set dst (RShiftI src1 src2));
10674 
10675   ins_cost(INSN_COST);
10676   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10677 
10678   ins_encode %{
10679     __ asrw(as_Register($dst$$reg),
10680             as_Register($src1$$reg),
10681             $src2$$constant &amp; 0x1f);
10682   %}
10683 
10684   ins_pipe(ialu_reg_shift);
10685 %}
10686 
10687 // Combined Int Mask and Right Shift (using UBFM)
10688 // TODO
10689 
10690 // Long Shifts
10691 
10692 // Shift Left Register
10693 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10694   match(Set dst (LShiftL src1 src2));
10695 
10696   ins_cost(INSN_COST * 2);
10697   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10698 
10699   ins_encode %{
10700     __ lslv(as_Register($dst$$reg),
10701             as_Register($src1$$reg),
10702             as_Register($src2$$reg));
10703   %}
10704 
10705   ins_pipe(ialu_reg_reg_vshift);
10706 %}
10707 
10708 // Shift Left Immediate
10709 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10710   match(Set dst (LShiftL src1 src2));
10711 
10712   ins_cost(INSN_COST);
10713   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10714 
10715   ins_encode %{
10716     __ lsl(as_Register($dst$$reg),
10717             as_Register($src1$$reg),
10718             $src2$$constant &amp; 0x3f);
10719   %}
10720 
10721   ins_pipe(ialu_reg_shift);
10722 %}
10723 
10724 // Shift Right Logical Register
10725 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10726   match(Set dst (URShiftL src1 src2));
10727 
10728   ins_cost(INSN_COST * 2);
10729   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10730 
10731   ins_encode %{
10732     __ lsrv(as_Register($dst$$reg),
10733             as_Register($src1$$reg),
10734             as_Register($src2$$reg));
10735   %}
10736 
10737   ins_pipe(ialu_reg_reg_vshift);
10738 %}
10739 
10740 // Shift Right Logical Immediate
10741 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10742   match(Set dst (URShiftL src1 src2));
10743 
10744   ins_cost(INSN_COST);
10745   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10746 
10747   ins_encode %{
10748     __ lsr(as_Register($dst$$reg),
10749            as_Register($src1$$reg),
10750            $src2$$constant &amp; 0x3f);
10751   %}
10752 
10753   ins_pipe(ialu_reg_shift);
10754 %}
10755 
10756 // A special-case pattern for card table stores.
10757 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10758   match(Set dst (URShiftL (CastP2X src1) src2));
10759 
10760   ins_cost(INSN_COST);
10761   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10762 
10763   ins_encode %{
10764     __ lsr(as_Register($dst$$reg),
10765            as_Register($src1$$reg),
10766            $src2$$constant &amp; 0x3f);
10767   %}
10768 
10769   ins_pipe(ialu_reg_shift);
10770 %}
10771 
10772 // Shift Right Arithmetic Register
10773 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10774   match(Set dst (RShiftL src1 src2));
10775 
10776   ins_cost(INSN_COST * 2);
10777   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10778 
10779   ins_encode %{
10780     __ asrv(as_Register($dst$$reg),
10781             as_Register($src1$$reg),
10782             as_Register($src2$$reg));
10783   %}
10784 
10785   ins_pipe(ialu_reg_reg_vshift);
10786 %}
10787 
10788 // Shift Right Arithmetic Immediate
10789 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10790   match(Set dst (RShiftL src1 src2));
10791 
10792   ins_cost(INSN_COST);
10793   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10794 
10795   ins_encode %{
10796     __ asr(as_Register($dst$$reg),
10797            as_Register($src1$$reg),
10798            $src2$$constant &amp; 0x3f);
10799   %}
10800 
10801   ins_pipe(ialu_reg_shift);
10802 %}
10803 
10804 // BEGIN This section of the file is automatically generated. Do not edit --------------
10805 
10806 instruct regL_not_reg(iRegLNoSp dst,
10807                          iRegL src1, immL_M1 m1,
10808                          rFlagsReg cr) %{
10809   match(Set dst (XorL src1 m1));
10810   ins_cost(INSN_COST);
10811   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10812 
10813   ins_encode %{
10814     __ eon(as_Register($dst$$reg),
10815               as_Register($src1$$reg),
10816               zr,
10817               Assembler::LSL, 0);
10818   %}
10819 
10820   ins_pipe(ialu_reg);
10821 %}
10822 instruct regI_not_reg(iRegINoSp dst,
10823                          iRegIorL2I src1, immI_M1 m1,
10824                          rFlagsReg cr) %{
10825   match(Set dst (XorI src1 m1));
10826   ins_cost(INSN_COST);
10827   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10828 
10829   ins_encode %{
10830     __ eonw(as_Register($dst$$reg),
10831               as_Register($src1$$reg),
10832               zr,
10833               Assembler::LSL, 0);
10834   %}
10835 
10836   ins_pipe(ialu_reg);
10837 %}
10838 
10839 instruct AndI_reg_not_reg(iRegINoSp dst,
10840                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10841                          rFlagsReg cr) %{
10842   match(Set dst (AndI src1 (XorI src2 m1)));
10843   ins_cost(INSN_COST);
10844   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10845 
10846   ins_encode %{
10847     __ bicw(as_Register($dst$$reg),
10848               as_Register($src1$$reg),
10849               as_Register($src2$$reg),
10850               Assembler::LSL, 0);
10851   %}
10852 
10853   ins_pipe(ialu_reg_reg);
10854 %}
10855 
10856 instruct AndL_reg_not_reg(iRegLNoSp dst,
10857                          iRegL src1, iRegL src2, immL_M1 m1,
10858                          rFlagsReg cr) %{
10859   match(Set dst (AndL src1 (XorL src2 m1)));
10860   ins_cost(INSN_COST);
10861   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10862 
10863   ins_encode %{
10864     __ bic(as_Register($dst$$reg),
10865               as_Register($src1$$reg),
10866               as_Register($src2$$reg),
10867               Assembler::LSL, 0);
10868   %}
10869 
10870   ins_pipe(ialu_reg_reg);
10871 %}
10872 
10873 instruct OrI_reg_not_reg(iRegINoSp dst,
10874                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10875                          rFlagsReg cr) %{
10876   match(Set dst (OrI src1 (XorI src2 m1)));
10877   ins_cost(INSN_COST);
10878   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10879 
10880   ins_encode %{
10881     __ ornw(as_Register($dst$$reg),
10882               as_Register($src1$$reg),
10883               as_Register($src2$$reg),
10884               Assembler::LSL, 0);
10885   %}
10886 
10887   ins_pipe(ialu_reg_reg);
10888 %}
10889 
10890 instruct OrL_reg_not_reg(iRegLNoSp dst,
10891                          iRegL src1, iRegL src2, immL_M1 m1,
10892                          rFlagsReg cr) %{
10893   match(Set dst (OrL src1 (XorL src2 m1)));
10894   ins_cost(INSN_COST);
10895   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10896 
10897   ins_encode %{
10898     __ orn(as_Register($dst$$reg),
10899               as_Register($src1$$reg),
10900               as_Register($src2$$reg),
10901               Assembler::LSL, 0);
10902   %}
10903 
10904   ins_pipe(ialu_reg_reg);
10905 %}
10906 
10907 instruct XorI_reg_not_reg(iRegINoSp dst,
10908                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10909                          rFlagsReg cr) %{
10910   match(Set dst (XorI m1 (XorI src2 src1)));
10911   ins_cost(INSN_COST);
10912   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10913 
10914   ins_encode %{
10915     __ eonw(as_Register($dst$$reg),
10916               as_Register($src1$$reg),
10917               as_Register($src2$$reg),
10918               Assembler::LSL, 0);
10919   %}
10920 
10921   ins_pipe(ialu_reg_reg);
10922 %}
10923 
10924 instruct XorL_reg_not_reg(iRegLNoSp dst,
10925                          iRegL src1, iRegL src2, immL_M1 m1,
10926                          rFlagsReg cr) %{
10927   match(Set dst (XorL m1 (XorL src2 src1)));
10928   ins_cost(INSN_COST);
10929   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10930 
10931   ins_encode %{
10932     __ eon(as_Register($dst$$reg),
10933               as_Register($src1$$reg),
10934               as_Register($src2$$reg),
10935               Assembler::LSL, 0);
10936   %}
10937 
10938   ins_pipe(ialu_reg_reg);
10939 %}
10940 
10941 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
10942                          iRegIorL2I src1, iRegIorL2I src2,
10943                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10944   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
10945   ins_cost(1.9 * INSN_COST);
10946   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
10947 
10948   ins_encode %{
10949     __ bicw(as_Register($dst$$reg),
10950               as_Register($src1$$reg),
10951               as_Register($src2$$reg),
10952               Assembler::LSR,
10953               $src3$$constant &amp; 0x1f);
10954   %}
10955 
10956   ins_pipe(ialu_reg_reg_shift);
10957 %}
10958 
10959 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
10960                          iRegL src1, iRegL src2,
10961                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10962   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
10963   ins_cost(1.9 * INSN_COST);
10964   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
10965 
10966   ins_encode %{
10967     __ bic(as_Register($dst$$reg),
10968               as_Register($src1$$reg),
10969               as_Register($src2$$reg),
10970               Assembler::LSR,
10971               $src3$$constant &amp; 0x3f);
10972   %}
10973 
10974   ins_pipe(ialu_reg_reg_shift);
10975 %}
10976 
10977 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
10978                          iRegIorL2I src1, iRegIorL2I src2,
10979                          immI src3, immI_M1 src4, rFlagsReg cr) %{
10980   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
10981   ins_cost(1.9 * INSN_COST);
10982   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
10983 
10984   ins_encode %{
10985     __ bicw(as_Register($dst$$reg),
10986               as_Register($src1$$reg),
10987               as_Register($src2$$reg),
10988               Assembler::ASR,
10989               $src3$$constant &amp; 0x1f);
10990   %}
10991 
10992   ins_pipe(ialu_reg_reg_shift);
10993 %}
10994 
10995 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
10996                          iRegL src1, iRegL src2,
10997                          immI src3, immL_M1 src4, rFlagsReg cr) %{
10998   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
10999   ins_cost(1.9 * INSN_COST);
11000   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11001 
11002   ins_encode %{
11003     __ bic(as_Register($dst$$reg),
11004               as_Register($src1$$reg),
11005               as_Register($src2$$reg),
11006               Assembler::ASR,
11007               $src3$$constant &amp; 0x3f);
11008   %}
11009 
11010   ins_pipe(ialu_reg_reg_shift);
11011 %}
11012 
11013 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11014                          iRegIorL2I src1, iRegIorL2I src2,
11015                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11016   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11017   ins_cost(1.9 * INSN_COST);
11018   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11019 
11020   ins_encode %{
11021     __ bicw(as_Register($dst$$reg),
11022               as_Register($src1$$reg),
11023               as_Register($src2$$reg),
11024               Assembler::LSL,
11025               $src3$$constant &amp; 0x1f);
11026   %}
11027 
11028   ins_pipe(ialu_reg_reg_shift);
11029 %}
11030 
11031 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11032                          iRegL src1, iRegL src2,
11033                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11034   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11035   ins_cost(1.9 * INSN_COST);
11036   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11037 
11038   ins_encode %{
11039     __ bic(as_Register($dst$$reg),
11040               as_Register($src1$$reg),
11041               as_Register($src2$$reg),
11042               Assembler::LSL,
11043               $src3$$constant &amp; 0x3f);
11044   %}
11045 
11046   ins_pipe(ialu_reg_reg_shift);
11047 %}
11048 
11049 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11050                          iRegIorL2I src1, iRegIorL2I src2,
11051                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11052   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11053   ins_cost(1.9 * INSN_COST);
11054   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11055 
11056   ins_encode %{
11057     __ eonw(as_Register($dst$$reg),
11058               as_Register($src1$$reg),
11059               as_Register($src2$$reg),
11060               Assembler::LSR,
11061               $src3$$constant &amp; 0x1f);
11062   %}
11063 
11064   ins_pipe(ialu_reg_reg_shift);
11065 %}
11066 
11067 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11068                          iRegL src1, iRegL src2,
11069                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11070   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11071   ins_cost(1.9 * INSN_COST);
11072   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11073 
11074   ins_encode %{
11075     __ eon(as_Register($dst$$reg),
11076               as_Register($src1$$reg),
11077               as_Register($src2$$reg),
11078               Assembler::LSR,
11079               $src3$$constant &amp; 0x3f);
11080   %}
11081 
11082   ins_pipe(ialu_reg_reg_shift);
11083 %}
11084 
11085 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11086                          iRegIorL2I src1, iRegIorL2I src2,
11087                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11088   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11089   ins_cost(1.9 * INSN_COST);
11090   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11091 
11092   ins_encode %{
11093     __ eonw(as_Register($dst$$reg),
11094               as_Register($src1$$reg),
11095               as_Register($src2$$reg),
11096               Assembler::ASR,
11097               $src3$$constant &amp; 0x1f);
11098   %}
11099 
11100   ins_pipe(ialu_reg_reg_shift);
11101 %}
11102 
11103 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11104                          iRegL src1, iRegL src2,
11105                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11106   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11107   ins_cost(1.9 * INSN_COST);
11108   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11109 
11110   ins_encode %{
11111     __ eon(as_Register($dst$$reg),
11112               as_Register($src1$$reg),
11113               as_Register($src2$$reg),
11114               Assembler::ASR,
11115               $src3$$constant &amp; 0x3f);
11116   %}
11117 
11118   ins_pipe(ialu_reg_reg_shift);
11119 %}
11120 
11121 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11122                          iRegIorL2I src1, iRegIorL2I src2,
11123                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11124   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11125   ins_cost(1.9 * INSN_COST);
11126   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11127 
11128   ins_encode %{
11129     __ eonw(as_Register($dst$$reg),
11130               as_Register($src1$$reg),
11131               as_Register($src2$$reg),
11132               Assembler::LSL,
11133               $src3$$constant &amp; 0x1f);
11134   %}
11135 
11136   ins_pipe(ialu_reg_reg_shift);
11137 %}
11138 
11139 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11140                          iRegL src1, iRegL src2,
11141                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11142   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11143   ins_cost(1.9 * INSN_COST);
11144   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11145 
11146   ins_encode %{
11147     __ eon(as_Register($dst$$reg),
11148               as_Register($src1$$reg),
11149               as_Register($src2$$reg),
11150               Assembler::LSL,
11151               $src3$$constant &amp; 0x3f);
11152   %}
11153 
11154   ins_pipe(ialu_reg_reg_shift);
11155 %}
11156 
11157 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11158                          iRegIorL2I src1, iRegIorL2I src2,
11159                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11160   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11161   ins_cost(1.9 * INSN_COST);
11162   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11163 
11164   ins_encode %{
11165     __ ornw(as_Register($dst$$reg),
11166               as_Register($src1$$reg),
11167               as_Register($src2$$reg),
11168               Assembler::LSR,
11169               $src3$$constant &amp; 0x1f);
11170   %}
11171 
11172   ins_pipe(ialu_reg_reg_shift);
11173 %}
11174 
11175 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11176                          iRegL src1, iRegL src2,
11177                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11178   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11179   ins_cost(1.9 * INSN_COST);
11180   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11181 
11182   ins_encode %{
11183     __ orn(as_Register($dst$$reg),
11184               as_Register($src1$$reg),
11185               as_Register($src2$$reg),
11186               Assembler::LSR,
11187               $src3$$constant &amp; 0x3f);
11188   %}
11189 
11190   ins_pipe(ialu_reg_reg_shift);
11191 %}
11192 
11193 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11194                          iRegIorL2I src1, iRegIorL2I src2,
11195                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11196   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11197   ins_cost(1.9 * INSN_COST);
11198   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11199 
11200   ins_encode %{
11201     __ ornw(as_Register($dst$$reg),
11202               as_Register($src1$$reg),
11203               as_Register($src2$$reg),
11204               Assembler::ASR,
11205               $src3$$constant &amp; 0x1f);
11206   %}
11207 
11208   ins_pipe(ialu_reg_reg_shift);
11209 %}
11210 
11211 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11212                          iRegL src1, iRegL src2,
11213                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11214   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11215   ins_cost(1.9 * INSN_COST);
11216   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11217 
11218   ins_encode %{
11219     __ orn(as_Register($dst$$reg),
11220               as_Register($src1$$reg),
11221               as_Register($src2$$reg),
11222               Assembler::ASR,
11223               $src3$$constant &amp; 0x3f);
11224   %}
11225 
11226   ins_pipe(ialu_reg_reg_shift);
11227 %}
11228 
11229 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11230                          iRegIorL2I src1, iRegIorL2I src2,
11231                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11232   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11233   ins_cost(1.9 * INSN_COST);
11234   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11235 
11236   ins_encode %{
11237     __ ornw(as_Register($dst$$reg),
11238               as_Register($src1$$reg),
11239               as_Register($src2$$reg),
11240               Assembler::LSL,
11241               $src3$$constant &amp; 0x1f);
11242   %}
11243 
11244   ins_pipe(ialu_reg_reg_shift);
11245 %}
11246 
11247 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11248                          iRegL src1, iRegL src2,
11249                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11250   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11251   ins_cost(1.9 * INSN_COST);
11252   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11253 
11254   ins_encode %{
11255     __ orn(as_Register($dst$$reg),
11256               as_Register($src1$$reg),
11257               as_Register($src2$$reg),
11258               Assembler::LSL,
11259               $src3$$constant &amp; 0x3f);
11260   %}
11261 
11262   ins_pipe(ialu_reg_reg_shift);
11263 %}
11264 
11265 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11266                          iRegIorL2I src1, iRegIorL2I src2,
11267                          immI src3, rFlagsReg cr) %{
11268   match(Set dst (AndI src1 (URShiftI src2 src3)));
11269 
11270   ins_cost(1.9 * INSN_COST);
11271   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11272 
11273   ins_encode %{
11274     __ andw(as_Register($dst$$reg),
11275               as_Register($src1$$reg),
11276               as_Register($src2$$reg),
11277               Assembler::LSR,
11278               $src3$$constant &amp; 0x1f);
11279   %}
11280 
11281   ins_pipe(ialu_reg_reg_shift);
11282 %}
11283 
11284 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11285                          iRegL src1, iRegL src2,
11286                          immI src3, rFlagsReg cr) %{
11287   match(Set dst (AndL src1 (URShiftL src2 src3)));
11288 
11289   ins_cost(1.9 * INSN_COST);
11290   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11291 
11292   ins_encode %{
11293     __ andr(as_Register($dst$$reg),
11294               as_Register($src1$$reg),
11295               as_Register($src2$$reg),
11296               Assembler::LSR,
11297               $src3$$constant &amp; 0x3f);
11298   %}
11299 
11300   ins_pipe(ialu_reg_reg_shift);
11301 %}
11302 
11303 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11304                          iRegIorL2I src1, iRegIorL2I src2,
11305                          immI src3, rFlagsReg cr) %{
11306   match(Set dst (AndI src1 (RShiftI src2 src3)));
11307 
11308   ins_cost(1.9 * INSN_COST);
11309   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11310 
11311   ins_encode %{
11312     __ andw(as_Register($dst$$reg),
11313               as_Register($src1$$reg),
11314               as_Register($src2$$reg),
11315               Assembler::ASR,
11316               $src3$$constant &amp; 0x1f);
11317   %}
11318 
11319   ins_pipe(ialu_reg_reg_shift);
11320 %}
11321 
11322 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11323                          iRegL src1, iRegL src2,
11324                          immI src3, rFlagsReg cr) %{
11325   match(Set dst (AndL src1 (RShiftL src2 src3)));
11326 
11327   ins_cost(1.9 * INSN_COST);
11328   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11329 
11330   ins_encode %{
11331     __ andr(as_Register($dst$$reg),
11332               as_Register($src1$$reg),
11333               as_Register($src2$$reg),
11334               Assembler::ASR,
11335               $src3$$constant &amp; 0x3f);
11336   %}
11337 
11338   ins_pipe(ialu_reg_reg_shift);
11339 %}
11340 
11341 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11342                          iRegIorL2I src1, iRegIorL2I src2,
11343                          immI src3, rFlagsReg cr) %{
11344   match(Set dst (AndI src1 (LShiftI src2 src3)));
11345 
11346   ins_cost(1.9 * INSN_COST);
11347   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11348 
11349   ins_encode %{
11350     __ andw(as_Register($dst$$reg),
11351               as_Register($src1$$reg),
11352               as_Register($src2$$reg),
11353               Assembler::LSL,
11354               $src3$$constant &amp; 0x1f);
11355   %}
11356 
11357   ins_pipe(ialu_reg_reg_shift);
11358 %}
11359 
11360 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11361                          iRegL src1, iRegL src2,
11362                          immI src3, rFlagsReg cr) %{
11363   match(Set dst (AndL src1 (LShiftL src2 src3)));
11364 
11365   ins_cost(1.9 * INSN_COST);
11366   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11367 
11368   ins_encode %{
11369     __ andr(as_Register($dst$$reg),
11370               as_Register($src1$$reg),
11371               as_Register($src2$$reg),
11372               Assembler::LSL,
11373               $src3$$constant &amp; 0x3f);
11374   %}
11375 
11376   ins_pipe(ialu_reg_reg_shift);
11377 %}
11378 
11379 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11380                          iRegIorL2I src1, iRegIorL2I src2,
11381                          immI src3, rFlagsReg cr) %{
11382   match(Set dst (XorI src1 (URShiftI src2 src3)));
11383 
11384   ins_cost(1.9 * INSN_COST);
11385   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11386 
11387   ins_encode %{
11388     __ eorw(as_Register($dst$$reg),
11389               as_Register($src1$$reg),
11390               as_Register($src2$$reg),
11391               Assembler::LSR,
11392               $src3$$constant &amp; 0x1f);
11393   %}
11394 
11395   ins_pipe(ialu_reg_reg_shift);
11396 %}
11397 
11398 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11399                          iRegL src1, iRegL src2,
11400                          immI src3, rFlagsReg cr) %{
11401   match(Set dst (XorL src1 (URShiftL src2 src3)));
11402 
11403   ins_cost(1.9 * INSN_COST);
11404   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11405 
11406   ins_encode %{
11407     __ eor(as_Register($dst$$reg),
11408               as_Register($src1$$reg),
11409               as_Register($src2$$reg),
11410               Assembler::LSR,
11411               $src3$$constant &amp; 0x3f);
11412   %}
11413 
11414   ins_pipe(ialu_reg_reg_shift);
11415 %}
11416 
11417 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11418                          iRegIorL2I src1, iRegIorL2I src2,
11419                          immI src3, rFlagsReg cr) %{
11420   match(Set dst (XorI src1 (RShiftI src2 src3)));
11421 
11422   ins_cost(1.9 * INSN_COST);
11423   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11424 
11425   ins_encode %{
11426     __ eorw(as_Register($dst$$reg),
11427               as_Register($src1$$reg),
11428               as_Register($src2$$reg),
11429               Assembler::ASR,
11430               $src3$$constant &amp; 0x1f);
11431   %}
11432 
11433   ins_pipe(ialu_reg_reg_shift);
11434 %}
11435 
11436 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11437                          iRegL src1, iRegL src2,
11438                          immI src3, rFlagsReg cr) %{
11439   match(Set dst (XorL src1 (RShiftL src2 src3)));
11440 
11441   ins_cost(1.9 * INSN_COST);
11442   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11443 
11444   ins_encode %{
11445     __ eor(as_Register($dst$$reg),
11446               as_Register($src1$$reg),
11447               as_Register($src2$$reg),
11448               Assembler::ASR,
11449               $src3$$constant &amp; 0x3f);
11450   %}
11451 
11452   ins_pipe(ialu_reg_reg_shift);
11453 %}
11454 
11455 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11456                          iRegIorL2I src1, iRegIorL2I src2,
11457                          immI src3, rFlagsReg cr) %{
11458   match(Set dst (XorI src1 (LShiftI src2 src3)));
11459 
11460   ins_cost(1.9 * INSN_COST);
11461   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11462 
11463   ins_encode %{
11464     __ eorw(as_Register($dst$$reg),
11465               as_Register($src1$$reg),
11466               as_Register($src2$$reg),
11467               Assembler::LSL,
11468               $src3$$constant &amp; 0x1f);
11469   %}
11470 
11471   ins_pipe(ialu_reg_reg_shift);
11472 %}
11473 
11474 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11475                          iRegL src1, iRegL src2,
11476                          immI src3, rFlagsReg cr) %{
11477   match(Set dst (XorL src1 (LShiftL src2 src3)));
11478 
11479   ins_cost(1.9 * INSN_COST);
11480   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11481 
11482   ins_encode %{
11483     __ eor(as_Register($dst$$reg),
11484               as_Register($src1$$reg),
11485               as_Register($src2$$reg),
11486               Assembler::LSL,
11487               $src3$$constant &amp; 0x3f);
11488   %}
11489 
11490   ins_pipe(ialu_reg_reg_shift);
11491 %}
11492 
11493 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11494                          iRegIorL2I src1, iRegIorL2I src2,
11495                          immI src3, rFlagsReg cr) %{
11496   match(Set dst (OrI src1 (URShiftI src2 src3)));
11497 
11498   ins_cost(1.9 * INSN_COST);
11499   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11500 
11501   ins_encode %{
11502     __ orrw(as_Register($dst$$reg),
11503               as_Register($src1$$reg),
11504               as_Register($src2$$reg),
11505               Assembler::LSR,
11506               $src3$$constant &amp; 0x1f);
11507   %}
11508 
11509   ins_pipe(ialu_reg_reg_shift);
11510 %}
11511 
11512 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11513                          iRegL src1, iRegL src2,
11514                          immI src3, rFlagsReg cr) %{
11515   match(Set dst (OrL src1 (URShiftL src2 src3)));
11516 
11517   ins_cost(1.9 * INSN_COST);
11518   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11519 
11520   ins_encode %{
11521     __ orr(as_Register($dst$$reg),
11522               as_Register($src1$$reg),
11523               as_Register($src2$$reg),
11524               Assembler::LSR,
11525               $src3$$constant &amp; 0x3f);
11526   %}
11527 
11528   ins_pipe(ialu_reg_reg_shift);
11529 %}
11530 
11531 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11532                          iRegIorL2I src1, iRegIorL2I src2,
11533                          immI src3, rFlagsReg cr) %{
11534   match(Set dst (OrI src1 (RShiftI src2 src3)));
11535 
11536   ins_cost(1.9 * INSN_COST);
11537   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11538 
11539   ins_encode %{
11540     __ orrw(as_Register($dst$$reg),
11541               as_Register($src1$$reg),
11542               as_Register($src2$$reg),
11543               Assembler::ASR,
11544               $src3$$constant &amp; 0x1f);
11545   %}
11546 
11547   ins_pipe(ialu_reg_reg_shift);
11548 %}
11549 
11550 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11551                          iRegL src1, iRegL src2,
11552                          immI src3, rFlagsReg cr) %{
11553   match(Set dst (OrL src1 (RShiftL src2 src3)));
11554 
11555   ins_cost(1.9 * INSN_COST);
11556   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11557 
11558   ins_encode %{
11559     __ orr(as_Register($dst$$reg),
11560               as_Register($src1$$reg),
11561               as_Register($src2$$reg),
11562               Assembler::ASR,
11563               $src3$$constant &amp; 0x3f);
11564   %}
11565 
11566   ins_pipe(ialu_reg_reg_shift);
11567 %}
11568 
11569 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11570                          iRegIorL2I src1, iRegIorL2I src2,
11571                          immI src3, rFlagsReg cr) %{
11572   match(Set dst (OrI src1 (LShiftI src2 src3)));
11573 
11574   ins_cost(1.9 * INSN_COST);
11575   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11576 
11577   ins_encode %{
11578     __ orrw(as_Register($dst$$reg),
11579               as_Register($src1$$reg),
11580               as_Register($src2$$reg),
11581               Assembler::LSL,
11582               $src3$$constant &amp; 0x1f);
11583   %}
11584 
11585   ins_pipe(ialu_reg_reg_shift);
11586 %}
11587 
11588 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11589                          iRegL src1, iRegL src2,
11590                          immI src3, rFlagsReg cr) %{
11591   match(Set dst (OrL src1 (LShiftL src2 src3)));
11592 
11593   ins_cost(1.9 * INSN_COST);
11594   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11595 
11596   ins_encode %{
11597     __ orr(as_Register($dst$$reg),
11598               as_Register($src1$$reg),
11599               as_Register($src2$$reg),
11600               Assembler::LSL,
11601               $src3$$constant &amp; 0x3f);
11602   %}
11603 
11604   ins_pipe(ialu_reg_reg_shift);
11605 %}
11606 
11607 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11608                          iRegIorL2I src1, iRegIorL2I src2,
11609                          immI src3, rFlagsReg cr) %{
11610   match(Set dst (AddI src1 (URShiftI src2 src3)));
11611 
11612   ins_cost(1.9 * INSN_COST);
11613   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11614 
11615   ins_encode %{
11616     __ addw(as_Register($dst$$reg),
11617               as_Register($src1$$reg),
11618               as_Register($src2$$reg),
11619               Assembler::LSR,
11620               $src3$$constant &amp; 0x1f);
11621   %}
11622 
11623   ins_pipe(ialu_reg_reg_shift);
11624 %}
11625 
11626 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11627                          iRegL src1, iRegL src2,
11628                          immI src3, rFlagsReg cr) %{
11629   match(Set dst (AddL src1 (URShiftL src2 src3)));
11630 
11631   ins_cost(1.9 * INSN_COST);
11632   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11633 
11634   ins_encode %{
11635     __ add(as_Register($dst$$reg),
11636               as_Register($src1$$reg),
11637               as_Register($src2$$reg),
11638               Assembler::LSR,
11639               $src3$$constant &amp; 0x3f);
11640   %}
11641 
11642   ins_pipe(ialu_reg_reg_shift);
11643 %}
11644 
11645 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11646                          iRegIorL2I src1, iRegIorL2I src2,
11647                          immI src3, rFlagsReg cr) %{
11648   match(Set dst (AddI src1 (RShiftI src2 src3)));
11649 
11650   ins_cost(1.9 * INSN_COST);
11651   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11652 
11653   ins_encode %{
11654     __ addw(as_Register($dst$$reg),
11655               as_Register($src1$$reg),
11656               as_Register($src2$$reg),
11657               Assembler::ASR,
11658               $src3$$constant &amp; 0x1f);
11659   %}
11660 
11661   ins_pipe(ialu_reg_reg_shift);
11662 %}
11663 
11664 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11665                          iRegL src1, iRegL src2,
11666                          immI src3, rFlagsReg cr) %{
11667   match(Set dst (AddL src1 (RShiftL src2 src3)));
11668 
11669   ins_cost(1.9 * INSN_COST);
11670   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11671 
11672   ins_encode %{
11673     __ add(as_Register($dst$$reg),
11674               as_Register($src1$$reg),
11675               as_Register($src2$$reg),
11676               Assembler::ASR,
11677               $src3$$constant &amp; 0x3f);
11678   %}
11679 
11680   ins_pipe(ialu_reg_reg_shift);
11681 %}
11682 
11683 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11684                          iRegIorL2I src1, iRegIorL2I src2,
11685                          immI src3, rFlagsReg cr) %{
11686   match(Set dst (AddI src1 (LShiftI src2 src3)));
11687 
11688   ins_cost(1.9 * INSN_COST);
11689   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11690 
11691   ins_encode %{
11692     __ addw(as_Register($dst$$reg),
11693               as_Register($src1$$reg),
11694               as_Register($src2$$reg),
11695               Assembler::LSL,
11696               $src3$$constant &amp; 0x1f);
11697   %}
11698 
11699   ins_pipe(ialu_reg_reg_shift);
11700 %}
11701 
11702 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11703                          iRegL src1, iRegL src2,
11704                          immI src3, rFlagsReg cr) %{
11705   match(Set dst (AddL src1 (LShiftL src2 src3)));
11706 
11707   ins_cost(1.9 * INSN_COST);
11708   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11709 
11710   ins_encode %{
11711     __ add(as_Register($dst$$reg),
11712               as_Register($src1$$reg),
11713               as_Register($src2$$reg),
11714               Assembler::LSL,
11715               $src3$$constant &amp; 0x3f);
11716   %}
11717 
11718   ins_pipe(ialu_reg_reg_shift);
11719 %}
11720 
11721 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11722                          iRegIorL2I src1, iRegIorL2I src2,
11723                          immI src3, rFlagsReg cr) %{
11724   match(Set dst (SubI src1 (URShiftI src2 src3)));
11725 
11726   ins_cost(1.9 * INSN_COST);
11727   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11728 
11729   ins_encode %{
11730     __ subw(as_Register($dst$$reg),
11731               as_Register($src1$$reg),
11732               as_Register($src2$$reg),
11733               Assembler::LSR,
11734               $src3$$constant &amp; 0x1f);
11735   %}
11736 
11737   ins_pipe(ialu_reg_reg_shift);
11738 %}
11739 
11740 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11741                          iRegL src1, iRegL src2,
11742                          immI src3, rFlagsReg cr) %{
11743   match(Set dst (SubL src1 (URShiftL src2 src3)));
11744 
11745   ins_cost(1.9 * INSN_COST);
11746   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11747 
11748   ins_encode %{
11749     __ sub(as_Register($dst$$reg),
11750               as_Register($src1$$reg),
11751               as_Register($src2$$reg),
11752               Assembler::LSR,
11753               $src3$$constant &amp; 0x3f);
11754   %}
11755 
11756   ins_pipe(ialu_reg_reg_shift);
11757 %}
11758 
11759 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11760                          iRegIorL2I src1, iRegIorL2I src2,
11761                          immI src3, rFlagsReg cr) %{
11762   match(Set dst (SubI src1 (RShiftI src2 src3)));
11763 
11764   ins_cost(1.9 * INSN_COST);
11765   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11766 
11767   ins_encode %{
11768     __ subw(as_Register($dst$$reg),
11769               as_Register($src1$$reg),
11770               as_Register($src2$$reg),
11771               Assembler::ASR,
11772               $src3$$constant &amp; 0x1f);
11773   %}
11774 
11775   ins_pipe(ialu_reg_reg_shift);
11776 %}
11777 
11778 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11779                          iRegL src1, iRegL src2,
11780                          immI src3, rFlagsReg cr) %{
11781   match(Set dst (SubL src1 (RShiftL src2 src3)));
11782 
11783   ins_cost(1.9 * INSN_COST);
11784   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11785 
11786   ins_encode %{
11787     __ sub(as_Register($dst$$reg),
11788               as_Register($src1$$reg),
11789               as_Register($src2$$reg),
11790               Assembler::ASR,
11791               $src3$$constant &amp; 0x3f);
11792   %}
11793 
11794   ins_pipe(ialu_reg_reg_shift);
11795 %}
11796 
11797 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11798                          iRegIorL2I src1, iRegIorL2I src2,
11799                          immI src3, rFlagsReg cr) %{
11800   match(Set dst (SubI src1 (LShiftI src2 src3)));
11801 
11802   ins_cost(1.9 * INSN_COST);
11803   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11804 
11805   ins_encode %{
11806     __ subw(as_Register($dst$$reg),
11807               as_Register($src1$$reg),
11808               as_Register($src2$$reg),
11809               Assembler::LSL,
11810               $src3$$constant &amp; 0x1f);
11811   %}
11812 
11813   ins_pipe(ialu_reg_reg_shift);
11814 %}
11815 
11816 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11817                          iRegL src1, iRegL src2,
11818                          immI src3, rFlagsReg cr) %{
11819   match(Set dst (SubL src1 (LShiftL src2 src3)));
11820 
11821   ins_cost(1.9 * INSN_COST);
11822   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11823 
11824   ins_encode %{
11825     __ sub(as_Register($dst$$reg),
11826               as_Register($src1$$reg),
11827               as_Register($src2$$reg),
11828               Assembler::LSL,
11829               $src3$$constant &amp; 0x3f);
11830   %}
11831 
11832   ins_pipe(ialu_reg_reg_shift);
11833 %}
11834 
11835 
11836 
11837 // Shift Left followed by Shift Right.
11838 // This idiom is used by the compiler for the i2b bytecode etc.
11839 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11840 %{
11841   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11842   ins_cost(INSN_COST * 2);
11843   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11844   ins_encode %{
11845     int lshift = $lshift_count$$constant &amp; 63;
11846     int rshift = $rshift_count$$constant &amp; 63;
11847     int s = 63 - lshift;
11848     int r = (rshift - lshift) &amp; 63;
11849     __ sbfm(as_Register($dst$$reg),
11850             as_Register($src$$reg),
11851             r, s);
11852   %}
11853 
11854   ins_pipe(ialu_reg_shift);
11855 %}
11856 
11857 // Shift Left followed by Shift Right.
11858 // This idiom is used by the compiler for the i2b bytecode etc.
11859 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11860 %{
11861   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11862   ins_cost(INSN_COST * 2);
11863   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11864   ins_encode %{
11865     int lshift = $lshift_count$$constant &amp; 31;
11866     int rshift = $rshift_count$$constant &amp; 31;
11867     int s = 31 - lshift;
11868     int r = (rshift - lshift) &amp; 31;
11869     __ sbfmw(as_Register($dst$$reg),
11870             as_Register($src$$reg),
11871             r, s);
11872   %}
11873 
11874   ins_pipe(ialu_reg_shift);
11875 %}
11876 
11877 // Shift Left followed by Shift Right.
11878 // This idiom is used by the compiler for the i2b bytecode etc.
11879 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11880 %{
11881   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11882   ins_cost(INSN_COST * 2);
11883   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11884   ins_encode %{
11885     int lshift = $lshift_count$$constant &amp; 63;
11886     int rshift = $rshift_count$$constant &amp; 63;
11887     int s = 63 - lshift;
11888     int r = (rshift - lshift) &amp; 63;
11889     __ ubfm(as_Register($dst$$reg),
11890             as_Register($src$$reg),
11891             r, s);
11892   %}
11893 
11894   ins_pipe(ialu_reg_shift);
11895 %}
11896 
11897 // Shift Left followed by Shift Right.
11898 // This idiom is used by the compiler for the i2b bytecode etc.
11899 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11900 %{
11901   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11902   ins_cost(INSN_COST * 2);
11903   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11904   ins_encode %{
11905     int lshift = $lshift_count$$constant &amp; 31;
11906     int rshift = $rshift_count$$constant &amp; 31;
11907     int s = 31 - lshift;
11908     int r = (rshift - lshift) &amp; 31;
11909     __ ubfmw(as_Register($dst$$reg),
11910             as_Register($src$$reg),
11911             r, s);
11912   %}
11913 
11914   ins_pipe(ialu_reg_shift);
11915 %}
11916 // Bitfield extract with shift &amp; mask
11917 
11918 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11919 %{
11920   match(Set dst (AndI (URShiftI src rshift) mask));
11921   // Make sure we are not going to exceed what ubfxw can do.
11922   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11923 
11924   ins_cost(INSN_COST);
11925   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11926   ins_encode %{
11927     int rshift = $rshift$$constant &amp; 31;
11928     long mask = $mask$$constant;
11929     int width = exact_log2(mask+1);
11930     __ ubfxw(as_Register($dst$$reg),
11931             as_Register($src$$reg), rshift, width);
11932   %}
11933   ins_pipe(ialu_reg_shift);
11934 %}
11935 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
11936 %{
11937   match(Set dst (AndL (URShiftL src rshift) mask));
11938   // Make sure we are not going to exceed what ubfx can do.
11939   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11940 
11941   ins_cost(INSN_COST);
11942   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11943   ins_encode %{
11944     int rshift = $rshift$$constant &amp; 63;
11945     long mask = $mask$$constant;
11946     int width = exact_log2_long(mask+1);
11947     __ ubfx(as_Register($dst$$reg),
11948             as_Register($src$$reg), rshift, width);
11949   %}
11950   ins_pipe(ialu_reg_shift);
11951 %}
11952 
11953 // We can use ubfx when extending an And with a mask when we know mask
11954 // is positive.  We know that because immI_bitmask guarantees it.
11955 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11956 %{
11957   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
11958   // Make sure we are not going to exceed what ubfxw can do.
11959   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11960 
11961   ins_cost(INSN_COST * 2);
11962   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
11963   ins_encode %{
11964     int rshift = $rshift$$constant &amp; 31;
11965     long mask = $mask$$constant;
11966     int width = exact_log2(mask+1);
11967     __ ubfx(as_Register($dst$$reg),
11968             as_Register($src$$reg), rshift, width);
11969   %}
11970   ins_pipe(ialu_reg_shift);
11971 %}
11972 
11973 // We can use ubfiz when masking by a positive number and then left shifting the result.
11974 // We know that the mask is positive because immI_bitmask guarantees it.
11975 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
11976 %{
11977   match(Set dst (LShiftI (AndI src mask) lshift));
11978   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11979 
11980   ins_cost(INSN_COST);
11981   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
11982   ins_encode %{
11983     int lshift = $lshift$$constant &amp; 31;
11984     long mask = $mask$$constant;
11985     int width = exact_log2(mask+1);
11986     __ ubfizw(as_Register($dst$$reg),
11987           as_Register($src$$reg), lshift, width);
11988   %}
11989   ins_pipe(ialu_reg_shift);
11990 %}
11991 // We can use ubfiz when masking by a positive number and then left shifting the result.
11992 // We know that the mask is positive because immL_bitmask guarantees it.
11993 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
11994 %{
11995   match(Set dst (LShiftL (AndL src mask) lshift));
11996   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
11997 
11998   ins_cost(INSN_COST);
11999   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12000   ins_encode %{
12001     int lshift = $lshift$$constant &amp; 63;
12002     long mask = $mask$$constant;
12003     int width = exact_log2_long(mask+1);
12004     __ ubfiz(as_Register($dst$$reg),
12005           as_Register($src$$reg), lshift, width);
12006   %}
12007   ins_pipe(ialu_reg_shift);
12008 %}
12009 
12010 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12011 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12012 %{
12013   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12014   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12015 
12016   ins_cost(INSN_COST);
12017   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12018   ins_encode %{
12019     int lshift = $lshift$$constant &amp; 63;
12020     long mask = $mask$$constant;
12021     int width = exact_log2(mask+1);
12022     __ ubfiz(as_Register($dst$$reg),
12023              as_Register($src$$reg), lshift, width);
12024   %}
12025   ins_pipe(ialu_reg_shift);
12026 %}
12027 
12028 // Rotations
12029 
12030 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12031 %{
12032   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12033   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12034 
12035   ins_cost(INSN_COST);
12036   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12037 
12038   ins_encode %{
12039     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12040             $rshift$$constant &amp; 63);
12041   %}
12042   ins_pipe(ialu_reg_reg_extr);
12043 %}
12044 
12045 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12046 %{
12047   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12048   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12049 
12050   ins_cost(INSN_COST);
12051   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12052 
12053   ins_encode %{
12054     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12055             $rshift$$constant &amp; 31);
12056   %}
12057   ins_pipe(ialu_reg_reg_extr);
12058 %}
12059 
12060 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12061 %{
12062   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12063   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12064 
12065   ins_cost(INSN_COST);
12066   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12067 
12068   ins_encode %{
12069     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12070             $rshift$$constant &amp; 63);
12071   %}
12072   ins_pipe(ialu_reg_reg_extr);
12073 %}
12074 
12075 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12076 %{
12077   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12078   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12079 
12080   ins_cost(INSN_COST);
12081   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12082 
12083   ins_encode %{
12084     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12085             $rshift$$constant &amp; 31);
12086   %}
12087   ins_pipe(ialu_reg_reg_extr);
12088 %}
12089 
12090 
12091 // rol expander
12092 
12093 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12094 %{
12095   effect(DEF dst, USE src, USE shift);
12096 
12097   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12098   ins_cost(INSN_COST * 3);
12099   ins_encode %{
12100     __ subw(rscratch1, zr, as_Register($shift$$reg));
12101     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12102             rscratch1);
12103     %}
12104   ins_pipe(ialu_reg_reg_vshift);
12105 %}
12106 
12107 // rol expander
12108 
12109 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12110 %{
12111   effect(DEF dst, USE src, USE shift);
12112 
12113   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12114   ins_cost(INSN_COST * 3);
12115   ins_encode %{
12116     __ subw(rscratch1, zr, as_Register($shift$$reg));
12117     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12118             rscratch1);
12119     %}
12120   ins_pipe(ialu_reg_reg_vshift);
12121 %}
12122 
12123 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12124 %{
12125   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12126 
12127   expand %{
12128     rolL_rReg(dst, src, shift, cr);
12129   %}
12130 %}
12131 
12132 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12133 %{
12134   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12135 
12136   expand %{
12137     rolL_rReg(dst, src, shift, cr);
12138   %}
12139 %}
12140 
12141 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12142 %{
12143   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12144 
12145   expand %{
12146     rolI_rReg(dst, src, shift, cr);
12147   %}
12148 %}
12149 
12150 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12151 %{
12152   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12153 
12154   expand %{
12155     rolI_rReg(dst, src, shift, cr);
12156   %}
12157 %}
12158 
12159 // ror expander
12160 
12161 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12162 %{
12163   effect(DEF dst, USE src, USE shift);
12164 
12165   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12166   ins_cost(INSN_COST);
12167   ins_encode %{
12168     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12169             as_Register($shift$$reg));
12170     %}
12171   ins_pipe(ialu_reg_reg_vshift);
12172 %}
12173 
12174 // ror expander
12175 
12176 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12177 %{
12178   effect(DEF dst, USE src, USE shift);
12179 
12180   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12181   ins_cost(INSN_COST);
12182   ins_encode %{
12183     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12184             as_Register($shift$$reg));
12185     %}
12186   ins_pipe(ialu_reg_reg_vshift);
12187 %}
12188 
12189 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12190 %{
12191   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12192 
12193   expand %{
12194     rorL_rReg(dst, src, shift, cr);
12195   %}
12196 %}
12197 
12198 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12199 %{
12200   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12201 
12202   expand %{
12203     rorL_rReg(dst, src, shift, cr);
12204   %}
12205 %}
12206 
12207 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12208 %{
12209   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12210 
12211   expand %{
12212     rorI_rReg(dst, src, shift, cr);
12213   %}
12214 %}
12215 
12216 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12217 %{
12218   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12219 
12220   expand %{
12221     rorI_rReg(dst, src, shift, cr);
12222   %}
12223 %}
12224 
12225 // Add/subtract (extended)
12226 
12227 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12228 %{
12229   match(Set dst (AddL src1 (ConvI2L src2)));
12230   ins_cost(INSN_COST);
12231   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12232 
12233    ins_encode %{
12234      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12235             as_Register($src2$$reg), ext::sxtw);
12236    %}
12237   ins_pipe(ialu_reg_reg);
12238 %};
12239 
12240 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12241 %{
12242   match(Set dst (SubL src1 (ConvI2L src2)));
12243   ins_cost(INSN_COST);
12244   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12245 
12246    ins_encode %{
12247      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12248             as_Register($src2$$reg), ext::sxtw);
12249    %}
12250   ins_pipe(ialu_reg_reg);
12251 %};
12252 
12253 
12254 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12255 %{
12256   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12257   ins_cost(INSN_COST);
12258   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12259 
12260    ins_encode %{
12261      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12262             as_Register($src2$$reg), ext::sxth);
12263    %}
12264   ins_pipe(ialu_reg_reg);
12265 %}
12266 
12267 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12268 %{
12269   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12270   ins_cost(INSN_COST);
12271   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12272 
12273    ins_encode %{
12274      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12275             as_Register($src2$$reg), ext::sxtb);
12276    %}
12277   ins_pipe(ialu_reg_reg);
12278 %}
12279 
12280 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12281 %{
12282   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12283   ins_cost(INSN_COST);
12284   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12285 
12286    ins_encode %{
12287      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12288             as_Register($src2$$reg), ext::uxtb);
12289    %}
12290   ins_pipe(ialu_reg_reg);
12291 %}
12292 
12293 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12294 %{
12295   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12296   ins_cost(INSN_COST);
12297   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12298 
12299    ins_encode %{
12300      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12301             as_Register($src2$$reg), ext::sxth);
12302    %}
12303   ins_pipe(ialu_reg_reg);
12304 %}
12305 
12306 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12307 %{
12308   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12309   ins_cost(INSN_COST);
12310   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12311 
12312    ins_encode %{
12313      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12314             as_Register($src2$$reg), ext::sxtw);
12315    %}
12316   ins_pipe(ialu_reg_reg);
12317 %}
12318 
12319 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12320 %{
12321   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12322   ins_cost(INSN_COST);
12323   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12324 
12325    ins_encode %{
12326      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12327             as_Register($src2$$reg), ext::sxtb);
12328    %}
12329   ins_pipe(ialu_reg_reg);
12330 %}
12331 
12332 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12333 %{
12334   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12335   ins_cost(INSN_COST);
12336   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12337 
12338    ins_encode %{
12339      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12340             as_Register($src2$$reg), ext::uxtb);
12341    %}
12342   ins_pipe(ialu_reg_reg);
12343 %}
12344 
12345 
12346 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12347 %{
12348   match(Set dst (AddI src1 (AndI src2 mask)));
12349   ins_cost(INSN_COST);
12350   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12351 
12352    ins_encode %{
12353      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12354             as_Register($src2$$reg), ext::uxtb);
12355    %}
12356   ins_pipe(ialu_reg_reg);
12357 %}
12358 
12359 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12360 %{
12361   match(Set dst (AddI src1 (AndI src2 mask)));
12362   ins_cost(INSN_COST);
12363   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12364 
12365    ins_encode %{
12366      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12367             as_Register($src2$$reg), ext::uxth);
12368    %}
12369   ins_pipe(ialu_reg_reg);
12370 %}
12371 
12372 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12373 %{
12374   match(Set dst (AddL src1 (AndL src2 mask)));
12375   ins_cost(INSN_COST);
12376   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12377 
12378    ins_encode %{
12379      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12380             as_Register($src2$$reg), ext::uxtb);
12381    %}
12382   ins_pipe(ialu_reg_reg);
12383 %}
12384 
12385 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12386 %{
12387   match(Set dst (AddL src1 (AndL src2 mask)));
12388   ins_cost(INSN_COST);
12389   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12390 
12391    ins_encode %{
12392      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12393             as_Register($src2$$reg), ext::uxth);
12394    %}
12395   ins_pipe(ialu_reg_reg);
12396 %}
12397 
12398 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12399 %{
12400   match(Set dst (AddL src1 (AndL src2 mask)));
12401   ins_cost(INSN_COST);
12402   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12403 
12404    ins_encode %{
12405      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12406             as_Register($src2$$reg), ext::uxtw);
12407    %}
12408   ins_pipe(ialu_reg_reg);
12409 %}
12410 
12411 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12412 %{
12413   match(Set dst (SubI src1 (AndI src2 mask)));
12414   ins_cost(INSN_COST);
12415   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12416 
12417    ins_encode %{
12418      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12419             as_Register($src2$$reg), ext::uxtb);
12420    %}
12421   ins_pipe(ialu_reg_reg);
12422 %}
12423 
12424 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12425 %{
12426   match(Set dst (SubI src1 (AndI src2 mask)));
12427   ins_cost(INSN_COST);
12428   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12429 
12430    ins_encode %{
12431      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12432             as_Register($src2$$reg), ext::uxth);
12433    %}
12434   ins_pipe(ialu_reg_reg);
12435 %}
12436 
12437 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12438 %{
12439   match(Set dst (SubL src1 (AndL src2 mask)));
12440   ins_cost(INSN_COST);
12441   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12442 
12443    ins_encode %{
12444      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12445             as_Register($src2$$reg), ext::uxtb);
12446    %}
12447   ins_pipe(ialu_reg_reg);
12448 %}
12449 
12450 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12451 %{
12452   match(Set dst (SubL src1 (AndL src2 mask)));
12453   ins_cost(INSN_COST);
12454   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12455 
12456    ins_encode %{
12457      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12458             as_Register($src2$$reg), ext::uxth);
12459    %}
12460   ins_pipe(ialu_reg_reg);
12461 %}
12462 
12463 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12464 %{
12465   match(Set dst (SubL src1 (AndL src2 mask)));
12466   ins_cost(INSN_COST);
12467   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12468 
12469    ins_encode %{
12470      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12471             as_Register($src2$$reg), ext::uxtw);
12472    %}
12473   ins_pipe(ialu_reg_reg);
12474 %}
12475 
12476 
12477 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12478 %{
12479   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12480   ins_cost(1.9 * INSN_COST);
12481   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12482 
12483    ins_encode %{
12484      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12485             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12486    %}
12487   ins_pipe(ialu_reg_reg_shift);
12488 %}
12489 
12490 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12491 %{
12492   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12493   ins_cost(1.9 * INSN_COST);
12494   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12495 
12496    ins_encode %{
12497      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12498             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12499    %}
12500   ins_pipe(ialu_reg_reg_shift);
12501 %}
12502 
12503 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12504 %{
12505   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12506   ins_cost(1.9 * INSN_COST);
12507   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12508 
12509    ins_encode %{
12510      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12511             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12512    %}
12513   ins_pipe(ialu_reg_reg_shift);
12514 %}
12515 
12516 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12517 %{
12518   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12519   ins_cost(1.9 * INSN_COST);
12520   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12521 
12522    ins_encode %{
12523      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12524             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12525    %}
12526   ins_pipe(ialu_reg_reg_shift);
12527 %}
12528 
12529 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12530 %{
12531   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12532   ins_cost(1.9 * INSN_COST);
12533   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12534 
12535    ins_encode %{
12536      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12537             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12538    %}
12539   ins_pipe(ialu_reg_reg_shift);
12540 %}
12541 
12542 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12543 %{
12544   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12545   ins_cost(1.9 * INSN_COST);
12546   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12547 
12548    ins_encode %{
12549      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12550             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12551    %}
12552   ins_pipe(ialu_reg_reg_shift);
12553 %}
12554 
12555 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12556 %{
12557   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12558   ins_cost(1.9 * INSN_COST);
12559   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12560 
12561    ins_encode %{
12562      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12563             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12564    %}
12565   ins_pipe(ialu_reg_reg_shift);
12566 %}
12567 
12568 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12569 %{
12570   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12571   ins_cost(1.9 * INSN_COST);
12572   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12573 
12574    ins_encode %{
12575      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12576             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12577    %}
12578   ins_pipe(ialu_reg_reg_shift);
12579 %}
12580 
12581 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12582 %{
12583   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12584   ins_cost(1.9 * INSN_COST);
12585   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12586 
12587    ins_encode %{
12588      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12589             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12590    %}
12591   ins_pipe(ialu_reg_reg_shift);
12592 %}
12593 
12594 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12595 %{
12596   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12597   ins_cost(1.9 * INSN_COST);
12598   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12599 
12600    ins_encode %{
12601      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12602             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12603    %}
12604   ins_pipe(ialu_reg_reg_shift);
12605 %}
12606 
12607 
12608 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12609 %{
12610   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12611   ins_cost(1.9 * INSN_COST);
12612   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12613 
12614    ins_encode %{
12615      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12616             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12617    %}
12618   ins_pipe(ialu_reg_reg_shift);
12619 %};
12620 
12621 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12622 %{
12623   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12624   ins_cost(1.9 * INSN_COST);
12625   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12626 
12627    ins_encode %{
12628      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12629             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12630    %}
12631   ins_pipe(ialu_reg_reg_shift);
12632 %};
12633 
12634 
12635 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12636 %{
12637   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12638   ins_cost(1.9 * INSN_COST);
12639   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12640 
12641    ins_encode %{
12642      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12643             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12644    %}
12645   ins_pipe(ialu_reg_reg_shift);
12646 %}
12647 
12648 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12649 %{
12650   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12651   ins_cost(1.9 * INSN_COST);
12652   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12653 
12654    ins_encode %{
12655      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12656             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12657    %}
12658   ins_pipe(ialu_reg_reg_shift);
12659 %}
12660 
12661 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12662 %{
12663   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12664   ins_cost(1.9 * INSN_COST);
12665   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12666 
12667    ins_encode %{
12668      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12669             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12670    %}
12671   ins_pipe(ialu_reg_reg_shift);
12672 %}
12673 
12674 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12675 %{
12676   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12677   ins_cost(1.9 * INSN_COST);
12678   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12679 
12680    ins_encode %{
12681      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12682             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12683    %}
12684   ins_pipe(ialu_reg_reg_shift);
12685 %}
12686 
12687 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12688 %{
12689   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12690   ins_cost(1.9 * INSN_COST);
12691   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12692 
12693    ins_encode %{
12694      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12695             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12696    %}
12697   ins_pipe(ialu_reg_reg_shift);
12698 %}
12699 
12700 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12701 %{
12702   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12703   ins_cost(1.9 * INSN_COST);
12704   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12705 
12706    ins_encode %{
12707      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12708             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12709    %}
12710   ins_pipe(ialu_reg_reg_shift);
12711 %}
12712 
12713 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12714 %{
12715   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12716   ins_cost(1.9 * INSN_COST);
12717   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12718 
12719    ins_encode %{
12720      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12721             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12722    %}
12723   ins_pipe(ialu_reg_reg_shift);
12724 %}
12725 
12726 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12727 %{
12728   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12729   ins_cost(1.9 * INSN_COST);
12730   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12731 
12732    ins_encode %{
12733      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12734             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12735    %}
12736   ins_pipe(ialu_reg_reg_shift);
12737 %}
12738 
12739 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12740 %{
12741   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12742   ins_cost(1.9 * INSN_COST);
12743   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12744 
12745    ins_encode %{
12746      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12747             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12748    %}
12749   ins_pipe(ialu_reg_reg_shift);
12750 %}
12751 
12752 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12753 %{
12754   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12755   ins_cost(1.9 * INSN_COST);
12756   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12757 
12758    ins_encode %{
12759      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12760             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12761    %}
12762   ins_pipe(ialu_reg_reg_shift);
12763 %}
12764 // END This section of the file is automatically generated. Do not edit --------------
12765 
12766 // ============================================================================
12767 // Floating Point Arithmetic Instructions
12768 
12769 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12770   match(Set dst (AddF src1 src2));
12771 
12772   ins_cost(INSN_COST * 5);
12773   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12774 
12775   ins_encode %{
12776     __ fadds(as_FloatRegister($dst$$reg),
12777              as_FloatRegister($src1$$reg),
12778              as_FloatRegister($src2$$reg));
12779   %}
12780 
12781   ins_pipe(fp_dop_reg_reg_s);
12782 %}
12783 
12784 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12785   match(Set dst (AddD src1 src2));
12786 
12787   ins_cost(INSN_COST * 5);
12788   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12789 
12790   ins_encode %{
12791     __ faddd(as_FloatRegister($dst$$reg),
12792              as_FloatRegister($src1$$reg),
12793              as_FloatRegister($src2$$reg));
12794   %}
12795 
12796   ins_pipe(fp_dop_reg_reg_d);
12797 %}
12798 
12799 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12800   match(Set dst (SubF src1 src2));
12801 
12802   ins_cost(INSN_COST * 5);
12803   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12804 
12805   ins_encode %{
12806     __ fsubs(as_FloatRegister($dst$$reg),
12807              as_FloatRegister($src1$$reg),
12808              as_FloatRegister($src2$$reg));
12809   %}
12810 
12811   ins_pipe(fp_dop_reg_reg_s);
12812 %}
12813 
12814 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12815   match(Set dst (SubD src1 src2));
12816 
12817   ins_cost(INSN_COST * 5);
12818   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12819 
12820   ins_encode %{
12821     __ fsubd(as_FloatRegister($dst$$reg),
12822              as_FloatRegister($src1$$reg),
12823              as_FloatRegister($src2$$reg));
12824   %}
12825 
12826   ins_pipe(fp_dop_reg_reg_d);
12827 %}
12828 
12829 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12830   match(Set dst (MulF src1 src2));
12831 
12832   ins_cost(INSN_COST * 6);
12833   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12834 
12835   ins_encode %{
12836     __ fmuls(as_FloatRegister($dst$$reg),
12837              as_FloatRegister($src1$$reg),
12838              as_FloatRegister($src2$$reg));
12839   %}
12840 
12841   ins_pipe(fp_dop_reg_reg_s);
12842 %}
12843 
12844 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12845   match(Set dst (MulD src1 src2));
12846 
12847   ins_cost(INSN_COST * 6);
12848   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12849 
12850   ins_encode %{
12851     __ fmuld(as_FloatRegister($dst$$reg),
12852              as_FloatRegister($src1$$reg),
12853              as_FloatRegister($src2$$reg));
12854   %}
12855 
12856   ins_pipe(fp_dop_reg_reg_d);
12857 %}
12858 
12859 // src1 * src2 + src3
12860 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12861   predicate(UseFMA);
12862   match(Set dst (FmaF src3 (Binary src1 src2)));
12863 
12864   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12865 
12866   ins_encode %{
12867     __ fmadds(as_FloatRegister($dst$$reg),
12868              as_FloatRegister($src1$$reg),
12869              as_FloatRegister($src2$$reg),
12870              as_FloatRegister($src3$$reg));
12871   %}
12872 
12873   ins_pipe(pipe_class_default);
12874 %}
12875 
12876 // src1 * src2 + src3
12877 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12878   predicate(UseFMA);
12879   match(Set dst (FmaD src3 (Binary src1 src2)));
12880 
12881   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12882 
12883   ins_encode %{
12884     __ fmaddd(as_FloatRegister($dst$$reg),
12885              as_FloatRegister($src1$$reg),
12886              as_FloatRegister($src2$$reg),
12887              as_FloatRegister($src3$$reg));
12888   %}
12889 
12890   ins_pipe(pipe_class_default);
12891 %}
12892 
12893 // -src1 * src2 + src3
12894 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12895   predicate(UseFMA);
12896   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12897   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12898 
12899   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12900 
12901   ins_encode %{
12902     __ fmsubs(as_FloatRegister($dst$$reg),
12903               as_FloatRegister($src1$$reg),
12904               as_FloatRegister($src2$$reg),
12905               as_FloatRegister($src3$$reg));
12906   %}
12907 
12908   ins_pipe(pipe_class_default);
12909 %}
12910 
12911 // -src1 * src2 + src3
12912 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12913   predicate(UseFMA);
12914   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12915   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12916 
12917   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12918 
12919   ins_encode %{
12920     __ fmsubd(as_FloatRegister($dst$$reg),
12921               as_FloatRegister($src1$$reg),
12922               as_FloatRegister($src2$$reg),
12923               as_FloatRegister($src3$$reg));
12924   %}
12925 
12926   ins_pipe(pipe_class_default);
12927 %}
12928 
12929 // -src1 * src2 - src3
12930 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12931   predicate(UseFMA);
12932   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
12933   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
12934 
12935   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
12936 
12937   ins_encode %{
12938     __ fnmadds(as_FloatRegister($dst$$reg),
12939                as_FloatRegister($src1$$reg),
12940                as_FloatRegister($src2$$reg),
12941                as_FloatRegister($src3$$reg));
12942   %}
12943 
12944   ins_pipe(pipe_class_default);
12945 %}
12946 
12947 // -src1 * src2 - src3
12948 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12949   predicate(UseFMA);
12950   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
12951   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
12952 
12953   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
12954 
12955   ins_encode %{
12956     __ fnmaddd(as_FloatRegister($dst$$reg),
12957                as_FloatRegister($src1$$reg),
12958                as_FloatRegister($src2$$reg),
12959                as_FloatRegister($src3$$reg));
12960   %}
12961 
12962   ins_pipe(pipe_class_default);
12963 %}
12964 
12965 // src1 * src2 - src3
12966 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
12967   predicate(UseFMA);
12968   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
12969 
12970   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
12971 
12972   ins_encode %{
12973     __ fnmsubs(as_FloatRegister($dst$$reg),
12974                as_FloatRegister($src1$$reg),
12975                as_FloatRegister($src2$$reg),
12976                as_FloatRegister($src3$$reg));
12977   %}
12978 
12979   ins_pipe(pipe_class_default);
12980 %}
12981 
12982 // src1 * src2 - src3
12983 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
12984   predicate(UseFMA);
12985   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
12986 
12987   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
12988 
12989   ins_encode %{
12990   // n.b. insn name should be fnmsubd
12991     __ fnmsub(as_FloatRegister($dst$$reg),
12992               as_FloatRegister($src1$$reg),
12993               as_FloatRegister($src2$$reg),
12994               as_FloatRegister($src3$$reg));
12995   %}
12996 
12997   ins_pipe(pipe_class_default);
12998 %}
12999 
13000 
13001 // Math.max(FF)F
13002 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13003   match(Set dst (MaxF src1 src2));
13004 
13005   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13006   ins_encode %{
13007     __ fmaxs(as_FloatRegister($dst$$reg),
13008              as_FloatRegister($src1$$reg),
13009              as_FloatRegister($src2$$reg));
13010   %}
13011 
13012   ins_pipe(fp_dop_reg_reg_s);
13013 %}
13014 
13015 // Math.min(FF)F
13016 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13017   match(Set dst (MinF src1 src2));
13018 
13019   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13020   ins_encode %{
13021     __ fmins(as_FloatRegister($dst$$reg),
13022              as_FloatRegister($src1$$reg),
13023              as_FloatRegister($src2$$reg));
13024   %}
13025 
13026   ins_pipe(fp_dop_reg_reg_s);
13027 %}
13028 
13029 // Math.max(DD)D
13030 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13031   match(Set dst (MaxD src1 src2));
13032 
13033   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13034   ins_encode %{
13035     __ fmaxd(as_FloatRegister($dst$$reg),
13036              as_FloatRegister($src1$$reg),
13037              as_FloatRegister($src2$$reg));
13038   %}
13039 
13040   ins_pipe(fp_dop_reg_reg_d);
13041 %}
13042 
13043 // Math.min(DD)D
13044 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13045   match(Set dst (MinD src1 src2));
13046 
13047   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13048   ins_encode %{
13049     __ fmind(as_FloatRegister($dst$$reg),
13050              as_FloatRegister($src1$$reg),
13051              as_FloatRegister($src2$$reg));
13052   %}
13053 
13054   ins_pipe(fp_dop_reg_reg_d);
13055 %}
13056 
13057 
13058 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13059   match(Set dst (DivF src1  src2));
13060 
13061   ins_cost(INSN_COST * 18);
13062   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13063 
13064   ins_encode %{
13065     __ fdivs(as_FloatRegister($dst$$reg),
13066              as_FloatRegister($src1$$reg),
13067              as_FloatRegister($src2$$reg));
13068   %}
13069 
13070   ins_pipe(fp_div_s);
13071 %}
13072 
13073 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13074   match(Set dst (DivD src1  src2));
13075 
13076   ins_cost(INSN_COST * 32);
13077   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13078 
13079   ins_encode %{
13080     __ fdivd(as_FloatRegister($dst$$reg),
13081              as_FloatRegister($src1$$reg),
13082              as_FloatRegister($src2$$reg));
13083   %}
13084 
13085   ins_pipe(fp_div_d);
13086 %}
13087 
13088 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13089   match(Set dst (NegF src));
13090 
13091   ins_cost(INSN_COST * 3);
13092   format %{ &quot;fneg   $dst, $src&quot; %}
13093 
13094   ins_encode %{
13095     __ fnegs(as_FloatRegister($dst$$reg),
13096              as_FloatRegister($src$$reg));
13097   %}
13098 
13099   ins_pipe(fp_uop_s);
13100 %}
13101 
13102 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13103   match(Set dst (NegD src));
13104 
13105   ins_cost(INSN_COST * 3);
13106   format %{ &quot;fnegd   $dst, $src&quot; %}
13107 
13108   ins_encode %{
13109     __ fnegd(as_FloatRegister($dst$$reg),
13110              as_FloatRegister($src$$reg));
13111   %}
13112 
13113   ins_pipe(fp_uop_d);
13114 %}
13115 
13116 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13117 %{
13118   match(Set dst (AbsI src));
13119 
13120   effect(KILL cr);
13121   ins_cost(INSN_COST * 2);
13122   format %{ &quot;cmpw  $src, zr\n\t&quot;
13123             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13124   %}
13125 
13126   ins_encode %{
13127     __ cmpw(as_Register($src$$reg), zr);
13128     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13129   %}
13130   ins_pipe(pipe_class_default);
13131 %}
13132 
13133 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13134 %{
13135   match(Set dst (AbsL src));
13136 
13137   effect(KILL cr);
13138   ins_cost(INSN_COST * 2);
13139   format %{ &quot;cmp  $src, zr\n\t&quot;
13140             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13141   %}
13142 
13143   ins_encode %{
13144     __ cmp(as_Register($src$$reg), zr);
13145     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13146   %}
13147   ins_pipe(pipe_class_default);
13148 %}
13149 
13150 instruct absF_reg(vRegF dst, vRegF src) %{
13151   match(Set dst (AbsF src));
13152 
13153   ins_cost(INSN_COST * 3);
13154   format %{ &quot;fabss   $dst, $src&quot; %}
13155   ins_encode %{
13156     __ fabss(as_FloatRegister($dst$$reg),
13157              as_FloatRegister($src$$reg));
13158   %}
13159 
13160   ins_pipe(fp_uop_s);
13161 %}
13162 
13163 instruct absD_reg(vRegD dst, vRegD src) %{
13164   match(Set dst (AbsD src));
13165 
13166   ins_cost(INSN_COST * 3);
13167   format %{ &quot;fabsd   $dst, $src&quot; %}
13168   ins_encode %{
13169     __ fabsd(as_FloatRegister($dst$$reg),
13170              as_FloatRegister($src$$reg));
13171   %}
13172 
13173   ins_pipe(fp_uop_d);
13174 %}
13175 
13176 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13177   match(Set dst (SqrtD src));
13178 
13179   ins_cost(INSN_COST * 50);
13180   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13181   ins_encode %{
13182     __ fsqrtd(as_FloatRegister($dst$$reg),
13183              as_FloatRegister($src$$reg));
13184   %}
13185 
13186   ins_pipe(fp_div_s);
13187 %}
13188 
13189 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13190   match(Set dst (SqrtF src));
13191 
13192   ins_cost(INSN_COST * 50);
13193   format %{ &quot;fsqrts  $dst, $src&quot; %}
13194   ins_encode %{
13195     __ fsqrts(as_FloatRegister($dst$$reg),
13196              as_FloatRegister($src$$reg));
13197   %}
13198 
13199   ins_pipe(fp_div_d);
13200 %}
13201 
13202 // Math.rint, floor, ceil
13203 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13204   match(Set dst (RoundDoubleMode src rmode));
13205   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13206   ins_encode %{
13207     switch ($rmode$$constant) {
13208       case RoundDoubleModeNode::rmode_rint:
13209         __ frintnd(as_FloatRegister($dst$$reg),
13210                    as_FloatRegister($src$$reg));
13211         break;
13212       case RoundDoubleModeNode::rmode_floor:
13213         __ frintmd(as_FloatRegister($dst$$reg),
13214                    as_FloatRegister($src$$reg));
13215         break;
13216       case RoundDoubleModeNode::rmode_ceil:
13217         __ frintpd(as_FloatRegister($dst$$reg),
13218                    as_FloatRegister($src$$reg));
13219         break;
13220     }
13221   %}
13222   ins_pipe(fp_uop_d);
13223 %}
13224 
13225 // ============================================================================
13226 // Logical Instructions
13227 
13228 // Integer Logical Instructions
13229 
13230 // And Instructions
13231 
13232 
13233 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13234   match(Set dst (AndI src1 src2));
13235 
13236   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13237 
13238   ins_cost(INSN_COST);
13239   ins_encode %{
13240     __ andw(as_Register($dst$$reg),
13241             as_Register($src1$$reg),
13242             as_Register($src2$$reg));
13243   %}
13244 
13245   ins_pipe(ialu_reg_reg);
13246 %}
13247 
13248 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13249   match(Set dst (AndI src1 src2));
13250 
13251   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13252 
13253   ins_cost(INSN_COST);
13254   ins_encode %{
13255     __ andw(as_Register($dst$$reg),
13256             as_Register($src1$$reg),
13257             (unsigned long)($src2$$constant));
13258   %}
13259 
13260   ins_pipe(ialu_reg_imm);
13261 %}
13262 
13263 // Or Instructions
13264 
13265 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13266   match(Set dst (OrI src1 src2));
13267 
13268   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13269 
13270   ins_cost(INSN_COST);
13271   ins_encode %{
13272     __ orrw(as_Register($dst$$reg),
13273             as_Register($src1$$reg),
13274             as_Register($src2$$reg));
13275   %}
13276 
13277   ins_pipe(ialu_reg_reg);
13278 %}
13279 
13280 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13281   match(Set dst (OrI src1 src2));
13282 
13283   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13284 
13285   ins_cost(INSN_COST);
13286   ins_encode %{
13287     __ orrw(as_Register($dst$$reg),
13288             as_Register($src1$$reg),
13289             (unsigned long)($src2$$constant));
13290   %}
13291 
13292   ins_pipe(ialu_reg_imm);
13293 %}
13294 
13295 // Xor Instructions
13296 
13297 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13298   match(Set dst (XorI src1 src2));
13299 
13300   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13301 
13302   ins_cost(INSN_COST);
13303   ins_encode %{
13304     __ eorw(as_Register($dst$$reg),
13305             as_Register($src1$$reg),
13306             as_Register($src2$$reg));
13307   %}
13308 
13309   ins_pipe(ialu_reg_reg);
13310 %}
13311 
13312 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13313   match(Set dst (XorI src1 src2));
13314 
13315   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13316 
13317   ins_cost(INSN_COST);
13318   ins_encode %{
13319     __ eorw(as_Register($dst$$reg),
13320             as_Register($src1$$reg),
13321             (unsigned long)($src2$$constant));
13322   %}
13323 
13324   ins_pipe(ialu_reg_imm);
13325 %}
13326 
13327 // Long Logical Instructions
13328 // TODO
13329 
13330 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13331   match(Set dst (AndL src1 src2));
13332 
13333   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13334 
13335   ins_cost(INSN_COST);
13336   ins_encode %{
13337     __ andr(as_Register($dst$$reg),
13338             as_Register($src1$$reg),
13339             as_Register($src2$$reg));
13340   %}
13341 
13342   ins_pipe(ialu_reg_reg);
13343 %}
13344 
13345 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13346   match(Set dst (AndL src1 src2));
13347 
13348   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13349 
13350   ins_cost(INSN_COST);
13351   ins_encode %{
13352     __ andr(as_Register($dst$$reg),
13353             as_Register($src1$$reg),
13354             (unsigned long)($src2$$constant));
13355   %}
13356 
13357   ins_pipe(ialu_reg_imm);
13358 %}
13359 
13360 // Or Instructions
13361 
13362 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13363   match(Set dst (OrL src1 src2));
13364 
13365   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13366 
13367   ins_cost(INSN_COST);
13368   ins_encode %{
13369     __ orr(as_Register($dst$$reg),
13370            as_Register($src1$$reg),
13371            as_Register($src2$$reg));
13372   %}
13373 
13374   ins_pipe(ialu_reg_reg);
13375 %}
13376 
13377 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13378   match(Set dst (OrL src1 src2));
13379 
13380   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13381 
13382   ins_cost(INSN_COST);
13383   ins_encode %{
13384     __ orr(as_Register($dst$$reg),
13385            as_Register($src1$$reg),
13386            (unsigned long)($src2$$constant));
13387   %}
13388 
13389   ins_pipe(ialu_reg_imm);
13390 %}
13391 
13392 // Xor Instructions
13393 
13394 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13395   match(Set dst (XorL src1 src2));
13396 
13397   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13398 
13399   ins_cost(INSN_COST);
13400   ins_encode %{
13401     __ eor(as_Register($dst$$reg),
13402            as_Register($src1$$reg),
13403            as_Register($src2$$reg));
13404   %}
13405 
13406   ins_pipe(ialu_reg_reg);
13407 %}
13408 
13409 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13410   match(Set dst (XorL src1 src2));
13411 
13412   ins_cost(INSN_COST);
13413   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13414 
13415   ins_encode %{
13416     __ eor(as_Register($dst$$reg),
13417            as_Register($src1$$reg),
13418            (unsigned long)($src2$$constant));
13419   %}
13420 
13421   ins_pipe(ialu_reg_imm);
13422 %}
13423 
13424 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13425 %{
13426   match(Set dst (ConvI2L src));
13427 
13428   ins_cost(INSN_COST);
13429   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13430   ins_encode %{
13431     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13432   %}
13433   ins_pipe(ialu_reg_shift);
13434 %}
13435 
13436 // this pattern occurs in bigmath arithmetic
13437 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13438 %{
13439   match(Set dst (AndL (ConvI2L src) mask));
13440 
13441   ins_cost(INSN_COST);
13442   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13443   ins_encode %{
13444     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13445   %}
13446 
13447   ins_pipe(ialu_reg_shift);
13448 %}
13449 
13450 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13451   match(Set dst (ConvL2I src));
13452 
13453   ins_cost(INSN_COST);
13454   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13455 
13456   ins_encode %{
13457     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13458   %}
13459 
13460   ins_pipe(ialu_reg);
13461 %}
13462 
13463 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13464 %{
13465   match(Set dst (Conv2B src));
13466   effect(KILL cr);
13467 
13468   format %{
13469     &quot;cmpw $src, zr\n\t&quot;
13470     &quot;cset $dst, ne&quot;
13471   %}
13472 
13473   ins_encode %{
13474     __ cmpw(as_Register($src$$reg), zr);
13475     __ cset(as_Register($dst$$reg), Assembler::NE);
13476   %}
13477 
13478   ins_pipe(ialu_reg);
13479 %}
13480 
13481 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13482 %{
13483   match(Set dst (Conv2B src));
13484   effect(KILL cr);
13485 
13486   format %{
13487     &quot;cmp  $src, zr\n\t&quot;
13488     &quot;cset $dst, ne&quot;
13489   %}
13490 
13491   ins_encode %{
13492     __ cmp(as_Register($src$$reg), zr);
13493     __ cset(as_Register($dst$$reg), Assembler::NE);
13494   %}
13495 
13496   ins_pipe(ialu_reg);
13497 %}
13498 
13499 instruct convD2F_reg(vRegF dst, vRegD src) %{
13500   match(Set dst (ConvD2F src));
13501 
13502   ins_cost(INSN_COST * 5);
13503   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13504 
13505   ins_encode %{
13506     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13507   %}
13508 
13509   ins_pipe(fp_d2f);
13510 %}
13511 
13512 instruct convF2D_reg(vRegD dst, vRegF src) %{
13513   match(Set dst (ConvF2D src));
13514 
13515   ins_cost(INSN_COST * 5);
13516   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13517 
13518   ins_encode %{
13519     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13520   %}
13521 
13522   ins_pipe(fp_f2d);
13523 %}
13524 
13525 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13526   match(Set dst (ConvF2I src));
13527 
13528   ins_cost(INSN_COST * 5);
13529   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13530 
13531   ins_encode %{
13532     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13533   %}
13534 
13535   ins_pipe(fp_f2i);
13536 %}
13537 
13538 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13539   match(Set dst (ConvF2L src));
13540 
13541   ins_cost(INSN_COST * 5);
13542   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13543 
13544   ins_encode %{
13545     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13546   %}
13547 
13548   ins_pipe(fp_f2l);
13549 %}
13550 
13551 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13552   match(Set dst (ConvI2F src));
13553 
13554   ins_cost(INSN_COST * 5);
13555   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13556 
13557   ins_encode %{
13558     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13559   %}
13560 
13561   ins_pipe(fp_i2f);
13562 %}
13563 
13564 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13565   match(Set dst (ConvL2F src));
13566 
13567   ins_cost(INSN_COST * 5);
13568   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13569 
13570   ins_encode %{
13571     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13572   %}
13573 
13574   ins_pipe(fp_l2f);
13575 %}
13576 
13577 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13578   match(Set dst (ConvD2I src));
13579 
13580   ins_cost(INSN_COST * 5);
13581   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13582 
13583   ins_encode %{
13584     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13585   %}
13586 
13587   ins_pipe(fp_d2i);
13588 %}
13589 
13590 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13591   match(Set dst (ConvD2L src));
13592 
13593   ins_cost(INSN_COST * 5);
13594   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13595 
13596   ins_encode %{
13597     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13598   %}
13599 
13600   ins_pipe(fp_d2l);
13601 %}
13602 
13603 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13604   match(Set dst (ConvI2D src));
13605 
13606   ins_cost(INSN_COST * 5);
13607   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13608 
13609   ins_encode %{
13610     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13611   %}
13612 
13613   ins_pipe(fp_i2d);
13614 %}
13615 
13616 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13617   match(Set dst (ConvL2D src));
13618 
13619   ins_cost(INSN_COST * 5);
13620   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13621 
13622   ins_encode %{
13623     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13624   %}
13625 
13626   ins_pipe(fp_l2d);
13627 %}
13628 
13629 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13630 
13631 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13632 
13633   match(Set dst (MoveF2I src));
13634 
13635   effect(DEF dst, USE src);
13636 
13637   ins_cost(4 * INSN_COST);
13638 
13639   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13640 
13641   ins_encode %{
13642     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13643   %}
13644 
13645   ins_pipe(iload_reg_reg);
13646 
13647 %}
13648 
13649 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13650 
13651   match(Set dst (MoveI2F src));
13652 
13653   effect(DEF dst, USE src);
13654 
13655   ins_cost(4 * INSN_COST);
13656 
13657   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13658 
13659   ins_encode %{
13660     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13661   %}
13662 
13663   ins_pipe(pipe_class_memory);
13664 
13665 %}
13666 
13667 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13668 
13669   match(Set dst (MoveD2L src));
13670 
13671   effect(DEF dst, USE src);
13672 
13673   ins_cost(4 * INSN_COST);
13674 
13675   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13676 
13677   ins_encode %{
13678     __ ldr($dst$$Register, Address(sp, $src$$disp));
13679   %}
13680 
13681   ins_pipe(iload_reg_reg);
13682 
13683 %}
13684 
13685 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13686 
13687   match(Set dst (MoveL2D src));
13688 
13689   effect(DEF dst, USE src);
13690 
13691   ins_cost(4 * INSN_COST);
13692 
13693   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13694 
13695   ins_encode %{
13696     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13697   %}
13698 
13699   ins_pipe(pipe_class_memory);
13700 
13701 %}
13702 
13703 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13704 
13705   match(Set dst (MoveF2I src));
13706 
13707   effect(DEF dst, USE src);
13708 
13709   ins_cost(INSN_COST);
13710 
13711   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13712 
13713   ins_encode %{
13714     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13715   %}
13716 
13717   ins_pipe(pipe_class_memory);
13718 
13719 %}
13720 
13721 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13722 
13723   match(Set dst (MoveI2F src));
13724 
13725   effect(DEF dst, USE src);
13726 
13727   ins_cost(INSN_COST);
13728 
13729   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13730 
13731   ins_encode %{
13732     __ strw($src$$Register, Address(sp, $dst$$disp));
13733   %}
13734 
13735   ins_pipe(istore_reg_reg);
13736 
13737 %}
13738 
13739 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13740 
13741   match(Set dst (MoveD2L src));
13742 
13743   effect(DEF dst, USE src);
13744 
13745   ins_cost(INSN_COST);
13746 
13747   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13748 
13749   ins_encode %{
13750     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13751   %}
13752 
13753   ins_pipe(pipe_class_memory);
13754 
13755 %}
13756 
13757 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13758 
13759   match(Set dst (MoveL2D src));
13760 
13761   effect(DEF dst, USE src);
13762 
13763   ins_cost(INSN_COST);
13764 
13765   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13766 
13767   ins_encode %{
13768     __ str($src$$Register, Address(sp, $dst$$disp));
13769   %}
13770 
13771   ins_pipe(istore_reg_reg);
13772 
13773 %}
13774 
13775 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13776 
13777   match(Set dst (MoveF2I src));
13778 
13779   effect(DEF dst, USE src);
13780 
13781   ins_cost(INSN_COST);
13782 
13783   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13784 
13785   ins_encode %{
13786     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13787   %}
13788 
13789   ins_pipe(fp_f2i);
13790 
13791 %}
13792 
13793 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13794 
13795   match(Set dst (MoveI2F src));
13796 
13797   effect(DEF dst, USE src);
13798 
13799   ins_cost(INSN_COST);
13800 
13801   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13802 
13803   ins_encode %{
13804     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13805   %}
13806 
13807   ins_pipe(fp_i2f);
13808 
13809 %}
13810 
13811 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13812 
13813   match(Set dst (MoveD2L src));
13814 
13815   effect(DEF dst, USE src);
13816 
13817   ins_cost(INSN_COST);
13818 
13819   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13820 
13821   ins_encode %{
13822     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13823   %}
13824 
13825   ins_pipe(fp_d2l);
13826 
13827 %}
13828 
13829 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13830 
13831   match(Set dst (MoveL2D src));
13832 
13833   effect(DEF dst, USE src);
13834 
13835   ins_cost(INSN_COST);
13836 
13837   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13838 
13839   ins_encode %{
13840     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13841   %}
13842 
13843   ins_pipe(fp_l2d);
13844 
13845 %}
13846 
13847 // ============================================================================
13848 // clearing of an array
13849 
13850 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13851 %{
13852   match(Set dummy (ClearArray cnt base));
13853   effect(USE_KILL cnt, USE_KILL base, KILL cr);
13854 
13855   ins_cost(4 * INSN_COST);
13856   format %{ &quot;ClearArray $cnt, $base&quot; %}
13857 
13858   ins_encode %{
13859     __ zero_words($base$$Register, $cnt$$Register);
13860   %}
13861 
13862   ins_pipe(pipe_class_memory);
13863 %}
13864 
13865 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13866 %{
13867   predicate((u_int64_t)n-&gt;in(2)-&gt;get_long()
13868             &lt; (u_int64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
13869   match(Set dummy (ClearArray cnt base));
13870   effect(USE_KILL base);
13871 
13872   ins_cost(4 * INSN_COST);
13873   format %{ &quot;ClearArray $cnt, $base&quot; %}
13874 
13875   ins_encode %{
13876     __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);
13877   %}
13878 
13879   ins_pipe(pipe_class_memory);
13880 %}
13881 
13882 // ============================================================================
13883 // Overflow Math Instructions
13884 
13885 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13886 %{
13887   match(Set cr (OverflowAddI op1 op2));
13888 
13889   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13890   ins_cost(INSN_COST);
13891   ins_encode %{
13892     __ cmnw($op1$$Register, $op2$$Register);
13893   %}
13894 
13895   ins_pipe(icmp_reg_reg);
13896 %}
13897 
13898 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13899 %{
13900   match(Set cr (OverflowAddI op1 op2));
13901 
13902   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13903   ins_cost(INSN_COST);
13904   ins_encode %{
13905     __ cmnw($op1$$Register, $op2$$constant);
13906   %}
13907 
13908   ins_pipe(icmp_reg_imm);
13909 %}
13910 
13911 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13912 %{
13913   match(Set cr (OverflowAddL op1 op2));
13914 
13915   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13916   ins_cost(INSN_COST);
13917   ins_encode %{
13918     __ cmn($op1$$Register, $op2$$Register);
13919   %}
13920 
13921   ins_pipe(icmp_reg_reg);
13922 %}
13923 
13924 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13925 %{
13926   match(Set cr (OverflowAddL op1 op2));
13927 
13928   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13929   ins_cost(INSN_COST);
13930   ins_encode %{
13931     __ cmn($op1$$Register, $op2$$constant);
13932   %}
13933 
13934   ins_pipe(icmp_reg_imm);
13935 %}
13936 
13937 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13938 %{
13939   match(Set cr (OverflowSubI op1 op2));
13940 
13941   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13942   ins_cost(INSN_COST);
13943   ins_encode %{
13944     __ cmpw($op1$$Register, $op2$$Register);
13945   %}
13946 
13947   ins_pipe(icmp_reg_reg);
13948 %}
13949 
13950 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13951 %{
13952   match(Set cr (OverflowSubI op1 op2));
13953 
13954   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13955   ins_cost(INSN_COST);
13956   ins_encode %{
13957     __ cmpw($op1$$Register, $op2$$constant);
13958   %}
13959 
13960   ins_pipe(icmp_reg_imm);
13961 %}
13962 
13963 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13964 %{
13965   match(Set cr (OverflowSubL op1 op2));
13966 
13967   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13968   ins_cost(INSN_COST);
13969   ins_encode %{
13970     __ cmp($op1$$Register, $op2$$Register);
13971   %}
13972 
13973   ins_pipe(icmp_reg_reg);
13974 %}
13975 
13976 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13977 %{
13978   match(Set cr (OverflowSubL op1 op2));
13979 
13980   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13981   ins_cost(INSN_COST);
13982   ins_encode %{
13983     __ subs(zr, $op1$$Register, $op2$$constant);
13984   %}
13985 
13986   ins_pipe(icmp_reg_imm);
13987 %}
13988 
13989 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
13990 %{
13991   match(Set cr (OverflowSubI zero op1));
13992 
13993   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
13994   ins_cost(INSN_COST);
13995   ins_encode %{
13996     __ cmpw(zr, $op1$$Register);
13997   %}
13998 
13999   ins_pipe(icmp_reg_imm);
14000 %}
14001 
14002 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14003 %{
14004   match(Set cr (OverflowSubL zero op1));
14005 
14006   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14007   ins_cost(INSN_COST);
14008   ins_encode %{
14009     __ cmp(zr, $op1$$Register);
14010   %}
14011 
14012   ins_pipe(icmp_reg_imm);
14013 %}
14014 
14015 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14016 %{
14017   match(Set cr (OverflowMulI op1 op2));
14018 
14019   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14020             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14021             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14022             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14023             &quot;cmpw  rscratch1, #1&quot; %}
14024   ins_cost(5 * INSN_COST);
14025   ins_encode %{
14026     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14027     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14028     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14029     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14030     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14031   %}
14032 
14033   ins_pipe(pipe_slow);
14034 %}
14035 
14036 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14037 %{
14038   match(If cmp (OverflowMulI op1 op2));
14039   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14040             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14041   effect(USE labl, KILL cr);
14042 
14043   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14044             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14045             &quot;b$cmp   $labl&quot; %}
14046   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14047   ins_encode %{
14048     Label* L = $labl$$label;
14049     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14050     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14051     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14052     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14053   %}
14054 
14055   ins_pipe(pipe_serial);
14056 %}
14057 
14058 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14059 %{
14060   match(Set cr (OverflowMulL op1 op2));
14061 
14062   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14063             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14064             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14065             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14066             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14067             &quot;cmpw  rscratch1, #1&quot; %}
14068   ins_cost(6 * INSN_COST);
14069   ins_encode %{
14070     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14071     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14072     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14073     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14074     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14075     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14076   %}
14077 
14078   ins_pipe(pipe_slow);
14079 %}
14080 
14081 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14082 %{
14083   match(If cmp (OverflowMulL op1 op2));
14084   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14085             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14086   effect(USE labl, KILL cr);
14087 
14088   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14089             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14090             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14091             &quot;b$cmp $labl&quot; %}
14092   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14093   ins_encode %{
14094     Label* L = $labl$$label;
14095     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14096     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14097     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14098     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14099     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14100   %}
14101 
14102   ins_pipe(pipe_serial);
14103 %}
14104 
14105 // ============================================================================
14106 // Compare Instructions
14107 
14108 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14109 %{
14110   match(Set cr (CmpI op1 op2));
14111 
14112   effect(DEF cr, USE op1, USE op2);
14113 
14114   ins_cost(INSN_COST);
14115   format %{ &quot;cmpw  $op1, $op2&quot; %}
14116 
14117   ins_encode(aarch64_enc_cmpw(op1, op2));
14118 
14119   ins_pipe(icmp_reg_reg);
14120 %}
14121 
14122 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14123 %{
14124   match(Set cr (CmpI op1 zero));
14125 
14126   effect(DEF cr, USE op1);
14127 
14128   ins_cost(INSN_COST);
14129   format %{ &quot;cmpw $op1, 0&quot; %}
14130 
14131   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14132 
14133   ins_pipe(icmp_reg_imm);
14134 %}
14135 
14136 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14137 %{
14138   match(Set cr (CmpI op1 op2));
14139 
14140   effect(DEF cr, USE op1);
14141 
14142   ins_cost(INSN_COST);
14143   format %{ &quot;cmpw  $op1, $op2&quot; %}
14144 
14145   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14146 
14147   ins_pipe(icmp_reg_imm);
14148 %}
14149 
14150 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14151 %{
14152   match(Set cr (CmpI op1 op2));
14153 
14154   effect(DEF cr, USE op1);
14155 
14156   ins_cost(INSN_COST * 2);
14157   format %{ &quot;cmpw  $op1, $op2&quot; %}
14158 
14159   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14160 
14161   ins_pipe(icmp_reg_imm);
14162 %}
14163 
14164 // Unsigned compare Instructions; really, same as signed compare
14165 // except it should only be used to feed an If or a CMovI which takes a
14166 // cmpOpU.
14167 
14168 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14169 %{
14170   match(Set cr (CmpU op1 op2));
14171 
14172   effect(DEF cr, USE op1, USE op2);
14173 
14174   ins_cost(INSN_COST);
14175   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14176 
14177   ins_encode(aarch64_enc_cmpw(op1, op2));
14178 
14179   ins_pipe(icmp_reg_reg);
14180 %}
14181 
14182 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14183 %{
14184   match(Set cr (CmpU op1 zero));
14185 
14186   effect(DEF cr, USE op1);
14187 
14188   ins_cost(INSN_COST);
14189   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14190 
14191   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14192 
14193   ins_pipe(icmp_reg_imm);
14194 %}
14195 
14196 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14197 %{
14198   match(Set cr (CmpU op1 op2));
14199 
14200   effect(DEF cr, USE op1);
14201 
14202   ins_cost(INSN_COST);
14203   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14204 
14205   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14206 
14207   ins_pipe(icmp_reg_imm);
14208 %}
14209 
14210 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14211 %{
14212   match(Set cr (CmpU op1 op2));
14213 
14214   effect(DEF cr, USE op1);
14215 
14216   ins_cost(INSN_COST * 2);
14217   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14218 
14219   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14220 
14221   ins_pipe(icmp_reg_imm);
14222 %}
14223 
14224 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14225 %{
14226   match(Set cr (CmpL op1 op2));
14227 
14228   effect(DEF cr, USE op1, USE op2);
14229 
14230   ins_cost(INSN_COST);
14231   format %{ &quot;cmp  $op1, $op2&quot; %}
14232 
14233   ins_encode(aarch64_enc_cmp(op1, op2));
14234 
14235   ins_pipe(icmp_reg_reg);
14236 %}
14237 
14238 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14239 %{
14240   match(Set cr (CmpL op1 zero));
14241 
14242   effect(DEF cr, USE op1);
14243 
14244   ins_cost(INSN_COST);
14245   format %{ &quot;tst  $op1&quot; %}
14246 
14247   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14248 
14249   ins_pipe(icmp_reg_imm);
14250 %}
14251 
14252 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14253 %{
14254   match(Set cr (CmpL op1 op2));
14255 
14256   effect(DEF cr, USE op1);
14257 
14258   ins_cost(INSN_COST);
14259   format %{ &quot;cmp  $op1, $op2&quot; %}
14260 
14261   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14262 
14263   ins_pipe(icmp_reg_imm);
14264 %}
14265 
14266 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14267 %{
14268   match(Set cr (CmpL op1 op2));
14269 
14270   effect(DEF cr, USE op1);
14271 
14272   ins_cost(INSN_COST * 2);
14273   format %{ &quot;cmp  $op1, $op2&quot; %}
14274 
14275   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14276 
14277   ins_pipe(icmp_reg_imm);
14278 %}
14279 
14280 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14281 %{
14282   match(Set cr (CmpUL op1 op2));
14283 
14284   effect(DEF cr, USE op1, USE op2);
14285 
14286   ins_cost(INSN_COST);
14287   format %{ &quot;cmp  $op1, $op2&quot; %}
14288 
14289   ins_encode(aarch64_enc_cmp(op1, op2));
14290 
14291   ins_pipe(icmp_reg_reg);
14292 %}
14293 
14294 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14295 %{
14296   match(Set cr (CmpUL op1 zero));
14297 
14298   effect(DEF cr, USE op1);
14299 
14300   ins_cost(INSN_COST);
14301   format %{ &quot;tst  $op1&quot; %}
14302 
14303   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14304 
14305   ins_pipe(icmp_reg_imm);
14306 %}
14307 
14308 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14309 %{
14310   match(Set cr (CmpUL op1 op2));
14311 
14312   effect(DEF cr, USE op1);
14313 
14314   ins_cost(INSN_COST);
14315   format %{ &quot;cmp  $op1, $op2&quot; %}
14316 
14317   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14318 
14319   ins_pipe(icmp_reg_imm);
14320 %}
14321 
14322 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14323 %{
14324   match(Set cr (CmpUL op1 op2));
14325 
14326   effect(DEF cr, USE op1);
14327 
14328   ins_cost(INSN_COST * 2);
14329   format %{ &quot;cmp  $op1, $op2&quot; %}
14330 
14331   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14332 
14333   ins_pipe(icmp_reg_imm);
14334 %}
14335 
14336 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14337 %{
14338   match(Set cr (CmpP op1 op2));
14339 
14340   effect(DEF cr, USE op1, USE op2);
14341 
14342   ins_cost(INSN_COST);
14343   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14344 
14345   ins_encode(aarch64_enc_cmpp(op1, op2));
14346 
14347   ins_pipe(icmp_reg_reg);
14348 %}
14349 
14350 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14351 %{
14352   match(Set cr (CmpN op1 op2));
14353 
14354   effect(DEF cr, USE op1, USE op2);
14355 
14356   ins_cost(INSN_COST);
14357   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14358 
14359   ins_encode(aarch64_enc_cmpn(op1, op2));
14360 
14361   ins_pipe(icmp_reg_reg);
14362 %}
14363 
14364 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14365 %{
14366   match(Set cr (CmpP op1 zero));
14367 
14368   effect(DEF cr, USE op1, USE zero);
14369 
14370   ins_cost(INSN_COST);
14371   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14372 
14373   ins_encode(aarch64_enc_testp(op1));
14374 
14375   ins_pipe(icmp_reg_imm);
14376 %}
14377 
14378 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14379 %{
14380   match(Set cr (CmpN op1 zero));
14381 
14382   effect(DEF cr, USE op1, USE zero);
14383 
14384   ins_cost(INSN_COST);
14385   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14386 
14387   ins_encode(aarch64_enc_testn(op1));
14388 
14389   ins_pipe(icmp_reg_imm);
14390 %}
14391 
14392 // FP comparisons
14393 //
14394 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14395 // using normal cmpOp. See declaration of rFlagsReg for details.
14396 
14397 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14398 %{
14399   match(Set cr (CmpF src1 src2));
14400 
14401   ins_cost(3 * INSN_COST);
14402   format %{ &quot;fcmps $src1, $src2&quot; %}
14403 
14404   ins_encode %{
14405     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14406   %}
14407 
14408   ins_pipe(pipe_class_compare);
14409 %}
14410 
14411 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14412 %{
14413   match(Set cr (CmpF src1 src2));
14414 
14415   ins_cost(3 * INSN_COST);
14416   format %{ &quot;fcmps $src1, 0.0&quot; %}
14417 
14418   ins_encode %{
14419     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14420   %}
14421 
14422   ins_pipe(pipe_class_compare);
14423 %}
14424 // FROM HERE
14425 
14426 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14427 %{
14428   match(Set cr (CmpD src1 src2));
14429 
14430   ins_cost(3 * INSN_COST);
14431   format %{ &quot;fcmpd $src1, $src2&quot; %}
14432 
14433   ins_encode %{
14434     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14435   %}
14436 
14437   ins_pipe(pipe_class_compare);
14438 %}
14439 
14440 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14441 %{
14442   match(Set cr (CmpD src1 src2));
14443 
14444   ins_cost(3 * INSN_COST);
14445   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14446 
14447   ins_encode %{
14448     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14449   %}
14450 
14451   ins_pipe(pipe_class_compare);
14452 %}
14453 
14454 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14455 %{
14456   match(Set dst (CmpF3 src1 src2));
14457   effect(KILL cr);
14458 
14459   ins_cost(5 * INSN_COST);
14460   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14461             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14462             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14463   %}
14464 
14465   ins_encode %{
14466     Label done;
14467     FloatRegister s1 = as_FloatRegister($src1$$reg);
14468     FloatRegister s2 = as_FloatRegister($src2$$reg);
14469     Register d = as_Register($dst$$reg);
14470     __ fcmps(s1, s2);
14471     // installs 0 if EQ else -1
14472     __ csinvw(d, zr, zr, Assembler::EQ);
14473     // keeps -1 if less or unordered else installs 1
14474     __ csnegw(d, d, d, Assembler::LT);
14475     __ bind(done);
14476   %}
14477 
14478   ins_pipe(pipe_class_default);
14479 
14480 %}
14481 
14482 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14483 %{
14484   match(Set dst (CmpD3 src1 src2));
14485   effect(KILL cr);
14486 
14487   ins_cost(5 * INSN_COST);
14488   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14489             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14490             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14491   %}
14492 
14493   ins_encode %{
14494     Label done;
14495     FloatRegister s1 = as_FloatRegister($src1$$reg);
14496     FloatRegister s2 = as_FloatRegister($src2$$reg);
14497     Register d = as_Register($dst$$reg);
14498     __ fcmpd(s1, s2);
14499     // installs 0 if EQ else -1
14500     __ csinvw(d, zr, zr, Assembler::EQ);
14501     // keeps -1 if less or unordered else installs 1
14502     __ csnegw(d, d, d, Assembler::LT);
14503     __ bind(done);
14504   %}
14505   ins_pipe(pipe_class_default);
14506 
14507 %}
14508 
14509 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14510 %{
14511   match(Set dst (CmpF3 src1 zero));
14512   effect(KILL cr);
14513 
14514   ins_cost(5 * INSN_COST);
14515   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14516             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14517             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14518   %}
14519 
14520   ins_encode %{
14521     Label done;
14522     FloatRegister s1 = as_FloatRegister($src1$$reg);
14523     Register d = as_Register($dst$$reg);
14524     __ fcmps(s1, 0.0);
14525     // installs 0 if EQ else -1
14526     __ csinvw(d, zr, zr, Assembler::EQ);
14527     // keeps -1 if less or unordered else installs 1
14528     __ csnegw(d, d, d, Assembler::LT);
14529     __ bind(done);
14530   %}
14531 
14532   ins_pipe(pipe_class_default);
14533 
14534 %}
14535 
14536 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14537 %{
14538   match(Set dst (CmpD3 src1 zero));
14539   effect(KILL cr);
14540 
14541   ins_cost(5 * INSN_COST);
14542   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14543             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14544             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14545   %}
14546 
14547   ins_encode %{
14548     Label done;
14549     FloatRegister s1 = as_FloatRegister($src1$$reg);
14550     Register d = as_Register($dst$$reg);
14551     __ fcmpd(s1, 0.0);
14552     // installs 0 if EQ else -1
14553     __ csinvw(d, zr, zr, Assembler::EQ);
14554     // keeps -1 if less or unordered else installs 1
14555     __ csnegw(d, d, d, Assembler::LT);
14556     __ bind(done);
14557   %}
14558   ins_pipe(pipe_class_default);
14559 
14560 %}
14561 
14562 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14563 %{
14564   match(Set dst (CmpLTMask p q));
14565   effect(KILL cr);
14566 
14567   ins_cost(3 * INSN_COST);
14568 
14569   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14570             &quot;csetw $dst, lt\n\t&quot;
14571             &quot;subw $dst, zr, $dst&quot;
14572   %}
14573 
14574   ins_encode %{
14575     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14576     __ csetw(as_Register($dst$$reg), Assembler::LT);
14577     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14578   %}
14579 
14580   ins_pipe(ialu_reg_reg);
14581 %}
14582 
14583 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14584 %{
14585   match(Set dst (CmpLTMask src zero));
14586   effect(KILL cr);
14587 
14588   ins_cost(INSN_COST);
14589 
14590   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14591 
14592   ins_encode %{
14593     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14594   %}
14595 
14596   ins_pipe(ialu_reg_shift);
14597 %}
14598 
14599 // ============================================================================
14600 // Max and Min
14601 
14602 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14603 %{
14604   effect( DEF dst, USE src1, USE src2, USE cr );
14605 
14606   ins_cost(INSN_COST * 2);
14607   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14608 
14609   ins_encode %{
14610     __ cselw(as_Register($dst$$reg),
14611              as_Register($src1$$reg),
14612              as_Register($src2$$reg),
14613              Assembler::LT);
14614   %}
14615 
14616   ins_pipe(icond_reg_reg);
14617 %}
14618 
14619 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14620 %{
14621   match(Set dst (MinI src1 src2));
14622   ins_cost(INSN_COST * 3);
14623 
14624   expand %{
14625     rFlagsReg cr;
14626     compI_reg_reg(cr, src1, src2);
14627     cmovI_reg_reg_lt(dst, src1, src2, cr);
14628   %}
14629 
14630 %}
14631 // FROM HERE
14632 
14633 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14634 %{
14635   effect( DEF dst, USE src1, USE src2, USE cr );
14636 
14637   ins_cost(INSN_COST * 2);
14638   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14639 
14640   ins_encode %{
14641     __ cselw(as_Register($dst$$reg),
14642              as_Register($src1$$reg),
14643              as_Register($src2$$reg),
14644              Assembler::GT);
14645   %}
14646 
14647   ins_pipe(icond_reg_reg);
14648 %}
14649 
14650 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14651 %{
14652   match(Set dst (MaxI src1 src2));
14653   ins_cost(INSN_COST * 3);
14654   expand %{
14655     rFlagsReg cr;
14656     compI_reg_reg(cr, src1, src2);
14657     cmovI_reg_reg_gt(dst, src1, src2, cr);
14658   %}
14659 %}
14660 
14661 // ============================================================================
14662 // Branch Instructions
14663 
14664 // Direct Branch.
14665 instruct branch(label lbl)
14666 %{
14667   match(Goto);
14668 
14669   effect(USE lbl);
14670 
14671   ins_cost(BRANCH_COST);
14672   format %{ &quot;b  $lbl&quot; %}
14673 
14674   ins_encode(aarch64_enc_b(lbl));
14675 
14676   ins_pipe(pipe_branch);
14677 %}
14678 
14679 // Conditional Near Branch
14680 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14681 %{
14682   // Same match rule as `branchConFar&#39;.
14683   match(If cmp cr);
14684 
14685   effect(USE lbl);
14686 
14687   ins_cost(BRANCH_COST);
14688   // If set to 1 this indicates that the current instruction is a
14689   // short variant of a long branch. This avoids using this
14690   // instruction in first-pass matching. It will then only be used in
14691   // the `Shorten_branches&#39; pass.
14692   // ins_short_branch(1);
14693   format %{ &quot;b$cmp  $lbl&quot; %}
14694 
14695   ins_encode(aarch64_enc_br_con(cmp, lbl));
14696 
14697   ins_pipe(pipe_branch_cond);
14698 %}
14699 
14700 // Conditional Near Branch Unsigned
14701 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14702 %{
14703   // Same match rule as `branchConFar&#39;.
14704   match(If cmp cr);
14705 
14706   effect(USE lbl);
14707 
14708   ins_cost(BRANCH_COST);
14709   // If set to 1 this indicates that the current instruction is a
14710   // short variant of a long branch. This avoids using this
14711   // instruction in first-pass matching. It will then only be used in
14712   // the `Shorten_branches&#39; pass.
14713   // ins_short_branch(1);
14714   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14715 
14716   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14717 
14718   ins_pipe(pipe_branch_cond);
14719 %}
14720 
14721 // Make use of CBZ and CBNZ.  These instructions, as well as being
14722 // shorter than (cmp; branch), have the additional benefit of not
14723 // killing the flags.
14724 
14725 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14726   match(If cmp (CmpI op1 op2));
14727   effect(USE labl);
14728 
14729   ins_cost(BRANCH_COST);
14730   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14731   ins_encode %{
14732     Label* L = $labl$$label;
14733     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14734     if (cond == Assembler::EQ)
14735       __ cbzw($op1$$Register, *L);
14736     else
14737       __ cbnzw($op1$$Register, *L);
14738   %}
14739   ins_pipe(pipe_cmp_branch);
14740 %}
14741 
14742 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14743   match(If cmp (CmpL op1 op2));
14744   effect(USE labl);
14745 
14746   ins_cost(BRANCH_COST);
14747   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14748   ins_encode %{
14749     Label* L = $labl$$label;
14750     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14751     if (cond == Assembler::EQ)
14752       __ cbz($op1$$Register, *L);
14753     else
14754       __ cbnz($op1$$Register, *L);
14755   %}
14756   ins_pipe(pipe_cmp_branch);
14757 %}
14758 
14759 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14760   match(If cmp (CmpP op1 op2));
14761   effect(USE labl);
14762 
14763   ins_cost(BRANCH_COST);
14764   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14765   ins_encode %{
14766     Label* L = $labl$$label;
14767     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14768     if (cond == Assembler::EQ)
14769       __ cbz($op1$$Register, *L);
14770     else
14771       __ cbnz($op1$$Register, *L);
14772   %}
14773   ins_pipe(pipe_cmp_branch);
14774 %}
14775 
14776 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14777   match(If cmp (CmpN op1 op2));
14778   effect(USE labl);
14779 
14780   ins_cost(BRANCH_COST);
14781   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14782   ins_encode %{
14783     Label* L = $labl$$label;
14784     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14785     if (cond == Assembler::EQ)
14786       __ cbzw($op1$$Register, *L);
14787     else
14788       __ cbnzw($op1$$Register, *L);
14789   %}
14790   ins_pipe(pipe_cmp_branch);
14791 %}
14792 
14793 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14794   match(If cmp (CmpP (DecodeN oop) zero));
14795   effect(USE labl);
14796 
14797   ins_cost(BRANCH_COST);
14798   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14799   ins_encode %{
14800     Label* L = $labl$$label;
14801     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14802     if (cond == Assembler::EQ)
14803       __ cbzw($oop$$Register, *L);
14804     else
14805       __ cbnzw($oop$$Register, *L);
14806   %}
14807   ins_pipe(pipe_cmp_branch);
14808 %}
14809 
14810 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14811   match(If cmp (CmpU op1 op2));
14812   effect(USE labl);
14813 
14814   ins_cost(BRANCH_COST);
14815   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14816   ins_encode %{
14817     Label* L = $labl$$label;
14818     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14819     if (cond == Assembler::EQ || cond == Assembler::LS)
14820       __ cbzw($op1$$Register, *L);
14821     else
14822       __ cbnzw($op1$$Register, *L);
14823   %}
14824   ins_pipe(pipe_cmp_branch);
14825 %}
14826 
14827 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14828   match(If cmp (CmpUL op1 op2));
14829   effect(USE labl);
14830 
14831   ins_cost(BRANCH_COST);
14832   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14833   ins_encode %{
14834     Label* L = $labl$$label;
14835     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14836     if (cond == Assembler::EQ || cond == Assembler::LS)
14837       __ cbz($op1$$Register, *L);
14838     else
14839       __ cbnz($op1$$Register, *L);
14840   %}
14841   ins_pipe(pipe_cmp_branch);
14842 %}
14843 
14844 // Test bit and Branch
14845 
14846 // Patterns for short (&lt; 32KiB) variants
14847 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14848   match(If cmp (CmpL op1 op2));
14849   effect(USE labl);
14850 
14851   ins_cost(BRANCH_COST);
14852   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14853   ins_encode %{
14854     Label* L = $labl$$label;
14855     Assembler::Condition cond =
14856       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14857     __ tbr(cond, $op1$$Register, 63, *L);
14858   %}
14859   ins_pipe(pipe_cmp_branch);
14860   ins_short_branch(1);
14861 %}
14862 
14863 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14864   match(If cmp (CmpI op1 op2));
14865   effect(USE labl);
14866 
14867   ins_cost(BRANCH_COST);
14868   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14869   ins_encode %{
14870     Label* L = $labl$$label;
14871     Assembler::Condition cond =
14872       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14873     __ tbr(cond, $op1$$Register, 31, *L);
14874   %}
14875   ins_pipe(pipe_cmp_branch);
14876   ins_short_branch(1);
14877 %}
14878 
14879 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14880   match(If cmp (CmpL (AndL op1 op2) op3));
14881   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14882   effect(USE labl);
14883 
14884   ins_cost(BRANCH_COST);
14885   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14886   ins_encode %{
14887     Label* L = $labl$$label;
14888     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14889     int bit = exact_log2_long($op2$$constant);
14890     __ tbr(cond, $op1$$Register, bit, *L);
14891   %}
14892   ins_pipe(pipe_cmp_branch);
14893   ins_short_branch(1);
14894 %}
14895 
14896 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14897   match(If cmp (CmpI (AndI op1 op2) op3));
14898   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14899   effect(USE labl);
14900 
14901   ins_cost(BRANCH_COST);
14902   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14903   ins_encode %{
14904     Label* L = $labl$$label;
14905     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14906     int bit = exact_log2((juint)$op2$$constant);
14907     __ tbr(cond, $op1$$Register, bit, *L);
14908   %}
14909   ins_pipe(pipe_cmp_branch);
14910   ins_short_branch(1);
14911 %}
14912 
14913 // And far variants
14914 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14915   match(If cmp (CmpL op1 op2));
14916   effect(USE labl);
14917 
14918   ins_cost(BRANCH_COST);
14919   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14920   ins_encode %{
14921     Label* L = $labl$$label;
14922     Assembler::Condition cond =
14923       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14924     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14925   %}
14926   ins_pipe(pipe_cmp_branch);
14927 %}
14928 
14929 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14930   match(If cmp (CmpI op1 op2));
14931   effect(USE labl);
14932 
14933   ins_cost(BRANCH_COST);
14934   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14935   ins_encode %{
14936     Label* L = $labl$$label;
14937     Assembler::Condition cond =
14938       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14939     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14940   %}
14941   ins_pipe(pipe_cmp_branch);
14942 %}
14943 
14944 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14945   match(If cmp (CmpL (AndL op1 op2) op3));
14946   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14947   effect(USE labl);
14948 
14949   ins_cost(BRANCH_COST);
14950   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14951   ins_encode %{
14952     Label* L = $labl$$label;
14953     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14954     int bit = exact_log2_long($op2$$constant);
14955     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14956   %}
14957   ins_pipe(pipe_cmp_branch);
14958 %}
14959 
14960 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14961   match(If cmp (CmpI (AndI op1 op2) op3));
14962   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14963   effect(USE labl);
14964 
14965   ins_cost(BRANCH_COST);
14966   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14967   ins_encode %{
14968     Label* L = $labl$$label;
14969     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14970     int bit = exact_log2((juint)$op2$$constant);
14971     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14972   %}
14973   ins_pipe(pipe_cmp_branch);
14974 %}
14975 
14976 // Test bits
14977 
14978 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
14979   match(Set cr (CmpL (AndL op1 op2) op3));
14980   predicate(Assembler::operand_valid_for_logical_immediate
14981             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14982 
14983   ins_cost(INSN_COST);
14984   format %{ &quot;tst $op1, $op2 # long&quot; %}
14985   ins_encode %{
14986     __ tst($op1$$Register, $op2$$constant);
14987   %}
14988   ins_pipe(ialu_reg_reg);
14989 %}
14990 
14991 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
14992   match(Set cr (CmpI (AndI op1 op2) op3));
14993   predicate(Assembler::operand_valid_for_logical_immediate
14994             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14995 
14996   ins_cost(INSN_COST);
14997   format %{ &quot;tst $op1, $op2 # int&quot; %}
14998   ins_encode %{
14999     __ tstw($op1$$Register, $op2$$constant);
15000   %}
15001   ins_pipe(ialu_reg_reg);
15002 %}
15003 
15004 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15005   match(Set cr (CmpL (AndL op1 op2) op3));
15006 
15007   ins_cost(INSN_COST);
15008   format %{ &quot;tst $op1, $op2 # long&quot; %}
15009   ins_encode %{
15010     __ tst($op1$$Register, $op2$$Register);
15011   %}
15012   ins_pipe(ialu_reg_reg);
15013 %}
15014 
15015 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15016   match(Set cr (CmpI (AndI op1 op2) op3));
15017 
15018   ins_cost(INSN_COST);
15019   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15020   ins_encode %{
15021     __ tstw($op1$$Register, $op2$$Register);
15022   %}
15023   ins_pipe(ialu_reg_reg);
15024 %}
15025 
15026 
15027 // Conditional Far Branch
15028 // Conditional Far Branch Unsigned
15029 // TODO: fixme
15030 
15031 // counted loop end branch near
15032 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15033 %{
15034   match(CountedLoopEnd cmp cr);
15035 
15036   effect(USE lbl);
15037 
15038   ins_cost(BRANCH_COST);
15039   // short variant.
15040   // ins_short_branch(1);
15041   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15042 
15043   ins_encode(aarch64_enc_br_con(cmp, lbl));
15044 
15045   ins_pipe(pipe_branch);
15046 %}
15047 
15048 // counted loop end branch near Unsigned
15049 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15050 %{
15051   match(CountedLoopEnd cmp cr);
15052 
15053   effect(USE lbl);
15054 
15055   ins_cost(BRANCH_COST);
15056   // short variant.
15057   // ins_short_branch(1);
15058   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15059 
15060   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15061 
15062   ins_pipe(pipe_branch);
15063 %}
15064 
15065 // counted loop end branch far
15066 // counted loop end branch far unsigned
15067 // TODO: fixme
15068 
15069 // ============================================================================
15070 // inlined locking and unlocking
15071 
15072 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15073 %{
15074   match(Set cr (FastLock object box));
15075   effect(TEMP tmp, TEMP tmp2);
15076 
15077   // TODO
15078   // identify correct cost
15079   ins_cost(5 * INSN_COST);
15080   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15081 
15082   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15083 
15084   ins_pipe(pipe_serial);
15085 %}
15086 
15087 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15088 %{
15089   match(Set cr (FastUnlock object box));
15090   effect(TEMP tmp, TEMP tmp2);
15091 
15092   ins_cost(5 * INSN_COST);
15093   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15094 
15095   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15096 
15097   ins_pipe(pipe_serial);
15098 %}
15099 
15100 
15101 // ============================================================================
15102 // Safepoint Instructions
15103 
15104 // TODO
15105 // provide a near and far version of this code
15106 
15107 instruct safePoint(rFlagsReg cr, iRegP poll)
15108 %{
15109   match(SafePoint poll);
15110   effect(KILL cr);
15111 
15112   format %{
15113     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15114   %}
15115   ins_encode %{
15116     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15117   %}
15118   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15119 %}
15120 
15121 
15122 // ============================================================================
15123 // Procedure Call/Return Instructions
15124 
15125 // Call Java Static Instruction
15126 
15127 instruct CallStaticJavaDirect(method meth)
15128 %{
15129   match(CallStaticJava);
15130 
15131   effect(USE meth);
15132 
15133   ins_cost(CALL_COST);
15134 
15135   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15136 
15137   ins_encode( aarch64_enc_java_static_call(meth),
15138               aarch64_enc_call_epilog );
15139 
15140   ins_pipe(pipe_class_call);
15141 %}
15142 
15143 // TO HERE
15144 
15145 // Call Java Dynamic Instruction
15146 instruct CallDynamicJavaDirect(method meth)
15147 %{
15148   match(CallDynamicJava);
15149 
15150   effect(USE meth);
15151 
15152   ins_cost(CALL_COST);
15153 
15154   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15155 
15156   ins_encode( aarch64_enc_java_dynamic_call(meth),
15157                aarch64_enc_call_epilog );
15158 
15159   ins_pipe(pipe_class_call);
15160 %}
15161 
15162 // Call Runtime Instruction
15163 
15164 instruct CallRuntimeDirect(method meth)
15165 %{
15166   match(CallRuntime);
15167 
15168   effect(USE meth);
15169 
15170   ins_cost(CALL_COST);
15171 
15172   format %{ &quot;CALL, runtime $meth&quot; %}
15173 
15174   ins_encode( aarch64_enc_java_to_runtime(meth) );
15175 
15176   ins_pipe(pipe_class_call);
15177 %}
15178 
15179 // Call Runtime Instruction
15180 
15181 instruct CallLeafDirect(method meth)
15182 %{
15183   match(CallLeaf);
15184 
15185   effect(USE meth);
15186 
15187   ins_cost(CALL_COST);
15188 
15189   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15190 
15191   ins_encode( aarch64_enc_java_to_runtime(meth) );
15192 
15193   ins_pipe(pipe_class_call);
15194 %}
15195 
15196 // Call Runtime Instruction
15197 
15198 instruct CallLeafNoFPDirect(method meth)
15199 %{
15200   match(CallLeafNoFP);
15201 
15202   effect(USE meth);
15203 
15204   ins_cost(CALL_COST);
15205 
15206   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15207 
15208   ins_encode( aarch64_enc_java_to_runtime(meth) );
15209 
15210   ins_pipe(pipe_class_call);
15211 %}
15212 
15213 // Tail Call; Jump from runtime stub to Java code.
15214 // Also known as an &#39;interprocedural jump&#39;.
15215 // Target of jump will eventually return to caller.
15216 // TailJump below removes the return address.
15217 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15218 %{
15219   match(TailCall jump_target method_oop);
15220 
15221   ins_cost(CALL_COST);
15222 
15223   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15224 
15225   ins_encode(aarch64_enc_tail_call(jump_target));
15226 
15227   ins_pipe(pipe_class_call);
15228 %}
15229 
15230 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15231 %{
15232   match(TailJump jump_target ex_oop);
15233 
15234   ins_cost(CALL_COST);
15235 
15236   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15237 
15238   ins_encode(aarch64_enc_tail_jmp(jump_target));
15239 
15240   ins_pipe(pipe_class_call);
15241 %}
15242 
15243 // Create exception oop: created by stack-crawling runtime code.
15244 // Created exception is now available to this handler, and is setup
15245 // just prior to jumping to this handler. No code emitted.
15246 // TODO check
15247 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15248 instruct CreateException(iRegP_R0 ex_oop)
15249 %{
15250   match(Set ex_oop (CreateEx));
15251 
15252   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15253 
15254   size(0);
15255 
15256   ins_encode( /*empty*/ );
15257 
15258   ins_pipe(pipe_class_empty);
15259 %}
15260 
15261 // Rethrow exception: The exception oop will come in the first
15262 // argument position. Then JUMP (not call) to the rethrow stub code.
15263 instruct RethrowException() %{
15264   match(Rethrow);
15265   ins_cost(CALL_COST);
15266 
15267   format %{ &quot;b rethrow_stub&quot; %}
15268 
15269   ins_encode( aarch64_enc_rethrow() );
15270 
15271   ins_pipe(pipe_class_call);
15272 %}
15273 
15274 
15275 // Return Instruction
15276 // epilog node loads ret address into lr as part of frame pop
15277 instruct Ret()
15278 %{
15279   match(Return);
15280 
15281   format %{ &quot;ret\t// return register&quot; %}
15282 
15283   ins_encode( aarch64_enc_ret() );
15284 
15285   ins_pipe(pipe_branch);
15286 %}
15287 
15288 // Die now.
15289 instruct ShouldNotReachHere() %{
15290   match(Halt);
15291 
15292   ins_cost(CALL_COST);
15293   format %{ &quot;ShouldNotReachHere&quot; %}
15294 
15295   ins_encode %{
15296     if (is_reachable()) {
15297       __ stop(_halt_reason);
15298     }
15299   %}
15300 
15301   ins_pipe(pipe_class_default);
15302 %}
15303 
15304 // ============================================================================
15305 // Partial Subtype Check
15306 //
15307 // superklass array for an instance of the superklass.  Set a hidden
15308 // internal cache on a hit (cache is checked with exposed code in
15309 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15310 // encoding ALSO sets flags.
15311 
15312 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15313 %{
15314   match(Set result (PartialSubtypeCheck sub super));
15315   effect(KILL cr, KILL temp);
15316 
15317   ins_cost(1100);  // slightly larger than the next version
15318   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15319 
15320   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15321 
15322   opcode(0x1); // Force zero of result reg on hit
15323 
15324   ins_pipe(pipe_class_memory);
15325 %}
15326 
15327 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15328 %{
15329   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15330   effect(KILL temp, KILL result);
15331 
15332   ins_cost(1100);  // slightly larger than the next version
15333   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15334 
15335   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15336 
15337   opcode(0x0); // Don&#39;t zero result reg on hit
15338 
15339   ins_pipe(pipe_class_memory);
15340 %}
15341 
15342 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15343                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15344 %{
15345   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15346   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15347   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15348 
15349   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15350   ins_encode %{
15351     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15352     __ string_compare($str1$$Register, $str2$$Register,
15353                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15354                       $tmp1$$Register, $tmp2$$Register,
15355                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15356   %}
15357   ins_pipe(pipe_class_memory);
15358 %}
15359 
15360 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15361                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15362 %{
15363   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15364   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15365   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15366 
15367   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15368   ins_encode %{
15369     __ string_compare($str1$$Register, $str2$$Register,
15370                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15371                       $tmp1$$Register, $tmp2$$Register,
15372                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15373   %}
15374   ins_pipe(pipe_class_memory);
15375 %}
15376 
15377 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15378                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15379                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15380 %{
15381   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15382   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15383   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15384          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15385 
15386   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15387   ins_encode %{
15388     __ string_compare($str1$$Register, $str2$$Register,
15389                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15390                       $tmp1$$Register, $tmp2$$Register,
15391                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15392                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15393   %}
15394   ins_pipe(pipe_class_memory);
15395 %}
15396 
15397 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15398                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15399                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15400 %{
15401   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15402   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15403   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15404          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15405 
15406   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15407   ins_encode %{
15408     __ string_compare($str1$$Register, $str2$$Register,
15409                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15410                       $tmp1$$Register, $tmp2$$Register,
15411                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15412                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15413   %}
15414   ins_pipe(pipe_class_memory);
15415 %}
15416 
15417 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15418        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15419        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15420 %{
15421   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15422   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15423   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15424          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15425   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15426 
15427   ins_encode %{
15428     __ string_indexof($str1$$Register, $str2$$Register,
15429                       $cnt1$$Register, $cnt2$$Register,
15430                       $tmp1$$Register, $tmp2$$Register,
15431                       $tmp3$$Register, $tmp4$$Register,
15432                       $tmp5$$Register, $tmp6$$Register,
15433                       -1, $result$$Register, StrIntrinsicNode::UU);
15434   %}
15435   ins_pipe(pipe_class_memory);
15436 %}
15437 
15438 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15439        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15440        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15441 %{
15442   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15443   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15444   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15445          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15446   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15447 
15448   ins_encode %{
15449     __ string_indexof($str1$$Register, $str2$$Register,
15450                       $cnt1$$Register, $cnt2$$Register,
15451                       $tmp1$$Register, $tmp2$$Register,
15452                       $tmp3$$Register, $tmp4$$Register,
15453                       $tmp5$$Register, $tmp6$$Register,
15454                       -1, $result$$Register, StrIntrinsicNode::LL);
15455   %}
15456   ins_pipe(pipe_class_memory);
15457 %}
15458 
15459 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15460        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15461        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15462 %{
15463   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15464   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15465   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15466          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15467   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15468 
15469   ins_encode %{
15470     __ string_indexof($str1$$Register, $str2$$Register,
15471                       $cnt1$$Register, $cnt2$$Register,
15472                       $tmp1$$Register, $tmp2$$Register,
15473                       $tmp3$$Register, $tmp4$$Register,
15474                       $tmp5$$Register, $tmp6$$Register,
15475                       -1, $result$$Register, StrIntrinsicNode::UL);
15476   %}
15477   ins_pipe(pipe_class_memory);
15478 %}
15479 
15480 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15481                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15482                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15483 %{
15484   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15485   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15486   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15487          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15488   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15489 
15490   ins_encode %{
15491     int icnt2 = (int)$int_cnt2$$constant;
15492     __ string_indexof($str1$$Register, $str2$$Register,
15493                       $cnt1$$Register, zr,
15494                       $tmp1$$Register, $tmp2$$Register,
15495                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15496                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15497   %}
15498   ins_pipe(pipe_class_memory);
15499 %}
15500 
15501 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15502                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15503                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15504 %{
15505   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15506   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15507   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15508          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15509   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15510 
15511   ins_encode %{
15512     int icnt2 = (int)$int_cnt2$$constant;
15513     __ string_indexof($str1$$Register, $str2$$Register,
15514                       $cnt1$$Register, zr,
15515                       $tmp1$$Register, $tmp2$$Register,
15516                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15517                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15518   %}
15519   ins_pipe(pipe_class_memory);
15520 %}
15521 
15522 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15523                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15524                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15525 %{
15526   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15527   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15528   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15529          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15530   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15531 
15532   ins_encode %{
15533     int icnt2 = (int)$int_cnt2$$constant;
15534     __ string_indexof($str1$$Register, $str2$$Register,
15535                       $cnt1$$Register, zr,
15536                       $tmp1$$Register, $tmp2$$Register,
15537                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15538                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15539   %}
15540   ins_pipe(pipe_class_memory);
15541 %}
15542 
15543 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15544                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15545                               iRegINoSp tmp3, rFlagsReg cr)
15546 %{
15547   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15548   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15549          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15550 
15551   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15552 
15553   ins_encode %{
15554     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15555                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15556                            $tmp3$$Register);
15557   %}
15558   ins_pipe(pipe_class_memory);
15559 %}
15560 
15561 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15562                         iRegI_R0 result, rFlagsReg cr)
15563 %{
15564   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15565   match(Set result (StrEquals (Binary str1 str2) cnt));
15566   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15567 
15568   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15569   ins_encode %{
15570     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15571     __ string_equals($str1$$Register, $str2$$Register,
15572                      $result$$Register, $cnt$$Register, 1);
15573   %}
15574   ins_pipe(pipe_class_memory);
15575 %}
15576 
15577 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15578                         iRegI_R0 result, rFlagsReg cr)
15579 %{
15580   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15581   match(Set result (StrEquals (Binary str1 str2) cnt));
15582   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15583 
15584   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15585   ins_encode %{
15586     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15587     __ string_equals($str1$$Register, $str2$$Register,
15588                      $result$$Register, $cnt$$Register, 2);
15589   %}
15590   ins_pipe(pipe_class_memory);
15591 %}
15592 
15593 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15594                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15595                        iRegP_R10 tmp, rFlagsReg cr)
15596 %{
15597   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15598   match(Set result (AryEq ary1 ary2));
15599   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15600 
15601   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15602   ins_encode %{
15603     __ arrays_equals($ary1$$Register, $ary2$$Register,
15604                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15605                      $result$$Register, $tmp$$Register, 1);
15606     %}
15607   ins_pipe(pipe_class_memory);
15608 %}
15609 
15610 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15611                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15612                        iRegP_R10 tmp, rFlagsReg cr)
15613 %{
15614   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15615   match(Set result (AryEq ary1 ary2));
15616   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15617 
15618   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15619   ins_encode %{
15620     __ arrays_equals($ary1$$Register, $ary2$$Register,
15621                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15622                      $result$$Register, $tmp$$Register, 2);
15623   %}
15624   ins_pipe(pipe_class_memory);
15625 %}
15626 
15627 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15628 %{
15629   match(Set result (HasNegatives ary1 len));
15630   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15631   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15632   ins_encode %{
15633     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15634   %}
15635   ins_pipe( pipe_slow );
15636 %}
15637 
15638 // fast char[] to byte[] compression
15639 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15640                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15641                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15642                          iRegI_R0 result, rFlagsReg cr)
15643 %{
15644   match(Set result (StrCompressedCopy src (Binary dst len)));
15645   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15646 
15647   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15648   ins_encode %{
15649     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15650                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15651                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15652                            $result$$Register);
15653   %}
15654   ins_pipe( pipe_slow );
15655 %}
15656 
15657 // fast byte[] to char[] inflation
15658 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15659                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15660 %{
15661   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15662   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15663 
15664   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15665   ins_encode %{
15666     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15667                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15668   %}
15669   ins_pipe(pipe_class_memory);
15670 %}
15671 
15672 // encode char[] to byte[] in ISO_8859_1
15673 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15674                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15675                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15676                           iRegI_R0 result, rFlagsReg cr)
15677 %{
15678   match(Set result (EncodeISOArray src (Binary dst len)));
15679   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15680          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15681 
15682   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15683   ins_encode %{
15684     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15685          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15686          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15687   %}
15688   ins_pipe( pipe_class_memory );
15689 %}
15690 
15691 // ============================================================================
15692 // This name is KNOWN by the ADLC and cannot be changed.
15693 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15694 // for this guy.
15695 instruct tlsLoadP(thread_RegP dst)
15696 %{
15697   match(Set dst (ThreadLocal));
15698 
15699   ins_cost(0);
15700 
15701   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15702 
15703   size(0);
15704 
15705   ins_encode( /*empty*/ );
15706 
15707   ins_pipe(pipe_class_empty);
15708 %}
15709 
15710 // ====================VECTOR INSTRUCTIONS=====================================
15711 
15712 // Load vector (32 bits)
15713 instruct loadV4(vecD dst, vmem4 mem)
15714 %{
15715   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15716   match(Set dst (LoadVector mem));
15717   ins_cost(4 * INSN_COST);
15718   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15719   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15720   ins_pipe(vload_reg_mem64);
15721 %}
15722 
15723 // Load vector (64 bits)
15724 instruct loadV8(vecD dst, vmem8 mem)
15725 %{
15726   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15727   match(Set dst (LoadVector mem));
15728   ins_cost(4 * INSN_COST);
15729   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15730   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15731   ins_pipe(vload_reg_mem64);
15732 %}
15733 
15734 // Load Vector (128 bits)
15735 instruct loadV16(vecX dst, vmem16 mem)
15736 %{
15737   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15738   match(Set dst (LoadVector mem));
15739   ins_cost(4 * INSN_COST);
15740   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15741   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15742   ins_pipe(vload_reg_mem128);
15743 %}
15744 
15745 // Store Vector (32 bits)
15746 instruct storeV4(vecD src, vmem4 mem)
15747 %{
15748   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15749   match(Set mem (StoreVector mem src));
15750   ins_cost(4 * INSN_COST);
15751   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15752   ins_encode( aarch64_enc_strvS(src, mem) );
15753   ins_pipe(vstore_reg_mem64);
15754 %}
15755 
15756 // Store Vector (64 bits)
15757 instruct storeV8(vecD src, vmem8 mem)
15758 %{
15759   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15760   match(Set mem (StoreVector mem src));
15761   ins_cost(4 * INSN_COST);
15762   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15763   ins_encode( aarch64_enc_strvD(src, mem) );
15764   ins_pipe(vstore_reg_mem64);
15765 %}
15766 
15767 // Store Vector (128 bits)
15768 instruct storeV16(vecX src, vmem16 mem)
15769 %{
15770   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15771   match(Set mem (StoreVector mem src));
15772   ins_cost(4 * INSN_COST);
15773   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15774   ins_encode( aarch64_enc_strvQ(src, mem) );
15775   ins_pipe(vstore_reg_mem128);
15776 %}
15777 
15778 instruct replicate8B(vecD dst, iRegIorL2I src)
15779 %{
15780   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15781             n-&gt;as_Vector()-&gt;length() == 8);
15782   match(Set dst (ReplicateB src));
15783   ins_cost(INSN_COST);
15784   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15785   ins_encode %{
15786     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15787   %}
15788   ins_pipe(vdup_reg_reg64);
15789 %}
15790 
15791 instruct replicate16B(vecX dst, iRegIorL2I src)
15792 %{
15793   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15794   match(Set dst (ReplicateB src));
15795   ins_cost(INSN_COST);
15796   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15797   ins_encode %{
15798     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15799   %}
15800   ins_pipe(vdup_reg_reg128);
15801 %}
15802 
15803 instruct replicate8B_imm(vecD dst, immI con)
15804 %{
15805   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15806             n-&gt;as_Vector()-&gt;length() == 8);
15807   match(Set dst (ReplicateB con));
15808   ins_cost(INSN_COST);
15809   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15810   ins_encode %{
15811     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15812   %}
15813   ins_pipe(vmovi_reg_imm64);
15814 %}
15815 
15816 instruct replicate16B_imm(vecX dst, immI con)
15817 %{
15818   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15819   match(Set dst (ReplicateB con));
15820   ins_cost(INSN_COST);
15821   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15822   ins_encode %{
15823     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15824   %}
15825   ins_pipe(vmovi_reg_imm128);
15826 %}
15827 
15828 instruct replicate4S(vecD dst, iRegIorL2I src)
15829 %{
15830   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15831             n-&gt;as_Vector()-&gt;length() == 4);
15832   match(Set dst (ReplicateS src));
15833   ins_cost(INSN_COST);
15834   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15835   ins_encode %{
15836     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15837   %}
15838   ins_pipe(vdup_reg_reg64);
15839 %}
15840 
15841 instruct replicate8S(vecX dst, iRegIorL2I src)
15842 %{
15843   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15844   match(Set dst (ReplicateS src));
15845   ins_cost(INSN_COST);
15846   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15847   ins_encode %{
15848     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15849   %}
15850   ins_pipe(vdup_reg_reg128);
15851 %}
15852 
15853 instruct replicate4S_imm(vecD dst, immI con)
15854 %{
15855   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15856             n-&gt;as_Vector()-&gt;length() == 4);
15857   match(Set dst (ReplicateS con));
15858   ins_cost(INSN_COST);
15859   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15860   ins_encode %{
15861     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15862   %}
15863   ins_pipe(vmovi_reg_imm64);
15864 %}
15865 
15866 instruct replicate8S_imm(vecX dst, immI con)
15867 %{
15868   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15869   match(Set dst (ReplicateS con));
15870   ins_cost(INSN_COST);
15871   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15872   ins_encode %{
15873     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15874   %}
15875   ins_pipe(vmovi_reg_imm128);
15876 %}
15877 
15878 instruct replicate2I(vecD dst, iRegIorL2I src)
15879 %{
15880   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15881   match(Set dst (ReplicateI src));
15882   ins_cost(INSN_COST);
15883   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15884   ins_encode %{
15885     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15886   %}
15887   ins_pipe(vdup_reg_reg64);
15888 %}
15889 
15890 instruct replicate4I(vecX dst, iRegIorL2I src)
15891 %{
15892   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15893   match(Set dst (ReplicateI src));
15894   ins_cost(INSN_COST);
15895   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15896   ins_encode %{
15897     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15898   %}
15899   ins_pipe(vdup_reg_reg128);
15900 %}
15901 
15902 instruct replicate2I_imm(vecD dst, immI con)
15903 %{
15904   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15905   match(Set dst (ReplicateI con));
15906   ins_cost(INSN_COST);
15907   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15908   ins_encode %{
15909     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15910   %}
15911   ins_pipe(vmovi_reg_imm64);
15912 %}
15913 
15914 instruct replicate4I_imm(vecX dst, immI con)
15915 %{
15916   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15917   match(Set dst (ReplicateI con));
15918   ins_cost(INSN_COST);
15919   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15920   ins_encode %{
15921     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15922   %}
15923   ins_pipe(vmovi_reg_imm128);
15924 %}
15925 
15926 instruct replicate2L(vecX dst, iRegL src)
15927 %{
15928   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15929   match(Set dst (ReplicateL src));
15930   ins_cost(INSN_COST);
15931   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15932   ins_encode %{
15933     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15934   %}
15935   ins_pipe(vdup_reg_reg128);
15936 %}
15937 
15938 instruct replicate2L_zero(vecX dst, immI0 zero)
15939 %{
15940   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15941   match(Set dst (ReplicateI zero));
15942   ins_cost(INSN_COST);
15943   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15944   ins_encode %{
15945     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15946            as_FloatRegister($dst$$reg),
15947            as_FloatRegister($dst$$reg));
15948   %}
15949   ins_pipe(vmovi_reg_imm128);
15950 %}
15951 
15952 instruct replicate2F(vecD dst, vRegF src)
15953 %{
15954   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15955   match(Set dst (ReplicateF src));
15956   ins_cost(INSN_COST);
15957   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15958   ins_encode %{
15959     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15960            as_FloatRegister($src$$reg));
15961   %}
15962   ins_pipe(vdup_reg_freg64);
15963 %}
15964 
15965 instruct replicate4F(vecX dst, vRegF src)
15966 %{
15967   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15968   match(Set dst (ReplicateF src));
15969   ins_cost(INSN_COST);
15970   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
15971   ins_encode %{
15972     __ dup(as_FloatRegister($dst$$reg), __ T4S,
15973            as_FloatRegister($src$$reg));
15974   %}
15975   ins_pipe(vdup_reg_freg128);
15976 %}
15977 
15978 instruct replicate2D(vecX dst, vRegD src)
15979 %{
15980   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15981   match(Set dst (ReplicateD src));
15982   ins_cost(INSN_COST);
15983   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
15984   ins_encode %{
15985     __ dup(as_FloatRegister($dst$$reg), __ T2D,
15986            as_FloatRegister($src$$reg));
15987   %}
15988   ins_pipe(vdup_reg_dreg128);
15989 %}
15990 
15991 // ====================REDUCTION ARITHMETIC====================================
15992 
15993 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
15994 %{
15995   match(Set dst (AddReductionVI isrc vsrc));
15996   ins_cost(INSN_COST);
15997   effect(TEMP tmp, TEMP tmp2);
15998   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
15999             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16000             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16001             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16002   %}
16003   ins_encode %{
16004     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16005     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16006     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16007     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16008   %}
16009   ins_pipe(pipe_class_default);
16010 %}
16011 
16012 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16013 %{
16014   match(Set dst (AddReductionVI isrc vsrc));
16015   ins_cost(INSN_COST);
16016   effect(TEMP vtmp, TEMP itmp);
16017   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16018             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16019             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16020   %}
16021   ins_encode %{
16022     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16023             as_FloatRegister($vsrc$$reg));
16024     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16025     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16026   %}
16027   ins_pipe(pipe_class_default);
16028 %}
16029 
16030 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16031 %{
16032   match(Set dst (MulReductionVI isrc vsrc));
16033   ins_cost(INSN_COST);
16034   effect(TEMP tmp, TEMP dst);
16035   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16036             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16037             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16038             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16039   %}
16040   ins_encode %{
16041     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16042     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16043     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16044     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16045   %}
16046   ins_pipe(pipe_class_default);
16047 %}
16048 
16049 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16050 %{
16051   match(Set dst (MulReductionVI isrc vsrc));
16052   ins_cost(INSN_COST);
16053   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16054   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16055             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16056             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16057             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16058             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16059             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16060   %}
16061   ins_encode %{
16062     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16063            as_FloatRegister($vsrc$$reg), 0, 1);
16064     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16065             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16066     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16067     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16068     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16069     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16070   %}
16071   ins_pipe(pipe_class_default);
16072 %}
16073 
16074 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16075 %{
16076   match(Set dst (AddReductionVF fsrc vsrc));
16077   ins_cost(INSN_COST);
16078   effect(TEMP tmp, TEMP dst);
16079   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16080             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16081             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16082   %}
16083   ins_encode %{
16084     __ fadds(as_FloatRegister($dst$$reg),
16085              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16086     __ ins(as_FloatRegister($tmp$$reg), __ S,
16087            as_FloatRegister($vsrc$$reg), 0, 1);
16088     __ fadds(as_FloatRegister($dst$$reg),
16089              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16090   %}
16091   ins_pipe(pipe_class_default);
16092 %}
16093 
16094 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16095 %{
16096   match(Set dst (AddReductionVF fsrc vsrc));
16097   ins_cost(INSN_COST);
16098   effect(TEMP tmp, TEMP dst);
16099   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16100             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16101             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16102             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16103             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16104             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16105             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16106   %}
16107   ins_encode %{
16108     __ fadds(as_FloatRegister($dst$$reg),
16109              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16110     __ ins(as_FloatRegister($tmp$$reg), __ S,
16111            as_FloatRegister($vsrc$$reg), 0, 1);
16112     __ fadds(as_FloatRegister($dst$$reg),
16113              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16114     __ ins(as_FloatRegister($tmp$$reg), __ S,
16115            as_FloatRegister($vsrc$$reg), 0, 2);
16116     __ fadds(as_FloatRegister($dst$$reg),
16117              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16118     __ ins(as_FloatRegister($tmp$$reg), __ S,
16119            as_FloatRegister($vsrc$$reg), 0, 3);
16120     __ fadds(as_FloatRegister($dst$$reg),
16121              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16122   %}
16123   ins_pipe(pipe_class_default);
16124 %}
16125 
16126 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16127 %{
16128   match(Set dst (MulReductionVF fsrc vsrc));
16129   ins_cost(INSN_COST);
16130   effect(TEMP tmp, TEMP dst);
16131   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16132             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16133             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16134   %}
16135   ins_encode %{
16136     __ fmuls(as_FloatRegister($dst$$reg),
16137              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16138     __ ins(as_FloatRegister($tmp$$reg), __ S,
16139            as_FloatRegister($vsrc$$reg), 0, 1);
16140     __ fmuls(as_FloatRegister($dst$$reg),
16141              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16142   %}
16143   ins_pipe(pipe_class_default);
16144 %}
16145 
16146 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16147 %{
16148   match(Set dst (MulReductionVF fsrc vsrc));
16149   ins_cost(INSN_COST);
16150   effect(TEMP tmp, TEMP dst);
16151   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16152             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16153             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16154             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16155             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16156             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16157             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16158   %}
16159   ins_encode %{
16160     __ fmuls(as_FloatRegister($dst$$reg),
16161              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16162     __ ins(as_FloatRegister($tmp$$reg), __ S,
16163            as_FloatRegister($vsrc$$reg), 0, 1);
16164     __ fmuls(as_FloatRegister($dst$$reg),
16165              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16166     __ ins(as_FloatRegister($tmp$$reg), __ S,
16167            as_FloatRegister($vsrc$$reg), 0, 2);
16168     __ fmuls(as_FloatRegister($dst$$reg),
16169              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16170     __ ins(as_FloatRegister($tmp$$reg), __ S,
16171            as_FloatRegister($vsrc$$reg), 0, 3);
16172     __ fmuls(as_FloatRegister($dst$$reg),
16173              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16174   %}
16175   ins_pipe(pipe_class_default);
16176 %}
16177 
16178 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16179 %{
16180   match(Set dst (AddReductionVD dsrc vsrc));
16181   ins_cost(INSN_COST);
16182   effect(TEMP tmp, TEMP dst);
16183   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16184             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16185             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16186   %}
16187   ins_encode %{
16188     __ faddd(as_FloatRegister($dst$$reg),
16189              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16190     __ ins(as_FloatRegister($tmp$$reg), __ D,
16191            as_FloatRegister($vsrc$$reg), 0, 1);
16192     __ faddd(as_FloatRegister($dst$$reg),
16193              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16194   %}
16195   ins_pipe(pipe_class_default);
16196 %}
16197 
16198 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16199 %{
16200   match(Set dst (MulReductionVD dsrc vsrc));
16201   ins_cost(INSN_COST);
16202   effect(TEMP tmp, TEMP dst);
16203   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16204             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16205             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16206   %}
16207   ins_encode %{
16208     __ fmuld(as_FloatRegister($dst$$reg),
16209              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16210     __ ins(as_FloatRegister($tmp$$reg), __ D,
16211            as_FloatRegister($vsrc$$reg), 0, 1);
16212     __ fmuld(as_FloatRegister($dst$$reg),
16213              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16214   %}
16215   ins_pipe(pipe_class_default);
16216 %}
16217 
16218 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16219   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16220   match(Set dst (MaxReductionV fsrc vsrc));
16221   ins_cost(INSN_COST);
16222   effect(TEMP_DEF dst, TEMP tmp);
16223   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16224             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16225             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16226   ins_encode %{
16227     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16228     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16229     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16230   %}
16231   ins_pipe(pipe_class_default);
16232 %}
16233 
16234 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16235   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16236   match(Set dst (MaxReductionV fsrc vsrc));
16237   ins_cost(INSN_COST);
16238   effect(TEMP_DEF dst);
16239   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16240             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16241   ins_encode %{
16242     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16243     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16244   %}
16245   ins_pipe(pipe_class_default);
16246 %}
16247 
16248 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16249   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16250   match(Set dst (MaxReductionV dsrc vsrc));
16251   ins_cost(INSN_COST);
16252   effect(TEMP_DEF dst, TEMP tmp);
16253   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16254             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16255             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16256   ins_encode %{
16257     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16258     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16259     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16260   %}
16261   ins_pipe(pipe_class_default);
16262 %}
16263 
16264 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16265   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16266   match(Set dst (MinReductionV fsrc vsrc));
16267   ins_cost(INSN_COST);
16268   effect(TEMP_DEF dst, TEMP tmp);
16269   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16270             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16271             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16272   ins_encode %{
16273     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16274     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16275     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16276   %}
16277   ins_pipe(pipe_class_default);
16278 %}
16279 
16280 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16281   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16282   match(Set dst (MinReductionV fsrc vsrc));
16283   ins_cost(INSN_COST);
16284   effect(TEMP_DEF dst);
16285   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16286             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16287   ins_encode %{
16288     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16289     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16290   %}
16291   ins_pipe(pipe_class_default);
16292 %}
16293 
16294 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16295   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16296   match(Set dst (MinReductionV dsrc vsrc));
16297   ins_cost(INSN_COST);
16298   effect(TEMP_DEF dst, TEMP tmp);
16299   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16300             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16301             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16302   ins_encode %{
16303     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16304     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16305     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16306   %}
16307   ins_pipe(pipe_class_default);
16308 %}
16309 
16310 // ====================VECTOR ARITHMETIC=======================================
16311 
16312 // --------------------------------- ADD --------------------------------------
16313 
16314 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16315 %{
16316   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16317             n-&gt;as_Vector()-&gt;length() == 8);
16318   match(Set dst (AddVB src1 src2));
16319   ins_cost(INSN_COST);
16320   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16321   ins_encode %{
16322     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16323             as_FloatRegister($src1$$reg),
16324             as_FloatRegister($src2$$reg));
16325   %}
16326   ins_pipe(vdop64);
16327 %}
16328 
16329 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16330 %{
16331   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16332   match(Set dst (AddVB src1 src2));
16333   ins_cost(INSN_COST);
16334   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16335   ins_encode %{
16336     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16337             as_FloatRegister($src1$$reg),
16338             as_FloatRegister($src2$$reg));
16339   %}
16340   ins_pipe(vdop128);
16341 %}
16342 
16343 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16344 %{
16345   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16346             n-&gt;as_Vector()-&gt;length() == 4);
16347   match(Set dst (AddVS src1 src2));
16348   ins_cost(INSN_COST);
16349   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16350   ins_encode %{
16351     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16352             as_FloatRegister($src1$$reg),
16353             as_FloatRegister($src2$$reg));
16354   %}
16355   ins_pipe(vdop64);
16356 %}
16357 
16358 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16359 %{
16360   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16361   match(Set dst (AddVS src1 src2));
16362   ins_cost(INSN_COST);
16363   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16364   ins_encode %{
16365     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16366             as_FloatRegister($src1$$reg),
16367             as_FloatRegister($src2$$reg));
16368   %}
16369   ins_pipe(vdop128);
16370 %}
16371 
16372 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16373 %{
16374   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16375   match(Set dst (AddVI src1 src2));
16376   ins_cost(INSN_COST);
16377   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16378   ins_encode %{
16379     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16380             as_FloatRegister($src1$$reg),
16381             as_FloatRegister($src2$$reg));
16382   %}
16383   ins_pipe(vdop64);
16384 %}
16385 
16386 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16387 %{
16388   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16389   match(Set dst (AddVI src1 src2));
16390   ins_cost(INSN_COST);
16391   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16392   ins_encode %{
16393     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16394             as_FloatRegister($src1$$reg),
16395             as_FloatRegister($src2$$reg));
16396   %}
16397   ins_pipe(vdop128);
16398 %}
16399 
16400 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16401 %{
16402   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16403   match(Set dst (AddVL src1 src2));
16404   ins_cost(INSN_COST);
16405   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16406   ins_encode %{
16407     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16408             as_FloatRegister($src1$$reg),
16409             as_FloatRegister($src2$$reg));
16410   %}
16411   ins_pipe(vdop128);
16412 %}
16413 
16414 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16415 %{
16416   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16417   match(Set dst (AddVF src1 src2));
16418   ins_cost(INSN_COST);
16419   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16420   ins_encode %{
16421     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16422             as_FloatRegister($src1$$reg),
16423             as_FloatRegister($src2$$reg));
16424   %}
16425   ins_pipe(vdop_fp64);
16426 %}
16427 
16428 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16429 %{
16430   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16431   match(Set dst (AddVF src1 src2));
16432   ins_cost(INSN_COST);
16433   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16434   ins_encode %{
16435     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16436             as_FloatRegister($src1$$reg),
16437             as_FloatRegister($src2$$reg));
16438   %}
16439   ins_pipe(vdop_fp128);
16440 %}
16441 
16442 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16443 %{
16444   match(Set dst (AddVD src1 src2));
16445   ins_cost(INSN_COST);
16446   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16447   ins_encode %{
16448     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16449             as_FloatRegister($src1$$reg),
16450             as_FloatRegister($src2$$reg));
16451   %}
16452   ins_pipe(vdop_fp128);
16453 %}
16454 
16455 // --------------------------------- SUB --------------------------------------
16456 
16457 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16458 %{
16459   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16460             n-&gt;as_Vector()-&gt;length() == 8);
16461   match(Set dst (SubVB src1 src2));
16462   ins_cost(INSN_COST);
16463   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16464   ins_encode %{
16465     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16466             as_FloatRegister($src1$$reg),
16467             as_FloatRegister($src2$$reg));
16468   %}
16469   ins_pipe(vdop64);
16470 %}
16471 
16472 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16473 %{
16474   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16475   match(Set dst (SubVB src1 src2));
16476   ins_cost(INSN_COST);
16477   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16478   ins_encode %{
16479     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16480             as_FloatRegister($src1$$reg),
16481             as_FloatRegister($src2$$reg));
16482   %}
16483   ins_pipe(vdop128);
16484 %}
16485 
16486 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16487 %{
16488   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16489             n-&gt;as_Vector()-&gt;length() == 4);
16490   match(Set dst (SubVS src1 src2));
16491   ins_cost(INSN_COST);
16492   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16493   ins_encode %{
16494     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16495             as_FloatRegister($src1$$reg),
16496             as_FloatRegister($src2$$reg));
16497   %}
16498   ins_pipe(vdop64);
16499 %}
16500 
16501 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16502 %{
16503   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16504   match(Set dst (SubVS src1 src2));
16505   ins_cost(INSN_COST);
16506   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16507   ins_encode %{
16508     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16509             as_FloatRegister($src1$$reg),
16510             as_FloatRegister($src2$$reg));
16511   %}
16512   ins_pipe(vdop128);
16513 %}
16514 
16515 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16516 %{
16517   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16518   match(Set dst (SubVI src1 src2));
16519   ins_cost(INSN_COST);
16520   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16521   ins_encode %{
16522     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16523             as_FloatRegister($src1$$reg),
16524             as_FloatRegister($src2$$reg));
16525   %}
16526   ins_pipe(vdop64);
16527 %}
16528 
16529 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16530 %{
16531   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16532   match(Set dst (SubVI src1 src2));
16533   ins_cost(INSN_COST);
16534   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16535   ins_encode %{
16536     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16537             as_FloatRegister($src1$$reg),
16538             as_FloatRegister($src2$$reg));
16539   %}
16540   ins_pipe(vdop128);
16541 %}
16542 
16543 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16544 %{
16545   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16546   match(Set dst (SubVL src1 src2));
16547   ins_cost(INSN_COST);
16548   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16549   ins_encode %{
16550     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16551             as_FloatRegister($src1$$reg),
16552             as_FloatRegister($src2$$reg));
16553   %}
16554   ins_pipe(vdop128);
16555 %}
16556 
16557 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16558 %{
16559   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16560   match(Set dst (SubVF src1 src2));
16561   ins_cost(INSN_COST);
16562   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16563   ins_encode %{
16564     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16565             as_FloatRegister($src1$$reg),
16566             as_FloatRegister($src2$$reg));
16567   %}
16568   ins_pipe(vdop_fp64);
16569 %}
16570 
16571 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16572 %{
16573   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16574   match(Set dst (SubVF src1 src2));
16575   ins_cost(INSN_COST);
16576   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16577   ins_encode %{
16578     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16579             as_FloatRegister($src1$$reg),
16580             as_FloatRegister($src2$$reg));
16581   %}
16582   ins_pipe(vdop_fp128);
16583 %}
16584 
16585 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16586 %{
16587   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16588   match(Set dst (SubVD src1 src2));
16589   ins_cost(INSN_COST);
16590   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16591   ins_encode %{
16592     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16593             as_FloatRegister($src1$$reg),
16594             as_FloatRegister($src2$$reg));
16595   %}
16596   ins_pipe(vdop_fp128);
16597 %}
16598 
16599 // --------------------------------- MUL --------------------------------------
16600 
16601 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16602 %{
16603   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16604             n-&gt;as_Vector()-&gt;length() == 8);
16605   match(Set dst (MulVB src1 src2));
16606   ins_cost(INSN_COST);
16607   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16608   ins_encode %{
16609     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16610             as_FloatRegister($src1$$reg),
16611             as_FloatRegister($src2$$reg));
16612   %}
16613   ins_pipe(vmul64);
16614 %}
16615 
16616 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16617 %{
16618   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16619   match(Set dst (MulVB src1 src2));
16620   ins_cost(INSN_COST);
16621   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16622   ins_encode %{
16623     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16624             as_FloatRegister($src1$$reg),
16625             as_FloatRegister($src2$$reg));
16626   %}
16627   ins_pipe(vmul128);
16628 %}
16629 
16630 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16631 %{
16632   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16633             n-&gt;as_Vector()-&gt;length() == 4);
16634   match(Set dst (MulVS src1 src2));
16635   ins_cost(INSN_COST);
16636   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16637   ins_encode %{
16638     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16639             as_FloatRegister($src1$$reg),
16640             as_FloatRegister($src2$$reg));
16641   %}
16642   ins_pipe(vmul64);
16643 %}
16644 
16645 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16646 %{
16647   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16648   match(Set dst (MulVS src1 src2));
16649   ins_cost(INSN_COST);
16650   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16651   ins_encode %{
16652     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16653             as_FloatRegister($src1$$reg),
16654             as_FloatRegister($src2$$reg));
16655   %}
16656   ins_pipe(vmul128);
16657 %}
16658 
16659 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16660 %{
16661   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16662   match(Set dst (MulVI src1 src2));
16663   ins_cost(INSN_COST);
16664   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16665   ins_encode %{
16666     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16667             as_FloatRegister($src1$$reg),
16668             as_FloatRegister($src2$$reg));
16669   %}
16670   ins_pipe(vmul64);
16671 %}
16672 
16673 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16674 %{
16675   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16676   match(Set dst (MulVI src1 src2));
16677   ins_cost(INSN_COST);
16678   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16679   ins_encode %{
16680     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16681             as_FloatRegister($src1$$reg),
16682             as_FloatRegister($src2$$reg));
16683   %}
16684   ins_pipe(vmul128);
16685 %}
16686 
16687 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16688 %{
16689   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16690   match(Set dst (MulVF src1 src2));
16691   ins_cost(INSN_COST);
16692   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16693   ins_encode %{
16694     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16695             as_FloatRegister($src1$$reg),
16696             as_FloatRegister($src2$$reg));
16697   %}
16698   ins_pipe(vmuldiv_fp64);
16699 %}
16700 
16701 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16702 %{
16703   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16704   match(Set dst (MulVF src1 src2));
16705   ins_cost(INSN_COST);
16706   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16707   ins_encode %{
16708     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16709             as_FloatRegister($src1$$reg),
16710             as_FloatRegister($src2$$reg));
16711   %}
16712   ins_pipe(vmuldiv_fp128);
16713 %}
16714 
16715 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16716 %{
16717   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16718   match(Set dst (MulVD src1 src2));
16719   ins_cost(INSN_COST);
16720   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16721   ins_encode %{
16722     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16723             as_FloatRegister($src1$$reg),
16724             as_FloatRegister($src2$$reg));
16725   %}
16726   ins_pipe(vmuldiv_fp128);
16727 %}
16728 
16729 // --------------------------------- MLA --------------------------------------
16730 
16731 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16732 %{
16733   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16734             n-&gt;as_Vector()-&gt;length() == 4);
16735   match(Set dst (AddVS dst (MulVS src1 src2)));
16736   ins_cost(INSN_COST);
16737   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16738   ins_encode %{
16739     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16740             as_FloatRegister($src1$$reg),
16741             as_FloatRegister($src2$$reg));
16742   %}
16743   ins_pipe(vmla64);
16744 %}
16745 
16746 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16747 %{
16748   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16749   match(Set dst (AddVS dst (MulVS src1 src2)));
16750   ins_cost(INSN_COST);
16751   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16752   ins_encode %{
16753     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16754             as_FloatRegister($src1$$reg),
16755             as_FloatRegister($src2$$reg));
16756   %}
16757   ins_pipe(vmla128);
16758 %}
16759 
16760 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16761 %{
16762   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16763   match(Set dst (AddVI dst (MulVI src1 src2)));
16764   ins_cost(INSN_COST);
16765   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16766   ins_encode %{
16767     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16768             as_FloatRegister($src1$$reg),
16769             as_FloatRegister($src2$$reg));
16770   %}
16771   ins_pipe(vmla64);
16772 %}
16773 
16774 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16775 %{
16776   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16777   match(Set dst (AddVI dst (MulVI src1 src2)));
16778   ins_cost(INSN_COST);
16779   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16780   ins_encode %{
16781     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16782             as_FloatRegister($src1$$reg),
16783             as_FloatRegister($src2$$reg));
16784   %}
16785   ins_pipe(vmla128);
16786 %}
16787 
16788 // dst + src1 * src2
16789 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16790   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16791   match(Set dst (FmaVF  dst (Binary src1 src2)));
16792   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16793   ins_cost(INSN_COST);
16794   ins_encode %{
16795     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16796             as_FloatRegister($src1$$reg),
16797             as_FloatRegister($src2$$reg));
16798   %}
16799   ins_pipe(vmuldiv_fp64);
16800 %}
16801 
16802 // dst + src1 * src2
16803 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16804   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16805   match(Set dst (FmaVF  dst (Binary src1 src2)));
16806   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16807   ins_cost(INSN_COST);
16808   ins_encode %{
16809     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16810             as_FloatRegister($src1$$reg),
16811             as_FloatRegister($src2$$reg));
16812   %}
16813   ins_pipe(vmuldiv_fp128);
16814 %}
16815 
16816 // dst + src1 * src2
16817 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16818   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16819   match(Set dst (FmaVD  dst (Binary src1 src2)));
16820   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16821   ins_cost(INSN_COST);
16822   ins_encode %{
16823     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16824             as_FloatRegister($src1$$reg),
16825             as_FloatRegister($src2$$reg));
16826   %}
16827   ins_pipe(vmuldiv_fp128);
16828 %}
16829 
16830 // --------------------------------- MLS --------------------------------------
16831 
16832 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16833 %{
16834   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16835             n-&gt;as_Vector()-&gt;length() == 4);
16836   match(Set dst (SubVS dst (MulVS src1 src2)));
16837   ins_cost(INSN_COST);
16838   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16839   ins_encode %{
16840     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16841             as_FloatRegister($src1$$reg),
16842             as_FloatRegister($src2$$reg));
16843   %}
16844   ins_pipe(vmla64);
16845 %}
16846 
16847 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16848 %{
16849   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16850   match(Set dst (SubVS dst (MulVS src1 src2)));
16851   ins_cost(INSN_COST);
16852   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16853   ins_encode %{
16854     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16855             as_FloatRegister($src1$$reg),
16856             as_FloatRegister($src2$$reg));
16857   %}
16858   ins_pipe(vmla128);
16859 %}
16860 
16861 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16862 %{
16863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16864   match(Set dst (SubVI dst (MulVI src1 src2)));
16865   ins_cost(INSN_COST);
16866   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16867   ins_encode %{
16868     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16869             as_FloatRegister($src1$$reg),
16870             as_FloatRegister($src2$$reg));
16871   %}
16872   ins_pipe(vmla64);
16873 %}
16874 
16875 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16876 %{
16877   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16878   match(Set dst (SubVI dst (MulVI src1 src2)));
16879   ins_cost(INSN_COST);
16880   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16881   ins_encode %{
16882     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16883             as_FloatRegister($src1$$reg),
16884             as_FloatRegister($src2$$reg));
16885   %}
16886   ins_pipe(vmla128);
16887 %}
16888 
16889 // dst - src1 * src2
16890 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16891   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16892   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16893   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16894   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16895   ins_cost(INSN_COST);
16896   ins_encode %{
16897     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16898             as_FloatRegister($src1$$reg),
16899             as_FloatRegister($src2$$reg));
16900   %}
16901   ins_pipe(vmuldiv_fp64);
16902 %}
16903 
16904 // dst - src1 * src2
16905 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16906   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16907   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16908   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16909   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16910   ins_cost(INSN_COST);
16911   ins_encode %{
16912     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16913             as_FloatRegister($src1$$reg),
16914             as_FloatRegister($src2$$reg));
16915   %}
16916   ins_pipe(vmuldiv_fp128);
16917 %}
16918 
16919 // dst - src1 * src2
16920 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16921   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16922   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16923   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16924   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16925   ins_cost(INSN_COST);
16926   ins_encode %{
16927     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16928             as_FloatRegister($src1$$reg),
16929             as_FloatRegister($src2$$reg));
16930   %}
16931   ins_pipe(vmuldiv_fp128);
16932 %}
16933 
16934 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16935 
16936 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16937   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16938   match(Set dst (MulAddVS2VI src1 src2));
16939   ins_cost(INSN_COST);
16940   effect(TEMP_DEF dst, TEMP tmp);
16941   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16942             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16943             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16944   ins_encode %{
16945     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16946               as_FloatRegister($src1$$reg),
16947               as_FloatRegister($src2$$reg));
16948     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16949               as_FloatRegister($src1$$reg),
16950               as_FloatRegister($src2$$reg));
16951     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16952              as_FloatRegister($tmp$$reg),
16953              as_FloatRegister($dst$$reg));
16954   %}
16955   ins_pipe(vmuldiv_fp128);
16956 %}
16957 
16958 // --------------------------------- DIV --------------------------------------
16959 
16960 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16961 %{
16962   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16963   match(Set dst (DivVF src1 src2));
16964   ins_cost(INSN_COST);
16965   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16966   ins_encode %{
16967     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16968             as_FloatRegister($src1$$reg),
16969             as_FloatRegister($src2$$reg));
16970   %}
16971   ins_pipe(vmuldiv_fp64);
16972 %}
16973 
16974 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16975 %{
16976   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16977   match(Set dst (DivVF src1 src2));
16978   ins_cost(INSN_COST);
16979   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16980   ins_encode %{
16981     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16982             as_FloatRegister($src1$$reg),
16983             as_FloatRegister($src2$$reg));
16984   %}
16985   ins_pipe(vmuldiv_fp128);
16986 %}
16987 
16988 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16989 %{
16990   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16991   match(Set dst (DivVD src1 src2));
16992   ins_cost(INSN_COST);
16993   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16994   ins_encode %{
16995     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16996             as_FloatRegister($src1$$reg),
16997             as_FloatRegister($src2$$reg));
16998   %}
16999   ins_pipe(vmuldiv_fp128);
17000 %}
17001 
17002 // --------------------------------- SQRT -------------------------------------
17003 
17004 instruct vsqrt2F(vecD dst, vecD src)
17005 %{
17006   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17007   match(Set dst (SqrtVF src));
17008   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17009   ins_encode %{
17010     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17011   %}
17012   ins_pipe(vunop_fp64);
17013 %}
17014 
17015 instruct vsqrt4F(vecX dst, vecX src)
17016 %{
17017   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17018   match(Set dst (SqrtVF src));
17019   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17020   ins_encode %{
17021     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17022   %}
17023   ins_pipe(vsqrt_fp128);
17024 %}
17025 
17026 instruct vsqrt2D(vecX dst, vecX src)
17027 %{
17028   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17029   match(Set dst (SqrtVD src));
17030   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17031   ins_encode %{
17032     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17033              as_FloatRegister($src$$reg));
17034   %}
17035   ins_pipe(vsqrt_fp128);
17036 %}
17037 
17038 // --------------------------------- ABS --------------------------------------
17039 
17040 instruct vabs8B(vecD dst, vecD src)
17041 %{
17042   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17043             n-&gt;as_Vector()-&gt;length() == 8);
17044   match(Set dst (AbsVB src));
17045   ins_cost(INSN_COST);
17046   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17047   ins_encode %{
17048     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17049   %}
17050   ins_pipe(vlogical64);
17051 %}
17052 
17053 instruct vabs16B(vecX dst, vecX src)
17054 %{
17055   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17056   match(Set dst (AbsVB src));
17057   ins_cost(INSN_COST);
17058   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17059   ins_encode %{
17060     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17061   %}
17062   ins_pipe(vlogical128);
17063 %}
17064 
17065 instruct vabs4S(vecD dst, vecD src)
17066 %{
17067   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17068   match(Set dst (AbsVS src));
17069   ins_cost(INSN_COST);
17070   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17071   ins_encode %{
17072     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17073   %}
17074   ins_pipe(vlogical64);
17075 %}
17076 
17077 instruct vabs8S(vecX dst, vecX src)
17078 %{
17079   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17080   match(Set dst (AbsVS src));
17081   ins_cost(INSN_COST);
17082   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17083   ins_encode %{
17084     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17085   %}
17086   ins_pipe(vlogical128);
17087 %}
17088 
17089 instruct vabs2I(vecD dst, vecD src)
17090 %{
17091   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17092   match(Set dst (AbsVI src));
17093   ins_cost(INSN_COST);
17094   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17095   ins_encode %{
17096     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17097   %}
17098   ins_pipe(vlogical64);
17099 %}
17100 
17101 instruct vabs4I(vecX dst, vecX src)
17102 %{
17103   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17104   match(Set dst (AbsVI src));
17105   ins_cost(INSN_COST);
17106   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17107   ins_encode %{
17108     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17109   %}
17110   ins_pipe(vlogical128);
17111 %}
17112 
17113 instruct vabs2L(vecX dst, vecX src)
17114 %{
17115   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17116   match(Set dst (AbsVL src));
17117   ins_cost(INSN_COST);
17118   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17119   ins_encode %{
17120     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17121   %}
17122   ins_pipe(vlogical128);
17123 %}
17124 
17125 instruct vabs2F(vecD dst, vecD src)
17126 %{
17127   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17128   match(Set dst (AbsVF src));
17129   ins_cost(INSN_COST * 3);
17130   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17131   ins_encode %{
17132     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17133             as_FloatRegister($src$$reg));
17134   %}
17135   ins_pipe(vunop_fp64);
17136 %}
17137 
17138 instruct vabs4F(vecX dst, vecX src)
17139 %{
17140   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17141   match(Set dst (AbsVF src));
17142   ins_cost(INSN_COST * 3);
17143   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17144   ins_encode %{
17145     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17146             as_FloatRegister($src$$reg));
17147   %}
17148   ins_pipe(vunop_fp128);
17149 %}
17150 
17151 instruct vabs2D(vecX dst, vecX src)
17152 %{
17153   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17154   match(Set dst (AbsVD src));
17155   ins_cost(INSN_COST * 3);
17156   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17157   ins_encode %{
17158     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17159             as_FloatRegister($src$$reg));
17160   %}
17161   ins_pipe(vunop_fp128);
17162 %}
17163 
17164 // --------------------------------- NEG --------------------------------------
17165 
17166 instruct vneg2F(vecD dst, vecD src)
17167 %{
17168   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17169   match(Set dst (NegVF src));
17170   ins_cost(INSN_COST * 3);
17171   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17172   ins_encode %{
17173     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17174             as_FloatRegister($src$$reg));
17175   %}
17176   ins_pipe(vunop_fp64);
17177 %}
17178 
17179 instruct vneg4F(vecX dst, vecX src)
17180 %{
17181   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17182   match(Set dst (NegVF src));
17183   ins_cost(INSN_COST * 3);
17184   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17185   ins_encode %{
17186     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17187             as_FloatRegister($src$$reg));
17188   %}
17189   ins_pipe(vunop_fp128);
17190 %}
17191 
17192 instruct vneg2D(vecX dst, vecX src)
17193 %{
17194   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17195   match(Set dst (NegVD src));
17196   ins_cost(INSN_COST * 3);
17197   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17198   ins_encode %{
17199     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17200             as_FloatRegister($src$$reg));
17201   %}
17202   ins_pipe(vunop_fp128);
17203 %}
17204 
17205 // --------------------------------- AND --------------------------------------
17206 
17207 instruct vand8B(vecD dst, vecD src1, vecD src2)
17208 %{
17209   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17210             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17211   match(Set dst (AndV src1 src2));
17212   ins_cost(INSN_COST);
17213   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17214   ins_encode %{
17215     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17216             as_FloatRegister($src1$$reg),
17217             as_FloatRegister($src2$$reg));
17218   %}
17219   ins_pipe(vlogical64);
17220 %}
17221 
17222 instruct vand16B(vecX dst, vecX src1, vecX src2)
17223 %{
17224   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17225   match(Set dst (AndV src1 src2));
17226   ins_cost(INSN_COST);
17227   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17228   ins_encode %{
17229     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17230             as_FloatRegister($src1$$reg),
17231             as_FloatRegister($src2$$reg));
17232   %}
17233   ins_pipe(vlogical128);
17234 %}
17235 
17236 // --------------------------------- OR ---------------------------------------
17237 
17238 instruct vor8B(vecD dst, vecD src1, vecD src2)
17239 %{
17240   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17241             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17242   match(Set dst (OrV src1 src2));
17243   ins_cost(INSN_COST);
17244   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17245   ins_encode %{
17246     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17247             as_FloatRegister($src1$$reg),
17248             as_FloatRegister($src2$$reg));
17249   %}
17250   ins_pipe(vlogical64);
17251 %}
17252 
17253 instruct vor16B(vecX dst, vecX src1, vecX src2)
17254 %{
17255   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17256   match(Set dst (OrV src1 src2));
17257   ins_cost(INSN_COST);
17258   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17259   ins_encode %{
17260     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17261             as_FloatRegister($src1$$reg),
17262             as_FloatRegister($src2$$reg));
17263   %}
17264   ins_pipe(vlogical128);
17265 %}
17266 
17267 // --------------------------------- XOR --------------------------------------
17268 
17269 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17270 %{
17271   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17272             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17273   match(Set dst (XorV src1 src2));
17274   ins_cost(INSN_COST);
17275   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17276   ins_encode %{
17277     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17278             as_FloatRegister($src1$$reg),
17279             as_FloatRegister($src2$$reg));
17280   %}
17281   ins_pipe(vlogical64);
17282 %}
17283 
17284 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17285 %{
17286   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17287   match(Set dst (XorV src1 src2));
17288   ins_cost(INSN_COST);
17289   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17290   ins_encode %{
17291     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17292             as_FloatRegister($src1$$reg),
17293             as_FloatRegister($src2$$reg));
17294   %}
17295   ins_pipe(vlogical128);
17296 %}
17297 
17298 // ------------------------------ Shift ---------------------------------------
17299 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17300   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17301   match(Set dst (LShiftCntV cnt));
17302   match(Set dst (RShiftCntV cnt));
17303   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17304   ins_encode %{
17305     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17306   %}
17307   ins_pipe(vdup_reg_reg64);
17308 %}
17309 
17310 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17311   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17312   match(Set dst (LShiftCntV cnt));
17313   match(Set dst (RShiftCntV cnt));
17314   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17315   ins_encode %{
17316     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17317   %}
17318   ins_pipe(vdup_reg_reg128);
17319 %}
17320 
17321 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17322   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17323             n-&gt;as_Vector()-&gt;length() == 8);
17324   match(Set dst (LShiftVB src shift));
17325   ins_cost(INSN_COST);
17326   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17327   ins_encode %{
17328     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17329             as_FloatRegister($src$$reg),
17330             as_FloatRegister($shift$$reg));
17331   %}
17332   ins_pipe(vshift64);
17333 %}
17334 
17335 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17336   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17337   match(Set dst (LShiftVB src shift));
17338   ins_cost(INSN_COST);
17339   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17340   ins_encode %{
17341     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17342             as_FloatRegister($src$$reg),
17343             as_FloatRegister($shift$$reg));
17344   %}
17345   ins_pipe(vshift128);
17346 %}
17347 
17348 // Right shifts with vector shift count on aarch64 SIMD are implemented
17349 // as left shift by negative shift count.
17350 // There are two cases for vector shift count.
17351 //
17352 // Case 1: The vector shift count is from replication.
17353 //        |            |
17354 //    LoadVector  RShiftCntV
17355 //        |       /
17356 //     RShiftVI
17357 // Note: In inner loop, multiple neg instructions are used, which can be
17358 // moved to outer loop and merge into one neg instruction.
17359 //
17360 // Case 2: The vector shift count is from loading.
17361 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17362 // panama/vectorIntrinsics(JEP 338: Vector API).
17363 //        |            |
17364 //    LoadVector  LoadVector
17365 //        |       /
17366 //     RShiftVI
17367 //
17368 
17369 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17370   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17371             n-&gt;as_Vector()-&gt;length() == 8);
17372   match(Set dst (RShiftVB src shift));
17373   ins_cost(INSN_COST);
17374   effect(TEMP tmp);
17375   format %{ &quot;negr  $tmp,$shift\t&quot;
17376             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17377   ins_encode %{
17378     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17379             as_FloatRegister($shift$$reg));
17380     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17381             as_FloatRegister($src$$reg),
17382             as_FloatRegister($tmp$$reg));
17383   %}
17384   ins_pipe(vshift64);
17385 %}
17386 
17387 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17388   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17389   match(Set dst (RShiftVB src shift));
17390   ins_cost(INSN_COST);
17391   effect(TEMP tmp);
17392   format %{ &quot;negr  $tmp,$shift\t&quot;
17393             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17394   ins_encode %{
17395     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17396             as_FloatRegister($shift$$reg));
17397     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17398             as_FloatRegister($src$$reg),
17399             as_FloatRegister($tmp$$reg));
17400   %}
17401   ins_pipe(vshift128);
17402 %}
17403 
17404 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17405   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17406             n-&gt;as_Vector()-&gt;length() == 8);
17407   match(Set dst (URShiftVB src shift));
17408   ins_cost(INSN_COST);
17409   effect(TEMP tmp);
17410   format %{ &quot;negr  $tmp,$shift\t&quot;
17411             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17412   ins_encode %{
17413     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17414             as_FloatRegister($shift$$reg));
17415     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17416             as_FloatRegister($src$$reg),
17417             as_FloatRegister($tmp$$reg));
17418   %}
17419   ins_pipe(vshift64);
17420 %}
17421 
17422 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17423   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17424   match(Set dst (URShiftVB src shift));
17425   ins_cost(INSN_COST);
17426   effect(TEMP tmp);
17427   format %{ &quot;negr  $tmp,$shift\t&quot;
17428             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17429   ins_encode %{
17430     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17431             as_FloatRegister($shift$$reg));
17432     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17433             as_FloatRegister($src$$reg),
17434             as_FloatRegister($tmp$$reg));
17435   %}
17436   ins_pipe(vshift128);
17437 %}
17438 
17439 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17440   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17441             n-&gt;as_Vector()-&gt;length() == 8);
17442   match(Set dst (LShiftVB src (LShiftCntV shift)));
17443   ins_cost(INSN_COST);
17444   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17445   ins_encode %{
17446     int sh = (int)$shift$$constant;
17447     if (sh &gt;= 8) {
17448       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17449              as_FloatRegister($src$$reg),
17450              as_FloatRegister($src$$reg));
17451     } else {
17452       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17453              as_FloatRegister($src$$reg), sh);
17454     }
17455   %}
17456   ins_pipe(vshift64_imm);
17457 %}
17458 
17459 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17460   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17461   match(Set dst (LShiftVB src (LShiftCntV shift)));
17462   ins_cost(INSN_COST);
17463   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17464   ins_encode %{
17465     int sh = (int)$shift$$constant;
17466     if (sh &gt;= 8) {
17467       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17468              as_FloatRegister($src$$reg),
17469              as_FloatRegister($src$$reg));
17470     } else {
17471       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17472              as_FloatRegister($src$$reg), sh);
17473     }
17474   %}
17475   ins_pipe(vshift128_imm);
17476 %}
17477 
17478 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17479   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17480             n-&gt;as_Vector()-&gt;length() == 8);
17481   match(Set dst (RShiftVB src (RShiftCntV shift)));
17482   ins_cost(INSN_COST);
17483   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17484   ins_encode %{
17485     int sh = (int)$shift$$constant;
17486     if (sh &gt;= 8) sh = 7;
17487     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17488            as_FloatRegister($src$$reg), sh);
17489   %}
17490   ins_pipe(vshift64_imm);
17491 %}
17492 
17493 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17494   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17495   match(Set dst (RShiftVB src (RShiftCntV shift)));
17496   ins_cost(INSN_COST);
17497   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17498   ins_encode %{
17499     int sh = (int)$shift$$constant;
17500     if (sh &gt;= 8) sh = 7;
17501     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17502            as_FloatRegister($src$$reg), sh);
17503   %}
17504   ins_pipe(vshift128_imm);
17505 %}
17506 
17507 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17508   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17509             n-&gt;as_Vector()-&gt;length() == 8);
17510   match(Set dst (URShiftVB src (RShiftCntV shift)));
17511   ins_cost(INSN_COST);
17512   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17513   ins_encode %{
17514     int sh = (int)$shift$$constant;
17515     if (sh &gt;= 8) {
17516       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17517              as_FloatRegister($src$$reg),
17518              as_FloatRegister($src$$reg));
17519     } else {
17520       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17521              as_FloatRegister($src$$reg), sh);
17522     }
17523   %}
17524   ins_pipe(vshift64_imm);
17525 %}
17526 
17527 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17528   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17529   match(Set dst (URShiftVB src (RShiftCntV shift)));
17530   ins_cost(INSN_COST);
17531   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17532   ins_encode %{
17533     int sh = (int)$shift$$constant;
17534     if (sh &gt;= 8) {
17535       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17536              as_FloatRegister($src$$reg),
17537              as_FloatRegister($src$$reg));
17538     } else {
17539       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17540              as_FloatRegister($src$$reg), sh);
17541     }
17542   %}
17543   ins_pipe(vshift128_imm);
17544 %}
17545 
17546 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17547   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17548             n-&gt;as_Vector()-&gt;length() == 4);
17549   match(Set dst (LShiftVS src shift));
17550   ins_cost(INSN_COST);
17551   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17552   ins_encode %{
17553     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17554             as_FloatRegister($src$$reg),
17555             as_FloatRegister($shift$$reg));
17556   %}
17557   ins_pipe(vshift64);
17558 %}
17559 
17560 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17561   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17562   match(Set dst (LShiftVS src shift));
17563   ins_cost(INSN_COST);
17564   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17565   ins_encode %{
17566     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17567             as_FloatRegister($src$$reg),
17568             as_FloatRegister($shift$$reg));
17569   %}
17570   ins_pipe(vshift128);
17571 %}
17572 
17573 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17574   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17575             n-&gt;as_Vector()-&gt;length() == 4);
17576   match(Set dst (RShiftVS src shift));
17577   ins_cost(INSN_COST);
17578   effect(TEMP tmp);
17579   format %{ &quot;negr  $tmp,$shift\t&quot;
17580             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17581   ins_encode %{
17582     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17583             as_FloatRegister($shift$$reg));
17584     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17585             as_FloatRegister($src$$reg),
17586             as_FloatRegister($tmp$$reg));
17587   %}
17588   ins_pipe(vshift64);
17589 %}
17590 
17591 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17592   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17593   match(Set dst (RShiftVS src shift));
17594   ins_cost(INSN_COST);
17595   effect(TEMP tmp);
17596   format %{ &quot;negr  $tmp,$shift\t&quot;
17597             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17598   ins_encode %{
17599     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17600             as_FloatRegister($shift$$reg));
17601     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17602             as_FloatRegister($src$$reg),
17603             as_FloatRegister($tmp$$reg));
17604   %}
17605   ins_pipe(vshift128);
17606 %}
17607 
17608 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17609   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17610             n-&gt;as_Vector()-&gt;length() == 4);
17611   match(Set dst (URShiftVS src shift));
17612   ins_cost(INSN_COST);
17613   effect(TEMP tmp);
17614   format %{ &quot;negr  $tmp,$shift\t&quot;
17615             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17616   ins_encode %{
17617     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17618             as_FloatRegister($shift$$reg));
17619     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17620             as_FloatRegister($src$$reg),
17621             as_FloatRegister($tmp$$reg));
17622   %}
17623   ins_pipe(vshift64);
17624 %}
17625 
17626 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17627   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17628   match(Set dst (URShiftVS src shift));
17629   ins_cost(INSN_COST);
17630   effect(TEMP tmp);
17631   format %{ &quot;negr  $tmp,$shift\t&quot;
17632             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17633   ins_encode %{
17634     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17635             as_FloatRegister($shift$$reg));
17636     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17637             as_FloatRegister($src$$reg),
17638             as_FloatRegister($tmp$$reg));
17639   %}
17640   ins_pipe(vshift128);
17641 %}
17642 
17643 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17644   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17645             n-&gt;as_Vector()-&gt;length() == 4);
17646   match(Set dst (LShiftVS src (LShiftCntV shift)));
17647   ins_cost(INSN_COST);
17648   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17649   ins_encode %{
17650     int sh = (int)$shift$$constant;
17651     if (sh &gt;= 16) {
17652       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17653              as_FloatRegister($src$$reg),
17654              as_FloatRegister($src$$reg));
17655     } else {
17656       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17657              as_FloatRegister($src$$reg), sh);
17658     }
17659   %}
17660   ins_pipe(vshift64_imm);
17661 %}
17662 
17663 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17664   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17665   match(Set dst (LShiftVS src (LShiftCntV shift)));
17666   ins_cost(INSN_COST);
17667   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17668   ins_encode %{
17669     int sh = (int)$shift$$constant;
17670     if (sh &gt;= 16) {
17671       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17672              as_FloatRegister($src$$reg),
17673              as_FloatRegister($src$$reg));
17674     } else {
17675       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17676              as_FloatRegister($src$$reg), sh);
17677     }
17678   %}
17679   ins_pipe(vshift128_imm);
17680 %}
17681 
17682 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17683   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17684             n-&gt;as_Vector()-&gt;length() == 4);
17685   match(Set dst (RShiftVS src (RShiftCntV shift)));
17686   ins_cost(INSN_COST);
17687   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17688   ins_encode %{
17689     int sh = (int)$shift$$constant;
17690     if (sh &gt;= 16) sh = 15;
17691     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17692            as_FloatRegister($src$$reg), sh);
17693   %}
17694   ins_pipe(vshift64_imm);
17695 %}
17696 
17697 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17698   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17699   match(Set dst (RShiftVS src (RShiftCntV shift)));
17700   ins_cost(INSN_COST);
17701   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17702   ins_encode %{
17703     int sh = (int)$shift$$constant;
17704     if (sh &gt;= 16) sh = 15;
17705     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17706            as_FloatRegister($src$$reg), sh);
17707   %}
17708   ins_pipe(vshift128_imm);
17709 %}
17710 
17711 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17712   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17713             n-&gt;as_Vector()-&gt;length() == 4);
17714   match(Set dst (URShiftVS src (RShiftCntV shift)));
17715   ins_cost(INSN_COST);
17716   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17717   ins_encode %{
17718     int sh = (int)$shift$$constant;
17719     if (sh &gt;= 16) {
17720       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17721              as_FloatRegister($src$$reg),
17722              as_FloatRegister($src$$reg));
17723     } else {
17724       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17725              as_FloatRegister($src$$reg), sh);
17726     }
17727   %}
17728   ins_pipe(vshift64_imm);
17729 %}
17730 
17731 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17732   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17733   match(Set dst (URShiftVS src (RShiftCntV shift)));
17734   ins_cost(INSN_COST);
17735   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17736   ins_encode %{
17737     int sh = (int)$shift$$constant;
17738     if (sh &gt;= 16) {
17739       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17740              as_FloatRegister($src$$reg),
17741              as_FloatRegister($src$$reg));
17742     } else {
17743       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17744              as_FloatRegister($src$$reg), sh);
17745     }
17746   %}
17747   ins_pipe(vshift128_imm);
17748 %}
17749 
17750 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17751   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17752   match(Set dst (LShiftVI src shift));
17753   ins_cost(INSN_COST);
17754   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17755   ins_encode %{
17756     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17757             as_FloatRegister($src$$reg),
17758             as_FloatRegister($shift$$reg));
17759   %}
17760   ins_pipe(vshift64);
17761 %}
17762 
17763 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17764   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17765   match(Set dst (LShiftVI src shift));
17766   ins_cost(INSN_COST);
17767   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17768   ins_encode %{
17769     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17770             as_FloatRegister($src$$reg),
17771             as_FloatRegister($shift$$reg));
17772   %}
17773   ins_pipe(vshift128);
17774 %}
17775 
17776 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17777   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17778   match(Set dst (RShiftVI src shift));
17779   ins_cost(INSN_COST);
17780   effect(TEMP tmp);
17781   format %{ &quot;negr  $tmp,$shift\t&quot;
17782             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17783   ins_encode %{
17784     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17785             as_FloatRegister($shift$$reg));
17786     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17787             as_FloatRegister($src$$reg),
17788             as_FloatRegister($tmp$$reg));
17789   %}
17790   ins_pipe(vshift64);
17791 %}
17792 
17793 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17794   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17795   match(Set dst (RShiftVI src shift));
17796   ins_cost(INSN_COST);
17797   effect(TEMP tmp);
17798   format %{ &quot;negr  $tmp,$shift\t&quot;
17799             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17800   ins_encode %{
17801     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17802             as_FloatRegister($shift$$reg));
17803     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17804             as_FloatRegister($src$$reg),
17805             as_FloatRegister($tmp$$reg));
17806   %}
17807   ins_pipe(vshift128);
17808 %}
17809 
17810 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17811   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17812   match(Set dst (URShiftVI src shift));
17813   ins_cost(INSN_COST);
17814   effect(TEMP tmp);
17815   format %{ &quot;negr  $tmp,$shift\t&quot;
17816             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17817   ins_encode %{
17818     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17819             as_FloatRegister($shift$$reg));
17820     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17821             as_FloatRegister($src$$reg),
17822             as_FloatRegister($tmp$$reg));
17823   %}
17824   ins_pipe(vshift64);
17825 %}
17826 
17827 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17828   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17829   match(Set dst (URShiftVI src shift));
17830   ins_cost(INSN_COST);
17831   effect(TEMP tmp);
17832   format %{ &quot;negr  $tmp,$shift\t&quot;
17833             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17834   ins_encode %{
17835     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17836             as_FloatRegister($shift$$reg));
17837     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17838             as_FloatRegister($src$$reg),
17839             as_FloatRegister($tmp$$reg));
17840   %}
17841   ins_pipe(vshift128);
17842 %}
17843 
17844 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17845   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17846   match(Set dst (LShiftVI src (LShiftCntV shift)));
17847   ins_cost(INSN_COST);
17848   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17849   ins_encode %{
17850     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17851            as_FloatRegister($src$$reg),
17852            (int)$shift$$constant);
17853   %}
17854   ins_pipe(vshift64_imm);
17855 %}
17856 
17857 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17858   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17859   match(Set dst (LShiftVI src (LShiftCntV shift)));
17860   ins_cost(INSN_COST);
17861   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17862   ins_encode %{
17863     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17864            as_FloatRegister($src$$reg),
17865            (int)$shift$$constant);
17866   %}
17867   ins_pipe(vshift128_imm);
17868 %}
17869 
17870 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17871   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17872   match(Set dst (RShiftVI src (RShiftCntV shift)));
17873   ins_cost(INSN_COST);
17874   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17875   ins_encode %{
17876     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17877             as_FloatRegister($src$$reg),
17878             (int)$shift$$constant);
17879   %}
17880   ins_pipe(vshift64_imm);
17881 %}
17882 
17883 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17884   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17885   match(Set dst (RShiftVI src (RShiftCntV shift)));
17886   ins_cost(INSN_COST);
17887   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17888   ins_encode %{
17889     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17890             as_FloatRegister($src$$reg),
17891             (int)$shift$$constant);
17892   %}
17893   ins_pipe(vshift128_imm);
17894 %}
17895 
17896 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17897   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17898   match(Set dst (URShiftVI src (RShiftCntV shift)));
17899   ins_cost(INSN_COST);
17900   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17901   ins_encode %{
17902     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17903             as_FloatRegister($src$$reg),
17904             (int)$shift$$constant);
17905   %}
17906   ins_pipe(vshift64_imm);
17907 %}
17908 
17909 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17910   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17911   match(Set dst (URShiftVI src (RShiftCntV shift)));
17912   ins_cost(INSN_COST);
17913   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17914   ins_encode %{
17915     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17916             as_FloatRegister($src$$reg),
17917             (int)$shift$$constant);
17918   %}
17919   ins_pipe(vshift128_imm);
17920 %}
17921 
17922 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17923   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17924   match(Set dst (LShiftVL src shift));
17925   ins_cost(INSN_COST);
17926   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17927   ins_encode %{
17928     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17929             as_FloatRegister($src$$reg),
17930             as_FloatRegister($shift$$reg));
17931   %}
17932   ins_pipe(vshift128);
17933 %}
17934 
17935 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17936   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17937   match(Set dst (RShiftVL src shift));
17938   ins_cost(INSN_COST);
17939   effect(TEMP tmp);
17940   format %{ &quot;negr  $tmp,$shift\t&quot;
17941             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17942   ins_encode %{
17943     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17944             as_FloatRegister($shift$$reg));
17945     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17946             as_FloatRegister($src$$reg),
17947             as_FloatRegister($tmp$$reg));
17948   %}
17949   ins_pipe(vshift128);
17950 %}
17951 
17952 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17953   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17954   match(Set dst (URShiftVL src shift));
17955   ins_cost(INSN_COST);
17956   effect(TEMP tmp);
17957   format %{ &quot;negr  $tmp,$shift\t&quot;
17958             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17959   ins_encode %{
17960     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17961             as_FloatRegister($shift$$reg));
17962     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17963             as_FloatRegister($src$$reg),
17964             as_FloatRegister($tmp$$reg));
17965   %}
17966   ins_pipe(vshift128);
17967 %}
17968 
17969 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17970   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17971   match(Set dst (LShiftVL src (LShiftCntV shift)));
17972   ins_cost(INSN_COST);
17973   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17974   ins_encode %{
17975     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17976            as_FloatRegister($src$$reg),
17977            (int)$shift$$constant);
17978   %}
17979   ins_pipe(vshift128_imm);
17980 %}
17981 
17982 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17983   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17984   match(Set dst (RShiftVL src (RShiftCntV shift)));
17985   ins_cost(INSN_COST);
17986   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17987   ins_encode %{
17988     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17989             as_FloatRegister($src$$reg),
17990             (int)$shift$$constant);
17991   %}
17992   ins_pipe(vshift128_imm);
17993 %}
17994 
17995 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17996   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17997   match(Set dst (URShiftVL src (RShiftCntV shift)));
17998   ins_cost(INSN_COST);
17999   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18000   ins_encode %{
18001     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18002             as_FloatRegister($src$$reg),
18003             (int)$shift$$constant);
18004   %}
18005   ins_pipe(vshift128_imm);
18006 %}
18007 
18008 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18009 %{
18010   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18011   match(Set dst (MaxV src1 src2));
18012   ins_cost(INSN_COST);
18013   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18014   ins_encode %{
18015     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18016             as_FloatRegister($src1$$reg),
18017             as_FloatRegister($src2$$reg));
18018   %}
18019   ins_pipe(vdop_fp64);
18020 %}
18021 
18022 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18023 %{
18024   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18025   match(Set dst (MaxV src1 src2));
18026   ins_cost(INSN_COST);
18027   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18028   ins_encode %{
18029     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18030             as_FloatRegister($src1$$reg),
18031             as_FloatRegister($src2$$reg));
18032   %}
18033   ins_pipe(vdop_fp128);
18034 %}
18035 
18036 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18037 %{
18038   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18039   match(Set dst (MaxV src1 src2));
18040   ins_cost(INSN_COST);
18041   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18042   ins_encode %{
18043     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18044             as_FloatRegister($src1$$reg),
18045             as_FloatRegister($src2$$reg));
18046   %}
18047   ins_pipe(vdop_fp128);
18048 %}
18049 
18050 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18051 %{
18052   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18053   match(Set dst (MinV src1 src2));
18054   ins_cost(INSN_COST);
18055   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18056   ins_encode %{
18057     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18058             as_FloatRegister($src1$$reg),
18059             as_FloatRegister($src2$$reg));
18060   %}
18061   ins_pipe(vdop_fp64);
18062 %}
18063 
18064 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18065 %{
18066   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18067   match(Set dst (MinV src1 src2));
18068   ins_cost(INSN_COST);
18069   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18070   ins_encode %{
18071     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18072             as_FloatRegister($src1$$reg),
18073             as_FloatRegister($src2$$reg));
18074   %}
18075   ins_pipe(vdop_fp128);
18076 %}
18077 
18078 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18079 %{
18080   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18081   match(Set dst (MinV src1 src2));
18082   ins_cost(INSN_COST);
18083   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18084   ins_encode %{
18085     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18086             as_FloatRegister($src1$$reg),
18087             as_FloatRegister($src2$$reg));
18088   %}
18089   ins_pipe(vdop_fp128);
18090 %}
18091 
18092 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18093   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18094   match(Set dst (RoundDoubleModeV src rmode));
18095   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18096   ins_encode %{
18097     switch ($rmode$$constant) {
18098       case RoundDoubleModeNode::rmode_rint:
18099         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18100                   as_FloatRegister($src$$reg));
18101         break;
18102       case RoundDoubleModeNode::rmode_floor:
18103         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18104                   as_FloatRegister($src$$reg));
18105         break;
18106       case RoundDoubleModeNode::rmode_ceil:
18107         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18108                   as_FloatRegister($src$$reg));
18109         break;
18110     }
18111   %}
18112   ins_pipe(vdop_fp128);
18113 %}
18114 
18115 instruct vpopcount4I(vecX dst, vecX src) %{
18116   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18117   match(Set dst (PopCountVI src));
18118   format %{
18119     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18120     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18121     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18122   %}
18123   ins_encode %{
18124      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18125             as_FloatRegister($src$$reg));
18126      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18127                as_FloatRegister($dst$$reg));
18128      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18129                as_FloatRegister($dst$$reg));
18130   %}
18131   ins_pipe(pipe_class_default);
18132 %}
18133 
18134 instruct vpopcount2I(vecD dst, vecD src) %{
18135   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18136   match(Set dst (PopCountVI src));
18137   format %{
18138     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18139     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18140     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18141   %}
18142   ins_encode %{
18143      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18144             as_FloatRegister($src$$reg));
18145      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18146                as_FloatRegister($dst$$reg));
18147      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18148                as_FloatRegister($dst$$reg));
18149   %}
18150   ins_pipe(pipe_class_default);
18151 %}
18152 
18153 //----------PEEPHOLE RULES-----------------------------------------------------
18154 // These must follow all instruction definitions as they use the names
18155 // defined in the instructions definitions.
18156 //
18157 // peepmatch ( root_instr_name [preceding_instruction]* );
18158 //
18159 // peepconstraint %{
18160 // (instruction_number.operand_name relational_op instruction_number.operand_name
18161 //  [, ...] );
18162 // // instruction numbers are zero-based using left to right order in peepmatch
18163 //
18164 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18165 // // provide an instruction_number.operand_name for each operand that appears
18166 // // in the replacement instruction&#39;s match rule
18167 //
18168 // ---------VM FLAGS---------------------------------------------------------
18169 //
18170 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18171 //
18172 // Each peephole rule is given an identifying number starting with zero and
18173 // increasing by one in the order seen by the parser.  An individual peephole
18174 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18175 // on the command-line.
18176 //
18177 // ---------CURRENT LIMITATIONS----------------------------------------------
18178 //
18179 // Only match adjacent instructions in same basic block
18180 // Only equality constraints
18181 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18182 // Only one replacement instruction
18183 //
18184 // ---------EXAMPLE----------------------------------------------------------
18185 //
18186 // // pertinent parts of existing instructions in architecture description
18187 // instruct movI(iRegINoSp dst, iRegI src)
18188 // %{
18189 //   match(Set dst (CopyI src));
18190 // %}
18191 //
18192 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18193 // %{
18194 //   match(Set dst (AddI dst src));
18195 //   effect(KILL cr);
18196 // %}
18197 //
18198 // // Change (inc mov) to lea
18199 // peephole %{
18200 //   // increment preceeded by register-register move
18201 //   peepmatch ( incI_iReg movI );
18202 //   // require that the destination register of the increment
18203 //   // match the destination register of the move
18204 //   peepconstraint ( 0.dst == 1.dst );
18205 //   // construct a replacement instruction that sets
18206 //   // the destination to ( move&#39;s source register + one )
18207 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18208 // %}
18209 //
18210 
18211 // Implementation no longer uses movX instructions since
18212 // machine-independent system no longer uses CopyX nodes.
18213 //
18214 // peephole
18215 // %{
18216 //   peepmatch (incI_iReg movI);
18217 //   peepconstraint (0.dst == 1.dst);
18218 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18219 // %}
18220 
18221 // peephole
18222 // %{
18223 //   peepmatch (decI_iReg movI);
18224 //   peepconstraint (0.dst == 1.dst);
18225 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18226 // %}
18227 
18228 // peephole
18229 // %{
18230 //   peepmatch (addI_iReg_imm movI);
18231 //   peepconstraint (0.dst == 1.dst);
18232 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18233 // %}
18234 
18235 // peephole
18236 // %{
18237 //   peepmatch (incL_iReg movL);
18238 //   peepconstraint (0.dst == 1.dst);
18239 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18240 // %}
18241 
18242 // peephole
18243 // %{
18244 //   peepmatch (decL_iReg movL);
18245 //   peepconstraint (0.dst == 1.dst);
18246 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18247 // %}
18248 
18249 // peephole
18250 // %{
18251 //   peepmatch (addL_iReg_imm movL);
18252 //   peepconstraint (0.dst == 1.dst);
18253 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18254 // %}
18255 
18256 // peephole
18257 // %{
18258 //   peepmatch (addP_iReg_imm movP);
18259 //   peepconstraint (0.dst == 1.dst);
18260 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18261 // %}
18262 
18263 // // Change load of spilled value to only a spill
18264 // instruct storeI(memory mem, iRegI src)
18265 // %{
18266 //   match(Set mem (StoreI mem src));
18267 // %}
18268 //
18269 // instruct loadI(iRegINoSp dst, memory mem)
18270 // %{
18271 //   match(Set dst (LoadI mem));
18272 // %}
18273 //
18274 
18275 //----------SMARTSPILL RULES---------------------------------------------------
18276 // These must follow all instruction definitions as they use the names
18277 // defined in the instructions definitions.
18278 
18279 // Local Variables:
18280 // mode: c++
18281 // End:
    </pre>
  </body>
</html>