<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;code/debugInfoRec.hpp&quot;
  30 #include &quot;code/icBuffer.hpp&quot;
  31 #include &quot;code/vtableStubs.hpp&quot;

  32 #include &quot;interpreter/interpreter.hpp&quot;
  33 #include &quot;interpreter/interp_masm.hpp&quot;
  34 #include &quot;logging/log.hpp&quot;
  35 #include &quot;memory/resourceArea.hpp&quot;
  36 #include &quot;nativeInst_aarch64.hpp&quot;
  37 #include &quot;oops/compiledICHolder.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/vframeArray.hpp&quot;
  42 #include &quot;utilities/align.hpp&quot;
  43 #include &quot;vmreg_aarch64.inline.hpp&quot;
  44 #ifdef COMPILER1
  45 #include &quot;c1/c1_Runtime1.hpp&quot;
  46 #endif
  47 #ifdef COMPILER2
  48 #include &quot;adfiles/ad_aarch64.hpp&quot;
  49 #include &quot;opto/runtime.hpp&quot;
  50 #endif
  51 #if INCLUDE_JVMCI
</pre>
<hr />
<pre>
 715 
 716   // Class initialization barrier for static methods
 717   address c2i_no_clinit_check_entry = NULL;
 718   if (VM_Version::supports_fast_class_init_checks()) {
 719     Label L_skip_barrier;
 720 
 721     { // Bypass the barrier for non-static methods
 722       __ ldrw(rscratch1, Address(rmethod, Method::access_flags_offset()));
 723       __ andsw(zr, rscratch1, JVM_ACC_STATIC);
 724       __ br(Assembler::EQ, L_skip_barrier); // non-static
 725     }
 726 
 727     __ load_method_holder(rscratch2, rmethod);
 728     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 729     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 730 
 731     __ bind(L_skip_barrier);
 732     c2i_no_clinit_check_entry = __ pc();
 733   }
 734 



 735   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);
 736 
 737   __ flush();
 738   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);
 739 }
 740 
 741 int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
 742                                          VMRegPair *regs,
 743                                          VMRegPair *regs2,
 744                                          int total_args_passed) {
 745   assert(regs2 == NULL, &quot;not needed on AArch64&quot;);
 746 
 747 // We return the amount of VMRegImpl stack slots we need to reserve for all
 748 // the arguments NOT counting out_preserve_stack_slots.
 749 
 750     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
 751       c_rarg0, c_rarg1, c_rarg2, c_rarg3, c_rarg4, c_rarg5,  c_rarg6,  c_rarg7
 752     };
 753     static const FloatRegister FP_ArgReg[Argument::n_float_register_parameters_c] = {
 754       c_farg0, c_farg1, c_farg2, c_farg3,
</pre>
<hr />
<pre>
1487     Label L_skip_barrier;
1488     __ mov_metadata(rscratch2, method-&gt;method_holder()); // InstanceKlass*
1489     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
1490     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
1491 
1492     __ bind(L_skip_barrier);
1493   }
1494 
1495   // Generate stack overflow check
1496   if (UseStackBanging) {
1497     __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());
1498   } else {
1499     Unimplemented();
1500   }
1501 
1502   // Generate a new frame for the wrapper.
1503   __ enter();
1504   // -2 because return address is already present and so is saved rfp
1505   __ sub(sp, sp, stack_size - 2*wordSize);
1506 



1507   // Frame is now completed as far as size and linkage.
1508   int frame_complete = ((intptr_t)__ pc()) - start;
1509 
1510   // We use r20 as the oop handle for the receiver/klass
1511   // It is callee save so it survives the call to native
1512 
1513   const Register oop_handle_reg = r20;
1514 
1515   if (is_critical_native) {
1516     check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,
1517                                        oop_handle_offset, oop_maps, in_regs, in_sig_bt);
1518   }
1519 
1520   //
1521   // We immediately shuffle the arguments so that any vm call we have to
1522   // make from here on out (sync slow path, jvmti, etc.) we will have
1523   // captured the oops from our caller and have a valid oopMap for
1524   // them.
1525 
1526   // -----------------
</pre>
</td>
<td>
<hr />
<pre>
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;code/debugInfoRec.hpp&quot;
  30 #include &quot;code/icBuffer.hpp&quot;
  31 #include &quot;code/vtableStubs.hpp&quot;
<span class="line-added">  32 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;</span>
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interp_masm.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
  37 #include &quot;nativeInst_aarch64.hpp&quot;
  38 #include &quot;oops/compiledICHolder.hpp&quot;
  39 #include &quot;oops/klass.inline.hpp&quot;
  40 #include &quot;runtime/safepointMechanism.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/vframeArray.hpp&quot;
  43 #include &quot;utilities/align.hpp&quot;
  44 #include &quot;vmreg_aarch64.inline.hpp&quot;
  45 #ifdef COMPILER1
  46 #include &quot;c1/c1_Runtime1.hpp&quot;
  47 #endif
  48 #ifdef COMPILER2
  49 #include &quot;adfiles/ad_aarch64.hpp&quot;
  50 #include &quot;opto/runtime.hpp&quot;
  51 #endif
  52 #if INCLUDE_JVMCI
</pre>
<hr />
<pre>
 716 
 717   // Class initialization barrier for static methods
 718   address c2i_no_clinit_check_entry = NULL;
 719   if (VM_Version::supports_fast_class_init_checks()) {
 720     Label L_skip_barrier;
 721 
 722     { // Bypass the barrier for non-static methods
 723       __ ldrw(rscratch1, Address(rmethod, Method::access_flags_offset()));
 724       __ andsw(zr, rscratch1, JVM_ACC_STATIC);
 725       __ br(Assembler::EQ, L_skip_barrier); // non-static
 726     }
 727 
 728     __ load_method_holder(rscratch2, rmethod);
 729     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 730     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 731 
 732     __ bind(L_skip_barrier);
 733     c2i_no_clinit_check_entry = __ pc();
 734   }
 735 
<span class="line-added"> 736   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added"> 737   bs-&gt;c2i_entry_barrier(masm);</span>
<span class="line-added"> 738 </span>
 739   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);
 740 
 741   __ flush();
 742   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);
 743 }
 744 
 745 int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
 746                                          VMRegPair *regs,
 747                                          VMRegPair *regs2,
 748                                          int total_args_passed) {
 749   assert(regs2 == NULL, &quot;not needed on AArch64&quot;);
 750 
 751 // We return the amount of VMRegImpl stack slots we need to reserve for all
 752 // the arguments NOT counting out_preserve_stack_slots.
 753 
 754     static const Register INT_ArgReg[Argument::n_int_register_parameters_c] = {
 755       c_rarg0, c_rarg1, c_rarg2, c_rarg3, c_rarg4, c_rarg5,  c_rarg6,  c_rarg7
 756     };
 757     static const FloatRegister FP_ArgReg[Argument::n_float_register_parameters_c] = {
 758       c_farg0, c_farg1, c_farg2, c_farg3,
</pre>
<hr />
<pre>
1491     Label L_skip_barrier;
1492     __ mov_metadata(rscratch2, method-&gt;method_holder()); // InstanceKlass*
1493     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
1494     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
1495 
1496     __ bind(L_skip_barrier);
1497   }
1498 
1499   // Generate stack overflow check
1500   if (UseStackBanging) {
1501     __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());
1502   } else {
1503     Unimplemented();
1504   }
1505 
1506   // Generate a new frame for the wrapper.
1507   __ enter();
1508   // -2 because return address is already present and so is saved rfp
1509   __ sub(sp, sp, stack_size - 2*wordSize);
1510 
<span class="line-added">1511   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added">1512   bs-&gt;nmethod_entry_barrier(masm);</span>
<span class="line-added">1513 </span>
1514   // Frame is now completed as far as size and linkage.
1515   int frame_complete = ((intptr_t)__ pc()) - start;
1516 
1517   // We use r20 as the oop handle for the receiver/klass
1518   // It is callee save so it survives the call to native
1519 
1520   const Register oop_handle_reg = r20;
1521 
1522   if (is_critical_native) {
1523     check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,
1524                                        oop_handle_offset, oop_maps, in_regs, in_sig_bt);
1525   }
1526 
1527   //
1528   // We immediately shuffle the arguments so that any vm call we have to
1529   // make from here on out (sync slow path, jvmti, etc.) we will have
1530   // captured the oops from our caller and have a valid oopMap for
1531   // them.
1532 
1533   // -----------------
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>