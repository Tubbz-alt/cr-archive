diff a/src/hotspot/share/gc/shared/taskqueue.inline.hpp b/src/hotspot/share/gc/shared/taskqueue.inline.hpp
--- a/src/hotspot/share/gc/shared/taskqueue.inline.hpp
+++ b/src/hotspot/share/gc/shared/taskqueue.inline.hpp
@@ -52,18 +52,18 @@
   _elems = ArrayAllocator<E>::allocate(N, F);
 }
 
 template<class E, MEMFLAGS F, unsigned int N>
 inline GenericTaskQueue<E, F, N>::~GenericTaskQueue() {
-  ArrayAllocator<E>::free(const_cast<E*>(_elems), N);
+  ArrayAllocator<E>::free(_elems, N);
 }
 
 template<class E, MEMFLAGS F, unsigned int N> inline bool
 GenericTaskQueue<E, F, N>::push(E t) {
-  uint localBot = _bottom;
+  uint localBot = bottom_relaxed();
   assert(localBot < N, "_bottom out of range.");
-  idx_t top = _age.top();
+  idx_t top = age_top_relaxed();
   uint dirty_n_elems = dirty_size(localBot, top);
   // A dirty_size of N-1 cannot happen in push.  Considering only push:
   // (1) dirty_n_elems is initially 0.
   // (2) push adds an element iff dirty_n_elems < max_elems(), which is N - 2.
   // (3) only push adding an element can increase dirty_n_elems.
@@ -73,26 +73,20 @@
   // A pop_global that is concurrent with push cannot produce a state where
   // dirty_size == N-1.  pop_global only removes an element if dirty_elems > 0,
   // so can't underflow to -1 (== N-1) with push.
   assert(dirty_n_elems <= max_elems(), "n_elems out of range.");
   if (dirty_n_elems < max_elems()) {
-    // g++ complains if the volatile result of the assignment is
-    // unused, so we cast the volatile away.  We cannot cast directly
-    // to void, because gcc treats that as not using the result of the
-    // assignment.  However, casting to E& means that we trigger an
-    // unused-value warning.  So, we cast the E& to void.
-    (void) const_cast<E&>(_elems[localBot] = t);
-    Atomic::release_store(&_bottom, increment_index(localBot));
+    _elems[localBot] = t;
+    release_set_bottom(increment_index(localBot));
     TASKQUEUE_STATS_ONLY(stats.record_push());
     return true;
   }
   return false;                 // Queue is full.
 }
 
 template <class E, MEMFLAGS F, unsigned int N>
-inline bool OverflowTaskQueue<E, F, N>::push(E t)
-{
+inline bool OverflowTaskQueue<E, F, N>::push(E t) {
   if (!taskqueue_t::push(t)) {
     overflow_stack()->push(t);
     TASKQUEUE_STATS_ONLY(stats.record_overflow(overflow_stack()->size()));
   }
   return true;
@@ -112,77 +106,72 @@
 template<class E, MEMFLAGS F, unsigned int N>
 bool GenericTaskQueue<E, F, N>::pop_local_slow(uint localBot, Age oldAge) {
   // This queue was observed to contain exactly one element; either this
   // thread will claim it, or a competing "pop_global".  In either case,
   // the queue will be logically empty afterwards.  Create a new Age value
-  // that represents the empty queue for the given value of "_bottom".  (We
+  // that represents the empty queue for the given value of "bottom".  (We
   // must also increment "tag" because of the case where "bottom == 1",
   // "top == 0".  A pop_global could read the queue element in that case,
   // then have the owner thread do a pop followed by another push.  Without
   // the incrementing of "tag", the pop_global's CAS could succeed,
   // allowing it to believe it has claimed the stale element.)
-  Age newAge((idx_t)localBot, oldAge.tag() + 1);
+  Age newAge((idx_t)localBot, (idx_t)(oldAge.tag() + 1));
   // Perhaps a competing pop_global has already incremented "top", in which
   // case it wins the element.
   if (localBot == oldAge.top()) {
     // No competing pop_global has yet incremented "top"; we'll try to
     // install new_age, thus claiming the element.
-    Age tempAge = _age.cmpxchg(newAge, oldAge);
+    Age tempAge = cmpxchg_age(oldAge, newAge);
     if (tempAge == oldAge) {
       // We win.
-      assert(dirty_size(localBot, _age.top()) != N - 1, "sanity");
+      assert(dirty_size(localBot, age_top_relaxed()) != N - 1, "sanity");
       TASKQUEUE_STATS_ONLY(stats.record_pop_slow());
       return true;
     }
   }
-  // We lose; a completing pop_global gets the element.  But the queue is empty
+  // We lose; a competing pop_global got the element.  But the queue is empty
   // and top is greater than bottom.  Fix this representation of the empty queue
   // to become the canonical one.
-  _age.set(newAge);
-  assert(dirty_size(localBot, _age.top()) != N - 1, "sanity");
+  set_age_relaxed(newAge);
+  assert(dirty_size(localBot, age_top_relaxed()) != N - 1, "sanity");
   return false;
 }
 
 template<class E, MEMFLAGS F, unsigned int N> inline bool
-GenericTaskQueue<E, F, N>::pop_local(volatile E& t, uint threshold) {
-  uint localBot = _bottom;
+GenericTaskQueue<E, F, N>::pop_local(E& t, uint threshold) {
+  uint localBot = bottom_relaxed();
   // This value cannot be N-1.  That can only occur as a result of
   // the assignment to bottom in this method.  If it does, this method
   // resets the size to 0 before the next call (which is sequential,
   // since this is pop_local.)
-  uint dirty_n_elems = dirty_size(localBot, _age.top());
+  uint dirty_n_elems = dirty_size(localBot, age_top_relaxed());
   assert(dirty_n_elems != N - 1, "Shouldn't be possible...");
   if (dirty_n_elems <= threshold) return false;
   localBot = decrement_index(localBot);
-  _bottom = localBot;
+  set_bottom_relaxed(localBot);
   // This is necessary to prevent any read below from being reordered
   // before the store just above.
   OrderAccess::fence();
-  // g++ complains if the volatile result of the assignment is
-  // unused, so we cast the volatile away.  We cannot cast directly
-  // to void, because gcc treats that as not using the result of the
-  // assignment.  However, casting to E& means that we trigger an
-  // unused-value warning.  So, we cast the E& to void.
-  (void) const_cast<E&>(t = _elems[localBot]);
+  t = _elems[localBot];
   // This is a second read of "age"; the "size()" above is the first.
   // If there's still at least one element in the queue, based on the
   // "_bottom" and "age" we've read, then there can be no interference with
   // a "pop_global" operation, and we're done.
-  idx_t tp = _age.top();    // XXX
-  if (size(localBot, tp) > 0) {
+  idx_t tp = age_top_relaxed();
+  if (clean_size(localBot, tp) > 0) {
     assert(dirty_size(localBot, tp) != N - 1, "sanity");
     TASKQUEUE_STATS_ONLY(stats.record_pop());
     return true;
   } else {
     // Otherwise, the queue contained exactly one element; we take the slow
     // path.
 
-    // The barrier is required to prevent reordering the two reads of _age:
-    // one is the _age.get() below, and the other is _age.top() above the if-stmt.
-    // The algorithm may fail if _age.get() reads an older value than _age.top().
+    // The barrier is required to prevent reordering the two reads of age:
+    // one is the age() below, and the other is age_top() above the if-stmt.
+    // The algorithm may fail if age() reads an older value than age_top().
     OrderAccess::loadload();
-    return pop_local_slow(localBot, _age.get());
+    return pop_local_slow(localBot, age_relaxed());
   }
 }
 
 template <class E, MEMFLAGS F, unsigned int N>
 bool OverflowTaskQueue<E, F, N>::pop_overflow(E& t)
@@ -190,13 +179,34 @@
   if (overflow_empty()) return false;
   t = overflow_stack()->pop();
   return true;
 }
 
+// A pop_global operation may read an element that is being concurrently
+// written by a push operation.  The pop_global operation will not use
+// such an element, returning failure instead.  But the concurrent read
+// and write places requirements on the element type.
+//
+// Strictly, such concurrent reads and writes are undefined behavior.
+// We ignore that. Instead we require that whatever value tearing may
+// occur as a result is benign. A trivially copyable type (C++14 3.9/9)
+// satisfies the requirement. But we might use classes such as oop that
+// are not trivially copyable (in some build configurations).  Such
+// classes need to be carefully examined with this requirement in mind.
+//
+// The sequence where such a read/write collision can arise is as follows.
+// Assume there is one value in the queue, so bottom == top+1.
+// (1) Thief is doing a pop_global.  It has read age and bottom, and its
+// captured (localBottom - oldAge.top) == 1.
+// (2) Owner does a pop_local and wins the race for that element.  It
+// decrements bottom and increments the age tag.
+// (3) Owner starts a push, writing elems[bottom].  At the same time, Thief
+// reads elems[oldAge.top].  The owner's bottom == the thief's oldAge.top.
+// (4) Thief will discard the read value, because its cmpxchg of age will fail.
 template<class E, MEMFLAGS F, unsigned int N>
-bool GenericTaskQueue<E, F, N>::pop_global(volatile E& t) {
-  Age oldAge = _age.get();
+bool GenericTaskQueue<E, F, N>::pop_global(E& t) {
+  Age oldAge = age_relaxed();
 #ifndef CPU_MULTI_COPY_ATOMIC
   // Architectures with non-multi-copy-atomic memory model require a
   // full fence here to guarantee that bottom is not older than age,
   // which is crucial for the correctness of the algorithm.
   //
@@ -210,30 +220,28 @@
   // value than Thread2 after Thread3 has seen the age value from
   // Thread2.
   OrderAccess::fence();
 #else
   // Everyone else can make do with a LoadLoad barrier to keep reads
-  // from _age and _bottom in order.
+  // from age and bottom in order.
   OrderAccess::loadload();
 #endif
-  uint localBot = Atomic::load_acquire(&_bottom);
-  uint n_elems = size(localBot, oldAge.top());
+  uint localBot = bottom_acquire();
+  uint n_elems = clean_size(localBot, oldAge.top());
   if (n_elems == 0) {
     return false;
   }
 
-  // g++ complains if the volatile result of the assignment is
-  // unused, so we cast the volatile away.  We cannot cast directly
-  // to void, because gcc treats that as not using the result of the
-  // assignment.  However, casting to E& means that we trigger an
-  // unused-value warning.  So, we cast the E& to void.
-  (void) const_cast<E&>(t = _elems[oldAge.top()]);
-  Age newAge(oldAge);
-  newAge.increment();
-  Age resAge = _age.cmpxchg(newAge, oldAge);
+  t = _elems[oldAge.top()];
+  // Increment top; if it wraps, also increment tag, to distinguish it
+  // from any recent _age for the same top() index.
+  idx_t new_top = increment_index(oldAge.top());
+  idx_t new_tag = oldAge.tag() + ((new_top == 0) ? 1 : 0);
+  Age newAge(new_top, new_tag);
+  Age resAge = cmpxchg_age(oldAge, newAge);
 
-  // Note that using "_bottom" here might fail, since a pop_local might
+  // Note that using "bottom" here might fail, since a pop_local might
   // have decremented it.
   assert(dirty_size(localBot, newAge.top()) != N - 1, "sanity");
   return resAge == oldAge;
 }
 
@@ -322,23 +330,18 @@
     }
   }
   return false;
 }
 
-template <unsigned int N, MEMFLAGS F>
-inline typename TaskQueueSuper<N, F>::Age TaskQueueSuper<N, F>::Age::cmpxchg(const Age new_age, const Age old_age) volatile {
-  return Atomic::cmpxchg(&_data, old_age._data, new_age._data);
-}
-
 template<class E, MEMFLAGS F, unsigned int N>
 template<class Fn>
 inline void GenericTaskQueue<E, F, N>::iterate(Fn fn) {
   uint iters = size();
-  uint index = _bottom;
+  uint index = bottom_relaxed();
   for (uint i = 0; i < iters; ++i) {
     index = decrement_index(index);
-    fn(const_cast<E&>(_elems[index])); // cast away volatility
+    fn(_elems[index]);
   }
 }
 
 
 #endif // SHARE_GC_SHARED_TASKQUEUE_INLINE_HPP
