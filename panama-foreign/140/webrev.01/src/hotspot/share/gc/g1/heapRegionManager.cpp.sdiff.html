<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/heapRegionManager.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1NUMAStats.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionManager.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/heapRegionManager.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 42   void check_mt_safety() {
 43     // Master Free List MT safety protocol:
 44     // (a) If we&#39;re at a safepoint, operations on the master free list
 45     // should be invoked by either the VM thread (which will serialize
 46     // them) or by the GC workers while holding the
 47     // FreeList_lock.
 48     // (b) If we&#39;re not at a safepoint, operations on the master free
 49     // list should be invoked while holding the Heap_lock.
 50 
 51     if (SafepointSynchronize::is_at_safepoint()) {
 52       guarantee(Thread::current()-&gt;is_VM_thread() ||
 53                 FreeList_lock-&gt;owned_by_self(), &quot;master free list MT safety protocol at a safepoint&quot;);
 54     } else {
 55       guarantee(Heap_lock-&gt;owned_by_self(), &quot;master free list MT safety protocol outside a safepoint&quot;);
 56     }
 57   }
 58   bool is_correct_type(HeapRegion* hr) { return hr-&gt;is_free(); }
 59   const char* get_description() { return &quot;Free Regions&quot;; }
 60 };
 61 




 62 HeapRegionManager::HeapRegionManager() :
 63   _bot_mapper(NULL),
 64   _cardtable_mapper(NULL),
 65   _card_counts_mapper(NULL),
 66   _available_map(mtGC),
 67   _num_committed(0),
 68   _allocated_heapregions_length(0),
 69   _regions(), _heap_mapper(NULL),
 70   _prev_bitmap_mapper(NULL),
 71   _next_bitmap_mapper(NULL),
 72   _free_list(&quot;Free list&quot;, new MasterFreeRegionListChecker())
 73 { }
 74 
 75 HeapRegionManager* HeapRegionManager::create_manager(G1CollectedHeap* heap) {
 76   if (G1Arguments::is_heterogeneous_heap()) {
 77     return new HeterogeneousHeapRegionManager((uint)(G1Arguments::heap_max_size_bytes() / HeapRegion::GrainBytes) /*heap size as num of regions*/);
 78   }
 79   return new HeapRegionManager();
 80 }
 81 
</pre>
<hr />
<pre>
265 
266   size_t committed_sz =
267     _prev_bitmap_mapper-&gt;reserved_size() +
268     _next_bitmap_mapper-&gt;reserved_size() +
269     _bot_mapper-&gt;reserved_size() +
270     _cardtable_mapper-&gt;reserved_size() +
271     _card_counts_mapper-&gt;reserved_size();
272 
273   return MemoryUsage(0, used_sz, committed_sz, committed_sz);
274 }
275 
276 uint HeapRegionManager::expand_by(uint num_regions, WorkGang* pretouch_workers) {
277   return expand_at(0, num_regions, pretouch_workers);
278 }
279 
280 uint HeapRegionManager::expand_at(uint start, uint num_regions, WorkGang* pretouch_workers) {
281   if (num_regions == 0) {
282     return 0;
283   }
284 
<span class="line-modified">285   uint cur = start;</span>
<span class="line-removed">286   uint idx_last_found = 0;</span>
<span class="line-removed">287   uint num_last_found = 0;</span>
<span class="line-removed">288 </span>
289   uint expanded = 0;
290 
<span class="line-modified">291   while (expanded &lt; num_regions &amp;&amp;</span>
<span class="line-modified">292          (num_last_found = find_unavailable_from_idx(cur, &amp;idx_last_found)) &gt; 0) {</span>
<span class="line-modified">293     uint to_expand = MIN2(num_regions - expanded, num_last_found);</span>
<span class="line-modified">294     make_regions_available(idx_last_found, to_expand, pretouch_workers);</span>





295     expanded += to_expand;
<span class="line-modified">296     cur = idx_last_found + num_last_found + 1;</span>
<span class="line-modified">297   }</span>
298 
299   verify_optional();
300   return expanded;
301 }
302 
303 void HeapRegionManager::expand_exact(uint start, uint num_regions, WorkGang* pretouch_workers) {
304   assert(num_regions != 0, &quot;Need to request at least one region&quot;);
305   uint end = start + num_regions;
306 
307   for (uint i = start; i &lt; end; i++) {
308     if (!is_available(i)) {
309       make_regions_available(i, 1, pretouch_workers);
310     }
311   }
312 
313   verify_optional();
314 }
315 
316 uint HeapRegionManager::expand_on_preferred_node(uint preferred_index) {
317   uint expand_candidate = UINT_MAX;
</pre>
<hr />
<pre>
412   }
413   return NULL;
414 }
415 
416 void HeapRegionManager::iterate(HeapRegionClosure* blk) const {
417   uint len = max_length();
418 
419   for (uint i = 0; i &lt; len; i++) {
420     if (!is_available(i)) {
421       continue;
422     }
423     guarantee(at(i) != NULL, &quot;Tried to access region %u that has a NULL HeapRegion*&quot;, i);
424     bool res = blk-&gt;do_heap_region(at(i));
425     if (res) {
426       blk-&gt;set_incomplete();
427       return;
428     }
429   }
430 }
431 
<span class="line-modified">432 uint HeapRegionManager::find_unavailable_from_idx(uint start_idx, uint* res_idx) const {</span>
<span class="line-modified">433   guarantee(res_idx != NULL, &quot;checking&quot;);</span>
<span class="line-removed">434   guarantee(start_idx &lt;= (max_length() + 1), &quot;checking&quot;);</span>
<span class="line-removed">435 </span>
<span class="line-removed">436   uint num_regions = 0;</span>
437 
<span class="line-modified">438   uint cur = start_idx;</span>
<span class="line-modified">439   while (cur &lt; max_length() &amp;&amp; is_available(cur)) {</span>
<span class="line-modified">440     cur++;</span>


441   }
<span class="line-modified">442   if (cur == max_length()) {</span>
<span class="line-modified">443     return num_regions;</span>
<span class="line-modified">444   }</span>
<span class="line-modified">445   *res_idx = cur;</span>
<span class="line-modified">446   while (cur &lt; max_length() &amp;&amp; !is_available(cur)) {</span>
<span class="line-modified">447     cur++;</span>
<span class="line-modified">448   }</span>
<span class="line-modified">449   num_regions = cur - *res_idx;</span>
<span class="line-modified">450 #ifdef ASSERT</span>
<span class="line-removed">451   for (uint i = *res_idx; i &lt; (*res_idx + num_regions); i++) {</span>
<span class="line-removed">452     assert(!is_available(i), &quot;just checking&quot;);</span>
<span class="line-removed">453   }</span>
<span class="line-removed">454   assert(cur == max_length() || num_regions == 0 || is_available(cur),</span>
<span class="line-removed">455          &quot;The region at the current position %u must be available or at the end of the heap.&quot;, cur);</span>
<span class="line-removed">456 #endif</span>
<span class="line-removed">457   return num_regions;</span>
458 }
459 
460 uint HeapRegionManager::find_highest_free(bool* expanded) {
461   // Loop downwards from the highest region index, looking for an
462   // entry which is either free or not yet committed.  If not yet
463   // committed, expand_at that index.
464   uint curr = max_length() - 1;
465   while (true) {
466     HeapRegion *hr = _regions.get_by_index(curr);
467     if (hr == NULL || !is_available(curr)) {
468       uint res = expand_at(curr, 1, NULL);
469       if (res == 1) {
470         *expanded = true;
471         return curr;
472       }
473     } else {
474       if (hr-&gt;is_free()) {
475         *expanded = false;
476         return curr;
477       }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 42   void check_mt_safety() {
 43     // Master Free List MT safety protocol:
 44     // (a) If we&#39;re at a safepoint, operations on the master free list
 45     // should be invoked by either the VM thread (which will serialize
 46     // them) or by the GC workers while holding the
 47     // FreeList_lock.
 48     // (b) If we&#39;re not at a safepoint, operations on the master free
 49     // list should be invoked while holding the Heap_lock.
 50 
 51     if (SafepointSynchronize::is_at_safepoint()) {
 52       guarantee(Thread::current()-&gt;is_VM_thread() ||
 53                 FreeList_lock-&gt;owned_by_self(), &quot;master free list MT safety protocol at a safepoint&quot;);
 54     } else {
 55       guarantee(Heap_lock-&gt;owned_by_self(), &quot;master free list MT safety protocol outside a safepoint&quot;);
 56     }
 57   }
 58   bool is_correct_type(HeapRegion* hr) { return hr-&gt;is_free(); }
 59   const char* get_description() { return &quot;Free Regions&quot;; }
 60 };
 61 
<span class="line-added"> 62 HeapRegionRange::HeapRegionRange(uint start, uint end) : _start(start), _end(end) {</span>
<span class="line-added"> 63   assert(start &lt;= end, &quot;Invariant&quot;);</span>
<span class="line-added"> 64 }</span>
<span class="line-added"> 65 </span>
 66 HeapRegionManager::HeapRegionManager() :
 67   _bot_mapper(NULL),
 68   _cardtable_mapper(NULL),
 69   _card_counts_mapper(NULL),
 70   _available_map(mtGC),
 71   _num_committed(0),
 72   _allocated_heapregions_length(0),
 73   _regions(), _heap_mapper(NULL),
 74   _prev_bitmap_mapper(NULL),
 75   _next_bitmap_mapper(NULL),
 76   _free_list(&quot;Free list&quot;, new MasterFreeRegionListChecker())
 77 { }
 78 
 79 HeapRegionManager* HeapRegionManager::create_manager(G1CollectedHeap* heap) {
 80   if (G1Arguments::is_heterogeneous_heap()) {
 81     return new HeterogeneousHeapRegionManager((uint)(G1Arguments::heap_max_size_bytes() / HeapRegion::GrainBytes) /*heap size as num of regions*/);
 82   }
 83   return new HeapRegionManager();
 84 }
 85 
</pre>
<hr />
<pre>
269 
270   size_t committed_sz =
271     _prev_bitmap_mapper-&gt;reserved_size() +
272     _next_bitmap_mapper-&gt;reserved_size() +
273     _bot_mapper-&gt;reserved_size() +
274     _cardtable_mapper-&gt;reserved_size() +
275     _card_counts_mapper-&gt;reserved_size();
276 
277   return MemoryUsage(0, used_sz, committed_sz, committed_sz);
278 }
279 
280 uint HeapRegionManager::expand_by(uint num_regions, WorkGang* pretouch_workers) {
281   return expand_at(0, num_regions, pretouch_workers);
282 }
283 
284 uint HeapRegionManager::expand_at(uint start, uint num_regions, WorkGang* pretouch_workers) {
285   if (num_regions == 0) {
286     return 0;
287   }
288 
<span class="line-modified">289   uint offset = start;</span>



290   uint expanded = 0;
291 
<span class="line-modified">292   do {</span>
<span class="line-modified">293     HeapRegionRange regions = find_unavailable_from_idx(offset);</span>
<span class="line-modified">294     if (regions.length() == 0) {</span>
<span class="line-modified">295       // No more unavailable regions.</span>
<span class="line-added">296       break;</span>
<span class="line-added">297     }</span>
<span class="line-added">298 </span>
<span class="line-added">299     uint to_expand = MIN2(num_regions - expanded, regions.length());</span>
<span class="line-added">300     make_regions_available(regions.start(), to_expand, pretouch_workers);</span>
301     expanded += to_expand;
<span class="line-modified">302     offset = regions.end();</span>
<span class="line-modified">303   } while (expanded &lt; num_regions);</span>
304 
305   verify_optional();
306   return expanded;
307 }
308 
309 void HeapRegionManager::expand_exact(uint start, uint num_regions, WorkGang* pretouch_workers) {
310   assert(num_regions != 0, &quot;Need to request at least one region&quot;);
311   uint end = start + num_regions;
312 
313   for (uint i = start; i &lt; end; i++) {
314     if (!is_available(i)) {
315       make_regions_available(i, 1, pretouch_workers);
316     }
317   }
318 
319   verify_optional();
320 }
321 
322 uint HeapRegionManager::expand_on_preferred_node(uint preferred_index) {
323   uint expand_candidate = UINT_MAX;
</pre>
<hr />
<pre>
418   }
419   return NULL;
420 }
421 
422 void HeapRegionManager::iterate(HeapRegionClosure* blk) const {
423   uint len = max_length();
424 
425   for (uint i = 0; i &lt; len; i++) {
426     if (!is_available(i)) {
427       continue;
428     }
429     guarantee(at(i) != NULL, &quot;Tried to access region %u that has a NULL HeapRegion*&quot;, i);
430     bool res = blk-&gt;do_heap_region(at(i));
431     if (res) {
432       blk-&gt;set_incomplete();
433       return;
434     }
435   }
436 }
437 
<span class="line-modified">438 HeapRegionRange HeapRegionManager::find_unavailable_from_idx(uint index) const {</span>
<span class="line-modified">439   guarantee(index &lt;= max_length(), &quot;checking&quot;);</span>



440 
<span class="line-modified">441   // Find first unavailable region from offset.</span>
<span class="line-modified">442   BitMap::idx_t start = _available_map.get_next_zero_offset(index);</span>
<span class="line-modified">443   if (start == _available_map.size()) {</span>
<span class="line-added">444     // No unavailable regions found.</span>
<span class="line-added">445     return HeapRegionRange(max_length(), max_length());</span>
446   }
<span class="line-modified">447 </span>
<span class="line-modified">448   // The end of the range is the next available region.</span>
<span class="line-modified">449   BitMap::idx_t end = _available_map.get_next_one_offset(start);</span>
<span class="line-modified">450 </span>
<span class="line-modified">451   assert(!_available_map.at(start), &quot;Found region (&quot; SIZE_FORMAT &quot;) is not unavailable&quot;, start);</span>
<span class="line-modified">452   assert(!_available_map.at(end - 1), &quot;Last region (&quot; SIZE_FORMAT &quot;) in range is not unavailable&quot;, end - 1);</span>
<span class="line-modified">453   assert(end == _available_map.size() || _available_map.at(end), &quot;Region (&quot; SIZE_FORMAT &quot;) is not available&quot;, end);</span>
<span class="line-modified">454 </span>
<span class="line-modified">455   return HeapRegionRange((uint) start, (uint) end);</span>







456 }
457 
458 uint HeapRegionManager::find_highest_free(bool* expanded) {
459   // Loop downwards from the highest region index, looking for an
460   // entry which is either free or not yet committed.  If not yet
461   // committed, expand_at that index.
462   uint curr = max_length() - 1;
463   while (true) {
464     HeapRegion *hr = _regions.get_by_index(curr);
465     if (hr == NULL || !is_available(curr)) {
466       uint res = expand_at(curr, 1, NULL);
467       if (res == 1) {
468         *expanded = true;
469         return curr;
470       }
471     } else {
472       if (hr-&gt;is_free()) {
473         *expanded = false;
474         return curr;
475       }
</pre>
</td>
</tr>
</table>
<center><a href="g1NUMAStats.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="heapRegionManager.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>