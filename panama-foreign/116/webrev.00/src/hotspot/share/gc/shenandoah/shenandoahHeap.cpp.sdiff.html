<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahFreeSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 470   _monitoring_support(NULL),
 471   _memory_pool(NULL),
 472   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 473   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 474   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 475   _soft_ref_policy(),
 476   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 477   _ref_processor(NULL),
 478   _marking_context(NULL),
 479   _bitmap_size(0),
 480   _bitmap_regions_per_slice(0),
 481   _bitmap_bytes_per_slice(0),
 482   _bitmap_region_special(false),
 483   _aux_bitmap_region_special(false),
 484   _liveness_cache(NULL),
 485   _collection_set(NULL)
 486 {
 487   _heap = this;
 488 
 489   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);
<span class="line-removed"> 490   log_info(gc, init)(&quot;Reference processing: %s&quot;, ParallelRefProcEnabled ? &quot;parallel&quot; : &quot;serial&quot;);</span>
 491 
 492   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 493 
 494   _max_workers = MAX2(_max_workers, 1U);
 495   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 496                             /* are_GC_task_threads */ true,
 497                             /* are_ConcurrentGC_threads */ true);
 498   if (_workers == NULL) {
 499     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 500   } else {
 501     _workers-&gt;initialize_workers();
 502   }
 503 
 504   if (ParallelGCThreads &gt; 1) {
 505     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
 506                                                 ParallelGCThreads,
 507                       /* are_GC_task_threads */ false,
 508                  /* are_ConcurrentGC_threads */ false);
 509     _safepoint_workers-&gt;initialize_workers();
 510   }
</pre>
<hr />
<pre>
 538 void ShenandoahHeap::reset_mark_bitmap() {
 539   assert_gc_workers(_workers-&gt;active_workers());
 540   mark_incomplete_marking_context();
 541 
 542   ShenandoahResetBitmapTask task;
 543   _workers-&gt;run_task(&amp;task);
 544 }
 545 
 546 void ShenandoahHeap::print_on(outputStream* st) const {
 547   st-&gt;print_cr(&quot;Shenandoah Heap&quot;);
 548   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot;%s total, &quot; SIZE_FORMAT &quot;%s committed, &quot; SIZE_FORMAT &quot;%s used&quot;,
 549                byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity()),
 550                byte_size_in_proper_unit(committed()),    proper_unit_for_byte_size(committed()),
 551                byte_size_in_proper_unit(used()),         proper_unit_for_byte_size(used()));
 552   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT&quot;%s regions&quot;,
 553                num_regions(),
 554                byte_size_in_proper_unit(ShenandoahHeapRegion::region_size_bytes()),
 555                proper_unit_for_byte_size(ShenandoahHeapRegion::region_size_bytes()));
 556 
 557   st-&gt;print(&quot;Status: &quot;);
<span class="line-modified"> 558   if (has_forwarded_objects())               st-&gt;print(&quot;has forwarded objects, &quot;);</span>
<span class="line-modified"> 559   if (is_concurrent_mark_in_progress())      st-&gt;print(&quot;marking, &quot;);</span>
<span class="line-modified"> 560   if (is_evacuation_in_progress())           st-&gt;print(&quot;evacuating, &quot;);</span>
<span class="line-modified"> 561   if (is_update_refs_in_progress())          st-&gt;print(&quot;updating refs, &quot;);</span>
<span class="line-modified"> 562   if (is_degenerated_gc_in_progress())       st-&gt;print(&quot;degenerated gc, &quot;);</span>
<span class="line-modified"> 563   if (is_full_gc_in_progress())              st-&gt;print(&quot;full gc, &quot;);</span>
<span class="line-modified"> 564   if (is_full_gc_move_in_progress())         st-&gt;print(&quot;full gc move, &quot;);</span>
<span class="line-modified"> 565   if (is_concurrent_root_in_progress())      st-&gt;print(&quot;concurrent roots, &quot;);</span>


 566 
 567   if (cancelled_gc()) {
 568     st-&gt;print(&quot;cancelled&quot;);
 569   } else {
 570     st-&gt;print(&quot;not cancelled&quot;);
 571   }
 572   st-&gt;cr();
 573 
 574   st-&gt;print_cr(&quot;Reserved region:&quot;);
 575   st-&gt;print_cr(&quot; - [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;) &quot;,
 576                p2i(reserved_region().start()),
 577                p2i(reserved_region().end()));
 578 
 579   ShenandoahCollectionSet* cset = collection_set();
 580   st-&gt;print_cr(&quot;Collection set:&quot;);
 581   if (cset != NULL) {
 582     st-&gt;print_cr(&quot; - map (vanilla): &quot; PTR_FORMAT, p2i(cset-&gt;map_address()));
 583     st-&gt;print_cr(&quot; - map (biased):  &quot; PTR_FORMAT, p2i(cset-&gt;biased_map_address()));
 584   } else {
 585     st-&gt;print_cr(&quot; (NULL)&quot;);
</pre>
<hr />
<pre>
1217       // and turn this on unconditionally.
1218     }
1219   }
1220 }
1221 size_t ShenandoahHeap::tlab_capacity(Thread *thr) const {
1222   return _free_set-&gt;capacity();
1223 }
1224 
1225 class ObjectIterateScanRootClosure : public BasicOopIterateClosure {
1226 private:
1227   MarkBitMap* _bitmap;
1228   Stack&lt;oop,mtGC&gt;* _oop_stack;
1229   ShenandoahHeap* const _heap;
1230   ShenandoahMarkingContext* const _marking_context;
1231 
1232   template &lt;class T&gt;
1233   void do_oop_work(T* p) {
1234     T o = RawAccess&lt;&gt;::oop_load(p);
1235     if (!CompressedOops::is_null(o)) {
1236       oop obj = CompressedOops::decode_not_null(o);
<span class="line-modified">1237       if (_heap-&gt;is_concurrent_root_in_progress() &amp;&amp; !_marking_context-&gt;is_marked(obj)) {</span>
1238         // There may be dead oops in weak roots in concurrent root phase, do not touch them.
1239         return;
1240       }
1241       obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);
1242 
1243       assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1244       if (!_bitmap-&gt;is_marked(obj)) {
1245         _bitmap-&gt;mark(obj);
1246         _oop_stack-&gt;push(obj);
1247       }
1248     }
1249   }
1250 public:
1251   ObjectIterateScanRootClosure(MarkBitMap* bitmap, Stack&lt;oop,mtGC&gt;* oop_stack) :
1252     _bitmap(bitmap), _oop_stack(oop_stack), _heap(ShenandoahHeap::heap()),
1253     _marking_context(_heap-&gt;marking_context()) {}
1254   void do_oop(oop* p)       { do_oop_work(p); }
1255   void do_oop(narrowOop* p) { do_oop_work(p); }
1256 };
1257 
</pre>
<hr />
<pre>
1359   }
1360 };
1361 
1362 void ShenandoahHeap::parallel_heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1363   assert(blk-&gt;is_thread_safe(), &quot;Only thread-safe closures here&quot;);
1364   if (num_regions() &gt; ShenandoahParallelRegionStride) {
1365     ShenandoahParallelHeapRegionTask task(blk);
1366     workers()-&gt;run_task(&amp;task);
1367   } else {
1368     heap_region_iterate(blk);
1369   }
1370 }
1371 
1372 class ShenandoahInitMarkUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {
1373 private:
1374   ShenandoahMarkingContext* const _ctx;
1375 public:
1376   ShenandoahInitMarkUpdateRegionStateClosure() : _ctx(ShenandoahHeap::heap()-&gt;marking_context()) {}
1377 
1378   void heap_region_do(ShenandoahHeapRegion* r) {

1379     if (r-&gt;is_active()) {
<span class="line-modified">1380       r-&gt;clear_live_data();</span>
<span class="line-modified">1381       _ctx-&gt;capture_top_at_mark_start(r);</span>



1382     } else {
<span class="line-removed">1383       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;index());</span>
1384       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1385              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;index());
1386     }
1387   }
1388 
1389   bool is_thread_safe() { return true; }
1390 };
1391 
1392 void ShenandoahHeap::op_init_mark() {
1393   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1394   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1395 
1396   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1397   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);
1398   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);
1399 
1400   if (ShenandoahVerify) {
1401     verifier()-&gt;verify_before_concmark();
1402   }
1403 
</pre>
<hr />
<pre>
1612   ShenandoahEvacuationTask task(this, _collection_set, true);
1613   workers()-&gt;run_task(&amp;task);
1614 }
1615 
1616 void ShenandoahHeap::op_stw_evac() {
1617   ShenandoahEvacuationTask task(this, _collection_set, false);
1618   workers()-&gt;run_task(&amp;task);
1619 }
1620 
1621 void ShenandoahHeap::op_updaterefs() {
1622   update_heap_references(true);
1623 }
1624 
1625 void ShenandoahHeap::op_cleanup() {
1626   free_set()-&gt;recycle_trash();
1627 }
1628 
1629 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1630 private:
1631   ShenandoahVMRoots&lt;true /*concurrent*/&gt;        _vm_roots;
<span class="line-removed">1632   ShenandoahWeakRoots&lt;true /*concurrent*/&gt;      _weak_roots;</span>
1633   ShenandoahClassLoaderDataRoots&lt;true /*concurrent*/, false /*single threaded*/&gt; _cld_roots;
1634   ShenandoahConcurrentStringDedupRoots          _dedup_roots;
<span class="line-removed">1635   bool                                          _include_weak_roots;</span>
1636 
1637 public:
<span class="line-modified">1638   ShenandoahConcurrentRootsEvacUpdateTask(bool include_weak_roots) :</span>
<span class="line-modified">1639     AbstractGangTask(&quot;Shenandoah Evacuate/Update Concurrent Roots Task&quot;),</span>
<span class="line-removed">1640     _include_weak_roots(include_weak_roots) {</span>
1641   }
1642 
1643   void work(uint worker_id) {
1644     ShenandoahEvacOOMScope oom;
1645     {
1646       // vm_roots and weak_roots are OopStorage backed roots, concurrent iteration
1647       // may race against OopStorage::release() calls.
1648       ShenandoahEvacUpdateOopStorageRootsClosure cl;
1649       _vm_roots.oops_do&lt;ShenandoahEvacUpdateOopStorageRootsClosure&gt;(&amp;cl);
<span class="line-removed">1650 </span>
<span class="line-removed">1651       if (_include_weak_roots) {</span>
<span class="line-removed">1652         _weak_roots.oops_do&lt;ShenandoahEvacUpdateOopStorageRootsClosure&gt;(&amp;cl);</span>
<span class="line-removed">1653       }</span>
1654     }
1655 
1656     {
1657       ShenandoahEvacuateUpdateRootsClosure&lt;&gt; cl;
1658       CLDToOopClosure clds(&amp;cl, ClassLoaderData::_claim_strong);
1659       _cld_roots.cld_do(&amp;clds);
1660     }
1661 
1662     {
1663       ShenandoahForwardedIsAliveClosure is_alive;
1664       ShenandoahEvacuateUpdateRootsClosure&lt;MO_RELEASE&gt; keep_alive;
1665       _dedup_roots.oops_do(&amp;is_alive, &amp;keep_alive, worker_id);
1666     }
1667   }
1668 };
1669 
1670 class ShenandoahEvacUpdateCleanupOopStorageRootsClosure : public BasicOopIterateClosure {
1671 private:
1672   ShenandoahHeap* const _heap;
1673   ShenandoahMarkingContext* const _mark_context;
</pre>
<hr />
<pre>
1752   }
1753 
1754   void work(uint worker_id) {
1755     ShenandoahEvacOOMScope oom;
1756     // jni_roots and weak_roots are OopStorage backed roots, concurrent iteration
1757     // may race against OopStorage::release() calls.
1758     ShenandoahEvacUpdateCleanupOopStorageRootsClosure cl;
1759     _jni_roots.oops_do(&amp;cl, worker_id);
1760     _vm_roots.oops_do(&amp;cl, worker_id);
1761 
1762     cl.reset_dead_counter();
1763     _string_table_roots.oops_do(&amp;cl, worker_id);
1764     StringTable::inc_dead_counter(cl.dead_counter());
1765 
1766     cl.reset_dead_counter();
1767     _resolved_method_table_roots.oops_do(&amp;cl, worker_id);
1768     ResolvedMethodTable::inc_dead_counter(cl.dead_counter());
1769   }
1770 };
1771 
<span class="line-modified">1772 void ShenandoahHeap::op_roots() {</span>
<span class="line-modified">1773   if (is_concurrent_root_in_progress()) {</span>
<span class="line-modified">1774     if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {</span>
<span class="line-modified">1775       // Concurrent weak root processing</span>
<span class="line-modified">1776       ShenandoahConcurrentWeakRootsEvacUpdateTask task;</span>
<span class="line-removed">1777       workers()-&gt;run_task(&amp;task);</span>
1778 

1779       _unloader.unload();
1780     }
















1781 
<span class="line-modified">1782     if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {</span>
<span class="line-modified">1783       ShenandoahConcurrentRootsEvacUpdateTask task(!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-modified">1784       workers()-&gt;run_task(&amp;task);</span>



1785     }
1786   }
1787 
<span class="line-modified">1788   set_concurrent_root_in_progress(false);</span>
<span class="line-modified">1789 }</span>
1790 
1791 void ShenandoahHeap::op_reset() {
1792   if (ShenandoahPacing) {
1793     pacer()-&gt;setup_for_reset();
1794   }
1795   reset_mark_bitmap();



1796 }
1797 
1798 void ShenandoahHeap::op_preclean() {
1799   if (ShenandoahPacing) {
1800     pacer()-&gt;setup_for_preclean();
1801   }
1802   concurrent_mark()-&gt;preclean_weak_refs();
1803 }
1804 
1805 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1806   ShenandoahMetricsSnapshot metrics;
1807   metrics.snap_before();
1808 
1809   full_gc()-&gt;do_it(cause);
1810   if (UseTLAB) {
1811     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::full_gc_resize_tlabs);
1812     resize_all_tlabs();
1813   }
1814 
1815   metrics.snap_after();
</pre>
<hr />
<pre>
1997 void ShenandoahHeap::set_gc_state_mask(uint mask, bool value) {
1998   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should really be Shenandoah safepoint&quot;);
1999   _gc_state.set_cond(mask, value);
2000   set_gc_state_all_threads(_gc_state.raw_value());
2001 }
2002 
2003 void ShenandoahHeap::set_concurrent_mark_in_progress(bool in_progress) {
2004   if (has_forwarded_objects()) {
2005     set_gc_state_mask(MARKING | UPDATEREFS, in_progress);
2006   } else {
2007     set_gc_state_mask(MARKING, in_progress);
2008   }
2009   ShenandoahBarrierSet::satb_mark_queue_set().set_active_all_threads(in_progress, !in_progress);
2010 }
2011 
2012 void ShenandoahHeap::set_evacuation_in_progress(bool in_progress) {
2013   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Only call this at safepoint&quot;);
2014   set_gc_state_mask(EVACUATION, in_progress);
2015 }
2016 
<span class="line-modified">2017 void ShenandoahHeap::set_concurrent_root_in_progress(bool in_progress) {</span>









2018   assert(ShenandoahConcurrentRoots::can_do_concurrent_roots(), &quot;Why set the flag?&quot;);
2019   if (in_progress) {
<span class="line-modified">2020     _concurrent_root_in_progress.set();</span>
2021   } else {
<span class="line-modified">2022     _concurrent_root_in_progress.unset();</span>
2023   }
2024 }
2025 
2026 void ShenandoahHeap::ref_processing_init() {
2027   assert(_max_workers &gt; 0, &quot;Sanity&quot;);
2028 



2029   _ref_processor =
2030     new ReferenceProcessor(&amp;_subject_to_discovery,  // is_subject_to_discovery
<span class="line-modified">2031                            ParallelRefProcEnabled,  // MT processing</span>
2032                            _max_workers,            // Degree of MT processing
<span class="line-modified">2033                            true,                    // MT discovery</span>
2034                            _max_workers,            // Degree of MT discovery
2035                            false,                   // Reference discovery is not atomic
2036                            NULL,                    // No closure, should be installed before use
2037                            true);                   // Scale worker threads
2038 




2039   shenandoah_assert_rp_isalive_not_installed();
2040 }
2041 
2042 GCTracer* ShenandoahHeap::tracer() {
2043   return shenandoah_policy()-&gt;tracer();
2044 }
2045 
2046 size_t ShenandoahHeap::tlab_used(Thread* thread) const {
2047   return _free_set-&gt;used();
2048 }
2049 
2050 bool ShenandoahHeap::try_cancel_gc() {
2051   while (true) {
2052     jbyte prev = _cancelled_gc.cmpxchg(CANCELLED, CANCELLABLE);
2053     if (prev == CANCELLABLE) return true;
2054     else if (prev == CANCELLED) return false;
2055     assert(ShenandoahSuspendibleWorkers, &quot;should not get here when not using suspendible workers&quot;);
2056     assert(prev == NOT_CANCELLED, &quot;must be NOT_CANCELLED&quot;);
2057     if (Thread::current()-&gt;is_Java_thread()) {
2058       // We need to provide a safepoint here, otherwise we might
</pre>
<hr />
<pre>
2276   assert_pinned_region_status();
2277 }
2278 
2279 #ifdef ASSERT
2280 void ShenandoahHeap::assert_pinned_region_status() {
2281   for (size_t i = 0; i &lt; num_regions(); i++) {
2282     ShenandoahHeapRegion* r = get_region(i);
2283     assert((r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() &gt; 0) || (!r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() == 0),
2284            &quot;Region &quot; SIZE_FORMAT &quot; pinning status is inconsistent&quot;, i);
2285   }
2286 }
2287 #endif
2288 
2289 ConcurrentGCTimer* ShenandoahHeap::gc_timer() const {
2290   return _gc_timer;
2291 }
2292 
2293 void ShenandoahHeap::prepare_concurrent_roots() {
2294   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2295   if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
<span class="line-modified">2296     set_concurrent_root_in_progress(true);</span>

2297   }
2298 }
2299 
2300 void ShenandoahHeap::prepare_concurrent_unloading() {
2301   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2302   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2303     _unloader.prepare();
2304   }
2305 }
2306 
2307 void ShenandoahHeap::finish_concurrent_unloading() {
2308   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2309   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2310     _unloader.finish();
2311   }
2312 }
2313 
2314 #ifdef ASSERT
2315 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2316   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
</pre>
<hr />
<pre>
2703   op_init_updaterefs();
2704 }
2705 
2706 void ShenandoahHeap::entry_final_updaterefs() {
2707   static const char* msg = &quot;Pause Final Update Refs&quot;;
2708   ShenandoahPausePhase gc_phase(msg);
2709   EventMark em(&quot;%s&quot;, msg);
2710 
2711   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2712   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);
2713 
2714   ShenandoahWorkerScope scope(workers(),
2715                               ShenandoahWorkerPolicy::calc_workers_for_final_update_ref(),
2716                               &quot;final reference update&quot;);
2717 
2718   op_final_updaterefs();
2719 }
2720 
2721 void ShenandoahHeap::entry_full(GCCause::Cause cause) {
2722   static const char* msg = &quot;Pause Full&quot;;
<span class="line-modified">2723   ShenandoahPausePhase gc_phase(msg);</span>
2724   EventMark em(&quot;%s&quot;, msg);
2725 
2726   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2727   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc);
2728 
2729   ShenandoahWorkerScope scope(workers(),
2730                               ShenandoahWorkerPolicy::calc_workers_for_fullgc(),
2731                               &quot;full gc&quot;);
2732 
2733   op_full(cause);
2734 }
2735 
2736 void ShenandoahHeap::entry_degenerated(int point) {
2737   ShenandoahDegenPoint dpoint = (ShenandoahDegenPoint)point;
2738   const char* msg = degen_event_message(dpoint);
<span class="line-modified">2739   ShenandoahPausePhase gc_phase(msg);</span>
2740   EventMark em(&quot;%s&quot;, msg);
2741 
2742   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2743   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc);
2744 
2745   ShenandoahWorkerScope scope(workers(),
2746                               ShenandoahWorkerPolicy::calc_workers_for_stw_degenerated(),
2747                               &quot;stw degenerated gc&quot;);
2748 
2749   set_degenerated_gc_in_progress(true);
2750   op_degenerated(dpoint);
2751   set_degenerated_gc_in_progress(false);
2752 }
2753 
2754 void ShenandoahHeap::entry_mark() {
2755   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2756 
2757   const char* msg = conc_mark_event_message();
2758   ShenandoahConcurrentPhase gc_phase(msg);
2759   EventMark em(&quot;%s&quot;, msg);
</pre>
<hr />
<pre>
2783 
2784   try_inject_alloc_failure();
2785   op_conc_evac();
2786 }
2787 
2788 void ShenandoahHeap::entry_updaterefs() {
2789   static const char* msg = &quot;Concurrent update references&quot;;
2790   ShenandoahConcurrentPhase gc_phase(msg);
2791   EventMark em(&quot;%s&quot;, msg);
2792 
2793   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_update_refs);
2794 
2795   ShenandoahWorkerScope scope(workers(),
2796                               ShenandoahWorkerPolicy::calc_workers_for_conc_update_ref(),
2797                               &quot;concurrent reference update&quot;);
2798 
2799   try_inject_alloc_failure();
2800   op_updaterefs();
2801 }
2802 
<span class="line-modified">2803 void ShenandoahHeap::entry_roots() {</span>
<span class="line-modified">2804   static const char* msg = &quot;Concurrent roots processing&quot;;</span>
2805   ShenandoahConcurrentPhase gc_phase(msg);
2806   EventMark em(&quot;%s&quot;, msg);
2807 
<span class="line-modified">2808   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_roots);</span>
2809 
2810   ShenandoahWorkerScope scope(workers(),
2811                               ShenandoahWorkerPolicy::calc_workers_for_conc_root_processing(),
<span class="line-modified">2812                               &quot;concurrent root processing&quot;);</span>
2813 
2814   try_inject_alloc_failure();
<span class="line-modified">2815   op_roots();</span>















2816 }
2817 
2818 void ShenandoahHeap::entry_cleanup() {
2819   static const char* msg = &quot;Concurrent cleanup&quot;;
2820   ShenandoahConcurrentPhase gc_phase(msg,  true /* log_heap_usage */);
2821   EventMark em(&quot;%s&quot;, msg);
2822 
2823   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_cleanup);
2824 
2825   // This phase does not use workers, no need for setup
2826 
2827   try_inject_alloc_failure();
2828   op_cleanup();
2829 }
2830 
2831 void ShenandoahHeap::entry_reset() {
2832   static const char* msg = &quot;Concurrent reset&quot;;
2833   ShenandoahConcurrentPhase gc_phase(msg);
2834   EventMark em(&quot;%s&quot;, msg);
2835 
</pre>
<hr />
<pre>
2846 void ShenandoahHeap::entry_preclean() {
2847   if (ShenandoahPreclean &amp;&amp; process_references()) {
2848     static const char* msg = &quot;Concurrent precleaning&quot;;
2849     ShenandoahConcurrentPhase gc_phase(msg);
2850     EventMark em(&quot;%s&quot;, msg);
2851 
2852     ShenandoahGCSubPhase conc_preclean(ShenandoahPhaseTimings::conc_preclean);
2853 
2854     ShenandoahWorkerScope scope(workers(),
2855                                 ShenandoahWorkerPolicy::calc_workers_for_conc_preclean(),
2856                                 &quot;concurrent preclean&quot;,
2857                                 /* check_workers = */ false);
2858 
2859     try_inject_alloc_failure();
2860     op_preclean();
2861   }
2862 }
2863 
2864 void ShenandoahHeap::entry_uncommit(double shrink_before) {
2865   static const char *msg = &quot;Concurrent uncommit&quot;;
<span class="line-modified">2866   ShenandoahConcurrentPhase gc_phase(msg);</span>
2867   EventMark em(&quot;%s&quot;, msg);
2868 
2869   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_uncommit);
2870 
2871   op_uncommit(shrink_before);
2872 }
2873 
2874 void ShenandoahHeap::try_inject_alloc_failure() {
2875   if (ShenandoahAllocFailureALot &amp;&amp; !cancelled_gc() &amp;&amp; ((os::random() % 1000) &gt; 950)) {
2876     _inject_alloc_failure.set();
2877     os::naked_short_sleep(1);
2878     if (cancelled_gc()) {
2879       log_info(gc)(&quot;Allocation failure was successfully injected&quot;);
2880     }
2881   }
2882 }
2883 
2884 bool ShenandoahHeap::should_inject_alloc_failure() {
2885   return _inject_alloc_failure.is_set() &amp;&amp; _inject_alloc_failure.try_unset();
2886 }
</pre>
</td>
<td>
<hr />
<pre>
 470   _monitoring_support(NULL),
 471   _memory_pool(NULL),
 472   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 473   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 474   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 475   _soft_ref_policy(),
 476   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 477   _ref_processor(NULL),
 478   _marking_context(NULL),
 479   _bitmap_size(0),
 480   _bitmap_regions_per_slice(0),
 481   _bitmap_bytes_per_slice(0),
 482   _bitmap_region_special(false),
 483   _aux_bitmap_region_special(false),
 484   _liveness_cache(NULL),
 485   _collection_set(NULL)
 486 {
 487   _heap = this;
 488 
 489   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);

 490 
 491   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 492 
 493   _max_workers = MAX2(_max_workers, 1U);
 494   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 495                             /* are_GC_task_threads */ true,
 496                             /* are_ConcurrentGC_threads */ true);
 497   if (_workers == NULL) {
 498     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 499   } else {
 500     _workers-&gt;initialize_workers();
 501   }
 502 
 503   if (ParallelGCThreads &gt; 1) {
 504     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
 505                                                 ParallelGCThreads,
 506                       /* are_GC_task_threads */ false,
 507                  /* are_ConcurrentGC_threads */ false);
 508     _safepoint_workers-&gt;initialize_workers();
 509   }
</pre>
<hr />
<pre>
 537 void ShenandoahHeap::reset_mark_bitmap() {
 538   assert_gc_workers(_workers-&gt;active_workers());
 539   mark_incomplete_marking_context();
 540 
 541   ShenandoahResetBitmapTask task;
 542   _workers-&gt;run_task(&amp;task);
 543 }
 544 
 545 void ShenandoahHeap::print_on(outputStream* st) const {
 546   st-&gt;print_cr(&quot;Shenandoah Heap&quot;);
 547   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot;%s total, &quot; SIZE_FORMAT &quot;%s committed, &quot; SIZE_FORMAT &quot;%s used&quot;,
 548                byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity()),
 549                byte_size_in_proper_unit(committed()),    proper_unit_for_byte_size(committed()),
 550                byte_size_in_proper_unit(used()),         proper_unit_for_byte_size(used()));
 551   st-&gt;print_cr(&quot; &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT&quot;%s regions&quot;,
 552                num_regions(),
 553                byte_size_in_proper_unit(ShenandoahHeapRegion::region_size_bytes()),
 554                proper_unit_for_byte_size(ShenandoahHeapRegion::region_size_bytes()));
 555 
 556   st-&gt;print(&quot;Status: &quot;);
<span class="line-modified"> 557   if (has_forwarded_objects())                 st-&gt;print(&quot;has forwarded objects, &quot;);</span>
<span class="line-modified"> 558   if (is_concurrent_mark_in_progress())        st-&gt;print(&quot;marking, &quot;);</span>
<span class="line-modified"> 559   if (is_evacuation_in_progress())             st-&gt;print(&quot;evacuating, &quot;);</span>
<span class="line-modified"> 560   if (is_update_refs_in_progress())            st-&gt;print(&quot;updating refs, &quot;);</span>
<span class="line-modified"> 561   if (is_degenerated_gc_in_progress())         st-&gt;print(&quot;degenerated gc, &quot;);</span>
<span class="line-modified"> 562   if (is_full_gc_in_progress())                st-&gt;print(&quot;full gc, &quot;);</span>
<span class="line-modified"> 563   if (is_full_gc_move_in_progress())           st-&gt;print(&quot;full gc move, &quot;);</span>
<span class="line-modified"> 564   if (is_concurrent_weak_root_in_progress())   st-&gt;print(&quot;concurrent weak roots, &quot;);</span>
<span class="line-added"> 565   if (is_concurrent_strong_root_in_progress() &amp;&amp;</span>
<span class="line-added"> 566       !is_concurrent_weak_root_in_progress())  st-&gt;print(&quot;concurrent strong roots, &quot;);</span>
 567 
 568   if (cancelled_gc()) {
 569     st-&gt;print(&quot;cancelled&quot;);
 570   } else {
 571     st-&gt;print(&quot;not cancelled&quot;);
 572   }
 573   st-&gt;cr();
 574 
 575   st-&gt;print_cr(&quot;Reserved region:&quot;);
 576   st-&gt;print_cr(&quot; - [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;) &quot;,
 577                p2i(reserved_region().start()),
 578                p2i(reserved_region().end()));
 579 
 580   ShenandoahCollectionSet* cset = collection_set();
 581   st-&gt;print_cr(&quot;Collection set:&quot;);
 582   if (cset != NULL) {
 583     st-&gt;print_cr(&quot; - map (vanilla): &quot; PTR_FORMAT, p2i(cset-&gt;map_address()));
 584     st-&gt;print_cr(&quot; - map (biased):  &quot; PTR_FORMAT, p2i(cset-&gt;biased_map_address()));
 585   } else {
 586     st-&gt;print_cr(&quot; (NULL)&quot;);
</pre>
<hr />
<pre>
1218       // and turn this on unconditionally.
1219     }
1220   }
1221 }
1222 size_t ShenandoahHeap::tlab_capacity(Thread *thr) const {
1223   return _free_set-&gt;capacity();
1224 }
1225 
1226 class ObjectIterateScanRootClosure : public BasicOopIterateClosure {
1227 private:
1228   MarkBitMap* _bitmap;
1229   Stack&lt;oop,mtGC&gt;* _oop_stack;
1230   ShenandoahHeap* const _heap;
1231   ShenandoahMarkingContext* const _marking_context;
1232 
1233   template &lt;class T&gt;
1234   void do_oop_work(T* p) {
1235     T o = RawAccess&lt;&gt;::oop_load(p);
1236     if (!CompressedOops::is_null(o)) {
1237       oop obj = CompressedOops::decode_not_null(o);
<span class="line-modified">1238       if (_heap-&gt;is_concurrent_weak_root_in_progress() &amp;&amp; !_marking_context-&gt;is_marked(obj)) {</span>
1239         // There may be dead oops in weak roots in concurrent root phase, do not touch them.
1240         return;
1241       }
1242       obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);
1243 
1244       assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1245       if (!_bitmap-&gt;is_marked(obj)) {
1246         _bitmap-&gt;mark(obj);
1247         _oop_stack-&gt;push(obj);
1248       }
1249     }
1250   }
1251 public:
1252   ObjectIterateScanRootClosure(MarkBitMap* bitmap, Stack&lt;oop,mtGC&gt;* oop_stack) :
1253     _bitmap(bitmap), _oop_stack(oop_stack), _heap(ShenandoahHeap::heap()),
1254     _marking_context(_heap-&gt;marking_context()) {}
1255   void do_oop(oop* p)       { do_oop_work(p); }
1256   void do_oop(narrowOop* p) { do_oop_work(p); }
1257 };
1258 
</pre>
<hr />
<pre>
1360   }
1361 };
1362 
1363 void ShenandoahHeap::parallel_heap_region_iterate(ShenandoahHeapRegionClosure* blk) const {
1364   assert(blk-&gt;is_thread_safe(), &quot;Only thread-safe closures here&quot;);
1365   if (num_regions() &gt; ShenandoahParallelRegionStride) {
1366     ShenandoahParallelHeapRegionTask task(blk);
1367     workers()-&gt;run_task(&amp;task);
1368   } else {
1369     heap_region_iterate(blk);
1370   }
1371 }
1372 
1373 class ShenandoahInitMarkUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {
1374 private:
1375   ShenandoahMarkingContext* const _ctx;
1376 public:
1377   ShenandoahInitMarkUpdateRegionStateClosure() : _ctx(ShenandoahHeap::heap()-&gt;marking_context()) {}
1378 
1379   void heap_region_do(ShenandoahHeapRegion* r) {
<span class="line-added">1380     assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;index());</span>
1381     if (r-&gt;is_active()) {
<span class="line-modified">1382       // Check if region needs updating its TAMS. We have updated it already during concurrent</span>
<span class="line-modified">1383       // reset, so it is very likely we don&#39;t need to do another write here.</span>
<span class="line-added">1384       if (_ctx-&gt;top_at_mark_start(r) != r-&gt;top()) {</span>
<span class="line-added">1385         _ctx-&gt;capture_top_at_mark_start(r);</span>
<span class="line-added">1386       }</span>
1387     } else {

1388       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1389              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;index());
1390     }
1391   }
1392 
1393   bool is_thread_safe() { return true; }
1394 };
1395 
1396 void ShenandoahHeap::op_init_mark() {
1397   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1398   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1399 
1400   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1401   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);
1402   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);
1403 
1404   if (ShenandoahVerify) {
1405     verifier()-&gt;verify_before_concmark();
1406   }
1407 
</pre>
<hr />
<pre>
1616   ShenandoahEvacuationTask task(this, _collection_set, true);
1617   workers()-&gt;run_task(&amp;task);
1618 }
1619 
1620 void ShenandoahHeap::op_stw_evac() {
1621   ShenandoahEvacuationTask task(this, _collection_set, false);
1622   workers()-&gt;run_task(&amp;task);
1623 }
1624 
1625 void ShenandoahHeap::op_updaterefs() {
1626   update_heap_references(true);
1627 }
1628 
1629 void ShenandoahHeap::op_cleanup() {
1630   free_set()-&gt;recycle_trash();
1631 }
1632 
1633 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1634 private:
1635   ShenandoahVMRoots&lt;true /*concurrent*/&gt;        _vm_roots;

1636   ShenandoahClassLoaderDataRoots&lt;true /*concurrent*/, false /*single threaded*/&gt; _cld_roots;
1637   ShenandoahConcurrentStringDedupRoots          _dedup_roots;

1638 
1639 public:
<span class="line-modified">1640   ShenandoahConcurrentRootsEvacUpdateTask() :</span>
<span class="line-modified">1641     AbstractGangTask(&quot;Shenandoah Evacuate/Update Concurrent Strong Roots Task&quot;) {</span>

1642   }
1643 
1644   void work(uint worker_id) {
1645     ShenandoahEvacOOMScope oom;
1646     {
1647       // vm_roots and weak_roots are OopStorage backed roots, concurrent iteration
1648       // may race against OopStorage::release() calls.
1649       ShenandoahEvacUpdateOopStorageRootsClosure cl;
1650       _vm_roots.oops_do&lt;ShenandoahEvacUpdateOopStorageRootsClosure&gt;(&amp;cl);




1651     }
1652 
1653     {
1654       ShenandoahEvacuateUpdateRootsClosure&lt;&gt; cl;
1655       CLDToOopClosure clds(&amp;cl, ClassLoaderData::_claim_strong);
1656       _cld_roots.cld_do(&amp;clds);
1657     }
1658 
1659     {
1660       ShenandoahForwardedIsAliveClosure is_alive;
1661       ShenandoahEvacuateUpdateRootsClosure&lt;MO_RELEASE&gt; keep_alive;
1662       _dedup_roots.oops_do(&amp;is_alive, &amp;keep_alive, worker_id);
1663     }
1664   }
1665 };
1666 
1667 class ShenandoahEvacUpdateCleanupOopStorageRootsClosure : public BasicOopIterateClosure {
1668 private:
1669   ShenandoahHeap* const _heap;
1670   ShenandoahMarkingContext* const _mark_context;
</pre>
<hr />
<pre>
1749   }
1750 
1751   void work(uint worker_id) {
1752     ShenandoahEvacOOMScope oom;
1753     // jni_roots and weak_roots are OopStorage backed roots, concurrent iteration
1754     // may race against OopStorage::release() calls.
1755     ShenandoahEvacUpdateCleanupOopStorageRootsClosure cl;
1756     _jni_roots.oops_do(&amp;cl, worker_id);
1757     _vm_roots.oops_do(&amp;cl, worker_id);
1758 
1759     cl.reset_dead_counter();
1760     _string_table_roots.oops_do(&amp;cl, worker_id);
1761     StringTable::inc_dead_counter(cl.dead_counter());
1762 
1763     cl.reset_dead_counter();
1764     _resolved_method_table_roots.oops_do(&amp;cl, worker_id);
1765     ResolvedMethodTable::inc_dead_counter(cl.dead_counter());
1766   }
1767 };
1768 
<span class="line-modified">1769 void ShenandoahHeap::op_weak_roots() {</span>
<span class="line-modified">1770   if (is_concurrent_weak_root_in_progress()) {</span>
<span class="line-modified">1771     // Concurrent weak root processing</span>
<span class="line-modified">1772     ShenandoahConcurrentWeakRootsEvacUpdateTask task;</span>
<span class="line-modified">1773     workers()-&gt;run_task(&amp;task);</span>

1774 
<span class="line-added">1775     if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {</span>
1776       _unloader.unload();
1777     }
<span class="line-added">1778     set_concurrent_weak_root_in_progress(false);</span>
<span class="line-added">1779   }</span>
<span class="line-added">1780 }</span>
<span class="line-added">1781 </span>
<span class="line-added">1782 void ShenandoahHeap::op_strong_roots() {</span>
<span class="line-added">1783   assert(is_concurrent_strong_root_in_progress(), &quot;Checked by caller&quot;);</span>
<span class="line-added">1784   ShenandoahConcurrentRootsEvacUpdateTask task;</span>
<span class="line-added">1785   workers()-&gt;run_task(&amp;task);</span>
<span class="line-added">1786   set_concurrent_strong_root_in_progress(false);</span>
<span class="line-added">1787 }</span>
<span class="line-added">1788 </span>
<span class="line-added">1789 class ShenandoahResetUpdateRegionStateClosure : public ShenandoahHeapRegionClosure {</span>
<span class="line-added">1790 private:</span>
<span class="line-added">1791   ShenandoahMarkingContext* const _ctx;</span>
<span class="line-added">1792 public:</span>
<span class="line-added">1793   ShenandoahResetUpdateRegionStateClosure() : _ctx(ShenandoahHeap::heap()-&gt;marking_context()) {}</span>
1794 
<span class="line-modified">1795   void heap_region_do(ShenandoahHeapRegion* r) {</span>
<span class="line-modified">1796     if (r-&gt;is_active()) {</span>
<span class="line-modified">1797       // Reset live data and set TAMS optimistically. We would recheck these under the pause</span>
<span class="line-added">1798       // anyway to capture any updates that happened since now.</span>
<span class="line-added">1799       r-&gt;clear_live_data();</span>
<span class="line-added">1800       _ctx-&gt;capture_top_at_mark_start(r);</span>
1801     }
1802   }
1803 
<span class="line-modified">1804   bool is_thread_safe() { return true; }</span>
<span class="line-modified">1805 };</span>
1806 
1807 void ShenandoahHeap::op_reset() {
1808   if (ShenandoahPacing) {
1809     pacer()-&gt;setup_for_reset();
1810   }
1811   reset_mark_bitmap();
<span class="line-added">1812 </span>
<span class="line-added">1813   ShenandoahResetUpdateRegionStateClosure cl;</span>
<span class="line-added">1814   parallel_heap_region_iterate(&amp;cl);</span>
1815 }
1816 
1817 void ShenandoahHeap::op_preclean() {
1818   if (ShenandoahPacing) {
1819     pacer()-&gt;setup_for_preclean();
1820   }
1821   concurrent_mark()-&gt;preclean_weak_refs();
1822 }
1823 
1824 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1825   ShenandoahMetricsSnapshot metrics;
1826   metrics.snap_before();
1827 
1828   full_gc()-&gt;do_it(cause);
1829   if (UseTLAB) {
1830     ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::full_gc_resize_tlabs);
1831     resize_all_tlabs();
1832   }
1833 
1834   metrics.snap_after();
</pre>
<hr />
<pre>
2016 void ShenandoahHeap::set_gc_state_mask(uint mask, bool value) {
2017   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should really be Shenandoah safepoint&quot;);
2018   _gc_state.set_cond(mask, value);
2019   set_gc_state_all_threads(_gc_state.raw_value());
2020 }
2021 
2022 void ShenandoahHeap::set_concurrent_mark_in_progress(bool in_progress) {
2023   if (has_forwarded_objects()) {
2024     set_gc_state_mask(MARKING | UPDATEREFS, in_progress);
2025   } else {
2026     set_gc_state_mask(MARKING, in_progress);
2027   }
2028   ShenandoahBarrierSet::satb_mark_queue_set().set_active_all_threads(in_progress, !in_progress);
2029 }
2030 
2031 void ShenandoahHeap::set_evacuation_in_progress(bool in_progress) {
2032   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Only call this at safepoint&quot;);
2033   set_gc_state_mask(EVACUATION, in_progress);
2034 }
2035 
<span class="line-modified">2036 void ShenandoahHeap::set_concurrent_strong_root_in_progress(bool in_progress) {</span>
<span class="line-added">2037   assert(ShenandoahConcurrentRoots::can_do_concurrent_roots(), &quot;Why set the flag?&quot;);</span>
<span class="line-added">2038   if (in_progress) {</span>
<span class="line-added">2039     _concurrent_strong_root_in_progress.set();</span>
<span class="line-added">2040   } else {</span>
<span class="line-added">2041     _concurrent_strong_root_in_progress.unset();</span>
<span class="line-added">2042   }</span>
<span class="line-added">2043 }</span>
<span class="line-added">2044 </span>
<span class="line-added">2045 void ShenandoahHeap::set_concurrent_weak_root_in_progress(bool in_progress) {</span>
2046   assert(ShenandoahConcurrentRoots::can_do_concurrent_roots(), &quot;Why set the flag?&quot;);
2047   if (in_progress) {
<span class="line-modified">2048     _concurrent_weak_root_in_progress.set();</span>
2049   } else {
<span class="line-modified">2050     _concurrent_weak_root_in_progress.unset();</span>
2051   }
2052 }
2053 
2054 void ShenandoahHeap::ref_processing_init() {
2055   assert(_max_workers &gt; 0, &quot;Sanity&quot;);
2056 
<span class="line-added">2057   bool mt_processing = ParallelRefProcEnabled &amp;&amp; (ParallelGCThreads &gt; 1);</span>
<span class="line-added">2058   bool mt_discovery = _max_workers &gt; 1;</span>
<span class="line-added">2059 </span>
2060   _ref_processor =
2061     new ReferenceProcessor(&amp;_subject_to_discovery,  // is_subject_to_discovery
<span class="line-modified">2062                            mt_processing,           // MT processing</span>
2063                            _max_workers,            // Degree of MT processing
<span class="line-modified">2064                            mt_discovery,            // MT discovery</span>
2065                            _max_workers,            // Degree of MT discovery
2066                            false,                   // Reference discovery is not atomic
2067                            NULL,                    // No closure, should be installed before use
2068                            true);                   // Scale worker threads
2069 
<span class="line-added">2070   log_info(gc, init)(&quot;Reference processing: %s discovery, %s processing&quot;,</span>
<span class="line-added">2071           mt_discovery ? &quot;parallel&quot; : &quot;serial&quot;,</span>
<span class="line-added">2072           mt_processing ? &quot;parallel&quot; : &quot;serial&quot;);</span>
<span class="line-added">2073 </span>
2074   shenandoah_assert_rp_isalive_not_installed();
2075 }
2076 
2077 GCTracer* ShenandoahHeap::tracer() {
2078   return shenandoah_policy()-&gt;tracer();
2079 }
2080 
2081 size_t ShenandoahHeap::tlab_used(Thread* thread) const {
2082   return _free_set-&gt;used();
2083 }
2084 
2085 bool ShenandoahHeap::try_cancel_gc() {
2086   while (true) {
2087     jbyte prev = _cancelled_gc.cmpxchg(CANCELLED, CANCELLABLE);
2088     if (prev == CANCELLABLE) return true;
2089     else if (prev == CANCELLED) return false;
2090     assert(ShenandoahSuspendibleWorkers, &quot;should not get here when not using suspendible workers&quot;);
2091     assert(prev == NOT_CANCELLED, &quot;must be NOT_CANCELLED&quot;);
2092     if (Thread::current()-&gt;is_Java_thread()) {
2093       // We need to provide a safepoint here, otherwise we might
</pre>
<hr />
<pre>
2311   assert_pinned_region_status();
2312 }
2313 
2314 #ifdef ASSERT
2315 void ShenandoahHeap::assert_pinned_region_status() {
2316   for (size_t i = 0; i &lt; num_regions(); i++) {
2317     ShenandoahHeapRegion* r = get_region(i);
2318     assert((r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() &gt; 0) || (!r-&gt;is_pinned() &amp;&amp; r-&gt;pin_count() == 0),
2319            &quot;Region &quot; SIZE_FORMAT &quot; pinning status is inconsistent&quot;, i);
2320   }
2321 }
2322 #endif
2323 
2324 ConcurrentGCTimer* ShenandoahHeap::gc_timer() const {
2325   return _gc_timer;
2326 }
2327 
2328 void ShenandoahHeap::prepare_concurrent_roots() {
2329   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2330   if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
<span class="line-modified">2331     set_concurrent_strong_root_in_progress(!collection_set()-&gt;is_empty());</span>
<span class="line-added">2332     set_concurrent_weak_root_in_progress(true);</span>
2333   }
2334 }
2335 
2336 void ShenandoahHeap::prepare_concurrent_unloading() {
2337   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2338   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2339     _unloader.prepare();
2340   }
2341 }
2342 
2343 void ShenandoahHeap::finish_concurrent_unloading() {
2344   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2345   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2346     _unloader.finish();
2347   }
2348 }
2349 
2350 #ifdef ASSERT
2351 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2352   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
</pre>
<hr />
<pre>
2739   op_init_updaterefs();
2740 }
2741 
2742 void ShenandoahHeap::entry_final_updaterefs() {
2743   static const char* msg = &quot;Pause Final Update Refs&quot;;
2744   ShenandoahPausePhase gc_phase(msg);
2745   EventMark em(&quot;%s&quot;, msg);
2746 
2747   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2748   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);
2749 
2750   ShenandoahWorkerScope scope(workers(),
2751                               ShenandoahWorkerPolicy::calc_workers_for_final_update_ref(),
2752                               &quot;final reference update&quot;);
2753 
2754   op_final_updaterefs();
2755 }
2756 
2757 void ShenandoahHeap::entry_full(GCCause::Cause cause) {
2758   static const char* msg = &quot;Pause Full&quot;;
<span class="line-modified">2759   ShenandoahPausePhase gc_phase(msg, true /* log_heap_usage */);</span>
2760   EventMark em(&quot;%s&quot;, msg);
2761 
2762   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2763   ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc);
2764 
2765   ShenandoahWorkerScope scope(workers(),
2766                               ShenandoahWorkerPolicy::calc_workers_for_fullgc(),
2767                               &quot;full gc&quot;);
2768 
2769   op_full(cause);
2770 }
2771 
2772 void ShenandoahHeap::entry_degenerated(int point) {
2773   ShenandoahDegenPoint dpoint = (ShenandoahDegenPoint)point;
2774   const char* msg = degen_event_message(dpoint);
<span class="line-modified">2775   ShenandoahPausePhase gc_phase(msg, true /* log_heap_usage */);</span>
2776   EventMark em(&quot;%s&quot;, msg);
2777 
2778   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2779   ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc);
2780 
2781   ShenandoahWorkerScope scope(workers(),
2782                               ShenandoahWorkerPolicy::calc_workers_for_stw_degenerated(),
2783                               &quot;stw degenerated gc&quot;);
2784 
2785   set_degenerated_gc_in_progress(true);
2786   op_degenerated(dpoint);
2787   set_degenerated_gc_in_progress(false);
2788 }
2789 
2790 void ShenandoahHeap::entry_mark() {
2791   TraceCollectorStats tcs(monitoring_support()-&gt;concurrent_collection_counters());
2792 
2793   const char* msg = conc_mark_event_message();
2794   ShenandoahConcurrentPhase gc_phase(msg);
2795   EventMark em(&quot;%s&quot;, msg);
</pre>
<hr />
<pre>
2819 
2820   try_inject_alloc_failure();
2821   op_conc_evac();
2822 }
2823 
2824 void ShenandoahHeap::entry_updaterefs() {
2825   static const char* msg = &quot;Concurrent update references&quot;;
2826   ShenandoahConcurrentPhase gc_phase(msg);
2827   EventMark em(&quot;%s&quot;, msg);
2828 
2829   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_update_refs);
2830 
2831   ShenandoahWorkerScope scope(workers(),
2832                               ShenandoahWorkerPolicy::calc_workers_for_conc_update_ref(),
2833                               &quot;concurrent reference update&quot;);
2834 
2835   try_inject_alloc_failure();
2836   op_updaterefs();
2837 }
2838 
<span class="line-modified">2839 void ShenandoahHeap::entry_weak_roots() {</span>
<span class="line-modified">2840   static const char* msg = &quot;Concurrent weak roots&quot;;</span>
2841   ShenandoahConcurrentPhase gc_phase(msg);
2842   EventMark em(&quot;%s&quot;, msg);
2843 
<span class="line-modified">2844   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_weak_roots);</span>
2845 
2846   ShenandoahWorkerScope scope(workers(),
2847                               ShenandoahWorkerPolicy::calc_workers_for_conc_root_processing(),
<span class="line-modified">2848                               &quot;concurrent weak root&quot;);</span>
2849 
2850   try_inject_alloc_failure();
<span class="line-modified">2851   op_weak_roots();</span>
<span class="line-added">2852 }</span>
<span class="line-added">2853 </span>
<span class="line-added">2854 void ShenandoahHeap::entry_strong_roots() {</span>
<span class="line-added">2855   static const char* msg = &quot;Concurrent strong roots&quot;;</span>
<span class="line-added">2856   ShenandoahConcurrentPhase gc_phase(msg);</span>
<span class="line-added">2857   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-added">2858 </span>
<span class="line-added">2859   ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_strong_roots);</span>
<span class="line-added">2860 </span>
<span class="line-added">2861   ShenandoahWorkerScope scope(workers(),</span>
<span class="line-added">2862                               ShenandoahWorkerPolicy::calc_workers_for_conc_root_processing(),</span>
<span class="line-added">2863                               &quot;concurrent strong root&quot;);</span>
<span class="line-added">2864 </span>
<span class="line-added">2865   try_inject_alloc_failure();</span>
<span class="line-added">2866   op_strong_roots();</span>
2867 }
2868 
2869 void ShenandoahHeap::entry_cleanup() {
2870   static const char* msg = &quot;Concurrent cleanup&quot;;
2871   ShenandoahConcurrentPhase gc_phase(msg,  true /* log_heap_usage */);
2872   EventMark em(&quot;%s&quot;, msg);
2873 
2874   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_cleanup);
2875 
2876   // This phase does not use workers, no need for setup
2877 
2878   try_inject_alloc_failure();
2879   op_cleanup();
2880 }
2881 
2882 void ShenandoahHeap::entry_reset() {
2883   static const char* msg = &quot;Concurrent reset&quot;;
2884   ShenandoahConcurrentPhase gc_phase(msg);
2885   EventMark em(&quot;%s&quot;, msg);
2886 
</pre>
<hr />
<pre>
2897 void ShenandoahHeap::entry_preclean() {
2898   if (ShenandoahPreclean &amp;&amp; process_references()) {
2899     static const char* msg = &quot;Concurrent precleaning&quot;;
2900     ShenandoahConcurrentPhase gc_phase(msg);
2901     EventMark em(&quot;%s&quot;, msg);
2902 
2903     ShenandoahGCSubPhase conc_preclean(ShenandoahPhaseTimings::conc_preclean);
2904 
2905     ShenandoahWorkerScope scope(workers(),
2906                                 ShenandoahWorkerPolicy::calc_workers_for_conc_preclean(),
2907                                 &quot;concurrent preclean&quot;,
2908                                 /* check_workers = */ false);
2909 
2910     try_inject_alloc_failure();
2911     op_preclean();
2912   }
2913 }
2914 
2915 void ShenandoahHeap::entry_uncommit(double shrink_before) {
2916   static const char *msg = &quot;Concurrent uncommit&quot;;
<span class="line-modified">2917   ShenandoahConcurrentPhase gc_phase(msg, true /* log_heap_usage */);</span>
2918   EventMark em(&quot;%s&quot;, msg);
2919 
2920   ShenandoahGCSubPhase phase(ShenandoahPhaseTimings::conc_uncommit);
2921 
2922   op_uncommit(shrink_before);
2923 }
2924 
2925 void ShenandoahHeap::try_inject_alloc_failure() {
2926   if (ShenandoahAllocFailureALot &amp;&amp; !cancelled_gc() &amp;&amp; ((os::random() % 1000) &gt; 950)) {
2927     _inject_alloc_failure.set();
2928     os::naked_short_sleep(1);
2929     if (cancelled_gc()) {
2930       log_info(gc)(&quot;Allocation failure was successfully injected&quot;);
2931     }
2932   }
2933 }
2934 
2935 bool ShenandoahHeap::should_inject_alloc_failure() {
2936   return _inject_alloc_failure.is_set() &amp;&amp; _inject_alloc_failure.try_unset();
2937 }
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahFreeSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>