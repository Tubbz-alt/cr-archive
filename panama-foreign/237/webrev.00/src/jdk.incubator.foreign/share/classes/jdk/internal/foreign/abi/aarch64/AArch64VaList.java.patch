diff a/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/aarch64/AArch64VaList.java b/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/aarch64/AArch64VaList.java
--- a/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/aarch64/AArch64VaList.java
+++ b/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/aarch64/AArch64VaList.java
@@ -29,10 +29,11 @@
 import jdk.incubator.foreign.GroupLayout;
 import jdk.incubator.foreign.MemoryAddress;
 import jdk.incubator.foreign.MemoryHandles;
 import jdk.incubator.foreign.MemoryLayout;
 import jdk.incubator.foreign.MemorySegment;
+import jdk.incubator.foreign.NativeScope;
 import jdk.internal.foreign.NativeMemorySegmentImpl;
 import jdk.internal.foreign.Utils;
 import jdk.internal.foreign.abi.SharedUtils;
 import jdk.internal.misc.Unsafe;
 
@@ -104,27 +105,31 @@
     private static final Cleaner cleaner = Cleaner.create();
     private static final CSupport.VaList EMPTY
         = new SharedUtils.EmptyVaList(emptyListAddress());
 
     private final MemorySegment segment;
-    private final List<MemorySegment> slices = new ArrayList<>();
-    private final MemorySegment fpRegsArea;
     private final MemorySegment gpRegsArea;
+    private final MemorySegment fpRegsArea;
+    private final List<MemorySegment> slices;
 
-    AArch64VaList(MemorySegment segment) {
+    private AArch64VaList(MemorySegment segment, MemorySegment gpRegsArea, MemorySegment fpRegsArea,
+                          List<MemorySegment>  slices) {
         this.segment = segment;
+        this.gpRegsArea = gpRegsArea;
+        this.fpRegsArea = fpRegsArea;
+        this.slices = slices;
+    }
 
-        gpRegsArea = MemorySegment.ofNativeRestricted(
-            grTop().addOffset(-MAX_GP_OFFSET), MAX_GP_OFFSET,
+    private static AArch64VaList readFromSegment(MemorySegment segment) {
+        MemorySegment gpRegsArea = MemorySegment.ofNativeRestricted(
+            grTop(segment).addOffset(-MAX_GP_OFFSET), MAX_GP_OFFSET,
             segment.ownerThread(), null, null);
 
-        fpRegsArea = MemorySegment.ofNativeRestricted(
-            vrTop().addOffset(-MAX_FP_OFFSET), MAX_FP_OFFSET,
+        MemorySegment fpRegsArea = MemorySegment.ofNativeRestricted(
+            vrTop(segment).addOffset(-MAX_FP_OFFSET), MAX_FP_OFFSET,
             segment.ownerThread(), null, null);
-
-        slices.add(gpRegsArea);
-        slices.add(fpRegsArea);
+        return new AArch64VaList(segment, gpRegsArea, fpRegsArea, List.of(gpRegsArea, fpRegsArea));
     }
 
     private static MemoryAddress emptyListAddress() {
         long ptr = U.allocateMemory(LAYOUT.byteSize());
         MemorySegment ms = NativeMemorySegmentImpl.makeNativeSegmentUnchecked(
@@ -143,14 +148,22 @@
     public static CSupport.VaList empty() {
         return EMPTY;
     }
 
     private MemoryAddress grTop() {
+        return grTop(segment);
+    }
+
+    private static MemoryAddress grTop(MemorySegment segment) {
         return (MemoryAddress) VH_gr_top.get(segment.baseAddress());
     }
 
     private MemoryAddress vrTop() {
+        return vrTop(segment);
+    }
+
+    private static MemoryAddress vrTop(MemorySegment segment) {
         return (MemoryAddress) VH_vr_top.get(segment.baseAddress());
     }
 
     private int grOffs() {
         final int offs = (int) VH_gr_offs.get(segment.baseAddress());
@@ -231,22 +244,31 @@
     @Override
     public MemorySegment vargAsSegment(MemoryLayout layout) {
         return (MemorySegment) read(MemorySegment.class, layout);
     }
 
+    @Override
+    public MemorySegment vargAsSegment(MemoryLayout layout, NativeScope scope) {
+        return (MemorySegment) read(MemorySegment.class, layout, SharedUtils.Allocator.ofScope(scope));
+    }
+
     private Object read(Class<?> carrier, MemoryLayout layout) {
+        return read(carrier, layout, MemorySegment::allocateNative);
+    }
+
+    private Object read(Class<?> carrier, MemoryLayout layout, SharedUtils.Allocator allocator) {
         checkCompatibleType(carrier, layout, AArch64Linker.ADDRESS_SIZE);
 
         TypeClass typeClass = TypeClass.classifyLayout(layout);
         if (isRegOverflow(currentGPOffset(), currentFPOffset(), typeClass, layout)) {
             preAlignStack(layout);
             return switch (typeClass) {
                 case STRUCT_REGISTER, STRUCT_HFA, STRUCT_REFERENCE -> {
                     try (MemorySegment slice = MemorySegment.ofNativeRestricted(
                              stackPtr(), layout.byteSize(),
                              segment.ownerThread(), null, null)) {
-                        MemorySegment seg = MemorySegment.allocateNative(layout);
+                        MemorySegment seg = allocator.allocate(layout);
                         seg.copyFrom(slice);
                         postAlignStack(layout);
                         yield seg;
                     }
                 }
@@ -263,11 +285,11 @@
             };
         } else {
             return switch (typeClass) {
                 case STRUCT_REGISTER -> {
                     // Struct is passed packed in integer registers.
-                    MemorySegment value = MemorySegment.allocateNative(layout);
+                    MemorySegment value = allocator.allocate(layout);
                     long offset = 0;
                     while (offset < layout.byteSize()) {
                         final long copy = Math.min(layout.byteSize() - offset, 8);
                         MemorySegment slice = value.asSlice(offset, copy);
                         slice.copyFrom(gpRegsArea.asSlice(currentGPOffset(), copy));
@@ -277,11 +299,11 @@
                     yield value;
                 }
                 case STRUCT_HFA -> {
                     // Struct is passed with each element in a separate floating
                     // point register.
-                    MemorySegment value = MemorySegment.allocateNative(layout);
+                    MemorySegment value = allocator.allocate(layout);
                     GroupLayout group = (GroupLayout)layout;
                     long offset = 0;
                     for (MemoryLayout elem : group.memberLayouts()) {
                         assert elem.byteSize() <= 8;
                         final long copy = elem.byteSize();
@@ -300,11 +322,11 @@
                         gpRegsArea.baseAddress().addOffset(currentGPOffset()));
                     consumeGPSlots(1);
 
                     try (MemorySegment slice = MemorySegment.ofNativeRestricted(
                              ptr, layout.byteSize(), segment.ownerThread(), null, null)) {
-                        MemorySegment seg = MemorySegment.allocateNative(layout);
+                        MemorySegment seg = allocator.allocate(layout);
                         seg.copyFrom(slice);
                         yield seg;
                     }
                 }
                 case POINTER, INTEGER -> {
@@ -338,17 +360,16 @@
                 consumeGPSlots(numSlots(layout));
             }
         }
     }
 
-    static AArch64VaList.Builder builder() {
-        return new AArch64VaList.Builder();
+    static AArch64VaList.Builder builder(SharedUtils.Allocator allocator) {
+        return new AArch64VaList.Builder(allocator);
     }
 
     public static VaList ofAddress(MemoryAddress ma) {
-        return new AArch64VaList(
-            MemorySegment.ofNativeRestricted(
+        return readFromSegment(MemorySegment.ofNativeRestricted(
                 ma, LAYOUT.byteSize(), Thread.currentThread(), null, null));
     }
 
     @Override
     public boolean isAlive() {
@@ -361,13 +382,22 @@
         slices.forEach(MemorySegment::close);
     }
 
     @Override
     public VaList copy() {
-        MemorySegment copy = MemorySegment.allocateNative(LAYOUT.byteSize());
+        return copy(MemorySegment::allocateNative);
+    }
+
+    @Override
+    public VaList copy(NativeScope scope) {
+        return copy(SharedUtils.Allocator.ofScope(scope));
+    }
+
+    private VaList copy(SharedUtils.Allocator allocator) {
+        MemorySegment copy = allocator.allocate(LAYOUT);
         copy.copyFrom(segment);
-        return new AArch64VaList(copy);
+        return readFromSegment(copy);
     }
 
     @Override
     public MemoryAddress address() {
         return segment.baseAddress();
@@ -398,19 +428,24 @@
             + ", __vr_offs=" + vrOffs()
             + '}';
     }
 
     static class Builder implements CSupport.VaList.Builder {
-        private final MemorySegment gpRegs
-            = MemorySegment.allocateNative(LAYOUT_GP_REGS);
-        private final MemorySegment fpRegs
-            = MemorySegment.allocateNative(LAYOUT_FP_REGS);
+        private final SharedUtils.Allocator allocator;
+        private final MemorySegment gpRegs;
+        private final MemorySegment fpRegs;
 
         private long currentGPOffset = 0;
         private long currentFPOffset = 0;
         private final List<SimpleVaArg> stackArgs = new ArrayList<>();
 
+        Builder(SharedUtils.Allocator allocator) {
+            this.allocator = allocator;
+            this.gpRegs = allocator.allocate(LAYOUT_GP_REGS);
+            this.fpRegs = allocator.allocate(LAYOUT_FP_REGS);
+        }
+
         @Override
         public Builder vargFromInt(MemoryLayout layout, int value) {
             return arg(int.class, layout, value);
         }
 
@@ -501,40 +536,39 @@
         public VaList build() {
             if (isEmpty()) {
                 return EMPTY;
             }
 
-            MemorySegment vaListSegment = MemorySegment.allocateNative(LAYOUT.byteSize());
-            AArch64VaList res = new AArch64VaList(vaListSegment);
-
+            MemorySegment vaListSegment = allocator.allocate(LAYOUT);
+            List<MemorySegment> slices = new ArrayList<>();
             MemoryAddress stackArgsPtr = MemoryAddress.NULL;
             if (!stackArgs.isEmpty()) {
                 long stackArgsSize = stackArgs.stream()
                     .reduce(0L, (acc, e) -> acc + Utils.alignUp(e.layout.byteSize(), 8), Long::sum);
-                MemorySegment stackArgsSegment = MemorySegment.allocateNative(stackArgsSize, 16);
+                MemorySegment stackArgsSegment = allocator.allocate(stackArgsSize, 16);
                 MemoryAddress maStackArea = stackArgsSegment.baseAddress();
                 for (SimpleVaArg arg : stackArgs) {
                     final long alignedSize = Utils.alignUp(arg.layout.byteSize(), 8);
                     maStackArea = Utils.alignUp(maStackArea, alignedSize);
                     VarHandle writer = arg.varHandle();
                     writer.set(maStackArea, arg.value);
                     maStackArea = maStackArea.addOffset(alignedSize);
                 }
                 stackArgsPtr = stackArgsSegment.baseAddress();
-                res.slices.add(stackArgsSegment);
+                slices.add(stackArgsSegment);
             }
 
             MemoryAddress vaListAddr = vaListSegment.baseAddress();
             VH_gr_top.set(vaListAddr, gpRegs.baseAddress().addOffset(gpRegs.byteSize()));
             VH_vr_top.set(vaListAddr, fpRegs.baseAddress().addOffset(fpRegs.byteSize()));
             VH_stack.set(vaListAddr, stackArgsPtr);
             VH_gr_offs.set(vaListAddr, -MAX_GP_OFFSET);
             VH_vr_offs.set(vaListAddr, -MAX_FP_OFFSET);
 
-            res.slices.add(gpRegs);
-            res.slices.add(fpRegs);
+            slices.add(gpRegs);
+            slices.add(fpRegs);
             assert gpRegs.ownerThread() == vaListSegment.ownerThread();
             assert fpRegs.ownerThread() == vaListSegment.ownerThread();
-            return res;
+            return new AArch64VaList(vaListSegment, gpRegs, fpRegs, slices);
         }
     }
 }
