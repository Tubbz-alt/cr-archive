diff a/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/x64/sysv/SysVVaList.java b/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/x64/sysv/SysVVaList.java
--- a/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/x64/sysv/SysVVaList.java
+++ b/src/jdk.incubator.foreign/share/classes/jdk/internal/foreign/abi/x64/sysv/SysVVaList.java
@@ -29,10 +29,11 @@
 import jdk.incubator.foreign.GroupLayout;
 import jdk.incubator.foreign.MemoryAddress;
 import jdk.incubator.foreign.MemoryHandles;
 import jdk.incubator.foreign.MemoryLayout;
 import jdk.incubator.foreign.MemorySegment;
+import jdk.incubator.foreign.NativeScope;
 import jdk.internal.foreign.NativeMemorySegmentImpl;
 import jdk.internal.foreign.Utils;
 import jdk.internal.foreign.abi.SharedUtils;
 import jdk.internal.misc.Unsafe;
 
@@ -118,17 +119,22 @@
 
     private static final Cleaner cleaner = Cleaner.create();
     private static final CSupport.VaList EMPTY = new SharedUtils.EmptyVaList(emptyListAddress());
 
     private final MemorySegment segment;
-    private final List<MemorySegment> slices = new ArrayList<>();
     private final MemorySegment regSaveArea;
+    private final List<MemorySegment> attachedSegments;
 
-    SysVVaList(MemorySegment segment) {
+    private SysVVaList(MemorySegment segment, MemorySegment regSaveArea, List<MemorySegment> attachedSegments) {
         this.segment = segment;
-        regSaveArea = regSaveArea();
-        slices.add(regSaveArea);
+        this.regSaveArea = regSaveArea;
+        this.attachedSegments = attachedSegments;
+    }
+
+    private static SysVVaList readFromSegment(MemorySegment segment) {
+        MemorySegment regSaveArea = getRegSaveArea(segment);
+        return new SysVVaList(segment, regSaveArea, List.of(regSaveArea));
     }
 
     private static MemoryAddress emptyListAddress() {
         long ptr = U.allocateMemory(LAYOUT.byteSize());
         MemorySegment ms = NativeMemorySegmentImpl.makeNativeSegmentUnchecked(
@@ -169,10 +175,14 @@
     private void stackPtr(MemoryAddress ptr) {
         VH_overflow_arg_area.set(segment.baseAddress(), ptr);
     }
 
     private MemorySegment regSaveArea() {
+        return getRegSaveArea(segment);
+    }
+
+    private static MemorySegment getRegSaveArea(MemorySegment segment) {
         return MemorySegment.ofNativeRestricted((MemoryAddress) VH_reg_save_area.get(segment.baseAddress()),
             LAYOUT_REG_SAVE_AREA.byteSize(), segment.ownerThread(), null, null);
     }
 
     private void preAlignStack(MemoryLayout layout) {
@@ -208,21 +218,30 @@
     @Override
     public MemorySegment vargAsSegment(MemoryLayout layout) {
         return (MemorySegment) read(MemorySegment.class, layout);
     }
 
+    @Override
+    public MemorySegment vargAsSegment(MemoryLayout layout, NativeScope scope) {
+        return (MemorySegment) read(MemorySegment.class, layout, SharedUtils.Allocator.ofScope(scope));
+    }
+
     private Object read(Class<?> carrier, MemoryLayout layout) {
+        return read(carrier, layout, MemorySegment::allocateNative);
+    }
+
+    private Object read(Class<?> carrier, MemoryLayout layout, SharedUtils.Allocator allocator) {
         checkCompatibleType(carrier, layout, SysVx64Linker.ADDRESS_SIZE);
         TypeClass typeClass = TypeClass.classifyLayout(layout);
         if (isRegOverflow(currentGPOffset(), currentFPOffset(), typeClass)
                 || typeClass.inMemory()) {
             preAlignStack(layout);
             return switch (typeClass.kind()) {
                 case STRUCT -> {
                     try (MemorySegment slice = MemorySegment.ofNativeRestricted(stackPtr(), layout.byteSize(),
                                                                                 segment.ownerThread(), null, null)) {
-                        MemorySegment seg = MemorySegment.allocateNative(layout);
+                        MemorySegment seg = allocator.allocate(layout);
                         seg.copyFrom(slice);
                         postAlignStack(layout);
                         yield seg;
                     }
                 }
@@ -237,11 +256,11 @@
                 }
             };
         } else {
             return switch (typeClass.kind()) {
                 case STRUCT -> {
-                    MemorySegment value = MemorySegment.allocateNative(layout);
+                    MemorySegment value = allocator.allocate(layout);
                     int classIdx = 0;
                     long offset = 0;
                     while (offset < layout.byteSize()) {
                         final long copy = Math.min(layout.byteSize() - offset, 8);
                         boolean isSSE = typeClass.classes.get(classIdx++) == ArgumentClassImpl.SSE;
@@ -285,34 +304,45 @@
                 currentFPOffset(currentFPOffset() + (((int) typeClass.nVectorRegs()) * FP_SLOT_SIZE));
             }
         }
     }
 
-    static SysVVaList.Builder builder() {
-        return new SysVVaList.Builder();
+    static SysVVaList.Builder builder(SharedUtils.Allocator allocator) {
+        return new SysVVaList.Builder(allocator);
     }
 
     public static VaList ofAddress(MemoryAddress ma) {
-        return new SysVVaList(MemorySegment.ofNativeRestricted(ma, LAYOUT.byteSize(), Thread.currentThread(), null, null));
+        MemorySegment vaListSegment
+            = MemorySegment.ofNativeRestricted(ma, LAYOUT.byteSize(), Thread.currentThread(), null, null);
+        return readFromSegment(vaListSegment);
     }
 
     @Override
     public boolean isAlive() {
         return segment.isAlive();
     }
 
     @Override
     public void close() {
         segment.close();
-        slices.forEach(MemorySegment::close);
+        attachedSegments.forEach(MemorySegment::close);
     }
 
     @Override
     public VaList copy() {
-        MemorySegment copy = MemorySegment.allocateNative(LAYOUT.byteSize());
+        return copy(MemorySegment::allocateNative);
+    }
+
+    @Override
+    public VaList copy(NativeScope scope) {
+        return copy(SharedUtils.Allocator.ofScope(scope));
+    }
+
+    private VaList copy(SharedUtils.Allocator allocator) {
+        MemorySegment copy = allocator.allocate(LAYOUT);
         copy.copyFrom(segment);
-        return new SysVVaList(copy);
+        return new SysVVaList(copy, regSaveArea, List.of());
     }
 
     @Override
     public MemoryAddress address() {
         return segment.baseAddress();
@@ -332,15 +362,21 @@
                + ", reg_save_area=" + regSaveArea()
                + '}';
     }
 
     static class Builder implements CSupport.VaList.Builder {
-        private final MemorySegment reg_save_area = MemorySegment.allocateNative(LAYOUT_REG_SAVE_AREA);
+        private final SharedUtils.Allocator allocator;
+        private final MemorySegment reg_save_area;
         private long currentGPOffset = 0;
         private long currentFPOffset = FP_OFFSET;
         private final List<SimpleVaArg> stackArgs = new ArrayList<>();
 
+        public Builder(SharedUtils.Allocator allocator) {
+            this.allocator = allocator;
+            this.reg_save_area = allocator.allocate(LAYOUT_REG_SAVE_AREA);
+        }
+
         @Override
         public Builder vargFromInt(MemoryLayout layout, int value) {
             return arg(int.class, layout, value);
         }
 
@@ -413,16 +449,16 @@
         public VaList build() {
             if (isEmpty()) {
                 return EMPTY;
             }
 
-            MemorySegment vaListSegment = MemorySegment.allocateNative(LAYOUT.byteSize());
-            SysVVaList res = new SysVVaList(vaListSegment);
+            MemorySegment vaListSegment = allocator.allocate(LAYOUT);
+            List<MemorySegment> attachedSegments = new ArrayList<>();
             MemoryAddress stackArgsPtr = MemoryAddress.NULL;
             if (!stackArgs.isEmpty()) {
                 long stackArgsSize = stackArgs.stream().reduce(0L, (acc, e) -> acc + e.layout.byteSize(), Long::sum);
-                MemorySegment stackArgsSegment = MemorySegment.allocateNative(stackArgsSize, 16);
+                MemorySegment stackArgsSegment = allocator.allocate(stackArgsSize, 16);
                 MemoryAddress maOverflowArgArea = stackArgsSegment.baseAddress();
                 for (SimpleVaArg arg : stackArgs) {
                     if (arg.layout.byteSize() > 8) {
                         maOverflowArgArea = Utils.alignUp(maOverflowArgArea, Math.min(16, arg.layout.byteSize()));
                     }
@@ -435,18 +471,18 @@
                         writer.set(maOverflowArgArea, arg.value);
                     }
                     maOverflowArgArea = maOverflowArgArea.addOffset(arg.layout.byteSize());
                 }
                 stackArgsPtr = stackArgsSegment.baseAddress();
-                res.slices.add(stackArgsSegment);
+                attachedSegments.add(stackArgsSegment);
             }
 
             MemoryAddress vaListAddr = vaListSegment.baseAddress();
             VH_fp_offset.set(vaListAddr, (int) FP_OFFSET);
             VH_overflow_arg_area.set(vaListAddr, stackArgsPtr);
             VH_reg_save_area.set(vaListAddr, reg_save_area.baseAddress());
-            res.slices.add(reg_save_area);
+            attachedSegments.add(reg_save_area);
             assert reg_save_area.ownerThread() == vaListSegment.ownerThread();
-            return res;
+            return new SysVVaList(vaListSegment, reg_save_area, attachedSegments);
         }
     }
 }
