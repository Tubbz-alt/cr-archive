<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/x86/universalNativeInvoker_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;asm/macroAssembler.hpp&quot;
 26 #include &quot;classfile/javaClasses.inline.hpp&quot;
 27 #include &quot;interpreter/interpreter.hpp&quot;
 28 #include &quot;interpreter/interpreterRuntime.hpp&quot;
 29 #include &quot;memory/allocation.inline.hpp&quot;
 30 #include &quot;memory/resourceArea.hpp&quot;
 31 #include &quot;include/jvm.h&quot;
 32 #include &quot;prims/universalNativeInvoker.hpp&quot;
 33 #include &quot;runtime/javaCalls.hpp&quot;
 34 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 35 #include &quot;logging/log.hpp&quot;
 36 #include &quot;logging/logStream.hpp&quot;
 37 #include &quot;oops/arrayOop.inline.hpp&quot;
 38 #include &quot;runtime/jniHandles.inline.hpp&quot;
 39 #include &quot;prims/methodHandles.hpp&quot;
 40 
 41 void generate_invoke_native(MacroAssembler* _masm, const ABIDescriptor&amp; abi, const BufferLayout&amp; layout) {
 42 
 43 #if 0
 44   fprintf(stderr, &quot;generate_invoke_native()\n&quot;);
 45 #endif
 46 
 47   /**
 48    * invoke_native_stub(struct ShuffleDowncallContext* ctxt) {
 49    *   rbx = ctxt;
 50    *
 51    *   stack = alloca(ctxt-&gt;arguments.stack_args_bytes);
 52    *
 53    *   load_all_registers();
 54    *   memcpy(stack, ctxt-&gt;arguments.stack_args, arguments.stack_args_bytes);
 55    *
 56    *   (*ctxt-&gt;arguments.next_pc)();
 57    *
 58    *   store_all_registers();
 59    * }
 60    */
 61 
 62   __ enter();
 63 
 64   // Put the context pointer in ebx/rbx - it&#39;s going to be heavily used below both before and after the call
 65   Register ctxt_reg = rbx;
 66   Register used_regs[] = { ctxt_reg, rcx, rsi, rdi };
 67   GrowableArray&lt;Register&gt; preserved_regs;
 68 
 69   for (size_t i = 0; i &lt; sizeof(used_regs)/sizeof(Register); i++) {
 70     Register used_reg = used_regs[i];
 71     if (!abi.is_volatile_reg(used_reg)) {
 72       preserved_regs.push(used_reg);
 73     }
 74   }
 75 
 76   __ block_comment(&quot;init_and_alloc_stack&quot;);
 77 
 78   for (int i = 0; i &lt; preserved_regs.length(); i++) {
 79     __ push(preserved_regs.at(i));
 80   }
 81 
 82   __ movptr(ctxt_reg, c_rarg0); // FIXME c args? or java?
 83 
 84   __ block_comment(&quot;allocate_stack&quot;);
 85   __ movptr(rcx, Address(ctxt_reg, (int) layout.stack_args_bytes));
 86   __ subptr(rsp, rcx);
 87   __ andptr(rsp, -abi._stack_alignment_bytes);
 88 
 89   // Note: rcx is used below!
 90 
 91 
 92   __ block_comment(&quot;load_arguments&quot;);
 93 
 94   __ shrptr(rcx, LogBytesPerWord); // bytes -&gt; words
 95   __ movptr(rsi, Address(ctxt_reg, (int) layout.stack_args));
 96   __ movptr(rdi, rsp);
 97   __ rep_mov();
 98 
 99 
100   for (int i = 0; i &lt; abi._vector_argument_registers.length(); i++) {
101     // [1] -&gt; 64 bit -&gt; xmm
102     // [2] -&gt; 128 bit -&gt; xmm
103     // [4] -&gt; 256 bit -&gt; ymm
104     // [8] -&gt; 512 bit -&gt; zmm
105 
106     XMMRegister reg = abi._vector_argument_registers.at(i);
107     size_t offs = layout.arguments_vector + i * sizeof(VectorRegister);
108     if (UseAVX &gt;= 3) {
109       __ evmovdqul(reg, Address(ctxt_reg, (int)offs), Assembler::AVX_512bit);
110     } else if (UseAVX &gt;= 1) {
111       __ vmovdqu(reg, Address(ctxt_reg, (int)offs));
112     } else {
113       __ movdqu(reg, Address(ctxt_reg, (int)offs));
114     }
115   }
116 
117   for (int i = 0; i &lt; abi._integer_argument_registers.length(); i++) {
118     size_t offs = layout.arguments_integer + i * sizeof(uintptr_t);
119     __ movptr(abi._integer_argument_registers.at(i), Address(ctxt_reg, (int)offs));
120   }
121 
122   if (abi._shadow_space_bytes != 0) {
123     __ block_comment(&quot;allocate shadow space for argument register spill&quot;);
124     __ subptr(rsp, abi._shadow_space_bytes);
125   }
126 
127   // call target function
128   __ block_comment(&quot;call target function&quot;);
129   __ call(Address(ctxt_reg, (int) layout.arguments_next_pc));
130 
131   if (abi._shadow_space_bytes != 0) {
132     __ block_comment(&quot;pop shadow space&quot;);
133     __ addptr(rsp, abi._shadow_space_bytes);
134   }
135 
136   __ block_comment(&quot;store_registers&quot;);
137   for (int i = 0; i &lt; abi._integer_return_registers.length(); i++) {
138     ssize_t offs = layout.returns_integer + i * sizeof(uintptr_t);
139     __ movptr(Address(ctxt_reg, offs), abi._integer_return_registers.at(i));
140   }
141 
142   for (int i = 0; i &lt; abi._vector_return_registers.length(); i++) {
143     // [1] -&gt; 64 bit -&gt; xmm
144     // [2] -&gt; 128 bit -&gt; xmm (SSE)
145     // [4] -&gt; 256 bit -&gt; ymm (AVX)
146     // [8] -&gt; 512 bit -&gt; zmm (AVX-512, aka AVX3)
147 
148     XMMRegister reg = abi._vector_return_registers.at(i);
149     size_t offs = layout.returns_vector + i * sizeof(VectorRegister);
150     if (UseAVX &gt;= 3) {
151       __ evmovdqul(Address(ctxt_reg, (int)offs), reg, Assembler::AVX_512bit);
152     } else if (UseAVX &gt;= 1) {
153       __ vmovdqu(Address(ctxt_reg, (int)offs), reg);
154     } else {
155       __ movdqu(Address(ctxt_reg, (int)offs), reg);
156     }
157   }
158 
159   for (size_t i = 0; i &lt; abi._X87_return_registers_noof; i++) {
160     size_t offs = layout.returns_x87 + i * (sizeof(long double));
161     __ fstp_x(Address(ctxt_reg, (int)offs)); //pop ST(0)
162   }
163 
164   // Restore backed up preserved register
165   for (int i = 0; i &lt; preserved_regs.length(); i++) {
166     __ movptr(preserved_regs.at(i), Address(rbp, -(int)(sizeof(uintptr_t) * (i + 1))));
167   }
168 
169   __ leave();
170   __ ret(0);
171 
172   __ flush();
173 }
174 
175 class ProgrammableInvokerGenerator : public StubCodeGenerator {
176 private:
177   const ABIDescriptor* _abi;
178   const BufferLayout* _layout;
179 public:
180   ProgrammableInvokerGenerator(CodeBuffer* code, const ABIDescriptor* abi, const BufferLayout* layout)
181    : StubCodeGenerator(code, PrintMethodHandleStubs), _abi(abi), _layout(layout) {}
182 
183   void generate() {
184       generate_invoke_native(_masm, *_abi, *_layout);
185   }
186 };
187 
188 jlong ProgrammableInvoker::generate_adapter(JNIEnv* env, jobject jabi, jobject jlayout) {
189     ResourceMark rm;
190     const ABIDescriptor abi = parseABIDescriptor(env, jabi);
191     const BufferLayout layout = parseBufferLayout(env, jlayout);
192 
193     BufferBlob* _invoke_native_blob = BufferBlob::create(&quot;invoke_native_blob&quot;, MethodHandles::adapter_code_size);
194 
195     CodeBuffer code2(_invoke_native_blob);
196     ProgrammableInvokerGenerator g2(&amp;code2, &amp;abi, &amp;layout);
197     g2.generate();
198     code2.log_section_sizes(&quot;InvokeNativeBlob&quot;);
199 
200     return (jlong) _invoke_native_blob-&gt;code_begin();
201 }
    </pre>
  </body>
</html>