<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1DirtyCardQueue.hpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1DirtyCardQueue.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1GCPhaseTimes.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1DirtyCardQueue.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
 26 #define SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
 27 
 28 #include &quot;gc/g1/g1BufferNodeList.hpp&quot;
 29 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;

 30 #include &quot;gc/shared/ptrQueue.hpp&quot;
 31 #include &quot;memory/allocation.hpp&quot;
 32 #include &quot;memory/padded.hpp&quot;
 33 
 34 class G1ConcurrentRefineThread;
 35 class G1DirtyCardQueueSet;
 36 class G1RedirtyCardsQueueSet;
 37 class Thread;
 38 
 39 // A ptrQueue whose elements are &quot;oops&quot;, pointers to object heads.
 40 class G1DirtyCardQueue: public PtrQueue {


 41 protected:
 42   virtual void handle_completed_buffer();
 43 
 44 public:
 45   G1DirtyCardQueue(G1DirtyCardQueueSet* qset);
 46 
 47   // Flush before destroying; queue may be used to capture pending work while
 48   // doing something else, with auto-flush on completion.
 49   ~G1DirtyCardQueue();
 50 
 51   // Process queue entries and release resources.
<span class="line-modified"> 52   void flush() { flush_impl(); }</span>
 53 
 54   inline G1DirtyCardQueueSet* dirty_card_qset() const;
 55 








 56   // Compiler support.
 57   static ByteSize byte_offset_of_index() {
 58     return PtrQueue::byte_offset_of_index&lt;G1DirtyCardQueue&gt;();
 59   }
 60   using PtrQueue::byte_width_of_index;
 61 
 62   static ByteSize byte_offset_of_buf() {
 63     return PtrQueue::byte_offset_of_buf&lt;G1DirtyCardQueue&gt;();
 64   }
 65   using PtrQueue::byte_width_of_buf;
 66 
 67 };
 68 
 69 class G1DirtyCardQueueSet: public PtrQueueSet {
 70   // Head and tail of a list of BufferNodes, linked through their next()
 71   // fields.  Similar to G1BufferNodeList, but without the _entry_count.
 72   struct HeadTail {
 73     BufferNode* _head;
 74     BufferNode* _tail;
 75     HeadTail() : _head(NULL), _tail(NULL) {}
</pre>
<hr />
<pre>
198   DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(G1ConcurrentRefineThread*));
199   // Upper bound on the number of cards in the completed and paused buffers.
200   volatile size_t _num_cards;
201   DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(size_t));
202   // Buffers ready for refinement.
203   Queue _completed;           // Has inner padding, including trailer.
204   // Buffers for which refinement is temporarily paused.
205   PausedBuffers _paused;      // Has inner padding, including trailer.
206 
207   G1FreeIdSet _free_ids;
208 
209   // Activation threshold for the primary refinement thread.
210   size_t _process_cards_threshold;
211 
212   // If the queue contains more cards than configured here, the
213   // mutator must start doing some of the concurrent refinement work.
214   size_t _max_cards;
215   volatile size_t _padded_max_cards;
216   static const size_t MaxCardsUnlimited = SIZE_MAX;
217 
<span class="line-modified">218   // Array of cumulative dirty cards refined by mutator threads.</span>
<span class="line-removed">219   // Array has an entry per id in _free_ids.</span>
<span class="line-removed">220   size_t* _mutator_refined_cards_counters;</span>
221 
222   // Verify _num_cards == sum of cards in the completed queue.
223   void verify_num_cards() const NOT_DEBUG_RETURN;
224 
225   // Thread-safe add a buffer to paused list for next safepoint.
226   // precondition: not at safepoint.
227   void record_paused_buffer(BufferNode* node);
228   void enqueue_paused_buffers_aux(const HeadTail&amp; paused);
229   // Thread-safe transfer paused buffers for previous safepoints to the queue.
230   // precondition: not at safepoint.
231   void enqueue_previous_paused_buffers();
232   // Transfer all paused buffers to the queue.
233   // precondition: at safepoint.
234   void enqueue_all_paused_buffers();
235 
236   void abandon_completed_buffers();
237 
238   // Refine the cards in &quot;node&quot; from its index to buffer_size.
239   // Stops processing if SuspendibleThreadSet::should_yield() is true.
240   // Returns true if the entire buffer was processed, false if there
241   // is a pending yield request.  The node&#39;s index is updated to exclude
242   // the processed elements, e.g. up to the element before processing
243   // stopped, or one past the last element if the entire buffer was
<span class="line-modified">244   // processed. Increments *total_refined_cards by the number of cards</span>
<span class="line-modified">245   // processed and removed from the buffer.</span>
<span class="line-modified">246   bool refine_buffer(BufferNode* node, uint worker_id, size_t* total_refined_cards);</span>

247 
248   // Deal with buffer after a call to refine_buffer.  If fully processed,
249   // deallocate the buffer.  Otherwise, record it as paused.
250   void handle_refined_buffer(BufferNode* node, bool fully_processed);
251 
252   // Remove and return a completed buffer from the list, or return NULL
253   // if none available.
254   BufferNode* get_completed_buffer();
255 
256 public:
257   G1DirtyCardQueueSet(BufferNode::Allocator* allocator);
258   ~G1DirtyCardQueueSet();
259 
260   void set_primary_refinement_thread(G1ConcurrentRefineThread* thread) {
261     _primary_refinement_thread = thread;
262   }
263 
264   // The number of parallel ids that can be claimed to allow collector or
265   // mutator threads to do card-processing work.
266   static uint num_par_ids();
</pre>
<hr />
<pre>
279   // threshold.
280   void set_process_cards_threshold(size_t sz) {
281     _process_cards_threshold = sz;
282   }
283   size_t process_cards_threshold() const {
284     return _process_cards_threshold;
285   }
286   static const size_t ProcessCardsThresholdNever = SIZE_MAX;
287 
288   // Notify the consumer if the number of buffers crossed the threshold
289   void notify_if_necessary();
290 
291   void merge_bufferlists(G1RedirtyCardsQueueSet* src);
292 
293   G1BufferNodeList take_all_completed_buffers();
294 
295   // Helper for G1DirtyCardQueue::handle_completed_buffer().
296   // Enqueue the buffer, and optionally perform refinement by the mutator.
297   // Mutator refinement is only done by Java threads, and only if there
298   // are more than max_cards (possibly padded) cards in the completed
<span class="line-modified">299   // buffers.</span>
300   //
301   // Mutator refinement, if performed, stops processing a buffer if
302   // SuspendibleThreadSet::should_yield(), recording the incompletely
303   // processed buffer for later processing of the remainder.
<span class="line-modified">304   void handle_completed_buffer(BufferNode* node);</span>
305 
306   // If there are more than stop_at cards in the completed buffers, pop
307   // a buffer, refine its contents, and return true.  Otherwise return
<span class="line-modified">308   // false.</span>
309   //
310   // Stops processing a buffer if SuspendibleThreadSet::should_yield(),
311   // recording the incompletely processed buffer for later processing of
312   // the remainder.
<span class="line-removed">313   //</span>
<span class="line-removed">314   // Increments *total_refined_cards by the number of cards processed and</span>
<span class="line-removed">315   // removed from the buffer.</span>
316   bool refine_completed_buffer_concurrently(uint worker_id,
317                                             size_t stop_at,
<span class="line-modified">318                                             size_t* total_refined_cards);</span>
319 
320   // If a full collection is happening, reset partial logs, and release
321   // completed ones: the full collection will make them all irrelevant.
322   void abandon_logs();
323 
324   // If any threads have partial logs, add them to the global list of logs.
325   void concatenate_logs();
326 








327   // Threshold for mutator threads to also do refinement when there
328   // are concurrent refinement threads.
329   size_t max_cards() const;
330 
331   // Set threshold for mutator threads to also do refinement.
332   void set_max_cards(size_t value);
333 
334   // Artificially increase mutator refinement threshold.
335   void set_max_cards_padding(size_t padding);
336 
337   // Discard artificial increase of mutator refinement threshold.
338   void discard_max_cards_padding();
<span class="line-removed">339 </span>
<span class="line-removed">340   // Total dirty cards refined by mutator threads.</span>
<span class="line-removed">341   size_t total_mutator_refined_cards() const;</span>
342 };
343 
344 inline G1DirtyCardQueueSet* G1DirtyCardQueue::dirty_card_qset() const {
345   return static_cast&lt;G1DirtyCardQueueSet*&gt;(qset());
346 }
347 
348 #endif // SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
</pre>
</td>
<td>
<hr />
<pre>
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
 26 #define SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
 27 
 28 #include &quot;gc/g1/g1BufferNodeList.hpp&quot;
 29 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;
<span class="line-added"> 30 #include &quot;gc/g1/g1ConcurrentRefineStats.hpp&quot;</span>
 31 #include &quot;gc/shared/ptrQueue.hpp&quot;
 32 #include &quot;memory/allocation.hpp&quot;
 33 #include &quot;memory/padded.hpp&quot;
 34 
 35 class G1ConcurrentRefineThread;
 36 class G1DirtyCardQueueSet;
 37 class G1RedirtyCardsQueueSet;
 38 class Thread;
 39 
 40 // A ptrQueue whose elements are &quot;oops&quot;, pointers to object heads.
 41 class G1DirtyCardQueue: public PtrQueue {
<span class="line-added"> 42   G1ConcurrentRefineStats* _refinement_stats;</span>
<span class="line-added"> 43 </span>
 44 protected:
 45   virtual void handle_completed_buffer();
 46 
 47 public:
 48   G1DirtyCardQueue(G1DirtyCardQueueSet* qset);
 49 
 50   // Flush before destroying; queue may be used to capture pending work while
 51   // doing something else, with auto-flush on completion.
 52   ~G1DirtyCardQueue();
 53 
 54   // Process queue entries and release resources.
<span class="line-modified"> 55   void flush();</span>
 56 
 57   inline G1DirtyCardQueueSet* dirty_card_qset() const;
 58 
<span class="line-added"> 59   G1ConcurrentRefineStats* refinement_stats() const {</span>
<span class="line-added"> 60     return _refinement_stats;</span>
<span class="line-added"> 61   }</span>
<span class="line-added"> 62 </span>
<span class="line-added"> 63   // To be called by the barrier set&#39;s on_thread_detach, to notify this</span>
<span class="line-added"> 64   // object of the corresponding state change of its owning thread.</span>
<span class="line-added"> 65   void on_thread_detach();</span>
<span class="line-added"> 66 </span>
 67   // Compiler support.
 68   static ByteSize byte_offset_of_index() {
 69     return PtrQueue::byte_offset_of_index&lt;G1DirtyCardQueue&gt;();
 70   }
 71   using PtrQueue::byte_width_of_index;
 72 
 73   static ByteSize byte_offset_of_buf() {
 74     return PtrQueue::byte_offset_of_buf&lt;G1DirtyCardQueue&gt;();
 75   }
 76   using PtrQueue::byte_width_of_buf;
 77 
 78 };
 79 
 80 class G1DirtyCardQueueSet: public PtrQueueSet {
 81   // Head and tail of a list of BufferNodes, linked through their next()
 82   // fields.  Similar to G1BufferNodeList, but without the _entry_count.
 83   struct HeadTail {
 84     BufferNode* _head;
 85     BufferNode* _tail;
 86     HeadTail() : _head(NULL), _tail(NULL) {}
</pre>
<hr />
<pre>
209   DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(G1ConcurrentRefineThread*));
210   // Upper bound on the number of cards in the completed and paused buffers.
211   volatile size_t _num_cards;
212   DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(size_t));
213   // Buffers ready for refinement.
214   Queue _completed;           // Has inner padding, including trailer.
215   // Buffers for which refinement is temporarily paused.
216   PausedBuffers _paused;      // Has inner padding, including trailer.
217 
218   G1FreeIdSet _free_ids;
219 
220   // Activation threshold for the primary refinement thread.
221   size_t _process_cards_threshold;
222 
223   // If the queue contains more cards than configured here, the
224   // mutator must start doing some of the concurrent refinement work.
225   size_t _max_cards;
226   volatile size_t _padded_max_cards;
227   static const size_t MaxCardsUnlimited = SIZE_MAX;
228 
<span class="line-modified">229   G1ConcurrentRefineStats _detached_refinement_stats;</span>


230 
231   // Verify _num_cards == sum of cards in the completed queue.
232   void verify_num_cards() const NOT_DEBUG_RETURN;
233 
234   // Thread-safe add a buffer to paused list for next safepoint.
235   // precondition: not at safepoint.
236   void record_paused_buffer(BufferNode* node);
237   void enqueue_paused_buffers_aux(const HeadTail&amp; paused);
238   // Thread-safe transfer paused buffers for previous safepoints to the queue.
239   // precondition: not at safepoint.
240   void enqueue_previous_paused_buffers();
241   // Transfer all paused buffers to the queue.
242   // precondition: at safepoint.
243   void enqueue_all_paused_buffers();
244 
245   void abandon_completed_buffers();
246 
247   // Refine the cards in &quot;node&quot; from its index to buffer_size.
248   // Stops processing if SuspendibleThreadSet::should_yield() is true.
249   // Returns true if the entire buffer was processed, false if there
250   // is a pending yield request.  The node&#39;s index is updated to exclude
251   // the processed elements, e.g. up to the element before processing
252   // stopped, or one past the last element if the entire buffer was
<span class="line-modified">253   // processed. Updates stats.</span>
<span class="line-modified">254   bool refine_buffer(BufferNode* node,</span>
<span class="line-modified">255                      uint worker_id,</span>
<span class="line-added">256                      G1ConcurrentRefineStats* stats);</span>
257 
258   // Deal with buffer after a call to refine_buffer.  If fully processed,
259   // deallocate the buffer.  Otherwise, record it as paused.
260   void handle_refined_buffer(BufferNode* node, bool fully_processed);
261 
262   // Remove and return a completed buffer from the list, or return NULL
263   // if none available.
264   BufferNode* get_completed_buffer();
265 
266 public:
267   G1DirtyCardQueueSet(BufferNode::Allocator* allocator);
268   ~G1DirtyCardQueueSet();
269 
270   void set_primary_refinement_thread(G1ConcurrentRefineThread* thread) {
271     _primary_refinement_thread = thread;
272   }
273 
274   // The number of parallel ids that can be claimed to allow collector or
275   // mutator threads to do card-processing work.
276   static uint num_par_ids();
</pre>
<hr />
<pre>
289   // threshold.
290   void set_process_cards_threshold(size_t sz) {
291     _process_cards_threshold = sz;
292   }
293   size_t process_cards_threshold() const {
294     return _process_cards_threshold;
295   }
296   static const size_t ProcessCardsThresholdNever = SIZE_MAX;
297 
298   // Notify the consumer if the number of buffers crossed the threshold
299   void notify_if_necessary();
300 
301   void merge_bufferlists(G1RedirtyCardsQueueSet* src);
302 
303   G1BufferNodeList take_all_completed_buffers();
304 
305   // Helper for G1DirtyCardQueue::handle_completed_buffer().
306   // Enqueue the buffer, and optionally perform refinement by the mutator.
307   // Mutator refinement is only done by Java threads, and only if there
308   // are more than max_cards (possibly padded) cards in the completed
<span class="line-modified">309   // buffers.  Updates stats.</span>
310   //
311   // Mutator refinement, if performed, stops processing a buffer if
312   // SuspendibleThreadSet::should_yield(), recording the incompletely
313   // processed buffer for later processing of the remainder.
<span class="line-modified">314   void handle_completed_buffer(BufferNode* node, G1ConcurrentRefineStats* stats);</span>
315 
316   // If there are more than stop_at cards in the completed buffers, pop
317   // a buffer, refine its contents, and return true.  Otherwise return
<span class="line-modified">318   // false.  Updates stats.</span>
319   //
320   // Stops processing a buffer if SuspendibleThreadSet::should_yield(),
321   // recording the incompletely processed buffer for later processing of
322   // the remainder.



323   bool refine_completed_buffer_concurrently(uint worker_id,
324                                             size_t stop_at,
<span class="line-modified">325                                             G1ConcurrentRefineStats* stats);</span>
326 
327   // If a full collection is happening, reset partial logs, and release
328   // completed ones: the full collection will make them all irrelevant.
329   void abandon_logs();
330 
331   // If any threads have partial logs, add them to the global list of logs.
332   void concatenate_logs();
333 
<span class="line-added">334   // Return the total of mutator refinement stats for all threads.</span>
<span class="line-added">335   // Also resets the stats for the threads.</span>
<span class="line-added">336   // precondition: at safepoint.</span>
<span class="line-added">337   G1ConcurrentRefineStats get_and_reset_refinement_stats();</span>
<span class="line-added">338 </span>
<span class="line-added">339   // Accumulate refinement stats from threads that are detaching.</span>
<span class="line-added">340   void record_detached_refinement_stats(G1ConcurrentRefineStats* stats);</span>
<span class="line-added">341 </span>
342   // Threshold for mutator threads to also do refinement when there
343   // are concurrent refinement threads.
344   size_t max_cards() const;
345 
346   // Set threshold for mutator threads to also do refinement.
347   void set_max_cards(size_t value);
348 
349   // Artificially increase mutator refinement threshold.
350   void set_max_cards_padding(size_t padding);
351 
352   // Discard artificial increase of mutator refinement threshold.
353   void discard_max_cards_padding();



354 };
355 
356 inline G1DirtyCardQueueSet* G1DirtyCardQueue::dirty_card_qset() const {
357   return static_cast&lt;G1DirtyCardQueueSet*&gt;(qset());
358 }
359 
360 #endif // SHARE_GC_G1_G1DIRTYCARDQUEUE_HPP
</pre>
</td>
</tr>
</table>
<center><a href="g1DirtyCardQueue.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1GCPhaseTimes.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>