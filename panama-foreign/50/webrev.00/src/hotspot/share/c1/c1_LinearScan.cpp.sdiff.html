<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/c1/c1_LinearScan.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../../os/linux/cgroupSubsystem_linux.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../classfile/javaClasses.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/c1/c1_LinearScan.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1075       }
1076 
1077       // The input operand is not forced to a register (moves from stack to register are allowed),
1078       // but it is faster if the input operand is in a register
1079       return shouldHaveRegister;
1080     }
1081   }
1082 
1083 
1084 #if defined(X86) || defined(S390)
1085   if (op-&gt;code() == lir_cmove) {
1086     // conditional moves can handle stack operands
1087     assert(op-&gt;result_opr()-&gt;is_register(), &quot;result must always be in a register&quot;);
1088     return shouldHaveRegister;
1089   }
1090 
1091   // optimizations for second input operand of arithmehtic operations on Intel
1092   // this operand is allowed to be on the stack in some cases
1093   BasicType opr_type = opr-&gt;type_register();
1094   if (opr_type == T_FLOAT || opr_type == T_DOUBLE) {
<span class="line-modified">1095     if ((UseSSE == 1 &amp;&amp; opr_type == T_FLOAT) || UseSSE &gt;= 2 S390_ONLY(|| true)) {</span>
1096       // SSE float instruction (T_DOUBLE only supported with SSE2)
1097       switch (op-&gt;code()) {
1098         case lir_cmp:
1099         case lir_add:
1100         case lir_sub:
1101         case lir_mul:
1102         case lir_div:
1103         {
1104           assert(op-&gt;as_Op2() != NULL, &quot;must be LIR_Op2&quot;);
1105           LIR_Op2* op2 = (LIR_Op2*)op;
1106           if (op2-&gt;in_opr1() != op2-&gt;in_opr2() &amp;&amp; op2-&gt;in_opr2() == opr) {
1107             assert((op2-&gt;result_opr()-&gt;is_register() || op-&gt;code() == lir_cmp) &amp;&amp; op2-&gt;in_opr1()-&gt;is_register(), &quot;cannot mark second operand as stack if others are not in register&quot;);
1108             return shouldHaveRegister;
1109           }
1110         }
1111         default:
1112           break;
1113       }
1114     } else {
1115       // FPU stack float instruction
</pre>
<hr />
<pre>
1137     // integer instruction (note: long operands must always be in register)
1138     switch (op-&gt;code()) {
1139       case lir_cmp:
1140       case lir_add:
1141       case lir_sub:
1142       case lir_logic_and:
1143       case lir_logic_or:
1144       case lir_logic_xor:
1145       {
1146         assert(op-&gt;as_Op2() != NULL, &quot;must be LIR_Op2&quot;);
1147         LIR_Op2* op2 = (LIR_Op2*)op;
1148         if (op2-&gt;in_opr1() != op2-&gt;in_opr2() &amp;&amp; op2-&gt;in_opr2() == opr) {
1149           assert((op2-&gt;result_opr()-&gt;is_register() || op-&gt;code() == lir_cmp) &amp;&amp; op2-&gt;in_opr1()-&gt;is_register(), &quot;cannot mark second operand as stack if others are not in register&quot;);
1150           return shouldHaveRegister;
1151         }
1152       }
1153       default:
1154         break;
1155     }
1156   }
<span class="line-modified">1157 #endif // X86 S390</span>
1158 
1159   // all other operands require a register
1160   return mustHaveRegister;
1161 }
1162 
1163 
1164 void LinearScan::handle_method_arguments(LIR_Op* op) {
1165   // special handling for method arguments (moves from stack to virtual register):
1166   // the interval gets no register assigned, but the stack slot.
1167   // it is split before the first use by the register allocator.
1168 
1169   if (op-&gt;code() == lir_move) {
1170     assert(op-&gt;as_Op1() != NULL, &quot;must be LIR_Op1&quot;);
1171     LIR_Op1* move = (LIR_Op1*)op;
1172 
1173     if (move-&gt;in_opr()-&gt;is_stack()) {
1174 #ifdef ASSERT
1175       int arg_size = compilation()-&gt;method()-&gt;arg_size();
1176       LIR_Opr o = move-&gt;in_opr();
1177       if (o-&gt;is_single_stack()) {
</pre>
<hr />
<pre>
1274 
1275   // create a list with all caller-save registers (cpu, fpu, xmm)
1276   // when an instruction is a call, a temp range is created for all these registers
1277   int num_caller_save_registers = 0;
1278   int caller_save_registers[LinearScan::nof_regs];
1279 
1280   int i;
1281   for (i = 0; i &lt; FrameMap::nof_caller_save_cpu_regs(); i++) {
1282     LIR_Opr opr = FrameMap::caller_save_cpu_reg_at(i);
1283     assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1284     assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1285     caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1286   }
1287 
1288   // temp ranges for fpu registers are only created when the method has
1289   // virtual fpu operands. Otherwise no allocation for fpu registers is
1290   // performed and so the temp ranges would be useless
1291   if (has_fpu_registers()) {
1292 #ifdef X86
1293     if (UseSSE &lt; 2) {
<span class="line-modified">1294 #endif</span>
1295       for (i = 0; i &lt; FrameMap::nof_caller_save_fpu_regs; i++) {
1296         LIR_Opr opr = FrameMap::caller_save_fpu_reg_at(i);
1297         assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1298         assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1299         caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1300       }
1301 #ifdef X86
1302     }



1303     if (UseSSE &gt; 0) {
1304       int num_caller_save_xmm_regs = FrameMap::get_num_caller_save_xmms();
1305       for (i = 0; i &lt; num_caller_save_xmm_regs; i ++) {
1306         LIR_Opr opr = FrameMap::caller_save_xmm_reg_at(i);
1307         assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1308         assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1309         caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1310       }
1311     }
<span class="line-modified">1312 #endif</span>
1313   }
1314   assert(num_caller_save_registers &lt;= LinearScan::nof_regs, &quot;out of bounds&quot;);
1315 
1316 
1317   LIR_OpVisitState visitor;
1318 
1319   // iterate all blocks in reverse order
1320   for (i = block_count() - 1; i &gt;= 0; i--) {
1321     BlockBegin* block = block_at(i);
1322     LIR_OpList* instructions = block-&gt;lir()-&gt;instructions_list();
1323     int         block_from =   block-&gt;first_lir_instruction_id();
1324     int         block_to =     block-&gt;last_lir_instruction_id();
1325 
1326     assert(block_from == instructions-&gt;at(0)-&gt;id(), &quot;must be&quot;);
1327     assert(block_to   == instructions-&gt;at(instructions-&gt;length() - 1)-&gt;id(), &quot;must be&quot;);
1328 
1329     // Update intervals for registers live at the end of this block;
1330     ResourceBitMap live = block-&gt;live_out();
1331     int size = (int)live.size();
1332     for (int number = (int)live.get_next_one_offset(0, size); number &lt; size; number = (int)live.get_next_one_offset(number + 1, size)) {
</pre>
<hr />
<pre>
2130 #ifdef _LP64
2131         return LIR_OprFact::double_cpu(assigned_reg, assigned_reg);
2132 #else
2133 #if defined(SPARC) || defined(PPC32)
2134         return LIR_OprFact::double_cpu(assigned_regHi, assigned_reg);
2135 #else
2136         return LIR_OprFact::double_cpu(assigned_reg, assigned_regHi);
2137 #endif // SPARC
2138 #endif // LP64
2139       }
2140 
2141 #ifndef __SOFTFP__
2142       case T_FLOAT: {
2143 #ifdef X86
2144         if (UseSSE &gt;= 1) {
2145           int last_xmm_reg = pd_last_xmm_reg;
2146 #ifdef _LP64
2147           if (UseAVX &lt; 3) {
2148             last_xmm_reg = pd_first_xmm_reg + (pd_nof_xmm_regs_frame_map / 2) - 1;
2149           }
<span class="line-modified">2150 #endif</span>
2151           assert(assigned_reg &gt;= pd_first_xmm_reg &amp;&amp; assigned_reg &lt;= last_xmm_reg, &quot;no xmm register&quot;);
2152           assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register&quot;);
2153           return LIR_OprFact::single_xmm(assigned_reg - pd_first_xmm_reg);
2154         }
<span class="line-modified">2155 #endif</span>
2156 
2157         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2158         assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register&quot;);
2159         return LIR_OprFact::single_fpu(assigned_reg - pd_first_fpu_reg);
2160       }
2161 
2162       case T_DOUBLE: {
2163 #ifdef X86
2164         if (UseSSE &gt;= 2) {
2165           int last_xmm_reg = pd_last_xmm_reg;
2166 #ifdef _LP64
2167           if (UseAVX &lt; 3) {
2168             last_xmm_reg = pd_first_xmm_reg + (pd_nof_xmm_regs_frame_map / 2) - 1;
2169           }
<span class="line-modified">2170 #endif</span>
2171           assert(assigned_reg &gt;= pd_first_xmm_reg &amp;&amp; assigned_reg &lt;= last_xmm_reg, &quot;no xmm register&quot;);
2172           assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register (double xmm values are stored in one register)&quot;);
2173           return LIR_OprFact::double_xmm(assigned_reg - pd_first_xmm_reg);
2174         }
<span class="line-modified">2175 #endif</span>
2176 
2177 #ifdef SPARC
2178         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2179         assert(interval-&gt;assigned_regHi() &gt;= pd_first_fpu_reg &amp;&amp; interval-&gt;assigned_regHi() &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2180         assert(assigned_reg % 2 == 0 &amp;&amp; assigned_reg + 1 == interval-&gt;assigned_regHi(), &quot;must be sequential and even&quot;);
2181         LIR_Opr result = LIR_OprFact::double_fpu(interval-&gt;assigned_regHi() - pd_first_fpu_reg, assigned_reg - pd_first_fpu_reg);
2182 #elif defined(ARM32)
2183         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2184         assert(interval-&gt;assigned_regHi() &gt;= pd_first_fpu_reg &amp;&amp; interval-&gt;assigned_regHi() &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2185         assert(assigned_reg % 2 == 0 &amp;&amp; assigned_reg + 1 == interval-&gt;assigned_regHi(), &quot;must be sequential and even&quot;);
2186         LIR_Opr result = LIR_OprFact::double_fpu(assigned_reg - pd_first_fpu_reg, interval-&gt;assigned_regHi() - pd_first_fpu_reg);
2187 #else
2188         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2189         assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register (double fpu values are stored in one register on Intel)&quot;);
2190         LIR_Opr result = LIR_OprFact::double_fpu(assigned_reg - pd_first_fpu_reg);
2191 #endif
2192         return result;
2193       }
2194 #endif // __SOFTFP__
2195 
</pre>
</td>
<td>
<hr />
<pre>
1075       }
1076 
1077       // The input operand is not forced to a register (moves from stack to register are allowed),
1078       // but it is faster if the input operand is in a register
1079       return shouldHaveRegister;
1080     }
1081   }
1082 
1083 
1084 #if defined(X86) || defined(S390)
1085   if (op-&gt;code() == lir_cmove) {
1086     // conditional moves can handle stack operands
1087     assert(op-&gt;result_opr()-&gt;is_register(), &quot;result must always be in a register&quot;);
1088     return shouldHaveRegister;
1089   }
1090 
1091   // optimizations for second input operand of arithmehtic operations on Intel
1092   // this operand is allowed to be on the stack in some cases
1093   BasicType opr_type = opr-&gt;type_register();
1094   if (opr_type == T_FLOAT || opr_type == T_DOUBLE) {
<span class="line-modified">1095     if (IA32_ONLY( (UseSSE == 1 &amp;&amp; opr_type == T_FLOAT) || UseSSE &gt;= 2 ) NOT_IA32( true )) {</span>
1096       // SSE float instruction (T_DOUBLE only supported with SSE2)
1097       switch (op-&gt;code()) {
1098         case lir_cmp:
1099         case lir_add:
1100         case lir_sub:
1101         case lir_mul:
1102         case lir_div:
1103         {
1104           assert(op-&gt;as_Op2() != NULL, &quot;must be LIR_Op2&quot;);
1105           LIR_Op2* op2 = (LIR_Op2*)op;
1106           if (op2-&gt;in_opr1() != op2-&gt;in_opr2() &amp;&amp; op2-&gt;in_opr2() == opr) {
1107             assert((op2-&gt;result_opr()-&gt;is_register() || op-&gt;code() == lir_cmp) &amp;&amp; op2-&gt;in_opr1()-&gt;is_register(), &quot;cannot mark second operand as stack if others are not in register&quot;);
1108             return shouldHaveRegister;
1109           }
1110         }
1111         default:
1112           break;
1113       }
1114     } else {
1115       // FPU stack float instruction
</pre>
<hr />
<pre>
1137     // integer instruction (note: long operands must always be in register)
1138     switch (op-&gt;code()) {
1139       case lir_cmp:
1140       case lir_add:
1141       case lir_sub:
1142       case lir_logic_and:
1143       case lir_logic_or:
1144       case lir_logic_xor:
1145       {
1146         assert(op-&gt;as_Op2() != NULL, &quot;must be LIR_Op2&quot;);
1147         LIR_Op2* op2 = (LIR_Op2*)op;
1148         if (op2-&gt;in_opr1() != op2-&gt;in_opr2() &amp;&amp; op2-&gt;in_opr2() == opr) {
1149           assert((op2-&gt;result_opr()-&gt;is_register() || op-&gt;code() == lir_cmp) &amp;&amp; op2-&gt;in_opr1()-&gt;is_register(), &quot;cannot mark second operand as stack if others are not in register&quot;);
1150           return shouldHaveRegister;
1151         }
1152       }
1153       default:
1154         break;
1155     }
1156   }
<span class="line-modified">1157 #endif // X86 || S390</span>
1158 
1159   // all other operands require a register
1160   return mustHaveRegister;
1161 }
1162 
1163 
1164 void LinearScan::handle_method_arguments(LIR_Op* op) {
1165   // special handling for method arguments (moves from stack to virtual register):
1166   // the interval gets no register assigned, but the stack slot.
1167   // it is split before the first use by the register allocator.
1168 
1169   if (op-&gt;code() == lir_move) {
1170     assert(op-&gt;as_Op1() != NULL, &quot;must be LIR_Op1&quot;);
1171     LIR_Op1* move = (LIR_Op1*)op;
1172 
1173     if (move-&gt;in_opr()-&gt;is_stack()) {
1174 #ifdef ASSERT
1175       int arg_size = compilation()-&gt;method()-&gt;arg_size();
1176       LIR_Opr o = move-&gt;in_opr();
1177       if (o-&gt;is_single_stack()) {
</pre>
<hr />
<pre>
1274 
1275   // create a list with all caller-save registers (cpu, fpu, xmm)
1276   // when an instruction is a call, a temp range is created for all these registers
1277   int num_caller_save_registers = 0;
1278   int caller_save_registers[LinearScan::nof_regs];
1279 
1280   int i;
1281   for (i = 0; i &lt; FrameMap::nof_caller_save_cpu_regs(); i++) {
1282     LIR_Opr opr = FrameMap::caller_save_cpu_reg_at(i);
1283     assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1284     assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1285     caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1286   }
1287 
1288   // temp ranges for fpu registers are only created when the method has
1289   // virtual fpu operands. Otherwise no allocation for fpu registers is
1290   // performed and so the temp ranges would be useless
1291   if (has_fpu_registers()) {
1292 #ifdef X86
1293     if (UseSSE &lt; 2) {
<span class="line-modified">1294 #endif // X86</span>
1295       for (i = 0; i &lt; FrameMap::nof_caller_save_fpu_regs; i++) {
1296         LIR_Opr opr = FrameMap::caller_save_fpu_reg_at(i);
1297         assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1298         assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1299         caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1300       }
1301 #ifdef X86
1302     }
<span class="line-added">1303 #endif // X86</span>
<span class="line-added">1304 </span>
<span class="line-added">1305 #ifdef X86</span>
1306     if (UseSSE &gt; 0) {
1307       int num_caller_save_xmm_regs = FrameMap::get_num_caller_save_xmms();
1308       for (i = 0; i &lt; num_caller_save_xmm_regs; i ++) {
1309         LIR_Opr opr = FrameMap::caller_save_xmm_reg_at(i);
1310         assert(opr-&gt;is_valid() &amp;&amp; opr-&gt;is_register(), &quot;FrameMap should not return invalid operands&quot;);
1311         assert(reg_numHi(opr) == -1, &quot;missing addition of range for hi-register&quot;);
1312         caller_save_registers[num_caller_save_registers++] = reg_num(opr);
1313       }
1314     }
<span class="line-modified">1315 #endif // X86</span>
1316   }
1317   assert(num_caller_save_registers &lt;= LinearScan::nof_regs, &quot;out of bounds&quot;);
1318 
1319 
1320   LIR_OpVisitState visitor;
1321 
1322   // iterate all blocks in reverse order
1323   for (i = block_count() - 1; i &gt;= 0; i--) {
1324     BlockBegin* block = block_at(i);
1325     LIR_OpList* instructions = block-&gt;lir()-&gt;instructions_list();
1326     int         block_from =   block-&gt;first_lir_instruction_id();
1327     int         block_to =     block-&gt;last_lir_instruction_id();
1328 
1329     assert(block_from == instructions-&gt;at(0)-&gt;id(), &quot;must be&quot;);
1330     assert(block_to   == instructions-&gt;at(instructions-&gt;length() - 1)-&gt;id(), &quot;must be&quot;);
1331 
1332     // Update intervals for registers live at the end of this block;
1333     ResourceBitMap live = block-&gt;live_out();
1334     int size = (int)live.size();
1335     for (int number = (int)live.get_next_one_offset(0, size); number &lt; size; number = (int)live.get_next_one_offset(number + 1, size)) {
</pre>
<hr />
<pre>
2133 #ifdef _LP64
2134         return LIR_OprFact::double_cpu(assigned_reg, assigned_reg);
2135 #else
2136 #if defined(SPARC) || defined(PPC32)
2137         return LIR_OprFact::double_cpu(assigned_regHi, assigned_reg);
2138 #else
2139         return LIR_OprFact::double_cpu(assigned_reg, assigned_regHi);
2140 #endif // SPARC
2141 #endif // LP64
2142       }
2143 
2144 #ifndef __SOFTFP__
2145       case T_FLOAT: {
2146 #ifdef X86
2147         if (UseSSE &gt;= 1) {
2148           int last_xmm_reg = pd_last_xmm_reg;
2149 #ifdef _LP64
2150           if (UseAVX &lt; 3) {
2151             last_xmm_reg = pd_first_xmm_reg + (pd_nof_xmm_regs_frame_map / 2) - 1;
2152           }
<span class="line-modified">2153 #endif // LP64</span>
2154           assert(assigned_reg &gt;= pd_first_xmm_reg &amp;&amp; assigned_reg &lt;= last_xmm_reg, &quot;no xmm register&quot;);
2155           assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register&quot;);
2156           return LIR_OprFact::single_xmm(assigned_reg - pd_first_xmm_reg);
2157         }
<span class="line-modified">2158 #endif // X86</span>
2159 
2160         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2161         assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register&quot;);
2162         return LIR_OprFact::single_fpu(assigned_reg - pd_first_fpu_reg);
2163       }
2164 
2165       case T_DOUBLE: {
2166 #ifdef X86
2167         if (UseSSE &gt;= 2) {
2168           int last_xmm_reg = pd_last_xmm_reg;
2169 #ifdef _LP64
2170           if (UseAVX &lt; 3) {
2171             last_xmm_reg = pd_first_xmm_reg + (pd_nof_xmm_regs_frame_map / 2) - 1;
2172           }
<span class="line-modified">2173 #endif // LP64</span>
2174           assert(assigned_reg &gt;= pd_first_xmm_reg &amp;&amp; assigned_reg &lt;= last_xmm_reg, &quot;no xmm register&quot;);
2175           assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register (double xmm values are stored in one register)&quot;);
2176           return LIR_OprFact::double_xmm(assigned_reg - pd_first_xmm_reg);
2177         }
<span class="line-modified">2178 #endif // X86</span>
2179 
2180 #ifdef SPARC
2181         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2182         assert(interval-&gt;assigned_regHi() &gt;= pd_first_fpu_reg &amp;&amp; interval-&gt;assigned_regHi() &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2183         assert(assigned_reg % 2 == 0 &amp;&amp; assigned_reg + 1 == interval-&gt;assigned_regHi(), &quot;must be sequential and even&quot;);
2184         LIR_Opr result = LIR_OprFact::double_fpu(interval-&gt;assigned_regHi() - pd_first_fpu_reg, assigned_reg - pd_first_fpu_reg);
2185 #elif defined(ARM32)
2186         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2187         assert(interval-&gt;assigned_regHi() &gt;= pd_first_fpu_reg &amp;&amp; interval-&gt;assigned_regHi() &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2188         assert(assigned_reg % 2 == 0 &amp;&amp; assigned_reg + 1 == interval-&gt;assigned_regHi(), &quot;must be sequential and even&quot;);
2189         LIR_Opr result = LIR_OprFact::double_fpu(assigned_reg - pd_first_fpu_reg, interval-&gt;assigned_regHi() - pd_first_fpu_reg);
2190 #else
2191         assert(assigned_reg &gt;= pd_first_fpu_reg &amp;&amp; assigned_reg &lt;= pd_last_fpu_reg, &quot;no fpu register&quot;);
2192         assert(interval-&gt;assigned_regHi() == any_reg, &quot;must not have hi register (double fpu values are stored in one register on Intel)&quot;);
2193         LIR_Opr result = LIR_OprFact::double_fpu(assigned_reg - pd_first_fpu_reg);
2194 #endif
2195         return result;
2196       }
2197 #endif // __SOFTFP__
2198 
</pre>
</td>
</tr>
</table>
<center><a href="../../os/linux/cgroupSubsystem_linux.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../classfile/javaClasses.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>