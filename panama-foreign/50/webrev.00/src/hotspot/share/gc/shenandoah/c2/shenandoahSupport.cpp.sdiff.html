<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
<body>
<center><a href="../../shared/gcCause.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="shenandoahSupport.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1127   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
1128 
1129   Unique_Node_List uses;
1130   for (int i = 0; i &lt; state-&gt;enqueue_barriers_count(); i++) {
1131     Node* barrier = state-&gt;enqueue_barrier(i);
1132     Node* ctrl = phase-&gt;get_ctrl(barrier);
1133     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1134     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1135       // Expanding a barrier here will break loop strip mining
1136       // verification. Transform the loop so the loop nest doesn&#39;t
1137       // appear as strip mined.
1138       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1139       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1140     }
1141   }
1142 
1143   Node_Stack stack(0);
1144   Node_List clones;
1145   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1146     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1147     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {</span>
1148       continue;
1149     }
1150 
1151     Node* ctrl = phase-&gt;get_ctrl(lrb);
1152     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1153 
1154     CallStaticJavaNode* unc = NULL;
1155     Node* unc_ctrl = NULL;
1156     Node* uncasted_val = val;
1157 
1158     for (DUIterator_Fast imax, i = lrb-&gt;fast_outs(imax); i &lt; imax; i++) {
1159       Node* u = lrb-&gt;fast_out(i);
1160       if (u-&gt;Opcode() == Op_CastPP &amp;&amp;
1161           u-&gt;in(0) != NULL &amp;&amp;
1162           phase-&gt;is_dominator(u-&gt;in(0), ctrl)) {
1163         const Type* u_t = phase-&gt;igvn().type(u);
1164 
1165         if (u_t-&gt;meet(TypePtr::NULL_PTR) != u_t &amp;&amp;
1166             u-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
1167             u-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
</pre>
<hr />
<pre>
1358                 int nb = u-&gt;replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
1359                 assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1360                 replaced = true;
1361               }
1362             }
1363             if (!replaced) {
1364               stack.set_index(idx+1);
1365             }
1366           }
1367         } else {
1368           stack.pop();
1369           clones.pop();
1370         }
1371       } while (stack.size() &gt; 0);
1372       assert(stack.size() == 0 &amp;&amp; clones.size() == 0, &quot;&quot;);
1373     }
1374   }
1375 
1376   for (int i = 0; i &lt; state-&gt;load_reference_barriers_count(); i++) {
1377     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1378     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {</span>
1379       continue;
1380     }
1381     Node* ctrl = phase-&gt;get_ctrl(lrb);
1382     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1383     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1384       // Expanding a barrier here will break loop strip mining
1385       // verification. Transform the loop so the loop nest doesn&#39;t
1386       // appear as strip mined.
1387       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1388       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1389     }
1390   }
1391 
1392   // Expand load-reference-barriers
1393   MemoryGraphFixer fixer(Compile::AliasIdxRaw, true, phase);
1394   Unique_Node_List uses_to_ignore;
1395   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1396     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1397     if (lrb-&gt;get_barrier_strength() == ShenandoahLoadReferenceBarrierNode::NONE) {</span>
1398       phase-&gt;igvn().replace_node(lrb, lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn));
1399       continue;
1400     }
1401     uint last = phase-&gt;C-&gt;unique();
1402     Node* ctrl = phase-&gt;get_ctrl(lrb);
1403     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1404 
1405 
1406     Node* orig_ctrl = ctrl;
1407 
1408     Node* raw_mem = fixer.find_mem(ctrl, lrb);
1409     Node* init_raw_mem = raw_mem;
1410     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1411 
1412     IdealLoopTree *loop = phase-&gt;get_loop(ctrl);
1413     CallStaticJavaNode* unc = lrb-&gt;pin_and_expand_null_check(phase-&gt;igvn());
1414     Node* unc_ctrl = NULL;
1415     if (unc != NULL) {
1416       if (val-&gt;in(ShenandoahLoadReferenceBarrierNode::Control) != ctrl) {
1417         unc = NULL;
</pre>
<hr />
<pre>
3173       return needs_barrier_impl(phase, n-&gt;in(2), visited) ||
3174              needs_barrier_impl(phase, n-&gt;in(3), visited);
3175     case Op_ShenandoahEnqueueBarrier:
3176       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3177     case Op_CreateEx:
3178       return false;
3179     default:
3180       break;
3181   }
3182 #ifdef ASSERT
3183   tty-&gt;print(&quot;need barrier on?: &quot;);
3184   tty-&gt;print_cr(&quot;ins:&quot;);
3185   n-&gt;dump(2);
3186   tty-&gt;print_cr(&quot;outs:&quot;);
3187   n-&gt;dump(-2);
3188   ShouldNotReachHere();
3189 #endif
3190   return true;
3191 }
3192 
<span class="line-modified">3193 ShenandoahLoadReferenceBarrierNode::Strength ShenandoahLoadReferenceBarrierNode::get_barrier_strength() {</span>
3194   Unique_Node_List visited;
3195   Node_Stack stack(0);
3196   stack.push(this, 0);
3197 
<span class="line-modified">3198   // Look for strongest strength: go over nodes looking for STRONG ones.</span>
<span class="line-modified">3199   // Stop once we encountered STRONG. Otherwise, walk until we ran out of nodes,</span>
<span class="line-modified">3200   // and then the overall strength is NONE.</span>
<span class="line-modified">3201   Strength strength = NONE;</span>
<span class="line-removed">3202   while (strength != STRONG &amp;&amp; stack.size() &gt; 0) {</span>
3203     Node* n = stack.node();
3204     if (visited.member(n)) {
3205       stack.pop();
3206       continue;
3207     }
3208     visited.push(n);
3209     bool visit_users = false;
3210     switch (n-&gt;Opcode()) {
3211       case Op_CallStaticJava:
3212       case Op_CallDynamicJava:
3213       case Op_CallLeaf:
3214       case Op_CallLeafNoFP:
3215       case Op_CompareAndSwapL:
3216       case Op_CompareAndSwapI:
3217       case Op_CompareAndSwapB:
3218       case Op_CompareAndSwapS:
3219       case Op_CompareAndSwapN:
3220       case Op_CompareAndSwapP:
3221       case Op_CompareAndExchangeL:
3222       case Op_CompareAndExchangeI:
</pre>
<hr />
<pre>
3258       case Op_StoreL:
3259       case Op_StoreLConditional:
3260       case Op_StoreI:
3261       case Op_StoreIConditional:
3262       case Op_StoreN:
3263       case Op_StoreP:
3264       case Op_StoreVector:
3265       case Op_StrInflatedCopy:
3266       case Op_StrCompressedCopy:
3267       case Op_EncodeP:
3268       case Op_CastP2X:
3269       case Op_SafePoint:
3270       case Op_EncodeISOArray:
3271       case Op_AryEq:
3272       case Op_StrEquals:
3273       case Op_StrComp:
3274       case Op_StrIndexOf:
3275       case Op_StrIndexOfChar:
3276       case Op_HasNegatives:
3277         // Known to require barriers
<span class="line-modified">3278         strength = STRONG;</span>
<span class="line-removed">3279         break;</span>
3280       case Op_CmpP: {
3281         if (n-&gt;in(1)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR) ||
3282             n-&gt;in(2)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR)) {
3283           // One of the sides is known null, no need for barrier.
3284         } else {
<span class="line-modified">3285           strength = STRONG;</span>
3286         }
3287         break;
3288       }
3289       case Op_LoadB:
3290       case Op_LoadUB:
3291       case Op_LoadUS:
3292       case Op_LoadD:
3293       case Op_LoadF:
3294       case Op_LoadL:
3295       case Op_LoadI:
3296       case Op_LoadS:
3297       case Op_LoadN:
3298       case Op_LoadP:
3299       case Op_LoadVector: {
3300         const TypePtr* adr_type = n-&gt;adr_type();
3301         int alias_idx = Compile::current()-&gt;get_alias_index(adr_type);
3302         Compile::AliasType* alias_type = Compile::current()-&gt;alias_type(alias_idx);
3303         ciField* field = alias_type-&gt;field();
3304         bool is_static = field != NULL &amp;&amp; field-&gt;is_static();
3305         bool is_final = field != NULL &amp;&amp; field-&gt;is_final();
3306 
3307         if (ShenandoahOptimizeStaticFinals &amp;&amp; is_static &amp;&amp; is_final) {
3308           // Loading the constant does not require barriers: it should be handled
3309           // as part of GC roots already.
3310         } else {
<span class="line-modified">3311           strength = STRONG;</span>
3312         }
3313         break;
3314       }
3315       case Op_Conv2B:
3316       case Op_LoadRange:
3317       case Op_LoadKlass:
3318       case Op_LoadNKlass:
3319         // Do not require barriers
3320         break;
3321       case Op_AddP:
3322       case Op_CheckCastPP:
3323       case Op_CastPP:
3324       case Op_CMoveP:
3325       case Op_Phi:
3326       case Op_ShenandoahLoadReferenceBarrier:
3327         // Whether or not these need the barriers depends on their users
3328         visit_users = true;
3329         break;
3330       default: {
3331 #ifdef ASSERT
<span class="line-modified">3332         fatal(&quot;Unknown node in get_barrier_strength: %s&quot;, NodeClassNames[n-&gt;Opcode()]);</span>
3333 #else
<span class="line-modified">3334         // Default to strong: better to have excess barriers, rather than miss some.</span>
<span class="line-modified">3335         strength = STRONG;</span>
3336 #endif
3337       }
3338     }
3339 
3340     stack.pop();
3341     if (visit_users) {
3342       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3343         Node* user = n-&gt;fast_out(i);
3344         if (user != NULL) {
3345           stack.push(user, 0);
3346         }
3347       }
3348     }
3349   }
<span class="line-modified">3350   return strength;</span>


3351 }
3352 
3353 CallStaticJavaNode* ShenandoahLoadReferenceBarrierNode::pin_and_expand_null_check(PhaseIterGVN&amp; igvn) {
3354   Node* val = in(ValueIn);
3355 
3356   const Type* val_t = igvn.type(val);
3357 
3358   if (val_t-&gt;meet(TypePtr::NULL_PTR) != val_t &amp;&amp;
3359       val-&gt;Opcode() == Op_CastPP &amp;&amp;
3360       val-&gt;in(0) != NULL &amp;&amp;
3361       val-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
3362       val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
3363       val-&gt;in(0)-&gt;in(0)-&gt;is_If() &amp;&amp;
3364       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;Opcode() == Op_Bool &amp;&amp;
3365       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::ne &amp;&amp;
3366       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpP &amp;&amp;
3367       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1) &amp;&amp;
3368       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;bottom_type() == TypePtr::NULL_PTR) {
3369     assert(val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1), &quot;&quot;);
3370     CallStaticJavaNode* unc = val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
</pre>
</td>
<td>
<hr />
<pre>
1127   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
1128 
1129   Unique_Node_List uses;
1130   for (int i = 0; i &lt; state-&gt;enqueue_barriers_count(); i++) {
1131     Node* barrier = state-&gt;enqueue_barrier(i);
1132     Node* ctrl = phase-&gt;get_ctrl(barrier);
1133     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1134     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1135       // Expanding a barrier here will break loop strip mining
1136       // verification. Transform the loop so the loop nest doesn&#39;t
1137       // appear as strip mined.
1138       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1139       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1140     }
1141   }
1142 
1143   Node_Stack stack(0);
1144   Node_List clones;
1145   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1146     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1147     if (lrb-&gt;is_redundant()) {</span>
1148       continue;
1149     }
1150 
1151     Node* ctrl = phase-&gt;get_ctrl(lrb);
1152     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1153 
1154     CallStaticJavaNode* unc = NULL;
1155     Node* unc_ctrl = NULL;
1156     Node* uncasted_val = val;
1157 
1158     for (DUIterator_Fast imax, i = lrb-&gt;fast_outs(imax); i &lt; imax; i++) {
1159       Node* u = lrb-&gt;fast_out(i);
1160       if (u-&gt;Opcode() == Op_CastPP &amp;&amp;
1161           u-&gt;in(0) != NULL &amp;&amp;
1162           phase-&gt;is_dominator(u-&gt;in(0), ctrl)) {
1163         const Type* u_t = phase-&gt;igvn().type(u);
1164 
1165         if (u_t-&gt;meet(TypePtr::NULL_PTR) != u_t &amp;&amp;
1166             u-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
1167             u-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
</pre>
<hr />
<pre>
1358                 int nb = u-&gt;replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
1359                 assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1360                 replaced = true;
1361               }
1362             }
1363             if (!replaced) {
1364               stack.set_index(idx+1);
1365             }
1366           }
1367         } else {
1368           stack.pop();
1369           clones.pop();
1370         }
1371       } while (stack.size() &gt; 0);
1372       assert(stack.size() == 0 &amp;&amp; clones.size() == 0, &quot;&quot;);
1373     }
1374   }
1375 
1376   for (int i = 0; i &lt; state-&gt;load_reference_barriers_count(); i++) {
1377     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1378     if (lrb-&gt;is_redundant()) {</span>
1379       continue;
1380     }
1381     Node* ctrl = phase-&gt;get_ctrl(lrb);
1382     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1383     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1384       // Expanding a barrier here will break loop strip mining
1385       // verification. Transform the loop so the loop nest doesn&#39;t
1386       // appear as strip mined.
1387       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1388       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1389     }
1390   }
1391 
1392   // Expand load-reference-barriers
1393   MemoryGraphFixer fixer(Compile::AliasIdxRaw, true, phase);
1394   Unique_Node_List uses_to_ignore;
1395   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1396     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
<span class="line-modified">1397     if (lrb-&gt;is_redundant()) {</span>
1398       phase-&gt;igvn().replace_node(lrb, lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn));
1399       continue;
1400     }
1401     uint last = phase-&gt;C-&gt;unique();
1402     Node* ctrl = phase-&gt;get_ctrl(lrb);
1403     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1404 
1405 
1406     Node* orig_ctrl = ctrl;
1407 
1408     Node* raw_mem = fixer.find_mem(ctrl, lrb);
1409     Node* init_raw_mem = raw_mem;
1410     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1411 
1412     IdealLoopTree *loop = phase-&gt;get_loop(ctrl);
1413     CallStaticJavaNode* unc = lrb-&gt;pin_and_expand_null_check(phase-&gt;igvn());
1414     Node* unc_ctrl = NULL;
1415     if (unc != NULL) {
1416       if (val-&gt;in(ShenandoahLoadReferenceBarrierNode::Control) != ctrl) {
1417         unc = NULL;
</pre>
<hr />
<pre>
3173       return needs_barrier_impl(phase, n-&gt;in(2), visited) ||
3174              needs_barrier_impl(phase, n-&gt;in(3), visited);
3175     case Op_ShenandoahEnqueueBarrier:
3176       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3177     case Op_CreateEx:
3178       return false;
3179     default:
3180       break;
3181   }
3182 #ifdef ASSERT
3183   tty-&gt;print(&quot;need barrier on?: &quot;);
3184   tty-&gt;print_cr(&quot;ins:&quot;);
3185   n-&gt;dump(2);
3186   tty-&gt;print_cr(&quot;outs:&quot;);
3187   n-&gt;dump(-2);
3188   ShouldNotReachHere();
3189 #endif
3190   return true;
3191 }
3192 
<span class="line-modified">3193 bool ShenandoahLoadReferenceBarrierNode::is_redundant() {</span>
3194   Unique_Node_List visited;
3195   Node_Stack stack(0);
3196   stack.push(this, 0);
3197 
<span class="line-modified">3198   // Check if the barrier is actually useful: go over nodes looking for useful uses</span>
<span class="line-modified">3199   // (e.g. memory accesses). Stop once we detected a required use. Otherwise, walk</span>
<span class="line-modified">3200   // until we ran out of nodes, and then declare the barrier redundant.</span>
<span class="line-modified">3201   while (stack.size() &gt; 0) {</span>

3202     Node* n = stack.node();
3203     if (visited.member(n)) {
3204       stack.pop();
3205       continue;
3206     }
3207     visited.push(n);
3208     bool visit_users = false;
3209     switch (n-&gt;Opcode()) {
3210       case Op_CallStaticJava:
3211       case Op_CallDynamicJava:
3212       case Op_CallLeaf:
3213       case Op_CallLeafNoFP:
3214       case Op_CompareAndSwapL:
3215       case Op_CompareAndSwapI:
3216       case Op_CompareAndSwapB:
3217       case Op_CompareAndSwapS:
3218       case Op_CompareAndSwapN:
3219       case Op_CompareAndSwapP:
3220       case Op_CompareAndExchangeL:
3221       case Op_CompareAndExchangeI:
</pre>
<hr />
<pre>
3257       case Op_StoreL:
3258       case Op_StoreLConditional:
3259       case Op_StoreI:
3260       case Op_StoreIConditional:
3261       case Op_StoreN:
3262       case Op_StoreP:
3263       case Op_StoreVector:
3264       case Op_StrInflatedCopy:
3265       case Op_StrCompressedCopy:
3266       case Op_EncodeP:
3267       case Op_CastP2X:
3268       case Op_SafePoint:
3269       case Op_EncodeISOArray:
3270       case Op_AryEq:
3271       case Op_StrEquals:
3272       case Op_StrComp:
3273       case Op_StrIndexOf:
3274       case Op_StrIndexOfChar:
3275       case Op_HasNegatives:
3276         // Known to require barriers
<span class="line-modified">3277         return false;</span>

3278       case Op_CmpP: {
3279         if (n-&gt;in(1)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR) ||
3280             n-&gt;in(2)-&gt;bottom_type()-&gt;higher_equal(TypePtr::NULL_PTR)) {
3281           // One of the sides is known null, no need for barrier.
3282         } else {
<span class="line-modified">3283           return false;</span>
3284         }
3285         break;
3286       }
3287       case Op_LoadB:
3288       case Op_LoadUB:
3289       case Op_LoadUS:
3290       case Op_LoadD:
3291       case Op_LoadF:
3292       case Op_LoadL:
3293       case Op_LoadI:
3294       case Op_LoadS:
3295       case Op_LoadN:
3296       case Op_LoadP:
3297       case Op_LoadVector: {
3298         const TypePtr* adr_type = n-&gt;adr_type();
3299         int alias_idx = Compile::current()-&gt;get_alias_index(adr_type);
3300         Compile::AliasType* alias_type = Compile::current()-&gt;alias_type(alias_idx);
3301         ciField* field = alias_type-&gt;field();
3302         bool is_static = field != NULL &amp;&amp; field-&gt;is_static();
3303         bool is_final = field != NULL &amp;&amp; field-&gt;is_final();
3304 
3305         if (ShenandoahOptimizeStaticFinals &amp;&amp; is_static &amp;&amp; is_final) {
3306           // Loading the constant does not require barriers: it should be handled
3307           // as part of GC roots already.
3308         } else {
<span class="line-modified">3309           return false;</span>
3310         }
3311         break;
3312       }
3313       case Op_Conv2B:
3314       case Op_LoadRange:
3315       case Op_LoadKlass:
3316       case Op_LoadNKlass:
3317         // Do not require barriers
3318         break;
3319       case Op_AddP:
3320       case Op_CheckCastPP:
3321       case Op_CastPP:
3322       case Op_CMoveP:
3323       case Op_Phi:
3324       case Op_ShenandoahLoadReferenceBarrier:
3325         // Whether or not these need the barriers depends on their users
3326         visit_users = true;
3327         break;
3328       default: {
3329 #ifdef ASSERT
<span class="line-modified">3330         fatal(&quot;Unknown node in is_redundant: %s&quot;, NodeClassNames[n-&gt;Opcode()]);</span>
3331 #else
<span class="line-modified">3332         // Default to have excess barriers, rather than miss some.</span>
<span class="line-modified">3333         return false;</span>
3334 #endif
3335       }
3336     }
3337 
3338     stack.pop();
3339     if (visit_users) {
3340       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3341         Node* user = n-&gt;fast_out(i);
3342         if (user != NULL) {
3343           stack.push(user, 0);
3344         }
3345       }
3346     }
3347   }
<span class="line-modified">3348 </span>
<span class="line-added">3349   // No need for barrier found.</span>
<span class="line-added">3350   return true;</span>
3351 }
3352 
3353 CallStaticJavaNode* ShenandoahLoadReferenceBarrierNode::pin_and_expand_null_check(PhaseIterGVN&amp; igvn) {
3354   Node* val = in(ValueIn);
3355 
3356   const Type* val_t = igvn.type(val);
3357 
3358   if (val_t-&gt;meet(TypePtr::NULL_PTR) != val_t &amp;&amp;
3359       val-&gt;Opcode() == Op_CastPP &amp;&amp;
3360       val-&gt;in(0) != NULL &amp;&amp;
3361       val-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
3362       val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
3363       val-&gt;in(0)-&gt;in(0)-&gt;is_If() &amp;&amp;
3364       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;Opcode() == Op_Bool &amp;&amp;
3365       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::ne &amp;&amp;
3366       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpP &amp;&amp;
3367       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1) &amp;&amp;
3368       val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;bottom_type() == TypePtr::NULL_PTR) {
3369     assert(val-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val-&gt;in(1), &quot;&quot;);
3370     CallStaticJavaNode* unc = val-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
</pre>
</td>
</tr>
</table>
<center><a href="../../shared/gcCause.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="shenandoahSupport.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>