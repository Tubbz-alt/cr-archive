<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 2707 }
 2708 
 2709 void MacroAssembler::divsd(XMMRegister dst, AddressLiteral src) {
 2710   if (reachable(src)) {
 2711     Assembler::divsd(dst, as_Address(src));
 2712   } else {
 2713     lea(rscratch1, src);
 2714     Assembler::divsd(dst, Address(rscratch1, 0));
 2715   }
 2716 }
 2717 
 2718 void MacroAssembler::divss(XMMRegister dst, AddressLiteral src) {
 2719   if (reachable(src)) {
 2720     Assembler::divss(dst, as_Address(src));
 2721   } else {
 2722     lea(rscratch1, src);
 2723     Assembler::divss(dst, Address(rscratch1, 0));
 2724   }
 2725 }
 2726 
<span class="line-removed"> 2727 #ifndef _LP64</span>
<span class="line-removed"> 2728 void MacroAssembler::empty_FPU_stack() {</span>
<span class="line-removed"> 2729   if (VM_Version::supports_mmx()) {</span>
<span class="line-removed"> 2730     emms();</span>
<span class="line-removed"> 2731   } else {</span>
<span class="line-removed"> 2732     for (int i = 8; i-- &gt; 0; ) ffree(i);</span>
<span class="line-removed"> 2733   }</span>
<span class="line-removed"> 2734 }</span>
<span class="line-removed"> 2735 #endif // !LP64</span>
<span class="line-removed"> 2736 </span>
<span class="line-removed"> 2737 </span>
 2738 void MacroAssembler::enter() {
 2739   push(rbp);
 2740   mov(rbp, rsp);
 2741 }
 2742 
 2743 // A 5 byte nop that is safe for patching (see patch_verified_entry)
 2744 void MacroAssembler::fat_nop() {
 2745   if (UseAddressNop) {
 2746     addr_nop_5();
 2747   } else {
 2748     emit_int8(0x26); // es:
 2749     emit_int8(0x2e); // cs:
 2750     emit_int8(0x64); // fs:
 2751     emit_int8(0x65); // gs:
 2752     emit_int8((unsigned char)0x90);
 2753   }
 2754 }
 2755 
<span class="line-modified"> 2756 #if !defined(_LP64)</span>
 2757 void MacroAssembler::fcmp(Register tmp) {
 2758   fcmp(tmp, 1, true, true);
 2759 }
 2760 
 2761 void MacroAssembler::fcmp(Register tmp, int index, bool pop_left, bool pop_right) {
 2762   assert(!pop_right || pop_left, &quot;usage error&quot;);
 2763   if (VM_Version::supports_cmov()) {
 2764     assert(tmp == noreg, &quot;unneeded temp&quot;);
 2765     if (pop_left) {
 2766       fucomip(index);
 2767     } else {
 2768       fucomi(index);
 2769     }
 2770     if (pop_right) {
 2771       fpop();
 2772     }
 2773   } else {
 2774     assert(tmp != noreg, &quot;need temp&quot;);
 2775     if (pop_left) {
 2776       if (pop_right) {
</pre>
<hr />
<pre>
 2835   ffree();
 2836   fincstp();
 2837 }
 2838 
 2839 void MacroAssembler::fremr(Register tmp) {
 2840   save_rax(tmp);
 2841   { Label L;
 2842     bind(L);
 2843     fprem();
 2844     fwait(); fnstsw_ax();
 2845     sahf();
 2846     jcc(Assembler::parity, L);
 2847   }
 2848   restore_rax(tmp);
 2849   // Result is in ST0.
 2850   // Note: fxch &amp; fpop to get rid of ST1
 2851   // (otherwise FPU stack could overflow eventually)
 2852   fxch(1);
 2853   fpop();
 2854 }








 2855 #endif // !LP64
 2856 
 2857 void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src) {
 2858   if (reachable(src)) {
 2859     Assembler::mulpd(dst, as_Address(src));
 2860   } else {
 2861     lea(rscratch1, src);
 2862     Assembler::mulpd(dst, Address(rscratch1, 0));
 2863   }
 2864 }
 2865 
 2866 void MacroAssembler::load_float(Address src) {



 2867   if (UseSSE &gt;= 1) {
 2868     movflt(xmm0, src);
 2869   } else {
<span class="line-modified"> 2870     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2871     NOT_LP64(fld_s(src));</span>
 2872   }

 2873 }
 2874 
 2875 void MacroAssembler::store_float(Address dst) {



 2876   if (UseSSE &gt;= 1) {
 2877     movflt(dst, xmm0);
 2878   } else {
<span class="line-modified"> 2879     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2880     NOT_LP64(fstp_s(dst));</span>
 2881   }

 2882 }
 2883 
 2884 void MacroAssembler::load_double(Address src) {



 2885   if (UseSSE &gt;= 2) {
 2886     movdbl(xmm0, src);
 2887   } else {
<span class="line-modified"> 2888     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2889     NOT_LP64(fld_d(src));</span>
 2890   }

 2891 }
 2892 
 2893 void MacroAssembler::store_double(Address dst) {



 2894   if (UseSSE &gt;= 2) {
 2895     movdbl(dst, xmm0);
 2896   } else {
<span class="line-modified"> 2897     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2898     NOT_LP64(fstp_d(dst));</span>
 2899   }

 2900 }
 2901 
 2902 // dst = c = a * b + c
 2903 void MacroAssembler::fmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2904   Assembler::vfmadd231sd(c, a, b);
 2905   if (dst != c) {
 2906     movdbl(dst, c);
 2907   }
 2908 }
 2909 
 2910 // dst = c = a * b + c
 2911 void MacroAssembler::fmaf(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2912   Assembler::vfmadd231ss(c, a, b);
 2913   if (dst != c) {
 2914     movflt(dst, c);
 2915   }
 2916 }
 2917 
 2918 // dst = c = a * b + c
 2919 void MacroAssembler::vfmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c, int vector_len) {
</pre>
</td>
<td>
<hr />
<pre>
 2707 }
 2708 
 2709 void MacroAssembler::divsd(XMMRegister dst, AddressLiteral src) {
 2710   if (reachable(src)) {
 2711     Assembler::divsd(dst, as_Address(src));
 2712   } else {
 2713     lea(rscratch1, src);
 2714     Assembler::divsd(dst, Address(rscratch1, 0));
 2715   }
 2716 }
 2717 
 2718 void MacroAssembler::divss(XMMRegister dst, AddressLiteral src) {
 2719   if (reachable(src)) {
 2720     Assembler::divss(dst, as_Address(src));
 2721   } else {
 2722     lea(rscratch1, src);
 2723     Assembler::divss(dst, Address(rscratch1, 0));
 2724   }
 2725 }
 2726 











 2727 void MacroAssembler::enter() {
 2728   push(rbp);
 2729   mov(rbp, rsp);
 2730 }
 2731 
 2732 // A 5 byte nop that is safe for patching (see patch_verified_entry)
 2733 void MacroAssembler::fat_nop() {
 2734   if (UseAddressNop) {
 2735     addr_nop_5();
 2736   } else {
 2737     emit_int8(0x26); // es:
 2738     emit_int8(0x2e); // cs:
 2739     emit_int8(0x64); // fs:
 2740     emit_int8(0x65); // gs:
 2741     emit_int8((unsigned char)0x90);
 2742   }
 2743 }
 2744 
<span class="line-modified"> 2745 #ifndef _LP64</span>
 2746 void MacroAssembler::fcmp(Register tmp) {
 2747   fcmp(tmp, 1, true, true);
 2748 }
 2749 
 2750 void MacroAssembler::fcmp(Register tmp, int index, bool pop_left, bool pop_right) {
 2751   assert(!pop_right || pop_left, &quot;usage error&quot;);
 2752   if (VM_Version::supports_cmov()) {
 2753     assert(tmp == noreg, &quot;unneeded temp&quot;);
 2754     if (pop_left) {
 2755       fucomip(index);
 2756     } else {
 2757       fucomi(index);
 2758     }
 2759     if (pop_right) {
 2760       fpop();
 2761     }
 2762   } else {
 2763     assert(tmp != noreg, &quot;need temp&quot;);
 2764     if (pop_left) {
 2765       if (pop_right) {
</pre>
<hr />
<pre>
 2824   ffree();
 2825   fincstp();
 2826 }
 2827 
 2828 void MacroAssembler::fremr(Register tmp) {
 2829   save_rax(tmp);
 2830   { Label L;
 2831     bind(L);
 2832     fprem();
 2833     fwait(); fnstsw_ax();
 2834     sahf();
 2835     jcc(Assembler::parity, L);
 2836   }
 2837   restore_rax(tmp);
 2838   // Result is in ST0.
 2839   // Note: fxch &amp; fpop to get rid of ST1
 2840   // (otherwise FPU stack could overflow eventually)
 2841   fxch(1);
 2842   fpop();
 2843 }
<span class="line-added"> 2844 </span>
<span class="line-added"> 2845 void MacroAssembler::empty_FPU_stack() {</span>
<span class="line-added"> 2846   if (VM_Version::supports_mmx()) {</span>
<span class="line-added"> 2847     emms();</span>
<span class="line-added"> 2848   } else {</span>
<span class="line-added"> 2849     for (int i = 8; i-- &gt; 0; ) ffree(i);</span>
<span class="line-added"> 2850   }</span>
<span class="line-added"> 2851 }</span>
 2852 #endif // !LP64
 2853 
 2854 void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src) {
 2855   if (reachable(src)) {
 2856     Assembler::mulpd(dst, as_Address(src));
 2857   } else {
 2858     lea(rscratch1, src);
 2859     Assembler::mulpd(dst, Address(rscratch1, 0));
 2860   }
 2861 }
 2862 
 2863 void MacroAssembler::load_float(Address src) {
<span class="line-added"> 2864 #ifdef _LP64</span>
<span class="line-added"> 2865   movflt(xmm0, src);</span>
<span class="line-added"> 2866 #else</span>
 2867   if (UseSSE &gt;= 1) {
 2868     movflt(xmm0, src);
 2869   } else {
<span class="line-modified"> 2870     fld_s(src);</span>

 2871   }
<span class="line-added"> 2872 #endif // LP64</span>
 2873 }
 2874 
 2875 void MacroAssembler::store_float(Address dst) {
<span class="line-added"> 2876 #ifdef _LP64</span>
<span class="line-added"> 2877   movflt(dst, xmm0);</span>
<span class="line-added"> 2878 #else</span>
 2879   if (UseSSE &gt;= 1) {
 2880     movflt(dst, xmm0);
 2881   } else {
<span class="line-modified"> 2882     fstp_s(dst);</span>

 2883   }
<span class="line-added"> 2884 #endif // LP64</span>
 2885 }
 2886 
 2887 void MacroAssembler::load_double(Address src) {
<span class="line-added"> 2888 #ifdef _LP64</span>
<span class="line-added"> 2889   movdbl(xmm0, src);</span>
<span class="line-added"> 2890 #else</span>
 2891   if (UseSSE &gt;= 2) {
 2892     movdbl(xmm0, src);
 2893   } else {
<span class="line-modified"> 2894     fld_d(src);</span>

 2895   }
<span class="line-added"> 2896 #endif // LP64</span>
 2897 }
 2898 
 2899 void MacroAssembler::store_double(Address dst) {
<span class="line-added"> 2900 #ifdef _LP64</span>
<span class="line-added"> 2901   movdbl(dst, xmm0);</span>
<span class="line-added"> 2902 #else</span>
 2903   if (UseSSE &gt;= 2) {
 2904     movdbl(dst, xmm0);
 2905   } else {
<span class="line-modified"> 2906     fstp_d(dst);</span>

 2907   }
<span class="line-added"> 2908 #endif // LP64</span>
 2909 }
 2910 
 2911 // dst = c = a * b + c
 2912 void MacroAssembler::fmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2913   Assembler::vfmadd231sd(c, a, b);
 2914   if (dst != c) {
 2915     movdbl(dst, c);
 2916   }
 2917 }
 2918 
 2919 // dst = c = a * b + c
 2920 void MacroAssembler::fmaf(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2921   Assembler::vfmadd231ss(c, a, b);
 2922   if (dst != c) {
 2923     movflt(dst, c);
 2924   }
 2925 }
 2926 
 2927 // dst = c = a * b + c
 2928 void MacroAssembler::vfmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c, int vector_len) {
</pre>
</td>
</tr>
</table>
<center><a href="globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>