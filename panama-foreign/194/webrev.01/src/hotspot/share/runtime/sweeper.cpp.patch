diff a/src/hotspot/share/runtime/sweeper.cpp b/src/hotspot/share/runtime/sweeper.cpp
--- a/src/hotspot/share/runtime/sweeper.cpp
+++ b/src/hotspot/share/runtime/sweeper.cpp
@@ -79,44 +79,10 @@
 };
 
 static int _sweep_index = 0;
 static SweeperRecord* _records = NULL;
 
-void NMethodSweeper::report_events(int id, address entry) {
-  if (_records != NULL) {
-    for (int i = _sweep_index; i < SweeperLogEntries; i++) {
-      if (_records[i].uep == entry ||
-          _records[i].vep == entry ||
-          _records[i].compile_id == id) {
-        _records[i].print();
-      }
-    }
-    for (int i = 0; i < _sweep_index; i++) {
-      if (_records[i].uep == entry ||
-          _records[i].vep == entry ||
-          _records[i].compile_id == id) {
-        _records[i].print();
-      }
-    }
-  }
-}
-
-void NMethodSweeper::report_events() {
-  if (_records != NULL) {
-    for (int i = _sweep_index; i < SweeperLogEntries; i++) {
-      // skip empty records
-      if (_records[i].vep == NULL) continue;
-      _records[i].print();
-    }
-    for (int i = 0; i < _sweep_index; i++) {
-      // skip empty records
-      if (_records[i].vep == NULL) continue;
-      _records[i].print();
-    }
-  }
-}
-
 void NMethodSweeper::record_sweep(CompiledMethod* nm, int line) {
   if (_records != NULL) {
     _records[_sweep_index].traversal = _traversals;
     _records[_sweep_index].traversal_mark = nm->is_nmethod() ? ((nmethod*)nm)->stack_traversal_mark() : 0;
     _records[_sweep_index].compile_id = nm->compile_id();
@@ -141,17 +107,16 @@
 #endif
 
 CompiledMethodIterator NMethodSweeper::_current(CompiledMethodIterator::all_blobs); // Current compiled method
 long     NMethodSweeper::_traversals                   = 0;    // Stack scan count, also sweep ID.
 long     NMethodSweeper::_total_nof_code_cache_sweeps  = 0;    // Total number of full sweeps of the code cache
-long     NMethodSweeper::_time_counter                 = 0;    // Virtual time used to periodically invoke sweeper
-long     NMethodSweeper::_last_sweep                   = 0;    // Value of _time_counter when the last sweep happened
 int      NMethodSweeper::_seen                         = 0;    // Nof. nmethod we have currently processed in current pass of CodeCache
+size_t   NMethodSweeper::_sweep_threshold_bytes        = 0;    // Threshold for when to sweep. Updated after ergonomics
 
-volatile bool NMethodSweeper::_should_sweep            = false;// Indicates if we should invoke the sweeper
-volatile bool NMethodSweeper::_force_sweep             = false;// Indicates if we should force a sweep
-volatile int  NMethodSweeper::_bytes_changed           = 0;    // Counts the total nmethod size if the nmethod changed from:
+volatile bool NMethodSweeper::_should_sweep            = false;// Indicates if a normal sweep will be done
+volatile bool NMethodSweeper::_force_sweep             = false;// Indicates if a forced sweep will be done
+volatile size_t NMethodSweeper::_bytes_changed         = 0;    // Counts the total nmethod size if the nmethod changed from:
                                                                //   1) alive       -> not_entrant
                                                                //   2) not_entrant -> zombie
 int    NMethodSweeper::_hotness_counter_reset_val       = 0;
 
 long   NMethodSweeper::_total_nof_methods_reclaimed     = 0;   // Accumulated nof methods flushed
@@ -208,48 +173,10 @@
       jt->nmethods_do(_cl);
     }
   }
 };
 
-class NMethodMarkingTask : public AbstractGangTask {
-private:
-  NMethodMarkingClosure* _cl;
-public:
-  NMethodMarkingTask(NMethodMarkingClosure* cl) :
-    AbstractGangTask("Parallel NMethod Marking"),
-    _cl(cl) {
-    Threads::change_thread_claim_token();
-  }
-
-  ~NMethodMarkingTask() {
-    Threads::assert_all_threads_claimed();
-  }
-
-  void work(uint worker_id) {
-    Threads::possibly_parallel_threads_do(true, _cl);
-  }
-};
-
-/**
-  * Scans the stacks of all Java threads and marks activations of not-entrant methods.
-  * No need to synchronize access, since 'mark_active_nmethods' is always executed at a
-  * safepoint.
-  */
-void NMethodSweeper::mark_active_nmethods() {
-  CodeBlobClosure* cl = prepare_mark_active_nmethods();
-  if (cl != NULL) {
-    WorkGang* workers = Universe::heap()->get_safepoint_workers();
-    if (workers != NULL) {
-      NMethodMarkingClosure tcl(cl);
-      NMethodMarkingTask task(&tcl);
-      workers->run_task(&task);
-    } else {
-      Threads::nmethods_do(cl);
-    }
-  }
-}
-
 CodeBlobClosure* NMethodSweeper::prepare_mark_active_nmethods() {
 #ifdef ASSERT
   assert(Thread::current()->is_Code_cache_sweeper_thread(), "must be executed under CodeCache_lock and in sweeper thread");
   assert_lock_strong(CodeCache_lock);
 #endif
@@ -258,13 +185,10 @@
   // to scan stacks
   if (!MethodFlushing) {
     return NULL;
   }
 
-  // Increase time so that we can estimate when to invoke the sweeper again.
-  _time_counter++;
-
   // Check for restart
   assert(_current.method() == NULL, "should only happen between sweeper cycles");
   assert(wait_for_stack_scanning(), "should only happen between sweeper cycles");
 
   _seen = 0;
@@ -287,13 +211,10 @@
   // to scan stacks
   if (!MethodFlushing) {
     return NULL;
   }
 
-  // Increase time so that we can estimate when to invoke the sweeper again.
-  _time_counter++;
-
   // Check for restart
   if (_current.method() != NULL) {
     if (_current.method()->is_nmethod()) {
       assert(CodeCache::find_blob_unsafe(_current.method()) == _current.method(), "Sweeper nmethod cached state invalid");
     } else if (_current.method()->is_aot()) {
@@ -328,46 +249,51 @@
 void NMethodSweeper::sweeper_loop() {
   bool timeout;
   while (true) {
     {
       ThreadBlockInVM tbivm(JavaThread::current());
-      MonitorLocker waiter(CodeCache_lock, Mutex::_no_safepoint_check_flag);
+      MonitorLocker waiter(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
       const long wait_time = 60*60*24 * 1000;
       timeout = waiter.wait(wait_time);
     }
-    if (!timeout) {
-      possibly_sweep();
+    if (!timeout && (_should_sweep || _force_sweep)) {
+      sweep();
     }
   }
 }
 
 /**
-  * Wakes up the sweeper thread to possibly sweep.
+  * Wakes up the sweeper thread to sweep if code cache space runs low
   */
-void NMethodSweeper::notify(int code_blob_type) {
+void NMethodSweeper::report_allocation(int code_blob_type) {
+  if (should_start_aggressive_sweep(code_blob_type)) {
+    MonitorLocker waiter(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
+    _should_sweep = true;
+    CodeSweeper_lock->notify();
+  }
+}
+
+bool NMethodSweeper::should_start_aggressive_sweep(int code_blob_type) {
   // Makes sure that we do not invoke the sweeper too often during startup.
   double start_threshold = 100.0 / (double)StartAggressiveSweepingAt;
-  double aggressive_sweep_threshold = MIN2(start_threshold, 1.1);
-  if (CodeCache::reverse_free_ratio(code_blob_type) >= aggressive_sweep_threshold) {
-    assert_locked_or_safepoint(CodeCache_lock);
-    CodeCache_lock->notify();
-  }
+  double aggressive_sweep_threshold = MAX2(start_threshold, 1.1);
+  return (CodeCache::reverse_free_ratio(code_blob_type) >= aggressive_sweep_threshold);
 }
 
 /**
   * Wakes up the sweeper thread and forces a sweep. Blocks until it finished.
   */
 void NMethodSweeper::force_sweep() {
   ThreadBlockInVM tbivm(JavaThread::current());
-  MonitorLocker waiter(CodeCache_lock, Mutex::_no_safepoint_check_flag);
+  MonitorLocker waiter(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
   // Request forced sweep
   _force_sweep = true;
   while (_force_sweep) {
     // Notify sweeper that we want to force a sweep and wait for completion.
     // In case a sweep currently takes place we timeout and try again because
     // we want to enforce a full sweep.
-    CodeCache_lock->notify();
+    CodeSweeper_lock->notify();
     waiter.wait(1000);
   }
 }
 
 /**
@@ -384,91 +310,32 @@
     ThreadBlockInVM tbivm(thread);
     thread->java_suspend_self();
   }
 }
 
-/**
- * This function invokes the sweeper if at least one of the three conditions is met:
- *    (1) The code cache is getting full
- *    (2) There are sufficient state changes in/since the last sweep.
- *    (3) We have not been sweeping for 'some time'
- */
-void NMethodSweeper::possibly_sweep() {
+void NMethodSweeper::sweep() {
+  assert(_should_sweep || _force_sweep, "must have been set");
   assert(JavaThread::current()->thread_state() == _thread_in_vm, "must run in vm mode");
-  // If there was no state change while nmethod sweeping, 'should_sweep' will be false.
-  // This is one of the two places where should_sweep can be set to true. The general
-  // idea is as follows: If there is enough free space in the code cache, there is no
-  // need to invoke the sweeper. The following formula (which determines whether to invoke
-  // the sweeper or not) depends on the assumption that for larger ReservedCodeCacheSizes
-  // we need less frequent sweeps than for smaller ReservedCodecCacheSizes. Furthermore,
-  // the formula considers how much space in the code cache is currently used. Here are
-  // some examples that will (hopefully) help in understanding.
-  //
-  // Small ReservedCodeCacheSizes:  (e.g., < 16M) We invoke the sweeper every time, since
-  //                                              the result of the division is 0. This
-  //                                              keeps the used code cache size small
-  //                                              (important for embedded Java)
-  // Large ReservedCodeCacheSize :  (e.g., 256M + code cache is 10% full). The formula
-  //                                              computes: (256 / 16) - 1 = 15
-  //                                              As a result, we invoke the sweeper after
-  //                                              15 invocations of 'mark_active_nmethods.
-  // Large ReservedCodeCacheSize:   (e.g., 256M + code Cache is 90% full). The formula
-  //                                              computes: (256 / 16) - 10 = 6.
-  if (!_should_sweep) {
-    const int time_since_last_sweep = _time_counter - _last_sweep;
-    // ReservedCodeCacheSize has an 'unsigned' type. We need a 'signed' type for max_wait_time,
-    // since 'time_since_last_sweep' can be larger than 'max_wait_time'. If that happens using
-    // an unsigned type would cause an underflow (wait_until_next_sweep becomes a large positive
-    // value) that disables the intended periodic sweeps.
-    const int max_wait_time = ReservedCodeCacheSize / (16 * M);
-    double wait_until_next_sweep = max_wait_time - time_since_last_sweep -
-        MAX2(CodeCache::reverse_free_ratio(CodeBlobType::MethodProfiled),
-             CodeCache::reverse_free_ratio(CodeBlobType::MethodNonProfiled));
-    assert(wait_until_next_sweep <= (double)max_wait_time, "Calculation of code cache sweeper interval is incorrect");
-
-    if ((wait_until_next_sweep <= 0.0) || !CompileBroker::should_compile_new_jobs()) {
-      _should_sweep = true;
-    }
+  Atomic::store(&_bytes_changed, static_cast<size_t>(0)); // reset regardless of sleep reason
+  if (_should_sweep) {
+    MutexLocker mu(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
+    _should_sweep = false;
   }
 
-  // Remember if this was a forced sweep
-  bool forced = _force_sweep;
-
-  // Force stack scanning if there is only 10% free space in the code cache.
-  // We force stack scanning only if the non-profiled code heap gets full, since critical
-  // allocations go to the non-profiled heap and we must be make sure that there is
-  // enough space.
-  double free_percent = 1 / CodeCache::reverse_free_ratio(CodeBlobType::MethodNonProfiled) * 100;
-  if (free_percent <= StartAggressiveSweepingAt || forced || _should_sweep) {
-    do_stack_scanning();
-  }
+  do_stack_scanning();
 
-  if (_should_sweep || forced) {
-    init_sweeper_log();
-    sweep_code_cache();
-  }
+  init_sweeper_log();
+  sweep_code_cache();
 
   // We are done with sweeping the code cache once.
   _total_nof_code_cache_sweeps++;
-  _last_sweep = _time_counter;
-  // Reset flag; temporarily disables sweeper
-  _should_sweep = false;
-  // If there was enough state change, 'possibly_enable_sweeper()'
-  // sets '_should_sweep' to true
-  possibly_enable_sweeper();
-  // Reset _bytes_changed only if there was enough state change. _bytes_changed
-  // can further increase by calls to 'report_state_change'.
-  if (_should_sweep) {
-    _bytes_changed = 0;
-  }
 
-  if (forced) {
+  if (_force_sweep) {
     // Notify requester that forced sweep finished
-    assert(_force_sweep, "Should be a forced sweep");
-    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);
+    MutexLocker mu(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
     _force_sweep = false;
-    CodeCache_lock->notify();
+    CodeSweeper_lock->notify();
   }
 }
 
 static void post_sweep_event(EventSweepCodeCache* event,
                              const Ticks& start,
@@ -607,32 +474,20 @@
     log.debug("restart compiler");
     log_sweep("restart_compiler");
   }
 }
 
-/**
- * This function updates the sweeper statistics that keep track of nmethods
- * state changes. If there is 'enough' state change, the sweeper is invoked
- * as soon as possible. There can be data races on _bytes_changed. The data
- * races are benign, since it does not matter if we loose a couple of bytes.
- * In the worst case we call the sweeper a little later. Also, we are guaranteed
- * to invoke the sweeper if the code cache gets full.
- */
+ // This function updates the sweeper statistics that keep track of nmethods
+ // state changes. If there is 'enough' state change, the sweeper is invoked
+ // as soon as possible. Also, we are guaranteed to invoke the sweeper if
+ // the code cache gets full.
 void NMethodSweeper::report_state_change(nmethod* nm) {
-  _bytes_changed += nm->total_size();
-  possibly_enable_sweeper();
-}
-
-/**
- * Function determines if there was 'enough' state change in the code cache to invoke
- * the sweeper again. Currently, we determine 'enough' as more than 1% state change in
- * the code cache since the last sweep.
- */
-void NMethodSweeper::possibly_enable_sweeper() {
-  double percent_changed = ((double)_bytes_changed / (double)ReservedCodeCacheSize) * 100;
-  if (percent_changed > 1.0) {
+  Atomic::add(&_bytes_changed, (size_t)nm->total_size());
+  if (Atomic::load(&_bytes_changed) > _sweep_threshold_bytes) {
+    MutexLocker mu(CodeSweeper_lock, Mutex::_no_safepoint_check_flag);
     _should_sweep = true;
+    CodeSweeper_lock->notify(); // Wake up sweeper.
   }
 }
 
 class CompiledMethodMarker: public StackObj {
  private:
