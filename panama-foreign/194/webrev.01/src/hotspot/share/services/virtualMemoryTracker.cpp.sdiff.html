<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/services/virtualMemoryTracker.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="threadService.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../utilities/hashtable.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/services/virtualMemoryTracker.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
522     size_t remaining_size = (_current_start + _current_size) - (committed_start + committed_size);
523     _current_start = committed_start + committed_size;
524     _current_size = remaining_size;
525     return true;
526   } else {
527     return false;
528   }
529 }
530 
531 // Walk all known thread stacks, snapshot their committed ranges.
532 class SnapshotThreadStackWalker : public VirtualMemoryWalker {
533 public:
534   SnapshotThreadStackWalker() {}
535 
536   bool do_allocation_site(const ReservedMemoryRegion* rgn) {
537     if (rgn-&gt;flag() == mtThreadStack) {
538       address stack_bottom = rgn-&gt;thread_stack_uncommitted_bottom();
539       address committed_start;
540       size_t  committed_size;
541       size_t stack_size = rgn-&gt;base() + rgn-&gt;size() - stack_bottom;


542 
543       ReservedMemoryRegion* region = const_cast&lt;ReservedMemoryRegion*&gt;(rgn);
544       NativeCallStack ncs; // empty stack
545 
<span class="line-modified">546       RegionIterator itr(stack_bottom, stack_size);</span>
547       DEBUG_ONLY(bool found_stack = false;)
548       while (itr.next_committed(committed_start, committed_size)) {
549         assert(committed_start != NULL, &quot;Should not be null&quot;);
550         assert(committed_size &gt; 0, &quot;Should not be 0&quot;);




551         region-&gt;add_committed_region(committed_start, committed_size, ncs);
552         DEBUG_ONLY(found_stack = true;)
553       }
554 #ifdef ASSERT
555       if (!found_stack) {
556         log_debug(thread)(&quot;Thread exited without proper cleanup, may leak thread object&quot;);
557       }
558 #endif
559     }
560     return true;
561   }
562 };
563 
564 void VirtualMemoryTracker::snapshot_thread_stacks() {
565   SnapshotThreadStackWalker walker;
566   walk_virtual_memory(&amp;walker);
567 }
568 
569 bool VirtualMemoryTracker::walk_virtual_memory(VirtualMemoryWalker* walker) {
570   assert(_reserved_regions != NULL, &quot;Sanity check&quot;);
</pre>
</td>
<td>
<hr />
<pre>
522     size_t remaining_size = (_current_start + _current_size) - (committed_start + committed_size);
523     _current_start = committed_start + committed_size;
524     _current_size = remaining_size;
525     return true;
526   } else {
527     return false;
528   }
529 }
530 
531 // Walk all known thread stacks, snapshot their committed ranges.
532 class SnapshotThreadStackWalker : public VirtualMemoryWalker {
533 public:
534   SnapshotThreadStackWalker() {}
535 
536   bool do_allocation_site(const ReservedMemoryRegion* rgn) {
537     if (rgn-&gt;flag() == mtThreadStack) {
538       address stack_bottom = rgn-&gt;thread_stack_uncommitted_bottom();
539       address committed_start;
540       size_t  committed_size;
541       size_t stack_size = rgn-&gt;base() + rgn-&gt;size() - stack_bottom;
<span class="line-added">542       // Align the size to work with full pages (Alpine and AIX stack top is not page aligned)</span>
<span class="line-added">543       size_t aligned_stack_size = align_up(stack_size, os::vm_page_size());</span>
544 
545       ReservedMemoryRegion* region = const_cast&lt;ReservedMemoryRegion*&gt;(rgn);
546       NativeCallStack ncs; // empty stack
547 
<span class="line-modified">548       RegionIterator itr(stack_bottom, aligned_stack_size);</span>
549       DEBUG_ONLY(bool found_stack = false;)
550       while (itr.next_committed(committed_start, committed_size)) {
551         assert(committed_start != NULL, &quot;Should not be null&quot;);
552         assert(committed_size &gt; 0, &quot;Should not be 0&quot;);
<span class="line-added">553         // unaligned stack_size case: correct the region to fit the actual stack_size</span>
<span class="line-added">554         if (stack_bottom + stack_size &lt; committed_start + committed_size) {</span>
<span class="line-added">555           committed_size = stack_bottom + stack_size - committed_start;</span>
<span class="line-added">556         }</span>
557         region-&gt;add_committed_region(committed_start, committed_size, ncs);
558         DEBUG_ONLY(found_stack = true;)
559       }
560 #ifdef ASSERT
561       if (!found_stack) {
562         log_debug(thread)(&quot;Thread exited without proper cleanup, may leak thread object&quot;);
563       }
564 #endif
565     }
566     return true;
567   }
568 };
569 
570 void VirtualMemoryTracker::snapshot_thread_stacks() {
571   SnapshotThreadStackWalker walker;
572   walk_virtual_memory(&amp;walker);
573 }
574 
575 bool VirtualMemoryTracker::walk_virtual_memory(VirtualMemoryWalker* walker) {
576   assert(_reserved_regions != NULL, &quot;Sanity check&quot;);
</pre>
</td>
</tr>
</table>
<center><a href="threadService.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../utilities/hashtable.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>