<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/opto/loopnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciMethodData.hpp&quot;
  27 #include &quot;compiler/compileLog.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  30 #include &quot;libadt/vectset.hpp&quot;
  31 #include &quot;memory/allocation.inline.hpp&quot;
  32 #include &quot;memory/resourceArea.hpp&quot;
  33 #include &quot;opto/addnode.hpp&quot;
  34 #include &quot;opto/arraycopynode.hpp&quot;
  35 #include &quot;opto/callnode.hpp&quot;
  36 #include &quot;opto/connode.hpp&quot;
  37 #include &quot;opto/convertnode.hpp&quot;
  38 #include &quot;opto/divnode.hpp&quot;
  39 #include &quot;opto/idealGraphPrinter.hpp&quot;
  40 #include &quot;opto/loopnode.hpp&quot;
  41 #include &quot;opto/movenode.hpp&quot;
  42 #include &quot;opto/mulnode.hpp&quot;
  43 #include &quot;opto/rootnode.hpp&quot;
  44 #include &quot;opto/superword.hpp&quot;
  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 
  47 //=============================================================================
  48 //--------------------------is_cloop_ind_var-----------------------------------
  49 // Determine if a node is a counted loop induction variable.
  50 // NOTE: The method is declared in &quot;node.hpp&quot;.
  51 bool Node::is_cloop_ind_var() const {
  52   return (is_Phi() &amp;&amp; !as_Phi()-&gt;is_copy() &amp;&amp;
  53           as_Phi()-&gt;region()-&gt;is_CountedLoop() &amp;&amp;
  54           as_Phi()-&gt;region()-&gt;as_CountedLoop()-&gt;phi() == this);
  55 }
  56 
  57 //=============================================================================
  58 //------------------------------dump_spec--------------------------------------
  59 // Dump special per-node info
  60 #ifndef PRODUCT
  61 void LoopNode::dump_spec(outputStream *st) const {
  62   if (is_inner_loop()) st-&gt;print( &quot;inner &quot; );
  63   if (is_partial_peel_loop()) st-&gt;print( &quot;partial_peel &quot; );
  64   if (partial_peel_has_failed()) st-&gt;print( &quot;partial_peel_failed &quot; );
  65 }
  66 #endif
  67 
  68 //------------------------------is_valid_counted_loop-------------------------
  69 bool LoopNode::is_valid_counted_loop() const {
  70   if (is_CountedLoop()) {
  71     CountedLoopNode*    l  = as_CountedLoop();
  72     CountedLoopEndNode* le = l-&gt;loopexit_or_null();
  73     if (le != NULL &amp;&amp;
  74         le-&gt;proj_out_or_null(1 /* true */) == l-&gt;in(LoopNode::LoopBackControl)) {
  75       Node* phi  = l-&gt;phi();
  76       Node* exit = le-&gt;proj_out_or_null(0 /* false */);
  77       if (exit != NULL &amp;&amp; exit-&gt;Opcode() == Op_IfFalse &amp;&amp;
  78           phi != NULL &amp;&amp; phi-&gt;is_Phi() &amp;&amp;
  79           phi-&gt;in(LoopNode::LoopBackControl) == l-&gt;incr() &amp;&amp;
  80           le-&gt;loopnode() == l &amp;&amp; le-&gt;stride_is_con()) {
  81         return true;
  82       }
  83     }
  84   }
  85   return false;
  86 }
  87 
  88 //------------------------------get_early_ctrl---------------------------------
  89 // Compute earliest legal control
  90 Node *PhaseIdealLoop::get_early_ctrl( Node *n ) {
  91   assert( !n-&gt;is_Phi() &amp;&amp; !n-&gt;is_CFG(), &quot;this code only handles data nodes&quot; );
  92   uint i;
  93   Node *early;
  94   if (n-&gt;in(0) &amp;&amp; !n-&gt;is_expensive()) {
  95     early = n-&gt;in(0);
  96     if (!early-&gt;is_CFG()) // Might be a non-CFG multi-def
  97       early = get_ctrl(early);        // So treat input as a straight data input
  98     i = 1;
  99   } else {
 100     early = get_ctrl(n-&gt;in(1));
 101     i = 2;
 102   }
 103   uint e_d = dom_depth(early);
 104   assert( early, &quot;&quot; );
 105   for (; i &lt; n-&gt;req(); i++) {
 106     Node *cin = get_ctrl(n-&gt;in(i));
 107     assert( cin, &quot;&quot; );
 108     // Keep deepest dominator depth
 109     uint c_d = dom_depth(cin);
 110     if (c_d &gt; e_d) {           // Deeper guy?
 111       early = cin;              // Keep deepest found so far
 112       e_d = c_d;
 113     } else if (c_d == e_d &amp;&amp;    // Same depth?
 114                early != cin) { // If not equal, must use slower algorithm
 115       // If same depth but not equal, one _must_ dominate the other
 116       // and we want the deeper (i.e., dominated) guy.
 117       Node *n1 = early;
 118       Node *n2 = cin;
 119       while (1) {
 120         n1 = idom(n1);          // Walk up until break cycle
 121         n2 = idom(n2);
 122         if (n1 == cin ||        // Walked early up to cin
 123             dom_depth(n2) &lt; c_d)
 124           break;                // early is deeper; keep him
 125         if (n2 == early ||      // Walked cin up to early
 126             dom_depth(n1) &lt; c_d) {
 127           early = cin;          // cin is deeper; keep him
 128           break;
 129         }
 130       }
 131       e_d = dom_depth(early);   // Reset depth register cache
 132     }
 133   }
 134 
 135   // Return earliest legal location
 136   assert(early == find_non_split_ctrl(early), &quot;unexpected early control&quot;);
 137 
 138   if (n-&gt;is_expensive() &amp;&amp; !_verify_only &amp;&amp; !_verify_me) {
 139     assert(n-&gt;in(0), &quot;should have control input&quot;);
 140     early = get_early_ctrl_for_expensive(n, early);
 141   }
 142 
 143   return early;
 144 }
 145 
 146 //------------------------------get_early_ctrl_for_expensive---------------------------------
 147 // Move node up the dominator tree as high as legal while still beneficial
 148 Node *PhaseIdealLoop::get_early_ctrl_for_expensive(Node *n, Node* earliest) {
 149   assert(n-&gt;in(0) &amp;&amp; n-&gt;is_expensive(), &quot;expensive node with control input here&quot;);
 150   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
 151 
 152   Node* ctl = n-&gt;in(0);
 153   assert(ctl-&gt;is_CFG(), &quot;expensive input 0 must be cfg&quot;);
 154   uint min_dom_depth = dom_depth(earliest);
 155 #ifdef ASSERT
 156   if (!is_dominator(ctl, earliest) &amp;&amp; !is_dominator(earliest, ctl)) {
 157     dump_bad_graph(&quot;Bad graph detected in get_early_ctrl_for_expensive&quot;, n, earliest, ctl);
 158     assert(false, &quot;Bad graph detected in get_early_ctrl_for_expensive&quot;);
 159   }
 160 #endif
 161   if (dom_depth(ctl) &lt; min_dom_depth) {
 162     return earliest;
 163   }
 164 
 165   while (1) {
 166     Node *next = ctl;
 167     // Moving the node out of a loop on the projection of a If
 168     // confuses loop predication. So once we hit a Loop in a If branch
 169     // that doesn&#39;t branch to an UNC, we stop. The code that process
 170     // expensive nodes will notice the loop and skip over it to try to
 171     // move the node further up.
 172     if (ctl-&gt;is_CountedLoop() &amp;&amp; ctl-&gt;in(1) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0) != NULL &amp;&amp; ctl-&gt;in(1)-&gt;in(0)-&gt;is_If()) {
 173       if (!ctl-&gt;in(1)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 174         break;
 175       }
 176       next = idom(ctl-&gt;in(1)-&gt;in(0));
 177     } else if (ctl-&gt;is_Proj()) {
 178       // We only move it up along a projection if the projection is
 179       // the single control projection for its parent: same code path,
 180       // if it&#39;s a If with UNC or fallthrough of a call.
 181       Node* parent_ctl = ctl-&gt;in(0);
 182       if (parent_ctl == NULL) {
 183         break;
 184       } else if (parent_ctl-&gt;is_CountedLoopEnd() &amp;&amp; parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode() != NULL) {
 185         next = parent_ctl-&gt;as_CountedLoopEnd()-&gt;loopnode()-&gt;init_control();
 186       } else if (parent_ctl-&gt;is_If()) {
 187         if (!ctl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none)) {
 188           break;
 189         }
 190         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 191         next = idom(parent_ctl);
 192       } else if (ctl-&gt;is_CatchProj()) {
 193         if (ctl-&gt;as_Proj()-&gt;_con != CatchProjNode::fall_through_index) {
 194           break;
 195         }
 196         assert(parent_ctl-&gt;in(0)-&gt;in(0)-&gt;is_Call(), &quot;strange graph&quot;);
 197         next = parent_ctl-&gt;in(0)-&gt;in(0)-&gt;in(0);
 198       } else {
 199         // Check if parent control has a single projection (this
 200         // control is the only possible successor of the parent
 201         // control). If so, we can try to move the node above the
 202         // parent control.
 203         int nb_ctl_proj = 0;
 204         for (DUIterator_Fast imax, i = parent_ctl-&gt;fast_outs(imax); i &lt; imax; i++) {
 205           Node *p = parent_ctl-&gt;fast_out(i);
 206           if (p-&gt;is_Proj() &amp;&amp; p-&gt;is_CFG()) {
 207             nb_ctl_proj++;
 208             if (nb_ctl_proj &gt; 1) {
 209               break;
 210             }
 211           }
 212         }
 213 
 214         if (nb_ctl_proj &gt; 1) {
 215           break;
 216         }
 217         assert(parent_ctl-&gt;is_Start() || parent_ctl-&gt;is_MemBar() || parent_ctl-&gt;is_Call() ||
 218                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(parent_ctl), &quot;unexpected node&quot;);
 219         assert(idom(ctl) == parent_ctl, &quot;strange&quot;);
 220         next = idom(parent_ctl);
 221       }
 222     } else {
 223       next = idom(ctl);
 224     }
 225     if (next-&gt;is_Root() || next-&gt;is_Start() || dom_depth(next) &lt; min_dom_depth) {
 226       break;
 227     }
 228     ctl = next;
 229   }
 230 
 231   if (ctl != n-&gt;in(0)) {
 232     _igvn.replace_input_of(n, 0, ctl);
 233     _igvn.hash_insert(n);
 234   }
 235 
 236   return ctl;
 237 }
 238 
 239 
 240 //------------------------------set_early_ctrl---------------------------------
 241 // Set earliest legal control
 242 void PhaseIdealLoop::set_early_ctrl( Node *n ) {
 243   Node *early = get_early_ctrl(n);
 244 
 245   // Record earliest legal location
 246   set_ctrl(n, early);
 247 }
 248 
 249 //------------------------------set_subtree_ctrl-------------------------------
 250 // set missing _ctrl entries on new nodes
 251 void PhaseIdealLoop::set_subtree_ctrl( Node *n ) {
 252   // Already set?  Get out.
 253   if( _nodes[n-&gt;_idx] ) return;
 254   // Recursively set _nodes array to indicate where the Node goes
 255   uint i;
 256   for( i = 0; i &lt; n-&gt;req(); ++i ) {
 257     Node *m = n-&gt;in(i);
 258     if( m &amp;&amp; m != C-&gt;root() )
 259       set_subtree_ctrl( m );
 260   }
 261 
 262   // Fixup self
 263   set_early_ctrl( n );
 264 }
 265 
 266 IdealLoopTree* PhaseIdealLoop::insert_outer_loop(IdealLoopTree* loop, LoopNode* outer_l, Node* outer_ift) {
 267   IdealLoopTree* outer_ilt = new IdealLoopTree(this, outer_l, outer_ift);
 268   IdealLoopTree* parent = loop-&gt;_parent;
 269   IdealLoopTree* sibling = parent-&gt;_child;
 270   if (sibling == loop) {
 271     parent-&gt;_child = outer_ilt;
 272   } else {
 273     while (sibling-&gt;_next != loop) {
 274       sibling = sibling-&gt;_next;
 275     }
 276     sibling-&gt;_next = outer_ilt;
 277   }
 278   outer_ilt-&gt;_next = loop-&gt;_next;
 279   outer_ilt-&gt;_parent = parent;
 280   outer_ilt-&gt;_child = loop;
 281   outer_ilt-&gt;_nest = loop-&gt;_nest;
 282   loop-&gt;_parent = outer_ilt;
 283   loop-&gt;_next = NULL;
 284   loop-&gt;_nest++;
 285   return outer_ilt;
 286 }
 287 
 288 // Create a skeleton strip mined outer loop: a Loop head before the
 289 // inner strip mined loop, a safepoint and an exit condition guarded
 290 // by an opaque node after the inner strip mined loop with a backedge
 291 // to the loop head. The inner strip mined loop is left as it is. Only
 292 // once loop optimizations are over, do we adjust the inner loop exit
 293 // condition to limit its number of iterations, set the outer loop
 294 // exit condition and add Phis to the outer loop head. Some loop
 295 // optimizations that operate on the inner strip mined loop need to be
 296 // aware of the outer strip mined loop: loop unswitching needs to
 297 // clone the outer loop as well as the inner, unrolling needs to only
 298 // clone the inner loop etc. No optimizations need to change the outer
 299 // strip mined loop as it is only a skeleton.
 300 IdealLoopTree* PhaseIdealLoop::create_outer_strip_mined_loop(BoolNode *test, Node *cmp, Node *init_control,
 301                                                              IdealLoopTree* loop, float cl_prob, float le_fcnt,
 302                                                              Node*&amp; entry_control, Node*&amp; iffalse) {
 303   Node* outer_test = _igvn.intcon(0);
 304   set_ctrl(outer_test, C-&gt;root());
 305   Node *orig = iffalse;
 306   iffalse = iffalse-&gt;clone();
 307   _igvn.register_new_node_with_optimizer(iffalse);
 308   set_idom(iffalse, idom(orig), dom_depth(orig));
 309 
 310   IfNode *outer_le = new OuterStripMinedLoopEndNode(iffalse, outer_test, cl_prob, le_fcnt);
 311   Node *outer_ift = new IfTrueNode (outer_le);
 312   Node* outer_iff = orig;
 313   _igvn.replace_input_of(outer_iff, 0, outer_le);
 314 
 315   LoopNode *outer_l = new OuterStripMinedLoopNode(C, init_control, outer_ift);
 316   entry_control = outer_l;
 317 
 318   IdealLoopTree* outer_ilt = insert_outer_loop(loop, outer_l, outer_ift);
 319 
 320   set_loop(iffalse, outer_ilt);
 321   // When this code runs, loop bodies have not yet been populated.
 322   const bool body_populated = false;
 323   register_control(outer_le, outer_ilt, iffalse, body_populated);
 324   register_control(outer_ift, outer_ilt, outer_le, body_populated);
 325   set_idom(outer_iff, outer_le, dom_depth(outer_le));
 326   _igvn.register_new_node_with_optimizer(outer_l);
 327   set_loop(outer_l, outer_ilt);
 328   set_idom(outer_l, init_control, dom_depth(init_control)+1);
 329 
 330   return outer_ilt;
 331 }
 332 
 333 void PhaseIdealLoop::insert_loop_limit_check(ProjNode* limit_check_proj, Node* cmp_limit, Node* bol) {
 334   Node* new_predicate_proj = create_new_if_for_predicate(limit_check_proj, NULL,
 335                                                          Deoptimization::Reason_loop_limit_check,
 336                                                          Op_If);
 337   Node* iff = new_predicate_proj-&gt;in(0);
 338   assert(iff-&gt;Opcode() == Op_If, &quot;bad graph shape&quot;);
 339   Node* conv = iff-&gt;in(1);
 340   assert(conv-&gt;Opcode() == Op_Conv2B, &quot;bad graph shape&quot;);
 341   Node* opaq = conv-&gt;in(1);
 342   assert(opaq-&gt;Opcode() == Op_Opaque1, &quot;bad graph shape&quot;);
 343   cmp_limit = _igvn.register_new_node_with_optimizer(cmp_limit);
 344   bol = _igvn.register_new_node_with_optimizer(bol);
 345   set_subtree_ctrl(bol);
 346   _igvn.replace_input_of(iff, 1, bol);
 347 
 348 #ifndef PRODUCT
 349   // report that the loop predication has been actually performed
 350   // for this loop
 351   if (TraceLoopLimitCheck) {
 352     tty-&gt;print_cr(&quot;Counted Loop Limit Check generated:&quot;);
 353     debug_only( bol-&gt;dump(2); )
 354   }
 355 #endif
 356 }
 357 
 358 Node* PhaseIdealLoop::loop_exit_control(Node* x, IdealLoopTree* loop) {
 359   // Counted loop head must be a good RegionNode with only 3 not NULL
 360   // control input edges: Self, Entry, LoopBack.
 361   if (x-&gt;in(LoopNode::Self) == NULL || x-&gt;req() != 3 || loop-&gt;_irreducible) {
 362     return NULL;
 363   }
 364   Node *init_control = x-&gt;in(LoopNode::EntryControl);
 365   Node *back_control = x-&gt;in(LoopNode::LoopBackControl);
 366   if (init_control == NULL || back_control == NULL) {   // Partially dead
 367     return NULL;
 368   }
 369   // Must also check for TOP when looking for a dead loop
 370   if (init_control-&gt;is_top() || back_control-&gt;is_top()) {
 371     return NULL;
 372   }
 373 
 374   // Allow funny placement of Safepoint
 375   if (back_control-&gt;Opcode() == Op_SafePoint) {
 376     back_control = back_control-&gt;in(TypeFunc::Control);
 377   }
 378 
 379   // Controlling test for loop
 380   Node *iftrue = back_control;
 381   uint iftrue_op = iftrue-&gt;Opcode();
 382   if (iftrue_op != Op_IfTrue &amp;&amp;
 383       iftrue_op != Op_IfFalse) {
 384     // I have a weird back-control.  Probably the loop-exit test is in
 385     // the middle of the loop and I am looking at some trailing control-flow
 386     // merge point.  To fix this I would have to partially peel the loop.
 387     return NULL; // Obscure back-control
 388   }
 389 
 390   // Get boolean guarding loop-back test
 391   Node *iff = iftrue-&gt;in(0);
 392   if (get_loop(iff) != loop || !iff-&gt;in(1)-&gt;is_Bool()) {
 393     return NULL;
 394   }
 395   return iftrue;
 396 }
 397 
 398 Node* PhaseIdealLoop::loop_exit_test(Node* back_control, IdealLoopTree* loop, Node*&amp; incr, Node*&amp; limit, BoolTest::mask&amp; bt, float&amp; cl_prob) {
 399   Node* iftrue = back_control;
 400   uint iftrue_op = iftrue-&gt;Opcode();
 401   Node* iff = iftrue-&gt;in(0);
 402   BoolNode* test = iff-&gt;in(1)-&gt;as_Bool();
 403   bt = test-&gt;_test._test;
 404   cl_prob = iff-&gt;as_If()-&gt;_prob;
 405   if (iftrue_op == Op_IfFalse) {
 406     bt = BoolTest(bt).negate();
 407     cl_prob = 1.0 - cl_prob;
 408   }
 409   // Get backedge compare
 410   Node* cmp = test-&gt;in(1);
 411   if (!cmp-&gt;is_Cmp()) {
 412     return NULL;
 413   }
 414 
 415   // Find the trip-counter increment &amp; limit.  Limit must be loop invariant.
 416   incr  = cmp-&gt;in(1);
 417   limit = cmp-&gt;in(2);
 418 
 419   // ---------
 420   // need &#39;loop()&#39; test to tell if limit is loop invariant
 421   // ---------
 422 
 423   if (!is_member(loop, get_ctrl(incr))) { // Swapped trip counter and limit?
 424     Node* tmp = incr;            // Then reverse order into the CmpI
 425     incr = limit;
 426     limit = tmp;
 427     bt = BoolTest(bt).commute(); // And commute the exit test
 428   }
 429   if (is_member(loop, get_ctrl(limit))) { // Limit must be loop-invariant
 430     return NULL;
 431   }
 432   if (!is_member(loop, get_ctrl(incr))) { // Trip counter must be loop-variant
 433     return NULL;
 434   }
 435   return cmp;
 436 }
 437 
 438 Node* PhaseIdealLoop::loop_iv_incr(Node* incr, Node* x, IdealLoopTree* loop, Node*&amp; phi_incr) {
 439   if (incr-&gt;is_Phi()) {
 440     if (incr-&gt;as_Phi()-&gt;region() != x || incr-&gt;req() != 3) {
 441       return NULL; // Not simple trip counter expression
 442     }
 443     phi_incr = incr;
 444     incr = phi_incr-&gt;in(LoopNode::LoopBackControl); // Assume incr is on backedge of Phi
 445     if (!is_member(loop, get_ctrl(incr))) { // Trip counter must be loop-variant
 446       return NULL;
 447     }
 448   }
 449   return incr;
 450 }
 451 
 452 Node* PhaseIdealLoop::loop_iv_stride(Node* incr, IdealLoopTree* loop, Node*&amp; xphi) {
 453   assert(incr-&gt;Opcode() == Op_AddI || incr-&gt;Opcode() == Op_AddL, &quot;caller resp.&quot;);
 454   // Get merge point
 455   xphi = incr-&gt;in(1);
 456   Node *stride = incr-&gt;in(2);
 457   if (!stride-&gt;is_Con()) {     // Oops, swap these
 458     if (!xphi-&gt;is_Con()) {     // Is the other guy a constant?
 459       return NULL;             // Nope, unknown stride, bail out
 460     }
 461     Node *tmp = xphi;          // &#39;incr&#39; is commutative, so ok to swap
 462     xphi = stride;
 463     stride = tmp;
 464   }
 465   return stride;
 466 }
 467 
 468 PhiNode* PhaseIdealLoop::loop_iv_phi(Node* xphi, Node* phi_incr, Node* x, IdealLoopTree* loop) {
 469   if (!xphi-&gt;is_Phi()) {
 470     return NULL; // Too much math on the trip counter
 471   }
 472   if (phi_incr != NULL &amp;&amp; phi_incr != xphi) {
 473     return NULL;
 474   }
 475   PhiNode *phi = xphi-&gt;as_Phi();
 476 
 477   // Phi must be of loop header; backedge must wrap to increment
 478   if (phi-&gt;region() != x) {
 479     return NULL;
 480   }
 481   return phi;
 482 }
 483 
 484 // Return 0 if it won&#39;t overflow, -1 if it must overflow, and 1 otherwise.
 485 static int check_stride_overflow(jint stride_con, const TypeInt* limit_t) {
 486   if (stride_con &gt; 0) {
 487     if (limit_t-&gt;_lo &gt; (max_jint - stride_con)) {
 488       return -1;
 489     }
 490     if (limit_t-&gt;_hi &gt; (max_jint - stride_con)) {
 491       return 1;
 492     }
 493   } else {
 494     if (limit_t-&gt;_hi &lt; (min_jint - stride_con)) {
 495       return -1;
 496     }
 497     if (limit_t-&gt;_lo &lt; (min_jint - stride_con)) {
 498       return 1;
 499     }
 500   }
 501   return 0;
 502 }
 503 
 504 //------------------------------is_counted_loop--------------------------------
 505 bool PhaseIdealLoop::is_counted_loop(Node* x, IdealLoopTree*&amp; loop) {
 506   PhaseGVN *gvn = &amp;_igvn;
 507 
 508   Node* back_control = loop_exit_control(x, loop);
 509   if (back_control == NULL) {
 510     return false;
 511   }
 512 
 513   BoolTest::mask bt = BoolTest::illegal;
 514   float cl_prob = 0;
 515   Node* incr = NULL;
 516   Node* limit = NULL;
 517 
 518   Node* cmp = loop_exit_test(back_control, loop, incr, limit, bt, cl_prob);
 519   if (cmp == NULL || cmp-&gt;Opcode() != Op_CmpI) {
 520     return false; // Avoid pointer &amp; float &amp; 64-bit compares
 521   }
 522 
 523   // Trip-counter increment must be commutative &amp; associative.
 524   if (incr-&gt;Opcode() == Op_CastII) {
 525     incr = incr-&gt;in(1);
 526   }
 527 
 528   Node* phi_incr = NULL;
 529   incr = loop_iv_incr(incr, x, loop, phi_incr);
 530   if (incr == NULL) {
 531     return false;
 532   }
 533 
 534   Node* trunc1 = NULL;
 535   Node* trunc2 = NULL;
 536   const TypeInt* iv_trunc_t = NULL;
 537   Node* orig_incr = incr;
 538   if (!(incr = CountedLoopNode::match_incr_with_optional_truncation(incr, &amp;trunc1, &amp;trunc2, &amp;iv_trunc_t))) {
 539     return false; // Funny increment opcode
 540   }
 541   assert(incr-&gt;Opcode() == Op_AddI, &quot;wrong increment code&quot;);
 542 
 543   Node* xphi = NULL;
 544   Node* stride = loop_iv_stride(incr, loop, xphi);
 545 
 546   if (stride == NULL) {
 547     return false;
 548   }
 549 
 550   if (xphi-&gt;Opcode() == Op_CastII) {
 551     xphi = xphi-&gt;in(1);
 552   }
 553 
 554   // Stride must be constant
 555   int stride_con = stride-&gt;get_int();
 556   assert(stride_con != 0, &quot;missed some peephole opt&quot;);
 557 
 558   PhiNode* phi = loop_iv_phi(xphi, phi_incr, x, loop);
 559 
 560   if (phi == NULL ||
 561       (trunc1 == NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != incr) ||
 562       (trunc1 != NULL &amp;&amp; phi-&gt;in(LoopNode::LoopBackControl) != trunc1)) {
 563     return false;
 564   }
 565 
 566   if (x-&gt;in(LoopNode::LoopBackControl)-&gt;Opcode() == Op_SafePoint &amp;&amp;
 567       LoopStripMiningIter != 0) {
 568     // Leaving the safepoint on the backedge and creating a
 569     // CountedLoop will confuse optimizations. We can&#39;t move the
 570     // safepoint around because its jvm state wouldn&#39;t match a new
 571     // location. Give up on that loop.
 572     return false;
 573   }
 574 
 575   Node* iftrue = back_control;
 576   uint iftrue_op = iftrue-&gt;Opcode();
 577   Node* iff = iftrue-&gt;in(0);
 578   BoolNode* test = iff-&gt;in(1)-&gt;as_Bool();
 579 
 580   const TypeInt* limit_t = gvn-&gt;type(limit)-&gt;is_int();
 581   if (trunc1 != NULL) {
 582     // When there is a truncation, we must be sure that after the truncation
 583     // the trip counter will end up higher than the limit, otherwise we are looking
 584     // at an endless loop. Can happen with range checks.
 585 
 586     // Example:
 587     // int i = 0;
 588     // while (true)
 589     //    sum + = array[i];
 590     //    i++;
 591     //    i = i &amp;&amp; 0x7fff;
 592     //  }
 593     //
 594     // If the array is shorter than 0x8000 this exits through a AIOOB
 595     //  - Counted loop transformation is ok
 596     // If the array is longer then this is an endless loop
 597     //  - No transformation can be done.
 598 
 599     const TypeInt* incr_t = gvn-&gt;type(orig_incr)-&gt;is_int();
 600     if (limit_t-&gt;_hi &gt; incr_t-&gt;_hi) {
 601       // if the limit can have a higher value than the increment (before the phi)
 602       return false;
 603     }
 604   }
 605 
 606   Node *init_trip = phi-&gt;in(LoopNode::EntryControl);
 607 
 608   // If iv trunc type is smaller than int, check for possible wrap.
 609   if (!TypeInt::INT-&gt;higher_equal(iv_trunc_t)) {
 610     assert(trunc1 != NULL, &quot;must have found some truncation&quot;);
 611 
 612     // Get a better type for the phi (filtered thru if&#39;s)
 613     const TypeInt* phi_ft = filtered_type(phi);
 614 
 615     // Can iv take on a value that will wrap?
 616     //
 617     // Ensure iv&#39;s limit is not within &quot;stride&quot; of the wrap value.
 618     //
 619     // Example for &quot;short&quot; type
 620     //    Truncation ensures value is in the range -32768..32767 (iv_trunc_t)
 621     //    If the stride is +10, then the last value of the induction
 622     //    variable before the increment (phi_ft-&gt;_hi) must be
 623     //    &lt;= 32767 - 10 and (phi_ft-&gt;_lo) must be &gt;= -32768 to
 624     //    ensure no truncation occurs after the increment.
 625 
 626     if (stride_con &gt; 0) {
 627       if (iv_trunc_t-&gt;_hi - phi_ft-&gt;_hi &lt; stride_con ||
 628           iv_trunc_t-&gt;_lo &gt; phi_ft-&gt;_lo) {
 629         return false;  // truncation may occur
 630       }
 631     } else if (stride_con &lt; 0) {
 632       if (iv_trunc_t-&gt;_lo - phi_ft-&gt;_lo &gt; stride_con ||
 633           iv_trunc_t-&gt;_hi &lt; phi_ft-&gt;_hi) {
 634         return false;  // truncation may occur
 635       }
 636     }
 637     // No possibility of wrap so truncation can be discarded
 638     // Promote iv type to Int
 639   } else {
 640     assert(trunc1 == NULL &amp;&amp; trunc2 == NULL, &quot;no truncation for int&quot;);
 641   }
 642 
 643   // If the condition is inverted and we will be rolling
 644   // through MININT to MAXINT, then bail out.
 645   if (bt == BoolTest::eq || // Bail out, but this loop trips at most twice!
 646       // Odd stride
 647       (bt == BoolTest::ne &amp;&amp; stride_con != 1 &amp;&amp; stride_con != -1) ||
 648       // Count down loop rolls through MAXINT
 649       ((bt == BoolTest::le || bt == BoolTest::lt) &amp;&amp; stride_con &lt; 0) ||
 650       // Count up loop rolls through MININT
 651       ((bt == BoolTest::ge || bt == BoolTest::gt) &amp;&amp; stride_con &gt; 0)) {
 652     return false; // Bail out
 653   }
 654 
 655   const TypeInt* init_t = gvn-&gt;type(init_trip)-&gt;is_int();
 656 
 657   if (stride_con &gt; 0) {
 658     jlong init_p = (jlong)init_t-&gt;_lo + stride_con;
 659     if (init_p &gt; (jlong)max_jint || init_p &gt; (jlong)limit_t-&gt;_hi)
 660       return false; // cyclic loop or this loop trips only once
 661   } else {
 662     jlong init_p = (jlong)init_t-&gt;_hi + stride_con;
 663     if (init_p &lt; (jlong)min_jint || init_p &lt; (jlong)limit_t-&gt;_lo)
 664       return false; // cyclic loop or this loop trips only once
 665   }
 666 
 667   if (phi_incr != NULL &amp;&amp; bt != BoolTest::ne) {
 668     // check if there is a possiblity of IV overflowing after the first increment
 669     if (stride_con &gt; 0) {
 670       if (init_t-&gt;_hi &gt; max_jint - stride_con) {
 671         return false;
 672       }
 673     } else {
 674       if (init_t-&gt;_lo &lt; min_jint - stride_con) {
 675         return false;
 676       }
 677     }
 678   }
 679 
 680   // =================================================
 681   // ---- SUCCESS!   Found A Trip-Counted Loop!  -----
 682   //
 683   assert(x-&gt;Opcode() == Op_Loop, &quot;regular loops only&quot;);
 684   C-&gt;print_method(PHASE_BEFORE_CLOOPS, 3);
 685 
 686   Node *hook = new Node(6);
 687 
 688   // ===================================================
 689   // Generate loop limit check to avoid integer overflow
 690   // in cases like next (cyclic loops):
 691   //
 692   // for (i=0; i &lt;= max_jint; i++) {}
 693   // for (i=0; i &lt;  max_jint; i+=2) {}
 694   //
 695   //
 696   // Limit check predicate depends on the loop test:
 697   //
 698   // for(;i != limit; i++)       --&gt; limit &lt;= (max_jint)
 699   // for(;i &lt;  limit; i+=stride) --&gt; limit &lt;= (max_jint - stride + 1)
 700   // for(;i &lt;= limit; i+=stride) --&gt; limit &lt;= (max_jint - stride    )
 701   //
 702 
 703   // Check if limit is excluded to do more precise int overflow check.
 704   bool incl_limit = (bt == BoolTest::le || bt == BoolTest::ge);
 705   int stride_m  = stride_con - (incl_limit ? 0 : (stride_con &gt; 0 ? 1 : -1));
 706 
 707   // If compare points directly to the phi we need to adjust
 708   // the compare so that it points to the incr. Limit have
 709   // to be adjusted to keep trip count the same and the
 710   // adjusted limit should be checked for int overflow.
 711   Node* adjusted_limit = limit;
 712   if (phi_incr != NULL) {
 713     stride_m  += stride_con;
 714   }
 715 
 716   Node *init_control = x-&gt;in(LoopNode::EntryControl);
 717 
 718   int sov = check_stride_overflow(stride_m, limit_t);
 719   // If sov==0, limit&#39;s type always satisfies the condition, for
 720   // example, when it is an array length.
 721   if (sov != 0) {
 722     if (sov &lt; 0) {
 723       return false;  // Bailout: integer overflow is certain.
 724     }
 725     // Generate loop&#39;s limit check.
 726     // Loop limit check predicate should be near the loop.
 727     ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 728     if (!limit_check_proj) {
 729       // The limit check predicate is not generated if this method trapped here before.
 730 #ifdef ASSERT
 731       if (TraceLoopLimitCheck) {
 732         tty-&gt;print(&quot;missing loop limit check:&quot;);
 733         loop-&gt;dump_head();
 734         x-&gt;dump(1);
 735       }
 736 #endif
 737       return false;
 738     }
 739 
 740     IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 741 
 742     if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0))) {
 743       return false;
 744     }
 745 
 746     Node* cmp_limit;
 747     Node* bol;
 748 
 749     if (stride_con &gt; 0) {
 750       cmp_limit = new CmpINode(limit, _igvn.intcon(max_jint - stride_m));
 751       bol = new BoolNode(cmp_limit, BoolTest::le);
 752     } else {
 753       cmp_limit = new CmpINode(limit, _igvn.intcon(min_jint - stride_m));
 754       bol = new BoolNode(cmp_limit, BoolTest::ge);
 755     }
 756 
 757     insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 758   }
 759 
 760   // Now we need to canonicalize loop condition.
 761   if (bt == BoolTest::ne) {
 762     assert(stride_con == 1 || stride_con == -1, &quot;simple increment only&quot;);
 763     if (stride_con &gt; 0 &amp;&amp; init_t-&gt;_hi &lt; limit_t-&gt;_lo) {
 764       // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 765       bt = BoolTest::lt;
 766     } else if (stride_con &lt; 0 &amp;&amp; init_t-&gt;_lo &gt; limit_t-&gt;_hi) {
 767       // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 768       bt = BoolTest::gt;
 769     } else {
 770       ProjNode *limit_check_proj = find_predicate_insertion_point(init_control, Deoptimization::Reason_loop_limit_check);
 771       if (!limit_check_proj) {
 772         // The limit check predicate is not generated if this method trapped here before.
 773 #ifdef ASSERT
 774         if (TraceLoopLimitCheck) {
 775           tty-&gt;print(&quot;missing loop limit check:&quot;);
 776           loop-&gt;dump_head();
 777           x-&gt;dump(1);
 778         }
 779 #endif
 780         return false;
 781       }
 782       IfNode* check_iff = limit_check_proj-&gt;in(0)-&gt;as_If();
 783 
 784       if (!is_dominator(get_ctrl(limit), check_iff-&gt;in(0)) ||
 785           !is_dominator(get_ctrl(init_trip), check_iff-&gt;in(0))) {
 786         return false;
 787       }
 788 
 789       Node* cmp_limit;
 790       Node* bol;
 791 
 792       if (stride_con &gt; 0) {
 793         cmp_limit = new CmpINode(init_trip, limit);
 794         bol = new BoolNode(cmp_limit, BoolTest::lt);
 795       } else {
 796         cmp_limit = new CmpINode(init_trip, limit);
 797         bol = new BoolNode(cmp_limit, BoolTest::gt);
 798       }
 799 
 800       insert_loop_limit_check(limit_check_proj, cmp_limit, bol);
 801 
 802       if (stride_con &gt; 0) {
 803         // &#39;ne&#39; can be replaced with &#39;lt&#39; only when init &lt; limit.
 804         bt = BoolTest::lt;
 805       } else if (stride_con &lt; 0) {
 806         // &#39;ne&#39; can be replaced with &#39;gt&#39; only when init &gt; limit.
 807         bt = BoolTest::gt;
 808       }
 809     }
 810   }
 811 
 812   if (phi_incr != NULL) {
 813     // If compare points directly to the phi we need to adjust
 814     // the compare so that it points to the incr. Limit have
 815     // to be adjusted to keep trip count the same and we
 816     // should avoid int overflow.
 817     //
 818     //   i = init; do {} while(i++ &lt; limit);
 819     // is converted to
 820     //   i = init; do {} while(++i &lt; limit+1);
 821     //
 822     adjusted_limit = gvn-&gt;transform(new AddINode(limit, stride));
 823   }
 824 
 825   if (incl_limit) {
 826     // The limit check guaranties that &#39;limit &lt;= (max_jint - stride)&#39; so
 827     // we can convert &#39;i &lt;= limit&#39; to &#39;i &lt; limit+1&#39; since stride != 0.
 828     //
 829     Node* one = (stride_con &gt; 0) ? gvn-&gt;intcon( 1) : gvn-&gt;intcon(-1);
 830     adjusted_limit = gvn-&gt;transform(new AddINode(adjusted_limit, one));
 831     if (bt == BoolTest::le)
 832       bt = BoolTest::lt;
 833     else if (bt == BoolTest::ge)
 834       bt = BoolTest::gt;
 835     else
 836       ShouldNotReachHere();
 837   }
 838   set_subtree_ctrl(adjusted_limit);
 839 
 840   if (LoopStripMiningIter == 0) {
 841     // Check for SafePoint on backedge and remove
 842     Node *sfpt = x-&gt;in(LoopNode::LoopBackControl);
 843     if (sfpt-&gt;Opcode() == Op_SafePoint &amp;&amp; is_deleteable_safept(sfpt)) {
 844       lazy_replace( sfpt, iftrue );
 845       if (loop-&gt;_safepts != NULL) {
 846         loop-&gt;_safepts-&gt;yank(sfpt);
 847       }
 848       loop-&gt;_tail = iftrue;
 849     }
 850   }
 851 
 852   // Build a canonical trip test.
 853   // Clone code, as old values may be in use.
 854   incr = incr-&gt;clone();
 855   incr-&gt;set_req(1,phi);
 856   incr-&gt;set_req(2,stride);
 857   incr = _igvn.register_new_node_with_optimizer(incr);
 858   set_early_ctrl( incr );
 859   _igvn.rehash_node_delayed(phi);
 860   phi-&gt;set_req_X( LoopNode::LoopBackControl, incr, &amp;_igvn );
 861 
 862   // If phi type is more restrictive than Int, raise to
 863   // Int to prevent (almost) infinite recursion in igvn
 864   // which can only handle integer types for constants or minint..maxint.
 865   if (!TypeInt::INT-&gt;higher_equal(phi-&gt;bottom_type())) {
 866     Node* nphi = PhiNode::make(phi-&gt;in(0), phi-&gt;in(LoopNode::EntryControl), TypeInt::INT);
 867     nphi-&gt;set_req(LoopNode::LoopBackControl, phi-&gt;in(LoopNode::LoopBackControl));
 868     nphi = _igvn.register_new_node_with_optimizer(nphi);
 869     set_ctrl(nphi, get_ctrl(phi));
 870     _igvn.replace_node(phi, nphi);
 871     phi = nphi-&gt;as_Phi();
 872   }
 873   cmp = cmp-&gt;clone();
 874   cmp-&gt;set_req(1,incr);
 875   cmp-&gt;set_req(2, adjusted_limit);
 876   cmp = _igvn.register_new_node_with_optimizer(cmp);
 877   set_ctrl(cmp, iff-&gt;in(0));
 878 
 879   test = test-&gt;clone()-&gt;as_Bool();
 880   (*(BoolTest*)&amp;test-&gt;_test)._test = bt;
 881   test-&gt;set_req(1,cmp);
 882   _igvn.register_new_node_with_optimizer(test);
 883   set_ctrl(test, iff-&gt;in(0));
 884 
 885   // Replace the old IfNode with a new LoopEndNode
 886   Node *lex = _igvn.register_new_node_with_optimizer(new CountedLoopEndNode( iff-&gt;in(0), test, cl_prob, iff-&gt;as_If()-&gt;_fcnt ));
 887   IfNode *le = lex-&gt;as_If();
 888   uint dd = dom_depth(iff);
 889   set_idom(le, le-&gt;in(0), dd); // Update dominance for loop exit
 890   set_loop(le, loop);
 891 
 892   // Get the loop-exit control
 893   Node *iffalse = iff-&gt;as_If()-&gt;proj_out(!(iftrue_op == Op_IfTrue));
 894 
 895   // Need to swap loop-exit and loop-back control?
 896   if (iftrue_op == Op_IfFalse) {
 897     Node *ift2=_igvn.register_new_node_with_optimizer(new IfTrueNode (le));
 898     Node *iff2=_igvn.register_new_node_with_optimizer(new IfFalseNode(le));
 899 
 900     loop-&gt;_tail = back_control = ift2;
 901     set_loop(ift2, loop);
 902     set_loop(iff2, get_loop(iffalse));
 903 
 904     // Lazy update of &#39;get_ctrl&#39; mechanism.
 905     lazy_replace(iffalse, iff2);
 906     lazy_replace(iftrue,  ift2);
 907 
 908     // Swap names
 909     iffalse = iff2;
 910     iftrue  = ift2;
 911   } else {
 912     _igvn.rehash_node_delayed(iffalse);
 913     _igvn.rehash_node_delayed(iftrue);
 914     iffalse-&gt;set_req_X( 0, le, &amp;_igvn );
 915     iftrue -&gt;set_req_X( 0, le, &amp;_igvn );
 916   }
 917 
 918   set_idom(iftrue,  le, dd+1);
 919   set_idom(iffalse, le, dd+1);
 920   assert(iff-&gt;outcnt() == 0, &quot;should be dead now&quot;);
 921   lazy_replace( iff, le ); // fix &#39;get_ctrl&#39;
 922 
 923   Node *sfpt2 = le-&gt;in(0);
 924 
 925   Node* entry_control = init_control;
 926   bool strip_mine_loop = LoopStripMiningIter &gt; 1 &amp;&amp; loop-&gt;_child == NULL &amp;&amp;
 927     sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; !loop-&gt;_has_call;
 928   IdealLoopTree* outer_ilt = NULL;
 929   if (strip_mine_loop) {
 930     outer_ilt = create_outer_strip_mined_loop(test, cmp, init_control, loop,
 931                                               cl_prob, le-&gt;_fcnt, entry_control,
 932                                               iffalse);
 933   }
 934 
 935   // Now setup a new CountedLoopNode to replace the existing LoopNode
 936   CountedLoopNode *l = new CountedLoopNode(entry_control, back_control);
 937   l-&gt;set_unswitch_count(x-&gt;as_Loop()-&gt;unswitch_count()); // Preserve
 938   // The following assert is approximately true, and defines the intention
 939   // of can_be_counted_loop.  It fails, however, because phase-&gt;type
 940   // is not yet initialized for this loop and its parts.
 941   //assert(l-&gt;can_be_counted_loop(this), &quot;sanity&quot;);
 942   _igvn.register_new_node_with_optimizer(l);
 943   set_loop(l, loop);
 944   loop-&gt;_head = l;
 945   // Fix all data nodes placed at the old loop head.
 946   // Uses the lazy-update mechanism of &#39;get_ctrl&#39;.
 947   lazy_replace( x, l );
 948   set_idom(l, entry_control, dom_depth(entry_control) + 1);
 949 
 950   if (LoopStripMiningIter == 0 || strip_mine_loop) {
 951     // Check for immediately preceding SafePoint and remove
 952     if (sfpt2-&gt;Opcode() == Op_SafePoint &amp;&amp; (LoopStripMiningIter != 0 || is_deleteable_safept(sfpt2))) {
 953       if (strip_mine_loop) {
 954         Node* outer_le = outer_ilt-&gt;_tail-&gt;in(0);
 955         Node* sfpt = sfpt2-&gt;clone();
 956         sfpt-&gt;set_req(0, iffalse);
 957         outer_le-&gt;set_req(0, sfpt);
 958         // When this code runs, loop bodies have not yet been populated.
 959         const bool body_populated = false;
 960         register_control(sfpt, outer_ilt, iffalse, body_populated);
 961         set_idom(outer_le, sfpt, dom_depth(sfpt));
 962       }
 963       lazy_replace( sfpt2, sfpt2-&gt;in(TypeFunc::Control));
 964       if (loop-&gt;_safepts != NULL) {
 965         loop-&gt;_safepts-&gt;yank(sfpt2);
 966       }
 967     }
 968   }
 969 
 970   // Free up intermediate goo
 971   _igvn.remove_dead_node(hook);
 972 
 973 #ifdef ASSERT
 974   assert(l-&gt;is_valid_counted_loop(), &quot;counted loop shape is messed up&quot;);
 975   assert(l == loop-&gt;_head &amp;&amp; l-&gt;phi() == phi &amp;&amp; l-&gt;loopexit_or_null() == lex, &quot;&quot; );
 976 #endif
 977 #ifndef PRODUCT
 978   if (TraceLoopOpts) {
 979     tty-&gt;print(&quot;Counted      &quot;);
 980     loop-&gt;dump_head();
 981   }
 982 #endif
 983 
 984   C-&gt;print_method(PHASE_AFTER_CLOOPS, 3);
 985 
 986   // Capture bounds of the loop in the induction variable Phi before
 987   // subsequent transformation (iteration splitting) obscures the
 988   // bounds
 989   l-&gt;phi()-&gt;as_Phi()-&gt;set_type(l-&gt;phi()-&gt;Value(&amp;_igvn));
 990 
 991   if (strip_mine_loop) {
 992     l-&gt;mark_strip_mined();
 993     l-&gt;verify_strip_mined(1);
 994     outer_ilt-&gt;_head-&gt;as_Loop()-&gt;verify_strip_mined(1);
 995     loop = outer_ilt;
 996   }
 997 
 998   return true;
 999 }
1000 
1001 //----------------------exact_limit-------------------------------------------
1002 Node* PhaseIdealLoop::exact_limit( IdealLoopTree *loop ) {
1003   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
1004   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
1005   assert(cl-&gt;is_valid_counted_loop(), &quot;&quot;);
1006 
1007   if (ABS(cl-&gt;stride_con()) == 1 ||
1008       cl-&gt;limit()-&gt;Opcode() == Op_LoopLimit) {
1009     // Old code has exact limit (it could be incorrect in case of int overflow).
1010     // Loop limit is exact with stride == 1. And loop may already have exact limit.
1011     return cl-&gt;limit();
1012   }
1013   Node *limit = NULL;
1014 #ifdef ASSERT
1015   BoolTest::mask bt = cl-&gt;loopexit()-&gt;test_trip();
1016   assert(bt == BoolTest::lt || bt == BoolTest::gt, &quot;canonical test is expected&quot;);
1017 #endif
1018   if (cl-&gt;has_exact_trip_count()) {
1019     // Simple case: loop has constant boundaries.
1020     // Use jlongs to avoid integer overflow.
1021     int stride_con = cl-&gt;stride_con();
1022     jlong  init_con = cl-&gt;init_trip()-&gt;get_int();
1023     jlong limit_con = cl-&gt;limit()-&gt;get_int();
1024     julong trip_cnt = cl-&gt;trip_count();
1025     jlong final_con = init_con + trip_cnt*stride_con;
1026     int final_int = (int)final_con;
1027     // The final value should be in integer range since the loop
1028     // is counted and the limit was checked for overflow.
1029     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
1030     limit = _igvn.intcon(final_int);
1031   } else {
1032     // Create new LoopLimit node to get exact limit (final iv value).
1033     limit = new LoopLimitNode(C, cl-&gt;init_trip(), cl-&gt;limit(), cl-&gt;stride());
1034     register_new_node(limit, cl-&gt;in(LoopNode::EntryControl));
1035   }
1036   assert(limit != NULL, &quot;sanity&quot;);
1037   return limit;
1038 }
1039 
1040 //------------------------------Ideal------------------------------------------
1041 // Return a node which is more &quot;ideal&quot; than the current node.
1042 // Attempt to convert into a counted-loop.
1043 Node *LoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1044   if (!can_be_counted_loop(phase) &amp;&amp; !is_OuterStripMinedLoop()) {
1045     phase-&gt;C-&gt;set_major_progress();
1046   }
1047   return RegionNode::Ideal(phase, can_reshape);
1048 }
1049 
1050 #ifdef ASSERT
1051 void LoopNode::verify_strip_mined(int expect_skeleton) const {
1052   const OuterStripMinedLoopNode* outer = NULL;
1053   const CountedLoopNode* inner = NULL;
1054   if (is_strip_mined()) {
1055     if (!is_valid_counted_loop()) {
1056       return; // Skip malformed counted loop
1057     }
1058     assert(is_CountedLoop(), &quot;no Loop should be marked strip mined&quot;);
1059     inner = as_CountedLoop();
1060     outer = inner-&gt;in(LoopNode::EntryControl)-&gt;as_OuterStripMinedLoop();
1061   } else if (is_OuterStripMinedLoop()) {
1062     outer = this-&gt;as_OuterStripMinedLoop();
1063     inner = outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop();
1064     assert(inner-&gt;is_valid_counted_loop() &amp;&amp; inner-&gt;is_strip_mined(), &quot;OuterStripMinedLoop should have been removed&quot;);
1065     assert(!is_strip_mined(), &quot;outer loop shouldn&#39;t be marked strip mined&quot;);
1066   }
1067   if (inner != NULL || outer != NULL) {
1068     assert(inner != NULL &amp;&amp; outer != NULL, &quot;missing loop in strip mined nest&quot;);
1069     Node* outer_tail = outer-&gt;in(LoopNode::LoopBackControl);
1070     Node* outer_le = outer_tail-&gt;in(0);
1071     assert(outer_le-&gt;Opcode() == Op_OuterStripMinedLoopEnd, &quot;tail of outer loop should be an If&quot;);
1072     Node* sfpt = outer_le-&gt;in(0);
1073     assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;where&#39;s the safepoint?&quot;);
1074     Node* inner_out = sfpt-&gt;in(0);
1075     if (inner_out-&gt;outcnt() != 1) {
1076       ResourceMark rm;
1077       Unique_Node_List wq;
1078 
1079       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1080         Node* u = inner_out-&gt;fast_out(i);
1081         if (u == sfpt) {
1082           continue;
1083         }
1084         wq.clear();
1085         wq.push(u);
1086         bool found_sfpt = false;
1087         for (uint next = 0; next &lt; wq.size() &amp;&amp; !found_sfpt; next++) {
1088           Node* n = wq.at(next);
1089           for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; !found_sfpt; i++) {
1090             Node* u = n-&gt;fast_out(i);
1091             if (u == sfpt) {
1092               found_sfpt = true;
1093             }
1094             if (!u-&gt;is_CFG()) {
1095               wq.push(u);
1096             }
1097           }
1098         }
1099         assert(found_sfpt, &quot;no node in loop that&#39;s not input to safepoint&quot;);
1100       }
1101     }
1102 
1103     CountedLoopEndNode* cle = inner_out-&gt;in(0)-&gt;as_CountedLoopEnd();
1104     assert(cle == inner-&gt;loopexit_or_null(), &quot;mismatch&quot;);
1105     bool has_skeleton = outer_le-&gt;in(1)-&gt;bottom_type()-&gt;singleton() &amp;&amp; outer_le-&gt;in(1)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0;
1106     if (has_skeleton) {
1107       assert(expect_skeleton == 1 || expect_skeleton == -1, &quot;unexpected skeleton node&quot;);
1108       assert(outer-&gt;outcnt() == 2, &quot;only phis&quot;);
1109     } else {
1110       assert(expect_skeleton == 0 || expect_skeleton == -1, &quot;no skeleton node?&quot;);
1111       uint phis = 0;
1112       for (DUIterator_Fast imax, i = inner-&gt;fast_outs(imax); i &lt; imax; i++) {
1113         Node* u = inner-&gt;fast_out(i);
1114         if (u-&gt;is_Phi()) {
1115           phis++;
1116         }
1117       }
1118       for (DUIterator_Fast imax, i = outer-&gt;fast_outs(imax); i &lt; imax; i++) {
1119         Node* u = outer-&gt;fast_out(i);
1120         assert(u == outer || u == inner || u-&gt;is_Phi(), &quot;nothing between inner and outer loop&quot;);
1121       }
1122       uint stores = 0;
1123       for (DUIterator_Fast imax, i = inner_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1124         Node* u = inner_out-&gt;fast_out(i);
1125         if (u-&gt;is_Store()) {
1126           stores++;
1127         }
1128       }
1129       assert(outer-&gt;outcnt() &gt;= phis + 2 &amp;&amp; outer-&gt;outcnt() &lt;= phis + 2 + stores + 1, &quot;only phis&quot;);
1130     }
1131     assert(sfpt-&gt;outcnt() == 1, &quot;no data node&quot;);
1132     assert(outer_tail-&gt;outcnt() == 1 || !has_skeleton, &quot;no data node&quot;);
1133   }
1134 }
1135 #endif
1136 
1137 //=============================================================================
1138 //------------------------------Ideal------------------------------------------
1139 // Return a node which is more &quot;ideal&quot; than the current node.
1140 // Attempt to convert into a counted-loop.
1141 Node *CountedLoopNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1142   return RegionNode::Ideal(phase, can_reshape);
1143 }
1144 
1145 //------------------------------dump_spec--------------------------------------
1146 // Dump special per-node info
1147 #ifndef PRODUCT
1148 void CountedLoopNode::dump_spec(outputStream *st) const {
1149   LoopNode::dump_spec(st);
1150   if (stride_is_con()) {
1151     st-&gt;print(&quot;stride: %d &quot;,stride_con());
1152   }
1153   if (is_pre_loop ()) st-&gt;print(&quot;pre of N%d&quot; , _main_idx);
1154   if (is_main_loop()) st-&gt;print(&quot;main of N%d&quot;, _idx);
1155   if (is_post_loop()) st-&gt;print(&quot;post of N%d&quot;, _main_idx);
1156   if (is_strip_mined()) st-&gt;print(&quot; strip mined&quot;);
1157 }
1158 #endif
1159 
1160 //=============================================================================
1161 int CountedLoopEndNode::stride_con() const {
1162   return stride()-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1163 }
1164 
1165 //=============================================================================
1166 //------------------------------Value-----------------------------------------
1167 const Type* LoopLimitNode::Value(PhaseGVN* phase) const {
1168   const Type* init_t   = phase-&gt;type(in(Init));
1169   const Type* limit_t  = phase-&gt;type(in(Limit));
1170   const Type* stride_t = phase-&gt;type(in(Stride));
1171   // Either input is TOP ==&gt; the result is TOP
1172   if (init_t   == Type::TOP) return Type::TOP;
1173   if (limit_t  == Type::TOP) return Type::TOP;
1174   if (stride_t == Type::TOP) return Type::TOP;
1175 
1176   int stride_con = stride_t-&gt;is_int()-&gt;get_con();
1177   if (stride_con == 1)
1178     return NULL;  // Identity
1179 
1180   if (init_t-&gt;is_int()-&gt;is_con() &amp;&amp; limit_t-&gt;is_int()-&gt;is_con()) {
1181     // Use jlongs to avoid integer overflow.
1182     jlong init_con   =  init_t-&gt;is_int()-&gt;get_con();
1183     jlong limit_con  = limit_t-&gt;is_int()-&gt;get_con();
1184     int  stride_m   = stride_con - (stride_con &gt; 0 ? 1 : -1);
1185     jlong trip_count = (limit_con - init_con + stride_m)/stride_con;
1186     jlong final_con  = init_con + stride_con*trip_count;
1187     int final_int = (int)final_con;
1188     // The final value should be in integer range since the loop
1189     // is counted and the limit was checked for overflow.
1190     assert(final_con == (jlong)final_int, &quot;final value should be integer&quot;);
1191     return TypeInt::make(final_int);
1192   }
1193 
1194   return bottom_type(); // TypeInt::INT
1195 }
1196 
1197 //------------------------------Ideal------------------------------------------
1198 // Return a node which is more &quot;ideal&quot; than the current node.
1199 Node *LoopLimitNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1200   if (phase-&gt;type(in(Init))   == Type::TOP ||
1201       phase-&gt;type(in(Limit))  == Type::TOP ||
1202       phase-&gt;type(in(Stride)) == Type::TOP)
1203     return NULL;  // Dead
1204 
1205   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1206   if (stride_con == 1)
1207     return NULL;  // Identity
1208 
1209   if (in(Init)-&gt;is_Con() &amp;&amp; in(Limit)-&gt;is_Con())
1210     return NULL;  // Value
1211 
1212   // Delay following optimizations until all loop optimizations
1213   // done to keep Ideal graph simple.
1214   if (!can_reshape || phase-&gt;C-&gt;major_progress())
1215     return NULL;
1216 
1217   const TypeInt* init_t  = phase-&gt;type(in(Init) )-&gt;is_int();
1218   const TypeInt* limit_t = phase-&gt;type(in(Limit))-&gt;is_int();
1219   int stride_p;
1220   jlong lim, ini;
1221   julong max;
1222   if (stride_con &gt; 0) {
1223     stride_p = stride_con;
1224     lim = limit_t-&gt;_hi;
1225     ini = init_t-&gt;_lo;
1226     max = (julong)max_jint;
1227   } else {
1228     stride_p = -stride_con;
1229     lim = init_t-&gt;_hi;
1230     ini = limit_t-&gt;_lo;
1231     max = (julong)min_jint;
1232   }
1233   julong range = lim - ini + stride_p;
1234   if (range &lt;= max) {
1235     // Convert to integer expression if it is not overflow.
1236     Node* stride_m = phase-&gt;intcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1237     Node *range = phase-&gt;transform(new SubINode(in(Limit), in(Init)));
1238     Node *bias  = phase-&gt;transform(new AddINode(range, stride_m));
1239     Node *trip  = phase-&gt;transform(new DivINode(0, bias, in(Stride)));
1240     Node *span  = phase-&gt;transform(new MulINode(trip, in(Stride)));
1241     return new AddINode(span, in(Init)); // exact limit
1242   }
1243 
1244   if (is_power_of_2(stride_p) ||                // divisor is 2^n
1245       !Matcher::has_match_rule(Op_LoopLimit)) { // or no specialized Mach node?
1246     // Convert to long expression to avoid integer overflow
1247     // and let igvn optimizer convert this division.
1248     //
1249     Node*   init   = phase-&gt;transform( new ConvI2LNode(in(Init)));
1250     Node*  limit   = phase-&gt;transform( new ConvI2LNode(in(Limit)));
1251     Node* stride   = phase-&gt;longcon(stride_con);
1252     Node* stride_m = phase-&gt;longcon(stride_con - (stride_con &gt; 0 ? 1 : -1));
1253 
1254     Node *range = phase-&gt;transform(new SubLNode(limit, init));
1255     Node *bias  = phase-&gt;transform(new AddLNode(range, stride_m));
1256     Node *span;
1257     if (stride_con &gt; 0 &amp;&amp; is_power_of_2(stride_p)) {
1258       // bias &gt;= 0 if stride &gt;0, so if stride is 2^n we can use &amp;(-stride)
1259       // and avoid generating rounding for division. Zero trip guard should
1260       // guarantee that init &lt; limit but sometimes the guard is missing and
1261       // we can get situation when init &gt; limit. Note, for the empty loop
1262       // optimization zero trip guard is generated explicitly which leaves
1263       // only RCE predicate where exact limit is used and the predicate
1264       // will simply fail forcing recompilation.
1265       Node* neg_stride   = phase-&gt;longcon(-stride_con);
1266       span = phase-&gt;transform(new AndLNode(bias, neg_stride));
1267     } else {
1268       Node *trip  = phase-&gt;transform(new DivLNode(0, bias, stride));
1269       span = phase-&gt;transform(new MulLNode(trip, stride));
1270     }
1271     // Convert back to int
1272     Node *span_int = phase-&gt;transform(new ConvL2INode(span));
1273     return new AddINode(span_int, in(Init)); // exact limit
1274   }
1275 
1276   return NULL;    // No progress
1277 }
1278 
1279 //------------------------------Identity---------------------------------------
1280 // If stride == 1 return limit node.
1281 Node* LoopLimitNode::Identity(PhaseGVN* phase) {
1282   int stride_con = phase-&gt;type(in(Stride))-&gt;is_int()-&gt;get_con();
1283   if (stride_con == 1 || stride_con == -1)
1284     return in(Limit);
1285   return this;
1286 }
1287 
1288 //=============================================================================
1289 //----------------------match_incr_with_optional_truncation--------------------
1290 // Match increment with optional truncation:
1291 // CHAR: (i+1)&amp;0x7fff, BYTE: ((i+1)&lt;&lt;8)&gt;&gt;8, or SHORT: ((i+1)&lt;&lt;16)&gt;&gt;16
1292 // Return NULL for failure. Success returns the increment node.
1293 Node* CountedLoopNode::match_incr_with_optional_truncation(
1294                       Node* expr, Node** trunc1, Node** trunc2, const TypeInt** trunc_type) {
1295   // Quick cutouts:
1296   if (expr == NULL || expr-&gt;req() != 3)  return NULL;
1297 
1298   Node *t1 = NULL;
1299   Node *t2 = NULL;
1300   const TypeInt* trunc_t = TypeInt::INT;
1301   Node* n1 = expr;
1302   int   n1op = n1-&gt;Opcode();
1303 
1304   // Try to strip (n1 &amp; M) or (n1 &lt;&lt; N &gt;&gt; N) from n1.
1305   if (n1op == Op_AndI &amp;&amp;
1306       n1-&gt;in(2)-&gt;is_Con() &amp;&amp;
1307       n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con() == 0x7fff) {
1308     // %%% This check should match any mask of 2**K-1.
1309     t1 = n1;
1310     n1 = t1-&gt;in(1);
1311     n1op = n1-&gt;Opcode();
1312     trunc_t = TypeInt::CHAR;
1313   } else if (n1op == Op_RShiftI &amp;&amp;
1314              n1-&gt;in(1) != NULL &amp;&amp;
1315              n1-&gt;in(1)-&gt;Opcode() == Op_LShiftI &amp;&amp;
1316              n1-&gt;in(2) == n1-&gt;in(1)-&gt;in(2) &amp;&amp;
1317              n1-&gt;in(2)-&gt;is_Con()) {
1318     jint shift = n1-&gt;in(2)-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1319     // %%% This check should match any shift in [1..31].
1320     if (shift == 16 || shift == 8) {
1321       t1 = n1;
1322       t2 = t1-&gt;in(1);
1323       n1 = t2-&gt;in(1);
1324       n1op = n1-&gt;Opcode();
1325       if (shift == 16) {
1326         trunc_t = TypeInt::SHORT;
1327       } else if (shift == 8) {
1328         trunc_t = TypeInt::BYTE;
1329       }
1330     }
1331   }
1332 
1333   // If (maybe after stripping) it is an AddI, we won:
1334   if (n1op == Op_AddI) {
1335     *trunc1 = t1;
1336     *trunc2 = t2;
1337     *trunc_type = trunc_t;
1338     return n1;
1339   }
1340 
1341   // failed
1342   return NULL;
1343 }
1344 
1345 LoopNode* CountedLoopNode::skip_strip_mined(int expect_skeleton) {
1346   if (is_strip_mined() &amp;&amp; is_valid_counted_loop()) {
1347     verify_strip_mined(expect_skeleton);
1348     return in(EntryControl)-&gt;as_Loop();
1349   }
1350   return this;
1351 }
1352 
1353 OuterStripMinedLoopNode* CountedLoopNode::outer_loop() const {
1354   assert(is_strip_mined(), &quot;not a strip mined loop&quot;);
1355   Node* c = in(EntryControl);
1356   if (c == NULL || c-&gt;is_top() || !c-&gt;is_OuterStripMinedLoop()) {
1357     return NULL;
1358   }
1359   return c-&gt;as_OuterStripMinedLoop();
1360 }
1361 
1362 IfTrueNode* OuterStripMinedLoopNode::outer_loop_tail() const {
1363   Node* c = in(LoopBackControl);
1364   if (c == NULL || c-&gt;is_top()) {
1365     return NULL;
1366   }
1367   return c-&gt;as_IfTrue();
1368 }
1369 
1370 IfTrueNode* CountedLoopNode::outer_loop_tail() const {
1371   LoopNode* l = outer_loop();
1372   if (l == NULL) {
1373     return NULL;
1374   }
1375   return l-&gt;outer_loop_tail();
1376 }
1377 
1378 OuterStripMinedLoopEndNode* OuterStripMinedLoopNode::outer_loop_end() const {
1379   IfTrueNode* proj = outer_loop_tail();
1380   if (proj == NULL) {
1381     return NULL;
1382   }
1383   Node* c = proj-&gt;in(0);
1384   if (c == NULL || c-&gt;is_top() || c-&gt;outcnt() != 2) {
1385     return NULL;
1386   }
1387   return c-&gt;as_OuterStripMinedLoopEnd();
1388 }
1389 
1390 OuterStripMinedLoopEndNode* CountedLoopNode::outer_loop_end() const {
1391   LoopNode* l = outer_loop();
1392   if (l == NULL) {
1393     return NULL;
1394   }
1395   return l-&gt;outer_loop_end();
1396 }
1397 
1398 IfFalseNode* OuterStripMinedLoopNode::outer_loop_exit() const {
1399   IfNode* le = outer_loop_end();
1400   if (le == NULL) {
1401     return NULL;
1402   }
1403   Node* c = le-&gt;proj_out_or_null(false);
1404   if (c == NULL) {
1405     return NULL;
1406   }
1407   return c-&gt;as_IfFalse();
1408 }
1409 
1410 IfFalseNode* CountedLoopNode::outer_loop_exit() const {
1411   LoopNode* l = outer_loop();
1412   if (l == NULL) {
1413     return NULL;
1414   }
1415   return l-&gt;outer_loop_exit();
1416 }
1417 
1418 SafePointNode* OuterStripMinedLoopNode::outer_safepoint() const {
1419   IfNode* le = outer_loop_end();
1420   if (le == NULL) {
1421     return NULL;
1422   }
1423   Node* c = le-&gt;in(0);
1424   if (c == NULL || c-&gt;is_top()) {
1425     return NULL;
1426   }
1427   assert(c-&gt;Opcode() == Op_SafePoint, &quot;broken outer loop&quot;);
1428   return c-&gt;as_SafePoint();
1429 }
1430 
1431 SafePointNode* CountedLoopNode::outer_safepoint() const {
1432   LoopNode* l = outer_loop();
1433   if (l == NULL) {
1434     return NULL;
1435   }
1436   return l-&gt;outer_safepoint();
1437 }
1438 
1439 Node* CountedLoopNode::skip_predicates_from_entry(Node* ctrl) {
1440     while (ctrl != NULL &amp;&amp; ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_If() &amp;&amp;
1441            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;outcnt() == 1 &amp;&amp;
1442            ctrl-&gt;in(0)-&gt;as_If()-&gt;proj_out(1-ctrl-&gt;as_Proj()-&gt;_con)-&gt;unique_out()-&gt;Opcode() == Op_Halt) {
1443       ctrl = ctrl-&gt;in(0)-&gt;in(0);
1444     }
1445 
1446     return ctrl;
1447   }
1448 
1449 Node* CountedLoopNode::skip_predicates() {
1450   if (is_main_loop()) {
1451     Node* ctrl = skip_strip_mined()-&gt;in(LoopNode::EntryControl);
1452 
1453     return skip_predicates_from_entry(ctrl);
1454   }
1455   return in(LoopNode::EntryControl);
1456 }
1457 
1458 void OuterStripMinedLoopNode::adjust_strip_mined_loop(PhaseIterGVN* igvn) {
1459   // Look for the outer &amp; inner strip mined loop, reduce number of
1460   // iterations of the inner loop, set exit condition of outer loop,
1461   // construct required phi nodes for outer loop.
1462   CountedLoopNode* inner_cl = unique_ctrl_out()-&gt;as_CountedLoop();
1463   assert(inner_cl-&gt;is_strip_mined(), &quot;inner loop should be strip mined&quot;);
1464   Node* inner_iv_phi = inner_cl-&gt;phi();
1465   if (inner_iv_phi == NULL) {
1466     IfNode* outer_le = outer_loop_end();
1467     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1468     igvn-&gt;replace_node(outer_le, iff);
1469     inner_cl-&gt;clear_strip_mined();
1470     return;
1471   }
1472   CountedLoopEndNode* inner_cle = inner_cl-&gt;loopexit();
1473 
1474   int stride = inner_cl-&gt;stride_con();
1475   jlong scaled_iters_long = ((jlong)LoopStripMiningIter) * ABS(stride);
1476   int scaled_iters = (int)scaled_iters_long;
1477   int short_scaled_iters = LoopStripMiningIterShortLoop* ABS(stride);
1478   const TypeInt* inner_iv_t = igvn-&gt;type(inner_iv_phi)-&gt;is_int();
1479   jlong iter_estimate = (jlong)inner_iv_t-&gt;_hi - (jlong)inner_iv_t-&gt;_lo;
1480   assert(iter_estimate &gt; 0, &quot;broken&quot;);
1481   if ((jlong)scaled_iters != scaled_iters_long || iter_estimate &lt;= short_scaled_iters) {
1482     // Remove outer loop and safepoint (too few iterations)
1483     Node* outer_sfpt = outer_safepoint();
1484     Node* outer_out = outer_loop_exit();
1485     igvn-&gt;replace_node(outer_out, outer_sfpt-&gt;in(0));
1486     igvn-&gt;replace_input_of(outer_sfpt, 0, igvn-&gt;C-&gt;top());
1487     inner_cl-&gt;clear_strip_mined();
1488     return;
1489   }
1490   if (iter_estimate &lt;= scaled_iters_long) {
1491     // We would only go through one iteration of
1492     // the outer loop: drop the outer loop but
1493     // keep the safepoint so we don&#39;t run for
1494     // too long without a safepoint
1495     IfNode* outer_le = outer_loop_end();
1496     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1497     igvn-&gt;replace_node(outer_le, iff);
1498     inner_cl-&gt;clear_strip_mined();
1499     return;
1500   }
1501 
1502   Node* cle_tail = inner_cle-&gt;proj_out(true);
1503   ResourceMark rm;
1504   Node_List old_new;
1505   if (cle_tail-&gt;outcnt() &gt; 1) {
1506     // Look for nodes on backedge of inner loop and clone them
1507     Unique_Node_List backedge_nodes;
1508     for (DUIterator_Fast imax, i = cle_tail-&gt;fast_outs(imax); i &lt; imax; i++) {
1509       Node* u = cle_tail-&gt;fast_out(i);
1510       if (u != inner_cl) {
1511         assert(!u-&gt;is_CFG(), &quot;control flow on the backedge?&quot;);
1512         backedge_nodes.push(u);
1513       }
1514     }
1515     uint last = igvn-&gt;C-&gt;unique();
1516     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1517       Node* n = backedge_nodes.at(next);
1518       old_new.map(n-&gt;_idx, n-&gt;clone());
1519       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
1520         Node* u = n-&gt;fast_out(i);
1521         assert(!u-&gt;is_CFG(), &quot;broken&quot;);
1522         if (u-&gt;_idx &gt;= last) {
1523           continue;
1524         }
1525         if (!u-&gt;is_Phi()) {
1526           backedge_nodes.push(u);
1527         } else {
1528           assert(u-&gt;in(0) == inner_cl, &quot;strange phi on the backedge&quot;);
1529         }
1530       }
1531     }
1532     // Put the clones on the outer loop backedge
1533     Node* le_tail = outer_loop_tail();
1534     for (uint next = 0; next &lt; backedge_nodes.size(); next++) {
1535       Node *n = old_new[backedge_nodes.at(next)-&gt;_idx];
1536       for (uint i = 1; i &lt; n-&gt;req(); i++) {
1537         if (n-&gt;in(i) != NULL &amp;&amp; old_new[n-&gt;in(i)-&gt;_idx] != NULL) {
1538           n-&gt;set_req(i, old_new[n-&gt;in(i)-&gt;_idx]);
1539         }
1540       }
1541       if (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0) == cle_tail) {
1542         n-&gt;set_req(0, le_tail);
1543       }
1544       igvn-&gt;register_new_node_with_optimizer(n);
1545     }
1546   }
1547 
1548   Node* iv_phi = NULL;
1549   // Make a clone of each phi in the inner loop
1550   // for the outer loop
1551   for (uint i = 0; i &lt; inner_cl-&gt;outcnt(); i++) {
1552     Node* u = inner_cl-&gt;raw_out(i);
1553     if (u-&gt;is_Phi()) {
1554       assert(u-&gt;in(0) == inner_cl, &quot;inconsistent&quot;);
1555       Node* phi = u-&gt;clone();
1556       phi-&gt;set_req(0, this);
1557       Node* be = old_new[phi-&gt;in(LoopNode::LoopBackControl)-&gt;_idx];
1558       if (be != NULL) {
1559         phi-&gt;set_req(LoopNode::LoopBackControl, be);
1560       }
1561       phi = igvn-&gt;transform(phi);
1562       igvn-&gt;replace_input_of(u, LoopNode::EntryControl, phi);
1563       if (u == inner_iv_phi) {
1564         iv_phi = phi;
1565       }
1566     }
1567   }
1568   Node* cle_out = inner_cle-&gt;proj_out(false);
1569   if (cle_out-&gt;outcnt() &gt; 1) {
1570     // Look for chains of stores that were sunk
1571     // out of the inner loop and are in the outer loop
1572     for (DUIterator_Fast imax, i = cle_out-&gt;fast_outs(imax); i &lt; imax; i++) {
1573       Node* u = cle_out-&gt;fast_out(i);
1574       if (u-&gt;is_Store()) {
1575         Node* first = u;
1576         for(;;) {
1577           Node* next = first-&gt;in(MemNode::Memory);
1578           if (!next-&gt;is_Store() || next-&gt;in(0) != cle_out) {
1579             break;
1580           }
1581           first = next;
1582         }
1583         Node* last = u;
1584         for(;;) {
1585           Node* next = NULL;
1586           for (DUIterator_Fast jmax, j = last-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1587             Node* uu = last-&gt;fast_out(j);
1588             if (uu-&gt;is_Store() &amp;&amp; uu-&gt;in(0) == cle_out) {
1589               assert(next == NULL, &quot;only one in the outer loop&quot;);
1590               next = uu;
1591             }
1592           }
1593           if (next == NULL) {
1594             break;
1595           }
1596           last = next;
1597         }
1598         Node* phi = NULL;
1599         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1600           Node* uu = fast_out(j);
1601           if (uu-&gt;is_Phi()) {
1602             Node* be = uu-&gt;in(LoopNode::LoopBackControl);
1603             if (be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL) {
1604               assert(false, &quot;store on the backedge + sunk stores: unsupported&quot;);
1605               // drop outer loop
1606               IfNode* outer_le = outer_loop_end();
1607               Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1608               igvn-&gt;replace_node(outer_le, iff);
1609               inner_cl-&gt;clear_strip_mined();
1610               return;
1611             }
1612             if (be == last || be == first-&gt;in(MemNode::Memory)) {
1613               assert(phi == NULL, &quot;only one phi&quot;);
1614               phi = uu;
1615             }
1616           }
1617         }
1618 #ifdef ASSERT
1619         for (DUIterator_Fast jmax, j = fast_outs(jmax); j &lt; jmax; j++) {
1620           Node* uu = fast_out(j);
1621           if (uu-&gt;is_Phi() &amp;&amp; uu-&gt;bottom_type() == Type::MEMORY) {
1622             if (uu-&gt;adr_type() == igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()))) {
1623               assert(phi == uu, &quot;what&#39;s that phi?&quot;);
1624             } else if (uu-&gt;adr_type() == TypePtr::BOTTOM) {
1625               Node* n = uu-&gt;in(LoopNode::LoopBackControl);
1626               uint limit = igvn-&gt;C-&gt;live_nodes();
1627               uint i = 0;
1628               while (n != uu) {
1629                 i++;
1630                 assert(i &lt; limit, &quot;infinite loop&quot;);
1631                 if (n-&gt;is_Proj()) {
1632                   n = n-&gt;in(0);
1633                 } else if (n-&gt;is_SafePoint() || n-&gt;is_MemBar()) {
1634                   n = n-&gt;in(TypeFunc::Memory);
1635                 } else if (n-&gt;is_Phi()) {
1636                   n = n-&gt;in(1);
1637                 } else if (n-&gt;is_MergeMem()) {
1638                   n = n-&gt;as_MergeMem()-&gt;memory_at(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type()));
1639                 } else if (n-&gt;is_Store() || n-&gt;is_LoadStore() || n-&gt;is_ClearArray()) {
1640                   n = n-&gt;in(MemNode::Memory);
1641                 } else {
1642                   n-&gt;dump();
1643                   ShouldNotReachHere();
1644                 }
1645               }
1646             }
1647           }
1648         }
1649 #endif
1650         if (phi == NULL) {
1651           // If the an entire chains was sunk, the
1652           // inner loop has no phi for that memory
1653           // slice, create one for the outer loop
1654           phi = PhiNode::make(this, first-&gt;in(MemNode::Memory), Type::MEMORY,
1655                               igvn-&gt;C-&gt;get_adr_type(igvn-&gt;C-&gt;get_alias_index(u-&gt;adr_type())));
1656           phi-&gt;set_req(LoopNode::LoopBackControl, last);
1657           phi = igvn-&gt;transform(phi);
1658           igvn-&gt;replace_input_of(first, MemNode::Memory, phi);
1659         } else {
1660           // Or fix the outer loop fix to include
1661           // that chain of stores.
1662           Node* be = phi-&gt;in(LoopNode::LoopBackControl);
1663           assert(!(be-&gt;is_Store() &amp;&amp; old_new[be-&gt;_idx] != NULL), &quot;store on the backedge + sunk stores: unsupported&quot;);
1664           if (be == first-&gt;in(MemNode::Memory)) {
1665             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1666               igvn-&gt;replace_input_of(phi, LoopNode::LoopBackControl, last);
1667             } else {
1668               igvn-&gt;replace_input_of(be, MemNode::Memory, last);
1669             }
1670           } else {
1671 #ifdef ASSERT
1672             if (be == phi-&gt;in(LoopNode::LoopBackControl)) {
1673               assert(phi-&gt;in(LoopNode::LoopBackControl) == last, &quot;&quot;);
1674             } else {
1675               assert(be-&gt;in(MemNode::Memory) == last, &quot;&quot;);
1676             }
1677 #endif
1678           }
1679         }
1680       }
1681     }
1682   }
1683 
1684   if (iv_phi != NULL) {
1685     // Now adjust the inner loop&#39;s exit condition
1686     Node* limit = inner_cl-&gt;limit();
<a name="1" id="anc1"></a><span class="line-modified">1687     Node* sub = NULL;</span>




1688     if (stride &gt; 0) {
<a name="2" id="anc2"></a><span class="line-modified">1689       sub = igvn-&gt;transform(new SubINode(limit, iv_phi));</span>
1690     } else {
<a name="3" id="anc3"></a><span class="line-modified">1691       sub = igvn-&gt;transform(new SubINode(iv_phi, limit));</span>
1692     }
1693     // sub is positive and can be larger than the max signed int
1694     // value. Use an unsigned min.
1695     Node* const_iters = igvn-&gt;intcon(scaled_iters);
<a name="4" id="anc4"></a><span class="line-modified">1696     Node* min = MaxNode::unsigned_min(sub, const_iters, TypeInt::make(0, scaled_iters, Type::WidenMin), *igvn);</span>



1697 
1698     Node* new_limit = NULL;
1699     if (stride &gt; 0) {
1700       new_limit = igvn-&gt;transform(new AddINode(min, iv_phi));
1701     } else {
1702       new_limit = igvn-&gt;transform(new SubINode(iv_phi, min));
1703     }
1704     Node* inner_cmp = inner_cle-&gt;cmp_node();
1705     Node* inner_bol = inner_cle-&gt;in(CountedLoopEndNode::TestValue);
1706     Node* outer_bol = inner_bol;
1707     // cmp node for inner loop may be shared
1708     inner_cmp = inner_cmp-&gt;clone();
1709     inner_cmp-&gt;set_req(2, new_limit);
1710     inner_bol = inner_bol-&gt;clone();
1711     inner_bol-&gt;set_req(1, igvn-&gt;transform(inner_cmp));
1712     igvn-&gt;replace_input_of(inner_cle, CountedLoopEndNode::TestValue, igvn-&gt;transform(inner_bol));
1713     // Set the outer loop&#39;s exit condition too
1714     igvn-&gt;replace_input_of(outer_loop_end(), 1, outer_bol);
1715   } else {
1716     assert(false, &quot;should be able to adjust outer loop&quot;);
1717     IfNode* outer_le = outer_loop_end();
1718     Node* iff = igvn-&gt;transform(new IfNode(outer_le-&gt;in(0), outer_le-&gt;in(1), outer_le-&gt;_prob, outer_le-&gt;_fcnt));
1719     igvn-&gt;replace_node(outer_le, iff);
1720     inner_cl-&gt;clear_strip_mined();
1721   }
1722 }
1723 
1724 const Type* OuterStripMinedLoopEndNode::Value(PhaseGVN* phase) const {
1725   if (!in(0)) return Type::TOP;
1726   if (phase-&gt;type(in(0)) == Type::TOP)
1727     return Type::TOP;
1728 
1729   return TypeTuple::IFBOTH;
1730 }
1731 
1732 Node *OuterStripMinedLoopEndNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1733   if (remove_dead_region(phase, can_reshape))  return this;
1734 
1735   return NULL;
1736 }
1737 
1738 //------------------------------filtered_type--------------------------------
1739 // Return a type based on condition control flow
1740 // A successful return will be a type that is restricted due
1741 // to a series of dominating if-tests, such as:
1742 //    if (i &lt; 10) {
1743 //       if (i &gt; 0) {
1744 //          here: &quot;i&quot; type is [1..10)
1745 //       }
1746 //    }
1747 // or a control flow merge
1748 //    if (i &lt; 10) {
1749 //       do {
1750 //          phi( , ) -- at top of loop type is [min_int..10)
1751 //         i = ?
1752 //       } while ( i &lt; 10)
1753 //
1754 const TypeInt* PhaseIdealLoop::filtered_type( Node *n, Node* n_ctrl) {
1755   assert(n &amp;&amp; n-&gt;bottom_type()-&gt;is_int(), &quot;must be int&quot;);
1756   const TypeInt* filtered_t = NULL;
1757   if (!n-&gt;is_Phi()) {
1758     assert(n_ctrl != NULL || n_ctrl == C-&gt;top(), &quot;valid control&quot;);
1759     filtered_t = filtered_type_from_dominators(n, n_ctrl);
1760 
1761   } else {
1762     Node* phi    = n-&gt;as_Phi();
1763     Node* region = phi-&gt;in(0);
1764     assert(n_ctrl == NULL || n_ctrl == region, &quot;ctrl parameter must be region&quot;);
1765     if (region &amp;&amp; region != C-&gt;top()) {
1766       for (uint i = 1; i &lt; phi-&gt;req(); i++) {
1767         Node* val   = phi-&gt;in(i);
1768         Node* use_c = region-&gt;in(i);
1769         const TypeInt* val_t = filtered_type_from_dominators(val, use_c);
1770         if (val_t != NULL) {
1771           if (filtered_t == NULL) {
1772             filtered_t = val_t;
1773           } else {
1774             filtered_t = filtered_t-&gt;meet(val_t)-&gt;is_int();
1775           }
1776         }
1777       }
1778     }
1779   }
1780   const TypeInt* n_t = _igvn.type(n)-&gt;is_int();
1781   if (filtered_t != NULL) {
1782     n_t = n_t-&gt;join(filtered_t)-&gt;is_int();
1783   }
1784   return n_t;
1785 }
1786 
1787 
1788 //------------------------------filtered_type_from_dominators--------------------------------
1789 // Return a possibly more restrictive type for val based on condition control flow of dominators
1790 const TypeInt* PhaseIdealLoop::filtered_type_from_dominators( Node* val, Node *use_ctrl) {
1791   if (val-&gt;is_Con()) {
1792      return val-&gt;bottom_type()-&gt;is_int();
1793   }
1794   uint if_limit = 10; // Max number of dominating if&#39;s visited
1795   const TypeInt* rtn_t = NULL;
1796 
1797   if (use_ctrl &amp;&amp; use_ctrl != C-&gt;top()) {
1798     Node* val_ctrl = get_ctrl(val);
1799     uint val_dom_depth = dom_depth(val_ctrl);
1800     Node* pred = use_ctrl;
1801     uint if_cnt = 0;
1802     while (if_cnt &lt; if_limit) {
1803       if ((pred-&gt;Opcode() == Op_IfTrue || pred-&gt;Opcode() == Op_IfFalse)) {
1804         if_cnt++;
1805         const TypeInt* if_t = IfNode::filtered_int_type(&amp;_igvn, val, pred);
1806         if (if_t != NULL) {
1807           if (rtn_t == NULL) {
1808             rtn_t = if_t;
1809           } else {
1810             rtn_t = rtn_t-&gt;join(if_t)-&gt;is_int();
1811           }
1812         }
1813       }
1814       pred = idom(pred);
1815       if (pred == NULL || pred == C-&gt;top()) {
1816         break;
1817       }
1818       // Stop if going beyond definition block of val
1819       if (dom_depth(pred) &lt; val_dom_depth) {
1820         break;
1821       }
1822     }
1823   }
1824   return rtn_t;
1825 }
1826 
1827 
1828 //------------------------------dump_spec--------------------------------------
1829 // Dump special per-node info
1830 #ifndef PRODUCT
1831 void CountedLoopEndNode::dump_spec(outputStream *st) const {
1832   if( in(TestValue) != NULL &amp;&amp; in(TestValue)-&gt;is_Bool() ) {
1833     BoolTest bt( test_trip()); // Added this for g++.
1834 
1835     st-&gt;print(&quot;[&quot;);
1836     bt.dump_on(st);
1837     st-&gt;print(&quot;]&quot;);
1838   }
1839   st-&gt;print(&quot; &quot;);
1840   IfNode::dump_spec(st);
1841 }
1842 #endif
1843 
1844 //=============================================================================
1845 //------------------------------is_member--------------------------------------
1846 // Is &#39;l&#39; a member of &#39;this&#39;?
1847 bool IdealLoopTree::is_member(const IdealLoopTree *l) const {
1848   while( l-&gt;_nest &gt; _nest ) l = l-&gt;_parent;
1849   return l == this;
1850 }
1851 
1852 //------------------------------set_nest---------------------------------------
1853 // Set loop tree nesting depth.  Accumulate _has_call bits.
1854 int IdealLoopTree::set_nest( uint depth ) {
1855   _nest = depth;
1856   int bits = _has_call;
1857   if( _child ) bits |= _child-&gt;set_nest(depth+1);
1858   if( bits ) _has_call = 1;
1859   if( _next  ) bits |= _next -&gt;set_nest(depth  );
1860   return bits;
1861 }
1862 
1863 //------------------------------split_fall_in----------------------------------
1864 // Split out multiple fall-in edges from the loop header.  Move them to a
1865 // private RegionNode before the loop.  This becomes the loop landing pad.
1866 void IdealLoopTree::split_fall_in( PhaseIdealLoop *phase, int fall_in_cnt ) {
1867   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1868   uint i;
1869 
1870   // Make a new RegionNode to be the landing pad.
1871   Node *landing_pad = new RegionNode( fall_in_cnt+1 );
1872   phase-&gt;set_loop(landing_pad,_parent);
1873   // Gather all the fall-in control paths into the landing pad
1874   uint icnt = fall_in_cnt;
1875   uint oreq = _head-&gt;req();
1876   for( i = oreq-1; i&gt;0; i-- )
1877     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
1878       landing_pad-&gt;set_req(icnt--,_head-&gt;in(i));
1879 
1880   // Peel off PhiNode edges as well
1881   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1882     Node *oj = _head-&gt;fast_out(j);
1883     if( oj-&gt;is_Phi() ) {
1884       PhiNode* old_phi = oj-&gt;as_Phi();
1885       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1886       igvn.hash_delete(old_phi);   // Yank from hash before hacking edges
1887       Node *p = PhiNode::make_blank(landing_pad, old_phi);
1888       uint icnt = fall_in_cnt;
1889       for( i = oreq-1; i&gt;0; i-- ) {
1890         if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1891           p-&gt;init_req(icnt--, old_phi-&gt;in(i));
1892           // Go ahead and clean out old edges from old phi
1893           old_phi-&gt;del_req(i);
1894         }
1895       }
1896       // Search for CSE&#39;s here, because ZKM.jar does a lot of
1897       // loop hackery and we need to be a little incremental
1898       // with the CSE to avoid O(N^2) node blow-up.
1899       Node *p2 = igvn.hash_find_insert(p); // Look for a CSE
1900       if( p2 ) {                // Found CSE
1901         p-&gt;destruct();          // Recover useless new node
1902         p = p2;                 // Use old node
1903       } else {
1904         igvn.register_new_node_with_optimizer(p, old_phi);
1905       }
1906       // Make old Phi refer to new Phi.
1907       old_phi-&gt;add_req(p);
1908       // Check for the special case of making the old phi useless and
1909       // disappear it.  In JavaGrande I have a case where this useless
1910       // Phi is the loop limit and prevents recognizing a CountedLoop
1911       // which in turn prevents removing an empty loop.
1912       Node *id_old_phi = old_phi-&gt;Identity(&amp;igvn);
1913       if( id_old_phi != old_phi ) { // Found a simple identity?
1914         // Note that I cannot call &#39;replace_node&#39; here, because
1915         // that will yank the edge from old_phi to the Region and
1916         // I&#39;m mid-iteration over the Region&#39;s uses.
1917         for (DUIterator_Last imin, i = old_phi-&gt;last_outs(imin); i &gt;= imin; ) {
1918           Node* use = old_phi-&gt;last_out(i);
1919           igvn.rehash_node_delayed(use);
1920           uint uses_found = 0;
1921           for (uint j = 0; j &lt; use-&gt;len(); j++) {
1922             if (use-&gt;in(j) == old_phi) {
1923               if (j &lt; use-&gt;req()) use-&gt;set_req (j, id_old_phi);
1924               else                use-&gt;set_prec(j, id_old_phi);
1925               uses_found++;
1926             }
1927           }
1928           i -= uses_found;    // we deleted 1 or more copies of this edge
1929         }
1930       }
1931       igvn._worklist.push(old_phi);
1932     }
1933   }
1934   // Finally clean out the fall-in edges from the RegionNode
1935   for( i = oreq-1; i&gt;0; i-- ) {
1936     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) ) {
1937       _head-&gt;del_req(i);
1938     }
1939   }
1940   igvn.rehash_node_delayed(_head);
1941   // Transform landing pad
1942   igvn.register_new_node_with_optimizer(landing_pad, _head);
1943   // Insert landing pad into the header
1944   _head-&gt;add_req(landing_pad);
1945 }
1946 
1947 //------------------------------split_outer_loop-------------------------------
1948 // Split out the outermost loop from this shared header.
1949 void IdealLoopTree::split_outer_loop( PhaseIdealLoop *phase ) {
1950   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
1951 
1952   // Find index of outermost loop; it should also be my tail.
1953   uint outer_idx = 1;
1954   while( _head-&gt;in(outer_idx) != _tail ) outer_idx++;
1955 
1956   // Make a LoopNode for the outermost loop.
1957   Node *ctl = _head-&gt;in(LoopNode::EntryControl);
1958   Node *outer = new LoopNode( ctl, _head-&gt;in(outer_idx) );
1959   outer = igvn.register_new_node_with_optimizer(outer, _head);
1960   phase-&gt;set_created_loop_node();
1961 
1962   // Outermost loop falls into &#39;_head&#39; loop
1963   _head-&gt;set_req(LoopNode::EntryControl, outer);
1964   _head-&gt;del_req(outer_idx);
1965   // Split all the Phis up between &#39;_head&#39; loop and &#39;outer&#39; loop.
1966   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1967     Node *out = _head-&gt;fast_out(j);
1968     if( out-&gt;is_Phi() ) {
1969       PhiNode *old_phi = out-&gt;as_Phi();
1970       assert( old_phi-&gt;region() == _head, &quot;&quot; );
1971       Node *phi = PhiNode::make_blank(outer, old_phi);
1972       phi-&gt;init_req(LoopNode::EntryControl,    old_phi-&gt;in(LoopNode::EntryControl));
1973       phi-&gt;init_req(LoopNode::LoopBackControl, old_phi-&gt;in(outer_idx));
1974       phi = igvn.register_new_node_with_optimizer(phi, old_phi);
1975       // Make old Phi point to new Phi on the fall-in path
1976       igvn.replace_input_of(old_phi, LoopNode::EntryControl, phi);
1977       old_phi-&gt;del_req(outer_idx);
1978     }
1979   }
1980 
1981   // Use the new loop head instead of the old shared one
1982   _head = outer;
1983   phase-&gt;set_loop(_head, this);
1984 }
1985 
1986 //------------------------------fix_parent-------------------------------------
1987 static void fix_parent( IdealLoopTree *loop, IdealLoopTree *parent ) {
1988   loop-&gt;_parent = parent;
1989   if( loop-&gt;_child ) fix_parent( loop-&gt;_child, loop   );
1990   if( loop-&gt;_next  ) fix_parent( loop-&gt;_next , parent );
1991 }
1992 
1993 //------------------------------estimate_path_freq-----------------------------
1994 static float estimate_path_freq( Node *n ) {
1995   // Try to extract some path frequency info
1996   IfNode *iff;
1997   for( int i = 0; i &lt; 50; i++ ) { // Skip through a bunch of uncommon tests
1998     uint nop = n-&gt;Opcode();
1999     if( nop == Op_SafePoint ) {   // Skip any safepoint
2000       n = n-&gt;in(0);
2001       continue;
2002     }
2003     if( nop == Op_CatchProj ) {   // Get count from a prior call
2004       // Assume call does not always throw exceptions: means the call-site
2005       // count is also the frequency of the fall-through path.
2006       assert( n-&gt;is_CatchProj(), &quot;&quot; );
2007       if( ((CatchProjNode*)n)-&gt;_con != CatchProjNode::fall_through_index )
2008         return 0.0f;            // Assume call exception path is rare
2009       Node *call = n-&gt;in(0)-&gt;in(0)-&gt;in(0);
2010       assert( call-&gt;is_Call(), &quot;expect a call here&quot; );
2011       const JVMState *jvms = ((CallNode*)call)-&gt;jvms();
2012       ciMethodData* methodData = jvms-&gt;method()-&gt;method_data();
2013       if (!methodData-&gt;is_mature())  return 0.0f; // No call-site data
2014       ciProfileData* data = methodData-&gt;bci_to_data(jvms-&gt;bci());
2015       if ((data == NULL) || !data-&gt;is_CounterData()) {
2016         // no call profile available, try call&#39;s control input
2017         n = n-&gt;in(0);
2018         continue;
2019       }
2020       return data-&gt;as_CounterData()-&gt;count()/FreqCountInvocations;
2021     }
2022     // See if there&#39;s a gating IF test
2023     Node *n_c = n-&gt;in(0);
2024     if( !n_c-&gt;is_If() ) break;       // No estimate available
2025     iff = n_c-&gt;as_If();
2026     if( iff-&gt;_fcnt != COUNT_UNKNOWN )   // Have a valid count?
2027       // Compute how much count comes on this path
2028       return ((nop == Op_IfTrue) ? iff-&gt;_prob : 1.0f - iff-&gt;_prob) * iff-&gt;_fcnt;
2029     // Have no count info.  Skip dull uncommon-trap like branches.
2030     if( (nop == Op_IfTrue  &amp;&amp; iff-&gt;_prob &lt; PROB_LIKELY_MAG(5)) ||
2031         (nop == Op_IfFalse &amp;&amp; iff-&gt;_prob &gt; PROB_UNLIKELY_MAG(5)) )
2032       break;
2033     // Skip through never-taken branch; look for a real loop exit.
2034     n = iff-&gt;in(0);
2035   }
2036   return 0.0f;                  // No estimate available
2037 }
2038 
2039 //------------------------------merge_many_backedges---------------------------
2040 // Merge all the backedges from the shared header into a private Region.
2041 // Feed that region as the one backedge to this loop.
2042 void IdealLoopTree::merge_many_backedges( PhaseIdealLoop *phase ) {
2043   uint i;
2044 
2045   // Scan for the top 2 hottest backedges
2046   float hotcnt = 0.0f;
2047   float warmcnt = 0.0f;
2048   uint hot_idx = 0;
2049   // Loop starts at 2 because slot 1 is the fall-in path
2050   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
2051     float cnt = estimate_path_freq(_head-&gt;in(i));
2052     if( cnt &gt; hotcnt ) {       // Grab hottest path
2053       warmcnt = hotcnt;
2054       hotcnt = cnt;
2055       hot_idx = i;
2056     } else if( cnt &gt; warmcnt ) { // And 2nd hottest path
2057       warmcnt = cnt;
2058     }
2059   }
2060 
2061   // See if the hottest backedge is worthy of being an inner loop
2062   // by being much hotter than the next hottest backedge.
2063   if( hotcnt &lt;= 0.0001 ||
2064       hotcnt &lt; 2.0*warmcnt ) hot_idx = 0;// No hot backedge
2065 
2066   // Peel out the backedges into a private merge point; peel
2067   // them all except optionally hot_idx.
2068   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
2069 
2070   Node *hot_tail = NULL;
2071   // Make a Region for the merge point
2072   Node *r = new RegionNode(1);
2073   for( i = 2; i &lt; _head-&gt;req(); i++ ) {
2074     if( i != hot_idx )
2075       r-&gt;add_req( _head-&gt;in(i) );
2076     else hot_tail = _head-&gt;in(i);
2077   }
2078   igvn.register_new_node_with_optimizer(r, _head);
2079   // Plug region into end of loop _head, followed by hot_tail
2080   while( _head-&gt;req() &gt; 3 ) _head-&gt;del_req( _head-&gt;req()-1 );
2081   igvn.replace_input_of(_head, 2, r);
2082   if( hot_idx ) _head-&gt;add_req(hot_tail);
2083 
2084   // Split all the Phis up between &#39;_head&#39; loop and the Region &#39;r&#39;
2085   for (DUIterator_Fast jmax, j = _head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2086     Node *out = _head-&gt;fast_out(j);
2087     if( out-&gt;is_Phi() ) {
2088       PhiNode* n = out-&gt;as_Phi();
2089       igvn.hash_delete(n);      // Delete from hash before hacking edges
2090       Node *hot_phi = NULL;
2091       Node *phi = new PhiNode(r, n-&gt;type(), n-&gt;adr_type());
2092       // Check all inputs for the ones to peel out
2093       uint j = 1;
2094       for( uint i = 2; i &lt; n-&gt;req(); i++ ) {
2095         if( i != hot_idx )
2096           phi-&gt;set_req( j++, n-&gt;in(i) );
2097         else hot_phi = n-&gt;in(i);
2098       }
2099       // Register the phi but do not transform until whole place transforms
2100       igvn.register_new_node_with_optimizer(phi, n);
2101       // Add the merge phi to the old Phi
2102       while( n-&gt;req() &gt; 3 ) n-&gt;del_req( n-&gt;req()-1 );
2103       igvn.replace_input_of(n, 2, phi);
2104       if( hot_idx ) n-&gt;add_req(hot_phi);
2105     }
2106   }
2107 
2108 
2109   // Insert a new IdealLoopTree inserted below me.  Turn it into a clone
2110   // of self loop tree.  Turn self into a loop headed by _head and with
2111   // tail being the new merge point.
2112   IdealLoopTree *ilt = new IdealLoopTree( phase, _head, _tail );
2113   phase-&gt;set_loop(_tail,ilt);   // Adjust tail
2114   _tail = r;                    // Self&#39;s tail is new merge point
2115   phase-&gt;set_loop(r,this);
2116   ilt-&gt;_child = _child;         // New guy has my children
2117   _child = ilt;                 // Self has new guy as only child
2118   ilt-&gt;_parent = this;          // new guy has self for parent
2119   ilt-&gt;_nest = _nest;           // Same nesting depth (for now)
2120 
2121   // Starting with &#39;ilt&#39;, look for child loop trees using the same shared
2122   // header.  Flatten these out; they will no longer be loops in the end.
2123   IdealLoopTree **pilt = &amp;_child;
2124   while( ilt ) {
2125     if( ilt-&gt;_head == _head ) {
2126       uint i;
2127       for( i = 2; i &lt; _head-&gt;req(); i++ )
2128         if( _head-&gt;in(i) == ilt-&gt;_tail )
2129           break;                // Still a loop
2130       if( i == _head-&gt;req() ) { // No longer a loop
2131         // Flatten ilt.  Hang ilt&#39;s &quot;_next&quot; list from the end of
2132         // ilt&#39;s &#39;_child&#39; list.  Move the ilt&#39;s _child up to replace ilt.
2133         IdealLoopTree **cp = &amp;ilt-&gt;_child;
2134         while( *cp ) cp = &amp;(*cp)-&gt;_next;   // Find end of child list
2135         *cp = ilt-&gt;_next;       // Hang next list at end of child list
2136         *pilt = ilt-&gt;_child;    // Move child up to replace ilt
2137         ilt-&gt;_head = NULL;      // Flag as a loop UNIONED into parent
2138         ilt = ilt-&gt;_child;      // Repeat using new ilt
2139         continue;               // do not advance over ilt-&gt;_child
2140       }
2141       assert( ilt-&gt;_tail == hot_tail, &quot;expected to only find the hot inner loop here&quot; );
2142       phase-&gt;set_loop(_head,ilt);
2143     }
2144     pilt = &amp;ilt-&gt;_child;        // Advance to next
2145     ilt = *pilt;
2146   }
2147 
2148   if( _child ) fix_parent( _child, this );
2149 }
2150 
2151 //------------------------------beautify_loops---------------------------------
2152 // Split shared headers and insert loop landing pads.
2153 // Insert a LoopNode to replace the RegionNode.
2154 // Return TRUE if loop tree is structurally changed.
2155 bool IdealLoopTree::beautify_loops( PhaseIdealLoop *phase ) {
2156   bool result = false;
2157   // Cache parts in locals for easy
2158   PhaseIterGVN &amp;igvn = phase-&gt;_igvn;
2159 
2160   igvn.hash_delete(_head);      // Yank from hash before hacking edges
2161 
2162   // Check for multiple fall-in paths.  Peel off a landing pad if need be.
2163   int fall_in_cnt = 0;
2164   for( uint i = 1; i &lt; _head-&gt;req(); i++ )
2165     if( !phase-&gt;is_member( this, _head-&gt;in(i) ) )
2166       fall_in_cnt++;
2167   assert( fall_in_cnt, &quot;at least 1 fall-in path&quot; );
2168   if( fall_in_cnt &gt; 1 )         // Need a loop landing pad to merge fall-ins
2169     split_fall_in( phase, fall_in_cnt );
2170 
2171   // Swap inputs to the _head and all Phis to move the fall-in edge to
2172   // the left.
2173   fall_in_cnt = 1;
2174   while( phase-&gt;is_member( this, _head-&gt;in(fall_in_cnt) ) )
2175     fall_in_cnt++;
2176   if( fall_in_cnt &gt; 1 ) {
2177     // Since I am just swapping inputs I do not need to update def-use info
2178     Node *tmp = _head-&gt;in(1);
2179     igvn.rehash_node_delayed(_head);
2180     _head-&gt;set_req( 1, _head-&gt;in(fall_in_cnt) );
2181     _head-&gt;set_req( fall_in_cnt, tmp );
2182     // Swap also all Phis
2183     for (DUIterator_Fast imax, i = _head-&gt;fast_outs(imax); i &lt; imax; i++) {
2184       Node* phi = _head-&gt;fast_out(i);
2185       if( phi-&gt;is_Phi() ) {
2186         igvn.rehash_node_delayed(phi); // Yank from hash before hacking edges
2187         tmp = phi-&gt;in(1);
2188         phi-&gt;set_req( 1, phi-&gt;in(fall_in_cnt) );
2189         phi-&gt;set_req( fall_in_cnt, tmp );
2190       }
2191     }
2192   }
2193   assert( !phase-&gt;is_member( this, _head-&gt;in(1) ), &quot;left edge is fall-in&quot; );
2194   assert(  phase-&gt;is_member( this, _head-&gt;in(2) ), &quot;right edge is loop&quot; );
2195 
2196   // If I am a shared header (multiple backedges), peel off the many
2197   // backedges into a private merge point and use the merge point as
2198   // the one true backedge.
2199   if (_head-&gt;req() &gt; 3) {
2200     // Merge the many backedges into a single backedge but leave
2201     // the hottest backedge as separate edge for the following peel.
2202     if (!_irreducible) {
2203       merge_many_backedges( phase );
2204     }
2205 
2206     // When recursively beautify my children, split_fall_in can change
2207     // loop tree structure when I am an irreducible loop. Then the head
2208     // of my children has a req() not bigger than 3. Here we need to set
2209     // result to true to catch that case in order to tell the caller to
2210     // rebuild loop tree. See issue JDK-8244407 for details.
2211     result = true;
2212   }
2213 
2214   // If I have one hot backedge, peel off myself loop.
2215   // I better be the outermost loop.
2216   if (_head-&gt;req() &gt; 3 &amp;&amp; !_irreducible) {
2217     split_outer_loop( phase );
2218     result = true;
2219 
2220   } else if (!_head-&gt;is_Loop() &amp;&amp; !_irreducible) {
2221     // Make a new LoopNode to replace the old loop head
2222     Node *l = new LoopNode( _head-&gt;in(1), _head-&gt;in(2) );
2223     l = igvn.register_new_node_with_optimizer(l, _head);
2224     phase-&gt;set_created_loop_node();
2225     // Go ahead and replace _head
2226     phase-&gt;_igvn.replace_node( _head, l );
2227     _head = l;
2228     phase-&gt;set_loop(_head, this);
2229   }
2230 
2231   // Now recursively beautify nested loops
2232   if( _child ) result |= _child-&gt;beautify_loops( phase );
2233   if( _next  ) result |= _next -&gt;beautify_loops( phase );
2234   return result;
2235 }
2236 
2237 //------------------------------allpaths_check_safepts----------------------------
2238 // Allpaths backwards scan from loop tail, terminating each path at first safepoint
2239 // encountered.  Helper for check_safepts.
2240 void IdealLoopTree::allpaths_check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2241   assert(stack.size() == 0, &quot;empty stack&quot;);
2242   stack.push(_tail);
2243   visited.clear();
2244   visited.set(_tail-&gt;_idx);
2245   while (stack.size() &gt; 0) {
2246     Node* n = stack.pop();
2247     if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2248       // Terminate this path
2249     } else if (n-&gt;Opcode() == Op_SafePoint) {
2250       if (_phase-&gt;get_loop(n) != this) {
2251         if (_required_safept == NULL) _required_safept = new Node_List();
2252         _required_safept-&gt;push(n);  // save the one closest to the tail
2253       }
2254       // Terminate this path
2255     } else {
2256       uint start = n-&gt;is_Region() ? 1 : 0;
2257       uint end   = n-&gt;is_Region() &amp;&amp; !n-&gt;is_Loop() ? n-&gt;req() : start + 1;
2258       for (uint i = start; i &lt; end; i++) {
2259         Node* in = n-&gt;in(i);
2260         assert(in-&gt;is_CFG(), &quot;must be&quot;);
2261         if (!visited.test_set(in-&gt;_idx) &amp;&amp; is_member(_phase-&gt;get_loop(in))) {
2262           stack.push(in);
2263         }
2264       }
2265     }
2266   }
2267 }
2268 
2269 //------------------------------check_safepts----------------------------
2270 // Given dominators, try to find loops with calls that must always be
2271 // executed (call dominates loop tail).  These loops do not need non-call
2272 // safepoints (ncsfpt).
2273 //
2274 // A complication is that a safepoint in a inner loop may be needed
2275 // by an outer loop. In the following, the inner loop sees it has a
2276 // call (block 3) on every path from the head (block 2) to the
2277 // backedge (arc 3-&gt;2).  So it deletes the ncsfpt (non-call safepoint)
2278 // in block 2, _but_ this leaves the outer loop without a safepoint.
2279 //
2280 //          entry  0
2281 //                 |
2282 //                 v
2283 // outer 1,2    +-&gt;1
2284 //              |  |
2285 //              |  v
2286 //              |  2&lt;---+  ncsfpt in 2
2287 //              |_/|\   |
2288 //                 | v  |
2289 // inner 2,3      /  3  |  call in 3
2290 //               /   |  |
2291 //              v    +--+
2292 //        exit  4
2293 //
2294 //
2295 // This method creates a list (_required_safept) of ncsfpt nodes that must
2296 // be protected is created for each loop. When a ncsfpt maybe deleted, it
2297 // is first looked for in the lists for the outer loops of the current loop.
2298 //
2299 // The insights into the problem:
2300 //  A) counted loops are okay
2301 //  B) innermost loops are okay (only an inner loop can delete
2302 //     a ncsfpt needed by an outer loop)
2303 //  C) a loop is immune from an inner loop deleting a safepoint
2304 //     if the loop has a call on the idom-path
2305 //  D) a loop is also immune if it has a ncsfpt (non-call safepoint) on the
2306 //     idom-path that is not in a nested loop
2307 //  E) otherwise, an ncsfpt on the idom-path that is nested in an inner
2308 //     loop needs to be prevented from deletion by an inner loop
2309 //
2310 // There are two analyses:
2311 //  1) The first, and cheaper one, scans the loop body from
2312 //     tail to head following the idom (immediate dominator)
2313 //     chain, looking for the cases (C,D,E) above.
2314 //     Since inner loops are scanned before outer loops, there is summary
2315 //     information about inner loops.  Inner loops can be skipped over
2316 //     when the tail of an inner loop is encountered.
2317 //
2318 //  2) The second, invoked if the first fails to find a call or ncsfpt on
2319 //     the idom path (which is rare), scans all predecessor control paths
2320 //     from the tail to the head, terminating a path when a call or sfpt
2321 //     is encountered, to find the ncsfpt&#39;s that are closest to the tail.
2322 //
2323 void IdealLoopTree::check_safepts(VectorSet &amp;visited, Node_List &amp;stack) {
2324   // Bottom up traversal
2325   IdealLoopTree* ch = _child;
2326   if (_child) _child-&gt;check_safepts(visited, stack);
2327   if (_next)  _next -&gt;check_safepts(visited, stack);
2328 
2329   if (!_head-&gt;is_CountedLoop() &amp;&amp; !_has_sfpt &amp;&amp; _parent != NULL &amp;&amp; !_irreducible) {
2330     bool  has_call         = false; // call on dom-path
2331     bool  has_local_ncsfpt = false; // ncsfpt on dom-path at this loop depth
2332     Node* nonlocal_ncsfpt  = NULL;  // ncsfpt on dom-path at a deeper depth
2333     // Scan the dom-path nodes from tail to head
2334     for (Node* n = tail(); n != _head; n = _phase-&gt;idom(n)) {
2335       if (n-&gt;is_Call() &amp;&amp; n-&gt;as_Call()-&gt;guaranteed_safepoint()) {
2336         has_call = true;
2337         _has_sfpt = 1;          // Then no need for a safept!
2338         break;
2339       } else if (n-&gt;Opcode() == Op_SafePoint) {
2340         if (_phase-&gt;get_loop(n) == this) {
2341           has_local_ncsfpt = true;
2342           break;
2343         }
2344         if (nonlocal_ncsfpt == NULL) {
2345           nonlocal_ncsfpt = n; // save the one closest to the tail
2346         }
2347       } else {
2348         IdealLoopTree* nlpt = _phase-&gt;get_loop(n);
2349         if (this != nlpt) {
2350           // If at an inner loop tail, see if the inner loop has already
2351           // recorded seeing a call on the dom-path (and stop.)  If not,
2352           // jump to the head of the inner loop.
2353           assert(is_member(nlpt), &quot;nested loop&quot;);
2354           Node* tail = nlpt-&gt;_tail;
2355           if (tail-&gt;in(0)-&gt;is_If()) tail = tail-&gt;in(0);
2356           if (n == tail) {
2357             // If inner loop has call on dom-path, so does outer loop
2358             if (nlpt-&gt;_has_sfpt) {
2359               has_call = true;
2360               _has_sfpt = 1;
2361               break;
2362             }
2363             // Skip to head of inner loop
2364             assert(_phase-&gt;is_dominator(_head, nlpt-&gt;_head), &quot;inner head dominated by outer head&quot;);
2365             n = nlpt-&gt;_head;
2366           }
2367         }
2368       }
2369     }
2370     // Record safept&#39;s that this loop needs preserved when an
2371     // inner loop attempts to delete it&#39;s safepoints.
2372     if (_child != NULL &amp;&amp; !has_call &amp;&amp; !has_local_ncsfpt) {
2373       if (nonlocal_ncsfpt != NULL) {
2374         if (_required_safept == NULL) _required_safept = new Node_List();
2375         _required_safept-&gt;push(nonlocal_ncsfpt);
2376       } else {
2377         // Failed to find a suitable safept on the dom-path.  Now use
2378         // an all paths walk from tail to head, looking for safepoints to preserve.
2379         allpaths_check_safepts(visited, stack);
2380       }
2381     }
2382   }
2383 }
2384 
2385 //---------------------------is_deleteable_safept----------------------------
2386 // Is safept not required by an outer loop?
2387 bool PhaseIdealLoop::is_deleteable_safept(Node* sfpt) {
2388   assert(sfpt-&gt;Opcode() == Op_SafePoint, &quot;&quot;);
2389   IdealLoopTree* lp = get_loop(sfpt)-&gt;_parent;
2390   while (lp != NULL) {
2391     Node_List* sfpts = lp-&gt;_required_safept;
2392     if (sfpts != NULL) {
2393       for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2394         if (sfpt == sfpts-&gt;at(i))
2395           return false;
2396       }
2397     }
2398     lp = lp-&gt;_parent;
2399   }
2400   return true;
2401 }
2402 
2403 //---------------------------replace_parallel_iv-------------------------------
2404 // Replace parallel induction variable (parallel to trip counter)
2405 void PhaseIdealLoop::replace_parallel_iv(IdealLoopTree *loop) {
2406   assert(loop-&gt;_head-&gt;is_CountedLoop(), &quot;&quot;);
2407   CountedLoopNode *cl = loop-&gt;_head-&gt;as_CountedLoop();
2408   if (!cl-&gt;is_valid_counted_loop())
2409     return;         // skip malformed counted loop
2410   Node *incr = cl-&gt;incr();
2411   if (incr == NULL)
2412     return;         // Dead loop?
2413   Node *init = cl-&gt;init_trip();
2414   Node *phi  = cl-&gt;phi();
2415   int stride_con = cl-&gt;stride_con();
2416 
2417   // Visit all children, looking for Phis
2418   for (DUIterator i = cl-&gt;outs(); cl-&gt;has_out(i); i++) {
2419     Node *out = cl-&gt;out(i);
2420     // Look for other phis (secondary IVs). Skip dead ones
2421     if (!out-&gt;is_Phi() || out == phi || !has_node(out))
2422       continue;
2423     PhiNode* phi2 = out-&gt;as_Phi();
2424     Node *incr2 = phi2-&gt;in( LoopNode::LoopBackControl );
2425     // Look for induction variables of the form:  X += constant
2426     if (phi2-&gt;region() != loop-&gt;_head ||
2427         incr2-&gt;req() != 3 ||
2428         incr2-&gt;in(1) != phi2 ||
2429         incr2 == incr ||
2430         incr2-&gt;Opcode() != Op_AddI ||
2431         !incr2-&gt;in(2)-&gt;is_Con())
2432       continue;
2433 
2434     // Check for parallel induction variable (parallel to trip counter)
2435     // via an affine function.  In particular, count-down loops with
2436     // count-up array indices are common. We only RCE references off
2437     // the trip-counter, so we need to convert all these to trip-counter
2438     // expressions.
2439     Node *init2 = phi2-&gt;in( LoopNode::EntryControl );
2440     int stride_con2 = incr2-&gt;in(2)-&gt;get_int();
2441 
2442     // The ratio of the two strides cannot be represented as an int
2443     // if stride_con2 is min_int and stride_con is -1.
2444     if (stride_con2 == min_jint &amp;&amp; stride_con == -1) {
2445       continue;
2446     }
2447 
2448     // The general case here gets a little tricky.  We want to find the
2449     // GCD of all possible parallel IV&#39;s and make a new IV using this
2450     // GCD for the loop.  Then all possible IVs are simple multiples of
2451     // the GCD.  In practice, this will cover very few extra loops.
2452     // Instead we require &#39;stride_con2&#39; to be a multiple of &#39;stride_con&#39;,
2453     // where +/-1 is the common case, but other integer multiples are
2454     // also easy to handle.
2455     int ratio_con = stride_con2/stride_con;
2456 
2457     if ((ratio_con * stride_con) == stride_con2) { // Check for exact
2458 #ifndef PRODUCT
2459       if (TraceLoopOpts) {
2460         tty-&gt;print(&quot;Parallel IV: %d &quot;, phi2-&gt;_idx);
2461         loop-&gt;dump_head();
2462       }
2463 #endif
2464       // Convert to using the trip counter.  The parallel induction
2465       // variable differs from the trip counter by a loop-invariant
2466       // amount, the difference between their respective initial values.
2467       // It is scaled by the &#39;ratio_con&#39;.
2468       Node* ratio = _igvn.intcon(ratio_con);
2469       set_ctrl(ratio, C-&gt;root());
2470       Node* ratio_init = new MulINode(init, ratio);
2471       _igvn.register_new_node_with_optimizer(ratio_init, init);
2472       set_early_ctrl(ratio_init);
2473       Node* diff = new SubINode(init2, ratio_init);
2474       _igvn.register_new_node_with_optimizer(diff, init2);
2475       set_early_ctrl(diff);
2476       Node* ratio_idx = new MulINode(phi, ratio);
2477       _igvn.register_new_node_with_optimizer(ratio_idx, phi);
2478       set_ctrl(ratio_idx, cl);
2479       Node* add = new AddINode(ratio_idx, diff);
2480       _igvn.register_new_node_with_optimizer(add);
2481       set_ctrl(add, cl);
2482       _igvn.replace_node( phi2, add );
2483       // Sometimes an induction variable is unused
2484       if (add-&gt;outcnt() == 0) {
2485         _igvn.remove_dead_node(add);
2486       }
2487       --i; // deleted this phi; rescan starting with next position
2488       continue;
2489     }
2490   }
2491 }
2492 
2493 void IdealLoopTree::remove_safepoints(PhaseIdealLoop* phase, bool keep_one) {
2494   Node* keep = NULL;
2495   if (keep_one) {
2496     // Look for a safepoint on the idom-path.
2497     for (Node* i = tail(); i != _head; i = phase-&gt;idom(i)) {
2498       if (i-&gt;Opcode() == Op_SafePoint &amp;&amp; phase-&gt;get_loop(i) == this) {
2499         keep = i;
2500         break; // Found one
2501       }
2502     }
2503   }
2504 
2505   // Don&#39;t remove any safepoints if it is requested to keep a single safepoint and
2506   // no safepoint was found on idom-path. It is not safe to remove any safepoint
2507   // in this case since there&#39;s no safepoint dominating all paths in the loop body.
2508   bool prune = !keep_one || keep != NULL;
2509 
2510   // Delete other safepoints in this loop.
2511   Node_List* sfpts = _safepts;
2512   if (prune &amp;&amp; sfpts != NULL) {
2513     assert(keep == NULL || keep-&gt;Opcode() == Op_SafePoint, &quot;not safepoint&quot;);
2514     for (uint i = 0; i &lt; sfpts-&gt;size(); i++) {
2515       Node* n = sfpts-&gt;at(i);
2516       assert(phase-&gt;get_loop(n) == this, &quot;&quot;);
2517       if (n != keep &amp;&amp; phase-&gt;is_deleteable_safept(n)) {
2518         phase-&gt;lazy_replace(n, n-&gt;in(TypeFunc::Control));
2519       }
2520     }
2521   }
2522 }
2523 
2524 //------------------------------counted_loop-----------------------------------
2525 // Convert to counted loops where possible
2526 void IdealLoopTree::counted_loop( PhaseIdealLoop *phase ) {
2527 
2528   // For grins, set the inner-loop flag here
2529   if (!_child) {
2530     if (_head-&gt;is_Loop()) _head-&gt;as_Loop()-&gt;set_inner_loop();
2531   }
2532 
2533   IdealLoopTree* loop = this;
2534   if (_head-&gt;is_CountedLoop() ||
2535       phase-&gt;is_counted_loop(_head, loop)) {
2536 
2537     if (LoopStripMiningIter == 0 || (LoopStripMiningIter &gt; 1 &amp;&amp; _child == NULL)) {
2538       // Indicate we do not need a safepoint here
2539       _has_sfpt = 1;
2540     }
2541 
2542     // Remove safepoints
2543     bool keep_one_sfpt = !(_has_call || _has_sfpt);
2544     remove_safepoints(phase, keep_one_sfpt);
2545 
2546     // Look for induction variables
2547     phase-&gt;replace_parallel_iv(this);
2548 
2549   } else if (_parent != NULL &amp;&amp; !_irreducible) {
2550     // Not a counted loop. Keep one safepoint.
2551     bool keep_one_sfpt = true;
2552     remove_safepoints(phase, keep_one_sfpt);
2553   }
2554 
2555   // Recursively
2556   assert(loop-&gt;_child != this || (loop-&gt;_head-&gt;as_Loop()-&gt;is_OuterStripMinedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_strip_mined()), &quot;what kind of loop was added?&quot;);
2557   assert(loop-&gt;_child != this || (loop-&gt;_child-&gt;_child == NULL &amp;&amp; loop-&gt;_child-&gt;_next == NULL), &quot;would miss some loops&quot;);
2558   if (loop-&gt;_child &amp;&amp; loop-&gt;_child != this) loop-&gt;_child-&gt;counted_loop(phase);
2559   if (loop-&gt;_next)  loop-&gt;_next -&gt;counted_loop(phase);
2560 }
2561 
2562 
2563 // The Estimated Loop Clone Size:
2564 //   CloneFactor * (~112% * BodySize + BC) + CC + FanOutTerm,
2565 // where  BC and  CC are  totally ad-hoc/magic  &quot;body&quot; and &quot;clone&quot; constants,
2566 // respectively, used to ensure that the node usage estimates made are on the
2567 // safe side, for the most part. The FanOutTerm is an attempt to estimate the
2568 // possible additional/excessive nodes generated due to data and control flow
2569 // merging, for edges reaching outside the loop.
2570 uint IdealLoopTree::est_loop_clone_sz(uint factor) const {
2571 
2572   precond(0 &lt; factor &amp;&amp; factor &lt; 16);
2573 
2574   uint const bc = 13;
2575   uint const cc = 17;
2576   uint const sz = _body.size() + (_body.size() + 7) / 8;
2577   uint estimate = factor * (sz + bc) + cc;
2578 
2579   assert((estimate - cc) / factor == sz + bc, &quot;overflow&quot;);
2580 
2581   return estimate + est_loop_flow_merge_sz();
2582 }
2583 
2584 // The Estimated Loop (full-) Unroll Size:
2585 //   UnrollFactor * (~106% * BodySize) + CC + FanOutTerm,
2586 // where CC is a (totally) ad-hoc/magic &quot;clone&quot; constant, used to ensure that
2587 // node usage estimates made are on the safe side, for the most part. This is
2588 // a &quot;light&quot; version of the loop clone size calculation (above), based on the
2589 // assumption that most of the loop-construct overhead will be unraveled when
2590 // (fully) unrolled. Defined for unroll factors larger or equal to one (&gt;=1),
2591 // including an overflow check and returning UINT_MAX in case of an overflow.
2592 uint IdealLoopTree::est_loop_unroll_sz(uint factor) const {
2593 
2594   precond(factor &gt; 0);
2595 
2596   // Take into account that after unroll conjoined heads and tails will fold.
2597   uint const b0 = _body.size() - EMPTY_LOOP_SIZE;
2598   uint const cc = 7;
2599   uint const sz = b0 + (b0 + 15) / 16;
2600   uint estimate = factor * sz + cc;
2601 
2602   if ((estimate - cc) / factor != sz) {
2603     return UINT_MAX;
2604   }
2605 
2606   return estimate + est_loop_flow_merge_sz();
2607 }
2608 
2609 // Estimate the growth effect (in nodes) of merging control and data flow when
2610 // cloning a loop body, based on the amount of  control and data flow reaching
2611 // outside of the (current) loop body.
2612 uint IdealLoopTree::est_loop_flow_merge_sz() const {
2613 
2614   uint ctrl_edge_out_cnt = 0;
2615   uint data_edge_out_cnt = 0;
2616 
2617   for (uint i = 0; i &lt; _body.size(); i++) {
2618     Node* node = _body.at(i);
2619     uint outcnt = node-&gt;outcnt();
2620 
2621     for (uint k = 0; k &lt; outcnt; k++) {
2622       Node* out = node-&gt;raw_out(k);
2623       if (out == NULL) continue;
2624       if (out-&gt;is_CFG()) {
2625         if (!is_member(_phase-&gt;get_loop(out))) {
2626           ctrl_edge_out_cnt++;
2627         }
2628       } else if (_phase-&gt;has_ctrl(out)) {
2629         Node* ctrl = _phase-&gt;get_ctrl(out);
2630         assert(ctrl != NULL, &quot;must be&quot;);
2631         assert(ctrl-&gt;is_CFG(), &quot;must be&quot;);
2632         if (!is_member(_phase-&gt;get_loop(ctrl))) {
2633           data_edge_out_cnt++;
2634         }
2635       }
2636     }
2637   }
2638   // Use data and control count (x2.0) in estimate iff both are &gt; 0. This is
2639   // a rather pessimistic estimate for the most part, in particular for some
2640   // complex loops, but still not enough to capture all loops.
2641   if (ctrl_edge_out_cnt &gt; 0 &amp;&amp; data_edge_out_cnt &gt; 0) {
2642     return 2 * (ctrl_edge_out_cnt + data_edge_out_cnt);
2643   }
2644   return 0;
2645 }
2646 
2647 #ifndef PRODUCT
2648 //------------------------------dump_head--------------------------------------
2649 // Dump 1 liner for loop header info
2650 void IdealLoopTree::dump_head() const {
2651   tty-&gt;sp(2 * _nest);
2652   tty-&gt;print(&quot;Loop: N%d/N%d &quot;, _head-&gt;_idx, _tail-&gt;_idx);
2653   if (_irreducible) tty-&gt;print(&quot; IRREDUCIBLE&quot;);
2654   Node* entry = _head-&gt;is_Loop() ? _head-&gt;as_Loop()-&gt;skip_strip_mined(-1)-&gt;in(LoopNode::EntryControl) : _head-&gt;in(LoopNode::EntryControl);
2655   Node* predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_loop_limit_check);
2656   if (predicate != NULL ) {
2657     tty-&gt;print(&quot; limit_check&quot;);
2658     entry = PhaseIdealLoop::skip_loop_predicates(entry);
2659   }
2660   if (UseProfiledLoopPredicate) {
2661     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_profile_predicate);
2662     if (predicate != NULL) {
2663       tty-&gt;print(&quot; profile_predicated&quot;);
2664       entry = PhaseIdealLoop::skip_loop_predicates(entry);
2665     }
2666   }
2667   if (UseLoopPredicate) {
2668     predicate = PhaseIdealLoop::find_predicate_insertion_point(entry, Deoptimization::Reason_predicate);
2669     if (predicate != NULL) {
2670       tty-&gt;print(&quot; predicated&quot;);
2671     }
2672   }
2673   if (_head-&gt;is_CountedLoop()) {
2674     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
2675     tty-&gt;print(&quot; counted&quot;);
2676 
2677     Node* init_n = cl-&gt;init_trip();
2678     if (init_n  != NULL &amp;&amp;  init_n-&gt;is_Con())
2679       tty-&gt;print(&quot; [%d,&quot;, cl-&gt;init_trip()-&gt;get_int());
2680     else
2681       tty-&gt;print(&quot; [int,&quot;);
2682     Node* limit_n = cl-&gt;limit();
2683     if (limit_n  != NULL &amp;&amp;  limit_n-&gt;is_Con())
2684       tty-&gt;print(&quot;%d),&quot;, cl-&gt;limit()-&gt;get_int());
2685     else
2686       tty-&gt;print(&quot;int),&quot;);
2687     int stride_con  = cl-&gt;stride_con();
2688     if (stride_con &gt; 0) tty-&gt;print(&quot;+&quot;);
2689     tty-&gt;print(&quot;%d&quot;, stride_con);
2690 
2691     tty-&gt;print(&quot; (%0.f iters) &quot;, cl-&gt;profile_trip_cnt());
2692 
2693     if (cl-&gt;is_pre_loop ()) tty-&gt;print(&quot; pre&quot; );
2694     if (cl-&gt;is_main_loop()) tty-&gt;print(&quot; main&quot;);
2695     if (cl-&gt;is_post_loop()) tty-&gt;print(&quot; post&quot;);
2696     if (cl-&gt;is_vectorized_loop()) tty-&gt;print(&quot; vector&quot;);
2697     if (cl-&gt;range_checks_present()) tty-&gt;print(&quot; rc &quot;);
2698     if (cl-&gt;is_multiversioned()) tty-&gt;print(&quot; multi &quot;);
2699   }
2700   if (_has_call) tty-&gt;print(&quot; has_call&quot;);
2701   if (_has_sfpt) tty-&gt;print(&quot; has_sfpt&quot;);
2702   if (_rce_candidate) tty-&gt;print(&quot; rce&quot;);
2703   if (_safepts != NULL &amp;&amp; _safepts-&gt;size() &gt; 0) {
2704     tty-&gt;print(&quot; sfpts={&quot;); _safepts-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2705   }
2706   if (_required_safept != NULL &amp;&amp; _required_safept-&gt;size() &gt; 0) {
2707     tty-&gt;print(&quot; req={&quot;); _required_safept-&gt;dump_simple(); tty-&gt;print(&quot; }&quot;);
2708   }
2709   if (Verbose) {
2710     tty-&gt;print(&quot; body={&quot;); _body.dump_simple(); tty-&gt;print(&quot; }&quot;);
2711   }
2712   if (_head-&gt;is_Loop() &amp;&amp; _head-&gt;as_Loop()-&gt;is_strip_mined()) {
2713     tty-&gt;print(&quot; strip_mined&quot;);
2714   }
2715   tty-&gt;cr();
2716 }
2717 
2718 //------------------------------dump-------------------------------------------
2719 // Dump loops by loop tree
2720 void IdealLoopTree::dump() const {
2721   dump_head();
2722   if (_child) _child-&gt;dump();
2723   if (_next)  _next -&gt;dump();
2724 }
2725 
2726 #endif
2727 
2728 static void log_loop_tree(IdealLoopTree* root, IdealLoopTree* loop, CompileLog* log) {
2729   if (loop == root) {
2730     if (loop-&gt;_child != NULL) {
2731       log-&gt;begin_head(&quot;loop_tree&quot;);
2732       log-&gt;end_head();
2733       if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2734       log-&gt;tail(&quot;loop_tree&quot;);
2735       assert(loop-&gt;_next == NULL, &quot;what?&quot;);
2736     }
2737   } else {
2738     Node* head = loop-&gt;_head;
2739     log-&gt;begin_head(&quot;loop&quot;);
2740     log-&gt;print(&quot; idx=&#39;%d&#39; &quot;, head-&gt;_idx);
2741     if (loop-&gt;_irreducible) log-&gt;print(&quot;irreducible=&#39;1&#39; &quot;);
2742     if (head-&gt;is_Loop()) {
2743       if (head-&gt;as_Loop()-&gt;is_inner_loop()) log-&gt;print(&quot;inner_loop=&#39;1&#39; &quot;);
2744       if (head-&gt;as_Loop()-&gt;is_partial_peel_loop()) log-&gt;print(&quot;partial_peel_loop=&#39;1&#39; &quot;);
2745     }
2746     if (head-&gt;is_CountedLoop()) {
2747       CountedLoopNode* cl = head-&gt;as_CountedLoop();
2748       if (cl-&gt;is_pre_loop())  log-&gt;print(&quot;pre_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2749       if (cl-&gt;is_main_loop()) log-&gt;print(&quot;main_loop=&#39;%d&#39; &quot;, cl-&gt;_idx);
2750       if (cl-&gt;is_post_loop()) log-&gt;print(&quot;post_loop=&#39;%d&#39; &quot;,  cl-&gt;main_idx());
2751     }
2752     log-&gt;end_head();
2753     if( loop-&gt;_child ) log_loop_tree(root, loop-&gt;_child, log);
2754     log-&gt;tail(&quot;loop&quot;);
2755     if( loop-&gt;_next  ) log_loop_tree(root, loop-&gt;_next, log);
2756   }
2757 }
2758 
2759 //---------------------collect_potentially_useful_predicates-----------------------
2760 // Helper function to collect potentially useful predicates to prevent them from
2761 // being eliminated by PhaseIdealLoop::eliminate_useless_predicates
2762 void PhaseIdealLoop::collect_potentially_useful_predicates(
2763                          IdealLoopTree * loop, Unique_Node_List &amp;useful_predicates) {
2764   if (loop-&gt;_child) { // child
2765     collect_potentially_useful_predicates(loop-&gt;_child, useful_predicates);
2766   }
2767 
2768   // self (only loops that we can apply loop predication may use their predicates)
2769   if (loop-&gt;_head-&gt;is_Loop() &amp;&amp;
2770       !loop-&gt;_irreducible    &amp;&amp;
2771       !loop-&gt;tail()-&gt;is_top()) {
2772     LoopNode* lpn = loop-&gt;_head-&gt;as_Loop();
2773     Node* entry = lpn-&gt;in(LoopNode::EntryControl);
2774     Node* predicate_proj = find_predicate(entry); // loop_limit_check first
2775     if (predicate_proj != NULL) { // right pattern that can be used by loop predication
2776       assert(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2777       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2778       entry = skip_loop_predicates(entry);
2779     }
2780     if (UseProfiledLoopPredicate) {
2781       predicate_proj = find_predicate(entry); // Predicate
2782       if (predicate_proj != NULL) {
2783         useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2784         entry = skip_loop_predicates(entry);
2785       }
2786     }
2787     predicate_proj = find_predicate(entry); // Predicate
2788     if (predicate_proj != NULL) {
2789       useful_predicates.push(entry-&gt;in(0)-&gt;in(1)-&gt;in(1)); // good one
2790     }
2791   }
2792 
2793   if (loop-&gt;_next) { // sibling
2794     collect_potentially_useful_predicates(loop-&gt;_next, useful_predicates);
2795   }
2796 }
2797 
2798 //------------------------eliminate_useless_predicates-----------------------------
2799 // Eliminate all inserted predicates if they could not be used by loop predication.
2800 // Note: it will also eliminates loop limits check predicate since it also uses
2801 // Opaque1 node (see Parse::add_predicate()).
2802 void PhaseIdealLoop::eliminate_useless_predicates() {
2803   if (C-&gt;predicate_count() == 0)
2804     return; // no predicate left
2805 
2806   Unique_Node_List useful_predicates; // to store useful predicates
2807   if (C-&gt;has_loops()) {
2808     collect_potentially_useful_predicates(_ltree_root-&gt;_child, useful_predicates);
2809   }
2810 
2811   for (int i = C-&gt;predicate_count(); i &gt; 0; i--) {
2812      Node * n = C-&gt;predicate_opaque1_node(i-1);
2813      assert(n-&gt;Opcode() == Op_Opaque1, &quot;must be&quot;);
2814      if (!useful_predicates.member(n)) { // not in the useful list
2815        _igvn.replace_node(n, n-&gt;in(1));
2816      }
2817   }
2818 }
2819 
2820 //------------------------process_expensive_nodes-----------------------------
2821 // Expensive nodes have their control input set to prevent the GVN
2822 // from commoning them and as a result forcing the resulting node to
2823 // be in a more frequent path. Use CFG information here, to change the
2824 // control inputs so that some expensive nodes can be commoned while
2825 // not executed more frequently.
2826 bool PhaseIdealLoop::process_expensive_nodes() {
2827   assert(OptimizeExpensiveOps, &quot;optimization off?&quot;);
2828 
2829   // Sort nodes to bring similar nodes together
2830   C-&gt;sort_expensive_nodes();
2831 
2832   bool progress = false;
2833 
2834   for (int i = 0; i &lt; C-&gt;expensive_count(); ) {
2835     Node* n = C-&gt;expensive_node(i);
2836     int start = i;
2837     // Find nodes similar to n
2838     i++;
2839     for (; i &lt; C-&gt;expensive_count() &amp;&amp; Compile::cmp_expensive_nodes(n, C-&gt;expensive_node(i)) == 0; i++);
2840     int end = i;
2841     // And compare them two by two
2842     for (int j = start; j &lt; end; j++) {
2843       Node* n1 = C-&gt;expensive_node(j);
2844       if (is_node_unreachable(n1)) {
2845         continue;
2846       }
2847       for (int k = j+1; k &lt; end; k++) {
2848         Node* n2 = C-&gt;expensive_node(k);
2849         if (is_node_unreachable(n2)) {
2850           continue;
2851         }
2852 
2853         assert(n1 != n2, &quot;should be pair of nodes&quot;);
2854 
2855         Node* c1 = n1-&gt;in(0);
2856         Node* c2 = n2-&gt;in(0);
2857 
2858         Node* parent_c1 = c1;
2859         Node* parent_c2 = c2;
2860 
2861         // The call to get_early_ctrl_for_expensive() moves the
2862         // expensive nodes up but stops at loops that are in a if
2863         // branch. See whether we can exit the loop and move above the
2864         // If.
2865         if (c1-&gt;is_Loop()) {
2866           parent_c1 = c1-&gt;in(1);
2867         }
2868         if (c2-&gt;is_Loop()) {
2869           parent_c2 = c2-&gt;in(1);
2870         }
2871 
2872         if (parent_c1 == parent_c2) {
2873           _igvn._worklist.push(n1);
2874           _igvn._worklist.push(n2);
2875           continue;
2876         }
2877 
2878         // Look for identical expensive node up the dominator chain.
2879         if (is_dominator(c1, c2)) {
2880           c2 = c1;
2881         } else if (is_dominator(c2, c1)) {
2882           c1 = c2;
2883         } else if (parent_c1-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0)-&gt;is_If() &amp;&amp;
2884                    parent_c2-&gt;is_Proj() &amp;&amp; parent_c1-&gt;in(0) == parent_c2-&gt;in(0)) {
2885           // Both branches have the same expensive node so move it up
2886           // before the if.
2887           c1 = c2 = idom(parent_c1-&gt;in(0));
2888         }
2889         // Do the actual moves
2890         if (n1-&gt;in(0) != c1) {
2891           _igvn.hash_delete(n1);
2892           n1-&gt;set_req(0, c1);
2893           _igvn.hash_insert(n1);
2894           _igvn._worklist.push(n1);
2895           progress = true;
2896         }
2897         if (n2-&gt;in(0) != c2) {
2898           _igvn.hash_delete(n2);
2899           n2-&gt;set_req(0, c2);
2900           _igvn.hash_insert(n2);
2901           _igvn._worklist.push(n2);
2902           progress = true;
2903         }
2904       }
2905     }
2906   }
2907 
2908   return progress;
2909 }
2910 
2911 
2912 //=============================================================================
2913 //----------------------------build_and_optimize-------------------------------
2914 // Create a PhaseLoop.  Build the ideal Loop tree.  Map each Ideal Node to
2915 // its corresponding LoopNode.  If &#39;optimize&#39; is true, do some loop cleanups.
2916 void PhaseIdealLoop::build_and_optimize(LoopOptsMode mode) {
2917   bool do_split_ifs = (mode == LoopOptsDefault);
2918   bool skip_loop_opts = (mode == LoopOptsNone);
2919 
2920   int old_progress = C-&gt;major_progress();
2921   uint orig_worklist_size = _igvn._worklist.size();
2922 
2923   // Reset major-progress flag for the driver&#39;s heuristics
2924   C-&gt;clear_major_progress();
2925 
2926 #ifndef PRODUCT
2927   // Capture for later assert
2928   uint unique = C-&gt;unique();
2929   _loop_invokes++;
2930   _loop_work += unique;
2931 #endif
2932 
2933   // True if the method has at least 1 irreducible loop
2934   _has_irreducible_loops = false;
2935 
2936   _created_loop_node = false;
2937 
2938   Arena *a = Thread::current()-&gt;resource_area();
2939   VectorSet visited(a);
2940   // Pre-grow the mapping from Nodes to IdealLoopTrees.
2941   _nodes.map(C-&gt;unique(), NULL);
2942   memset(_nodes.adr(), 0, wordSize * C-&gt;unique());
2943 
2944   // Pre-build the top-level outermost loop tree entry
2945   _ltree_root = new IdealLoopTree( this, C-&gt;root(), C-&gt;root() );
2946   // Do not need a safepoint at the top level
2947   _ltree_root-&gt;_has_sfpt = 1;
2948 
2949   // Initialize Dominators.
2950   // Checked in clone_loop_predicate() during beautify_loops().
2951   _idom_size = 0;
2952   _idom      = NULL;
2953   _dom_depth = NULL;
2954   _dom_stk   = NULL;
2955 
2956   // Empty pre-order array
2957   allocate_preorders();
2958 
2959   // Build a loop tree on the fly.  Build a mapping from CFG nodes to
2960   // IdealLoopTree entries.  Data nodes are NOT walked.
2961   build_loop_tree();
2962   // Check for bailout, and return
2963   if (C-&gt;failing()) {
2964     return;
2965   }
2966 
2967   // No loops after all
2968   if( !_ltree_root-&gt;_child &amp;&amp; !_verify_only ) C-&gt;set_has_loops(false);
2969 
2970   // There should always be an outer loop containing the Root and Return nodes.
2971   // If not, we have a degenerate empty program.  Bail out in this case.
2972   if (!has_node(C-&gt;root())) {
2973     if (!_verify_only) {
2974       C-&gt;clear_major_progress();
2975       C-&gt;record_method_not_compilable(&quot;empty program detected during loop optimization&quot;);
2976     }
2977     return;
2978   }
2979 
2980   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
2981   // Nothing to do, so get out
2982   bool stop_early = !C-&gt;has_loops() &amp;&amp; !skip_loop_opts &amp;&amp; !do_split_ifs &amp;&amp; !_verify_me &amp;&amp; !_verify_only &amp;&amp;
2983     !bs-&gt;is_gc_specific_loop_opts_pass(mode);
2984   bool do_expensive_nodes = C-&gt;should_optimize_expensive_nodes(_igvn);
2985   bool strip_mined_loops_expanded = bs-&gt;strip_mined_loops_expanded(mode);
2986   if (stop_early &amp;&amp; !do_expensive_nodes) {
2987     _igvn.optimize();           // Cleanup NeverBranches
2988     return;
2989   }
2990 
2991   // Set loop nesting depth
2992   _ltree_root-&gt;set_nest( 0 );
2993 
2994   // Split shared headers and insert loop landing pads.
2995   // Do not bother doing this on the Root loop of course.
2996   if( !_verify_me &amp;&amp; !_verify_only &amp;&amp; _ltree_root-&gt;_child ) {
2997     C-&gt;print_method(PHASE_BEFORE_BEAUTIFY_LOOPS, 3);
2998     if( _ltree_root-&gt;_child-&gt;beautify_loops( this ) ) {
2999       // Re-build loop tree!
3000       _ltree_root-&gt;_child = NULL;
3001       _nodes.clear();
3002       reallocate_preorders();
3003       build_loop_tree();
3004       // Check for bailout, and return
3005       if (C-&gt;failing()) {
3006         return;
3007       }
3008       // Reset loop nesting depth
3009       _ltree_root-&gt;set_nest( 0 );
3010 
3011       C-&gt;print_method(PHASE_AFTER_BEAUTIFY_LOOPS, 3);
3012     }
3013   }
3014 
3015   // Build Dominators for elision of NULL checks &amp; loop finding.
3016   // Since nodes do not have a slot for immediate dominator, make
3017   // a persistent side array for that info indexed on node-&gt;_idx.
3018   _idom_size = C-&gt;unique();
3019   _idom      = NEW_RESOURCE_ARRAY( Node*, _idom_size );
3020   _dom_depth = NEW_RESOURCE_ARRAY( uint,  _idom_size );
3021   _dom_stk   = NULL; // Allocated on demand in recompute_dom_depth
3022   memset( _dom_depth, 0, _idom_size * sizeof(uint) );
3023 
3024   Dominators();
3025 
3026   if (!_verify_only) {
3027     // As a side effect, Dominators removed any unreachable CFG paths
3028     // into RegionNodes.  It doesn&#39;t do this test against Root, so
3029     // we do it here.
3030     for( uint i = 1; i &lt; C-&gt;root()-&gt;req(); i++ ) {
3031       if( !_nodes[C-&gt;root()-&gt;in(i)-&gt;_idx] ) {    // Dead path into Root?
3032         _igvn.delete_input_of(C-&gt;root(), i);
3033         i--;                      // Rerun same iteration on compressed edges
3034       }
3035     }
3036 
3037     // Given dominators, try to find inner loops with calls that must
3038     // always be executed (call dominates loop tail).  These loops do
3039     // not need a separate safepoint.
3040     Node_List cisstack(a);
3041     _ltree_root-&gt;check_safepts(visited, cisstack);
3042   }
3043 
3044   // Walk the DATA nodes and place into loops.  Find earliest control
3045   // node.  For CFG nodes, the _nodes array starts out and remains
3046   // holding the associated IdealLoopTree pointer.  For DATA nodes, the
3047   // _nodes array holds the earliest legal controlling CFG node.
3048 
3049   // Allocate stack with enough space to avoid frequent realloc
3050   int stack_size = (C-&gt;live_nodes() &gt;&gt; 1) + 16; // (live_nodes&gt;&gt;1)+16 from Java2D stats
3051   Node_Stack nstack( a, stack_size );
3052 
3053   visited.clear();
3054   Node_List worklist(a);
3055   // Don&#39;t need C-&gt;root() on worklist since
3056   // it will be processed among C-&gt;top() inputs
3057   worklist.push(C-&gt;top());
3058   visited.set(C-&gt;top()-&gt;_idx); // Set C-&gt;top() as visited now
3059   build_loop_early( visited, worklist, nstack );
3060 
3061   // Given early legal placement, try finding counted loops.  This placement
3062   // is good enough to discover most loop invariants.
3063   if (!_verify_me &amp;&amp; !_verify_only &amp;&amp; !strip_mined_loops_expanded) {
3064     _ltree_root-&gt;counted_loop( this );
3065   }
3066 
3067   // Find latest loop placement.  Find ideal loop placement.
3068   visited.clear();
3069   init_dom_lca_tags();
3070   // Need C-&gt;root() on worklist when processing outs
3071   worklist.push(C-&gt;root());
3072   NOT_PRODUCT( C-&gt;verify_graph_edges(); )
3073   worklist.push(C-&gt;top());
3074   build_loop_late( visited, worklist, nstack );
3075 
3076   if (_verify_only) {
3077     C-&gt;restore_major_progress(old_progress);
3078     assert(C-&gt;unique() == unique, &quot;verification mode made Nodes? ? ?&quot;);
3079     assert(_igvn._worklist.size() == orig_worklist_size, &quot;shouldn&#39;t push anything&quot;);
3080     return;
3081   }
3082 
3083   // clear out the dead code after build_loop_late
3084   while (_deadlist.size()) {
3085     _igvn.remove_globally_dead_node(_deadlist.pop());
3086   }
3087 
3088   if (stop_early) {
3089     assert(do_expensive_nodes, &quot;why are we here?&quot;);
3090     if (process_expensive_nodes()) {
3091       // If we made some progress when processing expensive nodes then
3092       // the IGVN may modify the graph in a way that will allow us to
3093       // make some more progress: we need to try processing expensive
3094       // nodes again.
3095       C-&gt;set_major_progress();
3096     }
3097     _igvn.optimize();
3098     return;
3099   }
3100 
3101   // Some parser-inserted loop predicates could never be used by loop
3102   // predication or they were moved away from loop during some optimizations.
3103   // For example, peeling. Eliminate them before next loop optimizations.
3104   eliminate_useless_predicates();
3105 
3106 #ifndef PRODUCT
3107   C-&gt;verify_graph_edges();
3108   if (_verify_me) {             // Nested verify pass?
3109     // Check to see if the verify mode is broken
3110     assert(C-&gt;unique() == unique, &quot;non-optimize mode made Nodes? ? ?&quot;);
3111     return;
3112   }
3113   if (VerifyLoopOptimizations) verify();
3114   if (TraceLoopOpts &amp;&amp; C-&gt;has_loops()) {
3115     _ltree_root-&gt;dump();
3116   }
3117 #endif
3118 
3119   if (skip_loop_opts) {
3120     // restore major progress flag
3121     C-&gt;restore_major_progress(old_progress);
3122 
3123     // Cleanup any modified bits
3124     _igvn.optimize();
3125 
3126     if (C-&gt;log() != NULL) {
3127       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3128     }
3129     return;
3130   }
3131 
3132   if (mode == LoopOptsMaxUnroll) {
3133     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3134       IdealLoopTree* lpt = iter.current();
3135       if (lpt-&gt;is_innermost() &amp;&amp; lpt-&gt;_allow_optimizations &amp;&amp; !lpt-&gt;_has_call &amp;&amp; lpt-&gt;is_counted()) {
3136         lpt-&gt;compute_trip_count(this);
3137         if (!lpt-&gt;do_one_iteration_loop(this) &amp;&amp;
3138             !lpt-&gt;do_remove_empty_loop(this)) {
3139           AutoNodeBudget node_budget(this);
3140           if (lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_normal_loop() &amp;&amp;
3141               lpt-&gt;policy_maximally_unroll(this)) {
3142             memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3143             do_maximally_unroll(lpt, worklist);
3144           }
3145         }
3146       }
3147     }
3148 
3149     C-&gt;restore_major_progress(old_progress);
3150 
3151     _igvn.optimize();
3152 
3153     if (C-&gt;log() != NULL) {
3154       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3155     }
3156     return;
3157   }
3158 
3159   if (bs-&gt;optimize_loops(this, mode, visited, nstack, worklist)) {
3160     _igvn.optimize();
3161     if (C-&gt;log() != NULL) {
3162       log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3163     }
3164     return;
3165   }
3166 
3167   if (ReassociateInvariants) {
3168     // Reassociate invariants and prep for split_thru_phi
3169     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3170       IdealLoopTree* lpt = iter.current();
3171       bool is_counted = lpt-&gt;is_counted();
3172       if (!is_counted || !lpt-&gt;is_innermost()) continue;
3173 
3174       // check for vectorized loops, any reassociation of invariants was already done
3175       if (is_counted &amp;&amp; lpt-&gt;_head-&gt;as_CountedLoop()-&gt;is_unroll_only()) {
3176         continue;
3177       } else {
3178         AutoNodeBudget node_budget(this);
3179         lpt-&gt;reassociate_invariants(this);
3180       }
3181       // Because RCE opportunities can be masked by split_thru_phi,
3182       // look for RCE candidates and inhibit split_thru_phi
3183       // on just their loop-phi&#39;s for this pass of loop opts
3184       if (SplitIfBlocks &amp;&amp; do_split_ifs) {
3185         AutoNodeBudget node_budget(this, AutoNodeBudget::NO_BUDGET_CHECK);
3186         if (lpt-&gt;policy_range_check(this)) {
3187           lpt-&gt;_rce_candidate = 1; // = true
3188         }
3189       }
3190     }
3191   }
3192 
3193   // Check for aggressive application of split-if and other transforms
3194   // that require basic-block info (like cloning through Phi&#39;s)
3195   if( SplitIfBlocks &amp;&amp; do_split_ifs ) {
3196     visited.clear();
3197     split_if_with_blocks( visited, nstack);
3198     NOT_PRODUCT( if( VerifyLoopOptimizations ) verify(); );
3199   }
3200 
3201   if (!C-&gt;major_progress() &amp;&amp; do_expensive_nodes &amp;&amp; process_expensive_nodes()) {
3202     C-&gt;set_major_progress();
3203   }
3204 
3205   // Perform loop predication before iteration splitting
3206   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3207     _ltree_root-&gt;_child-&gt;loop_predication(this);
3208   }
3209 
3210   if (OptimizeFill &amp;&amp; UseLoopPredicate &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3211     if (do_intrinsify_fill()) {
3212       C-&gt;set_major_progress();
3213     }
3214   }
3215 
3216   // Perform iteration-splitting on inner loops.  Split iterations to avoid
3217   // range checks or one-shot null checks.
3218 
3219   // If split-if&#39;s didn&#39;t hack the graph too bad (no CFG changes)
3220   // then do loop opts.
3221   if (C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3222     memset( worklist.adr(), 0, worklist.Size()*sizeof(Node*) );
3223     _ltree_root-&gt;_child-&gt;iteration_split( this, worklist );
3224     // No verify after peeling!  GCM has hoisted code out of the loop.
3225     // After peeling, the hoisted code could sink inside the peeled area.
3226     // The peeling code does not try to recompute the best location for
3227     // all the code before the peeled area, so the verify pass will always
3228     // complain about it.
3229   }
3230   // Do verify graph edges in any case
3231   NOT_PRODUCT( C-&gt;verify_graph_edges(); );
3232 
3233   if (!do_split_ifs) {
3234     // We saw major progress in Split-If to get here.  We forced a
3235     // pass with unrolling and not split-if, however more split-if&#39;s
3236     // might make progress.  If the unrolling didn&#39;t make progress
3237     // then the major-progress flag got cleared and we won&#39;t try
3238     // another round of Split-If.  In particular the ever-common
3239     // instance-of/check-cast pattern requires at least 2 rounds of
3240     // Split-If to clear out.
3241     C-&gt;set_major_progress();
3242   }
3243 
3244   // Repeat loop optimizations if new loops were seen
3245   if (created_loop_node()) {
3246     C-&gt;set_major_progress();
3247   }
3248 
3249   // Keep loop predicates and perform optimizations with them
3250   // until no more loop optimizations could be done.
3251   // After that switch predicates off and do more loop optimizations.
3252   if (!C-&gt;major_progress() &amp;&amp; (C-&gt;predicate_count() &gt; 0)) {
3253      C-&gt;cleanup_loop_predicates(_igvn);
3254      if (TraceLoopOpts) {
3255        tty-&gt;print_cr(&quot;PredicatesOff&quot;);
3256      }
3257      C-&gt;set_major_progress();
3258   }
3259 
3260   // Convert scalar to superword operations at the end of all loop opts.
3261   if (UseSuperWord &amp;&amp; C-&gt;has_loops() &amp;&amp; !C-&gt;major_progress()) {
3262     // SuperWord transform
3263     SuperWord sw(this);
3264     for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {
3265       IdealLoopTree* lpt = iter.current();
3266       if (lpt-&gt;is_counted()) {
3267         CountedLoopNode *cl = lpt-&gt;_head-&gt;as_CountedLoop();
3268 
3269         if (PostLoopMultiversioning &amp;&amp; cl-&gt;is_rce_post_loop() &amp;&amp; !cl-&gt;is_vectorized_loop()) {
3270           // Check that the rce&#39;d post loop is encountered first, multiversion after all
3271           // major main loop optimization are concluded
3272           if (!C-&gt;major_progress()) {
3273             IdealLoopTree *lpt_next = lpt-&gt;_next;
3274             if (lpt_next &amp;&amp; lpt_next-&gt;is_counted()) {
3275               CountedLoopNode *cl = lpt_next-&gt;_head-&gt;as_CountedLoop();
3276               has_range_checks(lpt_next);
3277               if (cl-&gt;is_post_loop() &amp;&amp; cl-&gt;range_checks_present()) {
3278                 if (!cl-&gt;is_multiversioned()) {
3279                   if (multi_version_post_loops(lpt, lpt_next) == false) {
3280                     // Cause the rce loop to be optimized away if we fail
3281                     cl-&gt;mark_is_multiversioned();
3282                     cl-&gt;set_slp_max_unroll(0);
3283                     poison_rce_post_loop(lpt);
3284                   }
3285                 }
3286               }
3287             }
3288             sw.transform_loop(lpt, true);
3289           }
3290         } else if (cl-&gt;is_main_loop()) {
3291           sw.transform_loop(lpt, true);
3292         }
3293       }
3294     }
3295   }
3296 
3297   // Cleanup any modified bits
3298   _igvn.optimize();
3299 
3300   // disable assert until issue with split_flow_path is resolved (6742111)
3301   // assert(!_has_irreducible_loops || C-&gt;parsed_irreducible_loop() || C-&gt;is_osr_compilation(),
3302   //        &quot;shouldn&#39;t introduce irreducible loops&quot;);
3303 
3304   if (C-&gt;log() != NULL) {
3305     log_loop_tree(_ltree_root, _ltree_root, C-&gt;log());
3306   }
3307 }
3308 
3309 #ifndef PRODUCT
3310 //------------------------------print_statistics-------------------------------
3311 int PhaseIdealLoop::_loop_invokes=0;// Count of PhaseIdealLoop invokes
3312 int PhaseIdealLoop::_loop_work=0; // Sum of PhaseIdealLoop x unique
3313 void PhaseIdealLoop::print_statistics() {
3314   tty-&gt;print_cr(&quot;PhaseIdealLoop=%d, sum _unique=%d&quot;, _loop_invokes, _loop_work);
3315 }
3316 
3317 //------------------------------verify-----------------------------------------
3318 // Build a verify-only PhaseIdealLoop, and see that it agrees with me.
3319 static int fail;                // debug only, so its multi-thread dont care
3320 void PhaseIdealLoop::verify() const {
3321   int old_progress = C-&gt;major_progress();
3322   ResourceMark rm;
3323   PhaseIdealLoop loop_verify( _igvn, this );
3324   VectorSet visited(Thread::current()-&gt;resource_area());
3325 
3326   fail = 0;
3327   verify_compare( C-&gt;root(), &amp;loop_verify, visited );
3328   assert( fail == 0, &quot;verify loops failed&quot; );
3329   // Verify loop structure is the same
3330   _ltree_root-&gt;verify_tree(loop_verify._ltree_root, NULL);
3331   // Reset major-progress.  It was cleared by creating a verify version of
3332   // PhaseIdealLoop.
3333   C-&gt;restore_major_progress(old_progress);
3334 }
3335 
3336 //------------------------------verify_compare---------------------------------
3337 // Make sure me and the given PhaseIdealLoop agree on key data structures
3338 void PhaseIdealLoop::verify_compare( Node *n, const PhaseIdealLoop *loop_verify, VectorSet &amp;visited ) const {
3339   if( !n ) return;
3340   if( visited.test_set( n-&gt;_idx ) ) return;
3341   if( !_nodes[n-&gt;_idx] ) {      // Unreachable
3342     assert( !loop_verify-&gt;_nodes[n-&gt;_idx], &quot;both should be unreachable&quot; );
3343     return;
3344   }
3345 
3346   uint i;
3347   for( i = 0; i &lt; n-&gt;req(); i++ )
3348     verify_compare( n-&gt;in(i), loop_verify, visited );
3349 
3350   // Check the &#39;_nodes&#39; block/loop structure
3351   i = n-&gt;_idx;
3352   if( has_ctrl(n) ) {           // We have control; verify has loop or ctrl
3353     if( _nodes[i] != loop_verify-&gt;_nodes[i] &amp;&amp;
3354         get_ctrl_no_update(n) != loop_verify-&gt;get_ctrl_no_update(n) ) {
3355       tty-&gt;print(&quot;Mismatched control setting for: &quot;);
3356       n-&gt;dump();
3357       if( fail++ &gt; 10 ) return;
3358       Node *c = get_ctrl_no_update(n);
3359       tty-&gt;print(&quot;We have it as: &quot;);
3360       if( c-&gt;in(0) ) c-&gt;dump();
3361         else tty-&gt;print_cr(&quot;N%d&quot;,c-&gt;_idx);
3362       tty-&gt;print(&quot;Verify thinks: &quot;);
3363       if( loop_verify-&gt;has_ctrl(n) )
3364         loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3365       else
3366         loop_verify-&gt;get_loop_idx(n)-&gt;dump();
3367       tty-&gt;cr();
3368     }
3369   } else {                    // We have a loop
3370     IdealLoopTree *us = get_loop_idx(n);
3371     if( loop_verify-&gt;has_ctrl(n) ) {
3372       tty-&gt;print(&quot;Mismatched loop setting for: &quot;);
3373       n-&gt;dump();
3374       if( fail++ &gt; 10 ) return;
3375       tty-&gt;print(&quot;We have it as: &quot;);
3376       us-&gt;dump();
3377       tty-&gt;print(&quot;Verify thinks: &quot;);
3378       loop_verify-&gt;get_ctrl_no_update(n)-&gt;dump();
3379       tty-&gt;cr();
3380     } else if (!C-&gt;major_progress()) {
3381       // Loop selection can be messed up if we did a major progress
3382       // operation, like split-if.  Do not verify in that case.
3383       IdealLoopTree *them = loop_verify-&gt;get_loop_idx(n);
3384       if( us-&gt;_head != them-&gt;_head ||  us-&gt;_tail != them-&gt;_tail ) {
3385         tty-&gt;print(&quot;Unequals loops for: &quot;);
3386         n-&gt;dump();
3387         if( fail++ &gt; 10 ) return;
3388         tty-&gt;print(&quot;We have it as: &quot;);
3389         us-&gt;dump();
3390         tty-&gt;print(&quot;Verify thinks: &quot;);
3391         them-&gt;dump();
3392         tty-&gt;cr();
3393       }
3394     }
3395   }
3396 
3397   // Check for immediate dominators being equal
3398   if( i &gt;= _idom_size ) {
3399     if( !n-&gt;is_CFG() ) return;
3400     tty-&gt;print(&quot;CFG Node with no idom: &quot;);
3401     n-&gt;dump();
3402     return;
3403   }
3404   if( !n-&gt;is_CFG() ) return;
3405   if( n == C-&gt;root() ) return; // No IDOM here
3406 
3407   assert(n-&gt;_idx == i, &quot;sanity&quot;);
3408   Node *id = idom_no_update(n);
3409   if( id != loop_verify-&gt;idom_no_update(n) ) {
3410     tty-&gt;print(&quot;Unequals idoms for: &quot;);
3411     n-&gt;dump();
3412     if( fail++ &gt; 10 ) return;
3413     tty-&gt;print(&quot;We have it as: &quot;);
3414     id-&gt;dump();
3415     tty-&gt;print(&quot;Verify thinks: &quot;);
3416     loop_verify-&gt;idom_no_update(n)-&gt;dump();
3417     tty-&gt;cr();
3418   }
3419 
3420 }
3421 
3422 //------------------------------verify_tree------------------------------------
3423 // Verify that tree structures match.  Because the CFG can change, siblings
3424 // within the loop tree can be reordered.  We attempt to deal with that by
3425 // reordering the verify&#39;s loop tree if possible.
3426 void IdealLoopTree::verify_tree(IdealLoopTree *loop, const IdealLoopTree *parent) const {
3427   assert( _parent == parent, &quot;Badly formed loop tree&quot; );
3428 
3429   // Siblings not in same order?  Attempt to re-order.
3430   if( _head != loop-&gt;_head ) {
3431     // Find _next pointer to update
3432     IdealLoopTree **pp = &amp;loop-&gt;_parent-&gt;_child;
3433     while( *pp != loop )
3434       pp = &amp;((*pp)-&gt;_next);
3435     // Find proper sibling to be next
3436     IdealLoopTree **nn = &amp;loop-&gt;_next;
3437     while( (*nn) &amp;&amp; (*nn)-&gt;_head != _head )
3438       nn = &amp;((*nn)-&gt;_next);
3439 
3440     // Check for no match.
3441     if( !(*nn) ) {
3442       // Annoyingly, irreducible loops can pick different headers
3443       // after a major_progress operation, so the rest of the loop
3444       // tree cannot be matched.
3445       if (_irreducible &amp;&amp; Compile::current()-&gt;major_progress())  return;
3446       assert( 0, &quot;failed to match loop tree&quot; );
3447     }
3448 
3449     // Move (*nn) to (*pp)
3450     IdealLoopTree *hit = *nn;
3451     *nn = hit-&gt;_next;
3452     hit-&gt;_next = loop;
3453     *pp = loop;
3454     loop = hit;
3455     // Now try again to verify
3456   }
3457 
3458   assert( _head  == loop-&gt;_head , &quot;mismatched loop head&quot; );
3459   Node *tail = _tail;           // Inline a non-updating version of
3460   while( !tail-&gt;in(0) )         // the &#39;tail()&#39; call.
3461     tail = tail-&gt;in(1);
3462   assert( tail == loop-&gt;_tail, &quot;mismatched loop tail&quot; );
3463 
3464   // Counted loops that are guarded should be able to find their guards
3465   if( _head-&gt;is_CountedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_main_loop() ) {
3466     CountedLoopNode *cl = _head-&gt;as_CountedLoop();
3467     Node *init = cl-&gt;init_trip();
3468     Node *ctrl = cl-&gt;in(LoopNode::EntryControl);
3469     assert( ctrl-&gt;Opcode() == Op_IfTrue || ctrl-&gt;Opcode() == Op_IfFalse, &quot;&quot; );
3470     Node *iff  = ctrl-&gt;in(0);
3471     assert( iff-&gt;Opcode() == Op_If, &quot;&quot; );
3472     Node *bol  = iff-&gt;in(1);
3473     assert( bol-&gt;Opcode() == Op_Bool, &quot;&quot; );
3474     Node *cmp  = bol-&gt;in(1);
3475     assert( cmp-&gt;Opcode() == Op_CmpI, &quot;&quot; );
3476     Node *add  = cmp-&gt;in(1);
3477     Node *opaq;
3478     if( add-&gt;Opcode() == Op_Opaque1 ) {
3479       opaq = add;
3480     } else {
3481       assert( add-&gt;Opcode() == Op_AddI || add-&gt;Opcode() == Op_ConI , &quot;&quot; );
3482       assert( add == init, &quot;&quot; );
3483       opaq = cmp-&gt;in(2);
3484     }
3485     assert( opaq-&gt;Opcode() == Op_Opaque1, &quot;&quot; );
3486 
3487   }
3488 
3489   if (_child != NULL)  _child-&gt;verify_tree(loop-&gt;_child, this);
3490   if (_next  != NULL)  _next -&gt;verify_tree(loop-&gt;_next,  parent);
3491   // Innermost loops need to verify loop bodies,
3492   // but only if no &#39;major_progress&#39;
3493   int fail = 0;
3494   if (!Compile::current()-&gt;major_progress() &amp;&amp; _child == NULL) {
3495     for( uint i = 0; i &lt; _body.size(); i++ ) {
3496       Node *n = _body.at(i);
3497       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3498       uint j;
3499       for( j = 0; j &lt; loop-&gt;_body.size(); j++ )
3500         if( loop-&gt;_body.at(j) == n )
3501           break;
3502       if( j == loop-&gt;_body.size() ) { // Not found in loop body
3503         // Last ditch effort to avoid assertion: Its possible that we
3504         // have some users (so outcnt not zero) but are still dead.
3505         // Try to find from root.
3506         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3507           fail++;
3508           tty-&gt;print(&quot;We have that verify does not: &quot;);
3509           n-&gt;dump();
3510         }
3511       }
3512     }
3513     for( uint i2 = 0; i2 &lt; loop-&gt;_body.size(); i2++ ) {
3514       Node *n = loop-&gt;_body.at(i2);
3515       if (n-&gt;outcnt() == 0)  continue; // Ignore dead
3516       uint j;
3517       for( j = 0; j &lt; _body.size(); j++ )
3518         if( _body.at(j) == n )
3519           break;
3520       if( j == _body.size() ) { // Not found in loop body
3521         // Last ditch effort to avoid assertion: Its possible that we
3522         // have some users (so outcnt not zero) but are still dead.
3523         // Try to find from root.
3524         if (Compile::current()-&gt;root()-&gt;find(n-&gt;_idx)) {
3525           fail++;
3526           tty-&gt;print(&quot;Verify has that we do not: &quot;);
3527           n-&gt;dump();
3528         }
3529       }
3530     }
3531     assert( !fail, &quot;loop body mismatch&quot; );
3532   }
3533 }
3534 
3535 #endif
3536 
3537 //------------------------------set_idom---------------------------------------
3538 void PhaseIdealLoop::set_idom(Node* d, Node* n, uint dom_depth) {
3539   uint idx = d-&gt;_idx;
3540   if (idx &gt;= _idom_size) {
3541     uint newsize = next_power_of_2(idx);
3542     _idom      = REALLOC_RESOURCE_ARRAY( Node*,     _idom,_idom_size,newsize);
3543     _dom_depth = REALLOC_RESOURCE_ARRAY( uint, _dom_depth,_idom_size,newsize);
3544     memset( _dom_depth + _idom_size, 0, (newsize - _idom_size) * sizeof(uint) );
3545     _idom_size = newsize;
3546   }
3547   _idom[idx] = n;
3548   _dom_depth[idx] = dom_depth;
3549 }
3550 
3551 //------------------------------recompute_dom_depth---------------------------------------
3552 // The dominator tree is constructed with only parent pointers.
3553 // This recomputes the depth in the tree by first tagging all
3554 // nodes as &quot;no depth yet&quot; marker.  The next pass then runs up
3555 // the dom tree from each node marked &quot;no depth yet&quot;, and computes
3556 // the depth on the way back down.
3557 void PhaseIdealLoop::recompute_dom_depth() {
3558   uint no_depth_marker = C-&gt;unique();
3559   uint i;
3560   // Initialize depth to &quot;no depth yet&quot; and realize all lazy updates
3561   for (i = 0; i &lt; _idom_size; i++) {
3562     // Only indices with a _dom_depth has a Node* or NULL (otherwise uninitalized).
3563     if (_dom_depth[i] &gt; 0 &amp;&amp; _idom[i] != NULL) {
3564       _dom_depth[i] = no_depth_marker;
3565 
3566       // heal _idom if it has a fwd mapping in _nodes
3567       if (_idom[i]-&gt;in(0) == NULL) {
3568         idom(i);
3569       }
3570     }
3571   }
3572   if (_dom_stk == NULL) {
3573     uint init_size = C-&gt;live_nodes() / 100; // Guess that 1/100 is a reasonable initial size.
3574     if (init_size &lt; 10) init_size = 10;
3575     _dom_stk = new GrowableArray&lt;uint&gt;(init_size);
3576   }
3577   // Compute new depth for each node.
3578   for (i = 0; i &lt; _idom_size; i++) {
3579     uint j = i;
3580     // Run up the dom tree to find a node with a depth
3581     while (_dom_depth[j] == no_depth_marker) {
3582       _dom_stk-&gt;push(j);
3583       j = _idom[j]-&gt;_idx;
3584     }
3585     // Compute the depth on the way back down this tree branch
3586     uint dd = _dom_depth[j] + 1;
3587     while (_dom_stk-&gt;length() &gt; 0) {
3588       uint j = _dom_stk-&gt;pop();
3589       _dom_depth[j] = dd;
3590       dd++;
3591     }
3592   }
3593 }
3594 
3595 //------------------------------sort-------------------------------------------
3596 // Insert &#39;loop&#39; into the existing loop tree.  &#39;innermost&#39; is a leaf of the
3597 // loop tree, not the root.
3598 IdealLoopTree *PhaseIdealLoop::sort( IdealLoopTree *loop, IdealLoopTree *innermost ) {
3599   if( !innermost ) return loop; // New innermost loop
3600 
3601   int loop_preorder = get_preorder(loop-&gt;_head); // Cache pre-order number
3602   assert( loop_preorder, &quot;not yet post-walked loop&quot; );
3603   IdealLoopTree **pp = &amp;innermost;      // Pointer to previous next-pointer
3604   IdealLoopTree *l = *pp;               // Do I go before or after &#39;l&#39;?
3605 
3606   // Insert at start of list
3607   while( l ) {                  // Insertion sort based on pre-order
3608     if( l == loop ) return innermost; // Already on list!
3609     int l_preorder = get_preorder(l-&gt;_head); // Cache pre-order number
3610     assert( l_preorder, &quot;not yet post-walked l&quot; );
3611     // Check header pre-order number to figure proper nesting
3612     if( loop_preorder &gt; l_preorder )
3613       break;                    // End of insertion
3614     // If headers tie (e.g., shared headers) check tail pre-order numbers.
3615     // Since I split shared headers, you&#39;d think this could not happen.
3616     // BUT: I must first do the preorder numbering before I can discover I
3617     // have shared headers, so the split headers all get the same preorder
3618     // number as the RegionNode they split from.
3619     if( loop_preorder == l_preorder &amp;&amp;
3620         get_preorder(loop-&gt;_tail) &lt; get_preorder(l-&gt;_tail) )
3621       break;                    // Also check for shared headers (same pre#)
3622     pp = &amp;l-&gt;_parent;           // Chain up list
3623     l = *pp;
3624   }
3625   // Link into list
3626   // Point predecessor to me
3627   *pp = loop;
3628   // Point me to successor
3629   IdealLoopTree *p = loop-&gt;_parent;
3630   loop-&gt;_parent = l;            // Point me to successor
3631   if( p ) sort( p, innermost ); // Insert my parents into list as well
3632   return innermost;
3633 }
3634 
3635 //------------------------------build_loop_tree--------------------------------
3636 // I use a modified Vick/Tarjan algorithm.  I need pre- and a post- visit
3637 // bits.  The _nodes[] array is mapped by Node index and holds a NULL for
3638 // not-yet-pre-walked, pre-order # for pre-but-not-post-walked and holds the
3639 // tightest enclosing IdealLoopTree for post-walked.
3640 //
3641 // During my forward walk I do a short 1-layer lookahead to see if I can find
3642 // a loop backedge with that doesn&#39;t have any work on the backedge.  This
3643 // helps me construct nested loops with shared headers better.
3644 //
3645 // Once I&#39;ve done the forward recursion, I do the post-work.  For each child
3646 // I check to see if there is a backedge.  Backedges define a loop!  I
3647 // insert an IdealLoopTree at the target of the backedge.
3648 //
3649 // During the post-work I also check to see if I have several children
3650 // belonging to different loops.  If so, then this Node is a decision point
3651 // where control flow can choose to change loop nests.  It is at this
3652 // decision point where I can figure out how loops are nested.  At this
3653 // time I can properly order the different loop nests from my children.
3654 // Note that there may not be any backedges at the decision point!
3655 //
3656 // Since the decision point can be far removed from the backedges, I can&#39;t
3657 // order my loops at the time I discover them.  Thus at the decision point
3658 // I need to inspect loop header pre-order numbers to properly nest my
3659 // loops.  This means I need to sort my childrens&#39; loops by pre-order.
3660 // The sort is of size number-of-control-children, which generally limits
3661 // it to size 2 (i.e., I just choose between my 2 target loops).
3662 void PhaseIdealLoop::build_loop_tree() {
3663   // Allocate stack of size C-&gt;live_nodes()/2 to avoid frequent realloc
3664   GrowableArray &lt;Node *&gt; bltstack(C-&gt;live_nodes() &gt;&gt; 1);
3665   Node *n = C-&gt;root();
3666   bltstack.push(n);
3667   int pre_order = 1;
3668   int stack_size;
3669 
3670   while ( ( stack_size = bltstack.length() ) != 0 ) {
3671     n = bltstack.top(); // Leave node on stack
3672     if ( !is_visited(n) ) {
3673       // ---- Pre-pass Work ----
3674       // Pre-walked but not post-walked nodes need a pre_order number.
3675 
3676       set_preorder_visited( n, pre_order ); // set as visited
3677 
3678       // ---- Scan over children ----
3679       // Scan first over control projections that lead to loop headers.
3680       // This helps us find inner-to-outer loops with shared headers better.
3681 
3682       // Scan children&#39;s children for loop headers.
3683       for ( int i = n-&gt;outcnt() - 1; i &gt;= 0; --i ) {
3684         Node* m = n-&gt;raw_out(i);       // Child
3685         if( m-&gt;is_CFG() &amp;&amp; !is_visited(m) ) { // Only for CFG children
3686           // Scan over children&#39;s children to find loop
3687           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3688             Node* l = m-&gt;fast_out(j);
3689             if( is_visited(l) &amp;&amp;       // Been visited?
3690                 !is_postvisited(l) &amp;&amp;  // But not post-visited
3691                 get_preorder(l) &lt; pre_order ) { // And smaller pre-order
3692               // Found!  Scan the DFS down this path before doing other paths
3693               bltstack.push(m);
3694               break;
3695             }
3696           }
3697         }
3698       }
3699       pre_order++;
3700     }
3701     else if ( !is_postvisited(n) ) {
3702       // Note: build_loop_tree_impl() adds out edges on rare occasions,
3703       // such as com.sun.rsasign.am::a.
3704       // For non-recursive version, first, process current children.
3705       // On next iteration, check if additional children were added.
3706       for ( int k = n-&gt;outcnt() - 1; k &gt;= 0; --k ) {
3707         Node* u = n-&gt;raw_out(k);
3708         if ( u-&gt;is_CFG() &amp;&amp; !is_visited(u) ) {
3709           bltstack.push(u);
3710         }
3711       }
3712       if ( bltstack.length() == stack_size ) {
3713         // There were no additional children, post visit node now
3714         (void)bltstack.pop(); // Remove node from stack
3715         pre_order = build_loop_tree_impl( n, pre_order );
3716         // Check for bailout
3717         if (C-&gt;failing()) {
3718           return;
3719         }
3720         // Check to grow _preorders[] array for the case when
3721         // build_loop_tree_impl() adds new nodes.
3722         check_grow_preorders();
3723       }
3724     }
3725     else {
3726       (void)bltstack.pop(); // Remove post-visited node from stack
3727     }
3728   }
3729 }
3730 
3731 //------------------------------build_loop_tree_impl---------------------------
3732 int PhaseIdealLoop::build_loop_tree_impl( Node *n, int pre_order ) {
3733   // ---- Post-pass Work ----
3734   // Pre-walked but not post-walked nodes need a pre_order number.
3735 
3736   // Tightest enclosing loop for this Node
3737   IdealLoopTree *innermost = NULL;
3738 
3739   // For all children, see if any edge is a backedge.  If so, make a loop
3740   // for it.  Then find the tightest enclosing loop for the self Node.
3741   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3742     Node* m = n-&gt;fast_out(i);   // Child
3743     if( n == m ) continue;      // Ignore control self-cycles
3744     if( !m-&gt;is_CFG() ) continue;// Ignore non-CFG edges
3745 
3746     IdealLoopTree *l;           // Child&#39;s loop
3747     if( !is_postvisited(m) ) {  // Child visited but not post-visited?
3748       // Found a backedge
3749       assert( get_preorder(m) &lt; pre_order, &quot;should be backedge&quot; );
3750       // Check for the RootNode, which is already a LoopNode and is allowed
3751       // to have multiple &quot;backedges&quot;.
3752       if( m == C-&gt;root()) {     // Found the root?
3753         l = _ltree_root;        // Root is the outermost LoopNode
3754       } else {                  // Else found a nested loop
3755         // Insert a LoopNode to mark this loop.
3756         l = new IdealLoopTree(this, m, n);
3757       } // End of Else found a nested loop
3758       if( !has_loop(m) )        // If &#39;m&#39; does not already have a loop set
3759         set_loop(m, l);         // Set loop header to loop now
3760 
3761     } else {                    // Else not a nested loop
3762       if( !_nodes[m-&gt;_idx] ) continue; // Dead code has no loop
3763       l = get_loop(m);          // Get previously determined loop
3764       // If successor is header of a loop (nest), move up-loop till it
3765       // is a member of some outer enclosing loop.  Since there are no
3766       // shared headers (I&#39;ve split them already) I only need to go up
3767       // at most 1 level.
3768       while( l &amp;&amp; l-&gt;_head == m ) // Successor heads loop?
3769         l = l-&gt;_parent;         // Move up 1 for me
3770       // If this loop is not properly parented, then this loop
3771       // has no exit path out, i.e. its an infinite loop.
3772       if( !l ) {
3773         // Make loop &quot;reachable&quot; from root so the CFG is reachable.  Basically
3774         // insert a bogus loop exit that is never taken.  &#39;m&#39;, the loop head,
3775         // points to &#39;n&#39;, one (of possibly many) fall-in paths.  There may be
3776         // many backedges as well.
3777 
3778         // Here I set the loop to be the root loop.  I could have, after
3779         // inserting a bogus loop exit, restarted the recursion and found my
3780         // new loop exit.  This would make the infinite loop a first-class
3781         // loop and it would then get properly optimized.  What&#39;s the use of
3782         // optimizing an infinite loop?
3783         l = _ltree_root;        // Oops, found infinite loop
3784 
3785         if (!_verify_only) {
3786           // Insert the NeverBranch between &#39;m&#39; and it&#39;s control user.
3787           NeverBranchNode *iff = new NeverBranchNode( m );
3788           _igvn.register_new_node_with_optimizer(iff);
3789           set_loop(iff, l);
3790           Node *if_t = new CProjNode( iff, 0 );
3791           _igvn.register_new_node_with_optimizer(if_t);
3792           set_loop(if_t, l);
3793 
3794           Node* cfg = NULL;       // Find the One True Control User of m
3795           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax; j++) {
3796             Node* x = m-&gt;fast_out(j);
3797             if (x-&gt;is_CFG() &amp;&amp; x != m &amp;&amp; x != iff)
3798               { cfg = x; break; }
3799           }
3800           assert(cfg != NULL, &quot;must find the control user of m&quot;);
3801           uint k = 0;             // Probably cfg-&gt;in(0)
3802           while( cfg-&gt;in(k) != m ) k++; // But check incase cfg is a Region
3803           cfg-&gt;set_req( k, if_t ); // Now point to NeverBranch
3804           _igvn._worklist.push(cfg);
3805 
3806           // Now create the never-taken loop exit
3807           Node *if_f = new CProjNode( iff, 1 );
3808           _igvn.register_new_node_with_optimizer(if_f);
3809           set_loop(if_f, l);
3810           // Find frame ptr for Halt.  Relies on the optimizer
3811           // V-N&#39;ing.  Easier and quicker than searching through
3812           // the program structure.
3813           Node *frame = new ParmNode( C-&gt;start(), TypeFunc::FramePtr );
3814           _igvn.register_new_node_with_optimizer(frame);
3815           // Halt &amp; Catch Fire
3816           Node* halt = new HaltNode(if_f, frame, &quot;never-taken loop exit reached&quot;);
3817           _igvn.register_new_node_with_optimizer(halt);
3818           set_loop(halt, l);
3819           C-&gt;root()-&gt;add_req(halt);
3820         }
3821         set_loop(C-&gt;root(), _ltree_root);
3822       }
3823     }
3824     // Weeny check for irreducible.  This child was already visited (this
3825     // IS the post-work phase).  Is this child&#39;s loop header post-visited
3826     // as well?  If so, then I found another entry into the loop.
3827     if (!_verify_only) {
3828       while( is_postvisited(l-&gt;_head) ) {
3829         // found irreducible
3830         l-&gt;_irreducible = 1; // = true
3831         l = l-&gt;_parent;
3832         _has_irreducible_loops = true;
3833         // Check for bad CFG here to prevent crash, and bailout of compile
3834         if (l == NULL) {
3835           C-&gt;record_method_not_compilable(&quot;unhandled CFG detected during loop optimization&quot;);
3836           return pre_order;
3837         }
3838       }
3839       C-&gt;set_has_irreducible_loop(_has_irreducible_loops);
3840     }
3841 
3842     // This Node might be a decision point for loops.  It is only if
3843     // it&#39;s children belong to several different loops.  The sort call
3844     // does a trivial amount of work if there is only 1 child or all
3845     // children belong to the same loop.  If however, the children
3846     // belong to different loops, the sort call will properly set the
3847     // _parent pointers to show how the loops nest.
3848     //
3849     // In any case, it returns the tightest enclosing loop.
3850     innermost = sort( l, innermost );
3851   }
3852 
3853   // Def-use info will have some dead stuff; dead stuff will have no
3854   // loop decided on.
3855 
3856   // Am I a loop header?  If so fix up my parent&#39;s child and next ptrs.
3857   if( innermost &amp;&amp; innermost-&gt;_head == n ) {
3858     assert( get_loop(n) == innermost, &quot;&quot; );
3859     IdealLoopTree *p = innermost-&gt;_parent;
3860     IdealLoopTree *l = innermost;
3861     while( p &amp;&amp; l-&gt;_head == n ) {
3862       l-&gt;_next = p-&gt;_child;     // Put self on parents &#39;next child&#39;
3863       p-&gt;_child = l;            // Make self as first child of parent
3864       l = p;                    // Now walk up the parent chain
3865       p = l-&gt;_parent;
3866     }
3867   } else {
3868     // Note that it is possible for a LoopNode to reach here, if the
3869     // backedge has been made unreachable (hence the LoopNode no longer
3870     // denotes a Loop, and will eventually be removed).
3871 
3872     // Record tightest enclosing loop for self.  Mark as post-visited.
3873     set_loop(n, innermost);
3874     // Also record has_call flag early on
3875     if( innermost ) {
3876       if( n-&gt;is_Call() &amp;&amp; !n-&gt;is_CallLeaf() &amp;&amp; !n-&gt;is_macro() ) {
3877         // Do not count uncommon calls
3878         if( !n-&gt;is_CallStaticJava() || !n-&gt;as_CallStaticJava()-&gt;_name ) {
3879           Node *iff = n-&gt;in(0)-&gt;in(0);
3880           // No any calls for vectorized loops.
3881           if( UseSuperWord || !iff-&gt;is_If() ||
3882               (n-&gt;in(0)-&gt;Opcode() == Op_IfFalse &amp;&amp;
3883                (1.0 - iff-&gt;as_If()-&gt;_prob) &gt;= 0.01) ||
3884               (iff-&gt;as_If()-&gt;_prob &gt;= 0.01) )
3885             innermost-&gt;_has_call = 1;
3886         }
3887       } else if( n-&gt;is_Allocate() &amp;&amp; n-&gt;as_Allocate()-&gt;_is_scalar_replaceable ) {
3888         // Disable loop optimizations if the loop has a scalar replaceable
3889         // allocation. This disabling may cause a potential performance lost
3890         // if the allocation is not eliminated for some reason.
3891         innermost-&gt;_allow_optimizations = false;
3892         innermost-&gt;_has_call = 1; // = true
3893       } else if (n-&gt;Opcode() == Op_SafePoint) {
3894         // Record all safepoints in this loop.
3895         if (innermost-&gt;_safepts == NULL) innermost-&gt;_safepts = new Node_List();
3896         innermost-&gt;_safepts-&gt;push(n);
3897       }
3898     }
3899   }
3900 
3901   // Flag as post-visited now
3902   set_postvisited(n);
3903   return pre_order;
3904 }
3905 
3906 
3907 //------------------------------build_loop_early-------------------------------
3908 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
3909 // First pass computes the earliest controlling node possible.  This is the
3910 // controlling input with the deepest dominating depth.
3911 void PhaseIdealLoop::build_loop_early( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
3912   while (worklist.size() != 0) {
3913     // Use local variables nstack_top_n &amp; nstack_top_i to cache values
3914     // on nstack&#39;s top.
3915     Node *nstack_top_n = worklist.pop();
3916     uint  nstack_top_i = 0;
3917 //while_nstack_nonempty:
3918     while (true) {
3919       // Get parent node and next input&#39;s index from stack&#39;s top.
3920       Node  *n = nstack_top_n;
3921       uint   i = nstack_top_i;
3922       uint cnt = n-&gt;req(); // Count of inputs
3923       if (i == 0) {        // Pre-process the node.
3924         if( has_node(n) &amp;&amp;            // Have either loop or control already?
3925             !has_ctrl(n) ) {          // Have loop picked out already?
3926           // During &quot;merge_many_backedges&quot; we fold up several nested loops
3927           // into a single loop.  This makes the members of the original
3928           // loop bodies pointing to dead loops; they need to move up
3929           // to the new UNION&#39;d larger loop.  I set the _head field of these
3930           // dead loops to NULL and the _parent field points to the owning
3931           // loop.  Shades of UNION-FIND algorithm.
3932           IdealLoopTree *ilt;
3933           while( !(ilt = get_loop(n))-&gt;_head ) {
3934             // Normally I would use a set_loop here.  But in this one special
3935             // case, it is legal (and expected) to change what loop a Node
3936             // belongs to.
3937             _nodes.map(n-&gt;_idx, (Node*)(ilt-&gt;_parent) );
3938           }
3939           // Remove safepoints ONLY if I&#39;ve already seen I don&#39;t need one.
3940           // (the old code here would yank a 2nd safepoint after seeing a
3941           // first one, even though the 1st did not dominate in the loop body
3942           // and thus could be avoided indefinitely)
3943           if( !_verify_only &amp;&amp; !_verify_me &amp;&amp; ilt-&gt;_has_sfpt &amp;&amp; n-&gt;Opcode() == Op_SafePoint &amp;&amp;
3944               is_deleteable_safept(n)) {
3945             Node *in = n-&gt;in(TypeFunc::Control);
3946             lazy_replace(n,in);       // Pull safepoint now
3947             if (ilt-&gt;_safepts != NULL) {
3948               ilt-&gt;_safepts-&gt;yank(n);
3949             }
3950             // Carry on with the recursion &quot;as if&quot; we are walking
3951             // only the control input
3952             if( !visited.test_set( in-&gt;_idx ) ) {
3953               worklist.push(in);      // Visit this guy later, using worklist
3954             }
3955             // Get next node from nstack:
3956             // - skip n&#39;s inputs processing by setting i &gt; cnt;
3957             // - we also will not call set_early_ctrl(n) since
3958             //   has_node(n) == true (see the condition above).
3959             i = cnt + 1;
3960           }
3961         }
3962       } // if (i == 0)
3963 
3964       // Visit all inputs
3965       bool done = true;       // Assume all n&#39;s inputs will be processed
3966       while (i &lt; cnt) {
3967         Node *in = n-&gt;in(i);
3968         ++i;
3969         if (in == NULL) continue;
3970         if (in-&gt;pinned() &amp;&amp; !in-&gt;is_CFG())
3971           set_ctrl(in, in-&gt;in(0));
3972         int is_visited = visited.test_set( in-&gt;_idx );
3973         if (!has_node(in)) {  // No controlling input yet?
3974           assert( !in-&gt;is_CFG(), &quot;CFG Node with no controlling input?&quot; );
3975           assert( !is_visited, &quot;visit only once&quot; );
3976           nstack.push(n, i);  // Save parent node and next input&#39;s index.
3977           nstack_top_n = in;  // Process current input now.
3978           nstack_top_i = 0;
3979           done = false;       // Not all n&#39;s inputs processed.
3980           break; // continue while_nstack_nonempty;
3981         } else if (!is_visited) {
3982           // This guy has a location picked out for him, but has not yet
3983           // been visited.  Happens to all CFG nodes, for instance.
3984           // Visit him using the worklist instead of recursion, to break
3985           // cycles.  Since he has a location already we do not need to
3986           // find his location before proceeding with the current Node.
3987           worklist.push(in);  // Visit this guy later, using worklist
3988         }
3989       }
3990       if (done) {
3991         // All of n&#39;s inputs have been processed, complete post-processing.
3992 
3993         // Compute earliest point this Node can go.
3994         // CFG, Phi, pinned nodes already know their controlling input.
3995         if (!has_node(n)) {
3996           // Record earliest legal location
3997           set_early_ctrl( n );
3998         }
3999         if (nstack.is_empty()) {
4000           // Finished all nodes on stack.
4001           // Process next node on the worklist.
4002           break;
4003         }
4004         // Get saved parent node and next input&#39;s index.
4005         nstack_top_n = nstack.node();
4006         nstack_top_i = nstack.index();
4007         nstack.pop();
4008       }
4009     } // while (true)
4010   }
4011 }
4012 
4013 //------------------------------dom_lca_internal--------------------------------
4014 // Pair-wise LCA
4015 Node *PhaseIdealLoop::dom_lca_internal( Node *n1, Node *n2 ) const {
4016   if( !n1 ) return n2;          // Handle NULL original LCA
4017   assert( n1-&gt;is_CFG(), &quot;&quot; );
4018   assert( n2-&gt;is_CFG(), &quot;&quot; );
4019   // find LCA of all uses
4020   uint d1 = dom_depth(n1);
4021   uint d2 = dom_depth(n2);
4022   while (n1 != n2) {
4023     if (d1 &gt; d2) {
4024       n1 =      idom(n1);
4025       d1 = dom_depth(n1);
4026     } else if (d1 &lt; d2) {
4027       n2 =      idom(n2);
4028       d2 = dom_depth(n2);
4029     } else {
4030       // Here d1 == d2.  Due to edits of the dominator-tree, sections
4031       // of the tree might have the same depth.  These sections have
4032       // to be searched more carefully.
4033 
4034       // Scan up all the n1&#39;s with equal depth, looking for n2.
4035       Node *t1 = idom(n1);
4036       while (dom_depth(t1) == d1) {
4037         if (t1 == n2)  return n2;
4038         t1 = idom(t1);
4039       }
4040       // Scan up all the n2&#39;s with equal depth, looking for n1.
4041       Node *t2 = idom(n2);
4042       while (dom_depth(t2) == d2) {
4043         if (t2 == n1)  return n1;
4044         t2 = idom(t2);
4045       }
4046       // Move up to a new dominator-depth value as well as up the dom-tree.
4047       n1 = t1;
4048       n2 = t2;
4049       d1 = dom_depth(n1);
4050       d2 = dom_depth(n2);
4051     }
4052   }
4053   return n1;
4054 }
4055 
4056 //------------------------------compute_idom-----------------------------------
4057 // Locally compute IDOM using dom_lca call.  Correct only if the incoming
4058 // IDOMs are correct.
4059 Node *PhaseIdealLoop::compute_idom( Node *region ) const {
4060   assert( region-&gt;is_Region(), &quot;&quot; );
4061   Node *LCA = NULL;
4062   for( uint i = 1; i &lt; region-&gt;req(); i++ ) {
4063     if( region-&gt;in(i) != C-&gt;top() )
4064       LCA = dom_lca( LCA, region-&gt;in(i) );
4065   }
4066   return LCA;
4067 }
4068 
4069 bool PhaseIdealLoop::verify_dominance(Node* n, Node* use, Node* LCA, Node* early) {
4070   bool had_error = false;
4071 #ifdef ASSERT
4072   if (early != C-&gt;root()) {
4073     // Make sure that there&#39;s a dominance path from LCA to early
4074     Node* d = LCA;
4075     while (d != early) {
4076       if (d == C-&gt;root()) {
4077         dump_bad_graph(&quot;Bad graph detected in compute_lca_of_uses&quot;, n, early, LCA);
4078         tty-&gt;print_cr(&quot;*** Use %d isn&#39;t dominated by def %d ***&quot;, use-&gt;_idx, n-&gt;_idx);
4079         had_error = true;
4080         break;
4081       }
4082       d = idom(d);
4083     }
4084   }
4085 #endif
4086   return had_error;
4087 }
4088 
4089 
4090 Node* PhaseIdealLoop::compute_lca_of_uses(Node* n, Node* early, bool verify) {
4091   // Compute LCA over list of uses
4092   bool had_error = false;
4093   Node *LCA = NULL;
4094   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax &amp;&amp; LCA != early; i++) {
4095     Node* c = n-&gt;fast_out(i);
4096     if (_nodes[c-&gt;_idx] == NULL)
4097       continue;                 // Skip the occasional dead node
4098     if( c-&gt;is_Phi() ) {         // For Phis, we must land above on the path
4099       for( uint j=1; j&lt;c-&gt;req(); j++ ) {// For all inputs
4100         if( c-&gt;in(j) == n ) {   // Found matching input?
4101           Node *use = c-&gt;in(0)-&gt;in(j);
4102           if (_verify_only &amp;&amp; use-&gt;is_top()) continue;
4103           LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
4104           if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
4105         }
4106       }
4107     } else {
4108       // For CFG data-users, use is in the block just prior
4109       Node *use = has_ctrl(c) ? get_ctrl(c) : c-&gt;in(0);
4110       LCA = dom_lca_for_get_late_ctrl( LCA, use, n );
4111       if (verify) had_error = verify_dominance(n, use, LCA, early) || had_error;
4112     }
4113   }
4114   assert(!had_error, &quot;bad dominance&quot;);
4115   return LCA;
4116 }
4117 
4118 // Check the shape of the graph at the loop entry. In some cases,
4119 // the shape of the graph does not match the shape outlined below.
4120 // That is caused by the Opaque1 node &quot;protecting&quot; the shape of
4121 // the graph being removed by, for example, the IGVN performed
4122 // in PhaseIdealLoop::build_and_optimize().
4123 //
4124 // After the Opaque1 node has been removed, optimizations (e.g., split-if,
4125 // loop unswitching, and IGVN, or a combination of them) can freely change
4126 // the graph&#39;s shape. As a result, the graph shape outlined below cannot
4127 // be guaranteed anymore.
4128 bool PhaseIdealLoop::is_canonical_loop_entry(CountedLoopNode* cl) {
4129   if (!cl-&gt;is_main_loop() &amp;&amp; !cl-&gt;is_post_loop()) {
4130     return false;
4131   }
4132   Node* ctrl = cl-&gt;skip_predicates();
4133 
4134   if (ctrl == NULL || (!ctrl-&gt;is_IfTrue() &amp;&amp; !ctrl-&gt;is_IfFalse())) {
4135     return false;
4136   }
4137   Node* iffm = ctrl-&gt;in(0);
4138   if (iffm == NULL || !iffm-&gt;is_If()) {
4139     return false;
4140   }
4141   Node* bolzm = iffm-&gt;in(1);
4142   if (bolzm == NULL || !bolzm-&gt;is_Bool()) {
4143     return false;
4144   }
4145   Node* cmpzm = bolzm-&gt;in(1);
4146   if (cmpzm == NULL || !cmpzm-&gt;is_Cmp()) {
4147     return false;
4148   }
4149   // compares can get conditionally flipped
4150   bool found_opaque = false;
4151   for (uint i = 1; i &lt; cmpzm-&gt;req(); i++) {
4152     Node* opnd = cmpzm-&gt;in(i);
4153     if (opnd &amp;&amp; opnd-&gt;Opcode() == Op_Opaque1) {
4154       found_opaque = true;
4155       break;
4156     }
4157   }
4158   if (!found_opaque) {
4159     return false;
4160   }
4161   return true;
4162 }
4163 
4164 //------------------------------get_late_ctrl----------------------------------
4165 // Compute latest legal control.
4166 Node *PhaseIdealLoop::get_late_ctrl( Node *n, Node *early ) {
4167   assert(early != NULL, &quot;early control should not be NULL&quot;);
4168 
4169   Node* LCA = compute_lca_of_uses(n, early);
4170 #ifdef ASSERT
4171   if (LCA == C-&gt;root() &amp;&amp; LCA != early) {
4172     // def doesn&#39;t dominate uses so print some useful debugging output
4173     compute_lca_of_uses(n, early, true);
4174   }
4175 #endif
4176 
4177   // if this is a load, check for anti-dependent stores
4178   // We use a conservative algorithm to identify potential interfering
4179   // instructions and for rescheduling the load.  The users of the memory
4180   // input of this load are examined.  Any use which is not a load and is
4181   // dominated by early is considered a potentially interfering store.
4182   // This can produce false positives.
4183   if (n-&gt;is_Load() &amp;&amp; LCA != early) {
4184     int load_alias_idx = C-&gt;get_alias_index(n-&gt;adr_type());
4185     if (C-&gt;alias_type(load_alias_idx)-&gt;is_rewritable()) {
4186 
4187       Node_List worklist;
4188 
4189       Node *mem = n-&gt;in(MemNode::Memory);
4190       for (DUIterator_Fast imax, i = mem-&gt;fast_outs(imax); i &lt; imax; i++) {
4191         Node* s = mem-&gt;fast_out(i);
4192         worklist.push(s);
4193       }
4194       while(worklist.size() != 0 &amp;&amp; LCA != early) {
4195         Node* s = worklist.pop();
4196         if (s-&gt;is_Load() || s-&gt;Opcode() == Op_SafePoint ||
4197             (s-&gt;is_CallStaticJava() &amp;&amp; s-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0)) {
4198           continue;
4199         } else if (s-&gt;is_MergeMem()) {
4200           for (DUIterator_Fast imax, i = s-&gt;fast_outs(imax); i &lt; imax; i++) {
4201             Node* s1 = s-&gt;fast_out(i);
4202             worklist.push(s1);
4203           }
4204         } else {
4205           Node *sctrl = has_ctrl(s) ? get_ctrl(s) : s-&gt;in(0);
4206           const TypePtr* adr_type = s-&gt;adr_type();
4207           if (s-&gt;is_ArrayCopy()) {
4208             // Copy to known instance needs destination type to test for aliasing
4209             const TypePtr* dest_type = s-&gt;as_ArrayCopy()-&gt;_dest_type;
4210             if (dest_type != TypeOopPtr::BOTTOM) {
4211               adr_type = dest_type;
4212             }
4213           }
4214           assert(sctrl != NULL || !s-&gt;is_reachable_from_root(), &quot;must have control&quot;);
4215           if (sctrl != NULL &amp;&amp; !sctrl-&gt;is_top() &amp;&amp; C-&gt;can_alias(adr_type, load_alias_idx) &amp;&amp; is_dominator(early, sctrl)) {
4216             LCA = dom_lca_for_get_late_ctrl(LCA, sctrl, n);
4217           }
4218         }
4219       }
4220     }
4221   }
4222 
4223   assert(LCA == find_non_split_ctrl(LCA), &quot;unexpected late control&quot;);
4224   return LCA;
4225 }
4226 
4227 // true if CFG node d dominates CFG node n
4228 bool PhaseIdealLoop::is_dominator(Node *d, Node *n) {
4229   if (d == n)
4230     return true;
4231   assert(d-&gt;is_CFG() &amp;&amp; n-&gt;is_CFG(), &quot;must have CFG nodes&quot;);
4232   uint dd = dom_depth(d);
4233   while (dom_depth(n) &gt;= dd) {
4234     if (n == d)
4235       return true;
4236     n = idom(n);
4237   }
4238   return false;
4239 }
4240 
4241 //------------------------------dom_lca_for_get_late_ctrl_internal-------------
4242 // Pair-wise LCA with tags.
4243 // Tag each index with the node &#39;tag&#39; currently being processed
4244 // before advancing up the dominator chain using idom().
4245 // Later calls that find a match to &#39;tag&#39; know that this path has already
4246 // been considered in the current LCA (which is input &#39;n1&#39; by convention).
4247 // Since get_late_ctrl() is only called once for each node, the tag array
4248 // does not need to be cleared between calls to get_late_ctrl().
4249 // Algorithm trades a larger constant factor for better asymptotic behavior
4250 //
4251 Node *PhaseIdealLoop::dom_lca_for_get_late_ctrl_internal( Node *n1, Node *n2, Node *tag ) {
4252   uint d1 = dom_depth(n1);
4253   uint d2 = dom_depth(n2);
4254 
4255   do {
4256     if (d1 &gt; d2) {
4257       // current lca is deeper than n2
4258       _dom_lca_tags.map(n1-&gt;_idx, tag);
4259       n1 =      idom(n1);
4260       d1 = dom_depth(n1);
4261     } else if (d1 &lt; d2) {
4262       // n2 is deeper than current lca
4263       Node *memo = _dom_lca_tags[n2-&gt;_idx];
4264       if( memo == tag ) {
4265         return n1;    // Return the current LCA
4266       }
4267       _dom_lca_tags.map(n2-&gt;_idx, tag);
4268       n2 =      idom(n2);
4269       d2 = dom_depth(n2);
4270     } else {
4271       // Here d1 == d2.  Due to edits of the dominator-tree, sections
4272       // of the tree might have the same depth.  These sections have
4273       // to be searched more carefully.
4274 
4275       // Scan up all the n1&#39;s with equal depth, looking for n2.
4276       _dom_lca_tags.map(n1-&gt;_idx, tag);
4277       Node *t1 = idom(n1);
4278       while (dom_depth(t1) == d1) {
4279         if (t1 == n2)  return n2;
4280         _dom_lca_tags.map(t1-&gt;_idx, tag);
4281         t1 = idom(t1);
4282       }
4283       // Scan up all the n2&#39;s with equal depth, looking for n1.
4284       _dom_lca_tags.map(n2-&gt;_idx, tag);
4285       Node *t2 = idom(n2);
4286       while (dom_depth(t2) == d2) {
4287         if (t2 == n1)  return n1;
4288         _dom_lca_tags.map(t2-&gt;_idx, tag);
4289         t2 = idom(t2);
4290       }
4291       // Move up to a new dominator-depth value as well as up the dom-tree.
4292       n1 = t1;
4293       n2 = t2;
4294       d1 = dom_depth(n1);
4295       d2 = dom_depth(n2);
4296     }
4297   } while (n1 != n2);
4298   return n1;
4299 }
4300 
4301 //------------------------------init_dom_lca_tags------------------------------
4302 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4303 // Intended use does not involve any growth for the array, so it could
4304 // be of fixed size.
4305 void PhaseIdealLoop::init_dom_lca_tags() {
4306   uint limit = C-&gt;unique() + 1;
4307   _dom_lca_tags.map( limit, NULL );
4308 #ifdef ASSERT
4309   for( uint i = 0; i &lt; limit; ++i ) {
4310     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4311   }
4312 #endif // ASSERT
4313 }
4314 
4315 //------------------------------clear_dom_lca_tags------------------------------
4316 // Tag could be a node&#39;s integer index, 32bits instead of 64bits in some cases
4317 // Intended use does not involve any growth for the array, so it could
4318 // be of fixed size.
4319 void PhaseIdealLoop::clear_dom_lca_tags() {
4320   uint limit = C-&gt;unique() + 1;
4321   _dom_lca_tags.map( limit, NULL );
4322   _dom_lca_tags.clear();
4323 #ifdef ASSERT
4324   for( uint i = 0; i &lt; limit; ++i ) {
4325     assert(_dom_lca_tags[i] == NULL, &quot;Must be distinct from each node pointer&quot;);
4326   }
4327 #endif // ASSERT
4328 }
4329 
4330 //------------------------------build_loop_late--------------------------------
4331 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4332 // Second pass finds latest legal placement, and ideal loop placement.
4333 void PhaseIdealLoop::build_loop_late( VectorSet &amp;visited, Node_List &amp;worklist, Node_Stack &amp;nstack ) {
4334   while (worklist.size() != 0) {
4335     Node *n = worklist.pop();
4336     // Only visit once
4337     if (visited.test_set(n-&gt;_idx)) continue;
4338     uint cnt = n-&gt;outcnt();
4339     uint   i = 0;
4340     while (true) {
4341       assert( _nodes[n-&gt;_idx], &quot;no dead nodes&quot; );
4342       // Visit all children
4343       if (i &lt; cnt) {
4344         Node* use = n-&gt;raw_out(i);
4345         ++i;
4346         // Check for dead uses.  Aggressively prune such junk.  It might be
4347         // dead in the global sense, but still have local uses so I cannot
4348         // easily call &#39;remove_dead_node&#39;.
4349         if( _nodes[use-&gt;_idx] != NULL || use-&gt;is_top() ) { // Not dead?
4350           // Due to cycles, we might not hit the same fixed point in the verify
4351           // pass as we do in the regular pass.  Instead, visit such phis as
4352           // simple uses of the loop head.
4353           if( use-&gt;in(0) &amp;&amp; (use-&gt;is_CFG() || use-&gt;is_Phi()) ) {
4354             if( !visited.test(use-&gt;_idx) )
4355               worklist.push(use);
4356           } else if( !visited.test_set(use-&gt;_idx) ) {
4357             nstack.push(n, i); // Save parent and next use&#39;s index.
4358             n   = use;         // Process all children of current use.
4359             cnt = use-&gt;outcnt();
4360             i   = 0;
4361           }
4362         } else {
4363           // Do not visit around the backedge of loops via data edges.
4364           // push dead code onto a worklist
4365           _deadlist.push(use);
4366         }
4367       } else {
4368         // All of n&#39;s children have been processed, complete post-processing.
4369         build_loop_late_post(n);
4370         if (nstack.is_empty()) {
4371           // Finished all nodes on stack.
4372           // Process next node on the worklist.
4373           break;
4374         }
4375         // Get saved parent node and next use&#39;s index. Visit the rest of uses.
4376         n   = nstack.node();
4377         cnt = n-&gt;outcnt();
4378         i   = nstack.index();
4379         nstack.pop();
4380       }
4381     }
4382   }
4383 }
4384 
4385 // Verify that no data node is scheduled in the outer loop of a strip
4386 // mined loop.
4387 void PhaseIdealLoop::verify_strip_mined_scheduling(Node *n, Node* least) {
4388 #ifdef ASSERT
4389   if (get_loop(least)-&gt;_nest == 0) {
4390     return;
4391   }
4392   IdealLoopTree* loop = get_loop(least);
4393   Node* head = loop-&gt;_head;
4394   if (head-&gt;is_OuterStripMinedLoop() &amp;&amp;
4395       // Verification can&#39;t be applied to fully built strip mined loops
4396       head-&gt;as_Loop()-&gt;outer_loop_end()-&gt;in(1)-&gt;find_int_con(-1) == 0) {
4397     Node* sfpt = head-&gt;as_Loop()-&gt;outer_safepoint();
4398     ResourceMark rm;
4399     Unique_Node_List wq;
4400     wq.push(sfpt);
4401     for (uint i = 0; i &lt; wq.size(); i++) {
4402       Node *m = wq.at(i);
4403       for (uint i = 1; i &lt; m-&gt;req(); i++) {
4404         Node* nn = m-&gt;in(i);
4405         if (nn == n) {
4406           return;
4407         }
4408         if (nn != NULL &amp;&amp; has_ctrl(nn) &amp;&amp; get_loop(get_ctrl(nn)) == loop) {
4409           wq.push(nn);
4410         }
4411       }
4412     }
4413     ShouldNotReachHere();
4414   }
4415 #endif
4416 }
4417 
4418 
4419 //------------------------------build_loop_late_post---------------------------
4420 // Put Data nodes into some loop nest, by setting the _nodes[]-&gt;loop mapping.
4421 // Second pass finds latest legal placement, and ideal loop placement.
4422 void PhaseIdealLoop::build_loop_late_post(Node *n) {
4423   build_loop_late_post_work(n, true);
4424 }
4425 
4426 void PhaseIdealLoop::build_loop_late_post_work(Node *n, bool pinned) {
4427 
4428   if (n-&gt;req() == 2 &amp;&amp; (n-&gt;Opcode() == Op_ConvI2L || n-&gt;Opcode() == Op_CastII) &amp;&amp; !C-&gt;major_progress() &amp;&amp; !_verify_only) {
4429     _igvn._worklist.push(n);  // Maybe we&#39;ll normalize it, if no more loops.
4430   }
4431 
4432 #ifdef ASSERT
4433   if (_verify_only &amp;&amp; !n-&gt;is_CFG()) {
4434     // Check def-use domination.
4435     compute_lca_of_uses(n, get_ctrl(n), true /* verify */);
4436   }
4437 #endif
4438 
4439   // CFG and pinned nodes already handled
4440   if( n-&gt;in(0) ) {
4441     if( n-&gt;in(0)-&gt;is_top() ) return; // Dead?
4442 
4443     // We&#39;d like +VerifyLoopOptimizations to not believe that Mod&#39;s/Loads
4444     // _must_ be pinned (they have to observe their control edge of course).
4445     // Unlike Stores (which modify an unallocable resource, the memory
4446     // state), Mods/Loads can float around.  So free them up.
4447     switch( n-&gt;Opcode() ) {
4448     case Op_DivI:
4449     case Op_DivF:
4450     case Op_DivD:
4451     case Op_ModI:
4452     case Op_ModF:
4453     case Op_ModD:
4454     case Op_LoadB:              // Same with Loads; they can sink
4455     case Op_LoadUB:             // during loop optimizations.
4456     case Op_LoadUS:
4457     case Op_LoadD:
4458     case Op_LoadF:
4459     case Op_LoadI:
4460     case Op_LoadKlass:
4461     case Op_LoadNKlass:
4462     case Op_LoadL:
4463     case Op_LoadS:
4464     case Op_LoadP:
4465     case Op_LoadN:
4466     case Op_LoadRange:
4467     case Op_LoadD_unaligned:
4468     case Op_LoadL_unaligned:
4469     case Op_StrComp:            // Does a bunch of load-like effects
4470     case Op_StrEquals:
4471     case Op_StrIndexOf:
4472     case Op_StrIndexOfChar:
4473     case Op_AryEq:
4474     case Op_HasNegatives:
4475       pinned = false;
4476     }
4477     if (n-&gt;is_CMove()) {
4478       pinned = false;
4479     }
4480     if( pinned ) {
4481       IdealLoopTree *chosen_loop = get_loop(n-&gt;is_CFG() ? n : get_ctrl(n));
4482       if( !chosen_loop-&gt;_child )       // Inner loop?
4483         chosen_loop-&gt;_body.push(n); // Collect inner loops
4484       return;
4485     }
4486   } else {                      // No slot zero
4487     if( n-&gt;is_CFG() ) {         // CFG with no slot 0 is dead
4488       _nodes.map(n-&gt;_idx,0);    // No block setting, it&#39;s globally dead
4489       return;
4490     }
4491     assert(!n-&gt;is_CFG() || n-&gt;outcnt() == 0, &quot;&quot;);
4492   }
4493 
4494   // Do I have a &quot;safe range&quot; I can select over?
4495   Node *early = get_ctrl(n);// Early location already computed
4496 
4497   // Compute latest point this Node can go
4498   Node *LCA = get_late_ctrl( n, early );
4499   // LCA is NULL due to uses being dead
4500   if( LCA == NULL ) {
4501 #ifdef ASSERT
4502     for (DUIterator i1 = n-&gt;outs(); n-&gt;has_out(i1); i1++) {
4503       assert( _nodes[n-&gt;out(i1)-&gt;_idx] == NULL, &quot;all uses must also be dead&quot;);
4504     }
4505 #endif
4506     _nodes.map(n-&gt;_idx, 0);     // This node is useless
4507     _deadlist.push(n);
4508     return;
4509   }
4510   assert(LCA != NULL &amp;&amp; !LCA-&gt;is_top(), &quot;no dead nodes&quot;);
4511 
4512   Node *legal = LCA;            // Walk &#39;legal&#39; up the IDOM chain
4513   Node *least = legal;          // Best legal position so far
4514   while( early != legal ) {     // While not at earliest legal
4515 #ifdef ASSERT
4516     if (legal-&gt;is_Start() &amp;&amp; !early-&gt;is_Root()) {
4517       // Bad graph. Print idom path and fail.
4518       dump_bad_graph(&quot;Bad graph detected in build_loop_late&quot;, n, early, LCA);
4519       assert(false, &quot;Bad graph detected in build_loop_late&quot;);
4520     }
4521 #endif
4522     // Find least loop nesting depth
4523     legal = idom(legal);        // Bump up the IDOM tree
4524     // Check for lower nesting depth
4525     if( get_loop(legal)-&gt;_nest &lt; get_loop(least)-&gt;_nest )
4526       least = legal;
4527   }
4528   assert(early == legal || legal != C-&gt;root(), &quot;bad dominance of inputs&quot;);
4529 
4530   // Try not to place code on a loop entry projection
4531   // which can inhibit range check elimination.
4532   if (least != early) {
4533     Node* ctrl_out = least-&gt;unique_ctrl_out();
4534     if (ctrl_out &amp;&amp; ctrl_out-&gt;is_Loop() &amp;&amp;
4535         least == ctrl_out-&gt;in(LoopNode::EntryControl)) {
4536       // Move the node above predicates as far up as possible so a
4537       // following pass of loop predication doesn&#39;t hoist a predicate
4538       // that depends on it above that node.
4539       Node* new_ctrl = least;
4540       for (;;) {
4541         if (!new_ctrl-&gt;is_Proj()) {
4542           break;
4543         }
4544         CallStaticJavaNode* call = new_ctrl-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none);
4545         if (call == NULL) {
4546           break;
4547         }
4548         int req = call-&gt;uncommon_trap_request();
4549         Deoptimization::DeoptReason trap_reason = Deoptimization::trap_request_reason(req);
4550         if (trap_reason != Deoptimization::Reason_loop_limit_check &amp;&amp;
4551             trap_reason != Deoptimization::Reason_predicate &amp;&amp;
4552             trap_reason != Deoptimization::Reason_profile_predicate) {
4553           break;
4554         }
4555         Node* c = new_ctrl-&gt;in(0)-&gt;in(0);
4556         if (is_dominator(c, early) &amp;&amp; c != early) {
4557           break;
4558         }
4559         new_ctrl = c;
4560       }
4561       least = new_ctrl;
4562     }
4563   }
4564 
4565 #ifdef ASSERT
4566   // If verifying, verify that &#39;verify_me&#39; has a legal location
4567   // and choose it as our location.
4568   if( _verify_me ) {
4569     Node *v_ctrl = _verify_me-&gt;get_ctrl_no_update(n);
4570     Node *legal = LCA;
4571     while( early != legal ) {   // While not at earliest legal
4572       if( legal == v_ctrl ) break;  // Check for prior good location
4573       legal = idom(legal)      ;// Bump up the IDOM tree
4574     }
4575     // Check for prior good location
4576     if( legal == v_ctrl ) least = legal; // Keep prior if found
4577   }
4578 #endif
4579 
4580   // Assign discovered &quot;here or above&quot; point
4581   least = find_non_split_ctrl(least);
4582   verify_strip_mined_scheduling(n, least);
4583   set_ctrl(n, least);
4584 
4585   // Collect inner loop bodies
4586   IdealLoopTree *chosen_loop = get_loop(least);
4587   if( !chosen_loop-&gt;_child )   // Inner loop?
4588     chosen_loop-&gt;_body.push(n);// Collect inner loops
4589 }
4590 
4591 #ifdef ASSERT
4592 void PhaseIdealLoop::dump_bad_graph(const char* msg, Node* n, Node* early, Node* LCA) {
4593   tty-&gt;print_cr(&quot;%s&quot;, msg);
4594   tty-&gt;print(&quot;n: &quot;); n-&gt;dump();
4595   tty-&gt;print(&quot;early(n): &quot;); early-&gt;dump();
4596   if (n-&gt;in(0) != NULL  &amp;&amp; !n-&gt;in(0)-&gt;is_top() &amp;&amp;
4597       n-&gt;in(0) != early &amp;&amp; !n-&gt;in(0)-&gt;is_Root()) {
4598     tty-&gt;print(&quot;n-&gt;in(0): &quot;); n-&gt;in(0)-&gt;dump();
4599   }
4600   for (uint i = 1; i &lt; n-&gt;req(); i++) {
4601     Node* in1 = n-&gt;in(i);
4602     if (in1 != NULL &amp;&amp; in1 != n &amp;&amp; !in1-&gt;is_top()) {
4603       tty-&gt;print(&quot;n-&gt;in(%d): &quot;, i); in1-&gt;dump();
4604       Node* in1_early = get_ctrl(in1);
4605       tty-&gt;print(&quot;early(n-&gt;in(%d)): &quot;, i); in1_early-&gt;dump();
4606       if (in1-&gt;in(0) != NULL     &amp;&amp; !in1-&gt;in(0)-&gt;is_top() &amp;&amp;
4607           in1-&gt;in(0) != in1_early &amp;&amp; !in1-&gt;in(0)-&gt;is_Root()) {
4608         tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(0): &quot;, i); in1-&gt;in(0)-&gt;dump();
4609       }
4610       for (uint j = 1; j &lt; in1-&gt;req(); j++) {
4611         Node* in2 = in1-&gt;in(j);
4612         if (in2 != NULL &amp;&amp; in2 != n &amp;&amp; in2 != in1 &amp;&amp; !in2-&gt;is_top()) {
4613           tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d): &quot;, i, j); in2-&gt;dump();
4614           Node* in2_early = get_ctrl(in2);
4615           tty-&gt;print(&quot;early(n-&gt;in(%d)-&gt;in(%d)): &quot;, i, j); in2_early-&gt;dump();
4616           if (in2-&gt;in(0) != NULL     &amp;&amp; !in2-&gt;in(0)-&gt;is_top() &amp;&amp;
4617               in2-&gt;in(0) != in2_early &amp;&amp; !in2-&gt;in(0)-&gt;is_Root()) {
4618             tty-&gt;print(&quot;n-&gt;in(%d)-&gt;in(%d)-&gt;in(0): &quot;, i, j); in2-&gt;in(0)-&gt;dump();
4619           }
4620         }
4621       }
4622     }
4623   }
4624   tty-&gt;cr();
4625   tty-&gt;print(&quot;LCA(n): &quot;); LCA-&gt;dump();
4626   for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {
4627     Node* u1 = n-&gt;raw_out(i);
4628     if (u1 == n)
4629       continue;
4630     tty-&gt;print(&quot;n-&gt;out(%d): &quot;, i); u1-&gt;dump();
4631     if (u1-&gt;is_CFG()) {
4632       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4633         Node* u2 = u1-&gt;raw_out(j);
4634         if (u2 != u1 &amp;&amp; u2 != n &amp;&amp; u2-&gt;is_CFG()) {
4635           tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4636         }
4637       }
4638     } else {
4639       Node* u1_later = get_ctrl(u1);
4640       tty-&gt;print(&quot;later(n-&gt;out(%d)): &quot;, i); u1_later-&gt;dump();
4641       if (u1-&gt;in(0) != NULL     &amp;&amp; !u1-&gt;in(0)-&gt;is_top() &amp;&amp;
4642           u1-&gt;in(0) != u1_later &amp;&amp; !u1-&gt;in(0)-&gt;is_Root()) {
4643         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u1-&gt;in(0)-&gt;dump();
4644       }
4645       for (uint j = 0; j &lt; u1-&gt;outcnt(); j++) {
4646         Node* u2 = u1-&gt;raw_out(j);
4647         if (u2 == n || u2 == u1)
4648           continue;
4649         tty-&gt;print(&quot;n-&gt;out(%d)-&gt;out(%d): &quot;, i, j); u2-&gt;dump();
4650         if (!u2-&gt;is_CFG()) {
4651           Node* u2_later = get_ctrl(u2);
4652           tty-&gt;print(&quot;later(n-&gt;out(%d)-&gt;out(%d)): &quot;, i, j); u2_later-&gt;dump();
4653           if (u2-&gt;in(0) != NULL     &amp;&amp; !u2-&gt;in(0)-&gt;is_top() &amp;&amp;
4654               u2-&gt;in(0) != u2_later &amp;&amp; !u2-&gt;in(0)-&gt;is_Root()) {
4655             tty-&gt;print(&quot;n-&gt;out(%d)-&gt;in(0): &quot;, i); u2-&gt;in(0)-&gt;dump();
4656           }
4657         }
4658       }
4659     }
4660   }
4661   tty-&gt;cr();
4662   int ct = 0;
4663   Node *dbg_legal = LCA;
4664   while(!dbg_legal-&gt;is_Start() &amp;&amp; ct &lt; 100) {
4665     tty-&gt;print(&quot;idom[%d] &quot;,ct); dbg_legal-&gt;dump();
4666     ct++;
4667     dbg_legal = idom(dbg_legal);
4668   }
4669   tty-&gt;cr();
4670 }
4671 #endif
4672 
4673 #ifndef PRODUCT
4674 //------------------------------dump-------------------------------------------
4675 void PhaseIdealLoop::dump() const {
4676   ResourceMark rm;
4677   Arena* arena = Thread::current()-&gt;resource_area();
4678   Node_Stack stack(arena, C-&gt;live_nodes() &gt;&gt; 2);
4679   Node_List rpo_list;
4680   VectorSet visited(arena);
4681   visited.set(C-&gt;top()-&gt;_idx);
4682   rpo(C-&gt;root(), stack, visited, rpo_list);
4683   // Dump root loop indexed by last element in PO order
4684   dump(_ltree_root, rpo_list.size(), rpo_list);
4685 }
4686 
4687 void PhaseIdealLoop::dump(IdealLoopTree* loop, uint idx, Node_List &amp;rpo_list) const {
4688   loop-&gt;dump_head();
4689 
4690   // Now scan for CFG nodes in the same loop
4691   for (uint j = idx; j &gt; 0; j--) {
4692     Node* n = rpo_list[j-1];
4693     if (!_nodes[n-&gt;_idx])      // Skip dead nodes
4694       continue;
4695 
4696     if (get_loop(n) != loop) { // Wrong loop nest
4697       if (get_loop(n)-&gt;_head == n &amp;&amp;    // Found nested loop?
4698           get_loop(n)-&gt;_parent == loop)
4699         dump(get_loop(n), rpo_list.size(), rpo_list);     // Print it nested-ly
4700       continue;
4701     }
4702 
4703     // Dump controlling node
4704     tty-&gt;sp(2 * loop-&gt;_nest);
4705     tty-&gt;print(&quot;C&quot;);
4706     if (n == C-&gt;root()) {
4707       n-&gt;dump();
4708     } else {
4709       Node* cached_idom   = idom_no_update(n);
4710       Node* computed_idom = n-&gt;in(0);
4711       if (n-&gt;is_Region()) {
4712         computed_idom = compute_idom(n);
4713         // computed_idom() will return n-&gt;in(0) when idom(n) is an IfNode (or
4714         // any MultiBranch ctrl node), so apply a similar transform to
4715         // the cached idom returned from idom_no_update.
4716         cached_idom = find_non_split_ctrl(cached_idom);
4717       }
4718       tty-&gt;print(&quot; ID:%d&quot;, computed_idom-&gt;_idx);
4719       n-&gt;dump();
4720       if (cached_idom != computed_idom) {
4721         tty-&gt;print_cr(&quot;*** BROKEN IDOM!  Computed as: %d, cached as: %d&quot;,
4722                       computed_idom-&gt;_idx, cached_idom-&gt;_idx);
4723       }
4724     }
4725     // Dump nodes it controls
4726     for (uint k = 0; k &lt; _nodes.Size(); k++) {
4727       // (k &lt; C-&gt;unique() &amp;&amp; get_ctrl(find(k)) == n)
4728       if (k &lt; C-&gt;unique() &amp;&amp; _nodes[k] == (Node*)((intptr_t)n + 1)) {
4729         Node* m = C-&gt;root()-&gt;find(k);
4730         if (m &amp;&amp; m-&gt;outcnt() &gt; 0) {
4731           if (!(has_ctrl(m) &amp;&amp; get_ctrl_no_update(m) == n)) {
4732             tty-&gt;print_cr(&quot;*** BROKEN CTRL ACCESSOR!  _nodes[k] is %p, ctrl is %p&quot;,
4733                           _nodes[k], has_ctrl(m) ? get_ctrl_no_update(m) : NULL);
4734           }
4735           tty-&gt;sp(2 * loop-&gt;_nest + 1);
4736           m-&gt;dump();
4737         }
4738       }
4739     }
4740   }
4741 }
4742 #endif
4743 
4744 // Collect a R-P-O for the whole CFG.
4745 // Result list is in post-order (scan backwards for RPO)
4746 void PhaseIdealLoop::rpo(Node* start, Node_Stack &amp;stk, VectorSet &amp;visited, Node_List &amp;rpo_list) const {
4747   stk.push(start, 0);
4748   visited.set(start-&gt;_idx);
4749 
4750   while (stk.is_nonempty()) {
4751     Node* m   = stk.node();
4752     uint  idx = stk.index();
4753     if (idx &lt; m-&gt;outcnt()) {
4754       stk.set_index(idx + 1);
4755       Node* n = m-&gt;raw_out(idx);
4756       if (n-&gt;is_CFG() &amp;&amp; !visited.test_set(n-&gt;_idx)) {
4757         stk.push(n, 0);
4758       }
4759     } else {
4760       rpo_list.push(m);
4761       stk.pop();
4762     }
4763   }
4764 }
4765 
4766 
4767 //=============================================================================
4768 //------------------------------LoopTreeIterator-------------------------------
4769 
4770 // Advance to next loop tree using a preorder, left-to-right traversal.
4771 void LoopTreeIterator::next() {
4772   assert(!done(), &quot;must not be done.&quot;);
4773   if (_curnt-&gt;_child != NULL) {
4774     _curnt = _curnt-&gt;_child;
4775   } else if (_curnt-&gt;_next != NULL) {
4776     _curnt = _curnt-&gt;_next;
4777   } else {
4778     while (_curnt != _root &amp;&amp; _curnt-&gt;_next == NULL) {
4779       _curnt = _curnt-&gt;_parent;
4780     }
4781     if (_curnt == _root) {
4782       _curnt = NULL;
4783       assert(done(), &quot;must be done.&quot;);
4784     } else {
4785       assert(_curnt-&gt;_next != NULL, &quot;must be more to do&quot;);
4786       _curnt = _curnt-&gt;_next;
4787     }
4788   }
4789 }
<a name="5" id="anc5"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="5" type="hidden" />
</body>
</html>