<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/memory/metaspaceShared.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="metaspace.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspaceShared.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspaceShared.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  71 #include &quot;utilities/bitMap.inline.hpp&quot;
  72 #include &quot;utilities/ostream.hpp&quot;
  73 #include &quot;utilities/defaultStream.hpp&quot;
  74 #include &quot;utilities/hashtable.inline.hpp&quot;
  75 #if INCLUDE_G1GC
  76 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
  77 #endif
  78 
  79 ReservedSpace MetaspaceShared::_shared_rs;
  80 VirtualSpace MetaspaceShared::_shared_vs;
  81 ReservedSpace MetaspaceShared::_symbol_rs;
  82 VirtualSpace MetaspaceShared::_symbol_vs;
  83 MetaspaceSharedStats MetaspaceShared::_stats;
  84 bool MetaspaceShared::_has_error_classes;
  85 bool MetaspaceShared::_archive_loading_failed = false;
  86 bool MetaspaceShared::_remapped_readwrite = false;
  87 address MetaspaceShared::_i2i_entry_code_buffers = NULL;
  88 size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;
  89 void* MetaspaceShared::_shared_metaspace_static_top = NULL;
  90 intx MetaspaceShared::_relocation_delta;

  91 
  92 // The CDS archive is divided into the following regions:
  93 //     mc  - misc code (the method entry trampolines, c++ vtables)
  94 //     rw  - read-write metadata
  95 //     ro  - read-only metadata and read-only tables
  96 //
  97 //     ca0 - closed archive heap space #0
  98 //     ca1 - closed archive heap space #1 (may be empty)
  99 //     oa0 - open archive heap space #0
 100 //     oa1 - open archive heap space #1 (may be empty)
 101 //
 102 // The mc, rw, and ro regions are linearly allocated, starting from
 103 // SharedBaseAddress, in the order of mc-&gt;rw-&gt;ro. The size of these 3 regions
 104 // are page-aligned, and there&#39;s no gap between any consecutive regions.
 105 //
 106 // These 3 regions are populated in the following steps:
 107 // [1] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are
 108 //     temporarily allocated outside of the shared regions. Only the method entry
 109 //     trampolines are written into the mc region.
 110 // [2] C++ vtables are copied into the mc region.
</pre>
<hr />
<pre>
 223 
 224 void MetaspaceShared::pack_dump_space(DumpRegion* current, DumpRegion* next,
 225                                       ReservedSpace* rs) {
 226   current-&gt;pack(next);
 227 }
 228 
 229 char* MetaspaceShared::symbol_space_alloc(size_t num_bytes) {
 230   return _symbol_region.allocate(num_bytes);
 231 }
 232 
 233 char* MetaspaceShared::misc_code_space_alloc(size_t num_bytes) {
 234   return _mc_region.allocate(num_bytes);
 235 }
 236 
 237 char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {
 238   return _ro_region.allocate(num_bytes);
 239 }
 240 
 241 size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 242 

 243 #ifdef _LP64
<span class="line-modified"> 244 // Check SharedBaseAddress for validity. At this point, os::init() must</span>
<span class="line-modified"> 245 //  have been ran.</span>
<span class="line-modified"> 246 static void check_SharedBaseAddress() {</span>
<span class="line-modified"> 247   SharedBaseAddress = align_up(SharedBaseAddress,</span>
<span class="line-modified"> 248                                MetaspaceShared::reserved_space_alignment());</span>
<span class="line-modified"> 249   if (!CompressedKlassPointers::is_valid_base((address)SharedBaseAddress)) {</span>
<span class="line-modified"> 250     log_warning(cds)(&quot;SharedBaseAddress=&quot; PTR_FORMAT &quot; is invalid for this &quot;</span>
<span class="line-modified"> 251                      &quot;platform, option will be ignored.&quot;,</span>
<span class="line-modified"> 252                      p2i((address)SharedBaseAddress));</span>























 253     SharedBaseAddress = Arguments::default_SharedBaseAddress();

 254   }


 255 }
<span class="line-removed"> 256 #endif</span>
 257 
 258 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
 259   assert(DumpSharedSpaces, &quot;should be called for dump time only&quot;);
 260 
<span class="line-removed"> 261 #ifdef _LP64</span>
<span class="line-removed"> 262   check_SharedBaseAddress();</span>
<span class="line-removed"> 263 #endif</span>
<span class="line-removed"> 264 </span>
 265   const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();
<span class="line-removed"> 266   char* shared_base = (char*)align_up((char*)SharedBaseAddress, reserve_alignment);</span>
 267 
 268 #ifdef _LP64
<span class="line-removed"> 269   assert(CompressedKlassPointers::is_valid_base((address)shared_base), &quot;Sanity&quot;);</span>
 270   // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
 271   //  will use that to house both the archives and the ccs. See below for
 272   //  details.
 273   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
 274   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
 275 #else
 276   // We don&#39;t support archives larger than 256MB on 32-bit due to limited
 277   //  virtual address space.
 278   size_t cds_total = align_down(256*M, reserve_alignment);
 279 #endif
 280 



 281   // Whether to use SharedBaseAddress as attach address.
 282   bool use_requested_base = true;
 283 
 284   if (shared_base == NULL) {
 285     use_requested_base = false;
 286   }
 287 
 288   if (ArchiveRelocationMode == 1) {
 289     log_info(cds)(&quot;ArchiveRelocationMode == 1: always allocate class space at an alternative address&quot;);
 290     use_requested_base = false;
 291   }
 292 
 293   // First try to reserve the space at the specified SharedBaseAddress.
 294   assert(!_shared_rs.is_reserved(), &quot;must be&quot;);
 295   if (use_requested_base) {
 296     _shared_rs = ReservedSpace(cds_total, reserve_alignment,
 297                                false /* large */, (char*)shared_base);
 298     if (_shared_rs.is_reserved()) {
 299       assert(_shared_rs.base() == shared_base, &quot;should match&quot;);
 300     } else {
</pre>
<hr />
<pre>
 381 
 382     log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 383                   p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 384 
 385     log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 386                   CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 387 
 388     assert(_shared_rs.end() == tmp_class_space.base() &amp;&amp;
 389            is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &amp;&amp;
 390            is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &amp;&amp;
 391            is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), &quot;Sanity&quot;);
 392   }
 393 
 394 #endif
 395 
 396   init_shared_dump_space(&amp;_mc_region);
 397   SharedBaseAddress = (size_t)_shared_rs.base();
 398   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 399                 _shared_rs.size(), p2i(_shared_rs.base()));
 400 




 401   size_t symbol_rs_size = LP64_ONLY(3 * G) NOT_LP64(128 * M);
 402   _symbol_rs = ReservedSpace(symbol_rs_size);
 403   if (!_symbol_rs.is_reserved()) {
 404     vm_exit_during_initialization(&quot;Unable to reserve memory for symbols&quot;,
 405                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, symbol_rs_size));
 406   }
 407   _symbol_region.init(&amp;_symbol_rs, &amp;_symbol_vs);
 408 }
 409 
 410 // Called by universe_post_init()
 411 void MetaspaceShared::post_initialize(TRAPS) {
 412   if (UseSharedSpaces) {
 413     int size = FileMapInfo::get_number_of_shared_paths();
 414     if (size &gt; 0) {
 415       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 416       if (!DynamicDumpSharedSpaces) {
 417         FileMapInfo* info;
 418         if (FileMapInfo::dynamic_info() == NULL) {
 419           info = FileMapInfo::current_info();
 420         } else {
</pre>
<hr />
<pre>
1183 
1184 class VM_PopulateDumpSharedSpace: public VM_Operation {
1185 private:
1186   GrowableArray&lt;MemRegion&gt; *_closed_archive_heap_regions;
1187   GrowableArray&lt;MemRegion&gt; *_open_archive_heap_regions;
1188 
1189   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_closed_archive_heap_oopmaps;
1190   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_open_archive_heap_oopmaps;
1191 
1192   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1193   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1194   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1195                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1196   void dump_symbols();
1197   char* dump_read_only_tables();
1198   void print_class_stats();
1199   void print_region_stats(FileMapInfo* map_info);
1200   void print_bitmap_region_stats(size_t size, size_t total_size);
1201   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1202                                const char *name, size_t total_size);
<span class="line-modified">1203   void relocate_to_default_base_address(CHeapBitMap* ptrmap);</span>
1204 
1205 public:
1206 
1207   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1208   void doit();   // outline because gdb sucks
1209   bool allow_nested_vm_operations() const { return true; }
1210 }; // class VM_PopulateDumpSharedSpace
1211 
1212 class SortedSymbolClosure: public SymbolClosure {
1213   GrowableArray&lt;Symbol*&gt; _symbols;
1214   virtual void do_symbol(Symbol** sym) {
1215     assert((*sym)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);
1216     _symbols.append(*sym);
1217   }
1218   static int compare_symbols_by_address(Symbol** a, Symbol** b) {
1219     if (a[0] &lt; b[0]) {
1220       return -1;
1221     } else if (a[0] == b[0]) {
1222       ResourceMark rm;
1223       log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());
</pre>
<hr />
<pre>
1551   log_info(cds)(&quot;Number of classes %d&quot;, _global_klass_objects-&gt;length());
1552   {
1553     int num_type_array = 0, num_obj_array = 0, num_inst = 0;
1554     for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1555       Klass* k = _global_klass_objects-&gt;at(i);
1556       if (k-&gt;is_instance_klass()) {
1557         num_inst ++;
1558       } else if (k-&gt;is_objArray_klass()) {
1559         num_obj_array ++;
1560       } else {
1561         assert(k-&gt;is_typeArray_klass(), &quot;sanity&quot;);
1562         num_type_array ++;
1563       }
1564     }
1565     log_info(cds)(&quot;    instance classes   = %5d&quot;, num_inst);
1566     log_info(cds)(&quot;    obj array classes  = %5d&quot;, num_obj_array);
1567     log_info(cds)(&quot;    type array classes = %5d&quot;, num_type_array);
1568   }
1569 }
1570 
<span class="line-modified">1571 void VM_PopulateDumpSharedSpace::relocate_to_default_base_address(CHeapBitMap* ptrmap) {</span>
1572   intx addr_delta = MetaspaceShared::final_delta();
1573   if (addr_delta == 0) {
1574     ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());
1575   } else {
<span class="line-modified">1576     // We are not able to reserve space at Arguments::default_SharedBaseAddress() (due to ASLR).</span>
1577     // This means that the current content of the archive is based on a random
1578     // address. Let&#39;s relocate all the pointers, so that it can be mapped to
<span class="line-modified">1579     // Arguments::default_SharedBaseAddress() without runtime relocation.</span>
1580     //
1581     // Note: both the base and dynamic archive are written with
<span class="line-modified">1582     // FileMapHeader::_shared_base_address == Arguments::default_SharedBaseAddress()</span>
1583 
1584     // Patch all pointers that are marked by ptrmap within this region,
1585     // where we have just dumped all the metaspace data.
1586     address patch_base = (address)SharedBaseAddress;
1587     address patch_end  = (address)_ro_region.top();
1588     size_t size = patch_end - patch_base;
1589 
1590     // the current value of the pointers to be patched must be within this
1591     // range (i.e., must point to valid metaspace objects)
1592     address valid_old_base = patch_base;
1593     address valid_old_end  = patch_end;
1594 
1595     // after patching, the pointers must point inside this range
1596     // (the requested location of the archive, as mapped at runtime).
<span class="line-modified">1597     address valid_new_base = (address)Arguments::default_SharedBaseAddress();</span>
1598     address valid_new_end  = valid_new_base + size;
1599 
1600     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1601                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1602                    p2i(valid_new_base), p2i(valid_new_end));
1603 
1604     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1605                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1606     ptrmap-&gt;iterate(&amp;patcher);
1607     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1608   }
1609 }
1610 
1611 void VM_PopulateDumpSharedSpace::doit() {
1612   CHeapBitMap ptrmap;
1613   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1614 
1615   // We should no longer allocate anything from the metaspace, so that:
1616   //
1617   // (1) Metaspace::allocate might trigger GC if we have run out of
</pre>
<hr />
<pre>
1664   ArchiveCompactor::copy_and_compact();
1665 
1666   dump_symbols();
1667 
1668   // Dump supported java heap objects
1669   _closed_archive_heap_regions = NULL;
1670   _open_archive_heap_regions = NULL;
1671   dump_java_heap_objects();
1672 
1673   ArchiveCompactor::relocate_well_known_klasses();
1674 
1675   char* serialized_data = dump_read_only_tables();
1676   _ro_region.pack();
1677 
1678   // The vtable clones contain addresses of the current process.
1679   // We don&#39;t want to write these addresses into the archive. Same for i2i buffer.
1680   MetaspaceShared::zero_cpp_vtable_clones_for_writing();
1681   memset(MetaspaceShared::i2i_entry_code_buffers(), 0,
1682          MetaspaceShared::i2i_entry_code_buffers_size());
1683 
<span class="line-modified">1684   // relocate the data so that it can be mapped to Arguments::default_SharedBaseAddress()</span>
1685   // without runtime relocation.
<span class="line-modified">1686   relocate_to_default_base_address(&amp;ptrmap);</span>
1687 
1688   // Create and write the archive file that maps the shared spaces.
1689 
1690   FileMapInfo* mapinfo = new FileMapInfo(true);
1691   mapinfo-&gt;populate_header(os::vm_allocation_granularity());
1692   mapinfo-&gt;set_serialized_data(serialized_data);
1693   mapinfo-&gt;set_cloned_vtables(cloned_vtables);
1694   mapinfo-&gt;set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers(),
1695                                       MetaspaceShared::i2i_entry_code_buffers_size());
1696   mapinfo-&gt;open_for_write();
1697   MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps, _open_archive_heap_oopmaps);
1698   _total_closed_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1699                                         _closed_archive_heap_regions,
1700                                         _closed_archive_heap_oopmaps,
1701                                         MetaspaceShared::first_closed_archive_heap_region,
1702                                         MetaspaceShared::max_closed_archive_heap_region);
1703   _total_open_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1704                                         _open_archive_heap_regions,
1705                                         _open_archive_heap_oopmaps,
1706                                         MetaspaceShared::first_open_archive_heap_region,
1707                                         MetaspaceShared::max_open_archive_heap_region);
1708 
<span class="line-modified">1709   mapinfo-&gt;set_final_requested_base((char*)Arguments::default_SharedBaseAddress());</span>
1710   mapinfo-&gt;set_header_crc(mapinfo-&gt;compute_header_crc());
1711   mapinfo-&gt;write_header();
1712   print_region_stats(mapinfo);
1713   mapinfo-&gt;close();
1714 
1715   if (log_is_enabled(Info, cds)) {
1716     ArchiveCompactor::alloc_stats()-&gt;print_stats(int(_ro_region.used()), int(_rw_region.used()),
1717                                                  int(_mc_region.used()));
1718   }
1719 
1720   if (PrintSystemDictionaryAtExit) {
1721     SystemDictionary::print();
1722   }
1723 
1724   if (AllowArchivingWithJavaAgent) {
1725     warning(&quot;This archive was created with AllowArchivingWithJavaAgent. It should be used &quot;
1726             &quot;for testing purposes only and should not be used in a production environment&quot;);
1727   }
1728 
1729   // There may be other pending VM operations that operate on the InstanceKlasses,
</pre>
<hr />
<pre>
2145     result = map_archives(static_mapinfo, dynamic_mapinfo, true);
2146     if (result == MAP_ARCHIVE_MMAP_FAILURE) {
2147       // Mapping has failed (probably due to ASLR). Let&#39;s map at an address chosen
2148       // by the OS.
2149       log_info(cds)(&quot;Try to map archive(s) at an alternative address&quot;);
2150       result = map_archives(static_mapinfo, dynamic_mapinfo, false);
2151     }
2152   }
2153 
2154   if (result == MAP_ARCHIVE_SUCCESS) {
2155     bool dynamic_mapped = (dynamic_mapinfo != NULL &amp;&amp; dynamic_mapinfo-&gt;is_mapped());
2156     char* cds_base = static_mapinfo-&gt;mapped_base();
2157     char* cds_end =  dynamic_mapped ? dynamic_mapinfo-&gt;mapped_end() : static_mapinfo-&gt;mapped_end();
2158     set_shared_metaspace_range(cds_base, static_mapinfo-&gt;mapped_end(), cds_end);
2159     _relocation_delta = static_mapinfo-&gt;relocation_delta();
2160     if (dynamic_mapped) {
2161       FileMapInfo::set_shared_path_table(dynamic_mapinfo);
2162     } else {
2163       FileMapInfo::set_shared_path_table(static_mapinfo);
2164     }

2165   } else {
2166     set_shared_metaspace_range(NULL, NULL, NULL);
2167     UseSharedSpaces = false;
2168     FileMapInfo::fail_continue(&quot;Unable to map shared spaces&quot;);
2169     if (PrintSharedArchiveAndExit) {
2170       vm_exit_during_initialization(&quot;Unable to use shared archive.&quot;);
2171     }
2172   }
2173 
2174   if (static_mapinfo != NULL &amp;&amp; !static_mapinfo-&gt;is_mapped()) {
2175     delete static_mapinfo;
2176   }
2177   if (dynamic_mapinfo != NULL &amp;&amp; !dynamic_mapinfo-&gt;is_mapped()) {
2178     delete dynamic_mapinfo;
2179   }
2180 }
2181 
2182 FileMapInfo* MetaspaceShared::open_static_archive() {
2183   FileMapInfo* mapinfo = new FileMapInfo(true);
2184   if (!mapinfo-&gt;initialize()) {
</pre>
<hr />
<pre>
2192   if (DynamicDumpSharedSpaces) {
2193     return NULL;
2194   }
2195   if (Arguments::GetSharedDynamicArchivePath() == NULL) {
2196     return NULL;
2197   }
2198 
2199   FileMapInfo* mapinfo = new FileMapInfo(false);
2200   if (!mapinfo-&gt;initialize()) {
2201     delete(mapinfo);
2202     return NULL;
2203   }
2204   return mapinfo;
2205 }
2206 
2207 // use_requested_addr:
2208 //  true  = map at FileMapHeader::_requested_base_address
2209 //  false = map at an alternative address picked by OS.
2210 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
2211                                                bool use_requested_addr) {





2212   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 &amp;&amp; use_requested_addr) {
2213       // For product build only -- this is for benchmarking the cost of doing relocation.
2214       // For debug builds, the check is done below, after reserving the space, for better test coverage
2215       // (see comment below).
2216       log_info(cds)(&quot;ArchiveRelocationMode == 1: always map archive(s) at an alternative address&quot;);
2217       return MAP_ARCHIVE_MMAP_FAILURE;
2218     });
2219 
2220   if (ArchiveRelocationMode == 2 &amp;&amp; !use_requested_addr) {
2221     log_info(cds)(&quot;ArchiveRelocationMode == 2: never map archive(s) at an alternative address&quot;);
2222     return MAP_ARCHIVE_MMAP_FAILURE;
2223   };
2224 
2225   if (dynamic_mapinfo != NULL) {
2226     // Ensure that the OS won&#39;t be able to allocate new memory spaces between the two
2227     // archives, or else it would mess up the simple comparision in MetaspaceObj::is_shared().
2228     assert(static_mapinfo-&gt;mapping_end_offset() == dynamic_mapinfo-&gt;mapping_base_offset(), &quot;no gap&quot;);
2229   }
2230 
2231   ReservedSpace archive_space_rs, class_space_rs;
</pre>
<hr />
<pre>
2643         return false;
2644       }
2645     }
2646     _remapped_readwrite = true;
2647   }
2648   return true;
2649 }
2650 
2651 void MetaspaceShared::report_out_of_space(const char* name, size_t needed_bytes) {
2652   // This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.
2653   // On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes
2654   // or so.
2655   _mc_region.print_out_of_space_msg(name, needed_bytes);
2656   _rw_region.print_out_of_space_msg(name, needed_bytes);
2657   _ro_region.print_out_of_space_msg(name, needed_bytes);
2658 
2659   vm_exit_during_initialization(err_msg(&quot;Unable to allocate from &#39;%s&#39; region&quot;, name),
2660                                 &quot;Please reduce the number of shared classes.&quot;);
2661 }
2662 
<span class="line-modified">2663 // This is used to relocate the pointers so that the archive can be mapped at</span>
<span class="line-modified">2664 // Arguments::default_SharedBaseAddress() without runtime relocation.</span>
2665 intx MetaspaceShared::final_delta() {
<span class="line-modified">2666   return intx(Arguments::default_SharedBaseAddress())  // We want the archive to be mapped to here at runtime</span>
<span class="line-modified">2667        - intx(SharedBaseAddress);                      // .. but the archive is mapped at here at dump time</span>
2668 }
2669 
2670 void MetaspaceShared::print_on(outputStream* st) {
2671   if (UseSharedSpaces || DumpSharedSpaces) {
2672     st-&gt;print(&quot;CDS archive(s) mapped at: &quot;);
2673     address base;
2674     address top;
2675     if (UseSharedSpaces) { // Runtime
2676       base = (address)MetaspaceObj::shared_metaspace_base();
2677       address static_top = (address)_shared_metaspace_static_top;
2678       top = (address)MetaspaceObj::shared_metaspace_top();
2679       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(static_top), p2i(top));
2680     } else if (DumpSharedSpaces) { // Dump Time
2681       base = (address)_shared_rs.base();
2682       top = (address)_shared_rs.end();
2683       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(top));
2684     }
2685     st-&gt;print(&quot;size &quot; SIZE_FORMAT &quot;, &quot;, top - base);
2686     st-&gt;print(&quot;SharedBaseAddress: &quot; PTR_FORMAT &quot;, ArchiveRelocationMode: %d.&quot;, SharedBaseAddress, (int)ArchiveRelocationMode);
2687   } else {
</pre>
</td>
<td>
<hr />
<pre>
  71 #include &quot;utilities/bitMap.inline.hpp&quot;
  72 #include &quot;utilities/ostream.hpp&quot;
  73 #include &quot;utilities/defaultStream.hpp&quot;
  74 #include &quot;utilities/hashtable.inline.hpp&quot;
  75 #if INCLUDE_G1GC
  76 #include &quot;gc/g1/g1CollectedHeap.hpp&quot;
  77 #endif
  78 
  79 ReservedSpace MetaspaceShared::_shared_rs;
  80 VirtualSpace MetaspaceShared::_shared_vs;
  81 ReservedSpace MetaspaceShared::_symbol_rs;
  82 VirtualSpace MetaspaceShared::_symbol_vs;
  83 MetaspaceSharedStats MetaspaceShared::_stats;
  84 bool MetaspaceShared::_has_error_classes;
  85 bool MetaspaceShared::_archive_loading_failed = false;
  86 bool MetaspaceShared::_remapped_readwrite = false;
  87 address MetaspaceShared::_i2i_entry_code_buffers = NULL;
  88 size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;
  89 void* MetaspaceShared::_shared_metaspace_static_top = NULL;
  90 intx MetaspaceShared::_relocation_delta;
<span class="line-added">  91 char* MetaspaceShared::_requested_base_address;</span>
  92 
  93 // The CDS archive is divided into the following regions:
  94 //     mc  - misc code (the method entry trampolines, c++ vtables)
  95 //     rw  - read-write metadata
  96 //     ro  - read-only metadata and read-only tables
  97 //
  98 //     ca0 - closed archive heap space #0
  99 //     ca1 - closed archive heap space #1 (may be empty)
 100 //     oa0 - open archive heap space #0
 101 //     oa1 - open archive heap space #1 (may be empty)
 102 //
 103 // The mc, rw, and ro regions are linearly allocated, starting from
 104 // SharedBaseAddress, in the order of mc-&gt;rw-&gt;ro. The size of these 3 regions
 105 // are page-aligned, and there&#39;s no gap between any consecutive regions.
 106 //
 107 // These 3 regions are populated in the following steps:
 108 // [1] All classes are loaded in MetaspaceShared::preload_classes(). All metadata are
 109 //     temporarily allocated outside of the shared regions. Only the method entry
 110 //     trampolines are written into the mc region.
 111 // [2] C++ vtables are copied into the mc region.
</pre>
<hr />
<pre>
 224 
 225 void MetaspaceShared::pack_dump_space(DumpRegion* current, DumpRegion* next,
 226                                       ReservedSpace* rs) {
 227   current-&gt;pack(next);
 228 }
 229 
 230 char* MetaspaceShared::symbol_space_alloc(size_t num_bytes) {
 231   return _symbol_region.allocate(num_bytes);
 232 }
 233 
 234 char* MetaspaceShared::misc_code_space_alloc(size_t num_bytes) {
 235   return _mc_region.allocate(num_bytes);
 236 }
 237 
 238 char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {
 239   return _ro_region.allocate(num_bytes);
 240 }
 241 
 242 size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 243 
<span class="line-added"> 244 static bool shared_base_valid(char* shared_base) {</span>
 245 #ifdef _LP64
<span class="line-modified"> 246   return CompressedKlassPointers::is_valid_base((address)shared_base);</span>
<span class="line-modified"> 247 #else</span>
<span class="line-modified"> 248   return true;</span>
<span class="line-modified"> 249 #endif</span>
<span class="line-modified"> 250 }</span>
<span class="line-modified"> 251 </span>
<span class="line-modified"> 252 static bool shared_base_too_high(char* shared_base, size_t cds_total) {</span>
<span class="line-modified"> 253   if (SharedBaseAddress != 0 &amp;&amp; shared_base &lt; (char*)SharedBaseAddress) {</span>
<span class="line-modified"> 254     // SharedBaseAddress is very high (e.g., 0xffffffffffffff00) so</span>
<span class="line-added"> 255     // align_up(SharedBaseAddress, MetaspaceShared::reserved_space_alignment()) has wrapped around.</span>
<span class="line-added"> 256     return true;</span>
<span class="line-added"> 257   }</span>
<span class="line-added"> 258   if (max_uintx - uintx(shared_base) &lt; uintx(cds_total)) {</span>
<span class="line-added"> 259     // The end of the archive will wrap around</span>
<span class="line-added"> 260     return true;</span>
<span class="line-added"> 261   }</span>
<span class="line-added"> 262 </span>
<span class="line-added"> 263   return false;</span>
<span class="line-added"> 264 }</span>
<span class="line-added"> 265 </span>
<span class="line-added"> 266 static char* compute_shared_base(size_t cds_total) {</span>
<span class="line-added"> 267   char* shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());</span>
<span class="line-added"> 268   const char* err = NULL;</span>
<span class="line-added"> 269   if (shared_base_too_high(shared_base, cds_total)) {</span>
<span class="line-added"> 270     err = &quot;too high&quot;;</span>
<span class="line-added"> 271   } else if (!shared_base_valid(shared_base)) {</span>
<span class="line-added"> 272     err = &quot;invalid for this platform&quot;;</span>
<span class="line-added"> 273   }</span>
<span class="line-added"> 274   if (err) {</span>
<span class="line-added"> 275     log_warning(cds)(&quot;SharedBaseAddress (&quot; INTPTR_FORMAT &quot;) is %s. Reverted to &quot; INTPTR_FORMAT,</span>
<span class="line-added"> 276                      p2i((void*)SharedBaseAddress), err,</span>
<span class="line-added"> 277                      p2i((void*)Arguments::default_SharedBaseAddress()));</span>
 278     SharedBaseAddress = Arguments::default_SharedBaseAddress();
<span class="line-added"> 279     shared_base = (char*)align_up((char*)SharedBaseAddress, MetaspaceShared::reserved_space_alignment());</span>
 280   }
<span class="line-added"> 281   assert(!shared_base_too_high(shared_base, cds_total) &amp;&amp; shared_base_valid(shared_base), &quot;Sanity&quot;);</span>
<span class="line-added"> 282   return shared_base;</span>
 283 }

 284 
 285 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
 286   assert(DumpSharedSpaces, &quot;should be called for dump time only&quot;);
 287 




 288   const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();

 289 
 290 #ifdef _LP64

 291   // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
 292   //  will use that to house both the archives and the ccs. See below for
 293   //  details.
 294   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
 295   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
 296 #else
 297   // We don&#39;t support archives larger than 256MB on 32-bit due to limited
 298   //  virtual address space.
 299   size_t cds_total = align_down(256*M, reserve_alignment);
 300 #endif
 301 
<span class="line-added"> 302   char* shared_base = compute_shared_base(cds_total);</span>
<span class="line-added"> 303   _requested_base_address = shared_base;</span>
<span class="line-added"> 304 </span>
 305   // Whether to use SharedBaseAddress as attach address.
 306   bool use_requested_base = true;
 307 
 308   if (shared_base == NULL) {
 309     use_requested_base = false;
 310   }
 311 
 312   if (ArchiveRelocationMode == 1) {
 313     log_info(cds)(&quot;ArchiveRelocationMode == 1: always allocate class space at an alternative address&quot;);
 314     use_requested_base = false;
 315   }
 316 
 317   // First try to reserve the space at the specified SharedBaseAddress.
 318   assert(!_shared_rs.is_reserved(), &quot;must be&quot;);
 319   if (use_requested_base) {
 320     _shared_rs = ReservedSpace(cds_total, reserve_alignment,
 321                                false /* large */, (char*)shared_base);
 322     if (_shared_rs.is_reserved()) {
 323       assert(_shared_rs.base() == shared_base, &quot;should match&quot;);
 324     } else {
</pre>
<hr />
<pre>
 405 
 406     log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 407                   p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 408 
 409     log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 410                   CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 411 
 412     assert(_shared_rs.end() == tmp_class_space.base() &amp;&amp;
 413            is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &amp;&amp;
 414            is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &amp;&amp;
 415            is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), &quot;Sanity&quot;);
 416   }
 417 
 418 #endif
 419 
 420   init_shared_dump_space(&amp;_mc_region);
 421   SharedBaseAddress = (size_t)_shared_rs.base();
 422   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 423                 _shared_rs.size(), p2i(_shared_rs.base()));
 424 
<span class="line-added"> 425   // We don&#39;t want any valid object to be at the very bottom of the archive.</span>
<span class="line-added"> 426   // See ArchivePtrMarker::mark_pointer().</span>
<span class="line-added"> 427   MetaspaceShared::misc_code_space_alloc(16);</span>
<span class="line-added"> 428 </span>
 429   size_t symbol_rs_size = LP64_ONLY(3 * G) NOT_LP64(128 * M);
 430   _symbol_rs = ReservedSpace(symbol_rs_size);
 431   if (!_symbol_rs.is_reserved()) {
 432     vm_exit_during_initialization(&quot;Unable to reserve memory for symbols&quot;,
 433                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, symbol_rs_size));
 434   }
 435   _symbol_region.init(&amp;_symbol_rs, &amp;_symbol_vs);
 436 }
 437 
 438 // Called by universe_post_init()
 439 void MetaspaceShared::post_initialize(TRAPS) {
 440   if (UseSharedSpaces) {
 441     int size = FileMapInfo::get_number_of_shared_paths();
 442     if (size &gt; 0) {
 443       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 444       if (!DynamicDumpSharedSpaces) {
 445         FileMapInfo* info;
 446         if (FileMapInfo::dynamic_info() == NULL) {
 447           info = FileMapInfo::current_info();
 448         } else {
</pre>
<hr />
<pre>
1211 
1212 class VM_PopulateDumpSharedSpace: public VM_Operation {
1213 private:
1214   GrowableArray&lt;MemRegion&gt; *_closed_archive_heap_regions;
1215   GrowableArray&lt;MemRegion&gt; *_open_archive_heap_regions;
1216 
1217   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_closed_archive_heap_oopmaps;
1218   GrowableArray&lt;ArchiveHeapOopmapInfo&gt; *_open_archive_heap_oopmaps;
1219 
1220   void dump_java_heap_objects() NOT_CDS_JAVA_HEAP_RETURN;
1221   void dump_archive_heap_oopmaps() NOT_CDS_JAVA_HEAP_RETURN;
1222   void dump_archive_heap_oopmaps(GrowableArray&lt;MemRegion&gt;* regions,
1223                                  GrowableArray&lt;ArchiveHeapOopmapInfo&gt;* oopmaps);
1224   void dump_symbols();
1225   char* dump_read_only_tables();
1226   void print_class_stats();
1227   void print_region_stats(FileMapInfo* map_info);
1228   void print_bitmap_region_stats(size_t size, size_t total_size);
1229   void print_heap_region_stats(GrowableArray&lt;MemRegion&gt; *heap_mem,
1230                                const char *name, size_t total_size);
<span class="line-modified">1231   void relocate_to_requested_base_address(CHeapBitMap* ptrmap);</span>
1232 
1233 public:
1234 
1235   VMOp_Type type() const { return VMOp_PopulateDumpSharedSpace; }
1236   void doit();   // outline because gdb sucks
1237   bool allow_nested_vm_operations() const { return true; }
1238 }; // class VM_PopulateDumpSharedSpace
1239 
1240 class SortedSymbolClosure: public SymbolClosure {
1241   GrowableArray&lt;Symbol*&gt; _symbols;
1242   virtual void do_symbol(Symbol** sym) {
1243     assert((*sym)-&gt;is_permanent(), &quot;archived symbols must be permanent&quot;);
1244     _symbols.append(*sym);
1245   }
1246   static int compare_symbols_by_address(Symbol** a, Symbol** b) {
1247     if (a[0] &lt; b[0]) {
1248       return -1;
1249     } else if (a[0] == b[0]) {
1250       ResourceMark rm;
1251       log_warning(cds)(&quot;Duplicated symbol %s unexpected&quot;, (*a)-&gt;as_C_string());
</pre>
<hr />
<pre>
1579   log_info(cds)(&quot;Number of classes %d&quot;, _global_klass_objects-&gt;length());
1580   {
1581     int num_type_array = 0, num_obj_array = 0, num_inst = 0;
1582     for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1583       Klass* k = _global_klass_objects-&gt;at(i);
1584       if (k-&gt;is_instance_klass()) {
1585         num_inst ++;
1586       } else if (k-&gt;is_objArray_klass()) {
1587         num_obj_array ++;
1588       } else {
1589         assert(k-&gt;is_typeArray_klass(), &quot;sanity&quot;);
1590         num_type_array ++;
1591       }
1592     }
1593     log_info(cds)(&quot;    instance classes   = %5d&quot;, num_inst);
1594     log_info(cds)(&quot;    obj array classes  = %5d&quot;, num_obj_array);
1595     log_info(cds)(&quot;    type array classes = %5d&quot;, num_type_array);
1596   }
1597 }
1598 
<span class="line-modified">1599 void VM_PopulateDumpSharedSpace::relocate_to_requested_base_address(CHeapBitMap* ptrmap) {</span>
1600   intx addr_delta = MetaspaceShared::final_delta();
1601   if (addr_delta == 0) {
1602     ArchivePtrMarker::compact((address)SharedBaseAddress, (address)_ro_region.top());
1603   } else {
<span class="line-modified">1604     // We are not able to reserve space at MetaspaceShared::requested_base_address() (due to ASLR).</span>
1605     // This means that the current content of the archive is based on a random
1606     // address. Let&#39;s relocate all the pointers, so that it can be mapped to
<span class="line-modified">1607     // MetaspaceShared::requested_base_address() without runtime relocation.</span>
1608     //
1609     // Note: both the base and dynamic archive are written with
<span class="line-modified">1610     // FileMapHeader::_requested_base_address == MetaspaceShared::requested_base_address()</span>
1611 
1612     // Patch all pointers that are marked by ptrmap within this region,
1613     // where we have just dumped all the metaspace data.
1614     address patch_base = (address)SharedBaseAddress;
1615     address patch_end  = (address)_ro_region.top();
1616     size_t size = patch_end - patch_base;
1617 
1618     // the current value of the pointers to be patched must be within this
1619     // range (i.e., must point to valid metaspace objects)
1620     address valid_old_base = patch_base;
1621     address valid_old_end  = patch_end;
1622 
1623     // after patching, the pointers must point inside this range
1624     // (the requested location of the archive, as mapped at runtime).
<span class="line-modified">1625     address valid_new_base = (address)MetaspaceShared::requested_base_address();</span>
1626     address valid_new_end  = valid_new_base + size;
1627 
1628     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1629                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1630                    p2i(valid_new_base), p2i(valid_new_end));
1631 
1632     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1633                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1634     ptrmap-&gt;iterate(&amp;patcher);
1635     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1636   }
1637 }
1638 
1639 void VM_PopulateDumpSharedSpace::doit() {
1640   CHeapBitMap ptrmap;
1641   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1642 
1643   // We should no longer allocate anything from the metaspace, so that:
1644   //
1645   // (1) Metaspace::allocate might trigger GC if we have run out of
</pre>
<hr />
<pre>
1692   ArchiveCompactor::copy_and_compact();
1693 
1694   dump_symbols();
1695 
1696   // Dump supported java heap objects
1697   _closed_archive_heap_regions = NULL;
1698   _open_archive_heap_regions = NULL;
1699   dump_java_heap_objects();
1700 
1701   ArchiveCompactor::relocate_well_known_klasses();
1702 
1703   char* serialized_data = dump_read_only_tables();
1704   _ro_region.pack();
1705 
1706   // The vtable clones contain addresses of the current process.
1707   // We don&#39;t want to write these addresses into the archive. Same for i2i buffer.
1708   MetaspaceShared::zero_cpp_vtable_clones_for_writing();
1709   memset(MetaspaceShared::i2i_entry_code_buffers(), 0,
1710          MetaspaceShared::i2i_entry_code_buffers_size());
1711 
<span class="line-modified">1712   // relocate the data so that it can be mapped to MetaspaceShared::requested_base_address()</span>
1713   // without runtime relocation.
<span class="line-modified">1714   relocate_to_requested_base_address(&amp;ptrmap);</span>
1715 
1716   // Create and write the archive file that maps the shared spaces.
1717 
1718   FileMapInfo* mapinfo = new FileMapInfo(true);
1719   mapinfo-&gt;populate_header(os::vm_allocation_granularity());
1720   mapinfo-&gt;set_serialized_data(serialized_data);
1721   mapinfo-&gt;set_cloned_vtables(cloned_vtables);
1722   mapinfo-&gt;set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers(),
1723                                       MetaspaceShared::i2i_entry_code_buffers_size());
1724   mapinfo-&gt;open_for_write();
1725   MetaspaceShared::write_core_archive_regions(mapinfo, _closed_archive_heap_oopmaps, _open_archive_heap_oopmaps);
1726   _total_closed_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1727                                         _closed_archive_heap_regions,
1728                                         _closed_archive_heap_oopmaps,
1729                                         MetaspaceShared::first_closed_archive_heap_region,
1730                                         MetaspaceShared::max_closed_archive_heap_region);
1731   _total_open_archive_region_size = mapinfo-&gt;write_archive_heap_regions(
1732                                         _open_archive_heap_regions,
1733                                         _open_archive_heap_oopmaps,
1734                                         MetaspaceShared::first_open_archive_heap_region,
1735                                         MetaspaceShared::max_open_archive_heap_region);
1736 
<span class="line-modified">1737   mapinfo-&gt;set_final_requested_base((char*)MetaspaceShared::requested_base_address());</span>
1738   mapinfo-&gt;set_header_crc(mapinfo-&gt;compute_header_crc());
1739   mapinfo-&gt;write_header();
1740   print_region_stats(mapinfo);
1741   mapinfo-&gt;close();
1742 
1743   if (log_is_enabled(Info, cds)) {
1744     ArchiveCompactor::alloc_stats()-&gt;print_stats(int(_ro_region.used()), int(_rw_region.used()),
1745                                                  int(_mc_region.used()));
1746   }
1747 
1748   if (PrintSystemDictionaryAtExit) {
1749     SystemDictionary::print();
1750   }
1751 
1752   if (AllowArchivingWithJavaAgent) {
1753     warning(&quot;This archive was created with AllowArchivingWithJavaAgent. It should be used &quot;
1754             &quot;for testing purposes only and should not be used in a production environment&quot;);
1755   }
1756 
1757   // There may be other pending VM operations that operate on the InstanceKlasses,
</pre>
<hr />
<pre>
2173     result = map_archives(static_mapinfo, dynamic_mapinfo, true);
2174     if (result == MAP_ARCHIVE_MMAP_FAILURE) {
2175       // Mapping has failed (probably due to ASLR). Let&#39;s map at an address chosen
2176       // by the OS.
2177       log_info(cds)(&quot;Try to map archive(s) at an alternative address&quot;);
2178       result = map_archives(static_mapinfo, dynamic_mapinfo, false);
2179     }
2180   }
2181 
2182   if (result == MAP_ARCHIVE_SUCCESS) {
2183     bool dynamic_mapped = (dynamic_mapinfo != NULL &amp;&amp; dynamic_mapinfo-&gt;is_mapped());
2184     char* cds_base = static_mapinfo-&gt;mapped_base();
2185     char* cds_end =  dynamic_mapped ? dynamic_mapinfo-&gt;mapped_end() : static_mapinfo-&gt;mapped_end();
2186     set_shared_metaspace_range(cds_base, static_mapinfo-&gt;mapped_end(), cds_end);
2187     _relocation_delta = static_mapinfo-&gt;relocation_delta();
2188     if (dynamic_mapped) {
2189       FileMapInfo::set_shared_path_table(dynamic_mapinfo);
2190     } else {
2191       FileMapInfo::set_shared_path_table(static_mapinfo);
2192     }
<span class="line-added">2193     _requested_base_address = static_mapinfo-&gt;requested_base_address();</span>
2194   } else {
2195     set_shared_metaspace_range(NULL, NULL, NULL);
2196     UseSharedSpaces = false;
2197     FileMapInfo::fail_continue(&quot;Unable to map shared spaces&quot;);
2198     if (PrintSharedArchiveAndExit) {
2199       vm_exit_during_initialization(&quot;Unable to use shared archive.&quot;);
2200     }
2201   }
2202 
2203   if (static_mapinfo != NULL &amp;&amp; !static_mapinfo-&gt;is_mapped()) {
2204     delete static_mapinfo;
2205   }
2206   if (dynamic_mapinfo != NULL &amp;&amp; !dynamic_mapinfo-&gt;is_mapped()) {
2207     delete dynamic_mapinfo;
2208   }
2209 }
2210 
2211 FileMapInfo* MetaspaceShared::open_static_archive() {
2212   FileMapInfo* mapinfo = new FileMapInfo(true);
2213   if (!mapinfo-&gt;initialize()) {
</pre>
<hr />
<pre>
2221   if (DynamicDumpSharedSpaces) {
2222     return NULL;
2223   }
2224   if (Arguments::GetSharedDynamicArchivePath() == NULL) {
2225     return NULL;
2226   }
2227 
2228   FileMapInfo* mapinfo = new FileMapInfo(false);
2229   if (!mapinfo-&gt;initialize()) {
2230     delete(mapinfo);
2231     return NULL;
2232   }
2233   return mapinfo;
2234 }
2235 
2236 // use_requested_addr:
2237 //  true  = map at FileMapHeader::_requested_base_address
2238 //  false = map at an alternative address picked by OS.
2239 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
2240                                                bool use_requested_addr) {
<span class="line-added">2241   if (use_requested_addr &amp;&amp; static_mapinfo-&gt;requested_base_address() == NULL) {</span>
<span class="line-added">2242     log_info(cds)(&quot;Archive(s) were created with -XX:SharedBaseAddress=0. Always map at os-selected address.&quot;);</span>
<span class="line-added">2243     return MAP_ARCHIVE_MMAP_FAILURE;</span>
<span class="line-added">2244   }</span>
<span class="line-added">2245 </span>
2246   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 &amp;&amp; use_requested_addr) {
2247       // For product build only -- this is for benchmarking the cost of doing relocation.
2248       // For debug builds, the check is done below, after reserving the space, for better test coverage
2249       // (see comment below).
2250       log_info(cds)(&quot;ArchiveRelocationMode == 1: always map archive(s) at an alternative address&quot;);
2251       return MAP_ARCHIVE_MMAP_FAILURE;
2252     });
2253 
2254   if (ArchiveRelocationMode == 2 &amp;&amp; !use_requested_addr) {
2255     log_info(cds)(&quot;ArchiveRelocationMode == 2: never map archive(s) at an alternative address&quot;);
2256     return MAP_ARCHIVE_MMAP_FAILURE;
2257   };
2258 
2259   if (dynamic_mapinfo != NULL) {
2260     // Ensure that the OS won&#39;t be able to allocate new memory spaces between the two
2261     // archives, or else it would mess up the simple comparision in MetaspaceObj::is_shared().
2262     assert(static_mapinfo-&gt;mapping_end_offset() == dynamic_mapinfo-&gt;mapping_base_offset(), &quot;no gap&quot;);
2263   }
2264 
2265   ReservedSpace archive_space_rs, class_space_rs;
</pre>
<hr />
<pre>
2677         return false;
2678       }
2679     }
2680     _remapped_readwrite = true;
2681   }
2682   return true;
2683 }
2684 
2685 void MetaspaceShared::report_out_of_space(const char* name, size_t needed_bytes) {
2686   // This is highly unlikely to happen on 64-bits because we have reserved a 4GB space.
2687   // On 32-bit we reserve only 256MB so you could run out of space with 100,000 classes
2688   // or so.
2689   _mc_region.print_out_of_space_msg(name, needed_bytes);
2690   _rw_region.print_out_of_space_msg(name, needed_bytes);
2691   _ro_region.print_out_of_space_msg(name, needed_bytes);
2692 
2693   vm_exit_during_initialization(err_msg(&quot;Unable to allocate from &#39;%s&#39; region&quot;, name),
2694                                 &quot;Please reduce the number of shared classes.&quot;);
2695 }
2696 
<span class="line-modified">2697 // This is used to relocate the pointers so that the base archive can be mapped at</span>
<span class="line-modified">2698 // MetaspaceShared::requested_base_address() without runtime relocation.</span>
2699 intx MetaspaceShared::final_delta() {
<span class="line-modified">2700   return intx(MetaspaceShared::requested_base_address())  // We want the base archive to be mapped to here at runtime</span>
<span class="line-modified">2701        - intx(SharedBaseAddress);                         // .. but the base archive is mapped at here at dump time</span>
2702 }
2703 
2704 void MetaspaceShared::print_on(outputStream* st) {
2705   if (UseSharedSpaces || DumpSharedSpaces) {
2706     st-&gt;print(&quot;CDS archive(s) mapped at: &quot;);
2707     address base;
2708     address top;
2709     if (UseSharedSpaces) { // Runtime
2710       base = (address)MetaspaceObj::shared_metaspace_base();
2711       address static_top = (address)_shared_metaspace_static_top;
2712       top = (address)MetaspaceObj::shared_metaspace_top();
2713       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(static_top), p2i(top));
2714     } else if (DumpSharedSpaces) { // Dump Time
2715       base = (address)_shared_rs.base();
2716       top = (address)_shared_rs.end();
2717       st-&gt;print(&quot;[&quot; PTR_FORMAT &quot;-&quot; PTR_FORMAT &quot;), &quot;, p2i(base), p2i(top));
2718     }
2719     st-&gt;print(&quot;size &quot; SIZE_FORMAT &quot;, &quot;, top - base);
2720     st-&gt;print(&quot;SharedBaseAddress: &quot; PTR_FORMAT &quot;, ArchiveRelocationMode: %d.&quot;, SharedBaseAddress, (int)ArchiveRelocationMode);
2721   } else {
</pre>
</td>
</tr>
</table>
<center><a href="metaspace.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspaceShared.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>