<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/s390/methodHandles_s390.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2016, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2016, 2017, SAP SE. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #include &quot;precompiled.hpp&quot;
 27 #include &quot;jvm.h&quot;
 28 #include &quot;asm/macroAssembler.inline.hpp&quot;
 29 #include &quot;classfile/javaClasses.inline.hpp&quot;
 30 #include &quot;interpreter/interpreter.hpp&quot;
 31 #include &quot;logging/log.hpp&quot;
 32 #include &quot;memory/allocation.inline.hpp&quot;
 33 #include &quot;memory/resourceArea.hpp&quot;
 34 #include &quot;prims/methodHandles.hpp&quot;
 35 #include &quot;runtime/frame.inline.hpp&quot;
 36 #include &quot;utilities/preserveException.hpp&quot;
 37 
 38 #ifdef PRODUCT
 39 #define __ _masm-&gt;
 40 #define BLOCK_COMMENT(str) /* nothing */
 41 #else
 42 #define __ (Verbose ? (_masm-&gt;block_comment(FILE_AND_LINE),_masm):_masm)-&gt;
 43 #define BLOCK_COMMENT(str) __ block_comment(str)
 44 #endif
 45 
 46 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
 47 
 48 // Workaround for C++ overloading nastiness on &#39;0&#39; for RegisterOrConstant.
 49 static RegisterOrConstant constant(int value) {
 50   return RegisterOrConstant(value);
 51 }
 52 
 53 void MethodHandles::load_klass_from_Class(MacroAssembler* _masm, Register klass_reg,
 54                                           Register temp_reg, Register temp2_reg) {
 55   if (VerifyMethodHandles) {
 56     verify_klass(_masm, klass_reg, SystemDictionary::WK_KLASS_ENUM_NAME(java_lang_Class),
 57                  temp_reg, temp2_reg, &quot;MH argument is a Class&quot;);
 58   }
 59   __ z_lg(klass_reg, Address(klass_reg, java_lang_Class::klass_offset_in_bytes()));
 60 }
 61 
 62 
 63 #ifdef ASSERT
 64 static int check_nonzero(const char* xname, int x) {
 65   assert(x != 0, &quot;%s should be nonzero&quot;, xname);
 66   return x;
 67 }
 68 #define NONZERO(x) check_nonzero(#x, x)
 69 #else
 70 #define NONZERO(x) (x)
 71 #endif
 72 
 73 #ifdef ASSERT
 74 void MethodHandles::verify_klass(MacroAssembler* _masm,
 75                                  Register obj_reg, SystemDictionary::WKID klass_id,
 76                                  Register temp_reg, Register temp2_reg,
 77                                  const char* error_message) {
 78 
 79   InstanceKlass** klass_addr = SystemDictionary::well_known_klass_addr(klass_id);
 80   Klass* klass = SystemDictionary::well_known_klass(klass_id);
 81 
 82   assert(temp_reg != Z_R0 &amp;&amp; // Is used as base register!
 83          temp_reg != noreg &amp;&amp; temp2_reg != noreg, &quot;need valid registers!&quot;);
 84 
 85   NearLabel L_ok, L_bad;
 86 
 87   BLOCK_COMMENT(&quot;verify_klass {&quot;);
 88 
 89   __ verify_oop(obj_reg, FILE_AND_LINE);
 90   __ compareU64_and_branch(obj_reg, (intptr_t)0L, Assembler::bcondEqual, L_bad);
 91   __ load_klass(temp_reg, obj_reg);
 92   // klass_addr is a klass in allstatic SystemDictionaryHandles. Can&#39;t get GCed.
 93   __ load_const_optimized(temp2_reg, (address)klass_addr);
 94   __ z_lg(temp2_reg, Address(temp2_reg));
 95   __ compareU64_and_branch(temp_reg, temp2_reg, Assembler::bcondEqual, L_ok);
 96 
 97   intptr_t super_check_offset = klass-&gt;super_check_offset();
 98   __ z_lg(temp_reg, Address(temp_reg, super_check_offset));
 99   __ compareU64_and_branch(temp_reg, temp2_reg, Assembler::bcondEqual, L_ok);
100   __ BIND(L_bad);
101   __ stop(error_message);
102   __ BIND(L_ok);
103 
104   BLOCK_COMMENT(&quot;} verify_klass&quot;);
105 }
106 
107 void MethodHandles::verify_ref_kind(MacroAssembler* _masm, int ref_kind,
108                                     Register member_reg, Register temp  ) {
109   NearLabel L;
110   BLOCK_COMMENT(&quot;verify_ref_kind {&quot;);
111 
112   __ z_llgf(temp,
113             Address(member_reg,
114                     NONZERO(java_lang_invoke_MemberName::flags_offset_in_bytes())));
115   __ z_srl(temp,  java_lang_invoke_MemberName::MN_REFERENCE_KIND_SHIFT);
116   __ z_nilf(temp, java_lang_invoke_MemberName::MN_REFERENCE_KIND_MASK);
117   __ compare32_and_branch(temp, constant(ref_kind), Assembler::bcondEqual, L);
118 
119   {
120     char *buf = NEW_C_HEAP_ARRAY(char, 100, mtInternal);
121 
122     jio_snprintf(buf, 100, &quot;verify_ref_kind expected %x&quot;, ref_kind);
123     if (ref_kind == JVM_REF_invokeVirtual || ref_kind == JVM_REF_invokeSpecial) {
124       // Could do this for all ref_kinds, but would explode assembly code size.
125       trace_method_handle(_masm, buf);
126     }
127     __ stop(buf);
128   }
129 
130   BLOCK_COMMENT(&quot;} verify_ref_kind&quot;);
131 
132   __ bind(L);
133 }
134 #endif // ASSERT
135 
136 void MethodHandles::jump_from_method_handle(MacroAssembler* _masm, Register method, Register target,
137                                             Register temp, bool for_compiler_entry) {
138   assert(method == Z_method, &quot;interpreter calling convention&quot;);
139   __ verify_method_ptr(method);
140 
141   assert(target != method, &quot;don &#39;t you kill the method reg!&quot;);
142 
143   Label L_no_such_method;
144 
145   if (!for_compiler_entry &amp;&amp; JvmtiExport::can_post_interpreter_events()) {
146     // JVMTI events, such as single-stepping, are implemented partly
147     // by avoiding running compiled code in threads for which the
148     // event is enabled. Check here for interp_only_mode if these
149     // events CAN be enabled.
150     __ verify_thread();
151 
152     Label run_compiled_code;
153 
154     __ load_and_test_int(temp, Address(Z_thread, JavaThread::interp_only_mode_offset()));
155     __ z_bre(run_compiled_code);
156 
157     // Null method test is replicated below in compiled case,
158     // it might be able to address across the verify_thread().
159     __ z_ltgr(temp, method);
160     __ z_bre(L_no_such_method);
161 
162     __ z_lg(target, Address(method, Method::interpreter_entry_offset()));
163     __ z_br(target);
164 
165     __ bind(run_compiled_code);
166   }
167 
168   // Compiled case, either static or fall-through from runtime conditional.
169   __ z_ltgr(temp, method);
170   __ z_bre(L_no_such_method);
171 
172   ByteSize offset = for_compiler_entry ?
173                        Method::from_compiled_offset() : Method::from_interpreted_offset();
174   Address method_from(method, offset);
175 
176   __ z_lg(target, method_from);
177   __ z_br(target);
178 
179   __ bind(L_no_such_method);
180   assert(StubRoutines::throw_AbstractMethodError_entry() != NULL, &quot;not yet generated!&quot;);
181   __ load_const_optimized(target, StubRoutines::throw_AbstractMethodError_entry());
182   __ z_br(target);
183 }
184 
185 void MethodHandles::jump_to_lambda_form(MacroAssembler* _masm,
186                                         Register recv, Register method_temp,
187                                         Register temp2, Register temp3,
188                                         bool for_compiler_entry) {
189 
190   // This is the initial entry point of a lazy method handle.
191   // After type checking, it picks up the invoker from the LambdaForm.
192   assert_different_registers(recv, method_temp, temp2, temp3);
193   assert(method_temp == Z_method, &quot;required register for loading method&quot;);
194 
195   BLOCK_COMMENT(&quot;jump_to_lambda_form {&quot;);
196 
197   // Load the invoker, as MH -&gt; MH.form -&gt; LF.vmentry
198   __ verify_oop(recv, FILE_AND_LINE);
199   __ load_heap_oop(method_temp,
200                    Address(recv,
201                            NONZERO(java_lang_invoke_MethodHandle::form_offset_in_bytes())),
202                    noreg, noreg, IS_NOT_NULL);
203   __ verify_oop(method_temp, FILE_AND_LINE);
204   __ load_heap_oop(method_temp,
205                    Address(method_temp,
206                            NONZERO(java_lang_invoke_LambdaForm::vmentry_offset_in_bytes())),
207                    noreg, noreg, IS_NOT_NULL);
208   __ verify_oop(method_temp, FILE_AND_LINE);
209   __ load_heap_oop(method_temp,
210                    Address(method_temp,
211                            NONZERO(java_lang_invoke_MemberName::method_offset_in_bytes())),
212                    noreg, noreg, IS_NOT_NULL);
213   __ verify_oop(method_temp, FILE_AND_LINE);
214   __ z_lg(method_temp,
215           Address(method_temp,
216                   NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset_in_bytes())));
217 
218   if (VerifyMethodHandles &amp;&amp; !for_compiler_entry) {
219     // Make sure recv is already on stack.
220     NearLabel L;
221     Address paramSize(temp2, ConstMethod::size_of_parameters_offset());
222 
223     __ z_lg(temp2, Address(method_temp, Method::const_offset()));
224     __ load_sized_value(temp2, paramSize, sizeof(u2), /*is_signed*/ false);
225     // if (temp2 != recv) stop
226     __ z_lg(temp2, __ argument_address(temp2, temp2, 0));
227     __ compare64_and_branch(temp2, recv, Assembler::bcondEqual, L);
228     __ stop(&quot;receiver not on stack&quot;);
229     __ BIND(L);
230   }
231 
232   jump_from_method_handle(_masm, method_temp, temp2, Z_R0, for_compiler_entry);
233 
234   BLOCK_COMMENT(&quot;} jump_to_lambda_form&quot;);
235 }
236 
237 // code generation
238 address MethodHandles::generate_method_handle_interpreter_entry(MacroAssembler* _masm,
239                                                                 vmIntrinsics::ID iid) {
240   const bool not_for_compiler_entry = false;  // This is the interpreter entry.
241   assert(is_signature_polymorphic(iid), &quot;expected invoke iid&quot;);
242 
243   if (iid == vmIntrinsics::_invokeGeneric || iid == vmIntrinsics::_compiledLambdaForm) {
244     // Perhaps surprisingly, the symbolic references visible to Java
245     // are not directly used. They are linked to Java-generated
246     // adapters via MethodHandleNatives.linkMethod. They all allow an
247     // appendix argument.
248     __ should_not_reach_here();           // Empty stubs make SG sick.
249     return NULL;
250   }
251 
252   // Z_R10: sender SP (must preserve; see prepare_to_jump_from_interprted)
253   // Z_method: method
254   // Z_ARG1 (Gargs): incoming argument list (must preserve)
255   Register Z_R4_param_size = Z_R4;   // size of parameters
256   address code_start = __ pc();
257 
258   // Here is where control starts out:
259   __ align(CodeEntryAlignment);
260 
261   address entry_point = __ pc();
262 
263   if (VerifyMethodHandles) {
264     Label L;
265     BLOCK_COMMENT(&quot;verify_intrinsic_id {&quot;);
266 
267     // Supplement to 8139891: _intrinsic_id exceeded 1-byte size limit.
268     if (Method::intrinsic_id_size_in_bytes() == 1) {
269       __ z_cli(Address(Z_method, Method::intrinsic_id_offset_in_bytes()), (int)iid);
270     } else {
271       assert(Method::intrinsic_id_size_in_bytes() == 2, &quot;size error: check Method::_intrinsic_id&quot;);
272       __ z_lh(Z_R0_scratch, Address(Z_method, Method::intrinsic_id_offset_in_bytes()));
273       __ z_chi(Z_R0_scratch, (int)iid);
274     }
275     __ z_bre(L);
276 
277     if (iid == vmIntrinsics::_linkToVirtual || iid == vmIntrinsics::_linkToSpecial) {
278       // Could do this for all kinds, but would explode assembly code size.
279       trace_method_handle(_masm, &quot;bad Method::intrinsic_id&quot;);
280     }
281 
282     __ stop(&quot;bad Method::intrinsic_id&quot;);
283     __ bind(L);
284 
285     BLOCK_COMMENT(&quot;} verify_intrinsic_id&quot;);
286   }
287 
288   // First task: Find out how big the argument list is.
289   Address Z_R4_first_arg_addr;
290   int ref_kind = signature_polymorphic_intrinsic_ref_kind(iid);
291 
292   assert(ref_kind != 0 || iid == vmIntrinsics::_invokeBasic,
293          &quot;must be _invokeBasic or a linkTo intrinsic&quot;);
294 
295   if (ref_kind == 0 || MethodHandles::ref_kind_has_receiver(ref_kind)) {
296      Address paramSize(Z_R1_scratch, ConstMethod::size_of_parameters_offset());
297 
298     __ z_lg(Z_R1_scratch, Address(Z_method, Method::const_offset()));
299     __ load_sized_value(Z_R4_param_size, paramSize, sizeof(u2), /*is_signed*/ false);
300     Z_R4_first_arg_addr = __ argument_address(Z_R4_param_size, Z_R4_param_size, 0);
301   } else {
302     DEBUG_ONLY(Z_R4_param_size = noreg);
303   }
304 
305   Register Z_mh = noreg;
306   if (!is_signature_polymorphic_static(iid)) {
307     Z_mh = Z_ARG4;
308     __ z_lg(Z_mh, Z_R4_first_arg_addr);
309     DEBUG_ONLY(Z_R4_param_size = noreg);
310   }
311 
312   // Z_R4_first_arg_addr is live!
313 
314   trace_method_handle_interpreter_entry(_masm, iid);
315 
316   if (iid == vmIntrinsics::_invokeBasic) {
317     __ pc(); // just for the block comment
318     generate_method_handle_dispatch(_masm, iid, Z_mh, noreg, not_for_compiler_entry);
319   } else {
320     // Adjust argument list by popping the trailing MemberName argument.
321     Register Z_recv = noreg;
322 
323     if (MethodHandles::ref_kind_has_receiver(ref_kind)) {
324       // Load the receiver (not the MH; the actual MemberName&#39;s receiver)
325       // up from the interpreter stack.
326       __ z_lg(Z_recv = Z_R5, Z_R4_first_arg_addr);
327       DEBUG_ONLY(Z_R4_param_size = noreg);
328     }
329 
330     Register Z_member = Z_method;  // MemberName ptr; incoming method ptr is dead now
331 
332     __ z_lg(Z_member, __ argument_address(constant(1)));
333     __ add2reg(Z_esp, Interpreter::stackElementSize);
334     generate_method_handle_dispatch(_masm, iid, Z_recv, Z_member, not_for_compiler_entry);
335   }
336 
337   return entry_point;
338 }
339 
340 void MethodHandles::generate_method_handle_dispatch(MacroAssembler* _masm,
341                                                     vmIntrinsics::ID iid,
342                                                     Register receiver_reg,
343                                                     Register member_reg,
344                                                     bool for_compiler_entry) {
345   assert(is_signature_polymorphic(iid), &quot;expected invoke iid&quot;);
346 
347   Register temp1 = for_compiler_entry ? Z_R10 : Z_R6;
348   Register temp2 = Z_R12;
349   Register temp3 = Z_R11;
350   Register temp4 = Z_R13;
351 
352   if (for_compiler_entry) {
353     assert(receiver_reg == (iid == vmIntrinsics::_linkToStatic ? noreg : Z_ARG1),
354            &quot;only valid assignment&quot;);
355   }
356   if (receiver_reg != noreg) {
357     assert_different_registers(temp1, temp2, temp3, temp4, receiver_reg);
358   }
359   if (member_reg != noreg) {
360     assert_different_registers(temp1, temp2, temp3, temp4, member_reg);
361   }
362   if (!for_compiler_entry) {  // Don&#39;t trash last SP.
363     assert_different_registers(temp1, temp2, temp3, temp4, Z_R10);
364   }
365 
366   if (iid == vmIntrinsics::_invokeBasic) {
367     __ pc(); // Just for the block comment.
368     // Indirect through MH.form.vmentry.vmtarget.
369     jump_to_lambda_form(_masm, receiver_reg, Z_method, Z_R1, temp3, for_compiler_entry);
370     return;
371   }
372 
373   // The method is a member invoker used by direct method handles.
374   if (VerifyMethodHandles) {
375     // Make sure the trailing argument really is a MemberName (caller responsibility).
376     verify_klass(_masm, member_reg,
377                  SystemDictionary::WK_KLASS_ENUM_NAME(MemberName_klass),
378                  temp1, temp2,
379                  &quot;MemberName required for invokeVirtual etc.&quot;);
380   }
381 
382   Address  member_clazz(   member_reg, NONZERO(java_lang_invoke_MemberName::clazz_offset_in_bytes()));
383   Address  member_vmindex( member_reg, NONZERO(java_lang_invoke_MemberName::vmindex_offset_in_bytes()));
384   Address  member_vmtarget(member_reg, NONZERO(java_lang_invoke_MemberName::method_offset_in_bytes()));
385   Address  vmtarget_method(Z_method, NONZERO(java_lang_invoke_ResolvedMethodName::vmtarget_offset_in_bytes()));
386   Register temp1_recv_klass = temp1;
387 
388   if (iid != vmIntrinsics::_linkToStatic) {
389     __ verify_oop(receiver_reg, FILE_AND_LINE);
390     if (iid == vmIntrinsics::_linkToSpecial) {
391       // Don&#39;t actually load the klass; just null-check the receiver.
392       __ null_check(receiver_reg);
393     } else {
394       // Load receiver klass itself.
395       __ null_check(receiver_reg, Z_R0, oopDesc::klass_offset_in_bytes());
396       __ load_klass(temp1_recv_klass, receiver_reg);
397       __ verify_klass_ptr(temp1_recv_klass);
398     }
399     BLOCK_COMMENT(&quot;check_receiver {&quot;);
400     // The receiver for the MemberName must be in receiver_reg.
401     // Check the receiver against the MemberName.clazz.
402     if (VerifyMethodHandles &amp;&amp; iid == vmIntrinsics::_linkToSpecial) {
403       // Did not load it above...
404       __ load_klass(temp1_recv_klass, receiver_reg);
405       __ verify_klass_ptr(temp1_recv_klass);
406     }
407 
408     if (VerifyMethodHandles &amp;&amp; iid != vmIntrinsics::_linkToInterface) {
409       NearLabel L_ok;
410       Register temp2_defc = temp2;
411 
412       __ load_heap_oop(temp2_defc, member_clazz,
413                        noreg, noreg, IS_NOT_NULL);
414       load_klass_from_Class(_masm, temp2_defc, temp3, temp4);
415       __ verify_klass_ptr(temp2_defc);
416       __ check_klass_subtype(temp1_recv_klass, temp2_defc, temp3, temp4, L_ok);
417       // If we get here, the type check failed!
418       __ stop(&quot;receiver class disagrees with MemberName.clazz&quot;);
419       __ bind(L_ok);
420     }
421     BLOCK_COMMENT(&quot;} check_receiver&quot;);
422   }
423   if (iid == vmIntrinsics::_linkToSpecial || iid == vmIntrinsics::_linkToStatic) {
424     DEBUG_ONLY(temp1_recv_klass = noreg);  // These guys didn&#39;t load the recv_klass.
425   }
426 
427   // Live registers at this point:
428   //   member_reg       - MemberName that was the trailing argument.
429   //   temp1_recv_klass - Klass of stacked receiver, if needed.
430   //   Z_R10            - Interpreter linkage if interpreted.
431 
432   bool method_is_live = false;
433 
434   switch (iid) {
435     case vmIntrinsics::_linkToSpecial:
436       if (VerifyMethodHandles) {
437         verify_ref_kind(_masm, JVM_REF_invokeSpecial, member_reg, temp3);
438       }
439       __ load_heap_oop(Z_method, member_vmtarget,
440                        noreg, noreg, IS_NOT_NULL);
441       __ z_lg(Z_method, vmtarget_method);
442       method_is_live = true;
443       break;
444 
445     case vmIntrinsics::_linkToStatic:
446       if (VerifyMethodHandles) {
447         verify_ref_kind(_masm, JVM_REF_invokeStatic, member_reg, temp3);
448       }
449       __ load_heap_oop(Z_method, member_vmtarget,
450                        noreg, noreg, IS_NOT_NULL);
451       __ z_lg(Z_method, vmtarget_method);
452       method_is_live = true;
453       break;
454 
455     case vmIntrinsics::_linkToVirtual: {
456       // Same as TemplateTable::invokevirtual, minus the CP setup and profiling.
457       if (VerifyMethodHandles) {
458         verify_ref_kind(_masm, JVM_REF_invokeVirtual, member_reg, temp3);
459       }
460 
461       // Pick out the vtable index from the MemberName, and then we can discard it.
462       Register temp2_index = temp2;
463       __ z_lg(temp2_index, member_vmindex);
464 
465       if (VerifyMethodHandles) {
466         // if (member_vmindex &lt; 0) stop
467         NearLabel L_index_ok;
468         __ compare32_and_branch(temp2_index, constant(0), Assembler::bcondNotLow, L_index_ok);
469         __ stop(&quot;no virtual index&quot;);
470         __ BIND(L_index_ok);
471       }
472 
473       // Note: The verifier invariants allow us to ignore MemberName.clazz and vmtarget
474       // at this point. And VerifyMethodHandles has already checked clazz, if needed.
475 
476       // Get target method and entry point.
477       __ lookup_virtual_method(temp1_recv_klass, temp2_index, Z_method);
478       method_is_live = true;
479       break;
480     }
481 
482     case vmIntrinsics::_linkToInterface: {
483       // Same as TemplateTable::invokeinterface, minus the CP setup
484       // and profiling, with different argument motion.
485       if (VerifyMethodHandles) {
486         verify_ref_kind(_masm, JVM_REF_invokeInterface, member_reg, temp3);
487       }
488 
489       Register temp3_intf = temp3;
490 
491       __ load_heap_oop(temp3_intf, member_clazz,
492                        noreg, noreg, IS_NOT_NULL);
493       load_klass_from_Class(_masm, temp3_intf, temp2, temp4);
494 
495       Register Z_index = Z_method;
496 
497       __ z_lg(Z_index, member_vmindex);
498 
499       if (VerifyMethodHandles) {
500         NearLabel L;
501         // if (member_vmindex &lt; 0) stop
502         __ compare32_and_branch(Z_index, constant(0), Assembler::bcondNotLow, L);
503         __ stop(&quot;invalid vtable index for MH.invokeInterface&quot;);
504         __ bind(L);
505       }
506 
507       // Given interface, index, and recv klass, dispatch to the implementation method.
508       Label L_no_such_interface;
509       __ lookup_interface_method(temp1_recv_klass, temp3_intf,
510                                  // Note: next two args must be the same:
511                                  Z_index, Z_method, temp2,
512                                  L_no_such_interface);
513       jump_from_method_handle(_masm, Z_method, temp2, Z_R0, for_compiler_entry);
514 
515       __ bind(L_no_such_interface);
516 
517       // Throw exception.
518       __ load_const_optimized(Z_R1, StubRoutines::throw_IncompatibleClassChangeError_entry());
519       __ z_br(Z_R1);
520       break;
521     }
522 
523     default:
524       fatal(&quot;unexpected intrinsic %d: %s&quot;, iid, vmIntrinsics::name_at(iid));
525       break;
526   }
527 
528   if (method_is_live) {
529     // Live at this point: Z_method, O5_savedSP (if interpreted).
530 
531     // After figuring out which concrete method to call, jump into it.
532     // Note that this works in the interpreter with no data motion.
533     // But the compiled version will require that rcx_recv be shifted out.
534     jump_from_method_handle(_masm, Z_method, temp1, Z_R0, for_compiler_entry);
535   }
536 }
537 
538 #ifndef PRODUCT
539 void trace_method_handle_stub(const char* adaptername,
540                               oopDesc* mh,
541                               intptr_t* sender_sp,
542                               intptr_t* args,
543                               intptr_t* tracing_fp) {
544   bool has_mh = (strstr(adaptername, &quot;/static&quot;) == NULL &amp;&amp;
545                  strstr(adaptername, &quot;linkTo&quot;) == NULL);    // Static linkers don&#39;t have MH.
546   const char* mh_reg_name = has_mh ? &quot;Z_R4_mh&quot; : &quot;Z_R4&quot;;
547   tty-&gt;print_cr(&quot;MH %s %s=&quot; INTPTR_FORMAT &quot; sender_sp=&quot; INTPTR_FORMAT &quot; args=&quot; INTPTR_FORMAT,
548                 adaptername, mh_reg_name,
549                 p2i(mh), p2i(sender_sp), p2i(args));
550 
551   if (Verbose) {
552     // Dumping last frame with frame::describe.
553 
554     JavaThread* p = JavaThread::active();
555 
556     ResourceMark rm;
557     PRESERVE_EXCEPTION_MARK; // May not be needed by safer and unexpensive here.
558     FrameValues values;
559 
560     // Note: We want to allow trace_method_handle from any call site.
561     // While trace_method_handle creates a frame, it may be entered
562     // without a valid return PC in Z_R14 (e.g. not just after a call).
563     // Walking that frame could lead to failures due to that invalid PC.
564     // =&gt; carefully detect that frame when doing the stack walking.
565 
566     // Walk up to the right frame using the &quot;tracing_fp&quot; argument.
567     frame cur_frame = os::current_frame(); // Current C frame.
568 
569     while (cur_frame.fp() != tracing_fp) {
570       cur_frame = os::get_sender_for_C_frame(&amp;cur_frame);
571     }
572 
573     // Safely create a frame and call frame::describe.
574     intptr_t *dump_sp = cur_frame.sender_sp();
575     intptr_t *dump_fp = cur_frame.link();
576 
577     bool walkable = has_mh; // Whether the traced frame shoud be walkable.
578 
579     // The sender for cur_frame is the caller of trace_method_handle.
580     if (walkable) {
581       // The previous definition of walkable may have to be refined
582       // if new call sites cause the next frame constructor to start
583       // failing. Alternatively, frame constructors could be
584       // modified to support the current or future non walkable
585       // frames (but this is more intrusive and is not considered as
586       // part of this RFE, which will instead use a simpler output).
587       frame dump_frame = frame(dump_sp);
588       dump_frame.describe(values, 1);
589     } else {
590       // Robust dump for frames which cannot be constructed from sp/younger_sp
591       // Add descriptions without building a Java frame to avoid issues.
592       values.describe(-1, dump_fp, &quot;fp for #1 &lt;not parsed, cannot trust pc&gt;&quot;);
593       values.describe(-1, dump_sp, &quot;sp&quot;);
594     }
595 
596     bool has_args = has_mh; // Whether Z_esp is meaningful.
597 
598     // Mark args, if seems valid (may not be valid for some adapters).
599     if (has_args) {
600       if ((args &gt;= dump_sp) &amp;&amp; (args &lt; dump_fp)) {
601         values.describe(-1, args, &quot;*Z_esp&quot;);
602       }
603     }
604 
605     // Note: the unextended_sp may not be correct.
606     tty-&gt;print_cr(&quot;  stack layout:&quot;);
607     values.print(p);
608     if (has_mh &amp;&amp; oopDesc::is_oop(mh)) {
609       mh-&gt;print();
610       if (java_lang_invoke_MethodHandle::is_instance(mh)) {
611         if (java_lang_invoke_MethodHandle::form_offset_in_bytes() != 0) {
612           java_lang_invoke_MethodHandle::form(mh)-&gt;print();
613         }
614       }
615     }
616   }
617 }
618 
619 void MethodHandles::trace_method_handle(MacroAssembler* _masm, const char* adaptername) {
620   if (!log_is_enabled(Info, methodhandles)) { return; }
621 
622   // If arg registers are contiguous, we can use STMG/LMG.
623   assert((Z_ARG5-&gt;encoding() - Z_ARG1-&gt;encoding() + 1) == RegisterImpl::number_of_arg_registers, &quot;Oops&quot;);
624 
625   BLOCK_COMMENT(&quot;trace_method_handle {&quot;);
626 
627   // Save argument registers (they are used in raise exception stub).
628   // Argument registers have contiguous register numbers -&gt; we can use stmg/lmg.
629   __ z_stmg(Z_ARG1, Z_ARG5, 16, Z_SP);
630 
631   // Setup arguments.
632   __ z_lgr(Z_ARG2, Z_ARG4); // mh, see generate_method_handle_interpreter_entry()
633   __ z_lgr(Z_ARG3, Z_R10);  // sender_sp
634   __ z_lgr(Z_ARG4, Z_esp);
635   __ load_const_optimized(Z_ARG1, (void *)adaptername);
636   __ z_lgr(Z_ARG5, Z_SP);   // tracing_fp
637   __ save_return_pc();      // saves Z_R14
638   __ push_frame_abi160(0);
639   __ call_VM_leaf(CAST_FROM_FN_PTR(address, trace_method_handle_stub));
640   __ pop_frame();
641   __ restore_return_pc();   // restores to Z_R14
642 
643   // Restore argument registers
644   __ z_lmg(Z_ARG1, Z_ARG5, 16, Z_SP);
645   __ zap_from_to(Z_SP, Z_SP, Z_R0, Z_R1, 50, -1);
646   __ zap_from_to(Z_SP, Z_SP, Z_R0, Z_R1, -1, 5);
647 
648   BLOCK_COMMENT(&quot;} trace_method_handle&quot;);
649 }
650 #endif // !PRODUCT
    </pre>
  </body>
</html>