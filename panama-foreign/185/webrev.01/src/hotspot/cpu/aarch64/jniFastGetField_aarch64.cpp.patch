diff a/src/hotspot/cpu/aarch64/jniFastGetField_aarch64.cpp b/src/hotspot/cpu/aarch64/jniFastGetField_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/jniFastGetField_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/jniFastGetField_aarch64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2004, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2004, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -78,35 +78,32 @@
           SafepointSynchronize::safepoint_counter_addr(), offset);
   Address safepoint_counter_addr(rcounter_addr, offset);
   __ ldrw(rcounter, safepoint_counter_addr);
   __ tbnz(rcounter, 0, slow);
 
-  if (!UseBarriersForVolatile) {
-    // Field may be volatile. See other usages of this flag.
-    __ membar(MacroAssembler::AnyAny);
-    __ mov(robj, c_rarg1);
-  } else if (JvmtiExport::can_post_field_access()) {
+  // It doesn't need to issue a full barrier here even if the field
+  // is volatile, since it has already used "ldar" for it.
+  if (JvmtiExport::can_post_field_access()) {
     // Using barrier to order wrt. JVMTI check and load of result.
     __ membar(Assembler::LoadLoad);
-    __ mov(robj, c_rarg1);
-  } else {
-    // Using address dependency to order wrt. load of result.
-    __ eor(robj, c_rarg1, rcounter);
-    __ eor(robj, robj, rcounter);         // obj, since
-                                          // robj ^ rcounter ^ rcounter == robj
-                                          // robj is address dependent on rcounter.
-  }
 
-  if (JvmtiExport::can_post_field_access()) {
     // Check to see if a field access watch has been set before we
     // take the fast path.
     unsigned long offset2;
     __ adrp(result,
             ExternalAddress((address) JvmtiExport::get_field_access_count_addr()),
             offset2);
     __ ldrw(result, Address(result, offset2));
     __ cbnzw(result, slow);
+
+    __ mov(robj, c_rarg1);
+  } else {
+    // Using address dependency to order wrt. load of result.
+    __ eor(robj, c_rarg1, rcounter);
+    __ eor(robj, robj, rcounter);         // obj, since
+                                          // robj ^ rcounter ^ rcounter == robj
+                                          // robj is address dependent on rcounter.
   }
 
   // Both robj and rscratch1 are clobbered by try_resolve_jobject_in_native.
   BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();
   bs->try_resolve_jobject_in_native(masm, c_rarg0, robj, rscratch1, slow);
