<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 2707 }
 2708 
 2709 void MacroAssembler::divsd(XMMRegister dst, AddressLiteral src) {
 2710   if (reachable(src)) {
 2711     Assembler::divsd(dst, as_Address(src));
 2712   } else {
 2713     lea(rscratch1, src);
 2714     Assembler::divsd(dst, Address(rscratch1, 0));
 2715   }
 2716 }
 2717 
 2718 void MacroAssembler::divss(XMMRegister dst, AddressLiteral src) {
 2719   if (reachable(src)) {
 2720     Assembler::divss(dst, as_Address(src));
 2721   } else {
 2722     lea(rscratch1, src);
 2723     Assembler::divss(dst, Address(rscratch1, 0));
 2724   }
 2725 }
 2726 
<span class="line-removed"> 2727 #ifndef _LP64</span>
<span class="line-removed"> 2728 void MacroAssembler::empty_FPU_stack() {</span>
<span class="line-removed"> 2729   if (VM_Version::supports_mmx()) {</span>
<span class="line-removed"> 2730     emms();</span>
<span class="line-removed"> 2731   } else {</span>
<span class="line-removed"> 2732     for (int i = 8; i-- &gt; 0; ) ffree(i);</span>
<span class="line-removed"> 2733   }</span>
<span class="line-removed"> 2734 }</span>
<span class="line-removed"> 2735 #endif // !LP64</span>
<span class="line-removed"> 2736 </span>
<span class="line-removed"> 2737 </span>
 2738 void MacroAssembler::enter() {
 2739   push(rbp);
 2740   mov(rbp, rsp);
 2741 }
 2742 
 2743 // A 5 byte nop that is safe for patching (see patch_verified_entry)
 2744 void MacroAssembler::fat_nop() {
 2745   if (UseAddressNop) {
 2746     addr_nop_5();
 2747   } else {
 2748     emit_int8(0x26); // es:
 2749     emit_int8(0x2e); // cs:
 2750     emit_int8(0x64); // fs:
 2751     emit_int8(0x65); // gs:
 2752     emit_int8((unsigned char)0x90);
 2753   }
 2754 }
 2755 
<span class="line-modified"> 2756 #if !defined(_LP64)</span>
 2757 void MacroAssembler::fcmp(Register tmp) {
 2758   fcmp(tmp, 1, true, true);
 2759 }
 2760 
 2761 void MacroAssembler::fcmp(Register tmp, int index, bool pop_left, bool pop_right) {
 2762   assert(!pop_right || pop_left, &quot;usage error&quot;);
 2763   if (VM_Version::supports_cmov()) {
 2764     assert(tmp == noreg, &quot;unneeded temp&quot;);
 2765     if (pop_left) {
 2766       fucomip(index);
 2767     } else {
 2768       fucomi(index);
 2769     }
 2770     if (pop_right) {
 2771       fpop();
 2772     }
 2773   } else {
 2774     assert(tmp != noreg, &quot;need temp&quot;);
 2775     if (pop_left) {
 2776       if (pop_right) {
</pre>
<hr />
<pre>
 2839   ffree();
 2840   fincstp();
 2841 }
 2842 
 2843 void MacroAssembler::fremr(Register tmp) {
 2844   save_rax(tmp);
 2845   { Label L;
 2846     bind(L);
 2847     fprem();
 2848     fwait(); fnstsw_ax();
 2849     sahf();
 2850     jcc(Assembler::parity, L);
 2851   }
 2852   restore_rax(tmp);
 2853   // Result is in ST0.
 2854   // Note: fxch &amp; fpop to get rid of ST1
 2855   // (otherwise FPU stack could overflow eventually)
 2856   fxch(1);
 2857   fpop();
 2858 }








 2859 #endif // !LP64
 2860 
 2861 void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src) {
 2862   if (reachable(src)) {
 2863     Assembler::mulpd(dst, as_Address(src));
 2864   } else {
 2865     lea(rscratch1, src);
 2866     Assembler::mulpd(dst, Address(rscratch1, 0));
 2867   }
 2868 }
 2869 
 2870 void MacroAssembler::load_float(Address src) {



 2871   if (UseSSE &gt;= 1) {
 2872     movflt(xmm0, src);
 2873   } else {
<span class="line-modified"> 2874     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2875     NOT_LP64(fld_s(src));</span>
 2876   }

 2877 }
 2878 
 2879 void MacroAssembler::store_float(Address dst) {



 2880   if (UseSSE &gt;= 1) {
 2881     movflt(dst, xmm0);
 2882   } else {
<span class="line-modified"> 2883     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2884     NOT_LP64(fstp_s(dst));</span>
 2885   }

 2886 }
 2887 
 2888 void MacroAssembler::load_double(Address src) {



 2889   if (UseSSE &gt;= 2) {
 2890     movdbl(xmm0, src);
 2891   } else {
<span class="line-modified"> 2892     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2893     NOT_LP64(fld_d(src));</span>
 2894   }

 2895 }
 2896 
 2897 void MacroAssembler::store_double(Address dst) {



 2898   if (UseSSE &gt;= 2) {
 2899     movdbl(dst, xmm0);
 2900   } else {
<span class="line-modified"> 2901     LP64_ONLY(ShouldNotReachHere());</span>
<span class="line-removed"> 2902     NOT_LP64(fstp_d(dst));</span>
 2903   }

 2904 }
 2905 
 2906 // dst = c = a * b + c
 2907 void MacroAssembler::fmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2908   Assembler::vfmadd231sd(c, a, b);
 2909   if (dst != c) {
 2910     movdbl(dst, c);
 2911   }
 2912 }
 2913 
 2914 // dst = c = a * b + c
 2915 void MacroAssembler::fmaf(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2916   Assembler::vfmadd231ss(c, a, b);
 2917   if (dst != c) {
 2918     movflt(dst, c);
 2919   }
 2920 }
 2921 
 2922 // dst = c = a * b + c
 2923 void MacroAssembler::vfmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c, int vector_len) {
</pre>
</td>
<td>
<hr />
<pre>
 2707 }
 2708 
 2709 void MacroAssembler::divsd(XMMRegister dst, AddressLiteral src) {
 2710   if (reachable(src)) {
 2711     Assembler::divsd(dst, as_Address(src));
 2712   } else {
 2713     lea(rscratch1, src);
 2714     Assembler::divsd(dst, Address(rscratch1, 0));
 2715   }
 2716 }
 2717 
 2718 void MacroAssembler::divss(XMMRegister dst, AddressLiteral src) {
 2719   if (reachable(src)) {
 2720     Assembler::divss(dst, as_Address(src));
 2721   } else {
 2722     lea(rscratch1, src);
 2723     Assembler::divss(dst, Address(rscratch1, 0));
 2724   }
 2725 }
 2726 











 2727 void MacroAssembler::enter() {
 2728   push(rbp);
 2729   mov(rbp, rsp);
 2730 }
 2731 
 2732 // A 5 byte nop that is safe for patching (see patch_verified_entry)
 2733 void MacroAssembler::fat_nop() {
 2734   if (UseAddressNop) {
 2735     addr_nop_5();
 2736   } else {
 2737     emit_int8(0x26); // es:
 2738     emit_int8(0x2e); // cs:
 2739     emit_int8(0x64); // fs:
 2740     emit_int8(0x65); // gs:
 2741     emit_int8((unsigned char)0x90);
 2742   }
 2743 }
 2744 
<span class="line-modified"> 2745 #ifndef _LP64</span>
 2746 void MacroAssembler::fcmp(Register tmp) {
 2747   fcmp(tmp, 1, true, true);
 2748 }
 2749 
 2750 void MacroAssembler::fcmp(Register tmp, int index, bool pop_left, bool pop_right) {
 2751   assert(!pop_right || pop_left, &quot;usage error&quot;);
 2752   if (VM_Version::supports_cmov()) {
 2753     assert(tmp == noreg, &quot;unneeded temp&quot;);
 2754     if (pop_left) {
 2755       fucomip(index);
 2756     } else {
 2757       fucomi(index);
 2758     }
 2759     if (pop_right) {
 2760       fpop();
 2761     }
 2762   } else {
 2763     assert(tmp != noreg, &quot;need temp&quot;);
 2764     if (pop_left) {
 2765       if (pop_right) {
</pre>
<hr />
<pre>
 2828   ffree();
 2829   fincstp();
 2830 }
 2831 
 2832 void MacroAssembler::fremr(Register tmp) {
 2833   save_rax(tmp);
 2834   { Label L;
 2835     bind(L);
 2836     fprem();
 2837     fwait(); fnstsw_ax();
 2838     sahf();
 2839     jcc(Assembler::parity, L);
 2840   }
 2841   restore_rax(tmp);
 2842   // Result is in ST0.
 2843   // Note: fxch &amp; fpop to get rid of ST1
 2844   // (otherwise FPU stack could overflow eventually)
 2845   fxch(1);
 2846   fpop();
 2847 }
<span class="line-added"> 2848 </span>
<span class="line-added"> 2849 void MacroAssembler::empty_FPU_stack() {</span>
<span class="line-added"> 2850   if (VM_Version::supports_mmx()) {</span>
<span class="line-added"> 2851     emms();</span>
<span class="line-added"> 2852   } else {</span>
<span class="line-added"> 2853     for (int i = 8; i-- &gt; 0; ) ffree(i);</span>
<span class="line-added"> 2854   }</span>
<span class="line-added"> 2855 }</span>
 2856 #endif // !LP64
 2857 
 2858 void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src) {
 2859   if (reachable(src)) {
 2860     Assembler::mulpd(dst, as_Address(src));
 2861   } else {
 2862     lea(rscratch1, src);
 2863     Assembler::mulpd(dst, Address(rscratch1, 0));
 2864   }
 2865 }
 2866 
 2867 void MacroAssembler::load_float(Address src) {
<span class="line-added"> 2868 #ifdef _LP64</span>
<span class="line-added"> 2869   movflt(xmm0, src);</span>
<span class="line-added"> 2870 #else</span>
 2871   if (UseSSE &gt;= 1) {
 2872     movflt(xmm0, src);
 2873   } else {
<span class="line-modified"> 2874     fld_s(src);</span>

 2875   }
<span class="line-added"> 2876 #endif // LP64</span>
 2877 }
 2878 
 2879 void MacroAssembler::store_float(Address dst) {
<span class="line-added"> 2880 #ifdef _LP64</span>
<span class="line-added"> 2881   movflt(dst, xmm0);</span>
<span class="line-added"> 2882 #else</span>
 2883   if (UseSSE &gt;= 1) {
 2884     movflt(dst, xmm0);
 2885   } else {
<span class="line-modified"> 2886     fstp_s(dst);</span>

 2887   }
<span class="line-added"> 2888 #endif // LP64</span>
 2889 }
 2890 
 2891 void MacroAssembler::load_double(Address src) {
<span class="line-added"> 2892 #ifdef _LP64</span>
<span class="line-added"> 2893   movdbl(xmm0, src);</span>
<span class="line-added"> 2894 #else</span>
 2895   if (UseSSE &gt;= 2) {
 2896     movdbl(xmm0, src);
 2897   } else {
<span class="line-modified"> 2898     fld_d(src);</span>

 2899   }
<span class="line-added"> 2900 #endif // LP64</span>
 2901 }
 2902 
 2903 void MacroAssembler::store_double(Address dst) {
<span class="line-added"> 2904 #ifdef _LP64</span>
<span class="line-added"> 2905   movdbl(dst, xmm0);</span>
<span class="line-added"> 2906 #else</span>
 2907   if (UseSSE &gt;= 2) {
 2908     movdbl(dst, xmm0);
 2909   } else {
<span class="line-modified"> 2910     fstp_d(dst);</span>

 2911   }
<span class="line-added"> 2912 #endif // LP64</span>
 2913 }
 2914 
 2915 // dst = c = a * b + c
 2916 void MacroAssembler::fmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2917   Assembler::vfmadd231sd(c, a, b);
 2918   if (dst != c) {
 2919     movdbl(dst, c);
 2920   }
 2921 }
 2922 
 2923 // dst = c = a * b + c
 2924 void MacroAssembler::fmaf(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c) {
 2925   Assembler::vfmadd231ss(c, a, b);
 2926   if (dst != c) {
 2927     movflt(dst, c);
 2928   }
 2929 }
 2930 
 2931 // dst = c = a * b + c
 2932 void MacroAssembler::vfmad(XMMRegister dst, XMMRegister a, XMMRegister b, XMMRegister c, int vector_len) {
</pre>
</td>
</tr>
</table>
<center><a href="globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_x86_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>